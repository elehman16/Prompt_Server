<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Hum Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Hum Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Hum. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Human Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1662-5161</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26528160</article-id><article-id pub-id-type="pmc">4604246</article-id><article-id pub-id-type="doi">10.3389/fnhum.2015.00526</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>The impact of expert visual guidance on trainee visual search strategy, visual attention and motor skills</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Leff</surname><given-names>Daniel R.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn002"><sup>&#x02020;</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/238161/overview"/></contrib><contrib contrib-type="author"><name><surname>James</surname><given-names>David R. C.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn002"><sup>&#x02020;</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/260373/overview"/></contrib><contrib contrib-type="author"><name><surname>Orihuela-Espina</surname><given-names>Felipe</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/268340/overview"/></contrib><contrib contrib-type="author"><name><surname>Kwok</surname><given-names>Ka-Wai</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/267225/overview"/></contrib><contrib contrib-type="author"><name><surname>Sun</surname><given-names>Loi Wah</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Mylonas</surname><given-names>George</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/242327/overview"/></contrib><contrib contrib-type="author"><name><surname>Athanasiou</surname><given-names>Thanos</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Darzi</surname><given-names>Ara W.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Yang</surname><given-names>Guang-Zhong</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Hamlyn Centre for Robotic Surgery, Imperial College London</institution><country>London, UK</country></aff><aff id="aff2"><sup>2</sup><institution>National Institute for Astrophysics, Optics and Electronics (INAOE)</institution><country>Tonantzintla, Mexico</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Klaus Gramann, Berlin Institute of Technology, Germany</p></fn><fn fn-type="edited-by"><p>Reviewed by: Peter K&#x000f6;nig, University of Osnabr&#x000fc;ck, Germany; Frederic Dehais, Institut Sup&#x000e9;rieur de l&#x02019;A&#x000e9;ronautique et de l&#x02019;Espace, France</p></fn><corresp id="fn001">*Correspondence: Guang-Zhong Yang, Hamlyn Centre for Robotic Surgery, Imperial College London, Level 4, Bessemer Building, South Kensington Campus, London, SW7 2AZ, UK <email xlink:type="simple">g.z.yang@imperial.ac.uk</email></corresp><fn fn-type="other" id="fn002"><p><sup>&#x02020;</sup>These authors have contributed equally to this work.</p></fn></author-notes><pub-date pub-type="epub"><day>14</day><month>10</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>9</volume><elocation-id>526</elocation-id><history><date date-type="received"><day>28</day><month>7</month><year>2015</year></date><date date-type="accepted"><day>10</day><month>9</month><year>2015</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2015 Leff, James, Orihuela-Espina, Kwok, Sun, Mylonas, Athanasiou, Darzi and Yang.</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Leff, James, Orihuela-Espina, Kwok, Sun, Mylonas, Athanasiou, Darzi and Yang</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution and reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Minimally invasive and robotic surgery changes the capacity for surgical mentors to guide their trainees with the control customary to open surgery. This neuroergonomic study aims to assess a &#x0201c;Collaborative Gaze Channel&#x0201d; (CGC); which detects trainer gaze-behavior and displays the point of regard to the trainee. A randomized crossover study was conducted in which twenty subjects performed a simulated robotic surgical task necessitating collaboration either with verbal (control condition) or visual guidance with CGC (study condition). Trainee occipito-parietal (O-P) cortical function was assessed with optical topography (OT) and gaze-behavior was evaluated using video-oculography. Performance during gaze-assistance was significantly superior [biopsy number: (mean &#x000b1; SD): control = 5.6 &#x000b1; 1.8 vs. CGC = 6.6 &#x000b1; 2.0; <italic>p</italic> &#x0003c; 0.05] and was associated with significantly lower O-P cortical activity [&#x00394;HbO<sub>2</sub> mMol &#x000d7; cm [median (IQR)] control = 2.5 (12.0) vs. CGC 0.63 (11.2), <italic>p</italic> &#x0003c; 0.001]. A random effect model (REM) confirmed the association between guidance mode and O-P excitation. Network cost and global efficiency were not significantly influenced by guidance mode. A gaze channel enhances performance, modulates visual search, and alleviates the burden in brain centers subserving visual attention and does not induce changes in the trainee&#x02019;s O-P functional network observable with the current OT technique. The results imply that through visual guidance, attentional resources may be liberated, potentially improving the capability of trainees to attend to other safety critical events during the procedure.</p></abstract><kwd-group><kwd>functional near infrared spectroscopy</kwd><kwd>optical topography</kwd><kwd>neuroergonomics</kwd><kwd>graph theory</kwd><kwd>collaborative gaze</kwd><kwd>visual attention</kwd><kwd>skills assessment</kwd><kwd>mentoring</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">Academy of Medical Sciences<named-content content-type="fundref-id">10.13039/501100000691</named-content></funding-source></award-group></funding-group><counts><fig-count count="5"/><table-count count="2"/><equation-count count="0"/><ref-count count="54"/><page-count count="11"/><word-count count="7702"/></counts></article-meta></front><body><sec id="s1"><title>Highlights</title><list list-type="order"><list-item><p>A randomized crossover study assessing the impact of trainer visual guidance upon trainee visual cognition, occipito-parietal (O-P) brain function and technical performance.</p></list-item><list-item><p>Visual guidance is associated with enhanced gaze behavior, improved technical accuracy and attenuated activity across O-P cortices.</p></list-item><list-item><p>Parameters of network performance such as cost and global efficiency are not detrimentally effected by visual guidance.</p></list-item></list></sec><sec sec-type="introduction" id="s2"><title>Introduction</title><p>In high-risk industry, collaboration between operators is integral to performing goal-orientated tasks successfully (e.g., pilots, air-traffic controller, surgeons, etc). Regarding surgery, collaboration is necessary between surgeons and their assistant(s), theatre nurse(s) and occasionally members of allied specialties. Recent developments in technologies for robotic surgery such as dual console systems (e.g., da Vinci<sup>&#x000ae;</sup> Si) enable two surgeons to operate simultaneously, facilitating both high-level co-operation and mentorship as well as potentially streamlining the operators&#x02019; cognitive resources towards improved safety. However, in this scenario, it is important that communication between both surgeons is effective to enable a seamless flow of information between the two operators and ensure an efficient workflow. Similarly, excellent communication facilitates technical skills training in surgery. During &#x0201c;open&#x0201d; surgery, expert trainers&#x02019; employ a variety of methods for communication with trainees that include a combination of verbal instruction, physical pointing or actual demonstration(s). However, during robotic minimally invasive surgery (MIS), there may be circumstances in which the trainee or collaborating surgeon is using both instruments simultaneously within the operative field of view, constraining the trainer/master surgeon and rendering them reliant solely on verbal communication.</p><p>Within MIS and robotic surgery, techniques exist such as telestration that aid information transfer between surgeons and/or between trainer and trainee. Telestration allows information to be &#x0201c;<italic>drawn</italic>&#x0201d; onto a monitor at a remote site by the surgeon guiding the procedure. This information is then displayed on the operator&#x02019;s screen with the aim of guiding performance and may be undertaken either remotely or locally (Ferguson and Stack, <xref rid="B14" ref-type="bibr">2010</xref>). Remote guidance or telementoring enables surgeons to be guided by a mentor at a location remote from the operation. This form of instruction has been applied to better enable regional experts to guide surgeons at local centers and to provide assistance and mentoring from surgical experts in other countries (Micali et al., <xref rid="B31" ref-type="bibr">2000</xref>; Schlachta et al., <xref rid="B38" ref-type="bibr">2010</xref>).</p><p>There has been interest in the role that gaze behavior may have in improving the flow of communication between collaborating subjects. For example, it has been demonstrated that shared gaze during visual collaboration enables a more efficient search strategy when compared to verbal collaboration alone (Brennan et al., <xref rid="B6" ref-type="bibr">2008</xref>). Therefore, it is anticipated that observing a guiding surgeon&#x02019;s point of regard instead of, or in conjunction with their verbal instruction(s) will significantly improve the performance of the operating surgeon by providing supplementary cues critical to task success. Based on this concept, a new system referred to as &#x0201c;<italic>collaborative gaze control</italic>&#x0201d; (CGC) was developed to enable an operating surgeon to be directed by visual guidance as opposed to or in conjunction with verbal instruction(s) from an expert (Kwok et al., <xref rid="B26" ref-type="bibr">2012</xref>). With CGC enabled, the trainer&#x02019;s gaze behavior is extracted in real-time. Their point of regard is subsequently relayed to the trainee&#x02019;s screen, which may be in a remote location. Therefore, the trainee&#x02019;s operative manoeuvres can be directed more precisely, potentially obviating the dependence on verbal instruction(s). Importantly, in manipulating target salience, visual search is modulated leading to enhanced behavioral performance (Avraham et al., <xref rid="B2" ref-type="bibr">2008</xref>).</p><p>More recently, there is evidence that workload can be inferred from saccadic eye movements (Tokuda et al., <xref rid="B43" ref-type="bibr">2011</xref>), pupillary responses (Zheng et al., <xref rid="B52" ref-type="bibr">2015</xref>) and blink frequency (Zheng et al., <xref rid="B51" ref-type="bibr">2012</xref>). Challenging, effortful visual search results in greater visual cortical (V1) excitation (Kojima and Suzuki, <xref rid="B25" ref-type="bibr">2010</xref>). Evaluating the impact that technological manipulation of visual search has on an operator&#x02019;s cortical function helps to determine whether performance enhancement is offset by the need for greater attentional demands at brain level. This is encompassed by &#x0201c;<italic>neuroergonomics</italic>&#x0201d; which concerns the investigation of the brain behavior at work (Parasuraman, <xref rid="B36" ref-type="bibr">2003</xref>), a paradigm that has been applied to surgery in order to investigate how recruited brain regions may be modulated by novel performance-enhancing tools (James et al., <xref rid="B21" ref-type="bibr">2010b</xref>, <xref rid="B18" ref-type="bibr">2013</xref>).</p><p>In order to examine this effect, functional Near Infrared Spectroscopy (fNIRS) a non-invasive neuroimaging modality is utilized to measure task-evoked fluctuations in oxygenated and deoxygenated hemoglobin (HbO<sub>2</sub> and HHb respectively) within cortical tissues that reflects the magnitude of cortical activation (J&#x000f6;bsis, <xref rid="B22" ref-type="bibr">1977</xref>). This is based upon the principle that neuronal activity and the associated increased metabolic demand within the brain leads to local hemodynamic changes, so termed <italic>&#x0201c;neurovascular coupling&#x0201d;</italic> (Roy and Sherrington, <xref rid="B37" ref-type="bibr">1890</xref>). Unlike functional magnetic resonance imaging (fMRI), fNIRS is relatively resistant to motion artifact and can be used in conjunction with ferromagnetic instruments and has been successfully applied to monitor the cortical responses in surgeons (Leff et al., <xref rid="B27" ref-type="bibr">2008a</xref>,<xref rid="B28" ref-type="bibr">b</xref>,<xref rid="B29" ref-type="bibr">c</xref>; Ohuchida et al., <xref rid="B34" ref-type="bibr">2009</xref>; James et al., <xref rid="B19" ref-type="bibr">2011</xref>, <xref rid="B18" ref-type="bibr">2013</xref>). Broadly, these studies highlight the importance of the prefrontal cortex (PFC) in supporting &#x0201c;cognitive phases&#x0201d; of skill learning (Leff et al., <xref rid="B27" ref-type="bibr">2008a</xref>), evolution in PFC excitation with technical skills training (Leff et al., <xref rid="B29" ref-type="bibr">2008c</xref>), and relative PFC redundancy amongst expert surgeons (Ohuchida et al., <xref rid="B34" ref-type="bibr">2009</xref>). More recently, investigators have demonstrated the impact of the type of learning (e.g., implicit vs. explicit) and the influence of technology to stabilize performance and enhance neuronal efficiency amongst surgeons (Zhu et al., <xref rid="B53" ref-type="bibr">2011</xref>; James et al., <xref rid="B18" ref-type="bibr">2013</xref>).</p><p>Functional brain connectivity captured in coherence or cross-correlation between different brain regions can be used to investigate efficiency in brain networks (Zhu et al., <xref rid="B53" ref-type="bibr">2011</xref>; James et al., <xref rid="B18" ref-type="bibr">2013</xref>). Graph Theory, a popular method for interrogating brain networks, can model the organization, development and function of complex networks (Sporns et al., <xref rid="B39" ref-type="bibr">2004</xref>; Bullmore and Sporns, <xref rid="B7" ref-type="bibr">2009</xref>; Sporns, <xref rid="B40" ref-type="bibr">2011</xref>) and has been successfully employed to networks derived from fNIRS data (Niu et al., <xref rid="B33" ref-type="bibr">2012</xref>; James et al., <xref rid="B18" ref-type="bibr">2013</xref>). In this regard, studies investigating graph topology such as the number of connections, cost and efficiency have demonstrated associations between task performance and brain network efficiency or cost-efficiency (Bassett et al., <xref rid="B4" ref-type="bibr">2009</xref>). Despite the above, there have been no studies investigating the influence of varying trainer/mentor guidance on brain function or network architectures amongst trainees.</p><p>The aim of this paper is to investigate the influence of a gaze channel on changes in visual search strategies, technical performance, and brain behavior in a group of task na&#x000ef;ve subjects being instructed to perform simulated biopsy using robotic MIS. Therefore, it is anticipated that compared to verbal guidance technical procedural skills may be superior during gaze-assistance owing to the improved perceptual flow of information to the trainee. The primary hypothesis is that increased target saliency will lead to a <italic>&#x0201c;bottom-up&#x0201d;</italic> search strategy, reflected in a more focused pattern of V1 activation and a reduction in the need for recruitment of extra-striatal visual association areas. Conversely, verbal communication (gold standard) is anticipated to lead to a more effortful <italic>&#x0201c;top down&#x0201d;</italic> visual search strategy, necessitating recruitment of additional cortical regions outside V1, manifest as greater excitation in centers of visual attention. The secondary hypothesis is that collaborative gaze may facilitate the flow of information transfer in the visual-parietal network manifest as reduced network costs, improved efficiency and reduced network burden.</p></sec><sec sec-type="materials|methods" id="s3"><title>Materials and Methods</title><sec id="s3-1"><title>Subjects</title><p>The study was carried out in accordance with the recommendations of the Local Regional Research Ethics Committee (LREC 05/Q0403/142) with written informed consent from all subjects. All subjects gave written informed consent in accordance with the Declaration of Helsinki. Following ethical approval a randomized control trial was conducted in which 20 subjects (1 female) were recruited from Imperial College London (mean age, years &#x000b1; SD = 28.9 &#x000b1; 1.5). Left-handed subjects and those with a history of neuropsychiatric illness or previous exposure to the task were excluded (Orihuela-Espina et al., <xref rid="B35" ref-type="bibr">2010</xref>). Subjects were included on the basis that they were task na&#x000ef;ve. The task was performed under both guidance conditions (order randomized) such that subjects served as their own controls and bias associated with learning or ordering effects was minimized.</p></sec><sec id="s3-2"><title>Task Paradigm</title><p>The robotic surgical task entailed the subject (<italic>&#x0201c;trainee&#x0201d;</italic>) and an expert (<italic>&#x0201c;trainer&#x0201d;</italic>) collaborating in taking virtual biopsies from a simulated gastric mucosa in a shared surgical environment as depicted in Figure <xref ref-type="fig" rid="F1">1</xref>. Haptic manipulators (Phantom, Omni, SensAble Technologies, USA) were used to control robotic graspers in the virtual scene. The task necessitated the trainee take a virtual biopsy and pass the specimen to the guiding trainer. Both the trainee&#x02019;s and the trainer&#x02019;s graspers were visible within the same field of view with the former located inferiorly and the latter superiorly as depicted in Figure <xref ref-type="fig" rid="F1">1</xref> (panels i&#x02013;iv). Within the operative field, seven nodules were visible to the trainee. The choice of nodule for biopsy was randomly determined and this selection was available only to the trainer. Therefore, the appropriate biopsy site had to be conveyed to the trainee either visually or verbally by the trainer. Once the biopsy was taken by the trainee, the specimen was passed towards the trainer&#x02019;s graspers and when successfully transferred to the trainer, it disappeared from the field of view. This process was repeated as many times as possible during the allotted task periods.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Experimental task set up.</bold> Both the trainee <bold>(A)</bold> and trainer <bold>(B)</bold> control the virtual instruments, each with two haptic manipulators (Phantom Omni, SensAble Tech, USA). The trainer&#x02019;s right hand manipulator is highlighted (yellow). Gaze behavior is detected with portable eyetracker (X50 eyetracker, Tobii Technologies, Sweden) situated below both monitors (trainer eyetracker highlighted yellow). An Optical topography (OT) system (ETG-4000, Hitachi Medical Corp. Japan) positioned outside the trainee&#x02019;s field of view (left, highlighted) records cortical hemodynamic data from 24 cortical loci (channels). Appropriate channel locations (yellow circles) are understood by projecting 3D positional data onto a T1 weighted MRI image (upper subplot). The lowermost row of channels was centered on Oz of the International 10&#x02013;10 system (Jurcak et al., <xref rid="B23" ref-type="bibr">2007</xref>). Task images can be appreciated on trainer and trainee monitors and sample screen shots are represented in which the trainee&#x02019;s instruments are located inferiorly (i&#x02013;iv). With the collaborative gaze channel (CGC) enabled, the trainee regards the blue cross indicating the intended biopsy target (i). The trainee then grasps the nodule (black circle) (ii) and passes it to the trainer&#x02019;s instrument (iii&#x02013;iv). With the channel disabled, the trainee performs identical maneouvres but only with verbal instructions from the trainer.</p></caption><graphic xlink:href="fnhum-09-00526-g0001"/></fig><p>Prior to commencing the study, all subjects received a standardized period of task familiarization. All subjects performed the simulated biopsy task under verbal (control) and visual instruction (CGC; Kwok et al., <xref rid="B26" ref-type="bibr">2012</xref>). The order was randomized (random number generator) in order to control for learning effects. Regarding the control task, the location of the biopsy site was described by the trainer using verbal instructions. With CGC enabled, a portable eyetracker (&#x000d7;50 eyetracker Tobii Technologies, Sweden) situated beneath the trainer&#x02019;s monitor detected their fixation point and conveyed this to the trainee&#x02019;s screen as a cross. Therefore, with CGC enabled, the trainer&#x02019;s target selection would be conveyed to the trainee. For each condition (verbal and CGC) a block design experiment was employed comprising a baseline rest period (30 s) followed by five task blocks each of which comprised alternating episodes of simulated nodule biopsy (30 s) and inter-trial rest periods (30 s). During rest periods, subjects were asked to remain still with their eyes open regarding a black screen on the task monitor. Within functional neuroimaging experiments, block design paradigms have the advantage of allowing the hemodynamic response to return to baseline between each session, therefore providing reliable indices of task-evoked cortical activity. Furthermore, the block design allows task data to be averaged, increasing the signal to noise ratio.</p></sec><sec id="s3-3"><title>Cortical Activity</title><p>Brain activation was assessed using a commercially available 24-channel Optical topography (OT) system (ETG-4000, Hitachi Medical Corp., Japan). Sixteen optodes (8 emitters and 8 detectors) were positioned in a 4 &#x000d7; 4 array over the O-P cortices as displayed in Figure <xref ref-type="fig" rid="F1">1</xref>. A &#x0201c;channel&#x0201d; represents a banana-shaped volume of cortex where changes in absorption of near infrared light from the optode emitters are interpreted as changes in HbO<sub>2</sub> and HHb. The array was centered on &#x0201c;Oz&#x0201d; of the International 10&#x02013;20 system (Jurcak et al., <xref rid="B23" ref-type="bibr">2007</xref>) with the intention of capturing activation within the visual cortex. Cortical data was subject to both manual and automated data integrity checks (Orihuela-Espina et al., <xref rid="B35" ref-type="bibr">2010</xref>) to identify and eliminate data contaminated with noise, optode movement and saturation-related artifacts (i.e., apparent non-recordings and &#x0201c;mirroring&#x0201d;). Since both ambient light and near infra-red light from eye-tracking systems have the potential to influence OT data (Orihuela-Espina et al., <xref rid="B35" ref-type="bibr">2010</xref>), laboratory lights were dimmed and the probes were shielded using a combination of external fixation tapes and shower cap.</p></sec><sec id="s3-4"><title>Technical Performance</title><p>The number of nodules that the trainee was able to successfully biopsy and transfer to the trainer&#x02019;s graspers across the task period and the trainee&#x02019;s instrument pathlength (metres) were recorded and used as objective metrics of technical performance. This was preferred to restricting the overall number of moves towards calculating time/nodule biopsied, and helped to ensure that subjects were focusing on the task quality and not the procedural time, or perceiving the number of movements.</p></sec><sec id="s3-5"><title>Gaze Behavior</title><p>Subject and trainer gaze behavior was recorded throughout the study with portable eyetracking technology (&#x000d7;50 eyetracker, Tobii Technologies, Sweden) situated beneath the task monitor (as displayed in Figure <xref ref-type="fig" rid="F1">1</xref>). The gaze behavior of the trainer was interrogated to derive their fixation point in order to display this as a cross on the trainee&#x02019;s monitor thereby facilitating gaze-guidance in CGC (study condition). The trainer&#x02019;s fixation point was not visible to the trainee during episodes of verbal guidance (control condition). The trainee&#x02019;s fixation points were recorded to determine the time taken, termed &#x0201c;gaze latency&#x0201d; (GL, seconds), to fixate on the same area of the surgical scene as the expert.</p></sec><sec id="s3-6"><title>Heart Rate Monitoring</title><p>A portable band electrocardiogram (Bioharness v2.3.0.5; Zephyr Technology Limited, USA) was used to acquire continuous heart rate data, from which heart rate variability (HRV) was derived and used to infer subject stress (Task Force of the European Society of Cardiology the North American Society of Pacing Electrophysiology, <xref rid="B41" ref-type="bibr">1996</xref>).</p></sec></sec><sec id="s4"><title>Data Analysis</title><sec id="s4-1"><title>Cortical Hemodynamics</title><p>Cortical hemodynamic data and network graph econometrics were observed to be non-Gaussian and therefore analyzed using non-parametric tests of significance. Channel-wise cortical activation was determined as a task-evoked statistically significant increase in HbO<sub>2</sub> coupled to a significant decrease in HHb from baseline rest (Wilcoxon Rank Sign, <italic>p</italic> &#x0003c; 0.05). For each channel of data and hemoglobin species a variable &#x00394;Hb was computed (Hb task&#x02013;Hb rest). To investigate the influence of the mode of guidance (CGC vs. control) and stress on cortical hemodynamics (i.e., &#x00394;HbO<sub>2</sub> and &#x00394;HHb) random effects models (REM) were generated (Intercooled Stata, v10.0 for windows, Stata Corporation, USA).</p><p>Cortical hemodynamic data was subsequently used to construct a task-evoked network of the 24 channels using graph theory (Bullmore and Sporns, <xref rid="B7" ref-type="bibr">2009</xref>). A 24 &#x000d7; 24 bidimensional cross-correlation matrix was constructed by cross-correlating data between all channels, as previously described (James et al., <xref rid="B18" ref-type="bibr">2013</xref>). This matrix represents the strength of functional associations within the network of 24 channels. Comparisons between graphs of different functional networks are potentially sensitive to the method used for thresholding, for which an optimal solution does not yet exist (van Wijk et al., <xref rid="B46" ref-type="bibr">2010</xref>). Therefore, to evaluate the active network, the matrix was pruned to eliminate &#x0201c;inactive&#x0201d; graph nodes. This approach renders a network for each subject during each task condition.</p><p>Econometric data from these networks was then calculated to derive: (a) the number of network connections; (b) the maximum global efficiency (Achard and Bullmore, <xref rid="B1" ref-type="bibr">2007</xref>); (c) the normalized cost (Achard and Bullmore, <xref rid="B1" ref-type="bibr">2007</xref>); and (d) the task-induced <italic>&#x0201c;network burden&#x0201d;</italic> (James et al., <xref rid="B20" ref-type="bibr">2010a</xref>). Network economy is defined as efficiency minus cost (Achard and Bullmore, <xref rid="B1" ref-type="bibr">2007</xref>). The network burden is defined here as&#x02014;economy which equates to &#x0201c;cost-efficiency&#x0201d;. If a network is economical the cost-efficiency is high and accordingly the network burden is low. Network measures were also compared between the study and control groups using REM analysis to determine whether the mode of guidance (CGC vs. control) significantly influenced network econometrics. Statistical significance was set at <italic>p</italic> = 0.05.</p></sec><sec id="s4-2"><title>Performance and Gaze Behavior</title><p>The number of nodules biopsied by each subject during the allotted task time and the instrument pathlength (metres) were determined. GL (seconds) was derived from the eye-tracking data stream. Behavioral performance and GL data was observed to be Gaussian and therefore analyzed using paired <italic>t</italic>-tests. These data were subsequently incorporated into the REM analysis in order to assess whether the guidance mode (control vs. CGC) was a predictor of performance accuracy and efficiency in visual search.</p></sec><sec id="s4-3"><title>Heart Rate Analysis</title><p>HRV as calculated by the standard deviation of the R to R interval (SD<sub>RR</sub>) was derived from the HR data stream (Task Force of the European Society of Cardiology the North American Society of Pacing Electrophysiology, <xref rid="B41" ref-type="bibr">1996</xref>). The SD<sub>RR</sub> decreases under stress and was incorporated into the REM analysis, to exclude any potential confounding effect that differences in HRV or changes in mean HR may exert on changes in cortical hemodynamics. Furthermore, HRV was utilized to determine which mode of guidance (verbal vs. CGC) trainee&#x02019;s found the most stressful by undertaking a univariate random effects analysis (<italic>p</italic> = 0.05).</p></sec></sec><sec sec-type="results" id="s5"><title>Results</title><sec id="s5-1"><title>Technical Performance</title><p>Biopsy number and instrument pathlength was analyzed to determine whether CGC improved trainees&#x02019; technical performance. As illustrated in Figure <xref ref-type="fig" rid="F2">2A</xref>, gaze-guidance under the influence of CGC resulted in enhanced technical performance. Table <xref ref-type="table" rid="T1">1</xref> highlights the differences in technical performance according to the mode of guidance. With gaze-assistance, trainees&#x02019; biopsied a significantly greater number of nodules [biopsy number (mean &#x000b1; SD): control = 5.6 &#x000b1; 1.8 vs. CGC = 6.6 &#x000b1; 2.0, <italic>p</italic> &#x0003c; 0.05] using significantly shorter instrument pathlength (metres) [mean &#x000b1; SD: control = 0.6 &#x000b1; 0.1 vs. CGC = 0.3 &#x000b1; 0.7, <italic>p</italic> &#x0003c; 0.001]. This implies that trainees were faster, more productive and used virtual instruments more economically when operating from the CGC mode.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>(A)</bold> Technical performance as indexed by the number of biopsies retrieved (I) and instrument path length (II). Box plots indicate mean and error bars represent 95% confidence interval. <bold>(B)</bold> Gaze plots from a representative subject under control (I) and gaze guidance (II) demonstrate more focussed fixations during gaze-assistance.</p></caption><graphic xlink:href="fnhum-09-00526-g0002"/></fig><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>The influence of guidance mode on technical performance, visual search behavior, changes in cortical hemodynamics, network topological properties and systemic effects</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" rowspan="1" colspan="1">Outcome variable</th><th align="center" rowspan="1" colspan="1">Control condition (Mean &#x000b1; SD)</th><th align="center" rowspan="1" colspan="1">CGC condition (Mean &#x000b1; SD)</th><th align="center" rowspan="1" colspan="1"><italic>t</italic>-value</th><th align="center" rowspan="1" colspan="1"><italic>p</italic>-value</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Technical lerformance</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Biopsy number</td><td align="center" rowspan="1" colspan="1">5.6 &#x000b1; 1.8</td><td align="center" rowspan="1" colspan="1">6.6 &#x000b1; 2.0</td><td align="center" rowspan="1" colspan="1">&#x02212;3.394</td><td align="center" rowspan="1" colspan="1"><bold>0.003</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Instrument path length (m)</td><td align="center" rowspan="1" colspan="1">0.6 &#x000b1; 0.1</td><td align="center" rowspan="1" colspan="1">0.3 &#x000b1; 0.7</td><td align="center" rowspan="1" colspan="1">11.765</td><td align="center" rowspan="1" colspan="1"><bold><italic>0.000</italic></bold></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Visual search</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Gaze latency (s)</td><td align="center" rowspan="1" colspan="1">1.4 &#x000b1; 0.3</td><td align="center" rowspan="1" colspan="1">0.8 &#x000b1; 0.2</td><td align="center" rowspan="1" colspan="1">7.292</td><td align="center" rowspan="1" colspan="1"><bold><italic>0.000</italic></bold></td></tr><tr><td align="left" colspan="5" rowspan="1"><hr/></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Outcome variable</bold></td><td align="center" rowspan="1" colspan="1"><bold>Control condition median (IQR)</bold></td><td align="center" rowspan="1" colspan="1"><bold>CGC condition median (IQR)</bold></td><td align="center" rowspan="1" colspan="1"><bold><italic>z</italic>-value</bold></td><td align="center" rowspan="1" colspan="1"><bold><italic>p</italic>-value</bold></td></tr><tr><td align="left" colspan="5" rowspan="1"><hr/></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Cortical hemodynamics</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HbO<sub>2</sub> (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">2.5 (12.0)</td><td align="center" rowspan="1" colspan="1">0.6 (11.2)</td><td align="center" rowspan="1" colspan="1">&#x02212;4.049</td><td align="center" rowspan="1" colspan="1"><bold><italic>0.000</italic></bold></td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HHb (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">&#x02212;1.4 (5.0)</td><td align="center" rowspan="1" colspan="1">&#x02212;1.0 (4.5)</td><td align="center" rowspan="1" colspan="1">&#x02212;1.098</td><td align="center" rowspan="1" colspan="1">0.272</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HbT (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">3.6 (13)</td><td align="center" rowspan="1" colspan="1">1.1 (11.6)</td><td align="center" rowspan="1" colspan="1">&#x02212;6.064</td><td align="center" rowspan="1" colspan="1"><bold><italic>0.000</italic></bold></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Cortical network</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Normalized cost (a.u.)</td><td align="center" rowspan="1" colspan="1">0.10 (0.13)</td><td align="center" rowspan="1" colspan="1">0.19 (0.43)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.722</td><td align="center" rowspan="1" colspan="1">0.470</td></tr><tr><td align="left" rowspan="1" colspan="1">Global efficiency (a.u.)</td><td align="center" rowspan="1" colspan="1">0.03 (0.05)</td><td align="center" rowspan="1" colspan="1">0.02 (0.08)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.220</td><td align="center" rowspan="1" colspan="1">0.826</td></tr><tr><td align="left" rowspan="1" colspan="1">Network burden (a.u.)</td><td align="center" rowspan="1" colspan="1">0.09 (0.14)</td><td align="center" rowspan="1" colspan="1">0.18 (0.46)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.847</td><td align="center" rowspan="1" colspan="1">0.397</td></tr><tr><td align="left" rowspan="1" colspan="1">Network edges (a.u.)</td><td align="center" rowspan="1" colspan="1">56.0 (304.0)</td><td align="center" rowspan="1" colspan="1">81.0 (120.0)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.589</td><td align="center" rowspan="1" colspan="1">0.556</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Systemic effect</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Heart rate (beatsmin<sup>-1</sup>)</td><td align="center" rowspan="1" colspan="1">71.2 (10.0)</td><td align="center" rowspan="1" colspan="1">73.4 (8.1)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.392</td><td align="center" rowspan="1" colspan="1">0.695</td></tr><tr><td align="left" rowspan="1" colspan="1">SD<sub>NN</sub></td><td align="center" rowspan="1" colspan="1">57.7 (42.0)</td><td align="center" rowspan="1" colspan="1">47.2 (36.9)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.784</td><td align="center" rowspan="1" colspan="1">0.433</td></tr></tbody></table><table-wrap-foot><p><italic>p &#x0003c; 0.05 = bold, p &#x0003c; 0.001 = bold italic</italic>.</p></table-wrap-foot></table-wrap></sec><sec id="s5-2"><title>Gaze Behavior</title><p>GL which represents the temporal delay between trainer and trainee gaze fixation was analyzed to determine whether gaze guidance streamlined trainee visual search. Figure <xref ref-type="fig" rid="F2">2B</xref> depicts the visual search pattern acquired from a representative trainee under both guidance conditions. It is apparent that whilst operating under gaze guidance, trainee fixations appear to be more localized to the nodule to be biopsied. GL was significantly shorter in CGC mode [GL seconds (mean &#x000b1; SD): control = 1.4 &#x000b1; 0.3 vs. CGC = 0.8 &#x000b1; 0.2, <italic>p</italic> &#x0003c; 0.001]. This suggests that gaze assistance manifests as more rapid fixation on the appropriate target nodule to be biopsied.</p></sec><sec id="s5-3"><title>Cortical Activation</title><p>Cortical hemodynamic change was analyzed to compare trainee brain responses between verbal and gaze-assisted modes of operation, with the hypothesis that verbal guidance would induce higher amplitude and spatially broader O-P hemodynamic changes. Topograms of a representative subject depicting the average change in HbO<sub>2</sub> overlying the O-P cortices are displayed in Figure <xref ref-type="fig" rid="F3">3</xref>. Table <xref ref-type="table" rid="T1">1</xref>, depicts cortical hemodynamic change as &#x00394;HbO<sub>2</sub> (mMol &#x000d7; cm) averaged across the O-P cortices for both verbal and gaze-guidance. Cortical hemodynamic change evoked by verbal guidance was more diffuse as illustrated in Figure <xref ref-type="fig" rid="F4">4</xref> (CGC: 11/24 channels active vs. verbal: 19/24 channels active), more likely to involve bilateral parietal as well as bilateral visual cortices and was greater in magnitude than the response evoked by gaze guidance (&#x00394;HbO<sub>2</sub> mMol &#x000d7; cm [median (IQR)]: control = 2.5 (12.0) vs. CGC = 0.63 (11.2), <italic>p</italic> &#x0003c; 0.001; &#x00394;HbT mMol &#x000d7; cm [median (IQR)]: control = 3.6. (13.0) vs. CGC = 1.1 (11.6), <italic>p</italic> &#x0003c; 0.001). Overall, this data supports the primary hypothesis that training in CGC mode evokes an attenuated O-P brain response. The mode of guidance did not significantly influence the magnitude of &#x00394;HHb [&#x00394;HHb mMol &#x000d7; cm [median (IQR)]: control = &#x02212;1.4 (5.0) vs. CGC = &#x02212;1.0 (4.5), <italic>p</italic> = 0.27]. Similarly, as highlighted in Table <xref ref-type="table" rid="T2">2</xref>, REM analysis revealed that guidance mode was a predictor of &#x00394;HbO<sub>2</sub> (<italic>p</italic> &#x0003c; 0.001) but not of &#x00394;HHb (<italic>p</italic> = 0.19).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Topograms derived from task averaged HbO<sub>2</sub> response of a representative subject for verbal (left) and gaze guidance (right) conditions, depicting spatially broader task-evoked oxygenated hemoglobin change during verbal guidance</bold>.</p></caption><graphic xlink:href="fnhum-09-00526-g0003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Figure depicting group averaged (O-P) channel activation for verbal (left) and gaze guidance (right).</bold> Magnitude of statistical changes in cortical hemodynamics reflect intensity of brain activation as follows: <bold>(A)</bold> statistically significant (<italic>p</italic> &#x0003c; 0.05) increase in HbO<sub>2</sub> coupled to statistically significant (<italic>p</italic> &#x0003c; 0.05) decrease in HHb (red circles); <bold>(B)</bold> increase HbO<sub>2</sub> and decrease HHb with one species reaching statistical significance, <italic>p</italic> &#x0003c; 0.05 (spots); <bold>(C)</bold> increase HbO<sub>2</sub> and decrease HHb with neither species reaching statistical significance (stripes); and <bold>(D)</bold> no coupled increase HbO<sub>2</sub> and decrease HHb (clear circles). Verbal guidance resulted in a greater number of activating channels (control vs. CGC = 19/24 vs. 11/24).</p></caption><graphic xlink:href="fnhum-09-00526-g0004"/></fig><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Results of univariate random effect models (REM), evaluating the influence of the independent variable (mode of guidance) on dependent variables including performance, changes in cortical hemodynamics, cortical network metrics, heart rate (HR) and heart rate variability (HRV)</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Dependent variable</th><th align="center" rowspan="1" colspan="1">Coefficient</th><th align="center" rowspan="1" colspan="1"><italic>S.E.</italic></th><th align="center" rowspan="1" colspan="1"><italic>p</italic> &#x0003e; z</th><th align="center" rowspan="1" colspan="1">95% <italic>C.I.</italic></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Biopsy number</td><td align="center" rowspan="1" colspan="1">0.090</td><td align="center" rowspan="1" colspan="1">0.040</td><td align="center" rowspan="1" colspan="1"><bold>0.025</bold></td><td align="center" rowspan="1" colspan="1">0.011 to &#x02212;0.168</td></tr><tr><td align="left" rowspan="1" colspan="1">Instrument pathlength (m)</td><td align="center" rowspan="1" colspan="1">&#x02212;3.20</td><td align="center" rowspan="1" colspan="1">0.312</td><td align="center" rowspan="1" colspan="1"><italic>0.000</italic></td><td align="center" rowspan="1" colspan="1">&#x02212;3.808 to &#x02212;2.586</td></tr><tr><td align="left" rowspan="1" colspan="1">Gaze latency (s)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.761</td><td align="center" rowspan="1" colspan="1">0.118</td><td align="center" rowspan="1" colspan="1"><italic>0.000</italic></td><td align="center" rowspan="1" colspan="1">&#x02212;0.992 to &#x02212;0.530</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HbO<sub>2</sub> (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">&#x02212;1.294</td><td align="center" rowspan="1" colspan="1">0.326</td><td align="center" rowspan="1" colspan="1"><italic>0.000</italic></td><td align="center" rowspan="1" colspan="1">&#x02212;1.933 to &#x02212;0.654</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HHb (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.198</td><td align="center" rowspan="1" colspan="1">0.151</td><td align="center" rowspan="1" colspan="1">0.188</td><td align="center" rowspan="1" colspan="1">&#x02212;0.494 to &#x02212;0.097</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x00394;HbT (mMol &#x000d7; cm)</td><td align="center" rowspan="1" colspan="1">&#x02212;1.094</td><td align="center" rowspan="1" colspan="1">0.303</td><td align="center" rowspan="1" colspan="1"><italic>0.000</italic></td><td align="center" rowspan="1" colspan="1">&#x02212;1.689 to &#x02212;0.500</td></tr><tr><td align="left" rowspan="1" colspan="1">No. of connections</td><td align="center" rowspan="1" colspan="1">&#x02212;0.000</td><td align="center" rowspan="1" colspan="1">0.000</td><td align="center" rowspan="1" colspan="1">0.754</td><td align="center" rowspan="1" colspan="1">&#x02212;0.002 to &#x02212;0.001</td></tr><tr><td align="left" rowspan="1" colspan="1">Normalized cost (a.u.)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.036</td><td align="center" rowspan="1" colspan="1">0.101</td><td align="center" rowspan="1" colspan="1">0.720</td><td align="center" rowspan="1" colspan="1">&#x02212;0.234 to &#x02212;0.161</td></tr><tr><td align="left" rowspan="1" colspan="1">Network burden (a.u.)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.333</td><td align="center" rowspan="1" colspan="1">0.097</td><td align="center" rowspan="1" colspan="1">0.732</td><td align="center" rowspan="1" colspan="1">&#x02212;0.244 to &#x02212;0.157</td></tr><tr><td align="left" rowspan="1" colspan="1">Global efficiency (a.u.)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.106</td><td align="center" rowspan="1" colspan="1">0.282</td><td align="center" rowspan="1" colspan="1">0.706</td><td align="center" rowspan="1" colspan="1">&#x02212;0.659 to &#x02212;0.446</td></tr><tr><td align="left" rowspan="1" colspan="1">Mean HR (beatsmin<sup>-1</sup>)</td><td align="center" rowspan="1" colspan="1">0.008</td><td align="center" rowspan="1" colspan="1">0.009</td><td align="center" rowspan="1" colspan="1">0.353</td><td align="center" rowspan="1" colspan="1">&#x02212;0.009 to &#x02212;0.025</td></tr><tr><td align="left" rowspan="1" colspan="1">SD<sub>NN</sub></td><td align="center" rowspan="1" colspan="1">&#x02212;0.002</td><td align="center" rowspan="1" colspan="1">0.003</td><td align="center" rowspan="1" colspan="1">0.595</td><td align="center" rowspan="1" colspan="1">&#x02212;0.008 to &#x02212;0.004</td></tr></tbody></table><table-wrap-foot><p><italic>(p &#x0003c; 0.05 = bold, p &#x0003c; 0.001 = bold italic)</italic>.</p></table-wrap-foot></table-wrap></sec><sec id="s5-4"><title>Cortical Networks</title><p>Graph theoretical econometric data were computed and compared between guidance modes with the hypothesis that the performance of functional network in CGC mode would be associated with less cost and greater efficiency. Figure <xref ref-type="fig" rid="F5">5</xref> depicts the activated cortical network under control and CGC conditions for a representative subject. Table <xref ref-type="table" rid="T1">1</xref> represent results of econometric analysis delineating the number of cortical connections, normalized cost, maximum global efficiency and cognitive burden. Differences in these network topological properties between modes guidance did not reach statistical threshold. Additionally, even when subject-level clustering was considered (Table <xref ref-type="table" rid="T2">2</xref>) guidance mode was not found to predict network properties (e.g., cost, efficiency, etc). This suggests that CGC does not induce changes in the trainee&#x02019;s O-P functional network observable with the current OT technique.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Activity-guided cortical networks for a representative subject during the control condition (A) and study condition (B).</bold> Approximate channel locations (black circles) are overlain onto reference MRI atlas. The strength of functional associations between nodes in the network is represented by the boldness of network edges.</p></caption><graphic xlink:href="fnhum-09-00526-g0005"/></fig></sec><sec id="s5-5"><title>Heart Rate Data</title><p>HR and SD<sub>RR</sub> were monitored to determine the influence of guidance mode on stress-related change in systemic responses (Table <xref ref-type="table" rid="T1">1</xref>). Between-condition differences in HR and SD<sub>RR</sub> were not statistically significant [Median HR (IQR): control = 71.2 (10.0) vs. CGC = 73.4 (8.1) <italic>p</italic> = 0.70; Median SD<sub>RR</sub> (IQR): control = 57.7 (42.0) vs. CGC = 47.2 (36.9), <italic>p</italic> = 0.43). Additionally, upon REM analysis, neither HR nor SD<sub>RR</sub> were observed to be predictors for changes in cortical hemodynamics.</p></sec><sec id="s5-6"><title>Harms</title><p>No harms occurred in the study.</p></sec></sec><sec sec-type="discussion" id="s6"><title>Discussion</title><p>In this study, performance on a simulated surgical task has been improved by modulating the manner in which collaborating surgeons interact with one another. Communicating through collaborative gaze-driven control leads to a greater number of successful biopsies and a reduction in instrument path length, the latter being a measure of dexterity previously shown to reflect skill level in laparoscopic and open surgery (Bann et al., <xref rid="B3" ref-type="bibr">2003</xref>; Xeroulis et al., <xref rid="B49" ref-type="bibr">2009</xref>). The foundation for this improvement appears to be a change in visual search strategy manifest as a reduced GL indicating that with gaze-assistance, trainee fixation points more rapidly reach those of the expert. This was accompanied by an amelioration of cortical excitation across primary visual centers in the brain, but without an appreciable difference in O-P network costs or burden.</p><p>The current paper offers a potential mechanistic explanation for improvements observed in novices&#x02019; performance when training under the influence of expert visual cues (Wilson et al., <xref rid="B48" ref-type="bibr">2011</xref>; Chetwood et al., <xref rid="B10" ref-type="bibr">2012</xref>). Experienced operators are known to utilize more effective gaze-strategies than novices, characterized by fixating on relevant target locations and adopting optimal psychomotor control (Wilson et al., <xref rid="B48" ref-type="bibr">2011</xref>). Unlike novices who learn mapping rules by switching their point of regard between tool and target, experts utilize a target locking strategy and rarely need to check tool locations (Leong et al., <xref rid="B30" ref-type="bibr">2008</xref>). As demonstrated by Wilson et al. (<xref rid="B48" ref-type="bibr">2011</xref>), novices trained to observe and then &#x0201c;mimic&#x0201d; the more focused gaze patterns of experts improve their laparoscopic performance and multi-tasking capabilities more than novices trained to observe expert performance without the benefit of expert gaze-cues. Similarly, Chetwood et al. (<xref rid="B10" ref-type="bibr">2012</xref>) observed improved completion times and reduced errors in novices guided by expert gaze vs. expert verbal instructions. However, unlike the current experiment, the aforementioned studies were not designed to explain the foundation for improved performance owing to gaze guidance, resulting instead in speculation regarding adaptation in visual cognitive function. Here, improved performance as a result of expert gaze guidance is understood as a reduction in visual activation and hence attentional demand on the visual cortex. This is in line with studies demonstrating learning related plasticity in activation maps implying attenuation of attentional resources associated with training and expertise (Dayan and Cohen, <xref rid="B11" ref-type="bibr">2011</xref>). By manipulating the visual behavior of novices in a way that they align more closely with those of experts it is conceivable that novices may bypass the early &#x0201c;cognitive&#x0201d; phases of visual-motor learning (Fitts and Posner, <xref rid="B15" ref-type="bibr">1967</xref>). This notwithstanding confirming that the gaze behavior of trainees operating under gaze guidance was characterized by less random saccadic activity and was indeed more &#x0201c;expert&#x0201d; cannot be confirmed using GL alone and would necessitate a more elaborate analysis of eye-tracking data such as using exploit/explore ratio (Dehais et al., <xref rid="B120" ref-type="bibr">2015</xref>) or visual entropy (Di Nocera et al., <xref rid="B121" ref-type="bibr">2007</xref>).</p><p>There is evidence from functional neuroimaging studies that streamlined visual search strategies lead to reduced activation in the visual cortex (Kojima and Suzuki, <xref rid="B25" ref-type="bibr">2010</xref>). For example, Kojima and Suzuki (<xref rid="B25" ref-type="bibr">2010</xref>) observed greater hemodynamic responses in fNIRS channels centered on the visual cortex during more effortful search strategies. However, it must be acknowledged that the introduction of a target feature into the surgical scene might be anticipated to increase visual attention owing to changes in visual saliency. This is relevant since the eye-tracking derived fixation point of the expert was projected to trainee as a visually salient target. Interestingly, shifts in visual attention secondary to manipulations in visual saliency as a result of gaze-guidance (i.e., the trainer&#x02019;s fixation point) did not manifest as greater activation in the visual cortex when compared to verbal instruction. Rather, the resultant visual search is potentially streamlined from a <italic>&#x0201c;top-down&#x0201d;</italic> to <italic>&#x0201c;bottom-up&#x0201d;</italic> strategy (van der Stigchel et al., <xref rid="B45" ref-type="bibr">2009</xref>; Theeuwes, <xref rid="B42" ref-type="bibr">2010</xref>). Specifically, if a target markedly differs from its background, it is visually salient and is more likely to be detected by a <italic>&#x0201c;bottom-up&#x0201d;</italic> search strategy guided by the saliency of the scene, whereas if a target requires greater cognitive input to be identified, a <italic>&#x0201c;top down&#x0201d;</italic> search ensues which is dependent on the PFC and parietal cortex (PC; van der Stigchel et al., <xref rid="B45" ref-type="bibr">2009</xref>; Theeuwes, <xref rid="B42" ref-type="bibr">2010</xref>). Bottom up saliency is not coded in the primary visual cortex (Betz et al., <xref rid="B5" ref-type="bibr">2013</xref>), and this mode results in search simplification leading to a reduction in activity in visual association areas (Kojima and Suzuki, <xref rid="B25" ref-type="bibr">2010</xref>). Enhanced saliency through visual guidance may parallel visual processing of natural stimuli (Einh&#x000e4;user and K&#x000f6;nig, <xref rid="B13" ref-type="bibr">2010</xref>), whereby responses in V1 cells are optimally sparse (Vinje and Gallant, <xref rid="B47" ref-type="bibr">2000</xref>). In the current study, this effect has been observed as a reduction in O-P cortical hemodynamic changes with comparatively fewer channels reaching statistical threshold for activation.</p><p>Parietal cortical activity is also associated with oculomotor intention and attention and may be important in planning eye movements (Kanwisher and Wojciulik, <xref rid="B24" ref-type="bibr">2000</xref>). Verbal guidance may result in demanding visual search since it necessitates that auditory information be explicitly processed and translated into visual-spatial co-ordinates to understand the desired target&#x02019;s location, and parietal lobe activation has been shown to be important in spatial integration (Molholm et al., <xref rid="B32" ref-type="bibr">2006</xref>). Conversely, gaze-guidance protocols may share many similarities with implicit learning protocols (Wilson et al., <xref rid="B48" ref-type="bibr">2011</xref>). Implicit learning, a form of unconscious, incidental and procedural knowledge demands fewer attentional resources than explicit learning, a form of conscious, intentional or declarative knowledge. Implicit motor learning has been shown to reduce non-essential co-activation or connectivity between verbal-analytic and motor planning regions during laparoscopic performance (Zhu et al., <xref rid="B53" ref-type="bibr">2011</xref>).</p><p>Here, as well as investigating connectivity (i.e., correlations), network topology has been explored with graph theory, which provides a powerful method for quantitatively describing the topology of brain connectivity (He and Evans, <xref rid="B17" ref-type="bibr">2010</xref>). Graph theory has been utilized to interrogate cortical networks in both pathological and non-pathological brains (Achard and Bullmore, <xref rid="B1" ref-type="bibr">2007</xref>; Bassett et al., <xref rid="B4" ref-type="bibr">2009</xref>), and allows network parameters such as cost and efficiency to be determined (Bullmore and Bassett, <xref rid="B8" ref-type="bibr">2011</xref>). Presently, graph theory was applied to experimental data in order to further appreciate the impact of a &#x0201c;gaze-channel&#x0201d; on functional brain networks. From the active network analysis (i.e., that which retains only activated nodes), it is evident that compared to verbal-guidance, gaze-assistance does not lead to significant differences in O-P network topologies, therefore disproving the secondary hypothesis. Therefore, our conclusion is that collaborative gaze exerts a positive effect on technical skills, alleviates burden on the visual cortices, and yet critically does not significantly alter performance of the functional O-P network.</p><p>Intuitively verbal instructions about target location are time consuming to deliver, more complex to interpret and harder to translate into the &#x0201c;visual&#x0201d; workspace, ultimately relying therefore on greater cognitive work as evidenced by enhanced task performance when visual guidance is employed (Chetwood et al., <xref rid="B10" ref-type="bibr">2012</xref>). We suspect that gaze assistance makes the flow of information between the trainer and trainee more seamless by increasing the perceptual fidelity of the instruction given. Extrapolating this effect to the <italic>in vivo</italic> setting, a reduction in the attentional demands necessary to execute a procedure may manifest as a liberation of resources to devote to other safety critical aspects of clinical care (e.g., reacting to unexpected events, multitask decision making, planning operative steps, <italic>etc</italic>.). Future studies may capitalize on a framework that enables combined analysis of brain responses, visual behavior and HRV to improve the detection of changes in workload as has been demonstrated in pilots (Duratin et al., <xref rid="B12" ref-type="bibr">2014</xref>). Furthermore, although not specifically investigated within the confines of this study, it is feasible that in using visual guidance the need to verbalize the intended target is bypassed and as such the trainer can focus on supplementary aspects of the procedure. For example, if the site of suture placement is already determined and displayed visually, a trainer can then focus verbal instruction on the technical aspects of suturing manoeuvres required to achieve accurate tissue apposition.</p></sec><sec sec-type="conclusion" id="s7"><title>Conclusion</title><p>To summarize, this study demonstrates that capitalizing on visual behavior enhances communication between collaborating surgeons, and improves operator performance. This may be achieved through a <italic>bottom up</italic> allocation of resources within the visual cortex of the surgeon being instructed. It is plausible that trainees instructed in this fashion will be better able to devote neural resources to other safety critical aspects of the procedure. In investigating these hypotheses, fNIRS technology is well placed to make an impact, as it overcomes the limitations of traditional scanning environments (Cutini et al., <xref rid="B9" ref-type="bibr">2012</xref>). However, future validation of graph theory measures for fNIRS connectivity analysis will necessitate comparison against models of anticipated responses and structural connectivity as have been observed using other neuroimaging technologies such as fMRI (van den Heuvel et al., <xref rid="B44" ref-type="bibr">2009</xref>; Zhang et al., <xref rid="B50" ref-type="bibr">2010</xref>). Critically, demonstration of correspondence between predicted and observed patterns of functional connectivity would support the feasibility and validity of fNIRS-derived connectivity measures.</p></sec><sec id="s8"><title>Author Contributions</title><p>Study design and protocols were conceived by DRCJ, DRL, FO-E, LWS, K-WK, GM, G-ZY, and AWD. Data collection was performed by DRCJ, DRL, FO-E, LWS and K-WK. Data analysis was performed by DRCJ, FO-E, DRL, K-WK, LWS, GM and TA. The manuscript was written by DRCJ, DRL and FO-E and final critical editing was performed by DRL, LWS, GM, TA, G-ZY and AWD.</p></sec><sec id="s9"><title>Funding</title><p>This work was funded in part by research grants from the Academy of Medical Sciences (Lecturer Starter Grant) and Cancer Research UK (Academic Lecturership).</p></sec><sec id="s10"><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Achard</surname><given-names>S.</given-names></name><name><surname>Bullmore</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Efficiency and cost of economical brain functional networks</article-title>. <source>PLoS Comput. Biol.</source>
<volume>3</volume>:<fpage>e17</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.0030017</pub-id><pub-id pub-id-type="pmid">17274684</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avraham</surname><given-names>T.</given-names></name><name><surname>Yeshurun</surname><given-names>Y.</given-names></name><name><surname>Lindenbaum</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Predicting visual search performance by quantifying stimulus similarities</article-title>. <source>J. Vis.</source>
<volume>8</volume>:<fpage>9</fpage>
<pub-id pub-id-type="doi">10.1167/8.4.9</pub-id><pub-id pub-id-type="pmid">18484848</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bann</surname><given-names>S. D.</given-names></name><name><surname>Khan</surname><given-names>M. S.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name></person-group> (<year>2003</year>). <article-title>Measurement of surgical dexterity using motion analysis of simple bench tasks</article-title>. <source>World. J. Surg.</source>
<volume>27</volume>, <fpage>390</fpage>&#x02013;<lpage>394</lpage>. <pub-id pub-id-type="doi">10.1007/s00268-002-6769-7</pub-id><pub-id pub-id-type="pmid">12658479</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassett</surname><given-names>D. S.</given-names></name><name><surname>Bullmore</surname><given-names>E. T.</given-names></name><name><surname>Meyer-Lindenberg</surname><given-names>A.</given-names></name><name><surname>Apud</surname><given-names>J. A.</given-names></name><name><surname>Wienberger</surname><given-names>D. R.</given-names></name><name><surname>Coppola</surname><given-names>R.</given-names></name></person-group> (<year>2009</year>). <article-title>Cogntive fitness of cost-efficient functional networks</article-title>. <source>Proc. Natl. Acad. Sci. U S A</source>
<volume>106</volume>, <fpage>11747</fpage>&#x02013;<lpage>11752</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0903641106</pub-id><pub-id pub-id-type="pmid">19564605</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betz</surname><given-names>T.</given-names></name><name><surname>Wilming</surname><given-names>N.</given-names></name><name><surname>Bogler</surname><given-names>C.</given-names></name><name><surname>Haynes</surname><given-names>J. D.</given-names></name><name><surname>K&#x000f6;nig</surname><given-names>P.</given-names></name></person-group> (<year>2013</year>). <article-title>Dissociation between saliency signals and activity in the early visual cortex</article-title>. <source>J. Vis.</source>
<volume>13</volume>:<fpage>6</fpage>. <pub-id pub-id-type="doi">10.1167/13.14.6</pub-id><pub-id pub-id-type="pmid">24317424</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname><given-names>S. E.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Dickinson</surname><given-names>C. A.</given-names></name><name><surname>Neider</surname><given-names>M. B.</given-names></name><name><surname>Zelinsky</surname><given-names>G. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Coordinating cognition: the costs and benefits of shared gaze during collaborative search</article-title>. <source>Cognition.</source>
<volume>106</volume>, <fpage>1465</fpage>&#x02013;<lpage>1477</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2007.05.012</pub-id><pub-id pub-id-type="pmid">17617394</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullmore</surname><given-names>E.</given-names></name><name><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2009</year>). <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>10</volume>, <fpage>186</fpage>&#x02013;<lpage>198</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2575</pub-id><pub-id pub-id-type="pmid">19190637</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bullmore</surname><given-names>E. T.</given-names></name><name><surname>Bassett</surname><given-names>D. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Brain graphs: graphical models of the human brain connectome</article-title>. <source>Ann. Rev. Clin. Psychol.</source>
<volume>7</volume>, <fpage>113</fpage>&#x02013;<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-clinpsy-040510-143934</pub-id><pub-id pub-id-type="pmid">21128784</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutini</surname><given-names>S.</given-names></name><name><surname>Basso Moro</surname><given-names>S.</given-names></name><name><surname>Bisconti</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Functional near infrared optical imaging in cognitive neuroscience: an introductory review</article-title>. <source>J. Near Infrared Spectrosc.</source>
<volume>20</volume>, <fpage>75</fpage>&#x02013;<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1255/jnirs.969</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chetwood</surname><given-names>A. S.</given-names></name><name><surname>Kwok</surname><given-names>K. W.</given-names></name><name><surname>Sun</surname><given-names>L. W.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>Clark</surname><given-names>J.</given-names></name><name><surname>Darzi</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Collaborative eye tracking: a potential training tool in laparoscopic surgery</article-title>. <source>Surg. Endosc.</source>
<volume>26</volume>, <fpage>2003</fpage>&#x02013;<lpage>2009</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-011-2143-x</pub-id><pub-id pub-id-type="pmid">22258302</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>E.</given-names></name><name><surname>Cohen</surname><given-names>L. G.</given-names></name></person-group> (<year>2011</year>). <article-title>Neuroplasticity subserving motor skill learning</article-title>. <source>Neuron.</source>
<volume>72</volume>, <fpage>443</fpage>&#x02013;<lpage>445</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2011.10.008</pub-id><pub-id pub-id-type="pmid">22078504</pub-id></mixed-citation></ref><ref id="B120"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dehais</surname><given-names>F.</given-names></name><name><surname>Peysakhovich</surname><given-names>V.</given-names></name><name><surname>Scanella</surname><given-names>S.</given-names></name><name><surname>Fongue</surname><given-names>J.</given-names></name><name><surname>Gateau</surname><given-names>T.</given-names></name></person-group> (<year>2015</year>). &#x0201c;<article-title>&#x0201c;Automation suprise&#x0201d; in aviation: real-time solutions,</article-title>&#x0201d; in <source>CHI&#x02019;15 Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</source> (<publisher-loc>Seoul</publisher-loc>: <publisher-name>Republic of Korea</publisher-name>), <fpage>2525</fpage>&#x02013;<lpage>2534</lpage>.</mixed-citation></ref><ref id="B121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Nocera</surname><given-names>F.</given-names></name><name><surname>Camilli</surname><given-names>M.</given-names></name><name><surname>Terenzi</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>A random glance at the Flight Deck: Pilots&#x02019; scanning strategies and real-time assessment of mental workload</article-title>. <source>J. Cogn. Eng. Decis. Mak.</source>
<volume>1</volume>, <fpage>271</fpage>&#x02013;<lpage>285</lpage>. <pub-id pub-id-type="doi">10.1518/155534307X255627</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duratin</surname><given-names>G.</given-names></name><name><surname>Gagnon</surname><given-names>J. F.</given-names></name><name><surname>Tremblay</surname><given-names>S.</given-names></name><name><surname>Dehais</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>). <article-title>Using near infrared spectroscopy and heart rate variability to detect mental overload</article-title>. <source>Behav. Brain Res</source>
<volume>259</volume>, <fpage>16</fpage>&#x02013;<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.bbr.2013.10.042</pub-id><pub-id pub-id-type="pmid">24184083</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einh&#x000e4;user</surname><given-names>W.</given-names></name><name><surname>K&#x000f6;nig</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>). <article-title>Getting real-sensory processing of natural stimuli</article-title>. <source>Curr. Opin. Neurobiol.</source>
<volume>20</volume>, <fpage>389</fpage>&#x02013;<lpage>395</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2010.03.010</pub-id><pub-id pub-id-type="pmid">20434327</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferguson</surname><given-names>S.</given-names></name><name><surname>Stack</surname><given-names>B. C.</given-names></name></person-group> (<year>2010</year>). <article-title>Addition of a telestrator for teaching during video-based procedures</article-title>. <source>Otolaryngol. Head Neck Surg.</source>
<volume>143</volume>, <fpage>159</fpage>&#x02013;<lpage>160</lpage>. <pub-id pub-id-type="doi">10.1016/j.otohns.2009.12.043</pub-id><pub-id pub-id-type="pmid">20620636</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fitts</surname><given-names>P. M.</given-names></name><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>1967</year>). <source>Learning and Skilled Performance in Human Performance.</source>
<publisher-loc>Belmont, CA</publisher-loc>: <publisher-name>Brooks/Cole</publisher-name>.</mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Evans</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>Graph theoretical modeling of brain connectivity</article-title>. <source>Curr. Opin. Neurol.</source>
<volume>23</volume>, <fpage>341</fpage>&#x02013;<lpage>350</lpage>. <pub-id pub-id-type="doi">10.1097/wco.0b013e32833aa567</pub-id><pub-id pub-id-type="pmid">20581686</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>D. R.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Kwok</surname><given-names>K. W.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>Athanasiou</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Enhanced frontoparietal network architectures following &#x0201c;gaze-contingent&#x0201d; versus &#x0201c;free-hand&#x0201d; motor learning</article-title>. <source>Neuroimage.</source>
<volume>64</volume>, <fpage>267</fpage>&#x02013;<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.056</pub-id><pub-id pub-id-type="pmid">22960153</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>D. R. C.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Sodergren</surname><given-names>M. H.</given-names></name><name><surname>Athanasiou</surname><given-names>T.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>The ergonomics of Natural Orifice Translumenal Endoscopic Surgery (NOTES) in terms of performance, stress and cognitive behaviour</article-title>. <source>Surgery.</source>
<volume>149</volume>, <fpage>525</fpage>&#x02013;<lpage>533</lpage>. <pub-id pub-id-type="doi">10.1016/j.surg.2010.11.019</pub-id><pub-id pub-id-type="pmid">21295807</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>D. R. C.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>Kwok</surname><given-names>K. W.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group>. (<year>2010a</year>). <article-title>Cognitive burden estimation for visuomotor learning with fNIRS</article-title>. <source>Med. Image Comput. Comput. Assist. Interv.</source>
<volume>13</volume>, <fpage>319</fpage>&#x02013;<lpage>326</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-642-15711-0_40</pub-id><pub-id pub-id-type="pmid">20879415</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>D. R. C.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>Kwok</surname><given-names>K. W.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group> (<year>2010b</year>). <article-title>Neuroergonomic assessment of the robotic enhancement of surgery</article-title>. <source>Surg. Endosc.</source>
<volume>24</volume>, <fpage>192</fpage>&#x02013;<lpage>269</lpage>.<pub-id pub-id-type="pmid">20217145</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>J&#x000f6;bsis</surname><given-names>F. F.</given-names></name></person-group> (<year>1977</year>). <article-title>Noninvasive, infrared monitoring of cerebral and myocardial oxygen sufficiency and circulatory parameters</article-title>. <source>Science.</source>
<volume>198</volume>, <fpage>1264</fpage>&#x02013;<lpage>1267</lpage>. <pub-id pub-id-type="doi">10.1126/science.929199</pub-id><pub-id pub-id-type="pmid">929199</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurcak</surname><given-names>V.</given-names></name><name><surname>Tsuzuki</surname><given-names>D.</given-names></name><name><surname>Dan</surname><given-names>I.</given-names></name></person-group> (<year>2007</year>). <article-title>10/20, 10/10 and 10/5 systems revisited: their validity as relative head-surface-based positioning systems</article-title>. <source>Neuroimage.</source>
<volume>34</volume>, <fpage>1600</fpage>&#x02013;<lpage>1611</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.024</pub-id><pub-id pub-id-type="pmid">17207640</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N.</given-names></name><name><surname>Wojciulik</surname><given-names>E.</given-names></name></person-group> (<year>2000</year>). <article-title>Visual attention: insights from brain imaging</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>1</volume>, <fpage>91</fpage>&#x02013;<lpage>100</lpage>. <pub-id pub-id-type="doi">10.1038/35039043</pub-id><pub-id pub-id-type="pmid">11252779</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kojima</surname><given-names>H.</given-names></name><name><surname>Suzuki</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Hemodynamic change in occipital lobe during visual search: visual attention allocation measured with NIRS</article-title>. <source>Neuropsychologia.</source>
<volume>48</volume>, <fpage>349</fpage>&#x02013;<lpage>352</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.09.028</pub-id><pub-id pub-id-type="pmid">19800898</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwok</surname><given-names>K. W.</given-names></name><name><surname>Sun</surname><given-names>L. W.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>James</surname><given-names>D. R.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Yang</surname><given-names>G. Z.</given-names></name></person-group> (<year>2012</year>). <article-title>Collaborative gaze channelling for improved cooperation during robotic assisted surgery</article-title>. <source>Ann. Biomed. Eng.</source>
<volume>40</volume>, <fpage>2156</fpage>&#x02013;<lpage>2167</lpage>. <pub-id pub-id-type="doi">10.1007/s10439-012-0578-4</pub-id><pub-id pub-id-type="pmid">22581476</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Elwell</surname><given-names>C. E.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Atallah</surname><given-names>L.</given-names></name><name><surname>Delpy</surname><given-names>D. T.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group>. (<year>2008a</year>). <article-title>Changes in prefrontal cortical behaviour depend upon familiarity on a bimanual co-ordination task: an fNIRS study</article-title>. <source>Neuroimage.</source>
<volume>39</volume>, <fpage>805</fpage>&#x02013;<lpage>813</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.032</pub-id><pub-id pub-id-type="pmid">17964187</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Leong</surname><given-names>J. J.</given-names></name><name><surname>Aggarwal</surname><given-names>R.</given-names></name><name><surname>Yang</surname><given-names>G. Z.</given-names></name><name><surname>Darzi</surname><given-names>A.</given-names></name></person-group> (<year>2008b</year>). <article-title>Could variations in technical skills acquisition in surgery be explained by differences in cortical plasticity?</article-title>
<source>Ann. Surg.</source>
<volume>247</volume>, <fpage>540</fpage>&#x02013;<lpage>543</lpage>. <pub-id pub-id-type="doi">10.1097/sla.0b013e31815fa42e</pub-id><pub-id pub-id-type="pmid">18376201</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Atallah</surname><given-names>L.</given-names></name><name><surname>Athanasiou</surname><given-names>T.</given-names></name><name><surname>Leong</surname><given-names>J. J.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group>. (<year>2008c</year>). <article-title>Functional prefrontal reorganization accompanies learning-associated refinements in surgery: a manifold embedding approach</article-title>. <source>Comput. Aided Surg.</source>
<volume>13</volume>, <fpage>325</fpage>&#x02013;<lpage>339</lpage>. <pub-id pub-id-type="doi">10.3109/10929080802531482</pub-id><pub-id pub-id-type="pmid">18991082</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Leong</surname><given-names>J. H.</given-names></name><name><surname>Atallah</surname><given-names>L.</given-names></name><name><surname>Mylonas</surname><given-names>G. P.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>Emery</surname><given-names>R. J.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><etal/></person-group> (<year>2008</year>). &#x0201c;<article-title>Investigation of partial directed coherence for hand-eye coordination in laparoscopic training</article-title>,&#x0201d; in <source>Lecture Notes in Computer Science.</source> eds <person-group person-group-type="editor"><name><surname>Dohi</surname><given-names>T.</given-names></name><name><surname>Sakuma</surname><given-names>I.</given-names></name><name><surname>Liao</surname><given-names>H.</given-names></name></person-group> (<publisher-loc>Berlin Heidelberg</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>), <fpage>270</fpage>&#x02013;<lpage>278</lpage>.</mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Micali</surname><given-names>S.</given-names></name><name><surname>Virgili</surname><given-names>G.</given-names></name><name><surname>Vannozzi</surname><given-names>E.</given-names></name><name><surname>Grassi</surname><given-names>N.</given-names></name><name><surname>Jarrett</surname><given-names>T. W.</given-names></name><name><surname>Bauer</surname><given-names>J. J.</given-names></name><etal/></person-group>. (<year>2000</year>). <article-title>Feasibility of telementoring between Baltimore (USA) and Rome (Italy): the first five cases</article-title>. <source>J. Endourol.</source>
<volume>14</volume>, <fpage>493</fpage>&#x02013;<lpage>496</lpage>. <pub-id pub-id-type="doi">10.1089/end.2000.14.493</pub-id><pub-id pub-id-type="pmid">10954305</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molholm</surname><given-names>S.</given-names></name><name><surname>Sehatpour</surname><given-names>P.</given-names></name><name><surname>Mehta</surname><given-names>A. D.</given-names></name><name><surname>Shpaner</surname><given-names>M.</given-names></name><name><surname>Gomez-Ramirez</surname><given-names>M.</given-names></name><name><surname>Ortigue</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Audio-visual multisensory integration in superior parietal lobule revealed by human intracranial recordings</article-title>. <source>J. Neurophysiol.</source>
<volume>96</volume>, <fpage>721</fpage>&#x02013;<lpage>729</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00285.2006</pub-id><pub-id pub-id-type="pmid">16687619</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>T.</given-names></name><name><surname>Shu</surname><given-names>N.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name></person-group> (<year>2012</year>). <article-title>Revealing topological organization of human brain functional networks with resting-state functional near infrared spectroscopy</article-title>. <source>PLoS One</source>
<volume>7</volume>:<fpage>e45771</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0045771</pub-id><pub-id pub-id-type="pmid">23029235</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohuchida</surname><given-names>K.</given-names></name><name><surname>Kenmotsu</surname><given-names>H.</given-names></name><name><surname>Yamamoto</surname><given-names>A.</given-names></name><name><surname>Sawada</surname><given-names>K.</given-names></name><name><surname>Hayami</surname><given-names>T.</given-names></name><name><surname>Morooka</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>The frontal cortex is activated during learning of endoscopic procedures</article-title>. <source>Surg. Endosc.</source>
<volume>2310</volume>, <fpage>2296</fpage>&#x02013;<lpage>2301</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-008-0316-z</pub-id><pub-id pub-id-type="pmid">19172351</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orihuela-Espina</surname><given-names>F.</given-names></name><name><surname>Leff</surname><given-names>D. R.</given-names></name><name><surname>James</surname><given-names>D. R. C.</given-names></name><name><surname>Darzi</surname><given-names>A. W.</given-names></name><name><surname>Yang</surname><given-names>G. Z.</given-names></name></person-group> (<year>2010</year>). <article-title>Quality control and assurance in functional near infrared spectroscopy (fNIRS) experimentation</article-title>. <source>Phys. Med. Biol.</source>
<volume>55</volume>, <fpage>1</fpage>&#x02013;<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1088/0031-9155/55/13/009</pub-id><pub-id pub-id-type="pmid">19949261</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parasuraman</surname><given-names>R.</given-names></name></person-group> (<year>2003</year>). <article-title>Neuroergonomics: research and practice</article-title>. <source>Theor. Issues Erg.</source>
<volume>4</volume>, <fpage>5</fpage>&#x02013;<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1080/14639220210199753</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>C. S.</given-names></name><name><surname>Sherrington</surname><given-names>C. S.</given-names></name></person-group> (<year>1890</year>). <article-title>On the regulation of the blood-supply of the brain</article-title>. <source>J. Physiol.</source>
<volume>11</volume>, <fpage>85</fpage>&#x02013;<lpage>158</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.1890.sp000321</pub-id><pub-id pub-id-type="pmid">16991945</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlachta</surname><given-names>C. M.</given-names></name><name><surname>Lefebvre</surname><given-names>K. L.</given-names></name><name><surname>Sorsdahl</surname><given-names>A. K.</given-names></name><name><surname>Jayaraman</surname><given-names>S.</given-names></name></person-group> (<year>2010</year>). <article-title>Mentoring and telementoring leads to effective incorporation of laparoscopic colon surgery</article-title>. <source>Surg. Endosc.</source>
<volume>24</volume>, <fpage>841</fpage>&#x02013;<lpage>844</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-009-0674-1</pub-id><pub-id pub-id-type="pmid">19707821</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O.</given-names></name><name><surname>Chialvo</surname><given-names>D. R.</given-names></name><name><surname>Kaiser</surname><given-names>M.</given-names></name><name><surname>Hilgetag</surname><given-names>C. C.</given-names></name></person-group> (<year>2004</year>). <article-title>Organization, development and function of complex brain networks</article-title>. <source>Trends Cogn. Sci.</source>
<volume>8</volume>, <fpage>418</fpage>&#x02013;<lpage>425</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2004.07.008</pub-id><pub-id pub-id-type="pmid">15350243</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2011</year>). <source>Networks of the Brain.</source>
<publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Task Force of the European Society of Cardiology the North American Society of Pacing Electrophysiology</collab></person-group> (<year>1996</year>). <article-title>Heart rate variability. Standards of measurement, physiological interpretation and clinical use. Task Force of the European Society of Cardiology and the North American Society of Pacing and Electrophysiology</article-title>. <source>Eur. Heart J.</source>
<volume>17</volume>, <fpage>354</fpage>&#x02013;<lpage>381</lpage>. <pub-id pub-id-type="doi">10.1161/01.cir.93.5.1043</pub-id><pub-id pub-id-type="pmid">8737210</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J.</given-names></name></person-group> (<year>2010</year>). <article-title>Top-down and bottom-up control of visual selection</article-title>. <source>Acta Psychologica.</source>
<volume>135</volume>, <fpage>77</fpage>&#x02013;<lpage>99</lpage>. <pub-id pub-id-type="doi">10.1016/j.actpsy.2010.02.006</pub-id><pub-id pub-id-type="pmid">20507828</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tokuda</surname><given-names>S.</given-names></name><name><surname>Obinata</surname><given-names>G.</given-names></name><name><surname>Palmer</surname><given-names>E.</given-names></name><name><surname>Chaparro</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Estimation of mental workload using saccadic eye movements in a free-viewing task</article-title>. <source>Conf. Proc. IEEE Eng. Med. Biol. Soc.</source>
<volume>2011</volume>, <fpage>4523</fpage>&#x02013;<lpage>4529</lpage>. <pub-id pub-id-type="doi">10.1109/iembs.2011.6091121</pub-id><pub-id pub-id-type="pmid">22255344</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>M. P.</given-names></name><name><surname>Mandl</surname><given-names>R. C.</given-names></name><name><surname>Kahn</surname><given-names>R. S.</given-names></name><name><surname>Hulshoff Pol</surname><given-names>H. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Functionally linked resting-state networks reflect the underlying structural connectivity architecture of the human brain</article-title>. <source>Hum. Brain Mapp.</source>
<volume>30</volume>, <fpage>3127</fpage>&#x02013;<lpage>3141</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20737</pub-id><pub-id pub-id-type="pmid">19235882</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Stigchel</surname><given-names>S.</given-names></name><name><surname>Belopolsky</surname><given-names>A. V.</given-names></name><name><surname>Peters</surname><given-names>J. C.</given-names></name><name><surname>Wijnen</surname><given-names>J. G.</given-names></name><name><surname>Meeter</surname><given-names>M.</given-names></name><name><surname>Theeuwes</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>The limits of top-down control of visual attention</article-title>. <source>Acta. Psychologica.</source>
<volume>132</volume>, <fpage>201</fpage>&#x02013;<lpage>212</lpage>. <pub-id pub-id-type="doi">10.1016/j.actpsy.2009.07.001</pub-id><pub-id pub-id-type="pmid">19635610</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Wijk</surname><given-names>B. C.</given-names></name><name><surname>Stam</surname><given-names>C. J.</given-names></name><name><surname>Daffertshofer</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>Comparing brain networks of different size and connectivity density using graph theory</article-title>. <source>PLoS One</source>
<volume>5</volume>:<fpage>e13701</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0013701</pub-id><pub-id pub-id-type="pmid">21060892</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinje</surname><given-names>W. E.</given-names></name><name><surname>Gallant</surname><given-names>J. L.</given-names></name></person-group> (<year>2000</year>). <article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title>. <source>Science.</source>
<volume>287</volume>, <fpage>1273</fpage>&#x02013;<lpage>1276</lpage>. <pub-id pub-id-type="doi">10.1126/science.287.5456.1273</pub-id><pub-id pub-id-type="pmid">10678835</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>M. R.</given-names></name><name><surname>Vine</surname><given-names>S. J.</given-names></name><name><surname>Bright</surname><given-names>E.</given-names></name><name><surname>Masters</surname><given-names>R. S.</given-names></name><name><surname>Defriend</surname><given-names>D.</given-names></name><name><surname>McGrath</surname><given-names>J. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Gaze training enhances laparoscopic technical skill acquisition and multi-tasking performance: a randomized, controlled study</article-title>. <source>Surgi. Endosc.</source>
<volume>25</volume>, <fpage>3731</fpage>&#x02013;<lpage>3739</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-011-1802-2</pub-id><pub-id pub-id-type="pmid">21671125</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xeroulis</surname><given-names>G.</given-names></name><name><surname>Dubrowski</surname><given-names>A.</given-names></name><name><surname>Leslie</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>Simulation in laparoscopic surgery: a concurrent validity study for FLS</article-title>. <source>Surg. Endosc.</source>
<volume>23</volume>, <fpage>161</fpage>&#x02013;<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-008-0120-9</pub-id><pub-id pub-id-type="pmid">18814001</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Shimony</surname><given-names>J. S.</given-names></name><name><surname>Fox</surname><given-names>M. D.</given-names></name><name><surname>Raichle</surname><given-names>M. E.</given-names></name></person-group> (<year>2010</year>). <article-title>Noninvasive functional and structural connectivity mapping of the human thalamocortical system</article-title>. <source>Cereb. Cortex.</source>
<volume>20</volume>, <fpage>1187</fpage>&#x02013;<lpage>1194</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhp182</pub-id><pub-id pub-id-type="pmid">19729393</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>B.</given-names></name><name><surname>Jiang</surname><given-names>X.</given-names></name><name><surname>Tien</surname><given-names>G.</given-names></name><name><surname>Mengeghetti</surname><given-names>A.</given-names></name><name><surname>Panton</surname><given-names>O. N.</given-names></name><name><surname>Atkins</surname><given-names>M. S.</given-names></name></person-group> (<year>2012</year>). <article-title>Workload assessment of surgeons: correlation between NASA TLX and blinks</article-title>. <source>Surg. Endosc.</source>
<volume>26</volume>, <fpage>2746</fpage>&#x02013;<lpage>2750</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-012-p2268-6</pub-id><pub-id pub-id-type="pmid">22527300</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>B.</given-names></name><name><surname>Jiang</surname><given-names>X.</given-names></name><name><surname>Atkins</surname><given-names>M. S.</given-names></name></person-group> (<year>2015</year>). <article-title>Detection of changes in surgical difficulty: Evidence from pupil responses</article-title>. <source>Surg. Innov.</source> [Epub ahead of print]. <pub-id pub-id-type="doi">10.1177/1553350615573582</pub-id><pub-id pub-id-type="pmid">25759398</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>F. F.</given-names></name><name><surname>Poolton</surname><given-names>J. M.</given-names></name><name><surname>Wilson</surname><given-names>M. R.</given-names></name><name><surname>Hu</surname><given-names>Y.</given-names></name><name><surname>Maxwell</surname><given-names>J. P.</given-names></name><name><surname>Masters</surname><given-names>R. S.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Implicit motor learning promotes neural efficiency during laparoscopy</article-title>. <source>Surg. Endosc.</source>
<volume>25</volume>, <fpage>2950</fpage>&#x02013;<lpage>2955</lpage>. <pub-id pub-id-type="doi">10.1007/s00464-011-1647-8</pub-id><pub-id pub-id-type="pmid">21455805</pub-id></mixed-citation></ref></ref-list></back></article>