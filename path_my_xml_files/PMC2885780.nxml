<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="other"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Internet Res</journal-id><journal-id journal-id-type="publisher-id">JMIR</journal-id><journal-title-group><journal-title>Journal of Medical Internet Research</journal-title></journal-title-group><issn pub-type="epub">1438-8871</issn><publisher><publisher-name>Gunther Eysenbach</publisher-name><publisher-loc>Centre for Global eHealth Innovation, Toronto, Canada</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">20457556</article-id><article-id pub-id-type="pmc">2885780</article-id><article-id pub-id-type="publisher-id">v12i2e13</article-id><article-id pub-id-type="doi">10.2196/jmir.1251</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Effects of a Financial Incentive on Health Researchers&#x02019; Response to an Online Survey: a Randomized Controlled Trial</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Potts</surname><given-names>Henry</given-names></name></contrib><contrib contrib-type="editor"><name><surname>Eysenbach</surname><given-names>Gunther</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Dobrow</surname><given-names>Mark</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Callegaro</surname><given-names>Mario</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author" corresp="yes"><name><surname>Wilson</surname><given-names>Paul M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><address><institution>Centre for Reviews and Dissemination</institution><institution>University of York</institution><addr-line>Heslington</addr-line><addr-line>York, YO10 5DD</addr-line><country>United Kingdom</country><phone>44 0 1904 321073</phone><fax>44 0 1904 321041</fax><email>pmw7@york.ac.uk</email></address></contrib><contrib id="contrib2" contrib-type="author"><name><surname>Petticrew</surname><given-names>Mark</given-names></name><xref ref-type="aff" rid="aff2">2</xref></contrib><contrib id="contrib3" contrib-type="author"><name><surname>Calnan</surname><given-names>Mike</given-names></name><xref ref-type="aff" rid="aff3">3</xref></contrib><contrib id="contrib4" contrib-type="author"><name><surname>Nazareth</surname><given-names>Irwin</given-names></name><xref ref-type="aff" rid="aff4">4</xref></contrib></contrib-group><aff id="aff4" rid="aff4"><sup>4</sup><institution>MRC General Practice Research Framework</institution><institution>University College London</institution><addr-line>London</addr-line><country>United Kingdom</country></aff><aff id="aff3" rid="aff3"><sup>3</sup><institution>School of Social Policy</institution><institution>Sociology and Social Research</institution><institution>, University of Kent</institution><addr-line>Canterbury</addr-line><country>United Kingdom</country></aff><aff id="aff2" rid="aff2"><sup>2</sup><institution>Public and Environmental Health Research Unit</institution><institution>London School of Hygiene and Tropical Medicine</institution><addr-line>London</addr-line><country>United Kingdom</country></aff><aff id="aff1" rid="aff1"><sup>1</sup><institution>Centre for Reviews and Dissemination</institution><institution>University of York</institution><addr-line>York</addr-line><country>United Kingdom</country></aff><pub-date pub-type="collection"><season>Apr-Jun</season><year>2010</year></pub-date><pub-date pub-type="epub"><day>10</day><month>5</month><year>2010</year></pub-date><volume>12</volume><issue>2</issue><elocation-id>e13</elocation-id><history><date date-type="received"><day>21</day><month>4</month><year>2009</year></date><date date-type="rev-request"><day>09</day><month>7</month><year>2009</year></date><date date-type="rev-recd"><day>02</day><month>11</month><year>2009</year></date><date date-type="accepted"><day>01</day><month>12</month><year>2009</year></date></history><permissions><copyright-statement>&#x000a9;Paul M Wilson, Mark Petticrew, Mike Calnan, Irwin Nazareth. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 10.05.2010 &#x000a0;</copyright-statement><copyright-year>2010</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0/"><license-p><!--CREATIVE COMMONS-->This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0/">http://creativecommons.org/licenses/by/2.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/,">http://www.jmir.org/,</ext-link> as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:type="simple" xlink:href="http://www.jmir.org/2010/2/e13/"/><abstract><sec sec-type="background"><title>Background</title><p>Nonresponse to questionnaires can affect the validity of surveys and introduce bias. Offering financial incentives can increase response rates to postal questionnaires, but the effect of financial incentives on response rates to online surveys is less clear.</p></sec><sec sec-type="objective"><title>Objective</title><p>As part of a survey, we aimed to test whether knowledge of a financial incentive would increase the response rate to an online questionnaire.</p></sec><sec sec-type="methods"><title>Methods</title><p>A randomized controlled trial of 485 UK-based principal investigators of publicly funded health services and population health research. Participants were contacted by email and invited to complete an online questionnaire via an embedded URL. Participants were randomly allocated to groups with either &#x0201c;knowledge of&#x0201d; or &#x0201c;no knowledge of&#x0201d; a financial incentive (&#x000a3;10 Amazon gift voucher) to be provided on completion of the survey. At the end of the study, gift vouchers were given to all participants who completed the questionnaire regardless of initial randomization status. Four reminder emails (sent from the same email address as the initial invitation) were sent out to nonrespondents at one, two, three, and four weeks; a fifth postal reminder was also undertaken. The primary outcome measure for the trial was the response rate one week after the second reminder. Response rate was also measured at the end of weeks one, two, three, four, and five, and after a postal reminder was sent.</p></sec><sec sec-type="results"><title>Results</title><p>In total, 243 (50%) questionnaires were returned (232 completed, 11 in which participation was declined). One week after the second reminder, the response rate in the &#x0201c;knowledge&#x0201d; group was 27% (66/244) versus 20% (49/241) in the &#x0201c;no knowledge&#x0201d; group (&#x003c7;<sup>2</sup><sub>1</sub> = 3.0, P = .08). The odds ratio for responding among those with knowledge of an incentive was 1.45 (95% confidence interval [CI] 0.95 - 2.21). At the third reminder, participants in the &#x0201c;no knowledge&#x0201d; group were informed about the incentive, ending the randomized element of the study. However we continued to follow up all participants, and from reminder three onwards, no significant differences were observed in the response rates of the two groups.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>Knowledge of a financial incentive did not significantly increase the response rate to an online questionnaire. Future surveys should consider including a randomized element to further test the utility of offering incentives of other types and amounts to participate in online questionnaires.</p></sec><sec sec-type="trialreg"><title>Trial Registration</title><p>ISRCTN59912797; http://www.controlled-trials.com/ISRCTN59912797 (Archived by WebCite at http://www.webcitation.org/5iPPLbT7s)</p></sec></abstract><kwd-group><kwd>Questionnaires</kwd><kwd>Electronic Mail</kwd><kwd>Randomized Controlled Trial</kwd><kwd>Reminder Systems</kwd><kwd>reward</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>Nonresponse to questionnaires can affect the validity of surveys and introduce bias.</p><p>The offer of financial incentives has been a widely used method to increase response rates to postal questionnaires. A Cochrane systematic review of 481 randomized controlled trials (RCTs) evaluating 110 different ways of increasing response rates to postal questionnaires in a wide range of populations found that odds of response can be doubled through the use of monetary incentives [<xref ref-type="bibr" rid="ref1">1</xref>]. Other factors shown to increase the odds of response included a topic of interest, pre notification, follow-up contact, unconditional incentives, shorter questionnaires, provision of a second copy of the questionnaire at follow-up, mention of an obligation to respond, and university sponsorship [<xref ref-type="bibr" rid="ref1">1</xref>].</p><p>However, this evidence base relates to postal questionnaires, and although a number of systematic reviews [<xref ref-type="bibr" rid="ref1">1</xref>,<xref ref-type="bibr" rid="ref2">2</xref>] and meta-analyses [<xref ref-type="bibr" rid="ref3">3</xref>] have been conducted, the available evidence base relating to use of incentives in electronic questionnaires is less substantive. The Cochrane review included 32 RCTs that evaluated 27 different ways of increasing response rates to electronic questionnaires in a wide range of populations [<xref ref-type="bibr" rid="ref1">1</xref>]. Although the one included RCT that evaluated monetary incentives found no significant effect, a further six RCTs found that use of other financial incentives (such as Amazon gift vouchers) doubled the odds of response. Limited evidence from social and market research also suggests that the offer of some form of monetary or financial incentive can increase the odds of a person responding and completing a web survey [<xref ref-type="bibr" rid="ref3">3</xref>].</p><p>Theoretical frameworks have been used to explain the potential influence of incentives on response rates. Social exchange theory [<xref ref-type="bibr" rid="ref4">4</xref>] proposes that the actions of individuals are influenced by the balance between the rewards they expect to obtain and the costs they perceive may occur as a consequence; this exchange paradigm has become a key concept in marketing [<xref ref-type="bibr" rid="ref5">5</xref>]. A systematic review of the design and conduct of questionnaire surveys suggests that making exchange theory operational (in order to maximize response)involves minimizing the physical, mental, emotional, and economic costs of response, maximizing the tangible and intangible rewards for response, and establishing trust that those rewards will be delivered [<xref ref-type="bibr" rid="ref6">6</xref>]. In contrast, Leverage-saliency theory [<xref ref-type="bibr" rid="ref7">7</xref>] proposes that a potential participant&#x02019;s decision to respond to a survey is influenced by the importance placed on key factors such as interest in the topic, [<xref ref-type="bibr" rid="ref8">8</xref>] available time; the credibility of the research source, and the benefits (tangible or otherwise) the individual perceives will result from participation. The theory postulates that potential participants with a strong interest in the topic are more likely to respond; incentives can act as leverage for those potential participants for whom influencing factors (such as topic of interest) are deemed less important.</p><p>Our study was undertaken as part of a survey to assess what steps researchers in the fields of health service and population health within the United Kingdom are taking to disseminate the findings of their research. Addressing deficiencies in the dissemination and transfer of research-based knowledge into routine clinical practice is high on the policy agenda both in the United Kingdom [<xref ref-type="bibr" rid="ref9">9</xref>-<xref ref-type="bibr" rid="ref11">11</xref>] and internationally [<xref ref-type="bibr" rid="ref12">12</xref>]. Research dissemination and knowledge transfer is also highly relevant to the United Kingdom applied health research community. The main funder, the National Institute for Health Research (NIHR), is seeking to maximize the impact of its &#x000a3;800 million investment in applied health research [<xref ref-type="bibr" rid="ref13">13</xref>]. The NIHR has expectations that researchers will work to ensure that research is made available, can be used to support decision making, and will ultimately improve the quality and delivery of health care.</p><p>The population of interest for this survey is university-based and has high levels of Internet and email access. In addition, the major public funders of public health and health services research in the United Kingdom operate electronic online submission processes and use email as the principal mode of communication with grant holders and applicants. Given this, we decided to adopt a Web-based survey approach as it represented the most efficient and low cost mode of delivery.</p><p>However, there is some evidence that Web-based surveys can result in lower response rates (around 10%) compared with other survey modes [<xref ref-type="bibr" rid="ref2">2</xref>,<xref ref-type="bibr" rid="ref14">14</xref>,<xref ref-type="bibr" rid="ref15">15</xref>]. Because of this, we decided to offer an incentive (gift vouchers from the online retailer Amazon) to participants to respond. Although a variety of incentives to increase response rates have been tested in a wide range of professional populations (including nine previous studies involving faculty members at universities [<xref ref-type="bibr" rid="ref1">1</xref>]), to our knowledge there is no evidence based on a randomized trial relating to our specific population of interest. In addition, the Cochrane review included three randomized evaluations of Amazon gift vouchers that showed mixed effects [<xref ref-type="bibr" rid="ref1">1</xref>]. Given this, we decided to test&#x02014;using a randomized controlled trial nested within a survey&#x02014;whether knowledge of a financial incentive would increase the response rate to the online questionnaire.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Recruitment</title><p>In July 2008, after obtaining ethical approval for the study from the University of York IRISS Ethics Committee, we contacted 10 UK programs and agencies that fund health services and public health research. The agencies were invited to provide (secure and encrypted) email contact details for UK-based principal investigators of health services and public health research completed in the last five years (2003-2008). Five agencies (the Scottish Chief Scientist Office, Economic and Social Research Council, Medical Research Council, NIHR Health Technology Assessment Programme and Wellcome Trust) responded and provided details. Principal investigator details for one non responding agency (NIHR Service Delivery and Organisation Programme) were publicly available and were obtained from their website. Two agencies (British Heart Foundation and Joseph Rowntree Foundation) indicated that they fund very little public health and health services research and so were excluded from the survey. The Department of Health Policy Research Programme and Cancer Research UK responded stating that they were unable to provide details of principal investigators.</p><p>We identified 743 principal investigators from the six funding agencies. Duplicates were removed from the list resulting in a total survey sample of 536 potential participants. Email addresses for identified principal investigators were then checked and compiled.</p></sec><sec><title>Study design and randomisation</title><p>Potential participants were randomized to receive either &#x0201c;knowledge of&#x0201d; or &#x0201c;no knowledge of&#x0201d; a financial incentive&#x02014;in this instance gift vouchers (from the online retailer Amazon) to the value of &#x000a3;10. Amazon gift vouchers (distributed via the Amazon email gift certificate facility) were sent to all participants who completed the questionnaire regardless of the study group to which they were randomized.</p><p>Random allocation of participants using computer-generated numbers was undertaken independently by a statistician at the Medical Research Council (MRC) General Practice Research Framework.</p></sec><sec><title>Administration</title><p>On October 13, 2008, both groups were contacted by email (<xref ref-type="boxed-text" rid="box1">Textbox 1</xref>). Participants were told the purpose of the study and invited to complete an online questionnaire via an embedded URL. The online questionnaire was hosted on the SurveyMonkey website [<xref ref-type="bibr" rid="ref16">16</xref>] and was based on an instrument previously used to assess the practices of intramural MRC Research Units in an earlier phase of the project. The questionnaire comprised a combination of 36 open and closed questions that could be completed in 20 to 30 minutes. The questionnaire was piloted prior to use.</p><boxed-text id="box1" position="float"><caption><title>Email invitation to knowledge group</title></caption><p>
                        <bold>Subject: MRC PHSRN survey invite</bold>
                    </p><p>Dear Colleague,</p><p>Disseminating the Findings of Health Services and Public Health Research</p><p>We are writing to invite you to take part in a survey.</p><p>This survey aims to find out what steps public health and health services researchers working across the United Kingdom are taking to disseminate the findings of their research.</p><p>The survey is part of a three-year project funded by the MRC Population Health Sciences Research Network (Ref: PHSRN 11). The project aims to identify ways by which the uptake of publicly funded public health and health services research can be enhanced.</p><p>We very much hope that you will agree to participate and complete the questionnaire.</p><p>The questionnaire contains 36 questions and can be completed in 20-30 minutes.</p><p>Respondents who complete the full questionnaire will receive a &#x000a3;10 Amazon gift voucher.</p><p>Any information provided will be treated in the strictest confidence and presented on a nonattributed basis.</p><p>Click here to go to the questionnaire. http://tinyurl.com/5olpfq</p><p>Please do not circulate to other colleagues</p><p>Thank you for your cooperation.</p><p>Best wishes</p><p>Paul Wilson</p><p>On behalf of:</p><p>Mark Petticrew, London School of Hygiene and Tropical Medicine</p><p>Mike Calnan, University of Kent</p><p>Irwin Nazareth, MRC General Practice Research Framework</p><p>Paul Wilson</p><p>Centre for Reviews and Dissemination</p><p>University of York</p><p>York</p><p>YO10 5DD</p><p>t: +44 (0)1904 321073</p><p>f: +44 (0)1904 321041</p><p>e: pmw7@york.ac.uk</p></boxed-text><p>The email sent to the participants in the &#x0201c;knowledge&#x0201d; group stated that those who completed the online questionnaire would receive a &#x000a3;10 Amazon gift voucher. The study design specified that four reminder emails (sent from the same email address as the initial invitation) would be sent out to nonrespondents at one, two, three, and four weeks following the initial invitation; a fifth postal reminder would be sent to nonrespondents if the response rate was considered to be low. Participants who completed the online questionnaire were deemed to have given their consent. Questionnaires not returned by December 31, 2008, were deemed to be nonresponses.</p><p>As this RCT was nested within a larger survey, the primary concern was to maximize response rates. Given this, it was determined thatif the difference in the response rate between the two groups was such that it was likely to adversely affect the main aims of the survey, then knowledge of the incentive would be provided to the &#x0201c;no knowledge&#x0201d; group, but not before the third reminder. At the third reminder, we provided &#x0201c;knowledge of&#x0201d; the incentive to the &#x0201c;no knowledge&#x0201d; group to limit any adverse effects on total response to the survey.</p><p>A combination of IP address and questionnaire responses were used to identify multiple responses from a single participant [<xref ref-type="bibr" rid="ref17">17</xref>]. Where multiple responses from a single participant occurred, the most recently completed questionnaire was retained for analysis. Noninvited responses from individuals not part of the study sample were excluded from the analysis.</p></sec><sec><title>Analysis</title><p>The primary outcome measure for the trial was rate of response one week after the second reminder. Rate of response was also measured at the end of weeks one, two, three, four, and five, and after the postal reminder. Data were entered and analysed in SPSS version 15.0 (SPSS Inc, Chicago, IL, USA). We compared the response rates in each group using the chi-square statistic.</p></sec></sec><sec sec-type="results"><title>Results</title><p>Of the 536 identified email addresses, 51 were undeliverable resulting in a sample of 485. A total 243 (50%) questionnaires were returned (232 completed; 11 in which participation was declined). <xref ref-type="fig" rid="figure1">Figure 1</xref> illustrates the flow of responses to the study.</p><p>As a measure of completion [<xref ref-type="bibr" rid="ref17">17</xref>], 100% of the 232 participants who completed questionnaires answered the questions on the first page, and 95% (220/232) answered the final question. Excluded from the analyses were 4 questionnaires completed by noninvited individuals. Multiple responses were submitted by 2 participants; the most recently submitted questionnaire was included in the analyses in each case.</p><p><xref ref-type="table" rid="table1">Table 1</xref> shows the cumulative response rate over time by group. <xref ref-type="fig" rid="figure2">Figure 2</xref> shows the cumulative percentage response over time, again by group. The primary outcome measure for the trial was rate of response one week after the second reminder. The cumulative response rate in the &#x0201d;knowledge&#x0201d; group was 27% (66/244) versus 20% (49/241) in the &#x0201c;no knowledge&#x0201d; group. This difference was not statistically significant (&#x003c7;<sup>2</sup><sub>1</sub>=3.0, <italic>P</italic>=.08). The odds ratio for those with knowledge of an incentive that responded was 1.45 (95% confidence interval [CI] 0.95 - 2.21).</p><fig id="figure1" position="float"><label>Figure 1</label><caption><p>Flow chart of &#x0201c;knowledge of&#x0201d; versus &#x0201c;no knowledge of&#x0201d; financial incentive</p></caption><graphic xlink:href="jmir_v12i2e13_fig1"/></fig><table-wrap id="table1" position="float"><label>Table 1</label><caption><p>Cumulative response over time by group</p></caption><table frame="hsides" rules="groups" cellpadding="8" cellspacing="0" border="1"><thead><tr valign="bottom"><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Knowledge Group (n = 244)</td><td rowspan="1" colspan="1">No Knowledge Group<sup>a</sup> (n = 241)</td><td rowspan="1" colspan="1">&#x003c7;<sup>2</sup> Significance</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">First response</td><td rowspan="1" colspan="1">31 (13%)</td><td rowspan="1" colspan="1">15 (6%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.01</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reminder 1</td><td rowspan="1" colspan="1">49 (20%)</td><td rowspan="1" colspan="1">36 (15%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.13</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reminder 2</td><td rowspan="1" colspan="1">66 (27%)</td><td rowspan="1" colspan="1">49 (20%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.08</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reminder 3</td><td rowspan="1" colspan="1">81 (33%)</td><td rowspan="1" colspan="1">61 (25%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.06</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reminder 4</td><td rowspan="1" colspan="1">94 (38%)</td><td rowspan="1" colspan="1">77 (32%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.13</td></tr><tr valign="top"><td rowspan="1" colspan="1">Postal Reminder</td><td rowspan="1" colspan="1">122 (50%)</td><td rowspan="1" colspan="1">110 (46%)</td><td rowspan="1" colspan="1"><italic>P</italic>=.33</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><p>
                            <sup>a</sup>No knowledge group informed about incentive from reminder 3 onwards</p></fn></table-wrap-foot></table-wrap><fig id="figure2" position="float"><label>Figure 2</label><caption><p>Cumulative response (%) over time by group</p></caption><graphic xlink:href="jmir_v12i2e13_fig2"/></fig><p>At the third reminder, participants in the &#x0201c;no knowledge&#x0201d; group were informed about the incentive, ending the randomized trial nested within the survey. As this was a survey, we continued to follow up all respondents, and for transparency purposes, <xref ref-type="table" rid="table1">Table 1</xref> presents further data on the cumulative response rates. No significant differences were observed in response rates between the two groups from reminder 3 onwards.</p></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Statement of principal findings</title><p>Knowledge of a financial incentive did not significantly improve the response rate to this online questionnaire. However, one week after the second reminder&#x02014;the point before the &#x0201c;no knowledge&#x0201d; group were informed about the incentive&#x02014;a difference of 7% was apparent.</p></sec><sec><title>Comparison with other studies</title><p>In terms of overall response, our rate of 50% compares favourably with those reported for other Web surveys. For example, in a review of comparisons of Web survey versus other survey modes, only 6 of 45 Web surveys managed to obtain a response rate higher than 50% [<xref ref-type="bibr" rid="ref14">14</xref>]. In a second meta-analysis, which reported an 11% difference in response rates in favor of postal over Web modes, only 10 of 39 comparisons obtained a Web survey response rate higher than 50% [<xref ref-type="bibr" rid="ref15">15</xref>]. Previous randomized evaluations of our choice of incentive (an Amazon gift voucher) [<xref ref-type="bibr" rid="ref1">1</xref>] have shown mixed effects in different populations and settings. However, of three previous studies similar to ours included in the Cochrane review, researchers compared the effects of: a $5 cash incentive versus a $5 gift voucher [<xref ref-type="bibr" rid="ref19">19</xref>]; no incentive versus entry into a lottery for $50, $100, $150, or $200 gift vouchers [<xref ref-type="bibr" rid="ref20">20</xref>]; and unconditional $15 or $25 gift vouchers versus $15 or $25 gift vouchers conditional on completion of the survey [<xref ref-type="bibr" rid="ref21">21</xref>].</p></sec><sec><title>Strengths and limitations of study</title><p>In developing our survey, we adhered to recommendations for the design of email questionnaires [<xref ref-type="bibr" rid="ref18">18</xref>]. These included deriving an appropriate sample, using an embedded URL, using incentives, and sending the request for information from a recognized academic source. One recommendation beyond our control was that the research be perceived to be relevant to the population surveyed. As stated above, there is renewed emphasis on increasing the uptake and transfer of publicly funded research into policy and practice, and those responding indicated that dissemination of the results of research was highly relevant to their work. However, we had no way of knowing beforehand whether the topic or goal would be deemed relevant or of interest by those we surveyed.</p><p>In our study, we utilized a 36-item questionnaire and stated that it would take participants up to 30 minutes to complete. Shorter postal questionnaires are associated with increased response rates [<xref ref-type="bibr" rid="ref1">1</xref>]. It may be that the perceived return (&#x000a3;10) for time invested in completing the 36 items was deemed inadequate compensation by some participants, especially if considered in relation to their incomes as professional researchers. We do not know whether an increase in the financial incentive relative to participant income would have made any difference in this instance. Another consideration relates to the nature of the incentive offered. Receipt of the gift voucher was dependent on the participant completing the questionnaire. There is evidence that response rates can be higher when an incentive is given up front unconditionally rather than given conditional on completion [<xref ref-type="bibr" rid="ref1">1</xref>]. The use of unconditional versus conditional incentives merits further investigation.</p><p>In this study, members of the population of interest have high levels of Internet and email access. Yet, around a fifth of all returned completed questionnaires were paper copies that had been mailed out as part of the postal reminder. This decision to adopt a mixed mode approach in the event of a low response rate appears sensible in light of feedback from two of the respondents. They indicated that they found it hard to find the time to respond to Web surveys, and as they were often out of the office, it was easier to complete a survey that used a paper-and-pen format. Although we recognize that our experience relates to a very specific population and suggest some caution in generalizing these findings to other populations, designers of future Web surveys may wish to consider using this mixed mode approach.</p><p>This randomized study was undertaken as part of a wider survey to assess what steps public health and health services researchers working across the United Kingdom are taking to disseminate the findings of their research. This nesting approach offered a cheap and efficient method of adding to our knowledge of the utility of different survey modes. However, undertaking such an approach was not without potential challenges. Normally in randomized studies, one would compare an intervention against standard practice when the outcome is unknown. But in this instance our primary concern was to maximize response rates to the wider survey. In doing so it was possible we limited the duration of the intervention making it difficult to determine what the true effect of the incentive would have been over a longer time period. Future web surveys should consider nesting a randomized element to further test the utility of incentives but should also consider whether the time frame for response is adequate to determine the true effect.</p></sec><sec><title>Conclusions</title><p>Our trial can help researchers planning future Web-based surveys. It would appear that immediate responses within two weeks of initial contact to a Web-based survey might be improved by the offer of a small financial incentive. Hence, we would recommend small financial incentives to those researchers requiring quick responses to Web-based questionnaires. However our findings suggest that this effect may dissipate over time. Researchers should consider that even in specific populations with high levels of access to the Internet, there might be advantages in using mixed methods (ie, use of both web and paper questionnaires) in terms of participant preferences and in increasing response rates.</p></sec></sec></body><back><ack><p>This research was funded by MRC Population Health Sciences Research Network.</p></ack><fn-group><fn fn-type="conflict"><p>None declared</p></fn><fn fn-type="con"><p>All authors contributed to the conception, design and analysis of the study. All authors were involved in the writing of the first and subsequent versions of the paper. The views expressed in this paper are those of the authors alone.</p></fn></fn-group><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>PJ</given-names></name><name><surname>Roberts</surname><given-names>I</given-names></name><name><surname>Clarke</surname><given-names>MJ</given-names></name><name><surname>DiGuiseppi</surname><given-names>C</given-names></name><name><surname>Wentz</surname><given-names>R</given-names></name><name><surname>Kwan</surname><given-names>I</given-names></name><name><surname>Cooper</surname><given-names>R</given-names></name><name><surname>Felix</surname><given-names>LM</given-names></name><name><surname>Pratap</surname><given-names>S</given-names></name></person-group><article-title>Methods to increase response to postal and electronic questionnaires</article-title><source>Cochrane Database Syst Rev</source><year>2009</year><volume>3</volume><pub-id pub-id-type="doi">10.1002/14651858.MR000008.pub4.</pub-id><pub-id pub-id-type="medline">19588449</pub-id></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanGeest</surname><given-names>Jonathan B</given-names></name><name><surname>Johnson</surname><given-names>Timothy P</given-names></name><name><surname>Welch</surname><given-names>Verna L</given-names></name></person-group><article-title>Methodologies for improving response rates in surveys of physicians: a systematic review</article-title><source>Eval Health Prof</source><year>2007</year><month>12</month><volume>30</volume><issue>4</issue><fpage>303</fpage><lpage>21</lpage><pub-id pub-id-type="medline">17986667</pub-id><pub-id pub-id-type="pii">30/4/303</pub-id><pub-id pub-id-type="doi">10.1177/0163278707307899</pub-id><pub-id pub-id-type="pmid">17986667</pub-id></element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f6;ritz</surname><given-names>AS</given-names></name></person-group><article-title>Incentives in Web studies: Methodological issues and a review</article-title><source>International Journal of Internet Science</source><year>2008</year><volume>1</volume><fpage>58</fpage><lpage>70</lpage></element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Homans</surname><given-names>GC</given-names></name></person-group><article-title>Social Behavior as Exchange</article-title><source>Amer J Sociol</source><year>1958</year><volume>63</volume><issue>6</issue><fpage>597</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1086/222355</pub-id></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagozzi</surname><given-names>RP</given-names></name></person-group><article-title>Marketing as exchange</article-title><source>J Mark</source><year>1975</year><volume>39</volume><fpage>32</fpage><lpage>9</lpage></element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McColl</surname><given-names>E</given-names></name><name><surname>Jacoby</surname><given-names>A</given-names></name><name><surname>Thomas</surname><given-names>L</given-names></name><name><surname>Soutter</surname><given-names>J</given-names></name><name><surname>Bamford</surname><given-names>C</given-names></name><name><surname>Steen</surname><given-names>N</given-names></name><name><surname>Thomas</surname><given-names>R</given-names></name><name><surname>Harvey</surname><given-names>E</given-names></name><name><surname>Garratt</surname><given-names>A</given-names></name><name><surname>Bond</surname><given-names>J</given-names></name></person-group><article-title>Design and use of questionnaires: a review of best practice applicable to surveys of health service staff and patients</article-title><source>Health Technol Assess</source><year>2001</year><volume>5</volume><issue>31</issue><fpage>1</fpage><lpage>256</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.hta.ac.uk/execsumm/summ531.htm"/></comment><pub-id pub-id-type="medline">11809125</pub-id><pub-id pub-id-type="pmid">11809125</pub-id></element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groves</surname><given-names>R M</given-names></name><name><surname>Singer</surname><given-names>E</given-names></name><name><surname>Corning</surname><given-names>A</given-names></name></person-group><article-title>Leverage-saliency theory of survey participation: description and an illustration</article-title><source>Public Opin Q</source><year>2000</year><volume>64</volume><issue>3</issue><fpage>299</fpage><lpage>308</lpage><pub-id pub-id-type="medline">11114270</pub-id><pub-id pub-id-type="pii">POQ640304</pub-id><pub-id pub-id-type="doi">10.1086/317990</pub-id><pub-id pub-id-type="pmid">11114270</pub-id></element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groves</surname><given-names>RM</given-names></name><name><surname>Presser</surname><given-names>S</given-names></name><name><surname>Dipko</surname><given-names>S</given-names></name></person-group><article-title>The role of topic interest in survey participation decisions</article-title><source>Public Opin Q</source><year>2004</year><volume>68</volume><issue>1</issue><fpage>2</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1093/poq/nfh002</pub-id></element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cooksey</surname><given-names>D</given-names></name></person-group><source>A Review of UK Health Research Funding</source><year>2006</year><publisher-loc>London, England</publisher-loc><publisher-name>HM Treasury</publisher-name></element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="book"><collab collab-type="authors">Department of Health</collab><source>Best Research for Best Health: A new national health research strategy</source><year>2006</year><publisher-loc>London, England</publisher-loc><publisher-name>Department of Health</publisher-name></element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tooke</surname><given-names>J</given-names></name></person-group><source>Report of the High Level Group on Clinical Effectiveness. A report to Sir Liam Donaldson Chief Medical Officer</source><year>2007</year><publisher-loc>London, England</publisher-loc><publisher-name>Department of Health</publisher-name></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="book"><collab collab-type="authors">World Health Organization</collab><source>World Report on Knowledge for Better Health: Strengthening Health Systems</source><year>2004</year><publisher-loc>Geneva, Switzerland</publisher-loc><publisher-name>World Health Organization</publisher-name></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="book"><collab collab-type="authors">Department of Health, Research and Development Directorate</collab><source>Delivering Health Research. National Institute for Health Research Progress Report 2008/09</source><year>2009</year><publisher-loc>London, England</publisher-loc><publisher-name>Department of Health</publisher-name></element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manfreda</surname><given-names>KL</given-names></name><name><surname>Bosnjak</surname><given-names>M</given-names></name><name><surname>Berzelak</surname><given-names>J</given-names></name><name><surname>Haas</surname><given-names>I</given-names></name><name><surname>Vehovar</surname><given-names>V</given-names></name><name><surname>Berzelak</surname><given-names>N</given-names></name></person-group><article-title>Web surveys versus other survey modes. A Meta-Analysis Comparing Response Rates</article-title><source>International Journal of Market Research</source><year>2008</year><volume>50</volume><fpage>79</fpage><lpage>104</lpage></element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shih</surname><given-names>TH</given-names></name><name><surname>Fan</surname><given-names>X</given-names></name></person-group><article-title>Comparing response rates from web and mail surveys: A meta-analysis</article-title><source>Field methods</source><year>2008</year><volume>20</volume><issue>3</issue><fpage>249</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1177/1525822X08317085</pub-id></element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="webpage"><source>SurveyMonkey.com</source><comment><ext-link ext-link-type="uri" xlink:href="http://www.surveymonkey.com">http://www.surveymonkey.com</ext-link></comment><ext-link ext-link-type="webcite" xlink:href="5iPPdPhoD"/></element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eysenbach</surname><given-names>Gunther</given-names></name></person-group><article-title>Improving the quality of Web surveys: the Checklist for Reporting Results of Internet E-Surveys (CHERRIES)</article-title><source>J Med Internet Res</source><year>2004</year><month>9</month><day>29</day><volume>6</volume><issue>3</issue><fpage>e34</fpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/2004/3/e34/"/></comment><pub-id pub-id-type="medline">15471760</pub-id><pub-id pub-id-type="pii">v6e34</pub-id><pub-id pub-id-type="doi">10.2196/jmir.6.3.e34</pub-id><pub-id pub-id-type="pmcid">PMC1550605</pub-id><pub-id pub-id-type="pmid">15471760</pub-id></element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaelidou</surname><given-names>N</given-names></name><name><surname>Dibb</surname><given-names>S</given-names></name></person-group><article-title>Using e-mail questionnaires for consumer research: best practice in tackling non-response</article-title><source>Journal of Targeting, Measurement and Analysis for Marketing</source><year>2006</year><volume>14</volume><issue>4</issue><fpage>289</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1057/palgrave.jt.5740189</pub-id></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birnholtz</surname><given-names>JP</given-names></name><name><surname>Horn</surname><given-names>DB</given-names></name><name><surname>Finholt</surname><given-names>TA</given-names></name><name><surname>Bae</surname><given-names>SJ</given-names></name></person-group><article-title>The effect of cash, electronic,and paper gift certificates asrespondent incentives for a web based survey of technologically sophisticated respondents</article-title><source>Soc Sci Comput Rev</source><year>2004</year><volume>22</volume><fpage>355</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1177/0894439304263147</pub-id></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>SR</given-names></name><name><surname>Whitcomb</surname><given-names>ME</given-names></name></person-group><article-title>The impact of lottery incentives on student survey response rates</article-title><source>Research in Higher Education</source><year>2003</year><volume>44</volume><fpage>389</fpage><lpage>407</lpage></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downes-Le Guin</surname><given-names>T</given-names></name><name><surname>Janowitz</surname><given-names>P</given-names></name><name><surname>Stone</surname><given-names>R</given-names></name><name><surname>Khorram</surname><given-names>S</given-names></name></person-group><article-title>Use of pre-incentives in an Internet survey</article-title><source>Journal of Online Research</source><year>2002</year><pub-id pub-id-type="doi">10.1023/A:1024263031800</pub-id></element-citation></ref></ref-list></back></article>