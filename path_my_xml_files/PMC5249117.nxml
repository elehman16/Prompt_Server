<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28107359</article-id><article-id pub-id-type="pmc">5249117</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0168858</article-id><article-id pub-id-type="publisher-id">PONE-D-16-36874</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Bioassays and Physiological Analysis</subject><subj-group><subject>Electrophysiological Techniques</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain Mapping</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Diagnostic Medicine</subject><subj-group><subject>Clinical Neurophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Perceptual Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Sustained Cortical and Subcortical Measures of Auditory and Visual Plasticity following Short-Term Perceptual Learning</article-title><alt-title alt-title-type="running-head">Auditory and Visual Plasticity</alt-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0576-5470</contrib-id><name><surname>Lau</surname><given-names>Bonnie K.</given-names></name><xref ref-type="aff" rid="aff001"/><xref ref-type="author-notes" rid="currentaff001"><sup>&#x000a4;</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ruggles</surname><given-names>Dorea R.</given-names></name><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Katyal</surname><given-names>Sucharit</given-names></name><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Engel</surname><given-names>Stephen A.</given-names></name><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Oxenham</surname><given-names>Andrew J.</given-names></name><xref ref-type="aff" rid="aff001"/></contrib></contrib-group><aff id="aff001"><addr-line>Department of Psychology, University of Minnesota, Minneapolis, Minnesota, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Ahveninen</surname><given-names>Jyrki</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Harvard Medical School, UNITED STATES</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con"><p><list list-type="simple"><list-item><p><bold>Conceptualization:</bold> BKL DRR AJO.</p></list-item><list-item><p><bold>Funding acquisition:</bold> AJO.</p></list-item><list-item><p><bold>Methodology:</bold> BKL DRR SK SAE AJO.</p></list-item><list-item><p><bold>Software:</bold> BKL DRR SK SAE AJO.</p></list-item><list-item><p><bold>Writing &#x02013; original draft:</bold> BKL DRR.</p></list-item><list-item><p><bold>Writing &#x02013; review &#x00026; editing:</bold> BKL DRR SK SAE AJO.</p></list-item></list>
</p></fn><fn fn-type="current-aff" id="currentaff001"><label>&#x000a4;</label><p>Current address: Institute for Learning and Brain Sciences, University of Washington, Seattle, Washington, United States of America</p></fn><corresp id="cor001">* E-mail: <email>blau@uw.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>20</day><month>1</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>12</volume><issue>1</issue><elocation-id>e0168858</elocation-id><history><date date-type="received"><day>14</day><month>9</month><year>2016</year></date><date date-type="accepted"><day>6</day><month>11</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; 2017 Lau et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Lau et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0168858.pdf"/><abstract><p>Short-term training can lead to improvements in behavioral discrimination of auditory and visual stimuli, as well as enhanced EEG responses to those stimuli. In the auditory domain, fluency with tonal languages and musical training has been associated with long-term cortical and subcortical plasticity, but less is known about the effects of shorter-term training. This study combined electroencephalography (EEG) and behavioral measures to investigate short-term learning and neural plasticity in both auditory and visual domains. Forty adult participants were divided into four groups. Three groups trained on one of three tasks, involving discrimination of auditory fundamental frequency (F0), auditory amplitude modulation rate (AM), or visual orientation (VIS). The fourth (control) group received no training. Pre- and post-training tests, as well as retention tests 30 days after training, involved behavioral discrimination thresholds, steady-state visually evoked potentials (SSVEP) to the flicker frequencies of visual stimuli, and auditory envelope-following responses simultaneously evoked and measured in response to rapid stimulus F0 (EFR), thought to reflect subcortical generators, and slow amplitude modulation (ASSR), thought to reflect cortical generators. Enhancement of the ASSR was observed in both auditory-trained groups, not specific to the AM-trained group, whereas enhancement of the SSVEP was found only in the visually-trained group. No evidence was found for changes in the EFR. The results suggest that some aspects of neural plasticity can develop rapidly and may generalize across tasks but not across modalities. Behaviorally, the pattern of learning was complex, with significant cross-task and cross-modal learning effects.</p></abstract><funding-group><award-group id="award001"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01 DC005216</award-id><principal-award-recipient>Andrew J. Oxenham</principal-award-recipient></award-group><funding-statement>This work was supported by the National Institute of Health R01 DC0005216 to AJO.</funding-statement></funding-group><counts><fig-count count="5"/><table-count count="0"/><page-count count="17"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>One of the remarkable feats of perceptual neural processing is the ability to learn, change, and adapt to particular circumstances and tasks. Auditory plasticity has been demonstrated on multiple time scales and in a wide variety of contexts. Directed attention very quickly enhances the cortical representation of relevant sounds [<xref rid="pone.0168858.ref001" ref-type="bibr">1</xref>], and even very brief (1&#x02013;5 s) listening experience in reverberant [<xref rid="pone.0168858.ref002" ref-type="bibr">2</xref>,<xref rid="pone.0168858.ref003" ref-type="bibr">3</xref>] or spectrally colored [<xref rid="pone.0168858.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0168858.ref005" ref-type="bibr">5</xref>] environments can improve speech intelligibility. Long-term experience, such as musical training and tonal language fluency, have been associated with neural plasticity that may develop over the course of years [<xref rid="pone.0168858.ref006" ref-type="bibr">6</xref>&#x02013;<xref rid="pone.0168858.ref008" ref-type="bibr">8</xref>]. The physiological mechanisms that underlie long- and short-term plasticity in auditory perceptual processing continue to be elusive but have significant implications for understanding the neurophysiology of the auditory pathways and for developing interventions for clinical populations. Similar questions of mechanism and time scale are of interest in the visual domain [<xref rid="pone.0168858.ref009" ref-type="bibr">9</xref>].</p><p>Long-term musical training has been extensively studied in terms of its impact on auditory perception as well as the encoding of sound along the auditory pathway. Although it is difficult to rule out genetic and social factors that may influence neural development as well as the pursuit of musical training, both cortical and subcortical neurophysiological enhancements have been associated with musical experience. Structural neuroimaging studies report increased gray matter volume in auditory, motor, and visuo-spatial cortical regions in professional musicians [<xref rid="pone.0168858.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0168858.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0168858.ref011" ref-type="bibr">11</xref>]. Enhancement of cortical evoked potentials including N1 and P2 [<xref rid="pone.0168858.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0168858.ref013" ref-type="bibr">13</xref>] and the earlier N19m-P30m complex [<xref rid="pone.0168858.ref010" ref-type="bibr">10</xref>] have been observed in response to tonal stimuli. Sustained responses to periodic stimuli of 80&#x02013;1000 Hz (EFR) are thought to be generated primarily in the subcortical auditory structures [<xref rid="pone.0168858.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0168858.ref015" ref-type="bibr">15</xref>], and investigations of these responses have shown greater spectral magnitude of the fundamental frequency (F0; the acoustic correlate of pitch) of complex tones in musicians compared to non-musicians [<xref rid="pone.0168858.ref016" ref-type="bibr">16</xref>]. Behavioral results are consistent with these physiological findings, with superior frequency-discrimination abilities reliably reported in musicians compared to non-musicians [<xref rid="pone.0168858.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0168858.ref018" ref-type="bibr">18</xref>]. However, whether such auditory perceptual enhancements generalize beyond music-related tasks, such as frequency discrimination is unclear [<xref rid="pone.0168858.ref019" ref-type="bibr">19</xref>]. For instance, improvements in speech perception in noise or interfering talkers have been reported by some groups [<xref rid="pone.0168858.ref020" ref-type="bibr">20</xref>&#x02013;<xref rid="pone.0168858.ref022" ref-type="bibr">22</xref>] but not by others [<xref rid="pone.0168858.ref023" ref-type="bibr">23</xref>&#x02013;<xref rid="pone.0168858.ref026" ref-type="bibr">26</xref>]. Improved understanding of plasticity in EFR after shorter, more controlled learning may help to clarify details of the subcortical plasticity attributed to musical training.</p><p>Studies of learning-induced plasticity in non-human primates and rats have shown expanded representation of trained frequencies in primary auditory cortex following frequency-discrimination training [<xref rid="pone.0168858.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0168858.ref029" ref-type="bibr">29</xref>]. Much less is known about the cortical correlates of short-term perceptual learning in humans, but several studies report enhancement of the N1 and P2 cortical event-related potentials (ERP) following auditory training [<xref rid="pone.0168858.ref030" ref-type="bibr">30</xref>,<xref rid="pone.0168858.ref031" ref-type="bibr">31</xref>]. In this study, we investigate whether plasticity can also be observed in sustained steady-state EEG responses, which reflect the entrainment of neural responses to the periodicity of external stimuli, as opposed to previous time-domain ERP measures. We paired three tasks involving auditory or visual discrimination with corresponding steady-state responses. All behavioral tasks required discrimination as opposed to detection, in order to target high-level perceptual judgments [<xref rid="pone.0168858.ref032" ref-type="bibr">32</xref>].</p><p>Pitch discrimination can be quickly learned, to the extent that initially untrained listeners can achieve the same level of performance as professional musicians with 4&#x02013;6 hours of training [<xref rid="pone.0168858.ref033" ref-type="bibr">33</xref>]. Pitch discrimination also offers the opportunity to study short-term perceptual learning using a task that is also often associated with long-term plasticity. We trained listeners on pitch discrimination with harmonic complex tones, which elicit an EFR in response to the F0. The EFR is a broadly generated response which has been localized primarily to subcortical neural populations, and which reflects phase-locked responses to amplitude modulation in the range of 80&#x02013;1000 Hz [<xref rid="pone.0168858.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0168858.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0168858.ref034" ref-type="bibr">34</xref>]. Although reports of plasticity following short-term perceptual learning are mainly limited to cortical measures, at least one study investigated the possibility of subcortical plasticity in sustained responses [<xref rid="pone.0168858.ref035" ref-type="bibr">35</xref>]. In their study, Carcagno and Plack [<xref rid="pone.0168858.ref035" ref-type="bibr">35</xref>] found significant enhancement of EFR amplitude in response to dynamic and static pitch stimuli, along with improvements in behavioral discrimination. However, their results were inconsistent for the dynamic conditions and the effects were sufficiently small to warrant replication.</p><p>The processing of AM is central to speech perception in quiet and noise [<xref rid="pone.0168858.ref036" ref-type="bibr">36</xref>&#x02013;<xref rid="pone.0168858.ref038" ref-type="bibr">38</xref>], with modulation rates below about 16 Hz most important for speech understanding in general [<xref rid="pone.0168858.ref039" ref-type="bibr">39</xref>,<xref rid="pone.0168858.ref040" ref-type="bibr">40</xref>]. AM rate discrimination also improves with training and shows minimal generalization to other tasks, making it ideal for combining with frequency discrimination to study specificity of learning and plasticity along the auditory pathway [<xref rid="pone.0168858.ref041" ref-type="bibr">41</xref>]. We tested AM rate discrimination training with amplitude-modulated complex tones, which also elicit an auditory steady state response (ASSR). The ASSR in response to AM between 0&#x02013;40 Hz is thought to be generated in the auditory cortex [<xref rid="pone.0168858.ref015" ref-type="bibr">15</xref>].</p><p>The third set of measures included here involves a visual perceptual training task combined with steady-state visual evoked potentials (SSVEP). Visual and auditory steady-state responses are similar but independently generated, allowing us to investigate potential cross-modal transfer effects. Discrimination of Gabor pattern orientation improves with training [<xref rid="pone.0168858.ref042" ref-type="bibr">42</xref>] and some evidence suggests that the SSVEP is plastic in response to both perceptual training and aversive conditioning [<xref rid="pone.0168858.ref043" ref-type="bibr">43</xref>,<xref rid="pone.0168858.ref044" ref-type="bibr">44</xref>].</p><p>The aim of this study was to evaluate the influence of perceptual learning on sustained neurophysiological responses within and across sensory modalities. Each auditory stimulus had both an F0 and an AM rate, allowing us to test whether training on one feature (e.g., F0) affected the neural representation and perception of another feature (e.g., AM). Concurrent presentation of the AM and F0 also enables simultaneous measurements from potentially different auditory neural generators. Our hypothesis was that F0-discrimination training would selectively enhance the EFR to the F0, whereas AM-discrimination training would selectively enhance the ASSR to the AM rate, and that the visual orientation discrimination training would selectively enhance the SSVEP responses.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials &#x00026; Methods</title><sec id="sec003"><title>Subjects</title><p>The participants were forty (25 females and 15 males) normal-hearing listeners between 18 and 35 years of age who had less than 5 years of musical training, no prior experience in psychophysical experiments, and who did not speak any tonal languages. All participants passed an audiometric screening with pure-tone thresholds below 20 dB hearing level (HL) for octave frequencies between 250 and 8000 Hz and wore visual corrective lenses as prescribed by an optometrist during all sessions if required. Written informed consent was obtained from all participants in accordance with protocols reviewed and approved by the Institutional Review Board at the University of Minnesota. The participants were paid for their participation.</p></sec><sec id="sec004"><title>Stimuli</title><p>The auditory stimuli were amplitude-modulated harmonic complexes (<xref ref-type="fig" rid="pone.0168858.g001">Fig 1A</xref>) with all components added in sine phase, bandpass filtered between 1700 and 3600 Hz (Butterworth filter with 24 dB/oct slopes). This filtering ensured that only harmonics 17 to 33 were presented, which in turn meant that the participants had to rely on the periodicity in the temporal envelope to extract the pitch [<xref rid="pone.0168858.ref045" ref-type="bibr">45</xref>,<xref rid="pone.0168858.ref046" ref-type="bibr">46</xref>]. In this way, both the perception and the EFR relied on the same acoustic cues. The nominal F0 of the complex was 137 Hz, and the complex was sinusoidally amplitude modulated at a rate of 13 Hz with 100% depth. The duration of the complexes was 400 ms for behavioral tasks and 1 s for the EEG measurements, and all complexes had 10-ms raised-cosine onset and offset ramps. Modulated tones were embedded in a threshold equalizing noise (TEN) [<xref rid="pone.0168858.ref047" ref-type="bibr">47</xref>] extending from 50 to 8000 Hz, with a spectral notch from 1500 to 4800 Hz to limit the contributions from neurons tuning to frequencies outside the stimulus passband, and to reduce the audibility of any distortion products.</p><fig id="pone.0168858.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0168858.g001</object-id><label>Fig 1</label><caption><title>Auditory and visual stimuli.</title><p>(A) Unresolved harmonic complex with a F0 of 137 Hz, amplitude modulated at 13 Hz. (B) 3&#x000b0; of visual angle standard deviation degree Gabor pattern with spatial frequency of 1 degree per cycle embedded in a 9&#x000b0; background noise.</p></caption><graphic xlink:href="pone.0168858.g001"/></fig><p>During behavioral testing, the tones were presented at an overall level of 53 dB sound pressure level (SPL), and the TEN level was 43 dB SPL per equivalent rectangular bandwidth (ERB) at 1 kHz between 50 and 1500 Hz and 33 dB SPL per ERB between 4800 and 8000 Hz. During EEG recording, the tones were presented at an overall level of 65 dB SPL embedded in TEN at 55 dB SPL in the lower region and 45 dB SPL in the higher region. The tones were increased by 10 dB during EEG recording because higher presentation levels (65&#x02013;80 dB SPL) recruit larger neural populations and maximize the signal-to-noise ratio in recorded potentials [<xref rid="pone.0168858.ref034" ref-type="bibr">34</xref>,<xref rid="pone.0168858.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0168858.ref048" ref-type="bibr">48</xref>].</p><p>The visual stimuli were generated using Psychophysics toolbox [<xref rid="pone.0168858.ref049" ref-type="bibr">49</xref>&#x02013;<xref rid="pone.0168858.ref051" ref-type="bibr">51</xref>] in MATLAB (The MathWorks Inc., Natick, MA). The visual stimuli consisted of a 3&#x000b0; of visual angle standard deviation Gabor pattern with a spatial frequency of 1 cycle per degree embedded in a 9&#x000b0; background of filtered noise (<xref ref-type="fig" rid="pone.0168858.g001">Fig 1B</xref>). The noise was created by convolving white noise with an isotropic 2D Gaussian filter centered on 1 cycle per degree with a standard deviation of 0.33 cyc per degree. In order to record the SSVEP to both the stimuli and the background noise, the Gabor pattern sawtooth flickered at 13 Hz while the noise sawtooth flickered at 17 Hz.</p></sec><sec id="sec005"><title>Protocol</title><p>The perceptual training paradigm was conducted with four groups of ten participants, assigned randomly to each group. In the three experimental groups, participants were trained for about 30 minutes a day for 6 days on one of three tasks: F0 discrimination (F0 Group), AM rate discrimination (AM Group), or visual orientation discrimination (VIS Group). Participants were encouraged to complete the sessions on consecutive days but were allowed a maximum of two days between training sessions if they were unable to attend a weekend session. The final training session and the post-test were always completed on consecutive days. The EEG recording and behavioral measures were repeated again 30 days post-training to investigate whether training effects were maintained. A fourth, no-training control group (CON Group) was also included, where participants received EEG recording and behavioral pre- and post-tests at comparable time intervals to participants in the other groups but were not trained on any discrimination task. Control group participants received the initial EEG and behavioral pre-test and returned one week later to complete the post-test but did not participate in the maintenance test.</p></sec><sec id="sec006"><title>EEG test procedure</title><p>Pre-, post- and maintenance tests consisted of an EEG recording session followed by behavioral threshold measurements for each of the three discrimination tasks. EEG measurements were acquired using a Biosemi active electrode system with a sampling rate of 4096 Hz and 32 channels referenced to averaged mastoid electrodes. The recordings were made in a sound-attenuating booth.</p><p>The SSVEPs were recorded in response to a Gabor pattern embedded in background noise (<xref ref-type="fig" rid="pone.0168858.g001">Fig 1B</xref>), partitioned into twenty 1-minute blocks. Participants were seated two feet in front of an HP LP2065 LCD monitor with a refresh rate of 75 Hz. The monitor&#x02019;s luminance gamma curves were measured using a Photoresearch PR-655 and corrected in software to ensure correct display of stimulus intensity. During recording, participants were presented with a luminance-change discrimination task to ensure that they were attending to the stimuli. Within each 1-minute block, the intensity of the Gabor pattern increased ten times at random intervals. Participants were instructed to press a key on a number pad as quickly as possible whenever they detected the luminance change. All participants achieved 80% correct or better on the task. The blocks were self-paced and completed in less than 30 minutes for all participants.</p><p>Following the SSVEP, simultaneous cortical and subcortical auditory sustained responses were recorded to 1000 repetitions of the 1-s AM harmonic complex (<xref ref-type="fig" rid="pone.0168858.g001">Fig 1A</xref>). The (cortical) ASSR was measured to the 13-Hz AM rate while the (subcortical) EFR was measured to the 137-Hz F0 in the same tones. The complexes were generated using Matlab and played to participants via a Tucker Davis Technologies (TDT) real time processor with headphone buffer and Etymotic ER1 insert earphones. Interstimulus intervals were jittered randomly between 700 and 800 ms and stimulus polarity was randomly alternated, resulting in 500 presentations of each polarity. Participants watched a silent close-captioned movie while listening to the stimuli during the auditory EEG recordings.</p></sec><sec id="sec007"><title>Behavioral test procedure</title><p>All behavioral sessions took place in a double-walled sound-attenuating booth. The auditory stimuli were presented diotically over Sennheiser HD 650 headphones, which have an approximately diffuse-field response; specified sound pressure levels are approximate equivalent diffuse-field levels. The tones were generated digitally and presented through a soundcard with 24-bit resolution at a sampling rate of 48 kHz. The visual stimuli were presented via a Dell 1707FPc 17&#x0201d; LCD monitor with a vertical refresh rate of 76 Hz placed two feet from participants&#x02019; eyes. The monitor&#x02019;s luminance gamma curves were measured using a Photoresearch PR-655 and corrected in software to ensure correct display of stimulus intensity.</p><p>Participants&#x02019; thresholds were estimated using a standard two-alternative forced-choice procedure with a two-down one-up adaptive tracking rule for all three tasks [<xref rid="pone.0168858.ref052" ref-type="bibr">52</xref>]. For the auditory thresholds, the stimuli were always AM complex tones but either the AM or the F0 was varied depending on the task. To obtain an AM rate discrimination threshold, the F0 remained at 137 Hz but the AM rate was varied adaptively. For the F0 threshold, the AM rate remained at 13 Hz while the F0 was varied adaptively. An important point to note is that with this stimulus design, both auditory groups are exposed to the AM and the F0 of the tone but trained to discriminate only one of the two attributes. Each trial began with a 400-ms tone followed by a 200-ms gap, and then a second 400-ms tone. The background noise was gated on 500 ms before the first interval and off 200 ms after the second interval. Participants were asked to indicate via the computer keyboard which of the two tones had the higher pitch (F0) or AM modulation rate, and immediate feedback was provided after each trial.</p><p>For the visual orientation discrimination task the adaptive threshold tracked the contrast-to-noise ratio (CNR) required to discriminate the orientation of the Gabor pattern. On each trial, the Gabor pattern was presented for 200 ms followed by a 100-ms gap, and then for another 200 ms. One of the patterns was oriented at 45&#x000b0; and the other at 135&#x000b0;, randomly determined on each trial. Subjects had to indicate via button press if the second grating was rotated clockwise or counterclockwise in orientation relative to the first one.</p><p>Pre-test behavioral thresholds were obtained prior to the start of the first training session. Post-test and maintenance behavioral thresholds were obtained during the same session as their respective EEG measurements. The same adaptive procedure was implemented across the three tasks. For the auditory thresholds, the starting value of &#x00394;AM and &#x00394;F0 was 20%. Initially the value increased or decreased by a factor of 3. The step size was decreased to a factor of 1.41 after the first two reversals and to a factor of 1.2 after the first four reversals. For the orientation discrimination threshold, the starting value of &#x00394;CNR was 50%. Initially the value increased or decreased by a factor of 3. The step size was decreased to a factor of 2 after the first two reversals and to a factor of 1 after the first four reversals. For all threshold measures, six reversals occurred at the smallest step size, and threshold was calculated as the geometric mean of the &#x00394;AM, &#x00394;F0, or &#x00394;CNR rate value at those last six reversal points. For pre-test, post-test, and maintenance testing, each participant repeated the measures four times, and the geometric mean of the four repetitions was defined as the individual&#x02019;s threshold.</p></sec><sec id="sec008"><title>Behavioral training procedure</title><p>During each training session, participants completed 15 adaptive threshold tracks, which equates to approximately 900 trials of their designated training task. After training began, the participants were no longer exposed to the other two tasks. The adaptive tracks used for training were the same as described above in the test procedure.</p></sec><sec id="sec009"><title>Auditory EEG analysis</title><p>EEG data were analyzed using frequency-domain principal component analysis (cPCA), as described in Bharadwaj and Shinn-Cunningham [<xref rid="pone.0168858.ref053" ref-type="bibr">53</xref>]. This multi-channel analysis technique allows the reduction of data acquisition time and provides a significant SNR improvement to traditional single-channel steady-state response analysis methods. The cPCA combines multichannel recordings using complex-valued weights that consider channel-specific magnitudes and phases in each frequency bin (see [<xref rid="pone.0168858.ref053" ref-type="bibr">53</xref>] for further details). The cPCA is also more suited for the analysis of steady-state responses in comparison to time domain analyses that combine multichannel recordings, such as principal component analysis or averaging across electrodes, because these methods assume that the signal is the same phase across sensors.</p><p>The data were first filtered into high (70&#x02013;1000 Hz) and low (5&#x02013;20 Hz) frequency ranges, reflecting the putative sub-cortical and cortical responses, respectively. For each filtered dataset, individual epochs were extracted beginning 50 ms before stimulus onset and extending 200 ms beyond the stimulus offset. Epochs exceeding 100 &#x003bc;V peak-to-peak were rejected. Visual inspection of channels with a large proportion of rejected epochs resulted in exclusion of 1&#x02013;5 channels in about 1/3 of the recordings. One subject in the AM group had an unusably noisy EEG dataset from their maintenance session (i.e., a large proportion of epochs exceeding 100 &#x003bc;V peak-to-peak) and their maintenance data was excluded. The multi-taper complex PCA computation was completed using a single taper in both frequency ranges. Resulting phase locking values (PLV) reflect the consistency of the sustained response phase over all epochs and across all included electrodes. PLV magnitude was extracted at the experimental frequencies of the 13 Hz AM rate and the 137 Hz harmonic complex F0 in the cortical and subcortical filtered regions, respectively.</p></sec><sec id="sec010"><title>Visual EEG analysis</title><p>Raw SSVEP data were band-pass filtered 1&#x02013;59 Hz in EEGLAB [<xref rid="pone.0168858.ref054" ref-type="bibr">54</xref>] using a Hamming windowed sinc FIR filter, and 60-s epochs were extracted beginning at each event trigger. Epochs were transformed into the frequency domain, and signal-to-noise ratios (SNRs) were computed at expected SSVEP peaks (Gabor and noise flicker rates) compared to the average noise floor .05&#x02013;0.2 Hz above and below those peaks. Occipital, parieto-occipital, and parietal electrodes (CP1, CP2, CP5, CP6, P8, P7, Pz, P3, P4, PO3, PO4, O1, Oz, and O2) were considered, and SNRs were averaged for electrodes within this set that were greater than an SNR threshold of 1.5. Five subjects had no electrodes with peaks reaching the SNR threshold in one of the three sessions (Pre-, Post- or Maintenance). For those sessions, an average of the 3 electrodes with the best SNR was used. One subject in the F0 group and one subject in the control group had unusable EEG data due to recording error and were excluded. One subject in the AM group had noisy data (i.e., a large proportion of data did not meet SNR cutoffs) only from their maintenance session so that session was excluded.</p></sec></sec><sec sec-type="results" id="sec011"><title>Results</title><sec id="sec012"><title>Perceptual learning on trained and untrained tasks</title><p>We first assessed whether training improved behavioral discrimination thresholds. The participants trained on each task (<xref ref-type="fig" rid="pone.0168858.g002">Fig 2</xref>, filled symbols) had lower thresholds at post-test than pre-test suggesting that the training led to perceptual learning. However, improved thresholds were also seen in participants not trained on the task, including participants in the no-training CON group (<xref ref-type="fig" rid="pone.0168858.g002">Fig 2</xref>, open symbols). The thresholds were log-transformed prior to statistical analysis to maintain roughly equal variance across conditions. A Session (Pre vs. Post) by Group mixed-model ANOVA conducted for each task confirmed threshold improvements with a significant main effect of session for the AM task (<italic>F</italic><sub>1,36</sub> = 132, <italic>p &#x0003c;</italic> .<italic>001</italic>), F0 task (<italic>F</italic><sub>1,36</sub> = 31.7, <italic>p &#x0003c;</italic> .<italic>001</italic>), and the VIS task (<italic>F</italic><sub>1,36</sub> = 15.9, <italic>p &#x0003c;</italic> .<italic>0001</italic>). For both the F0 and VIS task, no significant effect of Group (F0: <italic>F</italic><sub>3,36</sub> = .793, <italic>p =</italic> .<italic>506</italic>, VIS: <italic>F</italic><sub>3,36</sub> = 1.762, <italic>p =</italic> .<italic>172</italic>) or the Session by Group interaction (F0: <italic>F</italic><sub>3,36</sub> = 2.255, <italic>p =</italic> .<italic>099</italic>, VIS: <italic>F</italic><sub>3,36</sub> = 1.502, <italic>p =</italic> .<italic>230</italic>) was observed, indicating that all groups demonstrated comparable threshold improvements.</p><fig id="pone.0168858.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0168858.g002</object-id><label>Fig 2</label><caption><title>Pre-test, post-test, maintenance, and training session thresholds for the discrimination of AM rate (left), F0 (middle) and orientation (right) for the four participant groups.</title><p>Participants who trained on each task are shown with filled symbols. Error bars represent &#x000b1; 1 standard error of the mean.</p></caption><graphic xlink:href="pone.0168858.g002"/></fig><p>For the AM task, there was a significant Session by Group interaction (<italic>F</italic><sub>3,36</sub> = 7.17, <italic>p =</italic> .<italic>001</italic>). Further analysis using an ANOVA with the difference between pre- and post-training threshold (<xref ref-type="fig" rid="pone.0168858.g003">Fig 3A</xref>) as the dependent variable also revealed a significant main effect of Group (<italic>F</italic><sub>3,36</sub> = 7.17, <italic>p =</italic> .<italic>001</italic>). Posthoc pairwise comparisons showed that the two auditory groups each had larger threshold improvements than the CON group (AM: <italic>p &#x0003c;</italic> .<italic>001</italic>; F0: <italic>p =</italic> .<italic>004</italic>), but there was no difference between the VIS and CON groups (<italic>p =</italic> .<italic>183</italic>). There was a significant difference between the VIS and AM group (<italic>p =</italic> .<italic>033</italic>) but no other difference between the three trained groups (<italic>p&#x0003e;</italic>.<italic>584</italic> in all cases).</p><fig id="pone.0168858.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0168858.g003</object-id><label>Fig 3</label><caption><title>Changes in the behavioral thresholds and EEG responses from pre-test to post-test.</title><p>(A) Pre&#x02014;Post difference of log transformed behavioral thresholds as a function of task and training group. (B) Pre&#x02014;Post difference in the PLV of subcortical EFRs as a function of training group. (C) Pre&#x02014;Post difference in the PLV of cortical ASSRs as a function of training group. (D) Pre&#x02014;Post difference in the SSVEP to the signal and noise as a function of training group.</p></caption><graphic xlink:href="pone.0168858.g003"/></fig><p>To account for the potential effect of initial threshold variability seen in participants both within and between groups, performance on the F0 and VIS task was also converted into Pre&#x02014;Post threshold difference scores (<xref ref-type="fig" rid="pone.0168858.g003">Fig 3A</xref>). However, an ANOVA with the Pre&#x02014;Post threshold difference did not show a significant effect of group for either task (F0: <italic>F</italic><sub>3,36</sub> = 2.255, <italic>p =</italic> .<italic>099</italic>; VIS: <italic>F</italic><sub>3,36</sub> = 1.502, <italic>p =</italic> .<italic>230)</italic>. Surprisingly, therefore, perceptual learning was observed across all training groups with relatively little evidence of task- or even modality-specific differences.</p></sec><sec id="sec013"><title>Neurophysiological responses</title><p>To assess subcortical physiological changes in response to the training, pre- and post-test EFRs were compared (<xref ref-type="fig" rid="pone.0168858.g004">Fig 4B</xref>). A Session by Group mixed-model ANOVA on the EFR PLVs showed no significant main effect of Session (<italic>F</italic><sub>1,36</sub> = .637, <italic>p =</italic> .<italic>430</italic>), Group (<italic>F</italic><sub>3,36</sub> = .402, <italic>p =</italic> .<italic>752</italic>), or the Group by Session interaction (<italic>F</italic><sub>3,36</sub> = 1.591, <italic>p =</italic> .<italic>209</italic>). A second analysis was conducted to investigate the effect of group on Pre&#x02014;Post EFR PLV difference (<xref ref-type="fig" rid="pone.0168858.g003">Fig 3B</xref>). An ANOVA also revealed no significant effect of group on the Pre&#x02014;Post PLVs (<italic>F</italic><sub>3,36</sub> = 1.591, <italic>p =</italic> .<italic>209</italic>), indicating that no significant changes in the EFRs were observed after the training.</p><fig id="pone.0168858.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0168858.g004</object-id><label>Fig 4</label><caption><title>Auditory EEG results showing (A) subcortical EFR phase locking by frequency for a single, representative subject (pre-test), (B) average phase locking values at 137 Hz by group and test session, (C) cortical ASSR phase locking by frequency for the same subject as panel A, and (D) average phase locking values at 13 Hz by training group and test session.</title><p>Error bars are &#x000b1; 1 standard error of the mean.</p></caption><graphic xlink:href="pone.0168858.g004"/></fig><p>Changes in cortical responses to auditory and visual stimuli after training were assessed by comparing ASSRs (<xref ref-type="fig" rid="pone.0168858.g004">Fig 4D</xref>), SSVEP-Signal (<xref ref-type="fig" rid="pone.0168858.g005">Fig 5B</xref>, left), and SSVEP-Noise (<xref ref-type="fig" rid="pone.0168858.g005">Fig 5B</xref>, right) across pre- and post-test sessions. For the ASSRs, all three training groups showed an increase in PLV at post-test, in contrast to the CON group which showed a decrease. This pattern is captured by a significant Session by Group interaction (<italic>F</italic><sub>3,36</sub> = 3.23, <italic>p =</italic> .<italic>034</italic>) on a Session by Group mixed-model ANOVA. Group differences were confirmed by a significant main effect of Group (<italic>F</italic><sub>3,36</sub> = 3.23, <italic>p =</italic> .<italic>034</italic>) in an ANOVA with the ASSR Pre&#x02014;Post Difference as the dependent variable (<xref ref-type="fig" rid="pone.0168858.g003">Fig 3C</xref>). Posthoc pairwise comparisons showed a significant difference between auditory groups and the CON group (AM: <italic>p =</italic> .<italic>022</italic>; F0: <italic>p =</italic> .<italic>006</italic>) but no significant difference between the VIS and CON groups (<italic>p =</italic> .<italic>061</italic>) or the VIS and auditory groups (AM: <italic>p =</italic> .<italic>649</italic>; F0: <italic>p =</italic> .<italic>339</italic>). This indicates that only the two auditory groups showed enhanced cortical ASSRs post-training, consistent with the pattern of AM behavioral threshold improvement.</p><fig id="pone.0168858.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0168858.g005</object-id><label>Fig 5</label><caption><title>Visual EEG results showing (A) the SSVEP frequency magnitude spectrum for the subject shown in <xref ref-type="fig" rid="pone.0168858.g003">Fig 3A and 3C</xref>, and (B) group averages by test session for the 13 Hz signal (left) and 17 Hz noise flicker rates.</title><p>Error bars are &#x000b1; 1 standard error of the mean.</p></caption><graphic xlink:href="pone.0168858.g005"/></fig><p>The SSVEPs show a similar trend as the ASSRs with enhanced responses post training for the VIS group and decreased responses for the auditory and CON groups. SSVEPs to the stimuli and the noise were collapsed into a single Session (Pre vs. Post) by Group and Stimuli (Stimuli vs. Noise) mixed-model ANOVA, which revealed a significant Session by Group interaction (<italic>F</italic><sub>3,66</sub> = 5.50, <italic>p =</italic> .<italic>002</italic>). Further analysis with a SSVEP Pre&#x02014;Post difference (<xref ref-type="fig" rid="pone.0168858.g003">Fig 3D</xref>) by Group and Stimuli ANOVA revealed group differences with a significant main effect of Group (<italic>F</italic><sub>3,66</sub> = 5.50, <italic>p =</italic> .<italic>002</italic>). Posthoc pairwise comparisons showed a significant difference between the VIS group and all other groups (AM: <italic>p =</italic> .<italic>022</italic>; F0: <italic>p &#x0003c;</italic> .<italic>001</italic>; CON: <italic>p =</italic> .<italic>028</italic>) with no other significant differences between the other groups (<italic>p&#x0003e;</italic>.<italic>09</italic> in all cases), suggesting that the SSVEP was enhanced only in the VIS group post training.</p><p>The correlations between behavioral threshold and EEG response difference scores were computed to assess the relationship between changes in behavioral performance and changes in the neurophysiological measures. The AM Pre&#x02014;Post threshold difference was not significantly correlated with the cortical ASSR Pre&#x02014;Post difference (r = -.245, <italic>p =</italic> .<italic>128</italic>). The VIS threshold difference was also not significantly correlated to the SSVEP-Signal (r = .128, <italic>p =</italic> .<italic>449</italic>) or the SSVEP-Noise Pre-Post difference (r = -.032, <italic>p =</italic> .<italic>850</italic>). Furthermore, there were no correlations between the behavioral pre-test thresholds and the EEG pre-test responses (AM Pre &#x00026; ASSR Pre: r = -.257, <italic>p =</italic> .<italic>109</italic>; F0 Pre &#x00026; EFR Pre: r = -.043, <italic>p =</italic> .<italic>793</italic>; VS Pre &#x00026; SSVEP-Signal: r = .252, <italic>p =</italic> .<italic>127</italic>; VS Pre &#x00026; SSVEP-Noise: r = .322, <italic>p =</italic> .<italic>05</italic>). Although enhancement of the cortical ASSR was seen only in the auditory trained groups and enhancement of the SSVEP was seen only in the visual trained group, there was no overall correlation between the amount of behavioral threshold improvement and change in neural response at the level of individual participants.</p></sec><sec id="sec014"><title>Maintenance</title><p>To assess the maintenance of the enhanced cortical responses 30 days after the training, a Session (Post vs. Maintenance) by Group mixed-model ANOVA was conducted for the cortical ASSRs and the SSVEPs. No significant effect of Session (<italic>F</italic><sub>1,26</sub> = .108, <italic>p =</italic> .<italic>745</italic>), Group (<italic>F</italic><sub>2,26</sub> = .265, <italic>p =</italic> .<italic>770</italic>), or Session by Group interaction (<italic>F</italic><sub>2,26</sub> = 2.133, <italic>p =</italic> .<italic>139</italic>) was observed for the cortical ASSRs. Likewise, an SSVEP Session (Post vs. Maintenance) by Group and Stimuli mixed-model ANOVA revealed no significant main effect of Session (<italic>F</italic><sub>1,50</sub> = .086, <italic>p =</italic> .<italic>770</italic>), Group (<italic>F</italic><sub>2,50</sub> = .769, <italic>p =</italic> .<italic>469</italic>), or Session by Group interaction (<italic>F</italic><sub>2,50</sub> = .872, <italic>p =</italic> .<italic>424</italic>). Thus, no change was observed in either response one month after the training. However, another important consideration is how maintenance thresholds compare to pre-test performance. A Pre vs. Maintenance by Group mixed-model ANOVA revealed that the Session by Group interaction was no longer significant for the ASSR (<italic>p =</italic> .<italic>695</italic>) but remained significant for the SSVEP (<italic>p =</italic> .<italic>002</italic>). This outcome suggests that group differences were retained after 30 days for the SSVEP but not the ASSR.</p><p>To assess the maintenance of behavioral learning 30 days after the training, a Session (Post vs. Maintenance) by Group mixed-model ANOVA was conducted for each task. No significant effect of Session (AM: <italic>F</italic><sub>1,27</sub> = .239, <italic>p =</italic> .<italic>629</italic>; F0: <italic>F</italic><sub>1,27</sub> = 1.60, <italic>p =</italic> .<italic>216</italic>), Group (AM: <italic>F</italic><sub>2,27</sub> = 2.48, <italic>p =</italic> .<italic>103</italic>; F0: <italic>F</italic><sub>2,27</sub> = .399, <italic>p =</italic> .<italic>675</italic>), or a Session by Group interaction (AM: <italic>F</italic><sub>2,27</sub> = 2.85, <italic>p =</italic> .<italic>076</italic>; F0: <italic>F</italic><sub>2,27</sub> = 3.04, <italic>p =</italic> .<italic>065</italic>) was observed for the auditory trained groups. For the VIS task, there was no significant effect of Session (VIS <italic>F</italic><sub>1,27</sub> = 1.28, <italic>p =</italic> .<italic>267</italic>) or the Session by Group interaction (VIS <italic>F</italic><sub>2,27</sub> = .281, <italic>p =</italic> .<italic>757)</italic> but a significant effect of group <italic>(F</italic><sub>2,27</sub> = 4.60, <italic>p =</italic> .<italic>019</italic>), presumably reflecting the fact that the CON group appeared to have lower thresholds in both sessions on average.</p></sec></sec><sec sec-type="conclusions" id="sec015"><title>Discussion</title><p>The data presented here show enhancement of both auditory and visual cortical steady-state responses following 3 hours of training spread over 6 days. Perceptual training led to behavioral improvements in the discrimination of the F0 and AM rates of complex tones as well as the visual orientation of Gabor patterns for all training groups. Although the behavioral threshold improvements showed minimal task specificity, the neurophysiological measures more closely matched the training: auditory-trained groups demonstrated an enhancement of ASSR PLV and the visual group demonstrated an enhancement of SSVEP amplitude. Despite the fact that the modality of training and neurophysiological enhancement aligned, there was no correlation between the change in behavioral threshold and the change in physiological response. Furthermore, the VIS group showed enhancement of SSVEP magnitude to both the stimuli and the noise although they were trained only on stimuli discrimination. Similarly, enhancement of the ASSR PLV was seen in the F0 group although they were exposed to AM but not trained on AM discrimination. Finally, even though all participant groups showed improvements in the discrimination of F0, no evidence of training-induced subcortical plasticity was observed in the auditory EFR.</p><p>The results presented here demonstrate that scalp-recorded auditory and visual steady-state responses are sensitive to cortical plasticity even after very short-term perceptual learning. We have extended previous time-domain ERP results by demonstrating plasticity of steady-state responses using an analysis of PLV. Although our techniques are novel, our findings are consistent with the outcomes of other studies using different designs and measurement methods. Auditory training studies have found cortical enhancements after speech-sound training in both N1-P2 responses [<xref rid="pone.0168858.ref030" ref-type="bibr">30</xref>] and mismatched negativity (MMN) responses [<xref rid="pone.0168858.ref055" ref-type="bibr">55</xref>]. Enhancement of C1 amplitude has been documented after visual perceptual training [<xref rid="pone.0168858.ref056" ref-type="bibr">56</xref>], and the SSVEP has been shown to be sensitive to aversive conditioning, arguably closely related to perceptual training [<xref rid="pone.0168858.ref044" ref-type="bibr">44</xref>].</p><p>Our results are also consistent with a large body of animal physiological studies showing cortical plasticity following perceptual training. Recanzone et al. [<xref rid="pone.0168858.ref057" ref-type="bibr">57</xref>] trained monkeys on frequency discrimination and showed enhanced representation of trained frequency in A1. This finding has been replicated in other species [<xref rid="pone.0168858.ref028" ref-type="bibr">28</xref>,<xref rid="pone.0168858.ref029" ref-type="bibr">29</xref>], supporting the idea that the auditory cortex is quite malleable to experience and highlighting the importance of determining effective ways of studying human neural plasticity.</p><p>Inconsistent with our findings are previous studies that have identified enhancement of the EFR in response to short- or long-term training. Most notable is the study by Carcagno and Plack [<xref rid="pone.0168858.ref035" ref-type="bibr">35</xref>], who found enhanced EFR responses to both dynamic and steady pitch tokens after short-term training. One important difference between the studies may be the amount of training received by subjects. We trained subjects for a total of about 3 hours over 6 days while Cacagno and Plack&#x02019;s subjects underwent a substantially greater amount of training of 10 hours over 10 days.</p><p>One surprising aspect of the visual results is the enhancement of SSVEP amplitude to both the signal and the noise. This outcome may suggest that repeated exposure to the background noise without discrimination training was sufficient to also enhance neural coding of the noise. A similar result was observed in the auditory domain with the enhancement of the ASSR PLV in the F0 group who was exposed to AM but not trained in AM discrimination. This pattern of results further suggests that stimulus exposure and procedural learning (e.g., how to direct auditory attention in the laboratory) without specific discrimination training can result in plasticity. Additional investigations are required to determine the robustness of these findings. In a study where participants were exposed to 40-Hz AM but trained only on pitch discrimination, Bosnyak et al. [<xref rid="pone.0168858.ref058" ref-type="bibr">58</xref>] report the opposing finding that training altered N1c and P2 evoked potentials but had no effect on the 40 Hz ASSR. One potential explanation for these inconsistent findings is that sustained cortical potentials in response to slower modulation rates may be more plastic [<xref rid="pone.0168858.ref048" ref-type="bibr">48</xref>].</p><p>Directed attention has been shown to modulate the ASSR amplitude both for the lower speech-related AM rates we used [<xref rid="pone.0168858.ref048" ref-type="bibr">48</xref>] and for more rapid rates [<xref rid="pone.0168858.ref059" ref-type="bibr">59</xref>,<xref rid="pone.0168858.ref060" ref-type="bibr">60</xref>]. It may be that the mechanisms of short-term learning observed here are more closely related to the mechanisms of directed sensory attention than to the longer-term mechanisms underlying the enhancement of musicians&#x02019; and tonal language speakers&#x02019; EFRs [<xref rid="pone.0168858.ref061" ref-type="bibr">61</xref>]. Such long-term training is complicated by personal, social, and emotional factors that are hard to replicate in the laboratory but may heighten the importance of certain sounds and the responses they elicit. Polley et al. [<xref rid="pone.0168858.ref062" ref-type="bibr">62</xref>] provide evidence suggesting that top-down, task-dependent factors, arising from multiple cortical areas play a role in the nature of observed physiological changes. While past studies [<xref rid="pone.0168858.ref048" ref-type="bibr">48</xref>] have reported the effect of attention on the amplitude of the ASSR, there is much less evidence for the effect of attention on measures of the ASSR&#x02019;s PLV. If the ASSR change observed here is indeed related to the direction of attention, our findings suggest that PLV holds potential as a tool for studying the effects of attention on neurophysiological responses.</p><p>Although the results of human EEG studies show enhancement of neurophysiological responses to trained stimuli, we cannot determine the exact neural mechanisms underlying the modulation of measured responses. It may be that training increases the synchrony (phase locking) of neural fibers to the AM of the visual or auditory stimulus or that an increased number of fibers are recruited to the processing of a trained stimulus. Combining behavioral and human results like these with modeling of the auditory and visual pathways and ongoing animal work may help to unravel the question of what neuronal response properties are causally related to perceptual improvements. An important limitation to note is that the actual sources of the EEG signals were not localized in this study. There is a general consensus that the neural sources of the fast-rate EFR are primarily subcortical and the sources of the slow-rate ASSR are primarily cortical [<xref rid="pone.0168858.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0168858.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0168858.ref053" ref-type="bibr">53</xref>]. However, a recent study that utilized magnetoencephalography for source localization, showed a right hemisphere cortical contribution in addition to the subcortical sources for the EFR [<xref rid="pone.0168858.ref063" ref-type="bibr">63</xref>]. Our use of cortical versus subcortical with reference to the primary generators of the ASSR and EFR, though consistent with past literature, is certainly an oversimplified consideration of their neural sources. Furthermore, it is also possible that a common neural rate-discrimination mechanism could account for both high-rate (F0) and low-rate (AM) discrimination, regardless of where the responses are generated. This could serve as an alternate explanation for the increase in ASSR PLV observed in the F0 group who was trained on high-rate discrimination but showed low-rate physiological enhancement. Additional investigation into the generalization of different high and low training rates is required to confirm this possibility.</p><p>Although the main question addressed in this study was whether there was evidence of plasticity in the steady-state EEG responses, the perceptual training paradigm produced an interesting and complex pattern of behavioral results. We found threshold improvements on all three tasks at post-test for all groups including the control group. Improvement in the no-training control group is actually a common phenomenon (for example, see [<xref rid="pone.0168858.ref064" ref-type="bibr">64</xref>]). However, this finding also speaks to the effect of stimulus exposure on behavioral measures of learning. Participants in our study were exposed to the stimuli significantly more than is typical in a behavior-only training paradigm with the one thousand stimulus repetitions presented during the EEG recording. Procedural learning, or the impact of subjects acclimating to the environment and nature of psychophysical tasks, is also likely to have impacted our behavioral results, as all of our subjects were entirely na&#x000ef;ve to psychophysical experiments before participating in this study. Although these effects have been demonstrated before, our data show a potentially large effect of these factors on the differences between pre-test and post-test thresholds.</p><p>Our behavioral findings also provide evidence for cross-modal transfer of learning. Participants trained on the auditory tasks showed improvement on the visual threshold while those trained on the visual task showed improvement on the auditory thresholds. This type of cross-modal effect was not seen in the EEG data (i.e., subjects learned behaviorally across modalities but did not exhibit any changes in cross-modal physiological responses). Neurophysiological enhancement matched the modality of training. One way to interpret this pattern of results is that the cross-modal transfer of behavioral learning may have occurred at a later stage, such as decision formation [<xref rid="pone.0168858.ref065" ref-type="bibr">65</xref>,<xref rid="pone.0168858.ref066" ref-type="bibr">66</xref>], and therefore did not affect stimulus coding as measured by EEG. It is important to note, however, that one complication in the interpretation of our behavioral results is the large difference in mean thresholds between the groups at pre-test. Additional analysis of the Pre&#x02014;Post threshold difference scores to account for initial baseline variability, nevertheless, did not change the results.</p><p>In conclusion, this study provides evidence that short-term, learning-related physiological changes may be measured in the adult auditory and visual cortex using EEG. Simultaneous subcortical and cortical sustained responses provide a unique insight into how different levels of the auditory pathway respond to amplitude modulation and how those responses might be sensitive to perceptual learning. Our findings suggest that cortical responses may be more reflective of training-induced plasticity than subcortical responses and that modality-based specificity is more apparent than task-based specificity. In contrast, our behavioral results revealed apparent cross-task and cross-modality transfer of learning.</p></sec></body><back><ack><p>We thank Beverly Wright and Christopher Plack for helpful discussions relating to this project.</p></ack><ref-list><title>References</title><ref id="pone.0168858.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Woldorff</surname><given-names>MG</given-names></name>, <name><surname>Gallen</surname><given-names>CC</given-names></name>, <name><surname>Hampson</surname><given-names>SA</given-names></name>, <name><surname>Hillyard</surname><given-names>SA</given-names></name>, <name><surname>Pantev</surname><given-names>C</given-names></name>, <name><surname>Sobel</surname><given-names>D</given-names></name>, <etal>et al</etal>
<article-title>Modulation of early sensory processing in human auditory cortex during auditory selective attention</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1993</year>;<volume>90</volume>: <fpage>8722</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="pmid">8378354</pub-id></mixed-citation></ref><ref id="pone.0168858.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Brandewie</surname><given-names>E</given-names></name>, <name><surname>Zahorik</surname><given-names>P</given-names></name>. <article-title>Prior listening in rooms improves speech intelligibility</article-title>. <source>J Acoust Soc Am</source>. <year>2010</year>;<volume>128</volume>: <fpage>291</fpage>&#x02013;<lpage>299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.3436565">10.1121/1.3436565</ext-link></comment>
<pub-id pub-id-type="pmid">20649224</pub-id></mixed-citation></ref><ref id="pone.0168858.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Brandewie</surname><given-names>E</given-names></name>, <name><surname>Zahorik</surname><given-names>P</given-names></name>. <article-title>Time course of a perceptual enhancement effect for noise-masked speech in reverberant environments</article-title>. <source>J Acoust Soc Am</source>. <year>2013</year>;<volume>134</volume>: <fpage>EL265</fpage>&#x02014;<lpage>EL270</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4816263">10.1121/1.4816263</ext-link></comment>
<pub-id pub-id-type="pmid">23927235</pub-id></mixed-citation></ref><ref id="pone.0168858.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Holt</surname><given-names>LL</given-names></name>, <name><surname>Lotto</surname><given-names>AJ</given-names></name>. <article-title>Behavioral examinations of the level of auditory processing of speech context effects</article-title>. <source>Hear Res</source>. <year>2002</year>;<volume>167</volume>: <fpage>156</fpage>&#x02013;<lpage>169</lpage>. <pub-id pub-id-type="pmid">12117538</pub-id></mixed-citation></ref><ref id="pone.0168858.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Lotto</surname><given-names>AJ</given-names></name>, <name><surname>Kluender</surname><given-names>KR</given-names></name>, <name><surname>Holt</surname><given-names>LL</given-names></name>. <article-title>Perceptual compensation for coarticulation by Japanese quail (Coturnix coturnix japonica)</article-title>. <source>J Acoust Soc Am</source>. <year>1997</year>;<volume>102</volume>: <fpage>1134</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="pmid">9265760</pub-id></mixed-citation></ref><ref id="pone.0168858.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Deutsch</surname><given-names>D</given-names></name>, <name><surname>Henthorn</surname><given-names>T</given-names></name>, <name><surname>Marvin</surname><given-names>E</given-names></name>, <name><surname>Xu</surname><given-names>H</given-names></name>. <article-title>Absolute pitch among American and Chinese conservatory students: prevalence differences, and evidence for a speech-related critical period</article-title>. <source>J Acoust Soc Am</source>. <year>2006</year>;<volume>119</volume>: <fpage>719</fpage>&#x02013;<lpage>722</lpage>. <pub-id pub-id-type="pmid">16521731</pub-id></mixed-citation></ref><ref id="pone.0168858.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>Gandour</surname><given-names>JT</given-names></name>. <article-title>The role of the auditory brainstem in processing linguistically-relevant pitch patterns</article-title>. <source>Brain Lang</source>. <year>2009</year>;<volume>110</volume>: <fpage>135</fpage>&#x02013;<lpage>48</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.bandl.2009.03.005">10.1016/j.bandl.2009.03.005</ext-link></comment>
<pub-id pub-id-type="pmid">19366639</pub-id></mixed-citation></ref><ref id="pone.0168858.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Gaser</surname><given-names>C</given-names></name>, <name><surname>Schlaug</surname><given-names>G</given-names></name>. <article-title>Brain structures differ between musicians and non-musicians</article-title>. <source>J Neurosci</source>. <year>2003</year>;<volume>23</volume>: <fpage>9240</fpage>&#x02013;<lpage>9245</lpage>. <pub-id pub-id-type="pmid">14534258</pub-id></mixed-citation></ref><ref id="pone.0168858.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Sasaki</surname><given-names>Y</given-names></name>, <name><surname>Nanez</surname><given-names>JE</given-names></name>, <name><surname>Watanabe</surname><given-names>T</given-names></name>. <article-title>Advances in visual perceptual learning and plasticity</article-title>. <source>Nat Rev Neurosci. Nature Publishing Group</source>; <year>2009</year>;<volume>11</volume>: <fpage>53</fpage>&#x02013;<lpage>60</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Schneider</surname><given-names>P</given-names></name>, <name><surname>Scherg</surname><given-names>M</given-names></name>, <name><surname>Dosch</surname><given-names>HG</given-names></name>, <name><surname>Specht</surname><given-names>HJ</given-names></name>, <name><surname>Gutschalk</surname><given-names>A</given-names></name>, <name><surname>Rupp</surname><given-names>A</given-names></name>. <article-title>Morphology of Heschl&#x02019;s gyrus reflects enhanced activation in the auditory cortex of musicians</article-title>. <source>Nat Neurosci</source>. <year>2002</year>;<volume>5</volume>: <fpage>688</fpage>&#x02013;<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn871">10.1038/nn871</ext-link></comment>
<pub-id pub-id-type="pmid">12068300</pub-id></mixed-citation></ref><ref id="pone.0168858.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Bermudez</surname><given-names>P</given-names></name>, <name><surname>Zatorre</surname><given-names>RJ</given-names></name>. <article-title>Differences in gray matter between musicians and nonmusicians</article-title>. <source>Ann N Y Acad Sci</source>. <year>2005</year>;<volume>1060</volume>: <fpage>395</fpage>&#x02013;<lpage>399</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1196/annals.1360.057">10.1196/annals.1360.057</ext-link></comment>
<pub-id pub-id-type="pmid">16597791</pub-id></mixed-citation></ref><ref id="pone.0168858.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Pantev</surname><given-names>C</given-names></name>, <name><surname>Oostenveld</surname><given-names>R</given-names></name>, <name><surname>Engelien</surname><given-names>A</given-names></name>, <name><surname>Ross</surname><given-names>B</given-names></name>, <name><surname>Roberts</surname><given-names>LE</given-names></name>, <name><surname>Hoke</surname><given-names>M</given-names></name>. <article-title>Increased auditory cortical representation in musicians</article-title>. <source>Nature</source>. <year>1998</year>;<volume>392</volume>: <fpage>811</fpage>&#x02013;<lpage>814</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/33918">10.1038/33918</ext-link></comment>
<pub-id pub-id-type="pmid">9572139</pub-id></mixed-citation></ref><ref id="pone.0168858.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Shahin</surname><given-names>A</given-names></name>, <name><surname>Bosnyak</surname><given-names>DJ</given-names></name>, <name><surname>Trainor</surname><given-names>LJ</given-names></name>, <name><surname>Roberts</surname><given-names>LE</given-names></name>. <article-title>Enhancement of Neuroplastic P2 and N1c Auditory Evoked Potentials in Musicians</article-title>. <source>J Neurosci</source>. <year>2003</year>;<volume>23</volume>: <fpage>5545</fpage>&#x02013;<lpage>5552</lpage>. <pub-id pub-id-type="pmid">12843255</pub-id></mixed-citation></ref><ref id="pone.0168858.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Herdman</surname><given-names>AT</given-names></name>, <name><surname>Lins</surname><given-names>O</given-names></name>, <name><surname>Roon</surname><given-names>PV</given-names></name>, <name><surname>Stapells</surname><given-names>DR</given-names></name>, <name><surname>Scherg</surname><given-names>M</given-names></name>, <name><surname>Picton</surname><given-names>TW</given-names></name>. <article-title>Intracerebral Sources of Human Auditory Steady-State Responses</article-title>. <source>Brain Topogr</source>. <year>2002</year>;<volume>15</volume>: <fpage>69</fpage>&#x02013;<lpage>86</lpage>. <pub-id pub-id-type="pmid">12537303</pub-id></mixed-citation></ref><ref id="pone.0168858.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>Bidelman</surname><given-names>GM</given-names></name>, <name><surname>Smalt</surname><given-names>CJ</given-names></name>, <name><surname>Ananthakrishnan</surname><given-names>S</given-names></name>, <name><surname>Gandour</surname><given-names>JT</given-names></name>. <article-title>Relationship between brainstem, cortical and behavioral measures relevant to pitch salience in humans</article-title>. <source>Neuropsychologia. Elsevier</source>; <year>2012</year>;<volume>50</volume>: <fpage>2849</fpage>&#x02013;<lpage>59</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Musacchia</surname><given-names>G</given-names></name>, <name><surname>Sams</surname><given-names>M</given-names></name>, <name><surname>Skoe</surname><given-names>E</given-names></name>, <name><surname>Kraus</surname><given-names>N</given-names></name>. <article-title>Musicians have enhanced subcortical auditory and audiovisual processing of speech and music</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2007</year>;<volume>104</volume>: <fpage>15894</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0701498104">10.1073/pnas.0701498104</ext-link></comment>
<pub-id pub-id-type="pmid">17898180</pub-id></mixed-citation></ref><ref id="pone.0168858.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Spiegel</surname><given-names>MF</given-names></name>, <name><surname>Watson</surname><given-names>CS</given-names></name>. <article-title>Performance on frequency-discrimination tasks by musicians and nonmusicians</article-title>. <source>J Acoust Soc Am</source>. <year>1984</year>;<volume>76</volume>: <fpage>1690</fpage>&#x02013;<lpage>1695</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Kishon-Rabin</surname><given-names>L</given-names></name>, <name><surname>Amir</surname><given-names>O</given-names></name>, <name><surname>Vexler</surname><given-names>Y</given-names></name>, <name><surname>Zaltz</surname><given-names>Y</given-names></name>. <article-title>Pitch discrimination: Are professional musicians better than non-musicians?</article-title>
<source>J Basic Clin Physiol Pharmacol</source>. <year>2001</year>;<volume>12</volume>: <fpage>125</fpage>&#x02013;<lpage>144</lpage>. <pub-id pub-id-type="pmid">11605682</pub-id></mixed-citation></ref><ref id="pone.0168858.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Carey</surname><given-names>D</given-names></name>, <name><surname>Rosen</surname><given-names>S</given-names></name>, <name><surname>Krishnan</surname><given-names>S</given-names></name>, <name><surname>Pearce</surname><given-names>MT</given-names></name>, <name><surname>Shepherd</surname><given-names>A</given-names></name>, <name><surname>Aydelott</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>Generality and specificity in the effects of musical expertise on perception and cognition</article-title>. <source>Cognition. Elsevier B.V.</source>; <year>2015</year>;<volume>137</volume>: <fpage>81</fpage>&#x02013;<lpage>105</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Parbery-Clark</surname><given-names>A</given-names></name>, <name><surname>Skoe</surname><given-names>E</given-names></name>, <name><surname>Lam</surname><given-names>C</given-names></name>, <name><surname>Kraus</surname><given-names>N</given-names></name>. <article-title>Musician enhancement for speech-in-noise</article-title>. <source>Ear Hear</source>. <year>2009</year>;<volume>30</volume>: <fpage>653</fpage>&#x02013;<lpage>61</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1097/AUD.0b013e3181b412e9">10.1097/AUD.0b013e3181b412e9</ext-link></comment>
<pub-id pub-id-type="pmid">19734788</pub-id></mixed-citation></ref><ref id="pone.0168858.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Zendel</surname><given-names>BR</given-names></name>, <name><surname>Alain</surname><given-names>C</given-names></name>. <article-title>Musicians experience less age-related decline in central auditory processing</article-title>. <source>Psychol Aging</source>. <year>2012</year>;<volume>27</volume>: <fpage>410</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0024816">10.1037/a0024816</ext-link></comment>
<pub-id pub-id-type="pmid">21910546</pub-id></mixed-citation></ref><ref id="pone.0168858.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Swaminathan</surname><given-names>J</given-names></name>, <name><surname>Mason</surname><given-names>CR</given-names></name>, <name><surname>Streeter</surname><given-names>TM</given-names></name>, <name><surname>Best</surname><given-names>V</given-names></name>, <name><surname>Kidd</surname><given-names>G</given-names></name>, <name><surname>Patel</surname><given-names>AD</given-names></name>. <article-title>Musical training, individual differences and the cocktail party problem</article-title>. <source>Sci Rep. Nature Publishing Group</source>; <year>2015</year>;<volume>5</volume>: <fpage>11628</fpage>.</mixed-citation></ref><ref id="pone.0168858.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Fuller</surname><given-names>CD</given-names></name>, <name><surname>Galvin</surname><given-names>JJ</given-names></name>, <name><surname>Maat</surname><given-names>B</given-names></name>, <name><surname>Free</surname><given-names>RH</given-names></name>, <name><surname>Ba&#x0015f;kent</surname><given-names>D</given-names></name>. <article-title>The musician effect: Does it persist under degraded pitch conditions of cochlear implant simulations?</article-title>
<source>Front Neurosci</source>. <year>2014</year>;<volume>8</volume>: <fpage>1</fpage>&#x02013;<lpage>16</lpage>.<pub-id pub-id-type="pmid">24478622</pub-id></mixed-citation></ref><ref id="pone.0168858.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Ruggles</surname><given-names>DR</given-names></name>, <name><surname>Freyman</surname><given-names>RL</given-names></name>, <name><surname>Oxenham</surname><given-names>AJ</given-names></name>. <article-title>Influence of Musical Training on Understanding Voiced and Whispered Speech in Noise</article-title>. <name><surname>Malmierca</surname><given-names>MS</given-names></name>, editor. <source>PLoS ONE</source>. <year>2014</year>;<volume>9</volume>: <fpage>e86980</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0086980">10.1371/journal.pone.0086980</ext-link></comment>
<pub-id pub-id-type="pmid">24489819</pub-id></mixed-citation></ref><ref id="pone.0168858.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Boebinger</surname><given-names>D</given-names></name>, <name><surname>Evans</surname><given-names>S</given-names></name>, <name><surname>Rosen</surname><given-names>S</given-names></name>, <name><surname>Lima</surname><given-names>CF</given-names></name>, <name><surname>Manly</surname><given-names>T</given-names></name>, <name><surname>Scott</surname><given-names>SK</given-names></name>. <article-title>Musicians and non-musicians are equally adept at perceiving masked speech</article-title>. <source>J Acoust Soc Am</source>. <year>2015</year>;<volume>137</volume>: <fpage>378</fpage>&#x02013;<lpage>387</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4904537">10.1121/1.4904537</ext-link></comment>
<pub-id pub-id-type="pmid">25618067</pub-id></mixed-citation></ref><ref id="pone.0168858.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Ba&#x0015f;kent</surname><given-names>D</given-names></name>, <name><surname>Gaudrain</surname><given-names>E</given-names></name>. <article-title>Musician advantage for speech-on-speech perception</article-title>. <source>J Acoust Soc Am</source>. <year>2016</year>;<volume>139</volume>: <fpage>EL51</fpage>&#x02013;<lpage>EL56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4942628">10.1121/1.4942628</ext-link></comment>
<pub-id pub-id-type="pmid">27036287</pub-id></mixed-citation></ref><ref id="pone.0168858.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Recanzone</surname><given-names>GH</given-names></name>, <name><surname>Schreiner</surname><given-names>CE</given-names></name>, <name><surname>Merzenich</surname><given-names>MM</given-names></name>. <article-title>Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys</article-title>. <source>J Neurosci Off J Soc Neurosci</source>. <year>1993</year>;<volume>13</volume>: <fpage>87</fpage>&#x02013;<lpage>103</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Rutkowski</surname><given-names>RG</given-names></name>, <name><surname>Weinberger</surname><given-names>NM</given-names></name>. <article-title>Encoding of learned importance of sound by magnitude of representational area in primary auditory cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2005</year>;<volume>102</volume>: <fpage>13664</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0506838102">10.1073/pnas.0506838102</ext-link></comment>
<pub-id pub-id-type="pmid">16174754</pub-id></mixed-citation></ref><ref id="pone.0168858.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Polley</surname><given-names>DB</given-names></name>, <name><surname>Steinberg</surname><given-names>EE</given-names></name>, <name><surname>Merzenich</surname><given-names>MM</given-names></name>. <article-title>Perceptual learning directs auditory cortical map reorganization through top-down influences</article-title>. <source>J Neurosci Off J Soc Neurosci</source>. <year>2006</year>;<volume>26</volume>: <fpage>4970</fpage>&#x02013;<lpage>4982</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Tremblay</surname><given-names>K</given-names></name>, <name><surname>Kraus</surname><given-names>N</given-names></name>, <name><surname>McGee</surname><given-names>T</given-names></name>, <name><surname>Ponton</surname><given-names>C</given-names></name>, <name><surname>Otis</surname><given-names>B</given-names></name>. <article-title>Central auditory plasticity: changes in the N1-P2 complex after speech-sound training</article-title>. <source>Ear Hear</source>. <year>2001</year>;<volume>22</volume>: <fpage>79</fpage>&#x02013;<lpage>90</lpage>. <pub-id pub-id-type="pmid">11324846</pub-id></mixed-citation></ref><ref id="pone.0168858.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Atienza</surname><given-names>M</given-names></name>, <name><surname>Cantero</surname><given-names>JL</given-names></name>, <name><surname>Dominguez-Marin</surname><given-names>E</given-names></name>. <article-title>The time course of neural changes underlying auditory perceptual learning</article-title>. <source>Learn Mem</source>. <year>2002</year>;<volume>9</volume>: <fpage>138</fpage>&#x02013;<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/lm.46502">10.1101/lm.46502</ext-link></comment>
<pub-id pub-id-type="pmid">12075002</pub-id></mixed-citation></ref><ref id="pone.0168858.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Lalonde</surname><given-names>K</given-names></name>, <name><surname>Holt</surname><given-names>RF</given-names></name>. <article-title>Audiovisual speech perception development at varying levels of perceptual processing</article-title>. <source>J Acoust Soc Am</source>. <year>2016</year>;<volume>139</volume>: <fpage>1713</fpage>&#x02013;<lpage>1723</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4945590">10.1121/1.4945590</ext-link></comment>
<pub-id pub-id-type="pmid">27106318</pub-id></mixed-citation></ref><ref id="pone.0168858.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Micheyl</surname><given-names>C</given-names></name>, <name><surname>Delhommeau</surname><given-names>K</given-names></name>, <name><surname>Perrot</surname><given-names>X</given-names></name>, <name><surname>Oxenham</surname><given-names>AJ</given-names></name>. <article-title>Influence of musical and psychoacoustical training on pitch discrimination</article-title>. <source>Hear Res</source>. <year>2006</year>;<volume>219</volume>: <fpage>36</fpage>&#x02013;<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.heares.2006.05.004">10.1016/j.heares.2006.05.004</ext-link></comment>
<pub-id pub-id-type="pmid">16839723</pub-id></mixed-citation></ref><ref id="pone.0168858.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name>, <name><surname>Masud</surname><given-names>S</given-names></name>, <name><surname>Mehraei</surname><given-names>G</given-names></name>, <name><surname>Verhulst</surname><given-names>S</given-names></name>, <name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name>. <article-title>Individual Differences Reveal Correlates of Hidden Hearing Deficits</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>: <fpage>2161</fpage>&#x02013;<lpage>2172</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3915-14.2015">10.1523/JNEUROSCI.3915-14.2015</ext-link></comment>
<pub-id pub-id-type="pmid">25653371</pub-id></mixed-citation></ref><ref id="pone.0168858.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Carcagno</surname><given-names>S</given-names></name>, <name><surname>Plack</surname><given-names>CJ</given-names></name>. <article-title>Subcortical plasticity following perceptual learning in a pitch discrimination task</article-title>. <source>J Assoc Res Otolaryngol</source>. <year>2011</year>;<volume>12</volume>: <fpage>89</fpage>&#x02013;<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10162-010-0236-1">10.1007/s10162-010-0236-1</ext-link></comment>
<pub-id pub-id-type="pmid">20878201</pub-id></mixed-citation></ref><ref id="pone.0168858.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Stone</surname><given-names>MA</given-names></name>, <name><surname>llgrabe</surname><given-names>C</given-names></name>, <name><surname>Moore</surname><given-names>BCJ</given-names></name>. <article-title>Notionally steady background noise acts primarily as a modulation masker of speech</article-title>. <source>J Acoust Soc Am</source>. <year>2012</year>;<volume>132</volume>: <fpage>317</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.4725766">10.1121/1.4725766</ext-link></comment>
<pub-id pub-id-type="pmid">22779480</pub-id></mixed-citation></ref><ref id="pone.0168858.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Yost</surname><given-names>WA</given-names></name>, <name><surname>Sheft</surname><given-names>S</given-names></name>, <name><surname>Opie</surname><given-names>J</given-names></name>. <article-title>Interference and Discrimination Amplitude Modulation</article-title>. <source>J Acoust Soc Am</source>. <year>1989</year>;<volume>86</volume>: <fpage>2138</fpage>&#x02013;<lpage>2147</lpage>.<pub-id pub-id-type="pmid">2600304</pub-id></mixed-citation></ref><ref id="pone.0168858.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Bacon</surname><given-names>SP</given-names></name>, <name><surname>Grantham</surname><given-names>DW</given-names></name>. <article-title>Modulation masking: effects of modulation frequency, depth, and phase</article-title>. <source>J Acoust Soc Am</source>. <year>1989</year>;<volume>85</volume>: <fpage>2575</fpage>&#x02013;<lpage>2580</lpage>. <pub-id pub-id-type="pmid">2745880</pub-id></mixed-citation></ref><ref id="pone.0168858.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Kingsbury</surname><given-names>BE</given-names></name>, <name><surname>Morgan</surname><given-names>N</given-names></name>, <name><surname>Greenberg</surname><given-names>S</given-names></name>. <article-title>Robust speech recognition using the modulation spectrogram</article-title>. <source>Speech Commun</source>. <year>1998</year>;<volume>25</volume>: <fpage>117</fpage>&#x02013;<lpage>132</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Drullman</surname><given-names>R</given-names></name>, <name><surname>Festen</surname><given-names>JM</given-names></name>, <name><surname>Plomp</surname><given-names>R</given-names></name>. <article-title>Effect of temporal envelope smearing on speech reception</article-title>. <source>J Acoust Soc Am</source>. <year>1994</year>;<volume>95</volume>: <fpage>1053</fpage>&#x02013;<lpage>64</lpage>. <pub-id pub-id-type="pmid">8132899</pub-id></mixed-citation></ref><ref id="pone.0168858.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Fitzgerald</surname><given-names>MB</given-names></name>, <name><surname>Wright</surname><given-names>BA</given-names></name>. <article-title>Perceptual learning and generalization resulting from training on an auditory amplitude-modulation detection task</article-title>. <source>J Acoust Soc Am</source>. <year>2011</year>;<volume>129</volume>: <fpage>898</fpage>&#x02013;<lpage>906</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1121/1.3531841">10.1121/1.3531841</ext-link></comment>
<pub-id pub-id-type="pmid">21361447</pub-id></mixed-citation></ref><ref id="pone.0168858.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Dosher</surname><given-names>BA</given-names></name>, <name><surname>Lu</surname><given-names>Z-L</given-names></name>. <article-title>Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting</article-title>. <source>Proc Natl Acad Sci</source>. <year>1998</year>;<volume>95</volume>: <fpage>13988</fpage>&#x02013;<lpage>13993</lpage>. <pub-id pub-id-type="pmid">9811913</pub-id></mixed-citation></ref><ref id="pone.0168858.ref043"><label>43</label><mixed-citation publication-type="other">Liebe S, Gold JM, Busey TA, O&#x02019;Donnell B. Electrophysiological correlates of the effects of perceptual learning on signal and noise in the human visual system. Vision Sciences Society Annual Meeting Abstracts. 2004.</mixed-citation></ref><ref id="pone.0168858.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>McTeague</surname><given-names>LM</given-names></name>, <name><surname>Gruss</surname><given-names>LF</given-names></name>, <name><surname>Keil</surname><given-names>A</given-names></name>. <article-title>Aversive learning shapes neuronal orientation tuning in human visual cortex</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>: <fpage>7823</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms8823">10.1038/ncomms8823</ext-link></comment>
<pub-id pub-id-type="pmid">26215466</pub-id></mixed-citation></ref><ref id="pone.0168858.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Houtsma</surname><given-names>AJM</given-names></name>, <name><surname>Smurzynski</surname><given-names>J</given-names></name>. <article-title>Pitch identification and discrimination for complex tones with many harmonics</article-title>. <source>J Acoust Soc Am</source>. <year>1990</year>;<volume>87</volume>: <fpage>304</fpage>&#x02013;<lpage>310</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Bernstein</surname><given-names>JG</given-names></name>, <name><surname>Oxenham</surname><given-names>AJ</given-names></name>. <article-title>Pitch discrimination of diotic and dichotic tone complexes: Harmonic resolvability or harmonic number?</article-title>
<source>J Acoust Soc Am</source>. <year>2003</year>;<volume>113</volume>: <fpage>3323</fpage>&#x02013;<lpage>3334</lpage>. <pub-id pub-id-type="pmid">12822804</pub-id></mixed-citation></ref><ref id="pone.0168858.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Moore</surname><given-names>BCJ</given-names></name>, <name><surname>Huss</surname><given-names>M</given-names></name>, <name><surname>Vickers</surname><given-names>DA</given-names></name>, <name><surname>Glasberg</surname><given-names>BR</given-names></name>, <name><surname>Alcantara</surname><given-names>JI</given-names></name>. <article-title>A test for the diagnosis of dead regions in the cochlea</article-title>. <source>Br J Audiol</source>. <year>2000</year>;<volume>34</volume>: <fpage>205</fpage>&#x02013;<lpage>24</lpage>. <pub-id pub-id-type="pmid">10997450</pub-id></mixed-citation></ref><ref id="pone.0168858.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Riecke</surname><given-names>L</given-names></name>, <name><surname>Scharke</surname><given-names>W</given-names></name>, <name><surname>Valente</surname><given-names>G</given-names></name>, <name><surname>Gutschalk</surname><given-names>A</given-names></name>. <article-title>Sustained Selective Attention to Competing Amplitude-Modulations in Human Auditory Cortex</article-title>. <source>PLoS ONE</source>. <year>2014</year>;<volume>9</volume>: <fpage>e108045</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0108045">10.1371/journal.pone.0108045</ext-link></comment>
<pub-id pub-id-type="pmid">25259525</pub-id></mixed-citation></ref><ref id="pone.0168858.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Brainard</surname><given-names>DH</given-names></name>. <source>The Psychophysics Toolbox</source>. <year>1997</year>;<volume>10</volume>: <fpage>433</fpage>&#x02013;<lpage>436</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Pelli</surname><given-names>DG</given-names></name>. <source>The VideoToolbox software for visual psychophysics: transforming numbers into movies</source>. <year>1997</year>;<volume>10</volume>: <fpage>437</fpage>&#x02013;<lpage>442</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Kleiner</surname><given-names>M</given-names></name>, <name><surname>Brainard</surname><given-names>D</given-names></name>, <name><surname>Pelli</surname><given-names>D</given-names></name>. <article-title>What&#x02019;s new in Psychtoolbox-3?</article-title>
<source>Perception</source>. <year>2007</year>;<volume>36</volume>: <fpage>14</fpage>&#x02013;<lpage>14</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Levitt</surname><given-names>H</given-names></name>. <article-title>Transformed Up-Down Methods in Psychoacoustics</article-title>. <source>J Acoust Soc Am</source>. <year>1971</year>;<volume>49</volume>: <fpage>467</fpage>&#x02013;<lpage>477</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name>, <name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name>. <article-title>Rapid acquisition of auditory subcortical steady state responses using multichannel recordings</article-title>. <source>Clin Neurophysiol. International Federation of Clinical Neurophysiology</source>; <year>2014</year>;<volume>125</volume>: <fpage>1878</fpage>&#x02013;<lpage>1888</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Delorme</surname><given-names>A</given-names></name>, <name><surname>Makeig</surname><given-names>S</given-names></name>. <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>. <source>J Neurosci Methods</source>. <year>2004</year>;<volume>134</volume>: <fpage>9</fpage>&#x02013;<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2003.10.009">10.1016/j.jneumeth.2003.10.009</ext-link></comment>
<pub-id pub-id-type="pmid">15102499</pub-id></mixed-citation></ref><ref id="pone.0168858.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Kraus</surname><given-names>N</given-names></name>, <name><surname>McGee</surname><given-names>T</given-names></name>, <name><surname>Carrell</surname><given-names>TD</given-names></name>, <name><surname>King</surname><given-names>C</given-names></name>, <name><surname>Tremblay</surname><given-names>KL</given-names></name>, <name><surname>Nicol</surname><given-names>T</given-names></name>. <article-title>Central auditory system plasticity associated with speech discrimination training</article-title>. <source>J Cogn Neurosci</source>. <year>1995</year>;<volume>7</volume>: <fpage>25</fpage>&#x02013;<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.1995.7.1.25">10.1162/jocn.1995.7.1.25</ext-link></comment>
<pub-id pub-id-type="pmid">23961751</pub-id></mixed-citation></ref><ref id="pone.0168858.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Bao</surname><given-names>M</given-names></name>, <name><surname>Yang</surname><given-names>L</given-names></name>, <name><surname>Rios</surname><given-names>C</given-names></name>, <name><surname>He</surname><given-names>B</given-names></name>, <name><surname>Engel</surname><given-names>SA</given-names></name>. <article-title>Perceptual learning increases the strength of the earliest signals in visual cortex</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>: <fpage>15080</fpage>&#x02013;<lpage>15084</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5703-09.2010">10.1523/JNEUROSCI.5703-09.2010</ext-link></comment>
<pub-id pub-id-type="pmid">21068313</pub-id></mixed-citation></ref><ref id="pone.0168858.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Recanzone</surname><given-names>GH</given-names></name>, <name><surname>Schreiner</surname><given-names>CE</given-names></name>, <name><surname>Merzenich</surname><given-names>MM</given-names></name>. <article-title>Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys</article-title>. <source>J Neurosci</source>. <year>1993</year>;<volume>13</volume>: <fpage>87</fpage>&#x02013;<lpage>103</lpage>. papers://FAFC0638-5DD4-4A81-A69F-F8A54DFE70C3/Paper/p11227 <pub-id pub-id-type="pmid">8423485</pub-id></mixed-citation></ref><ref id="pone.0168858.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Bosnyak</surname><given-names>DJ</given-names></name>, <name><surname>Eaton</surname><given-names>RA</given-names></name>, <name><surname>Roberts</surname><given-names>LE</given-names></name>. <article-title>Distributed auditory cortical representations are modified when non-musicians are trained at pitch discrimination with 40 Hz amplitude modulated tones</article-title>. <source>Cereb Cortex</source>. <year>2004</year>;<volume>14</volume>: <fpage>1088</fpage>&#x02013;<lpage>1099</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhh068">10.1093/cercor/bhh068</ext-link></comment>
<pub-id pub-id-type="pmid">15115745</pub-id></mixed-citation></ref><ref id="pone.0168858.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Bidet-Caulet</surname><given-names>A</given-names></name>, <name><surname>Fischer</surname><given-names>C</given-names></name>, <name><surname>Besle</surname><given-names>J</given-names></name>, <name><surname>Aguera</surname><given-names>P-E</given-names></name>, <name><surname>Giard</surname><given-names>M-H</given-names></name>, <name><surname>Bertrand</surname><given-names>O</given-names></name>. <article-title>Effects of selective attention on the electrophysiological representation of concurrent sounds in the human auditory cortex</article-title>. <source>J Neurosci</source>. <year>2007</year>;<volume>27</volume>: <fpage>9252</fpage>&#x02013;<lpage>61</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1402-07.2007">10.1523/JNEUROSCI.1402-07.2007</ext-link></comment>
<pub-id pub-id-type="pmid">17728439</pub-id></mixed-citation></ref><ref id="pone.0168858.ref060"><label>60</label><mixed-citation publication-type="journal"><name><surname>M&#x000fc;ller</surname><given-names>N</given-names></name>, <name><surname>Schlee</surname><given-names>W</given-names></name>, <name><surname>Hartmann</surname><given-names>T</given-names></name>, <name><surname>Lorenz</surname><given-names>I</given-names></name>, <name><surname>Weisz</surname><given-names>N</given-names></name>. <article-title>Top-down modulation of the auditory steady-state response in a task-switch paradigm</article-title>. <source>Front Hum Neurosci</source>. <year>2009</year>;<volume>3</volume>: <fpage>1</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.09.001.2009">10.3389/neuro.09.001.2009</ext-link></comment>
<pub-id pub-id-type="pmid">19255629</pub-id></mixed-citation></ref><ref id="pone.0168858.ref061"><label>61</label><mixed-citation publication-type="journal"><name><surname>Shiffrin</surname><given-names>RM</given-names></name>, <name><surname>Schneider</surname><given-names>W</given-names></name>. <article-title>Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory</article-title>. <source>Psychol Rev</source>. <year>1977</year>;<volume>84</volume>: <fpage>127</fpage>&#x02013;<lpage>190</lpage>.</mixed-citation></ref><ref id="pone.0168858.ref062"><label>62</label><mixed-citation publication-type="journal"><name><surname>Polley</surname><given-names>DB</given-names></name>. <article-title>Perceptual Learning Directs Auditory Cortical Map Reorganization through Top-Down Influences</article-title>. <source>J Neurosci</source>. <year>2006</year>;<volume>26</volume>: <fpage>4970</fpage>&#x02013;<lpage>4982</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3771-05.2006">10.1523/JNEUROSCI.3771-05.2006</ext-link></comment>
<pub-id pub-id-type="pmid">16672673</pub-id></mixed-citation></ref><ref id="pone.0168858.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Coffey</surname><given-names>EBJ</given-names></name>, <name><surname>Herholz</surname><given-names>SC</given-names></name>, <name><surname>Chepesiuk</surname><given-names>AMP</given-names></name>, <name><surname>Baillet</surname><given-names>S</given-names></name>, <name><surname>Zatorre</surname><given-names>RJ</given-names></name>. <article-title>Cortical contributions to the auditory frequency-following response revealed by MEG</article-title>. <source>Nat Commun</source>. <year>2016</year>;<volume>7</volume>: <fpage>11070</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms11070">10.1038/ncomms11070</ext-link></comment>
<pub-id pub-id-type="pmid">27009409</pub-id></mixed-citation></ref><ref id="pone.0168858.ref064"><label>64</label><mixed-citation publication-type="journal"><name><surname>Wright</surname><given-names>BA</given-names></name>, <name><surname>Fitzgerald</surname><given-names>MB</given-names></name>. <article-title>Different patterns of human discrimination learning for two interaural cues to sound-source location</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2001</year>;<volume>98</volume>: <fpage>12307</fpage>&#x02013;<lpage>12312</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.211220498">10.1073/pnas.211220498</ext-link></comment>
<pub-id pub-id-type="pmid">11593048</pub-id></mixed-citation></ref><ref id="pone.0168858.ref065"><label>65</label><mixed-citation publication-type="journal"><name><surname>Petrov</surname><given-names>AA</given-names></name>, <name><surname>Dosher</surname><given-names>BA</given-names></name>, <name><surname>Lu</surname><given-names>Z-L</given-names></name>. <article-title>The Dynamics of Perceptual Learning: An Incremental Reweighting Model</article-title>. <source>Psychol Rev</source>. <year>2005</year>;<volume>112</volume>: <fpage>715</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.112.4.715">10.1037/0033-295X.112.4.715</ext-link></comment>
<pub-id pub-id-type="pmid">16262466</pub-id></mixed-citation></ref><ref id="pone.0168858.ref066"><label>66</label><mixed-citation publication-type="journal"><name><surname>Law</surname><given-names>C-T</given-names></name>, <name><surname>Gold</surname><given-names>JI</given-names></name>. <article-title>Neural correlates of perceptual learning in a sensory-motor, but not a sensory, cortical area</article-title>. <source>Nat Neurosci</source>. <year>2008</year>;<volume>11</volume>: <fpage>505</fpage>&#x02013;<lpage>513</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn2070">10.1038/nn2070</ext-link></comment>
<pub-id pub-id-type="pmid">18327253</pub-id></mixed-citation></ref></ref-list></back></article>