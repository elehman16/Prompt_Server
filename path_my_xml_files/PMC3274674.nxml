<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Adv Health Sci Educ Theory Pract</journal-id><journal-title-group><journal-title>Advances in Health Sciences Education</journal-title></journal-title-group><issn pub-type="ppub">1382-4996</issn><issn pub-type="epub">1573-1677</issn><publisher><publisher-name>Springer Netherlands</publisher-name><publisher-loc>Dordrecht</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">21442416</article-id><article-id pub-id-type="pmc">3274674</article-id><article-id pub-id-type="publisher-id">9291</article-id><article-id pub-id-type="doi">10.1007/s10459-011-9291-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Challenging medical students with an interim assessment: a positive effect on formal examination score in a randomized controlled study</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Olde Bekkink</surname><given-names>Marleen</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Donders</surname><given-names>Rogier</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>van Muijen</surname><given-names>Goos N. P.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Ruiter</surname><given-names>Dirk J.</given-names></name><address><phone>+31-0-243617625</phone><fax>+31-0-24 3613789</fax><email>D.Ruiter@pathol.umcn.nl</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label>109 Department of Anatomy, Radboud University Nijmegen Medical Centre, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands </aff><aff id="Aff2"><label>2</label>Department of Epidemiology, Biostatistics and Health Technology Assessment, Radboud University Nijmegen Medical Centre, Nijmegen, The Netherlands </aff><aff id="Aff3"><label>3</label>Department of Pathology, Radboud University Nijmegen Medical Centre, Nijmegen, The Netherlands </aff></contrib-group><pub-date pub-type="epub"><day>27</day><month>3</month><year>2011</year></pub-date><pub-date pub-type="pmc-release"><day>27</day><month>3</month><year>2011</year></pub-date><pub-date pub-type="ppub"><month>3</month><year>2012</year></pub-date><volume>17</volume><issue>1</issue><fpage>27</fpage><lpage>37</lpage><history><date date-type="received"><day>15</day><month>11</month><year>2010</year></date><date date-type="accepted"><day>15</day><month>3</month><year>2011</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2011</copyright-statement></permissions><abstract id="Abs1"><p>Until now, positive effects of assessment at a medical curriculum level have not been demonstrated. This study was performed to determine whether an interim assessment, taken during a small group work session of an ongoing biomedical course, results in students&#x02019; increased performance at the formal course examination. A randomized controlled trial was set up, with an interim assessment without explicit feedback as intervention. It was performed during a regular biomedical Bachelor course of 4&#x000a0;weeks on General Pathology at the Radboud University Nijmegen Medical Centre. Participants were 326 medical and 91 biomedical science students divided into three study arms: arm Intervention-1 (I-1) receiving one interim assessment; arm I-2 receiving two interim assessments, and control arm C, receiving no interim assessment. The study arms were stratified for gender and study discipline. The interim assessment consisted of seven multiple-choice questions on tumour pathology. Main outcome measures were overall score of the formal examination (scale 1&#x02013;10), and the subscore of the questions on tumour pathology (scale 1&#x02013;10). We found that students who underwent an interim assessment (arm I) had a 0.29-point (scale 1&#x02013;10) higher score on the formal examination than the control group (<italic>p</italic>&#x000a0;=&#x000a0;0.037). For the questions in the formal examination on tumour pathology the score amounted to 0.47 points higher (<italic>p</italic>&#x000a0;=&#x000a0;0.007), whereas it was 0.17 points higher for the questions on topics related to the previous 3&#x000a0;weeks. No differences in formal examination score were found between arms I-1 and I-2 (<italic>p</italic>&#x000a0;=&#x000a0;0.817). These findings suggest that an interim assessment during a small group work session in a randomized study setting stimulates students to increase their formal examination score.</p></abstract><kwd-group><title>Keywords</title><kwd>Interim assessment</kwd><kwd>Increased examination score</kwd><kwd>Medical education</kwd><kwd>Student&#x02019;s performance</kwd><kwd>Test enhanced learning</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Science+Business Media B.V. 2012</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p>Doctors&#x02019; clinical reasoning skills depend highly on a relevant knowledge base (van der Vleuten and Newble <xref ref-type="bibr" rid="CR23">1995</xref>). Becoming an excellent doctor starts at medical school. In order to promote excellence in medical teaching and learning, it is necessary to find out how teaching affects learning (Ramani <xref ref-type="bibr" rid="CR20">2006</xref>). One could wonder whether our medical students are being optimally stimulated. Is the active learning of students sufficient, or can they be stimulated to perform even better? For this purpose, objective information on learning efficacy is needed. Assessment of learning efficacy currently involves an integrated approach of formative and summative assessments, and regular evaluation of competences, that are recorded in a student portfolio (Driessen et al. <xref ref-type="bibr" rid="CR3">2005</xref>; Epstein <xref ref-type="bibr" rid="CR4">2007</xref>). Recently, the role of interim assessments as a third type of assessment in a comprehensive assessment system of US school districts was described, that: (1) evaluates students&#x02019; knowledge and skills relative to a specific set of academic goals, typically within a limited time frame; and (2) are designed to inform decisions at the classroom level and beyond (Perie et al<italic>.</italic><xref ref-type="bibr" rid="CR18">2007</xref>). Interim assessments contain both formative and summative assessment features, but unlike true formative assessments, the results of interim assessments can be meaningfully aggregated and reported at a broader level. An interim assessment reflects the level of the students&#x02019; knowledge and skills, but unlike summative assessments, does not have strict consequences, i.e. pass or fail the assessment. Perie et al. see three different general classes of purposes for interim assessments: instructional; evaluative; and predictive (Perie et al. <xref ref-type="bibr" rid="CR18">2007</xref>). All three assessment purposes potentially provide useful information for both students and faculty, and they may also allow further scientific elaboration.</p><p>An important goal of assessment is to optimize the capabilities of all learners and practitioners by providing motivation and direction for future learning (Epstein <xref ref-type="bibr" rid="CR4">2007</xref>). Assessment also drives students&#x02019; learning behaviour (Cohen-Schotanus <xref ref-type="bibr" rid="CR2">1999</xref>; Frederiksen <xref ref-type="bibr" rid="CR6">1984</xref>; van der Vleuten and Schuwirth <xref ref-type="bibr" rid="CR24">2005</xref>). Assessment and learning are related to varying degrees, although the specific dynamics are not yet fully understood (Boulet <xref ref-type="bibr" rid="CR1">2008</xref>; Handfield-Jones et al. <xref ref-type="bibr" rid="CR7">2002</xref>). Apart from obtaining useful information from assessments, it is supposed that assessing drives, and may help learning, the so-called &#x0201c;testing effect&#x0201d; (Newble and Jaeger <xref ref-type="bibr" rid="CR16">1983</xref>). Karpicke and Roediger elegantly demonstrated the critical importance of retrieval practice in consolidating learning a foreign language by university students using repeated testing (Karpicke and Roediger <xref ref-type="bibr" rid="CR10">2008</xref>). A similar effect was demonstrated by the same authors in two experiments giving students one or three immediate recall tests without feedback (Roediger and Karpicke <xref ref-type="bibr" rid="CR22">2006b</xref>). A positive effect of test-driven learning was recently demonstrated in a didactic conference for paediatric and emergency medical residents (Larsen et al. <xref ref-type="bibr" rid="CR14">2009</xref>). Thus, assessment can be viewed as an educational tool that provides useful information for both students and faculty (Krupat and Dienstag <xref ref-type="bibr" rid="CR11">2009</xref>).</p><p>Until now, according to Norman et al. positive effects of assessment at a medical curriculum level have not been demonstrated (Norman et al. <xref ref-type="bibr" rid="CR17">2010</xref>). Does interim assessment also improve student performance in a non-laboratory undergraduate medical education setting? If so, we hypothesized that interim testing of the medical students results in a higher formal examination score. Here the interim assessment is used as a didactic instrument. Medical education uses a variety of settings and formats. Identification of which educational setting lends itself to test-enhanced learning is to be investigated (Larsen et al. <xref ref-type="bibr" rid="CR13">2008</xref>). We assumed that the best learning environment to administer the interim assessment is a small group work session, as it is considered to substantially contribute to meaningful learning (Michael <xref ref-type="bibr" rid="CR15">2006</xref>). Furthermore, we were interested if we could demonstrate an additional value of two interim assessments instead of one assessment. For this purpose, we set up a prospective randomized study comparing two different arms of small groups. In the intervention arm (I) an interim assessment was provided prior to the formal course examination, in the control arm (C) no interim assessment was provided. The intervention arm was further subdivided into two arms: one arm with one interim assessment (I-1) and the other arm with two interim assessments (I-2). The current study shows that an interim assessment in a randomized study setting is found to stimulate students to increase their formal examination score.</p></sec><sec id="Sec2" sec-type="methods"><title>Methods</title><sec id="Sec3"><title>Participants and setting</title><p>The study was conducted with biomedical students at the Radboud University Nijmegen Medical Centre, consisting of 326 medical and 91 biomedical science students, who undertook a second-year Bachelor course on General Pathology. The female to male ratio of students was 3:1. The Radboud University Nijmegen Medical Centre provides a learner outcome-oriented curriculum in which each course consists of 4&#x000a0;weeks. The subsequent topics of the course on General Pathology were: (1) Principles of diagnosis and cellular damage; (2) Inflammation and repair; (3) Circulatory disorders; and (4) Tumour pathology (pathogenesis and progression). Each topic had a consistent sequence of educational activities: lecture; task-driven directed self-study in preparation for the subsequent small group work; small group work (obligatory); practical course (obligatory); interactive lecture; and non-directed self-study (see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). The formal examination of all topics took place on the final day of the course. For the interim assessment, the small group work session on tumour pathology: &#x0201c;The pathogenesis of uterine cervical carcinoma&#x0201d; was selected.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Topic structure. Time of administration of a single interim assessment (study arm I-1) and double interim assessments (study arm I-2) in relation to topic structure. The time scheduled is indicated between <italic>brackets</italic> for each educational component</p></caption><graphic xlink:href="10459_2011_9291_Fig1_HTML" id="MO1"/></fig></p></sec><sec id="Sec4"><title>Ethical considerations</title><p>Formal written permission to execute the study was obtained from the course coordinator. As there is no access to a formal ethical approval process for medical education research in the Netherlands, information about the treatment of the students is provided. This concerns the possible risks for the students, the equitability of the selection, the guarantee of privacy and confidentiality, the procedure on informed consent, and the possible safeguards to protect vulnerable populations (Eva <xref ref-type="bibr" rid="CR5">2009</xref>; Kanter <xref ref-type="bibr" rid="CR8">2009</xref>). In our opinion, participation in the interim assessments bore no possible risk to students. The assignment of the students to the small groups and the assignment of the groups to one of the three arms of the study was random. The privacy of the students was guarded by the study coordinator. For the study, the examination scores were linked to a student number and the identity of the students was not disclosed. The students were adequately informed of the purpose of the interim assessment and consent was obtained. We were not aware of any vulnerable population among the students that would have required safeguards. When developing the current study, the ethical principles of the World Medical Association Declaration of Helsinki were taken into account.</p></sec><sec id="Sec5"><title>Intervention</title><p>An interim assessment consisted of seven multiple-choice questions with a maximum of four alternative answers on the topic of tumour pathology. A time of 10&#x000a0;min was allotted to each interim assessment. The questions were derived from a bank of 80 multiple-choice questions on tumour pathology formulated by one of the authors (DR), who is an expert in tumour pathology, and were validated by two independent pathologists, two independent medical educationalists, and a master medical student (MOB).</p><p>The formal examination consisted of 15 multiple-choice questions and one open question relating to tumour pathology and seven open questions on the other topics. Both the multiple-choice questions of the interim assessments and the formal examination were derived from the aforementioned bank of questions. The two interim assessments and the formal examination were composed of different multiple-choice questions, but the content and the level of the questions were similar.</p></sec><sec id="Sec6"><title>Randomization</title><p>Participants were randomized in three arms of equal numbers of small work groups. Allocation of intervention occurred on the level of the small work groups. The randomization was stratified for gender and study discipline, since these may influence learning behaviour and learning efficacy (Kusurkar et al. <xref ref-type="bibr" rid="CR12">2009</xref>). In arm I-1, students underwent an interim assessment once, i.e. at the end of the small group work session; in arm I-2, students underwent an interim assessment twice, i.e. at the beginning and at the end of the small group work session; and in arm C, students did not undergo an interim assessment (see Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>).<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Flow chart. Study design including two intervention groups (I-1 and I-2) and one control group (C). *Number of students excluded, because they did not participate in the formal examination (n&#x000a0;=&#x000a0;13)</p></caption><graphic xlink:href="10459_2011_9291_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec7"><title>Procedure</title><p>Students in the intervention arm were informed about the interim assessment at the small group work session. Tutors explained to the students immediately before the interim assessment that it was an investigation to inform the faculty on the learning outcome of the students during the small group work. Participation in the interim assessment was on a voluntary basis, and students could stop taking the assessment at any time. They were assured that the result of the interim assessment would not be taken into account for determining the score of the formal course examination. The participation rate was 100%. Students and tutors were not informed of the content of the questions of the interim assessment. The tutors were present at the beginning of the small group work session including the interim assessment, and during the second hour of the small group work session including the other interim assessment. Five different tutors guided the small group work sessions. Each tutor guided both intervention and control groups. No explicit feedback on the results was given to the students. The formal examination took place 3&#x000a0;days following the interim assessments.</p></sec><sec id="Sec8"><title>Outcome measures</title><p>The main outcome measures were overall score of the formal examination, and the subscore of the open and multiple-choice questions on tumour pathology. Both outcome measures were presented on a scale from 1 to a maximum of 10 points. A subgroup analysis of gender and discipline was performed. The interim assessment is intended as a didactic instrument, not a predictive instrument, therefore the scores of the interim assessment were not compared to that of the formal examination.</p></sec><sec id="Sec9"><title>Statistical analysis</title><p>Linear mixed models were used in order to account for the dependence caused by clustering of the students into small groups. The small group was used as a random factor. Analysis was performed according to the intention-to-treat principle. After the primary analysis, a subgroup analysis was performed according to gender and discipline.</p></sec></sec><sec id="Sec10"><title>Results</title><sec id="Sec11"><title>Main results</title><p>Students who underwent an interim assessment once or twice (arms I-1 and I-2, respectively) showed a 0.29 point (scale 1&#x02013;10) higher overall score on the formal examination than the control group C (<italic>p</italic>&#x000a0;=&#x000a0;0.037). For the questions in the formal examination related to the topic of tumour pathology, the score amounted to 0.47 points higher (<italic>p</italic>&#x000a0;=&#x000a0;0.007), whereas it was 0.17 points higher for the questions of the other topics on general pathology. Accompanying effect scores and standard deviations are reported in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Results of the mixed model analysis are reported in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. No differences in formal examination score were found between arms I-1 and I-2 (Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>).<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Outcome measures (scale 1&#x02013;10) including standard deviations and effect sizes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Study arm</th><th align="left">Formal examination score (SD)</th><th align="left">Subscore on tumour pathology (SD)</th></tr></thead><tbody><tr><td align="left">Intervention</td><td char="." align="char">6.27 (1.19)</td><td char="." align="char">6.34 (1.50)</td></tr><tr><td align="left">Control</td><td char="." align="char">5.98 (1.25)</td><td char="." align="char">5.87 (1.51)</td></tr><tr><td align="left">Effect size</td><td char="." align="char">0.24</td><td char="." align="char">0.31</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table&#x000a0;2</label><caption><p>Results of the mixed model analysis</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Source</th><th align="left">Numerator df</th><th align="left">Denominator df</th><th align="left">F</th><th align="left">Significance</th></tr></thead><tbody><tr><td align="left" colspan="5">a. Type III Tests of fixed effects, dependent variable: formal examination score</td></tr><tr><td align="left">&#x000a0;Intercept</td><td align="left">1</td><td char="." align="char">27.235</td><td char="." align="char">5,906.763</td><td char="." align="char">0.000</td></tr><tr><td align="left">&#x000a0;Intervention</td><td align="left">1</td><td char="." align="char">24.325</td><td char="." align="char">4.851</td><td char="." align="char">0.037</td></tr><tr><td align="left">&#x000a0;Gender</td><td align="left">1</td><td char="." align="char">399.947</td><td char="." align="char">27.381</td><td char="." align="char">0.000</td></tr><tr><td align="left">&#x000a0;Discipline</td><td align="left">1</td><td char="." align="char">25.620</td><td char="." align="char">18.454</td><td char="." align="char">0.000</td></tr><tr><td align="left" colspan="5">b. Type III Tests of fixed effects, dependent variable: subscore on tumour pathology</td></tr><tr><td align="left">&#x000a0;Intercept</td><td align="left">1</td><td char="." align="char">27.524</td><td char="." align="char">3,948.371</td><td char="." align="char">0.000</td></tr><tr><td align="left">&#x000a0;Intervention</td><td align="left">1</td><td char="." align="char">24. 494</td><td char="." align="char">8.513</td><td char="." align="char">0.007</td></tr><tr><td align="left">&#x000a0;Gender</td><td align="left">1</td><td char="." align="char">399.996</td><td char="." align="char">17.832</td><td char="." align="char">0.000</td></tr><tr><td align="left">&#x000a0;Discipline</td><td align="left">1</td><td char="." align="char">25.846</td><td char="." align="char">16.839</td><td char="." align="char">0.000</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table&#x000a0;3</label><caption><p>Results formal examination per intervention arm</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Study arm</th><th align="left">Formal examination score (scale 1&#x02013;10)</th></tr></thead><tbody><tr><td align="left">Intervention-1</td><td char="(" align="char">6.28 (6.40<sup>a</sup>)</td></tr><tr><td align="left">Intervention-2</td><td char="(" align="char">6.25 (6.27<sup>a</sup>)</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Subscore on tumour pathology</p></table-wrap-foot></table-wrap></p><p>No student refused to participate. Students who undertook the interim assessment, but did not undertake the examination, were excluded (n&#x000a0;=&#x000a0;13). A total of 404 students were included in the analysis. There was no significant difference in dropouts between the three study arms.</p></sec><sec id="Sec12"><title>Subgroup analysis</title><p>Female students scored significantly higher on the formal examination compared with the male students (0.65 points, <italic>p</italic>&#x000a0;&#x0003c;&#x000a0;0.001). Medical students scored 0.65 points higher than biomedical science students (<italic>p</italic>&#x000a0;&#x0003c;&#x000a0;0.001). There was no difference in progress imposed by the interim assessment between these subgroups.</p></sec></sec><sec id="Sec13"><title>Discussion</title><sec id="Sec14"><title>Main findings</title><p>An interim assessment during a small group work session in a randomized controlled trial setting was able to increase students&#x02019; formal examination score. This effect was similar for the students who took the interim assessment either once or twice. The increase in the score amounted to almost 0.5 points on a scale of 1&#x02013;10 for those questions in the formal examination that were related to the questions in the interim assessment. There was no difference in progress imposed by the interim assessment between gender or discipline.</p></sec><sec id="Sec15"><title>Strengths</title><p>The study design, a prospective randomized controlled trial with stratification for gender and discipline can be considered to be robust, because selection bias, information bias and confounding bias are highly unlikely. The primary outcome of the study, i.e. the score of the formal examination, is unequivocal. The data were subjected to a linear mixed-model analysis in order to account for the dependence caused by clustering of the students in small work groups. The multiple-choice questions in the interim assessment and formal examination were validated both on medical content and educational quality. Based on these considerations, the results appear consistent.</p><p>The control group was not engaged in an alternative interim assessment, as this would distract from the small group work. The students in the control group could spend time discussing the topic of the small workgroup, when the intervention groups received the interim assessment. Therefore, total exposure time to the subject matter was equal for the intervention and the control groups.</p><p>The study setting was directly related to educational practice, i.e. during an ongoing regular biomedical Bachelor course and it did not interfere with educational activities. The tutors were blinded to the content of the interim assessment. All tutors guided at least one student group from each of the three study arms. Both students and tutors accepted the interim assessment well and perceived it as a natural component of the small group work session. Based on regular evaluations, the course on General Pathology is highly appreciated by the students and the faculty, and can be considered to use current best practice. We therefore feel that the study is representative of current best educational practice.</p></sec><sec id="Sec16"><title>Limitations</title><p>The generalizability of our findings is currently limited. This study presents only a single study in a single curriculum. To increase the level of evidence and to investigate a broader application of the interim assessment, more similar studies are needed.</p><p>We were not able to demonstrate an additional learning effect of a second interim assessment in the current study. This might be caused by the length of the interval between de two interim assessments, as will be discussed later.</p><p>If our results, that participation in an interim assessment prior to a formal examination increases the score of the formal examination, are confirmed by other studies, this would mean that the students in the interim assessment arms were at an advantage over the students in the control group. Therefore, in future studies, the control group should also be subject to an interim assessment, using cross-over study designs, for example.</p><p>Thirteen students (3.1%) could not be included in our analysis, because they did not take part in the formal examination. Among the dropouts the male: female ratio was 5:8 (overall ratio: 1:2), the biomedical: medical ratio was 4:9 (overall ratio: 1:4). The dropouts were distributed equally over the three study arms; therefore it is unlikely this will have affected our results.</p></sec><sec id="Sec17"><title>Interpretation of the main findings</title><p>As the students were not aware of our study hypothesis, i.e. that participating in an interim assessment would lead to a higher formal examination score, we assume that they were stimulated or even challenged by the interim assessment, as such. By doing so, they probably were engaged in retrieval practice in consolidating learning as a manifestation of the testing effect (Karpicke and Roediger <xref ref-type="bibr" rid="CR10">2008</xref>). The underlying mechanisms of this effect may include: (1) enhanced <italic>motivation</italic> of the learners; (2) <italic>directing</italic> them to focus on relevant issues; and (3) giving them an opportunity to <italic>train</italic> for the formal course examination (Larsen et al. <xref ref-type="bibr" rid="CR13">2008</xref>). Although the positive effect on the formal examination was relatively small, we feel that it has educational relevance because it could have had a clear influence on the summative exam, i.e. pass or fail. In addition, it demonstrates that students in an ongoing curriculum (i.e. a realistic setting) can be stimulated by an interim assessment to perform better.</p><p>The fact that the positive effect on the formal examination score was not different using either one or two interim assessments indicates that a second interim assessment taken within a short time interval (i.e. less than 2&#x000a0;h) following the first interim assessment has no added value on the learning effect. Therefore, it is likely that such an additional effect requires a longer timeframe in between assessments. Karpicke and Roediger demonstrated increased benefits of repeated testing when tests are distributed over time (Karpicke and Roediger <xref ref-type="bibr" rid="CR9">2007</xref>). Another factor may be feedback, as it seems a prerequisite for the added value of multiple assessments (Larsen et al. <xref ref-type="bibr" rid="CR13">2008</xref>), as will be discussed later.</p></sec><sec id="Sec18"><title>Comparison with other studies</title><p>An interim assessment is a relatively new educational tool that has recently been developed in the context of secondary schools in the USA (Perie et al. <xref ref-type="bibr" rid="CR18">2007</xref>). Repeated testing during a course, that leads to better retention of information, could be considered as a series of interim assessments. Poljicanin et al. demonstrated a positive effect of daily mini quizzes on students&#x02019; performance in an anatomy course (Poljicanin et al. <xref ref-type="bibr" rid="CR19">2009</xref>). They conducted a total of 34 quizzes during a whole academic year; whereas in our study, we provided only one or two assessments in a 4-week course. It is to be investigated how many assessments per timeframe would gain an optimal increase in performance, without interfering with the regular course programme. Karpicke and Roediger demonstrated that repeated testing leads to better long-term recall in comparison with single testing (Karpicke and Roediger <xref ref-type="bibr" rid="CR10">2008</xref>). In the current study, we were not able to demonstrate this result, as there was no significant difference between the intervention groups taking one or two interim assessments. As stated before, this can be explained by the fact that both tests were applied in the same small group work session, with only 2&#x000a0;h in between. It would be interesting to investigate whether the timing of the interim assessment, i.e. either at the beginning or at the end of the small group, would matter in this respect.</p><p>Larsen and colleagues recently described improvement of long-term retention by medical residents following repeated testing in a real-life educational setting (Larsen et al. <xref ref-type="bibr" rid="CR14">2009</xref>). In contrast to our study, the testing was followed by feedback, and the findings were measured at a final recall interval of 6&#x000a0;months. Our findings suggest that even without such feedback, retention of information, as measured by the formal examination score, occurs. It is conceivable that the increase of the score might have been higher if we would have given feedback as indicated by the literature (Larsen et al. <xref ref-type="bibr" rid="CR13">2008</xref>; Roediger and Karpicke <xref ref-type="bibr" rid="CR21">2006a</xref>; Wood <xref ref-type="bibr" rid="CR26">2009</xref>). For the sake of clarity of the study design, we chose not to include explicit feedback in this study, but we have included it in a follow-up study using a cross-over design. In this new study, we have carefully considered the nature, source and timing of feedback, as suggested by Veloski et al. (<xref ref-type="bibr" rid="CR25">2006</xref>).</p></sec></sec><sec id="Sec19"><title>Conclusions</title><p>An interim assessment during a small group work session is found to stimulate students to learn better and to increase their score of the formal examination. The current study supports the efficacy of the testing effect in an ongoing medical curriculum and the view that assessment can be seen as an educational tool (Krupat and Dienstag <xref ref-type="bibr" rid="CR11">2009</xref>). An interim assessment may enrich the repertoire of formats of small group work as suggested by Michael, in order to further increase meaningful learning (Michael <xref ref-type="bibr" rid="CR15">2006</xref>). It also implies that in our current educational best practice, students still can be challenged to promote excellence in medical education. Further randomized controlled studies assessing the frequency of testing and the addition of feedback are needed to optimize the test-enhanced increase in student performance in a realistic educational setting.</p></sec></body><back><ack><p>The authors are grateful to Doctor Peter de Wilde, Radboud University Nijmegen Medical Centre, for his contribution to the pilot version of this study. We would also like to thank Ms Xandra Smits, IOWO Consultancy and Institutional Research in Higher Education, for her skilful assistance in data processing, and Professor Pieter de Vries Robb&#x000e9;, Radboud University Nijmegen Medical Centre, for giving valuable comments. Furthermore we would like to thank Professor Piet Slootweg, Doctor Arnold Thoben, Doctor Marc Vorstenbosch and Doctor Rob de Waal, Radboud University Nijmegen Medical Centre, for validating the questions of the interim assessment. This research was funded by the Radboud University Nijmegen Medical Centre.</p><p><bold>Conflict of interest</bold> None.</p><p><bold>Ethical approval</bold> Ethical considerations are discussed as a separate paragraph in the "<xref rid="Sec2" ref-type="sec">Methods</xref>" section.</p><p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution Noncommercial License which permits any noncommercial use, distribution, and reproduction in any medium, provided the original author(s) and source are credited.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boulet</surname><given-names>J</given-names></name></person-group><article-title>Teaching to test or testing to teach?</article-title><source>Medical Education</source><year>2008</year><volume>42</volume><fpage>952</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.2008.03165.x</pub-id><pub-id pub-id-type="pmid">18823511</pub-id></mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen-Schotanus</surname><given-names>J</given-names></name></person-group><article-title>Student assessment and examination rules</article-title><source>Medical Teacher</source><year>1999</year><volume>21</volume><fpage>318</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1080/01421599979626</pub-id></mixed-citation></ref><ref id="CR3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driessen</surname><given-names>E</given-names></name><name><surname>Vleuten</surname><given-names>C</given-names></name><name><surname>Schuwirth</surname><given-names>L</given-names></name><name><surname>Tartwijk</surname><given-names>J</given-names></name><name><surname>Vermunt</surname><given-names>J</given-names></name></person-group><article-title>The use of qualitative research criteria for portfolio assessment as an alternative to reliability evaluation: A case study</article-title><source>Medical Education</source><year>2005</year><volume>39</volume><fpage>214</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2929.2004.02059.x</pub-id><pub-id pub-id-type="pmid">15679689</pub-id></mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RM</given-names></name></person-group><article-title>Assessment in medical education</article-title><source>The New England Journal of Medicine</source><year>2007</year><volume>356</volume><fpage>387</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1056/NEJMe078002</pub-id><pub-id pub-id-type="pmid">17251535</pub-id></mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eva</surname><given-names>KW</given-names></name></person-group><article-title>Research ethics requirements for Medical Education</article-title><source>Medical Education</source><year>2009</year><volume>43</volume><fpage>194</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.2008.03285.x</pub-id><pub-id pub-id-type="pmid">19250343</pub-id></mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frederiksen</surname><given-names>N</given-names></name></person-group><article-title>The real test bias: Influences of testing on teaching and learning</article-title><source>American Psychologist</source><year>1984</year><volume>39</volume><fpage>193</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.39.3.193</pub-id></mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Handfield-Jones</surname><given-names>RS</given-names></name><name><surname>Mann</surname><given-names>KV</given-names></name><name><surname>Challis</surname><given-names>ME</given-names></name><name><surname>Hobma</surname><given-names>SO</given-names></name><name><surname>Klass</surname><given-names>DJ</given-names></name><name><surname>McManus</surname><given-names>IC</given-names></name><name><surname>Paget</surname><given-names>NS</given-names></name><name><surname>Parboosingh</surname><given-names>IJ</given-names></name><name><surname>Wade</surname><given-names>WB</given-names></name><name><surname>Wilkinson</surname><given-names>TJ</given-names></name></person-group><article-title>Linking assessment to learning: A new route to quality assurance in medical practice</article-title><source>Medical Education</source><year>2002</year><volume>36</volume><fpage>949</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2923.2002.01315.x</pub-id><pub-id pub-id-type="pmid">12390463</pub-id></mixed-citation></ref><ref id="CR8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanter</surname><given-names>SL</given-names></name></person-group><article-title>Ethical approval for studies involving human participants: Academic medicine&#x02019;s new policy</article-title><source>Academic Medicine</source><year>2009</year><volume>84</volume><fpage>149</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1097/ACM.0b013e318198c40f</pub-id><pub-id pub-id-type="pmid">19174645</pub-id></mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karpicke</surname><given-names>JD</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names><suffix>III</suffix></name></person-group><article-title>Expanding retrieval practice promotes short-term retention, but equally spaced retrieval enhances long-term retention</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><year>2007</year><volume>33</volume><fpage>704</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.33.4.704</pub-id></mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karpicke</surname><given-names>JD</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names><suffix>III</suffix></name></person-group><article-title>The critical importance of retrieval for learning</article-title><source>Science</source><year>2008</year><volume>319</volume><fpage>966</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1126/science.1152408</pub-id><pub-id pub-id-type="pmid">18276894</pub-id></mixed-citation></ref><ref id="CR11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupat</surname><given-names>E</given-names></name><name><surname>Dienstag</surname><given-names>JL</given-names></name></person-group><article-title>Commentary: Assessment is an educational tool</article-title><source>Academic Medicine</source><year>2009</year><volume>84</volume><fpage>548</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1097/ACM.0b013e31819f7fb9</pub-id><pub-id pub-id-type="pmid">19704183</pub-id></mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="other">Kusurkar, R., Kruitwagen, C., Ten Cate, O., Croiset, G. (2009). Effects of age, gender and educational background on strength of motivation for medical school. <italic>Advances in Health Sciences Education: Theory and Practice</italic>. doi:10.1007/s10459-010-9253-4.</mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsen</surname><given-names>DP</given-names></name><name><surname>Butler</surname><given-names>AC</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names><suffix>III</suffix></name></person-group><article-title>Test-enhanced learning in medical education</article-title><source>Medical Education</source><year>2008</year><volume>42</volume><fpage>959</fpage><lpage>966</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.2008.03124.x</pub-id><pub-id pub-id-type="pmid">18823514</pub-id></mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsen</surname><given-names>DP</given-names></name><name><surname>Butler</surname><given-names>AC</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names><suffix>III</suffix></name></person-group><article-title>Repeated testing improves long-term retention relative to repeated study: A randomised controlled trial</article-title><source>Medical Education</source><year>2009</year><volume>43</volume><fpage>1174</fpage><lpage>1181</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.2009.03518.x</pub-id><pub-id pub-id-type="pmid">19930508</pub-id></mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michael</surname><given-names>J</given-names></name></person-group><article-title>Where&#x02019;s the evidence that active learning works?</article-title><source>Advances in Physiology Education</source><year>2006</year><volume>30</volume><fpage>159</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1152/advan.00053.2006</pub-id><pub-id pub-id-type="pmid">17108243</pub-id></mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newble</surname><given-names>DI</given-names></name><name><surname>Jaeger</surname><given-names>K</given-names></name></person-group><article-title>The effect of assessments and examinations on the learning of medical students</article-title><source>Medical Education</source><year>1983</year><volume>17</volume><fpage>165</fpage><lpage>171</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.1983.tb00657.x</pub-id><pub-id pub-id-type="pmid">6865814</pub-id></mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>G</given-names></name><name><surname>Neville</surname><given-names>A</given-names></name><name><surname>Blake</surname><given-names>JM</given-names></name><name><surname>Mueller</surname><given-names>B</given-names></name></person-group><article-title>Assessment steers learning down the right road: Impact of progress testing on licensing examination performance</article-title><source>Medical Teacher</source><year>2010</year><volume>32</volume><fpage>496</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.3109/0142159X.2010.486063</pub-id><pub-id pub-id-type="pmid">20515380</pub-id></mixed-citation></ref><ref id="CR18"><mixed-citation publication-type="other">Perie, M., Marion, S., Gong, B., Wurtzel, J. (2007). The role of interim assessments in a comprehensive assessment system: A policy brief. <ext-link ext-link-type="uri" xlink:href="http://inpathways.net/role-interim.pdf">http://inpathways.net/role-interim.pdf</ext-link>.</mixed-citation></ref><ref id="CR19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poljicanin</surname><given-names>A</given-names></name><name><surname>Caric</surname><given-names>A</given-names></name><name><surname>Vilovic</surname><given-names>K</given-names></name><name><surname>Kosta</surname><given-names>V</given-names></name><name><surname>Marinovic Guic</surname><given-names>M</given-names></name><name><surname>Aljinovic</surname><given-names>J</given-names></name><name><surname>Grkovic</surname><given-names>I</given-names></name></person-group><article-title>Daily mini quizzes as means for improving student performance in anatomy course</article-title><source>Croatian Medical Journal</source><year>2009</year><volume>50</volume><fpage>55</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.3325/cmj.2009.50.55</pub-id><pub-id pub-id-type="pmid">19260145</pub-id></mixed-citation></ref><ref id="CR20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramani</surname><given-names>S</given-names></name></person-group><article-title>Twelve tips to promote excellence in medical teaching</article-title><source>Medical Teacher</source><year>2006</year><volume>28</volume><fpage>19</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1080/01421590500441786</pub-id><pub-id pub-id-type="pmid">16627316</pub-id></mixed-citation></ref><ref id="CR21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>Karpicke</surname><given-names>JD</given-names></name></person-group><article-title>The power of testing memory. Basic research an implications for educational practice</article-title><source>Perspectives on Psychological Science</source><year>2006</year><volume>1</volume><fpage>181</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1111/j.1745-6916.2006.00012.x</pub-id></mixed-citation></ref><ref id="CR22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>Karpicke</surname><given-names>JD</given-names></name></person-group><article-title>Test-enhanced learning: Taking memory tests improves long-term retention</article-title><source>Psychological Science</source><year>2006</year><volume>17</volume><fpage>249</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2006.01693.x</pub-id><pub-id pub-id-type="pmid">16507066</pub-id></mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vleuten</surname><given-names>CP</given-names></name><name><surname>Newble</surname><given-names>DI</given-names></name></person-group><article-title>How can we test clinical reasoning?</article-title><source>Lancet</source><year>1995</year><volume>345</volume><fpage>1032</fpage><lpage>1034</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(95)90763-7</pub-id><pub-id pub-id-type="pmid">7605439</pub-id></mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vleuten</surname><given-names>CP</given-names></name><name><surname>Schuwirth</surname><given-names>LW</given-names></name></person-group><article-title>Assessing professional competence: From methods to programmes</article-title><source>Medical Education</source><year>2005</year><volume>39</volume><fpage>309</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2929.2005.02094.x</pub-id><pub-id pub-id-type="pmid">15733167</pub-id></mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veloski</surname><given-names>J</given-names></name><name><surname>Boex</surname><given-names>JR</given-names></name><name><surname>Grasberger</surname><given-names>MJ</given-names></name><name><surname>Evans</surname><given-names>A</given-names></name><name><surname>Wolfson</surname><given-names>DB</given-names></name></person-group><article-title>Systematic review of the literature on assessment, feedback and physicians&#x02019; clinical performance: BEME Guide No. 7</article-title><source>Medical Teacher</source><year>2006</year><volume>28</volume><fpage>117</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1080/01421590600622665</pub-id><pub-id pub-id-type="pmid">16707292</pub-id></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>T</given-names></name></person-group><article-title>Assessment not only drives learning, it may also help learning</article-title><source>Medical Education</source><year>2009</year><volume>43</volume><fpage>5</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2923.2008.03237.x</pub-id><pub-id pub-id-type="pmid">19140992</pub-id></mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">World Medical Association Declaration of Helsinki: Ethical principles for medical research involving human subjects, adopted in 1964, readopted and revised in 2008, <ext-link ext-link-type="uri" xlink:href="http://www.wma.net/en/30publications/10policies/b3/17c.pdf">http://www.wma.net/en/30publications/10policies/b3/17c.pdf</ext-link>.</mixed-citation></ref></ref-list></back></article>