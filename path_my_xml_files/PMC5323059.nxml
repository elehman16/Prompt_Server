<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Clin Epidemiol</journal-id><journal-id journal-id-type="iso-abbrev">J Clin Epidemiol</journal-id><journal-title-group><journal-title>Journal of Clinical Epidemiology</journal-title></journal-title-group><issn pub-type="ppub">0895-4356</issn><issn pub-type="epub">1878-5921</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27663611</article-id><article-id pub-id-type="pmc">5323059</article-id><article-id pub-id-type="publisher-id">S0895-4356(16)30440-1</article-id><article-id pub-id-type="doi">10.1016/j.jclinepi.2016.09.004</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Mode of delivery affected questionnaire response rates in a birth cohort study</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bray</surname><given-names>Isabelle</given-names></name><email>Issy.Bray@uwe.ac.uk</email><xref rid="aff1" ref-type="aff">a</xref><xref rid="cor1" ref-type="corresp">&#x02217;</xref></contrib><contrib contrib-type="author"><name><surname>Noble</surname><given-names>Sian</given-names></name><xref rid="aff2" ref-type="aff">b</xref></contrib><contrib contrib-type="author"><name><surname>Robinson</surname><given-names>Ross</given-names></name><xref rid="aff3" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Molloy</surname><given-names>Lynn</given-names></name><xref rid="aff3" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Tilling</surname><given-names>Kate</given-names></name><xref rid="aff2" ref-type="aff">b</xref></contrib></contrib-group><aff id="aff1"><label>a</label>Department of Health and Social Science, University of the West of England, Frenchay Campus, Bristol BS16 1QY, England</aff><aff id="aff2"><label>b</label>School of Social and Community Medicine, University of Bristol, Canynge Hall, 39 Whatley Road, Bristol BS8 2PS, England</aff><aff id="aff3"><label>c</label>ALSPAC, School of Social and Community Medicine, University of Bristol, Oakfield House, Oakfield Grove, Bristol BS8 2BN, England</aff><author-notes><corresp id="cor1"><label>&#x02217;</label>Corresponding author. Tel.: +44 (0)117-3288923. <email>Issy.Bray@uwe.ac.uk</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>1</day><month>1</month><year>2017</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="ppub">.--><pub-date pub-type="ppub"><month>1</month><year>2017</year></pub-date><volume>81</volume><fpage>64</fpage><lpage>71</lpage><history><date date-type="accepted"><day>9</day><month>9</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; 2016 The Author(s)</copyright-statement><copyright-year>2016</copyright-year><license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0010"><sec><title>Objectives</title><p>Cohort studies must collect data from their participants as economically as possible, while maintaining response rates. This randomized controlled trial investigated whether offering a choice of online or paper questionnaires resulted in improved response rates compared with offering online first.</p></sec><sec><title>Study Design and Setting</title><p>Eligible participants were young people in the Avon Longitudinal Study of Parents and Children (ALSPAC) study (born April 1, 1991, to December 31, 1992, in the Avon area). After exclusions, 8,795 participants were randomized. The &#x0201c;online first&#x0201d; group were invited to complete the questionnaire online. The &#x0201c;choice&#x0201d; group were also sent a paper questionnaire and offered a choice of completion method. The trial was embedded within routine data collection. The main outcome measure was the number of questionnaires returned. Data on costs were also collected.</p></sec><sec><title>Results</title><p>Those in the &#x0201c;online first&#x0201d; arm of the trial were less likely to return a questionnaire [adjusted odds ratio: 0.90; 95% confidence interval (CI): 0.82, 0.99]. The &#x0201c;choice&#x0201d; arm was more expensive (mean difference per participant &#x000a3;0.71; 95% CI: &#x000a3;0.65, &#x000a3;0.76). It cost an extra &#x000a3;47 to have one extra person to complete the questionnaire in the &#x0201c;choice&#x0201d; arm.</p></sec><sec><title>Conclusion</title><p>Offering a choice of completion methods (paper or online) for questionnaires in ALSPAC increased response rates but was more expensive than offering online first.</p></sec></abstract><kwd-group id="kwrds0010"><title>Keywords</title><kwd>Randomized controlled trial</kwd><kwd>Online questionnaire</kwd><kwd>Response rates</kwd><kwd>Cohort study</kwd><kwd>ALSPAC</kwd><kwd>Mixed mode</kwd></kwd-group></article-meta></front><body><p><boxed-text id="dtbox1"><caption><title>What is new?</title></caption><p><list list-type="simple"><title>Key findings</title><list-item id="u0010"><label>&#x02022;</label><p>In this birth cohort study, offering a choice of online/paper questionnaire (concurrent mixed mode) resulted in higher response rates than offering online-only first (sequential mixed mode).</p></list-item></list><list list-type="simple"><title>What this adds to what was known?</title><list-item id="u0015"><label>&#x02022;</label><p>Cohort studies administering questionnaires should weigh this benefit in terms of response rates against the increase in cost associated with offering a choice.</p></list-item></list><list list-type="simple"><title>What is the implication and what should change now?</title><list-item id="u0020"><label>&#x02022;</label><p>This trial should be replicated in other cohorts of different ages, considering the effects in different demographic subgroups.</p></list-item></list></p></boxed-text></p><sec id="sec1"><label>1</label><title>Introduction</title><p>As the fields of lifecourse epidemiology and epigenetics develop, multigenerational birth cohort studies are becoming increasingly important to health and social research <xref rid="bib1" ref-type="bibr">[1]</xref>, <xref rid="bib2" ref-type="bibr">[2]</xref>. Initial response rates to population cohort studies have decreased over recent decades, and such studies experience declining participation rates throughout the lifetime of the study <xref rid="bib3" ref-type="bibr">[3]</xref>. Selection and attrition bias therefore threaten the validity and viability of large cohort studies. Reasons for attrition are generally divided into (1) failure to locate (i.e., address changes), (2) failure to contact, and (3) refusal to participate. There is a considerable literature around the best methods to keep up-to-date addresses for study participants, often referred to as &#x0201c;tracking&#x0201d; (e.g., <xref rid="bib4" ref-type="bibr">[4]</xref>, <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib6" ref-type="bibr">[6]</xref>). Failure to contact is most relevant to studies which seek face-to-face contact for data collection (e.g., the UK Household Longitudinal Survey). Maximizing participation, whether that be participating in an interview, attending a clinic, or completing a questionnaire, is crucial to the success of any cohort study. The approach taken by individual cohort studies is usually based on shared experience of best practice <xref rid="bib7" ref-type="bibr">[7]</xref>, although randomized controlled trials (RCTs) are increasingly being used to assess methods to improve response rates in cohort studies, for example, Boyd et&#x000a0;al. <xref rid="bib8" ref-type="bibr">[8]</xref>. Booker et&#x000a0;al. <xref rid="bib9" ref-type="bibr">[9]</xref> carried out a systematic review of various retention methods used by population cohort studies and concluded that incentives boost retention, but that the other methods they assessed (e.g., reminders, alternative methods of data collection) had not been sufficiently evaluated. Only 11 (39%) of the 28 studies included in the review were RCTs of methods for cohort retention. This highlights the lack of evidence about which cohort retention methods are most effective. There is better evidence about measures to improve response rates to questionnaires <xref rid="bib10" ref-type="bibr">[10]</xref>. For example, the use of incentives has been shown to improve response rates to electronic health surveys <xref rid="bib11" ref-type="bibr">[11]</xref>.</p><p>The Avon Longitudinal Study of Parents and Children (ALSPAC) is a birth cohort study which is following up children born in a 21-month period in 1991&#x02013;1992. Questionnaire data in ALSPAC have traditionally been collected by postal questionnaires. For large cohort studies, particularly in times of austerity, online data collection is a financially attractive option <xref rid="bib12" ref-type="bibr">[12]</xref>. It is also assumed to appeal to younger participants, whom have grown up in an electronic age and for whom mobile devices and social media are integral to their lives <xref rid="bib13" ref-type="bibr">[13]</xref>. Although online methods have been used for some data collection exercises in ALSPAC, the reported response rates <xref rid="bib14" ref-type="bibr">[14]</xref> suggest that participants are not ready to move to an online-only model, and the main questionnaires until 2012 were all administered on paper. But, like some other cohort studies, for example, Growing up Today (<ext-link ext-link-type="uri" xlink:href="http://www.gutsweb.org/" id="intref0010">http://www.gutsweb.org/</ext-link>), ALSPAC is seeking to move its participants toward online questionnaire completion for a variety of reasons. The main drivers are presumed improved response rates and reduced costs. The online approach is also expected to speed up the process of questionnaire administration and data entry, improve data accuracy, and reduce environmental costs. The anticipated improvements from the participants' point of view include choice about how and when to complete the questionnaire (particularly as functionality on Smartphones improves) and instant and easy submission of data (reducing unwanted reminders and the need to find a postbox).</p><p>However, there are concerns about using an online-only approach for data collection. Evidence from both market research <xref rid="bib15" ref-type="bibr">[15]</xref> and health-related research <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref> suggests that it will lead to lower response rates than traditional paper questionnaires. Furthermore, online data collection could exacerbate the bias toward more educated participants that typically arises through selection and attrition in cohort studies, as those with less access to the Internet might be discouraged from taking part <xref rid="bib18" ref-type="bibr">[18]</xref>, <xref rid="bib19" ref-type="bibr">[19]</xref>. In practice, however, online data collection in cohort studies is likely to be followed up with an option to complete a paper version (a sequential mixed-mode approach). The use of multiple methods of data collection in surveys has been debated <xref rid="bib20" ref-type="bibr">[20]</xref> and may even reduce response rates <xref rid="bib21" ref-type="bibr">[21]</xref> but is reported to have the potential to achieve similar response rates to those of traditional postal questionnaires <xref rid="bib22" ref-type="bibr">[22]</xref>. There is ongoing discussion in the survey literature about the relative merits of concurrent and sequential mixed-mode approaches <xref rid="bib23" ref-type="bibr">[23]</xref>, with some authors suggesting that a sequential approach is superior <xref rid="bib24" ref-type="bibr">[24]</xref>. At the same time, there is a paucity of evidence comparing concurrent and sequential mixed-mode approaches in population cohort studies administering lengthy questionnaires <xref rid="bib19" ref-type="bibr">[19]</xref>. We have conducted a nested RCT comparing an &#x0201c;online first&#x0201d; (sequential mixed mode) arm with a &#x0201c;choice&#x0201d; (concurrent mixed mode) arm, in a routine follow-up of a birth cohort (aged 21&#x000a0;years at the time of the RCT). We compared the two approaches in terms of response rates, completion rates, and costs, including administrative time.</p></sec><sec id="sec2"><label>2</label><title>Methods</title><sec id="sec2.1"><label>2.1</label><title>ALSPAC cohort</title><p>ALSPAC recruited 14,541 pregnant women resident in Avon, UK, with expected dates of delivery April 1, 1991, to December 31, 1992; 14,541 is the initial number of pregnancies for which the mother enrolled in the ALSPAC study and had either returned at least one questionnaire or attended a &#x0201c;Children in Focus&#x0201d; clinic by July 19, 1999. Of these initial pregnancies, there was a total of 14,676 fetuses, resulting in 14,062 live births and 13,988 children who were alive at 1&#x000a0;year of age.</p><p>When the oldest children were approximately 7&#x000a0;years of age, an attempt was made to bolster the initial sample with eligible cases who had failed to join the study originally. As a result, when considering variables collected from the age of 7 years onward (and potentially abstracted from obstetric notes), there are data available for more than the 14,541 pregnancies mentioned above. Further phases of enrollment are described in more detail in the cohort profile <xref rid="bib14" ref-type="bibr">[14]</xref>.</p><p>The total sample size for analyses using any data collected after the age of 7 years is therefore 15,247 pregnancies, resulting in 15,458 fetuses. Of this total sample of 15,458 fetuses, 14,775 were live births and 14,701 were alive at 1&#x000a0;year of age. These children, now young people (YP) of around 24&#x000a0;years of age, and their parents (or step parents) have been followed in detail until the present day. Please note that the study website contains details of all the data that is available through a fully searchable data dictionary (<ext-link ext-link-type="uri" xlink:href="http://www.bristol.ac.uk/alspac/researchers/data-access/data-dictionary/" id="intref0015">http://www.bristol.ac.uk/alspac/researchers/data-access/data-dictionary/</ext-link>).</p></sec><sec id="sec2.2"><label>2.2</label><title>Subjects</title><p>We devised a parallel-group RCT for the 2012 YPs' questionnaire [called &#x0201c;It's All About You (20+)&#x0201d;]. The study participants included in this data collection exercise are all YPs eligible to receive the questionnaire planned for 2012. Exclusions were due to death, withdrawal from the study, a noncontact status flag on the study database (e.g., due to family problems or bereavement), because returned mail has previously indicated that ALSPAC does not have the correct address, or because they have opted out of questionnaires. The &#x0201c;online first&#x0201d; arm of the trial received a letter with a link to the online questionnaire. The &#x0201c;choice&#x0201d; arm of the trial also received a letter with a link to the online questionnaire, in addition to a paper copy of the questionnaire (with prepaid return envelope) so that a choice of method was offered. Participants were not aware of the trial, as it was carried out as part of routine data collection.</p><p>Assuming an expected response rate of 50% (based on previous YP questionnaires), it was calculated that 1,605 participants in each arm of the trial would have 80% power to detect a difference in response rates of 5% between the two arms.</p></sec><sec id="sec2.3"><label>2.3</label><title>Paper questionnaire</title><p>The paper version of the questionnaire was an A5 booklet of 44 pages. Excluding the three administrative questions at the end, there were five sections: &#x0201c;Children of the 90s&#x0201d;; &#x0201c;Gambling&#x0201d;; &#x0201c;Deliberate Self-Harm&#x0201d;; &#x0201c;Employment, Education and Training&#x0201d;; and &#x0201c;Tobacco and Alcohol.&#x0201d; The number of questions in each section ranged from 7 to 43 (median 17), but many of these questions had several parts. Skip statements were used to divert participants around questions that were not relevant to them. The number of questions in each section that were followed by a skip statement ranged from 1 to 9 (median 5).</p></sec><sec id="sec2.4"><label>2.4</label><title>Online questionnaire</title><p>The online questionnaire was designed to be as similar as possible to the paper questionnaire, acknowledging that certain functions, such as skip statements, would be different because participants would be automatically directed to the next relevant question. This also affected the numbering of questions, which would have been nonconsecutive if not allowed to be dynamic in the online version.</p><p>Generally, the number of questions per page was less in the online version than in the paper version. The ability to have a variable page length was one of the key differences between paper and online as it allowed more logical grouping of questions. Finally, for online completion, an approximate progress indicator bar was given for each section.</p></sec><sec id="sec2.5"><label>2.5</label><title>Reminders and compensation</title><p>The reminder schedule was the same for both arms of the trial (<xref rid="tbl1" ref-type="table">Table&#x000a0;1</xref>). The first reminder (after 3&#x000a0;weeks) was by email, but if an email address was not recorded and a mobile number was on record, then a text was used. If neither electronic means of contact was possible, then a postcard reminder was used. Two weeks later, a different mode of reminder was sent (unless a postcard had already been used in which case no other reminder was sent, to avoid multiple reminders of the same method). Eight weeks after the initial letter, a reminder letter was sent to all nonrespondents, with a paper copy of the questionnaire enclosed. Another brief reminder (email, text, or postcard) was sent if necessary 2&#x000a0;weeks later. A Facebook reminder was also posted 12&#x000a0;weeks after the original letter. Finally, a phone call reminder was attempted for all those who had not responded between 12 and 19&#x000a0;weeks after the initial letter was sent out. Initially, an attempt was made to contact the participant using the landline number held on record. If this was not successful and if a mobile number was also recorded, then this number was also rung. If neither attempt was successful, then a message was left on both landline and mobile phones, wherever possible. If contact was made with a family member but the participant was not at home, then a message was left.</p><p>A reminder was sent only if a paper questionnaire had not been received from the participant and the online submission was not complete (i.e., at least one section of the questionnaire had not been submitted online). The exception to this was the reminder at 8&#x000a0;weeks enclosing a paper questionnaire&#x02014;this was only sent if a paper questionnaire had not been received and an online submission had not been initiated (i.e., no sections had been submitted online). If a participant contacted ALSPAC to request a paper questionnaire at any stage in the process, then this was recorded and one was sent.</p><p>A &#x000a3;10 Amazon voucher was offered to compensate participants for their time and to encourage response.</p></sec><sec id="sec2.6"><label>2.6</label><title>Pilot study</title><p>To test that both arms of the trial and the reminder process, which was more intensive than any used previously in ALSPAC, were acceptable to participants, and to identify any logistical problems, the RCT was piloted on 200 participants. To maximize the efficiency of the pilot study, we chose participants with a high probability of responding. They were randomly chosen from among those who had responded to the YP questionnaire administered around age 18&#x000a0;years. These YPs were then assigned to each arm of the trial using simple randomization. Because it was important to complete the pilot quickly, to administer the main questionnaire on schedule, the reminders were issued at 2 weekly intervals rather than the timeframe set out in <xref rid="tbl1" ref-type="table">Table&#x000a0;1</xref>. This was not felt to detract from the usefulness of the pilot study in testing the acceptability of the strategy as, if anything, more frequent reminders would be received less positively by participants.</p></sec><sec id="sec2.7"><label>2.7</label><title>Randomization</title><p>The remaining YPs were randomly assigned with equal probability to either the &#x0201c;online first&#x0201d; arm or the &#x0201c;choice&#x0201d; arm. Randomization was stratified on important confounders&#x02014;national tertiles of Index of Multiple Deprivation (IMD) score 2010, based on postcode <xref rid="bib25" ref-type="bibr">[25]</xref>, gender, and level of participation (&#x0003c;90% or &#x02265;90% participation calculated over the course of the study). The 200 participants in the pilot phase were excluded.</p><p>Randomization of participants was carried out using the runiform function in Stata with anonymous identifiers. This was performed by a researcher who was not involved with the ALSPAC administration process. The results of the randomization were passed to the questionnaire administration team, who implemented the mailings and reminders for both arms of the trial.</p></sec><sec id="sec2.8"><label>2.8</label><title>Outcome measures</title><p>The primary outcome measure was the number of questionnaires returned (with at least one question answered) in each arm of the trial. For the purposes of this analysis, return rates were calculated 30&#x000a0;weeks after the initial mailing.</p><p>A secondary outcome was completeness of questionnaires. For returned questionnaires, the number of questions answered was compared, to see if either approach (online first or choice of online/paper questionnaire) encouraged more complete responses. ALSPAC staff compiling the completion statistics were blinded to group assignment. Of the 314 possible questions included in the full questionnaire, 109 of these were not dependent on skip statements, and the analysis of completeness was repeated for this core subset of questions.</p><p>Other secondary outcomes included: mode of response (online or paper); time taken to respond; the number of reminders issued; and requests for paper questionnaires.</p><p>Resources used in the administration of each arm of the trial were identified. These included: printing, packing and posting of letters and questionnaires (including address labels and envelopes); printing and posting of reminder postcards; and text and phone call reminders. The amount of administrative time spent on individual calls and texts was based on an average for a sample of these communications spread over time.</p><p>Costs were applied to these resources. Administration time was valued using the wage rate per minute for casual staff. Consumables (e.g., printing, labels, paper, postage) were valued on a per item basis. Resources were only compared where there was a difference in costs between the two arms. Setup costs, for example, creation of database, design of questionnaire, and design of the data entry form, were not included as both the online version and the paper-based version had to be available for both arms in this trial. Some of the higher level administration costs (which included the time to send emails) for each stage of the reminder processes were also excluded as they were the same across both arms. The actual costs of telephone calls were also excluded because business telephone packages are based on a monthly fee.</p></sec><sec id="sec2.9"><label>2.9</label><title>Analysis</title><p>Analysis was carried out on an intention-to-treat basis. Logistic and robust multiple linear regression was used to compare responses, and other secondary outcomes, between the two arms of the trial, adjusting for stratification variables (gender, previous participation score, IMD tertile).</p><p>The mean cost per participant for each item of resource use for the two arms of the trial was calculated as the mean resource use per participant multiplied by the unit cost for that resource. The total mean cost per participant for the two arms of the trial was then calculated by summing up the individual cost items and dividing by the number of participants in each arm. An estimate of the extra cost to have one extra person to complete a questionnaire was calculated as the difference in total costs between the two arms divided by the difference in the number of people who completed a questionnaire, defined as completed at least one question.</p></sec><sec id="sec2.10"><label>2.10</label><title>Ethical approval</title><p>Ethical approval was obtained from the ALSPAC Ethics and Law Committee (ref: E201215).</p></sec></sec><sec id="sec3"><label>3</label><title>Results</title><sec id="sec3.1"><label>3.1</label><title>Pilot</title><p>Overall, response rates were very similar in both arms of the pilot trial&#x02014;84% in the &#x0201c;online first&#x0201d; arm and 81% in the &#x0201c;choice&#x0201d; arm&#x02014;with no evidence of a difference (<italic>P</italic>&#x000a0;=&#x000a0;0.6), suggesting that the planned RCT would not have a detrimental effect on response rates. These percentages are based on 100 participants in each arm and a cutoff of approximately 24&#x000a0;weeks after the initial mailing. As expected, the number of responses that were submitted online was greater in the &#x0201c;online first&#x0201d; arm (69) than in the &#x0201c;choice&#x0201d; arm (37). ALSPAC monitored feedback from participants and concluded that both arms of the trial and the reminder process were acceptable to participants.</p></sec><sec id="sec3.2"><label>3.2</label><title>Numbers of participants in the RCT</title><p>A flow diagram of participant numbers in the RCT is shown in <xref rid="fig1" ref-type="fig">Fig.&#x000a0;1</xref>. Excluding those in the pilot exercise and who could not be included for the other reasons listed in the Section <xref rid="sec2" ref-type="sec">2</xref>, a total of 8,795 participants were available for randomization, exceeding the required sample size. Of these, 329 (3.7%) had missing IMD score so were randomly assigned to an IMD category (tertile). The stratified randomization resulted in an equal number of participants in each arm of the trial (4,398 in the &#x0201c;online first&#x0201d; arm and 4,397 in the &#x0201c;choice&#x0201d; arm) and an equal distribution of stratification variables in each arm (49% male, 19% most deprived tertile, 50% least deprived tertile, 67% with a lower than 90% participation score). Before participants were mailed, a final check was made of their status flags on the study database. It was discovered that 13 participants in the &#x0201c;online first&#x0201d; arm (0.3%) and 17 in the &#x0201c;choice&#x0201d; arm (0.4%) were not eligible (e.g., due to changes in family circumstances or requests not to be contacted) and were therefore not mailed, but were included in this analysis, which was conducted on an intention-to-treat basis. Conversely, some participants who were not originally randomized went on to complete a questionnaire, but are not included in the analysis. The numbers of reminders sent at each reminder stage are shown in <xref rid="appsec1" ref-type="sec">Supplementary Table&#x000a0;1</xref> at <ext-link ext-link-type="uri" xlink:href="http://www.jclinepi.com" id="intref0020">www.jclinepi.com</ext-link>. At each stage, and for each mode (e.g., email, text, postcard), more reminders were sent in the &#x0201c;online first&#x0201d; arm (<italic>P</italic>&#x000a0;&#x0003c;&#x000a0;0.05).</p></sec><sec id="sec3.3"><label>3.3</label><title>Primary and secondary outcome measures</title><p><xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref> shows the number of questionnaires returned in each arm of the trial. Having adjusted for the stratification variables, participants in the &#x0201c;online first&#x0201d; arm were 10% less likely to return a questionnaire than those offered a choice [adjusted odds ratio&#x000a0;=&#x000a0;0.90; 95% confidence interval (CI): 0.82, 0.99; <italic>P</italic>&#x000a0;=&#x000a0;0.04].</p><p>The mean time to respond (by postal questionnaire or a section submitted online) was 3.5&#x000a0;days shorter in the &#x0201c;online first&#x0201d; arm than in the &#x0201c;choice&#x0201d; arm of the trial (95% CI: 1.2, 5.9; <italic>P</italic>&#x000a0;=&#x000a0;0.003). Other secondary outcomes are shown in <xref rid="appsec1" ref-type="sec">Supplementary Tables&#x000a0;2 and 3</xref> at <ext-link ext-link-type="uri" xlink:href="http://www.jclinepi.com" id="intref0025">www.jclinepi.com</ext-link>.</p></sec><sec id="sec3.4"><label>3.4</label><title>Economic analysis</title><p>A detailed economic breakdown for each arm of the trial is given in <xref rid="appsec1" ref-type="sec">Supplementary Table&#x000a0;4</xref> at <ext-link ext-link-type="uri" xlink:href="http://www.jclinepi.com" id="intref0030">www.jclinepi.com</ext-link>, including the costs associated with each type of reminder. The mean cost per participant was &#x000a3;3.14 (95% CI: &#x000a3;3.10, &#x000a3;3.18) in the &#x0201c;choice&#x0201d; arm and &#x000a3;2.43 (95% CI: &#x000a3;2.39, &#x000a3;2.47) in the &#x0201c;online first&#x0201d; arm. Adjusting for the stratification variables, this led to a mean difference per participant of &#x000a3;0.71 (95% CI: &#x000a3;0.65, &#x000a3;0.76). The total cost was &#x000a3;13,792 in the &#x0201c;choice&#x0201d; arm and &#x000a3;10,690 in the &#x0201c;online first&#x0201d; arm. Hence, it cost an extra &#x000a3;47 to have one extra person to complete the questionnaire in the &#x0201c;choice&#x0201d; arm.</p></sec></sec><sec id="sec4"><label>4</label><title>Discussion</title><sec id="sec4.1"><label>4.1</label><title>Summary of main findings</title><p>In an RCT of two approaches to questionnaire completion in a population cohort study, we found that response rates were higher in the group offered a choice of online or paper questionnaire from the outset compared with those initially offered only online completion and that offering a choice of method cost an average of &#x000a3;0.71 more per participant than offering only online completion. The additional cost per completed questionnaire in the group offered a choice was &#x000a3;47.</p></sec><sec id="sec4.2"><label>4.2</label><title>What this adds to previous research</title><p>The effects of offering alternative methods of data collection have not been sufficiently evaluated in cohort studies <xref rid="bib9" ref-type="bibr">[9]</xref>. There is a body of evidence about maximizing response rates to postal questionnaires in the survey literature. A Cochrane Review identified 110 methods of increasing response rates to postal questionnaires <xref rid="bib10" ref-type="bibr">[10]</xref>, many of which were found to improve response rates, including providing a second copy of the questionnaire at follow-up. A systematic review of cost-effectiveness of sample size maintenance programs in studies involving postal questionnaires revealed that insufficient economic information was reported to draw any general conclusions <xref rid="bib26" ref-type="bibr">[26]</xref>. Edwards et&#x000a0;al. <xref rid="bib10" ref-type="bibr">[10]</xref> found that some of the methods found to increase response rates to postal questionnaires also applied to electronic questionnaires, and other methods were also found to be effective (including a statement that others had responded, lottery with immediate notification of results, and offer of survey results). For both paper and online questionnaires Edwards et&#x000a0;al. <xref rid="bib10" ref-type="bibr">[10]</xref> found substantial heterogeneity among trial results for half of the methods evaluated. This probably reflects the fact that &#x0201c;what works&#x0201d; is very context specific&#x02014;depending on the type of the study, the country, the characteristics of the sample and how they were selected, and their expectations regarding study involvement.</p><p>The effectiveness of electronic questionnaires for data collection in cohort studies may differ from that in cross-sectional studies, and the use of online questionnaires as a primary data collection method in this setting has been relatively limited <xref rid="bib12" ref-type="bibr">[12]</xref>. Nevertheless, they offer a potentially cost-effective way to collect data from participants and evidence from existing cohort studies in encouraging. The US Millenium Cohort Study of families associated with US Defense reported that, when given a choice, over 50% of participants chose to enroll online and that those who responded online provided more complete contact information <xref rid="bib27" ref-type="bibr">[27]</xref>. An obvious drawback of electronic data collection is that not everyone has access to a computer, potentially introducing bias. In a study of Swedish women aged 30&#x02013;49&#x000a0;years, Ekman et&#x000a0;al. <xref rid="bib28" ref-type="bibr">[28]</xref> assessed the feasibility of using online questionnaires in large population-based epidemiological studies. They concluded that the bias associated with using online questionnaires was not greater than that caused by paper questionnaires and that web-based questionnaires are a feasible tool for data collection in this setting. van Gelder et&#x000a0;al. <xref rid="bib29" ref-type="bibr">[29]</xref> summarize the advantages and disadvantages of online questionnaires for epidemiological studies and conclude that they could be considered an alternative or complementary mode of data collection, compared with the methods traditionally used by cohort studies, of paper questionnaires and face-to-face interviews.</p><p>It seems likely that a mixed-mode approach (i.e., using both paper questionnaires and online questionnaires) will be important in the gradual shift from paper to online data collection in cohort studies. Although there has been much debate in the survey literature on whether a concurrent or sequential mixed-mode approach is better <xref rid="bib23" ref-type="bibr">[23]</xref>, there is less evidence about this in the context of population cohort studies <xref rid="bib19" ref-type="bibr">[19]</xref>. The YP in the ALSPAC study, born 1990&#x02013;1991, are an ideal cohort on which to evaluate the effect of offering an online questionnaire first, compared with offering a choice of online or paper questionnaire completion. People of this age are highly mobile, and we anticipate that an online strategy will be key to maintaining their involvement in the future, but the implications for response rates of online data collection are not clear from the existing literature.</p><p>In this trial, we found that response rates were 10% lower among participants in the &#x0201c;online first&#x0201d; arm, compared with those offered a choice of online or paper completion.</p></sec><sec id="sec4.3"><label>4.3</label><title>Limitations</title><p>Due to attrition throughout the 21&#x000a0;years of the study, the cohort included in this study is not representative of the initial ALSPAC cohort or of the general population. The effects of attrition bias are documented elsewhere <xref rid="bib14" ref-type="bibr">[14]</xref>.</p><p>There were pragmatic differences between the two arms which reduced their comparability. For example, the questionnaire layout was not identical in the two methods (paper/online), and reminders and the compensatory gift voucher were not triggered in exactly the same way.</p><p>No complaints about the questionnaire or reminder process were received. However, a small number of participants (thirteen) reported having difficulties logging on to complete the questionnaire online. Considerable numbers contacted the study to report that they had lost their login details (256) or that never received them (115). Although login details were provided when such cases were reported, it is conceivable that these problems might have resulted in reducing the number of participants who chose to complete the questionnaire online, thereby possibly reducing the efficacy of the &#x0201c;online first&#x0201d; arm of the trial.</p><p>Another important limitation is that the invitation to complete the online questionnaire was by post rather than by email (which would make it easier to access). This was because, at the time of this questionnaire, email addresses were not routinely held for participants. As such contact details are updated, it will be possible to send out invitations by email, which may increase the number of people accessing the online questionnaire and will certainly reduce costs.</p><p>Finally, we note that this is a rapidly evolving field and that a limitation of any research in this field is the speed with which technology evolves. For example, the effectiveness of online data collection may be quite dependent on not only the proportion of the cohort who own a Smartphone but also on the functionality of online questionnaires when completed on Smartphones. It is a challenge for methodological research to keep up with new and emerging data collection tools <xref rid="bib30" ref-type="bibr">[30]</xref>.</p></sec><sec id="sec4.4"><label>4.4</label><title>Recommendations for further work</title><p>Future work should attempt to replicate research into optimal approaches to mixed-mode data collection published in the survey methodology literature in the context of cohort studies, where a more cautious approach to experimentation has been noted <xref rid="bib19" ref-type="bibr">[19]</xref>.</p><p>Further studies should assess the effectiveness of different types of reminders. In this study, the reminder method was dependent on the contact details available, but ideally, participants would be randomized to different reminder methods to assess their relative impact on response rates (see, e.g., <xref rid="bib22" ref-type="bibr">[22]</xref>).</p><p>It is important to establish whether these results are generalizable to cohorts of other ages, such as the parents in the ALSPAC study. Future cohort studies could then tailor the contact method to different demographic groups.</p></sec></sec><sec id="sec5"><label>5</label><title>Conclusions</title><p>Based on the findings of this RCT, embedded in a population cohort study, we conclude that there is some benefit in offering a choice of completion methods (concurrent mixed mode) compared with offering online-only first (sequential mixed mode) to maximize response rates to questionnaires. The results are likely to be generalizable to other cohorts of similar age and will help cohort studies weigh up the extra cost against anticipated improvements in response rates.</p></sec></body><back><ref-list id="cebib0010"><title>References</title><ref id="bib1"><label>1</label><element-citation publication-type="journal" id="sref1"><person-group person-group-type="author"><name><surname>Ben-Shlomo</surname><given-names>Y.</given-names></name><name><surname>Kuh</surname><given-names>D.</given-names></name></person-group><article-title>A lifecourse approach to chronic disease epidemiology; conceptual models, empirical challenges and interdisciplinary perspectives</article-title><source>Int J Epidemiol</source><volume>31</volume><year>2002</year><fpage>285</fpage><lpage>293</lpage><pub-id pub-id-type="pmid">11980781</pub-id></element-citation></ref><ref id="bib2"><label>2</label><element-citation publication-type="journal" id="sref2"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>J.</given-names></name><name><surname>Barrett</surname><given-names>L.M.</given-names></name><name><surname>Wong</surname><given-names>A.</given-names></name><name><surname>Kuh</surname><given-names>D.</given-names></name><name><surname>Davey Smith</surname><given-names>G.</given-names></name><name><surname>Relton</surname><given-names>C.L.</given-names></name></person-group><article-title>The role of longitudinal cohort studies in epigenetics epidemiology: challenges and opportunities</article-title><source>Genome Biol</source><volume>13</volume><year>2012</year><fpage>246</fpage><pub-id pub-id-type="pmid">22747597</pub-id></element-citation></ref><ref id="bib3"><label>3</label><element-citation publication-type="journal" id="sref3"><person-group person-group-type="author"><name><surname>Pirius</surname><given-names>C.</given-names></name><name><surname>Leridon</surname><given-names>H.</given-names></name></person-group><article-title>Large child cohort studies across the world</article-title><source>Population</source><volume>65</volume><issue>4</issue><year>2010</year><fpage>575</fpage><lpage>629</lpage></element-citation></ref><ref id="bib4"><label>4</label><element-citation publication-type="journal" id="sref4"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>J.R.</given-names></name><name><surname>White</surname><given-names>E.</given-names></name></person-group><article-title>Retaining and tracking cohort study members</article-title><source>Epidemiologic Rev</source><volume>20</volume><year>1998</year><fpage>57</fpage><lpage>70</lpage></element-citation></ref><ref id="bib5"><label>5</label><element-citation publication-type="book" id="sref5"><person-group person-group-type="author"><name><surname>Calderwood</surname><given-names>L.</given-names></name></person-group><chapter-title>Keeping in touch with mobile families in the UK Millenium Cohort Study</chapter-title><year>2010</year><publisher-name>Centre for Longitudinal Studies</publisher-name><publisher-loc>London</publisher-loc><comment>CLS Working Paper 2010/7</comment></element-citation></ref><ref id="bib6"><label>6</label><element-citation publication-type="journal" id="sref6"><person-group person-group-type="author"><name><surname>Calderwood</surname><given-names>L.</given-names></name></person-group><article-title>Tracking sample members in longitudinal studies</article-title><source>Surv Pract</source><volume>5</volume><issue>4</issue><year>2013</year></element-citation></ref><ref id="bib7"><label>7</label><element-citation publication-type="journal" id="sref7"><person-group person-group-type="author"><name><surname>Golding</surname><given-names>J.</given-names></name><name><surname>Birmingham</surname><given-names>K.</given-names></name></person-group><article-title>Enrolment and response rates in a longitudinal birth cohort</article-title><source>Paediatr Perinat Epidemiol</source><volume>23</volume><year>2008</year><fpage>73</fpage><lpage>85</lpage></element-citation></ref><ref id="bib8"><label>8</label><element-citation publication-type="journal" id="sref8"><person-group person-group-type="author"><name><surname>Boyd</surname><given-names>A.</given-names></name><name><surname>Tilling</surname><given-names>K.</given-names></name><name><surname>Cornish</surname><given-names>R.</given-names></name><name><surname>Davies</surname><given-names>A.</given-names></name><name><surname>Humphries</surname><given-names>K.</given-names></name><name><surname>Macleod</surname><given-names>J.</given-names></name></person-group><article-title>Professionally designed information materials and telephone reminders improved consent response rates</article-title><source>J Clin Epidemiol</source><volume>68</volume><year>2015</year><fpage>877</fpage><lpage>887</lpage><pub-id pub-id-type="pmid">25920944</pub-id></element-citation></ref><ref id="bib9"><label>9</label><element-citation publication-type="journal" id="sref9"><person-group person-group-type="author"><name><surname>Booker</surname><given-names>C.L.</given-names></name><name><surname>Harding</surname><given-names>S.</given-names></name><name><surname>Benzeval</surname><given-names>M.</given-names></name></person-group><article-title>A systematic review of the effect of retention methods in population-based cohort studies</article-title><source>BMC Public Health</source><volume>11</volume><year>2011</year><fpage>249</fpage><pub-id pub-id-type="pmid">21504610</pub-id></element-citation></ref><ref id="bib10"><label>10</label><element-citation publication-type="journal" id="sref10"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>P.J.</given-names></name><name><surname>Roberts</surname><given-names>I.</given-names></name><name><surname>Clarke</surname><given-names>M.J.</given-names></name><name><surname>DiGuiseppi</surname><given-names>C.</given-names></name><name><surname>Wentz</surname><given-names>R.</given-names></name><name><surname>Kwan</surname><given-names>I.</given-names></name></person-group><article-title>Methods to increase response to postal and electronic questionnaires</article-title><source>Cochrane Database Syst Rev</source><year>2009</year><fpage>MR000008</fpage><pub-id pub-id-type="pmid">19588449</pub-id></element-citation></ref><ref id="bib11"><label>11</label><element-citation publication-type="journal" id="sref11"><person-group person-group-type="author"><name><surname>David</surname><given-names>M.C.</given-names></name><name><surname>Ware</surname><given-names>R.S.</given-names></name></person-group><article-title>Meta-analysis of randomised controlled trials supports the use of incentives for inducing response to electronic health surveys</article-title><source>J Clin Epidemiol</source><volume>67</volume><year>2014</year><fpage>1210</fpage><lpage>1221</lpage><pub-id pub-id-type="pmid">25216899</pub-id></element-citation></ref><ref id="bib12"><label>12</label><element-citation publication-type="journal" id="sref12"><person-group person-group-type="author"><name><surname>Calderwood</surname><given-names>L.</given-names></name></person-group><article-title>The use of new technologies on the British birth cohort studies</article-title><source>Int J Market Res</source><volume>55</volume><issue>4</issue><year>2013</year><fpage>590</fpage><lpage>595</lpage></element-citation></ref><ref id="bib13"><label>13</label><mixed-citation publication-type="other" id="sref30">Roberts VJ, Foehr UG, Rideout DF, Generation M2; Media in the lives of 8- to 18-year-olds, Kaiser Family Foundation. Available at: <ext-link ext-link-type="uri" xlink:href="http://kaiserfamilyfoundation.files.wordpress.com/2013/04/8010.pdf" id="interref0010">http://kaiserfamilyfoundation.files.wordpress.com/2013/04/8010.pdf</ext-link>. Accessed January 29, 2016.</mixed-citation></ref><ref id="bib14"><label>14</label><element-citation publication-type="journal" id="sref13"><person-group person-group-type="author"><name><surname>Boyd</surname><given-names>A.</given-names></name><name><surname>Golding</surname><given-names>J.</given-names></name><name><surname>Macleod</surname><given-names>J.</given-names></name><name><surname>Lawlor</surname><given-names>D.A.</given-names></name><name><surname>Fraser</surname><given-names>A.</given-names></name><name><surname>Henderson</surname><given-names>J.</given-names></name></person-group><article-title>Cohort Profile: the 'children of the 90s'--the index offspring of the Avon Longitudinal Study of Parents and Children</article-title><source>Int J Epidemiol</source><volume>42</volume><year>2013</year><fpage>111</fpage><lpage>127</lpage><pub-id pub-id-type="pmid">22507743</pub-id></element-citation></ref><ref id="bib15"><label>15</label><element-citation publication-type="journal" id="sref14"><person-group person-group-type="author"><name><surname>Lozar</surname><given-names>K.</given-names></name><name><surname>Bosnjak</surname><given-names>M.</given-names></name><name><surname>Berzelak</surname><given-names>J.</given-names></name><name><surname>Haas</surname><given-names>I.</given-names></name><name><surname>Vehovar</surname><given-names>V.</given-names></name></person-group><article-title>Web surveys versus other survey modes: a meta-analysis comparing response rates</article-title><source>Int J Market Res</source><volume>50</volume><issue>1</issue><year>2008</year><fpage>79</fpage><lpage>104</lpage></element-citation></ref><ref id="bib16"><label>16</label><element-citation publication-type="journal" id="sref15"><person-group person-group-type="author"><name><surname>Cantrell</surname><given-names>M.</given-names></name><name><surname>Lupinacci</surname><given-names>P.</given-names></name></person-group><article-title>Methodological issues in online data collection</article-title><source>J Adv Nurs</source><volume>60</volume><year>2007</year><fpage>544</fpage><lpage>549</lpage><pub-id pub-id-type="pmid">17973718</pub-id></element-citation></ref><ref id="bib17"><label>17</label><element-citation publication-type="journal" id="sref16"><person-group person-group-type="author"><name><surname>Pokhrel</surname><given-names>P.</given-names></name><name><surname>Little</surname><given-names>M.</given-names></name><name><surname>Herzog</surname><given-names>T.</given-names></name></person-group><article-title>Current methods in health behavior research among U.S. community college students: a review of the literature</article-title><source>Eval Health Prof</source><volume>37</volume><year>2014</year><fpage>178</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">24227658</pub-id></element-citation></ref><ref id="bib18"><label>18</label><element-citation publication-type="book" id="sref17"><person-group person-group-type="author"><name><surname>Dillman</surname><given-names>D.</given-names></name><name><surname>Smyth</surname><given-names>J.</given-names></name><name><surname>Christian</surname><given-names>L.</given-names></name></person-group><chapter-title>Internet, mail, and mixed-mode surveys: the tailored design method</chapter-title><year>2009</year><publisher-name>Wiley &#x00026; Sons</publisher-name><publisher-loc>Hoboken, NJ</publisher-loc></element-citation></ref><ref id="bib19"><label>19</label><element-citation publication-type="book" id="sref18"><person-group person-group-type="author"><name><surname>Dex</surname><given-names>S.</given-names></name><name><surname>Gumy</surname><given-names>J.</given-names></name></person-group><chapter-title>On the experience and evidence about mixing modes of data collection in large-scale surveys where the web is used as one of the modes in data collection</chapter-title><year>2011</year><comment>National Centre for Research Methods Working Paper Available at</comment><ext-link ext-link-type="uri" xlink:href="http://eprints.ncrm.ac.uk/2041/" id="intref0040">http://eprints.ncrm.ac.uk/2041/</ext-link><comment>Accessed January 29, 2016</comment></element-citation></ref><ref id="bib20"><label>20</label><element-citation publication-type="journal" id="sref19"><person-group person-group-type="author"><name><surname>De Leeuw</surname><given-names>E.D.</given-names></name></person-group><article-title>To mix or not to mix data collection modes in surveys</article-title><source>J Official Stat</source><volume>2</volume><issue>5</issue><year>2005</year><fpage>233</fpage><lpage>255</lpage></element-citation></ref><ref id="bib21"><label>21</label><element-citation publication-type="journal" id="sref20"><person-group person-group-type="author"><name><surname>Medway</surname><given-names>R.L.</given-names></name><name><surname>Fulton</surname><given-names>J.</given-names></name></person-group><article-title>When more gets you less: a meta-analysis of the effect of concurrent web options on mail survey response rates</article-title><source>Public Opin Q</source><volume>76</volume><year>2012</year><fpage>733</fpage><lpage>746</lpage></element-citation></ref><ref id="bib22"><label>22</label><element-citation publication-type="journal" id="sref21"><person-group person-group-type="author"><name><surname>Israel</surname><given-names>G.D.</given-names></name></person-group><article-title>Combining mail and e-mail contacts to facilitate participation in mixed-mode surveys</article-title><source>Soc Sci Comput Rev</source><volume>31</volume><year>2013</year><fpage>346</fpage><lpage>358</lpage></element-citation></ref><ref id="bib23"><label>23</label><element-citation publication-type="book" id="sref22"><person-group person-group-type="author"><name><surname>Levenstein</surname><given-names>R.M.</given-names></name></person-group><chapter-title>Non-response and measurement error in mixed-mode design</chapter-title><comment>PhD Thesis</comment><year>2010</year><publisher-name>University of Michigan</publisher-name><publisher-loc>Michigan</publisher-loc></element-citation></ref><ref id="bib24"><label>24</label><element-citation publication-type="journal" id="sref23"><person-group person-group-type="author"><name><surname>Couper</surname><given-names>M.P.</given-names></name></person-group><article-title>The future of modes of data collection</article-title><source>Public Opin Q</source><volume>75</volume><year>2011</year><fpage>889</fpage><lpage>908</lpage></element-citation></ref><ref id="bib25"><label>25</label><element-citation publication-type="book" id="sref24"><person-group person-group-type="author"><name><surname>McLennan</surname><given-names>D.</given-names></name><name><surname>Barnes</surname><given-names>H.</given-names></name><name><surname>Nonle</surname><given-names>M.</given-names></name><name><surname>Davies</surname><given-names>J.</given-names></name><name><surname>Garratt</surname><given-names>E.</given-names></name><name><surname>Dibben</surname><given-names>C.</given-names></name></person-group><chapter-title>The English Indices of Deprivation 2010, Department for Communities and Local Government Technical Report</chapter-title><year>2011</year><isbn>978-1-4098-2922-5</isbn><comment>Available at</comment><ext-link ext-link-type="uri" xlink:href="https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/6320/1870718.pdf" id="intref0045">https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/6320/1870718.pdf</ext-link><comment>Accessed January 30, 2016</comment></element-citation></ref><ref id="bib26"><label>26</label><element-citation publication-type="journal" id="sref25"><person-group person-group-type="author"><name><surname>David</surname><given-names>M.C.</given-names></name><name><surname>Bensink</surname><given-names>M.</given-names></name><name><surname>Higashi</surname><given-names>H.</given-names></name><name><surname>Boyd</surname><given-names>R.</given-names></name><name><surname>Williams</surname><given-names>L.</given-names></name><name><surname>Ware</surname><given-names>R.S.</given-names></name></person-group><article-title>Systematic review of the cost-effectiveness of sample size maintenance programs in studies involving postal questionnaires reveal insufficient economic information</article-title><source>J Clin Epidemiol</source><volume>65</volume><year>2012</year><fpage>1031</fpage><lpage>1040</lpage><pub-id pub-id-type="pmid">22809618</pub-id></element-citation></ref><ref id="bib27"><label>27</label><element-citation publication-type="journal" id="sref26"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>B.</given-names></name><name><surname>Smith</surname><given-names>T.C.</given-names></name><name><surname>Gray</surname><given-names>G.C.</given-names></name><collab>Ryan MAK for the Millenium Cohort Study Team</collab></person-group><article-title>When epidemiology meets the internet: web-based surveys in the Millenium Cohort Study</article-title><source>Am J Epidemiol</source><volume>166</volume><year>2007</year><fpage>1345</fpage><lpage>1354</lpage><pub-id pub-id-type="pmid">17728269</pub-id></element-citation></ref><ref id="bib28"><label>28</label><element-citation publication-type="journal" id="sref27"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>A.</given-names></name><name><surname>Dickman</surname><given-names>P.W.</given-names></name><name><surname>Klint</surname><given-names>A.</given-names></name><name><surname>Weiderpass</surname><given-names>E.</given-names></name></person-group><article-title>Feasibility of using web-based questionnaires in large population-based epidemiological studies</article-title><source>Eur J Epidemiol</source><volume>21</volume><year>2006</year><fpage>103</fpage><lpage>111</lpage><pub-id pub-id-type="pmid">16518678</pub-id></element-citation></ref><ref id="bib29"><label>29</label><element-citation publication-type="journal" id="sref28"><person-group person-group-type="author"><name><surname>van Gelder</surname><given-names>M.M.H.J.</given-names></name><name><surname>Bretveld</surname><given-names>R.W.</given-names></name><name><surname>Roeleveld</surname><given-names>N.</given-names></name></person-group><article-title>Web-based questionnaires: the future in epidemiology?</article-title><source>Am J Epidemiol</source><volume>172</volume><year>2010</year><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="pmid">20880962</pub-id></element-citation></ref><ref id="bib30"><label>30</label><element-citation publication-type="journal" id="sref29"><person-group person-group-type="author"><name><surname>Udtha</surname><given-names>M.</given-names></name><name><surname>Krystle</surname><given-names>N.</given-names></name><name><surname>Yu</surname><given-names>E.</given-names></name><name><surname>Sanner</surname><given-names>J.</given-names></name></person-group><article-title>Novel and emerging strategies for longitudinal data collection</article-title><source>J Nurs Scholarsh</source><volume>47</volume><year>2015</year><fpage>152</fpage><lpage>160</lpage><pub-id pub-id-type="pmid">25490868</pub-id></element-citation></ref></ref-list><sec id="appsec1" sec-type="supplementary-material"><title>Supplementary data</title><p><supplementary-material content-type="local-data" id="ec1"><caption><title>Supplementary Tables 1&#x02013;4</title></caption><media xlink:href="mmc1.doc"/></supplementary-material></p></sec><ack id="ack0010"><title>Acknowledgments</title><p>The authors are extremely grateful to all the families who took part in this study, the midwives for their help in recruiting them, and the whole ALSPAC team, which includes interviewers, computer and laboratory technicians, clerical workers, research scientists, volunteers, managers, receptionists, and nurses.</p><p>Authors' contributions: I.B. managed the RCT, carried out the statistical analysis, and wrote the first draft of the paper. All authors contributed to the design of the study and commented on the paper. S.N. performed the economic analysis. R.R. managed the data collection exercise and provided economic data. K.T. oversaw the design, analysis, and writing-up of the RCT.</p></ack><fn-group><fn id="d31e159"><p id="ntpara0010">Conflict of interest: The authors have no conflict of interest to declare.</p></fn><fn id="d31e162"><p id="ntpara0015">Funding: The <funding-source id="gs1">UK Medical Research Council</funding-source> and the <funding-source id="gs2">Wellcome Trust</funding-source> (Grant ref: 102215/2/13/2) and the <funding-source id="gs4">University of Bristol</funding-source> provide core support for ALSPAC.</p></fn><fn id="appsec2" fn-type="supplementary-material"><p>Supplementary data related to this article can be found at <ext-link ext-link-type="doi" xlink:href="10.1016/j.jclinepi.2016.09.004" id="intref0035">http://dx.doi.org/10.1016/j.jclinepi.2016.09.004</ext-link>.</p></fn></fn-group></back><floats-group><fig id="fig1"><label>Fig.&#x000a0;1</label><caption><p>Flow diagram of participant numbers. YP, young people.</p></caption><alt-text id="alttext0010">Fig.&#x000a0;1</alt-text><graphic xlink:href="gr1"/></fig><table-wrap id="tbl1" position="float"><label>Table&#x000a0;1</label><caption><p>Reminder schedule for both arms of the trial</p></caption><alt-text id="alttext0015">Table&#x000a0;1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Time since initial letter</th><th>Reminder method</th></tr></thead><tbody><tr><td>3 wks</td><td>Email/text/postcard reminder<xref rid="tbl1fna" ref-type="table-fn">a</xref></td></tr><tr><td>5 wks</td><td>Text/postcard reminder<xref rid="tbl1fnb" ref-type="table-fn">b</xref>&#x000a0;+&#x000a0;Facebook reminder</td></tr><tr><td>8 wks</td><td>Letter with paper questionnaire</td></tr><tr><td>10&#x000a0;wks</td><td>Email/text/postcard reminder<xref rid="tbl1fna" ref-type="table-fn">a</xref>&#x000a0;+&#x000a0;Facebook reminder</td></tr><tr><td>12&#x02013;19&#x000a0;wks</td><td>Phone call reminder</td></tr></tbody></table><table-wrap-foot><fn id="tbl1fna"><label>a</label><p id="ntpara0020">Depending on contact details available.</p></fn></table-wrap-foot><table-wrap-foot><fn id="tbl1fnb"><label>b</label><p id="ntpara0025">Depending on contact details available and not repeating the method used at 3&#x000a0;weeks.</p></fn></table-wrap-foot></table-wrap><table-wrap id="tbl2" position="float"><label>Table&#x000a0;2</label><caption><p>Numbers of questionnaires returned, by arm of trial</p></caption><alt-text id="alttext0020">Table&#x000a0;2</alt-text><table frame="hsides" rules="groups"><thead><tr><th/><th>Online first (<italic>n</italic>&#x000a0;=&#x000a0;4,398)</th><th>Choice (<italic>n</italic>&#x000a0;=&#x000a0;4,397)</th><th>Odds ratio (95% CI)</th><th><italic>P</italic>-value</th><th>Adjusted odds ratio<xref rid="tbl2fna" ref-type="table-fn">a</xref> (95% CI)</th><th><italic>P</italic>-value</th></tr></thead><tbody><tr><td>Total number (%) of questionnaires returned</td><td>2,078 (47%)</td><td>2,144 (49%)</td><td>0.94 (0.87, 1.02)</td><td>0.16</td><td>0.90 (0.82, 0.99)</td><td>0.04</td></tr></tbody></table><table-wrap-foot><fn><p><italic>Abbreviations:</italic> CI, confidence interval; IMD, Index of Multiple Deprivation.</p></fn></table-wrap-foot><table-wrap-foot><fn id="tbl2fna"><label>a</label><p id="ntpara0030">Adjusted for gender, previous participation score (continuous), and IMD tertile.</p></fn></table-wrap-foot></table-wrap></floats-group></article>