<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Facts Views Vis Obgyn</journal-id><journal-id journal-id-type="iso-abbrev">Facts Views Vis Obgyn</journal-id><journal-title-group><journal-title>Facts, Views &#x00026; Vision in ObGyn</journal-title></journal-title-group><issn pub-type="ppub">2032-0418</issn><publisher><publisher-name>Universa Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25897367</article-id><article-id pub-id-type="pmc">4402446</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Automated characterisation of ultrasound images of ovarian tumours: the diagnostic accuracy of a support vector machine and image processing with a local binary pattern operator</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Khazendar</surname><given-names>S.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Sayasneh</surname><given-names>A.</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Al-Assam</surname><given-names>H.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Du</surname><given-names>H.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Kaijser</surname><given-names>J.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Ferrara</surname><given-names>L.</given-names></name><xref ref-type="aff" rid="A4">4</xref></contrib><contrib contrib-type="author"><name><surname>Timmerman</surname><given-names>D.</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Jassim</surname><given-names>S.</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Bourne</surname><given-names>T.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref></contrib><aff id="A1"><label>1</label>Department of Applied Computing, University of Buckingham, Buckingham, MK18 1EG, U.K.
</aff><aff id="A2"><label>2</label>Department of Cancer and Surgery, Queen Charlotte&#x02019;s and Chelsea Hospital, Imperial College, London, W12 0HS, U.K.
</aff><aff id="A3"><label>3</label>KU Leuven Department of Development and Regeneration; Obstetrics and Gynaecology, University Hospitals KU Leuven, Leuven, Belgium.
</aff><aff id="A4"><label>4</label>Queen Charlotte&#x02019;s and Chelsea Hospital, Imperial College, London, W12 0HS, U.K.
</aff></contrib-group><author-notes><corresp id="COR1">
Correspondence at: Dr Ahmad Sayasneh MRCOG. Department of Cancer and Surgery, Imperial College London, Hammersmith Campus, Du Cane Road, W12 0HS. E-mail: <email>a.sayasneh@imperial.ac.uk</email></corresp></author-notes><pub-date pub-type="ppub"><year>2015</year></pub-date><volume>7</volume><issue>1</issue><fpage>7</fpage><lpage>15</lpage><permissions><copyright-statement>Copyright: &#x000a9; 2015 Facts, Views &#x00026; Vision</copyright-statement><copyright-year>2015</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p><italic>Introduction:</italic> Preoperative characterisation of ovarian masses into benign or malignant is of paramount importance to optimise patient management.</p><p><italic>Objectives:</italic> In this study, we developed and validated a computerised model to characterise ovarian masses as benign or malignant.</p><p><italic>Materials and methods:</italic> Transvaginal 2D B mode static ultrasound images of 187 ovarian masses with known histological diagnosis were included. Images were first pre-processed and enhanced, and Local Binary Pattern Histograms were then extracted from 2 &#x000d7; 2 blocks of each image. A Support Vector Machine (SVM) was trained using stratified cross validation with randomised sampling. The process was repeated 15 times and in each round 100 images were randomly selected.</p><p><italic>Results:</italic> The SVM classified the original non-treated static images as benign or malignant masses with an average accuracy of 0.62 (95% CI: 0.59-0.65). This performance significantly improved to an average accuracy of 0.77 (95% CI: 0.75-0.79) when images were pre-processed, enhanced and treated with a Local Binary Pattern operator (mean difference 0.15: 95% 0.11-0.19, p &#x0003c; 0.0001, two-tailed t test).</p><p><italic>Conclusion:</italic> We have shown that an SVM can classify static 2D B mode ultrasound images of ovarian masses into benign and malignant categories. The accuracy improves if texture related LBP features extracted from the images are considered.</p></abstract><kwd-group kwd-group-type="author-created"><kwd>Decision support techniques</kwd><kwd>ovarian cancer</kwd><kwd>ovarian neoplasm</kwd><kwd>Support Vector Machines</kwd><kwd>ultrasonography</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction" id="s1"><title>Introduction</title><p>Ovarian tumours are common and occur at all stages of life. Real-time ultrasonography is widely used to characterise ovarian tumours as benign or malignant. This may be achieved using the subjective impression of the examiner (Timmerman et al., 1999), applying ultrasound based simple rules and descriptors (Kaijser et al., 2013; Timmerman et al., 2010 a) or by using a variety of ultrasound based prediction models, such as the RMI (Risk of Malignancy Index) (Jacobs et al., 1990; Kaijser et al., 2013), and International Ovarian Tumour Analysis (IOTA) Group logistic regression models LR1 &#x00026; LR2 (Kaijser et al., 2013; Sayasneh et al., 2013; Timmerman et al., 2010 b). These prediction models rely on the examiner identifying different ultrasound features in real time and using these to calculate the risk of a lesion being benign and malignant. Such an approach is dependent on the experience and skill of the examiner. The preoperative classification of ovarian masses using the subjective impression of ultrasound operators has been shown to be less precise when assessing static ultrasound images compared to those obtained during real-time examination (Van Holsbeke et al., 2008). In the latter study, the authors obtained an accuracy of 85% based on expert consensus opinion of static images compared to 89% for real-time ultrasonography (Van Holsbeke et al., 2008).</p><p>The texture of static images refers to the appearance, structure and arrangement of parts of an object within the image (Castellano et al., 2004). Studying texture features, which includes the visual patterns and properties of homogeneity can give important structural information about the surfaces in relation to the surrounding environment (Linares et al., 2004). Texture analysis is widely used in image processing, such as face images for classification and segmentation. Local Binary Pattern (LBP) is an effective technique that captures grey-scale invariant texture information (Ojala et al., 2002).</p><p>Different learning machines, such as Support Vector Machines (SVM), have been developed to classify data (Cristianini et al., 2000). An SVM is a computationally efficient classifier that learns the hyper-planes in a high dimensional feature space that separate examples (i.e. data points) of the positive class from the negative class (Cristianini et al., 2000). During the training stage, SVM builds a classification model based on training samples, which is a Hyperplane in the case of a linear SVM. To classify a new sample, the resulting Hyperplane will be used to assign a class. For example, an image will be predicted as a malignant case if it falls on the negative side of Hyperplane and as a benign case vice versa. Moreover, SVM performance is highly generalizable without the need to add a priori knowledge (Song et al., 2002; Sun et al., 2003).</p><p>The aim of this study was to develop a computerised system, capable of characterising images of ovarian masses as benign or malignant independent of an examiner being competent to identify the features required to make a diagnosis. For this study we used original or enhanced B mode static ultrasound images.</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and Methods</title><p>This is a retrospective cohort study carried out on static ultrasound images of ovarian masses from women recruited into the IOTA study (Timmerman et al., 2010 b). All women in this study underwent surgical removal of the mass between November 2005 and November 2013 with a known histological diagnosis. All women gave written informed consent to use and analyse the data (Timmerman et al., 2010 b). The 187 anonymous 2D ultrasound images were retrieved from the IOTA database (Astraia software gmbh, Germany) at the Department of Gynaecological Ultrasonography, Campus Gasthuisberg, KU Leuven, Belgium. This study was granted ethical approval by the University of Buckingham&#x02019;s School of Science &#x00026; Medicine Ethics Committee in May 2012. We have followed the STARD guidelines for diagnostic accuracy studies (Bossuyt et al., 2003).</p></sec><sec id="s3"><title>Reference standard</title><p>The final outcome was the histological diagnosis of removed tissues as stipulated by the IOTA study protocol (Timmerman et al., 2010 b), and the classification of these as benign or malignant. Borderline tumours were classified as malignant. Tumours were classified using the criteria recommended by the World Health Organisation (WHO) (Tavasso&#x000e9;li et al., 2003).</p></sec><sec id="s4"><title>Static images</title><p>Each image represented the 2D B mode ultrasound features of the surgically removed adnexal mass. The image used for each mass was selected by author JK that on subjective impression was most representative of the final histopathology. In total 187 images were used from 177 patients (112 images of Benign and 75 images of malignant tumours). In ten patients we used an additional 2D-image with another representative region of interest (ROI) that reflected the final histopathology. Histology results were available for all masses corresponding to the images used (<xref ref-type="table" rid="T1">Table I</xref>).</p><table-wrap id="T1" orientation="portrait" position="float"><label>Table I</label><caption><title>The histopathology of ovarian masses included in the study in the training and test groups.</title></caption><table frame="hsides" rules="all"><thead><tr><td colspan="2" align="left" valign="top" rowspan="1">Histopathology</td><td align="center" valign="top" rowspan="1" colspan="1">N (total N = 187)</td></tr></thead><tbody><tr><td rowspan="8" align="left" valign="middle" colspan="1">Benign (n = 112)</td><td align="left" valign="top" rowspan="1" colspan="1">Mature teratoma</td><td align="center" valign="top" rowspan="1" colspan="1">23</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Endometrioma/endometriosis</td><td align="center" valign="top" rowspan="1" colspan="1">15</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Mucinous cystadenoma</td><td align="center" valign="top" rowspan="1" colspan="1">23</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Functional cyst</td><td align="center" valign="top" rowspan="1" colspan="1">5</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ovarian fibroma</td><td align="center" valign="top" rowspan="1" colspan="1">6</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Serous cystadenoma</td><td align="center" valign="top" rowspan="1" colspan="1">21</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Serous cystadenofibroma</td><td align="center" valign="top" rowspan="1" colspan="1">13</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Other benign</td><td align="center" valign="top" rowspan="1" colspan="1">6<break/>(1 tubal abscess, 1 Brenner tumour, 1 Multilocular peritoneal inclusion cyst MPIC, <break/>1 Mucinous cystadenofibroma, 1 subserous adenomyoma, 1 hydrosalpinx)</td></tr><tr><td rowspan="6" align="left" valign="middle" colspan="1">Malignant (n = 75)</td><td rowspan="1" colspan="1">Borderline mucinous tumour</td><td align="center" valign="top" rowspan="1" colspan="1">15</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Borderline serous tumour</td><td align="center" valign="top" rowspan="1" colspan="1">6</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Serous cyst/adenocarcinoma</td><td align="center" valign="top" rowspan="1" colspan="1">28</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Mucinous cyst/adenocarcinoma</td><td align="center" valign="top" rowspan="1" colspan="1">3</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Endometrioid adenocarcinoma</td><td align="center" valign="top" rowspan="1" colspan="1">6</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Other ovarian cancer</td><td align="center" valign="top" rowspan="1" colspan="1">17<break/>(1 Lymphoma, 7 metastatic tumours (3 intestinal, 1 breast, 1 pancreatic, <break/>1 gastric, and 1 lung cancers), 1 leiomyosarcoma,1 stromal tumour, <break/>1 germ cell tumour, 2 clear cell carcinomas, 2 carcinosarcomas, <break/>1 immature teratomas, 1 endometrial cancer)</td></tr></tbody></table></table-wrap><p>Power or colour Doppler had been performed for ten images, but this did not affect the segmentation process of the grey scale features of the ROI, therefore they were accepted in the study. The analysis was confined to the grey scale information contained within the image. MATLAB (Matlab R2012a MathWorks, Natick, Massachusetts, USA) image processing software was used in this study.</p></sec><sec id="s5"><title>Pre-processing</title><p>The original images were received in JPEG digitized format. Each image was pre-processed in three steps as illustrated in <xref ref-type="fig" rid="F1">Figure 1</xref>. Firstly, we used a Non Local mean (NL-means) filter (Buades et al., 2005) to de-noise the image and reduce the negative impact of the Speckle noise (<xref ref-type="fig" rid="F2">Fig. 2</xref>). Then, we conducted a negative transformation of each denoised image in preparation of the last enhancement step (Fig. 1). As a last step of the image pre-processing, we produced the enhanced copy of each image by obtaining the absolute difference between the de-noised image and its negative counterpart. As illustrated in Figure 1, the absolute difference has enhanced the edges in the original B mode image and produced a clearer texture of the cyst (the light grey shades in the resulting image).</p><fig id="F1" orientation="portrait" position="float"><label>Fig. 1</label><caption><title>Pre-processing the image before segmentation.</title><p>The Absolute Difference is a basic image processing operation that takes the absolute value of the difference between the values of the two corresponding pixels I1(i) and I2(i), from the two input images I1 (here is the filtered image) and I2 (here is the negative of the filtered image)</p><p><italic>r</italic>(<italic>i</italic>) = &#x02223;<italic>I</italic>1(<italic>i</italic>) - <italic>I</italic>2(<italic>i</italic>)&#x02223;</p><p>where r (i) represents the ith pixel in the result image. We apply the absolute difference operation on the de-noised image from the NL-means filtering step and its negative image. This means that</p><p><italic>r</italic>(<italic>i</italic>) = &#x02223;<italic>Intensity<sub>max</sub></italic> - 2&#x000d7;<italic>I</italic>(<italic>i</italic>)&#x02223;</p></caption><graphic xlink:href="FVVinObGyn-7-7-15-g001"/></fig><fig id="F2" orientation="portrait" position="float"><label>Fig. 2</label><caption><title>The NL-means de-noising method.</title></caption><graphic xlink:href="FVVinObGyn-7-7-15-g002"/></fig></sec><sec id="s6"><title>Segmentation</title><p>Image segmentation refers to separating the ROI (which in our study is the ovarian tumour) from the background of the whole image. Automatic segmentation of the ROI is not a trivial problem and can be very difficult when the ROI shares the same greyscale colour as the background. In our work, we have manually segmented the ROIs by the first author SK and further confirmed the ROIs by an ultrasound examiner (author AS). Post segmentation, there are four types of output images: original whole image, original ROI, enhanced whole image, and enhanced ROI (<xref ref-type="fig" rid="F3">Fig. 3</xref>).</p><fig id="F3" orientation="portrait" position="float"><label>Fig. 3</label><caption><title>An example of the features transformation using pre-processing methods (left images column) and corresponding LBP processing (right images column). As a result 7 extra images were created from each original image.</title></caption><graphic xlink:href="FVVinObGyn-7-7-15-g003"/></fig></sec><sec id="s7"><title>Image histogram of intensity</title><p>An image histogram shows the number of pixels in an image at each different intensity value. For an 8-bit greyscale image, there are 256 possible intensity values (0 is black and 255 is white), and the histogram of the image represents a frequency distribution of pixels amongst those values (Fig. 4).</p><fig id="F4" orientation="portrait" position="float"><label>Fig. 4</label><caption><title>Description of an ultrasound image of a functional cyst using a concatenated Local Binary Pattern histogram.</title></caption><graphic xlink:href="FVVinObGyn-7-7-15-g004"/></fig></sec><sec id="s8"><title>Histogram of Local Binary Pattern (LBPH) for Texture</title><p>LBP normally refers to replacing image pixels with an 8-bit binary code that is derived from the pixel&#x02019;s neighbourhood of pixels. It examines the eight neighbouring pixels ti (i = 0, 1, 2, ,,,, 7) of t in a clockwise order starting with the top left corner, and assigns 0 to the i-the bit if the pixel value of ti is less than that of t and 1 otherwise (Fig. 4) (Ojala et al., 2002). The corresponding LBP image is obtained by translating every 8-bit binary code into its decimal value in the range of 0 to 255. In this paper, we have used the LBP 256 bin obtained from window size of 5 &#x000d7; 5. We refer to this LBP form as the (8, 2) code.</p><p>Having obtained the LBP image we divided the image into 2 &#x000d7; 2 equal sized blocks, to capture localized texture information of ovarian tumours within the image. The 256-bin histogram was calculated for each block, and then the four histograms were concatenated and saved into a single feature vector for the whole image. That means we had 1024 feature components in one feature vector for each image (<xref ref-type="fig" rid="F4">Fig. 4</xref>). The feature vector for the image was later used as a training instance for the SVM.</p></sec><sec id="s9"><title>Designing the test and training groups</title><p>For the 187 images used in this study, we created the LBP images from the original images (Fig. 4) using the (8, 2) form. The same procedure was repeated for the enhanced, original ROI and enhanced ROI images (Fig. 3). As a result we obtained 8 groups of 187 feature vectors in each group. These groups were: histograms of intensity for the original whole, LBP-transformed original whole, enhanced whole, LBP-transformed enhanced whole, original ROI, LBP-transformed original ROI, enhanced ROI and LBP-transformed enhanced ROI images.</p><p>In order to address the class imbalance problem between benign (112 cases) and malignant (75 cases) in each data set and to develop a fair classification model for both cases, we randomly sampled 50 images of benign and 50 images of malignant tumours, totalling 100 images for training and testing the SVM. The sampling (without replacement) was performed using the Randsample function in Matlab (50 benign with Randsample (112, 50), and 50 malignant Randsample (75, 50)). For evaluation of performance, we employed a stratified 50-fold cross validation, which means applying the leave-one-out strategy to utilise the use of training examples. In an iterative process, one partition, i.e. two samples (one benign and one malignant), was taken as the test examples and the rest for training the SVM (<xref ref-type="fig" rid="F5">Fig. 5</xref>). We repeated this process 15 times with a different random selection of 100 images (50 benign and 50 malignant) to reduce the random effect.</p><fig id="F5" orientation="portrait" position="float"><label>Fig. 5</label><caption><title>A flow chart illustrating the randomised balanced cross validation process of selecting the training and test groups. This process was repeated 15 times to calculate the average diagnostic performance of the SVM in each one of the 8 main images&#x02019; groups.</title></caption><graphic xlink:href="FVVinObGyn-7-7-15-g005"/></fig></sec><sec id="s10"><title>Statistical analysis</title><p>We calculated the average sensitivity, specificity and accuracy of the SVM for each of the 15 cycles. The same test was performed for each of the 8 main image groups. Medcalc software (MedCalc Software bvba, version 12, 2013, Belgium) was used to calculate the difference in accuracies between different groups. The two-tailed t test was used to compare means and p &#x0003c; = 0.05 was considered significant.</p></sec><sec sec-type="results" id="s11"><title>Results</title><p>The SVM learning machine was able to characterise static images of ovarian masses into benign or malignant with an average accuracy ranging between 0.62 and 0.78 (<xref ref-type="table" rid="T2">Table II</xref>).</p><table-wrap id="T2" orientation="portrait" position="float"><label>Table II.</label><caption><title>Diagnostic performance of the Support Vector Machine on images processed using a Local Binary Pattern operator in the test group when using Radius R = 2.</title></caption><table frame="hsides" rules="all"><thead><tr><td rowspan="1" colspan="1"/><td colspan="3" align="center" valign="top" rowspan="1">Average diagnostics for SVM without LBP </td><td colspan="3" align="center" valign="top" rowspan="1">Average diagnostics for SVM &#x00026; LBP (P = 8,R = 2)</td><td rowspan="2" align="center" valign="middle" colspan="1">LBP/Histogram diff in Accuracy </td><td rowspan="2" align="center" valign="middle" colspan="1">p</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">2 &#x000d7; 2 block image</td><td align="center" valign="top" rowspan="1" colspan="1">Sensitivity [95%CI)</td><td align="center" valign="top" rowspan="1" colspan="1">Specificity [95%CI)</td><td align="center" valign="top" rowspan="1" colspan="1">Accuracy [95%CI)</td><td align="center" valign="top" rowspan="1" colspan="1">Sensitivity [95%CI)</td><td align="center" valign="top" rowspan="1" colspan="1">Specificity [95%CI)</td><td align="center" valign="top" rowspan="1" colspan="1">Accuracy [95%CI)</td></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Original image</td><td align="center" valign="top" rowspan="1" colspan="1">0.63 [0.60-0.66] </td><td align="center" valign="top" rowspan="1" colspan="1">0.61 [0.575-0.645]</td><td align="center" valign="top" rowspan="1" colspan="1">0.62 [0.59-0.65]</td><td align="center" valign="top" rowspan="1" colspan="1">0.69 [0.67-0.71]</td><td align="center" valign="top" rowspan="1" colspan="1">0.66 [0.635-0.685]</td><td align="center" valign="top" rowspan="1" colspan="1">0.67 [0.65-0.69]</td><td align="center" valign="top" rowspan="1" colspan="1">0.05 [0.01-0.09]</td><td align="center" valign="top" rowspan="1" colspan="1">0.01</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Original ROI</td><td align="center" valign="top" rowspan="1" colspan="1">0.68 [0.65-0.71]</td><td align="center" valign="top" rowspan="1" colspan="1">0.645 [0.61-0.68]</td><td align="center" valign="top" rowspan="1" colspan="1">0.66 [0.63-0.69]</td><td align="center" valign="top" rowspan="1" colspan="1">0.75 [0.73-0.77]</td><td align="center" valign="top" rowspan="1" colspan="1">0.72 [0.71-0.73]</td><td align="center" valign="top" rowspan="1" colspan="1">0.74 [0.73-0.75]</td><td align="center" valign="top" rowspan="1" colspan="1">0.08 [0.04-012]</td><td align="center" valign="top" rowspan="1" colspan="1">0.0008</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Enhanced image</td><td align="center" valign="top" rowspan="1" colspan="1">0.59 [0.54-0.64]</td><td align="center" valign="top" rowspan="1" colspan="1">0.64 [0.62-0.66]</td><td align="center" valign="top" rowspan="1" colspan="1">0.62 [0.59-0.65]</td><td align="center" valign="top" rowspan="1" colspan="1">0.80 [0.77-0.83]</td><td align="center" valign="top" rowspan="1" colspan="1">0.77 [0.74-0.80]</td><td align="center" valign="top" rowspan="1" colspan="1">0.78 [0.76-0.80]</td><td align="center" valign="top" rowspan="1" colspan="1">0.16 [0.12-0.20]</td><td align="center" valign="top" rowspan="1" colspan="1">0.0001 </td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Enhanced ROI</td><td align="center" valign="top" rowspan="1" colspan="1">0.66 [0.63-0.69]</td><td align="center" valign="top" rowspan="1" colspan="1">0.65 [0.625-0.675]</td><td align="center" valign="top" rowspan="1" colspan="1">0.65 [0.63-0.67]</td><td align="center" valign="top" rowspan="1" colspan="1">0.77 [0.75-0.79] </td><td align="center" valign="top" rowspan="1" colspan="1">0.77 [0.75-0.79</td><td align="center" valign="top" rowspan="1" colspan="1">0.77 [0.75-0.79]</td><td align="center" valign="top" rowspan="1" colspan="1">0.12 [0.09-0.15]</td><td align="center" valign="top" rowspan="1" colspan="1">0.0001</td></tr></tbody></table><table-wrap-foot><fn><p>SVM: Support vector machine. LBP: Linear binary processor. ROI: Region of interest.</p></fn></table-wrap-foot></table-wrap><p>We observed a general improvement in SVM average accuracy when images were processed by the LBP (8, 2) operator (Table II). This improvement in SVM diagnostic performance was statistically significant when LBP was applied to both original whole and ROI, as well as enhanced whole and ROI images (p value ranged between 0.0001 to 0.01) (Table II). Similarly, when the LBP was not applied (i.e. when the histogram of the spatial domain was used rather than the LBPH), the average accuracy of the SVM was improved when the learning machine was trained on ROI original images (0.66, 95%CI: 0.63-0.69) compared to whole area original images (0.62, 95%CI: 0.59-0.65) (difference of 0.04, 95%CI: -0.001 &#x02013; 0.08, p = 0.06).</p><p>When the LBP was applied, the latter difference in SVM average accuracy between ROI and whole image characterization increased to 0.07 (95%CI: 0.04-0.08, p &#x0003c; 0.0001). Image enhancement alone, with no LBP did not improve the capability of the SVM to characterize the images, with an average accuracy of 0.62 (95% CI, 0.59-0.65) for both enhanced and non-enhanced whole images, and with no significant difference for enhanced and non-enhanced ROI images (average accuracy of 0.65 and 0.66 respectively (p = 0.6) (Table II). However, when the LBP was applied on enhanced images, there was a significant improvement in the average accuracy of the SVM to characterise whole images (from 0.67 to 0.78, p &#x0003c; 0.0001) and ROI images (from 0.74 to 0.77, p = 0.03).</p><p>In our data, we have tried the kNN (k-Nearest Neighbours) classifier, instead of SVM, using Euclidean distance metric when k = 1. However we found that the performance of the SVM was significantly better (<xref ref-type="table" rid="T3">Table III</xref>). We believe that this might be due to the better performance of an SVM with higher dimensionality.</p><table-wrap id="T3" orientation="portrait" position="float"><label>Table III.</label><caption><title>Diagnostic performance of the kNN on images processed using a Local Binary Pattern operator. Euclidean distance metric when k = 1.</title></caption><table frame="hsides" rules="all"><thead><tr><td rowspan="1" colspan="1"/><td colspan="3" align="center" valign="top" rowspan="1">Average diagnostics for kNN &#x00026; LBP (P = 8,R = 2)</td><td colspan="3" align="center" valign="top" rowspan="1">Average diagnostics for kNN without LBP </td></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">2 &#x000d7; 2 block image</td><td align="center" valign="top" rowspan="1" colspan="1">Sensitivity [95%CI]</td><td align="center" valign="top" rowspan="1" colspan="1">Specificity [95%CI]</td><td align="center" valign="top" rowspan="1" colspan="1">Accuracy [95%CI]</td><td align="center" valign="top" rowspan="1" colspan="1">Sensitivity [95%CI]</td><td align="center" valign="top" rowspan="1" colspan="1">Specificity [95%CI]</td><td align="center" valign="top" rowspan="1" colspan="1">Accuracy [95%CI]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Original image</td><td align="center" valign="top" rowspan="1" colspan="1">0.55</td><td align="center" valign="top" rowspan="1" colspan="1">0.56</td><td align="center" valign="top" rowspan="1" colspan="1">0.55</td><td align="center" valign="top" rowspan="1" colspan="1">0.65</td><td align="center" valign="top" rowspan="1" colspan="1">0.59</td><td align="center" valign="top" rowspan="1" colspan="1">0.62</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Original ROI</td><td align="center" valign="top" rowspan="1" colspan="1">0.62</td><td align="center" valign="top" rowspan="1" colspan="1">0.53</td><td align="center" valign="top" rowspan="1" colspan="1">0.58</td><td align="center" valign="top" rowspan="1" colspan="1">0.71</td><td align="center" valign="top" rowspan="1" colspan="1">0.49</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Enhanced image</td><td align="center" valign="top" rowspan="1" colspan="1">0.57</td><td align="center" valign="top" rowspan="1" colspan="1">0.69</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td><td align="center" valign="top" rowspan="1" colspan="1">0.66</td><td align="center" valign="top" rowspan="1" colspan="1">0.59</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Enhanced ROI</td><td align="center" valign="top" rowspan="1" colspan="1">0.69</td><td align="center" valign="top" rowspan="1" colspan="1">0.56</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td><td align="center" valign="top" rowspan="1" colspan="1">0.73</td><td align="center" valign="top" rowspan="1" colspan="1">0.46</td><td align="center" valign="top" rowspan="1" colspan="1">0.60</td></tr></tbody></table><table-wrap-foot><fn><p>kNN: k-Nearest Neighbours LBP: Linear binary processor. ROI: Region of interest.</p></fn></table-wrap-foot></table-wrap></sec><sec sec-type="discussion" id="s12"><title>Discussion</title><p>In this study we have shown that computer-based image processing technologies can automatically categorise static B mode ultrasound images as being derived from either benign or malignant ovarian cysts. This accuracy of this technique is not significantly different from the accuracy reported by ultrasound examiners using their subjective impression to read similar static ultrasound images (accuracy 0.85, difference of 0.08, 95% CI: -.0.006 to 0.16. p = 0.08) (Newcombe, 1998; Van Holsbeke et al., 2008). We have also shown that average diagnostic accuracy is better using an LBP coding operator on enhanced images. To the best of our knowledge this approach has not been previously described.</p><p>We believe our three-step enhancement method (non-local mean filter, negative transformation, absolute difference) together with the use of an LBP improved the ability of an SVM to correctly read images by highlighting the external and internal borders of the mass and improving the contrast in solid areas (Fig. 3). Others have described different automatic techniques for classifying ovarian masses images using static images (Zimmer et al., 2003) or by analysing the parameters data derived from these images (Biagiotti et al., 1999; Tailor et al., 1999). However, the novelty of our approach lies in using blocked non-uniform local binary pattern alone for the feature extraction stage on the enhanced images to achieve best result.</p><p>The IOTA group has previously developed prediction models for the classification of ovarian masses using Bayesian least squares SVM and relevance vector machines (Van Calster et al., 2007). These approaches were fundamentally different to the current approach as they relied on ultrasound examiners identifying and recording ultrasound-based variables in &#x0201c;real time&#x0201d; for model development (Van Calster et al., 2007). Thus however sophisticated the model, the limiting factor is the competence of the ultrasound examiner. They found an accurate performance of the model in the test set with a sensitivity and specificity above 90% and 80% respectively for all models (Van Calster et al., 2007). Other studies have also approached the problem using automated assessment of images. In one, an SVM was successfully used with an average classification accuracy of 86.90%, to classify ultrasound images representing three types of benign ovarian cysts: simple, endometriomas, and benign teratomas (Sohail et al., 2010). In this study, histogram moments with Grey Level Co-Occurrence Matrix (GLCM) based statistical texture descriptors were used for image processing (Sohail et al., 2010). Recently, an accuracy of 95% was reported for the characterisation of ovarian tumours using an adjunct Computer Aided Diagnostic (CAD) technique and data mining algorithms on 3D acquired ultrasound images of the ovary (Acharya et al., 2012). In this latter study, the authors used a Decision Tree (DT) classifier on the four most significant texture and high order spectra features. However in this study the images were taken from only 20 patients (10 benign and 10 malignant) (Acharya et al., 2012). Although the DT model had a higher accuracy than the approach we have reported, it was achieved using a large number of images (1000 images of benign and a further 1000 images from malignant tumours) derived from the same 20 patients (Acharya et al., 2012). Compared to the latter study, our SVM model was trained with fewer training images, from a larger number of women and included a wider range of pathologies. Despite the appeal of producing comprehensive rules, DT classifiers have known limitations such as being sensitive to small changes in the training set, rectilinear decision boundaries, and locating split points for continuous features. On the other hand SVM&#x02019;s have known advantages for handling high dimensional data with non-linear decision boundaries (Tan et al., 2006). Taking a different approach, Acharya et al used advanced imaging and data mining technologies to classify benign and malignant ovarian masses with an accuracy of 99.8% (Acharya et al., 2014). This study used a probabilistic neural network (PNN) classifier, compared to the SVM used in our study. They also based the study on 20 patients, albeit examining 2600 images (50% benign and 50% malignant) derived from this cohort. Colour Doppler and 3D images were also used in this study whereas we used only B mode ultrasound information (Acharya et al., 2014). It is possible that the addition of 3D and Doppler information may improve our results further.</p><p>A strength of our study is the multidisciplinary cooperation between clinical experts in the IOTA group and the computing science team in the University of Buckingham. This cooperation was essential to understand the different features seen in static images of ovarian masses. Another strength is that we have access to a reasonable number of tumours with a diverse range of different benign and malignant pathological subtypes, with a prevalence of malignancy of 75/187(40%) in the study group. We also believe that the repeated randomized stratified cross validation of the SVM training and testing groups, is a robust methodology which has led to reliable results.</p><p>A weakness of our study is that we manually segmented the ultrasound images when obtaining the ROI, which may have caused selection bias. This is largely due to the fact that our primary focus was on the automatic feature extraction and image classification. Automatic segmentation of the ROI from ultrasound images is a known unsolved problem (Sohail et al., 2010) which may require extensive use of domain knowledge of the operator and need more future research. However, the results were still valid when the ROI was segmented and the LBP was applied on whole images (original and enhanced) (Table II). Indeed, the average accuracy was observed to be slightly higher when LBP was applied on enhanced whole images compared to enhanced ROI images (0.77) (Table II). Moreover, manual tracing is an available function in ultrasound machines; therefore this should not be a significant disadvantage when considering applying this technology in &#x0201c;real world&#x0201d; clinical practice. A further issue to consider is the selection bias of the ultrasound images themselves, as these have to contain the ROI if an accurate diagnosis is to be made and this in itself requires a level of competence from any ultrasound operator. Similarly, there was a selection bias caused by using different high specification machines, which is difficult to estimate. However this scenario is not unusual in imaging practice. Radiologists routinely review static images derived from different ultrasound machines that have been taken by a technician, this too can only be as accurate as the images provided. A reliance on the ROI being within an image supplied by a third party is therefore not unique to the use of computer processing technologies. Whilst we were careful to include a heterogeneous mix of pathology, once we have refined performance with more masses, it is critical that our approach is externally validated to see if the results are generalizable and have the potential to be transferred into every day clinical practice.</p></sec><sec sec-type="conclusions" id="s13"><title>Conclusion</title><p>In this paper we have shown new evidence that computer learning machines using novel methodology have the potential to characterize static ultrasound images. There is good evidence to show subjective assessment by experts using TVS in real time is the optimal approach to the classification of ovarian pathology. However this level of expertise is not available in most clinical environments. By automating the recognition of ultrasound features that discriminate between the benign and malignant nature of an ovarian mass the need for expert review of images may be reduced. If test performance improves with training on more masses and is retained on external validation, the incorporation of such machine intelligence into the software of ultrasound equipment would become a possibility enabling ovarian mass characterisation to be effectively carried out even in clinical environments where access to highly specialist expertise is not available.</p></sec></body><back><ack><p>Tom Bourne and Ahmad Sayasneh are supported by the National Institute for Health Research (NIHR) Biomedical Research Centre based at Imperial College Healthcare NHS Trust and Imperial College London. Dirk Timmerman is a Senior Clinical Investigator of the Research Foundation - Flanders (Belgium) (FWO). The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health. The author SK wishes to thank the Ministry of the Higher Education in Kurdistan for funding her PhD.</p></ack><ref-list><ref id="R01"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharya</surname><given-names>UR</given-names></name><name><surname>Mookiah</surname><given-names>MR</given-names></name><name><surname>Vinitha Sree</surname><given-names>S</given-names></name><etal/></person-group><article-title>Evolutionary algorithm-based classifier parameter tuning for automatic ovarian cancer tissue characterization and classification</article-title><source>Ultraschall Med</source><year>2014</year><volume>35</volume><fpage>237</fpage><lpage>245</lpage><pub-id pub-id-type="pmid">23258769</pub-id></element-citation></ref><ref id="R02"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharya</surname><given-names>U</given-names></name><name><surname>Vinitha Sree</surname><given-names>S</given-names></name><name><surname>Saba</surname><given-names>L</given-names></name><etal/></person-group><article-title>Ovarian tumor characterization and classification: A class of GyneScanTM Systems. Conference proceedings</article-title><source>IEEE Eng Med Biol Soc (EMBC)</source><year>2012</year><fpage>4446</fpage><lpage>4449</lpage></element-citation></ref><ref id="R03"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buades</surname><given-names>A</given-names></name><name><surname>Coll</surname><given-names>B</given-names></name><name><surname>Morel</surname><given-names>J</given-names></name></person-group><article-title>A non-local algorithm for image denoising</article-title><source>IEEE Comput Soc Conf Comput Vis Pattern Recognit</source><year>2005</year><volume>2</volume><fpage>60</fpage><lpage>65</lpage></element-citation></ref><ref id="R04"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biagiotti</surname><given-names>R</given-names></name><name><surname>Desii</surname><given-names>C</given-names></name><name><surname>Vanzi</surname><given-names>E</given-names></name><etal/></person-group><article-title>Predicting ovarian malignancy: application of artificial neural networks to transvaginal and color Doppler flow US</article-title><source>Radiology</source><year>1999</year><volume>210</volume><fpage>399</fpage><lpage>403</lpage><pub-id pub-id-type="pmid">10207421</pub-id></element-citation></ref><ref id="R05"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bossuyt</surname><given-names>PM</given-names></name><name><surname>Reitsma</surname><given-names>JB</given-names></name><name><surname>Bruns</surname><given-names>DE</given-names></name><etal/></person-group><article-title>Towards complete and accurate reporting of studies of diagnostic accuracy: The STARD Initiative</article-title><source>Radiology</source><year>2003</year><volume>226</volume><fpage>24</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">12511664</pub-id></element-citation></ref><ref id="R06"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castellano</surname><given-names>G</given-names></name><name><surname>Bonilha</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>LM</given-names></name><etal/></person-group><article-title>Texture analysis of medical images</article-title><source>Clin Radiol</source><year>2004</year><volume>59</volume><fpage>1061</fpage><lpage>1069</lpage><pub-id pub-id-type="pmid">15556588</pub-id></element-citation></ref><ref id="R07"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J</given-names></name></person-group><source>An introduction to Support Vector Machines: and other kernel-based learning methods</source><year>2000</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>93</fpage><lpage>122</lpage></element-citation></ref><ref id="R08"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>I</given-names></name><name><surname>Oram</surname><given-names>D</given-names></name><name><surname>Fairbanks</surname><given-names>J</given-names></name><etal/></person-group><article-title>A risk of malignancy index incorporating CA 125, ultrasound and menopausal status for the accurate preoperative diagnosis of ovarian cancer</article-title><source>Br J Obstet Gynaecol</source><year>1990</year><volume>97</volume><fpage>922</fpage><lpage>929</lpage><pub-id pub-id-type="pmid">2223684</pub-id></element-citation></ref><ref id="R09"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaijser</surname><given-names>J</given-names></name><name><surname>Bourne</surname><given-names>T</given-names></name><name><surname>Valentin</surname><given-names>L</given-names></name><etal/></person-group><article-title>Improving strategies for diagnosing ovarian cancer: a summary of the International Ovarian Tumor Analysis (IOTA) studies</article-title><source>Ultrasound Obstet Gynecol</source><year>2013</year><volume>41</volume><fpage>9</fpage><lpage>20</lpage><pub-id pub-id-type="pmid">23065859</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linares</surname><given-names>PA</given-names></name><name><surname>McCullagh</surname><given-names>PJ</given-names></name><name><surname>Black</surname><given-names>ND</given-names></name><etal/></person-group><article-title>Feature selection for the characterization of ultrasonic images of the placenta using texture classification</article-title><source> IEEE Int Symp Biomed Imaging</source><year>2004</year><volume>2</volume><fpage>1147</fpage><lpage>1150</lpage></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newcombe</surname><given-names>RG</given-names></name></person-group><article-title>Interval estimation for the difference between independent proportions: comparison of eleven methods</article-title><source>Stat Med</source><year>1998</year><volume>17</volume><fpage>873</fpage><lpage>890</lpage><pub-id pub-id-type="pmid">9595617</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ojala</surname><given-names>T</given-names></name><name><surname>Pietikainen</surname><given-names>M</given-names></name><name><surname>Maenpaa</surname><given-names>T</given-names></name></person-group><article-title>Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>2002</year><volume>24</volume><fpage>971</fpage><lpage>987</lpage></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sayasneh</surname><given-names>A</given-names></name><name><surname>Wynants</surname><given-names>L</given-names></name><name><surname>Preisler</surname><given-names>J</given-names></name><etal/></person-group><article-title>Multicentre external validation of IOTA prediction models and RMI by operators with varied training</article-title><source>Br J Cancer</source><year>2013</year><volume>108</volume><fpage>2448</fpage><lpage>2454</lpage><pub-id pub-id-type="pmid">23674083</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>YF</given-names></name><name><surname>Fan</surname><given-names>XD</given-names></name><name><surname>Li</surname><given-names>YD</given-names></name></person-group><article-title>Identifying splicing sites in eukaryotic RNA: support vector machine approach</article-title><source>Comput Biol Med</source><year>2003</year><volume>33</volume><fpage>17</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">12485627</pub-id></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohail</surname><given-names>ASM</given-names></name><name><surname>Rahman</surname><given-names>MM</given-names></name><name><surname>Bhattacharya</surname><given-names>P</given-names></name><etal/></person-group><article-title>Retrieval and classification of ultrasound images of ovarian cysts combining texture features and histogram moments</article-title><source>IEEE Int Symp Biomed Imaging. From Nano to Macro</source><year>2010</year><fpage>288</fpage><lpage>291</lpage></element-citation></ref><ref id="R16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Q</given-names></name><name><surname>Wenjie</surname><given-names>H</given-names></name><name><surname>Wenfang</surname><given-names>X</given-names></name></person-group><article-title>Robust support vector machine with bullet hole image classification</article-title><source>IEEE Trans Syst Man Cybern C Appl Rev</source><year>2002</year><volume>32</volume><fpage>440</fpage><lpage>448</lpage></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tailor</surname><given-names>A</given-names></name><name><surname>Jurkovic</surname><given-names>D</given-names></name><name><surname>Bourne</surname><given-names>T</given-names></name><etal/></person-group><article-title>Sonographic prediction of malignancy in adnexal masses using an artificial neural network</article-title><source>Br J Obstet Gynaeco</source><year>1999</year><volume>106</volume><fpage>21</fpage><lpage>30</lpage></element-citation></ref><ref id="R18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>P-N</given-names></name><name><surname>Steinbach</surname><given-names>M</given-names></name><name><surname>Kumar</surname><given-names>V</given-names></name></person-group><source>Introduction to data mining</source><year>2006</year><publisher-loc>Boston, Mass</publisher-loc><publisher-name>Addison Wesley</publisher-name><fpage>256</fpage><lpage>276</lpage></element-citation></ref><ref id="R19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tavasso&#x000e9;li</surname><given-names>FA</given-names></name><name><surname>Devilee</surname><given-names>P</given-names></name></person-group><source>Pathology and genetics of tumours of the breast and female genital organs. Third edition</source><year>2003</year><publisher-loc>Lyon</publisher-loc><publisher-name>IRAC press</publisher-name><fpage>113</fpage><lpage>212</lpage></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmerman</surname><given-names>D</given-names></name><name><surname>Schw&#x000e4;rzler</surname><given-names>P</given-names></name><name><surname>Collins</surname><given-names>WP</given-names></name><etal/></person-group><article-title>Subjective assessment of adnexal masses with the use of ultrasonography: an analysis of interobserver variability and experience</article-title><source>Ultrasound Obstet Gynecol</source><year>1999</year><volume>13</volume><fpage>11</fpage><lpage>16</lpage><pub-id pub-id-type="pmid">10201081</pub-id></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmerman</surname><given-names>D</given-names></name><name><surname>Ameye</surname><given-names>L</given-names></name><name><surname>Fischerova</surname><given-names>D</given-names></name><etal/></person-group><article-title>Simple ultrasound rules to distinguish between benign and malignant adnexal masses before surgery: prospective validation by IOTA group</article-title><source>BMJ</source><year>2010</year><volume>341</volume><fpage>c6839</fpage><pub-id pub-id-type="pmid">21156740</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmerman</surname><given-names>D</given-names></name><name><surname>Van Calster</surname><given-names>B</given-names></name><name><surname>Testa</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Ovarian cancer prediction in adnexal masses using ultrasound-based logistic regression models: a temporal and external validation study by the IOTA group</article-title><source>Ultrasound Obstet Gynecol</source><year>2010</year><volume>36</volume><fpage>226</fpage><lpage>234</lpage><pub-id pub-id-type="pmid">20455203</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Calster</surname><given-names/></name><name><surname>Timmerman</surname><given-names>D</given-names></name><name><surname>Lu</surname><given-names>C</given-names></name><etal/></person-group><article-title>Preoperative diagnosis of ovarian tumors using Bayesian kernel-based methods</article-title><source>Ultrasound Obstet Gynecol</source><year>2007</year><volume>29</volume><fpage>496</fpage><lpage>504</lpage><pub-id pub-id-type="pmid">17444557</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Holsbeke</surname><given-names>C</given-names></name><name><surname>Yazbek</surname><given-names>J</given-names></name><name><surname>Holland</surname><given-names>TK</given-names></name><etal/></person-group><article-title>Real-time ultrasound vs. evaluation of static images in the preoperative assessment of adnexal masses</article-title><source>Ultrasound Obstet Gynecol</source><year>2008</year><volume>32</volume><fpage>828</fpage><lpage>831</lpage><pub-id pub-id-type="pmid">18925606</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmer</surname><given-names>Y</given-names></name><name><surname>Tepper</surname><given-names>R</given-names></name><name><surname>Akselrod</surname><given-names>S</given-names></name></person-group><article-title>An automatic approach for morphological analysis and malignancy evaluation of ovarian masses using B-scans</article-title><source>Ultrasound Med Biol</source><year>2003</year><volume>29</volume><fpage>1561</fpage><lpage>1570</lpage><pub-id pub-id-type="pmid">14654152</pub-id></element-citation></ref></ref-list></back></article>