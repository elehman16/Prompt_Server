<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Educ</journal-id><journal-title>BMC Medical Education</journal-title><issn pub-type="epub">1472-6920</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">12694632</article-id><article-id pub-id-type="pmc">153535</article-id><article-id pub-id-type="publisher-id">1472-6920-3-2</article-id><article-id pub-id-type="doi">10.1186/1472-6920-3-2</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Randomised controlled trial of a theoretically grounded tailored intervention to diffuse evidence-based public health practice [ISRCTN23257060]</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Forsetlund</surname><given-names>Louise</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>louise.forsetlund@shdir.no</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Bradley</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>peter.michael.bradley@shdir.no</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Forsen</surname><given-names>Lisa</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>lisa.forsen@folkehelsa.no</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Nordheim</surname><given-names>Lena</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>lena.victoria.nordheim@shdir.no</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Jamtvedt</surname><given-names>Gro</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>gro.jamtvedt@shdir.no</email></contrib><contrib id="A6" contrib-type="author"><name><surname>Bj&#x000f8;rndal</surname><given-names>Arild</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>arild.bjorndal@shdir.no</email></contrib></contrib-group><aff id="I1"><label>1</label>Directorate for Health and Social Affairs, Postbox 8054 Dep, 0031 Oslo, Norway</aff><aff id="I2"><label>2</label>Norwegian Institute of Public Health, Postbox 4404 Nydalen, 0403 Oslo, Norway</aff><pub-date pub-type="collection"><year>2003</year></pub-date><pub-date pub-type="epub"><day>13</day><month>3</month><year>2003</year></pub-date><volume>3</volume><fpage>2</fpage><lpage>2</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6920/3/2"/><history><date date-type="received"><day>26</day><month>11</month><year>2002</year></date><date date-type="accepted"><day>13</day><month>3</month><year>2003</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2003 Forsetlund et al; licensee BioMed Central Ltd. This is an Open Access article: verbatim copying and redistribution of this article are permitted in all media for any purpose, provided this notice is preserved along with the article's original URL.</copyright-statement><copyright-year>2003</copyright-year><copyright-holder>Forsetlund et al; licensee BioMed Central Ltd. This is an Open Access article: verbatim copying and redistribution of this article are permitted in all media for any purpose, provided this notice is preserved along with the article's original URL.</copyright-holder></permissions><abstract><sec><title>Background</title><p>Previous studies have shown that Norwegian public health physicians do not systematically and explicitly use scientific evidence in their practice. They work in an environment that does not encourage the integration of this information in decision-making. In this study we investigate whether a theoretically grounded tailored intervention to diffuse evidence-based public health practice increases the physicians' use of research information.</p></sec><sec sec-type="methods"><title>Methods</title><p>148 self-selected public health physicians were randomised to an intervention group (n = 73) and a control group (n = 75). The intervention group received a multifaceted intervention while the control group received a letter declaring that they had access to library services. Baseline assessments before the intervention and post-testing immediately at the end of a 1.5-year intervention period were conducted. The intervention was theoretically based and consisted of a workshop in evidence-based public health, a newsletter, access to a specially designed information service, to relevant databases, and to an electronic discussion list. The main outcome measure was behaviour as measured by the use of research in different documents.</p></sec><sec><title>Results</title><p>The intervention did not demonstrate any evidence of effects on the objective behaviour outcomes. We found, however, a statistical significant difference between the two groups for both knowledge scores: Mean difference of 0.4 (95% CI: 0.2&#x02013;0.6) in the score for knowledge about EBM-resources and mean difference of 0.2 (95% CI: 0.0&#x02013;0.3) in the score for conceptual knowledge of importance for critical appraisal. There were no statistical significant differences in attitude-, self-efficacy-, decision-to-adopt- or job-satisfaction scales. There were no significant differences in Cochrane library searching after controlling for baseline values and characteristics.</p></sec><sec><title>Conclusion</title><p>Though demonstrating effect on knowledge the study failed to provide support for the hypothesis that a theory-based multifaceted intervention targeted at identified barriers will change professional behaviour.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>According to the evidence-based medicine paradigm the explicit utilisation of scientific information is an important tool to improve the quality of decision-making. Therefore, encouraging such practice is an important aim. It has been recommended that future trials of how to promote evidence-based practice should be embedded in a theoretical framework, identify barriers and facilitating factors within the target group and utilise evidence on effective strategies for behaviour change [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B3">3</xref>]. Such a framework for designing and evaluating complex interventions has subsequently been further elaborated by Campbell and colleagues [<xref ref-type="bibr" rid="B4">4</xref>].</p><p>The study described in this article is part of a larger project in which we was guided by the above-mentioned framework. The overall aim of the project was to encourage public health physicians in Norway to identify and use relevant scientific evidence in their decision-making and to promote understanding of such information through continuing professional development. The project investigated the extent that public health physicians used research information [<xref ref-type="bibr" rid="B5">5</xref>]; identified where public health physicians missed the opportunity to search for research information [<xref ref-type="bibr" rid="B6">6</xref>], and identified barriers to change [<xref ref-type="bibr" rid="B7">7</xref>]. A multifaceted intervention based on a theoretical model was planned during these stages.</p><p>The aim of this study was to evaluate whether a tailored theory-based and multifaceted intervention targeted at the whole process of evidence-based practice increased the explicit integration of research in public health physicians' decision-making. In turn, we wanted to find out whether municipalities were more likely to follow such evidence-based advice and whether this would influence the physicians' reported job-satisfaction.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Participants</title><p>All public health physicians working in municipalities in Norway with more than 3000 inhabitants (N = 332) were invited to participate in the project. The invitation letters explained that project participants would have free access to a library service. In return, they would be asked to return questionnaires and examples of written reports to be used for programme evaluation. We also stated that some participants would be asked to co-operate further during the project period.</p></sec><sec><title>Intervention components and theory</title><p>The intervention was carried out from April 1999 until the end of January 2001. The multifaceted intervention is illustrated graphically in Figure <xref ref-type="fig" rid="F1">1</xref> and detailed in Table 1 (see <xref ref-type="supplementary-material" rid="S1">Additional file 1</xref>). The barriers to the use of scientific evidence that we had identified were operationalised in the intervention model as knowledge, attitudes, self-efficacy and physical access [<xref ref-type="bibr" rid="B7">7</xref>]. We also aimed to influence environmentally related barriers like organisational and social context. For example, by offering geographically spread physicians a communication network and establishing a dedicated project team as a point of contact and information service. Rogers' model of innovation diffusion [<xref ref-type="bibr" rid="B8">8</xref>] was used to guide the organisation of the different components of the intervention.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>Intervention model</p></caption><graphic xlink:href="1472-6920-3-2-1"/></fig><p>Some of the different strategies previously shown to be effective in changing professional behaviour in some settings were used [<xref ref-type="bibr" rid="B2">2</xref>]: multifaceted intervention as such, reminders and feedback (on a general level) and interactive educational meetings [<xref ref-type="bibr" rid="B9">9</xref>]. Thus, important components of the intervention were a workshop, an information service, a discussion list and access to several databases.</p><p>Rogers defines diffusion as "the process by which an innovation is communicated through certain channels over time among the members of a social system" [<xref ref-type="bibr" rid="B8">8</xref>]. In the innovation-diffusion process the individual will first gain knowledge of the innovation, then form an opinion on it, which will be used to adopt or reject it in the decisional stage. The individual's feeling of self-efficacy will also influence the eventual outcome. After the individual decides to adopt the innovation, implementation and confirmation of the decision follow. The intervention sequence was built to lead each participant through each of these five steps. To further influence future task performance, goal setting was used in the intervention as a motivational technique [<xref ref-type="bibr" rid="B10">10</xref>]. This involved participants signing a contract about what they would change in their practice. They were informed that they would be asked if they really had made the changes 6 months later.</p><p>In contrast, participants in the control group received a letter confirming free access to library services for one year. Because there are no organised library services in Norway for practitioners around the country, this represented a potentially useful service. However, knowing how difficult it is to achieve behaviour change we also assumed that this offer, made in a letter, would be equivalent to no intervention.</p></sec><sec><title>Outcome measures</title><p>Behaviour was considered the primary outcome and was measured by analysing the contents of local health service reports and of a hypothetical assignment, by a postal survey, a telephone survey and a questionnaire. The questionnaire was also used to measure the other, secondary outcomes: attitudes, knowledge of evidence-based practice information sources and concepts, task-related self-efficacy, decision-to-adopt and job-satisfaction.</p><sec><title>Hypothetical assignment</title><p>Participants were asked to write a strategy for patients with serious psychiatric disorders in a medium-sized municipality with particular respect to how suggested measures might be supported. Five questions were added; e.g. how to identify initiatives, where to find relevant information and how to evaluate it. At post-test the topic was changed to accident prevention. The hypothetical assignment was developed through discussion with three experienced public health physicians. The assignment was enclosed with the questionnaire.</p></sec><sec><title>Postal survey</title><p>Participants were asked at the end of trial whether they had explicitly used research information in any of their written reports in the project period. Two examples were attached. Respondents responding affirmatively were asked to send in relevant documents. Reports on environmental health were excluded because they tended to have a very local focus.</p></sec><sec><title>Telephone survey</title><p>A report of the effectiveness of external hip protectors was distributed to all in the intervention group, accompanied by the following suggestion to the physician: "Inform the manager at your local nursing home and encourage them to take further action!" We called every nursing home in the appropriate municipalities, and enquired whether the local public health physician had contacted them regarding the use of external hip protectors.</p></sec><sec><title>Questionnaire</title><p>The questionnaire was based on previous literature [<xref ref-type="bibr" rid="B11">11</xref>-<xref ref-type="bibr" rid="B18">18</xref>]. In addition to questions on background variables it included items for measuring knowledge, attitude to the use of research information, task-related self-efficacy, decision-to-adopt, job satisfaction and on self-reported behaviour as mentioned above. Concepts from social cognitive theory considered equivalent to the concepts of attitudes, self-efficacy and decision-to-adopt from Rogers' theory of innovation diffusion were used to develop questionnaire items [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B14">14</xref>].</p><p>The questionnaire was pilot tested with 126 physicians working in municipalities with less than 3000 inhabitants of which 55 (43%) were returned. For most of the questionnaire, subjects were asked to rate each item on 7-point Likert-like scales ranging from "Strongly disagree" to "Strongly agree". Reversed items were converted for scoring. All the items that considered the concepts of attitude, decision-to-adopt, self-efficacy and job-satisfaction were summed and their means were computed. Thus, overall index measures of each concept with scores ranging from 1&#x02013;7 were obtained. Some concepts had their number of items reduced. The analysis of internal consistency of scale items based on the 55 pilot test data yielded a Cronbach's alpha score ranging from 0.83 to 0.87, indicating a satisfactory level of agreement (Table <xref ref-type="table" rid="T2">2</xref>).</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Internal consistency analysis</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td></td><td align="left"><bold><italic>Stand. Alpha</italic></bold></td><td></td><td></td></tr><tr><td></td><td align="left"><bold>Pilot</bold></td><td></td><td align="left"><bold>Pretest</bold></td><td align="left"><bold>Post-test</bold></td></tr></thead><tbody><tr><td align="left">Attitudes</td><td align="left">0.83</td><td align="left">9 items (out of 13)</td><td align="left">0.82</td><td align="left">0.83</td></tr><tr><td align="left">Self-efficacy</td><td align="left">0.84</td><td align="left">6 items (out of 6)</td><td align="left">0.72</td><td align="left">0.73</td></tr><tr><td align="left">Decision-to-adopt</td><td align="left">0.87</td><td align="left">2 items (out of 2)</td><td align="left">0.87</td><td align="left">0.90</td></tr><tr><td align="left">Job satisfaction</td><td align="left">0.83</td><td align="left">6 items (out of 8)</td><td align="left">0.80</td><td align="left">0.84</td></tr></tbody></table></table-wrap><p>The knowledge construct was divided into knowledge about terms of importance to critical appraisal (concept knowledge) and knowledge about information sources for evidence-based practice (source knowledge). Respondents were asked to grade self-perceived knowledge on scales ranging from 0 to 2 and from 0 to 3 respectively. An additional question was added to concept knowledge, scored as either 0 or 1. Scores were summed and means for individual overall scores for concept and source knowledge were computed.</p></sec><sec><title>Scoring</title><p>Frameworks for scoring the documents were developed: the planning documents, the hypothetical assignment and the additional question list. The criteria lists were pilot-tested with 10 cases for each document type, then discussed and revised. Then the lists were re-piloted with 10 more cases, after which some smaller changes were made.</p><p>Two assessors scored each document independently. The assessors gave a total score for the extent the document reflected the different evidence-based practice-elements that the intervention targeted, ranging from 1&#x02013;5. Disagreement was resolved by a third party.</p></sec></sec><sec><title>Sample size and randomisation</title><p>Using a table for sample size determination we specified a power of 80% to detect a medium-sized difference of 0.5 standardized effect size at a significance level of 5%. We found the required sample size to be 62 physicians in each group [<xref ref-type="bibr" rid="B19">19</xref>]. Public health physicians were enrolled by one of the authors (LForsetlund) upon receipt of the consenting letter. Enrolled physicians were subsequently randomised to one of two groups by an independent researcher using computer software.</p></sec><sec><title>Blinding</title><p>The registrar of the questionnaire data was blinded to group allocation. The researchers who scored the other study outcomes were blinded to the allocation of participants and whether the results were pre- or post-tests.</p></sec><sec><title>Analysis</title><p>The internal consistency for all indexes was estimated by using Cronbach's alpha. Interrater consistency was assessed by agreement in weighted Kappa score for the total document score (scale 1&#x02013;5) for all three predefined criteria lists at pre- and post-test.</p><p>The discriminative validity of the instruments was examined by correlating the scores of each scale to the scores obtained in the others, using Spearman's non-parametric test.</p><p>The effect of the intervention was evaluated by t-tests for ordinal (scale) variables. Confidence intervals (95% CI's) were calculated. Binary variables were evaluated by means of Chi-squared analysis. Because of their skewness Mann-Whitney tests were used to compare quantitative discrete variables. The scores (1&#x02013;5) for the hypothetical assignment and additional questions were also compared by means of the Mann-Whitney test, while the scores for reports were recoded and reported as 'used' or 'not used' research.</p><p>Data for all responding participants were analysed on an intention to treat basis, in the sense that even responders who had not received the intervention in full were included in the analysis. For those outcomes where an effect had been shown, sensitivity analyses were conducted by assigning the control group's lowest and average values in turn, to replace missing data in both groups.</p><p>Pre- and post-test analyses were planned because of potential threats of attrition and contamination. However, according to Vickers and Altman [<xref ref-type="bibr" rid="B20">20</xref>] analysing pre- and post-test change does not control for baseline imbalance because of regression to the mean. They suggest a type of multiple regression analysis (covariance analysis) to adjust each respondent's follow-up score with his or her baseline score. We expanded the model to also include baseline characteristics of possible prognostic strength.</p></sec></sec><sec><title>Results</title><sec><title>Participant flow</title><p>Overall, 148 physicians gave written consent to participate in the project. The randomisation process allocated 73 to the intervention group and 75 to the control group. See Figure <xref ref-type="fig" rid="F2">2</xref> for a flow diagram. Six of 73 (8%) physicians from the experimental group withdrew from the project before answering any material. 50 of 73 (68%) physicians attended the workshop while 62 (85%) of them were members of the discussion list. A total of eight physicians had no Internet access and these were sent copies of the reports that were made by the team in the web-based question-and-answer service.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p>Flow chart</p></caption><graphic xlink:href="1472-6920-3-2-2"/></fig><p>No control group participant explicitly withdrew from the project, but 7 physicians could not be contacted at follow-up because they had changed job or were on prolonged leave. One physician who had been randomised to the control group was in fact not a public health physician. He was treated as a non-responder.</p></sec><sec><title>Recruitment</title><p>Recruitment took place between January 1999 and January 2000. After randomisation, the participants were sent the baseline assessment forms. Follow-up measurements were started immediately at the end of the intervention.</p></sec><sec><title>Baseline data</title><p>Baseline characteristics revealed a possible imbalance for some variables (sex, number of years as a public health physician, specialist status, previous exposure to courses in critical appraisal and number of advisory reports written during the previous half year) (Table <xref ref-type="table" rid="T3">3</xref>).</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Baseline demographic and other characteristics of control and intervention groups. Values are numbers (percentages of participants) and means (SD)</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Baseline measure</bold></td><td align="left" colspan="2"><bold>Intervention group n = 59 (%)</bold></td><td align="left" colspan="2"><bold>Control group n = 62 (%)</bold></td></tr></thead><tbody><tr><td align="left"><bold>Demographic</bold></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">Women</td><td align="left">8</td><td align="left">(14)</td><td align="left">17</td><td align="left">(27)</td></tr><tr><td align="left">Men</td><td align="left">50</td><td align="left">(86)</td><td align="left">45</td><td align="left">(73)</td></tr><tr><td align="left">Specialist (yes/no)</td><td align="left">37</td><td align="left">(64)</td><td align="left">30</td><td align="left">(48)</td></tr><tr><td align="left">Mean (SD) Size of municipality (no.inhabitants)</td><td align="left">20137</td><td align="left">(26421)</td><td align="left">18494</td><td align="left">(33391)</td></tr><tr><td align="left">Mean (SD) age (years)</td><td align="left">47</td><td align="left">(6.4)</td><td align="left">47</td><td align="left">(7.9)</td></tr><tr><td align="left">Mean (SD) Public health weekly working hours</td><td align="left">16.4</td><td align="left">(9.8)</td><td align="left">17</td><td align="left">(9.6)</td></tr><tr><td align="left">Mean (SD) Experience (years as publ.health phys.)</td><td align="left">12</td><td align="left">(8.5)</td><td align="left">9.5</td><td align="left">(8.6)</td></tr><tr><td align="left"><bold>Other characteristics</bold></td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Back ground variables</italic></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">Access to Internet (office/home)</td><td align="left">52</td><td align="left">(88)</td><td align="left">52</td><td align="left">(85)</td></tr><tr><td align="left">Access to medical library</td><td align="left">10</td><td align="left">(18)</td><td align="left">13</td><td align="left">(22)</td></tr><tr><td align="left">Access to Cochrane</td><td align="left">5</td><td align="left">(10)</td><td align="left">5</td><td align="left">(9)</td></tr><tr><td align="left">Attended session(s) on searching (yes/no)</td><td align="left">14</td><td align="left">(24)</td><td align="left">14</td><td align="left">(23)</td></tr><tr><td align="left">Attended session(s) in critical appraisal (yes/no)</td><td align="left">24</td><td align="left">(42)</td><td align="left">18</td><td align="left">(30)</td></tr><tr><td align="left">Mean (SD) Data skill scale (1&#x02013;7)</td><td align="left">4.7</td><td align="left">(1.9)</td><td align="left">4.3</td><td align="left">(1.9)</td></tr><tr><td align="left">Mean (SD) Number of written reports</td><td align="left">14.5</td><td align="left">(15.1)</td><td align="left">11.3</td><td align="left">(10.8)</td></tr></tbody></table></table-wrap></sec><sec><title>Numbers analysed</title><p>Response rates for all instruments varied from 59% to 83% at pre-test and from 57% to 100% at post-test, except for the response rate for reports which was 23% for the experiment group and 33% for the control group (Table <xref ref-type="table" rid="T4">4</xref>). One questionnaire response in the intervention group at post-test was excluded because the majority of questions were not answered, so 58 were analysed. In the intervention group 49 (67%) and in the control group 53 (71%) answered the questionnaire at both pre- and post-test and were included in the regression analysis.</p><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>Response rates at pre- and post-test for all instruments</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Pre-test</bold></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></thead><tbody><tr><td></td><td align="left">Questionnaire</td><td align="left">Hypothetical<break/>assignment</td><td align="left">Additional<break/>questions</td><td align="left">Reports</td><td></td><td></td></tr><tr><td colspan="7"><hr></hr></td></tr><tr><td></td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td><td></td><td></td></tr><tr><td align="left">Intervention group</td><td align="left">59 (81)</td><td align="left">49 (67)</td><td align="left">45 (62)</td><td align="left">43 (59)</td><td></td><td></td></tr><tr><td align="left">Control group</td><td align="left">62 (83)</td><td align="left">51 (68)</td><td align="left">47 (63)</td><td align="left">57 (76)</td><td></td><td></td></tr><tr><td align="left"><bold>Post-test</bold></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="7"><hr></hr></td></tr><tr><td></td><td align="left">Questionnaire</td><td align="left">Hypothetical<break/>assignment</td><td align="left">Additional<break/>questions</td><td align="left">Reports</td><td align="left">Postal<break/>Survey</td><td align="left">Telephone<break/>Survey</td></tr><tr><td colspan="7"><hr></hr></td></tr><tr><td></td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td><td align="left">N (%)</td></tr><tr><td align="left">Intervention group</td><td align="left">59 (81)</td><td align="left">50 (68)</td><td align="left">46 (63)</td><td align="left">17 (23)</td><td align="left">52 (71)</td><td align="left">73 (100)</td></tr><tr><td align="left">Control group</td><td align="left">61 (81)</td><td align="left">48 (64)</td><td align="left">43 (57)</td><td align="left">25 (33)</td><td align="left">58 (77)</td><td align="left">75 (100)</td></tr></tbody></table></table-wrap></sec><sec><title>Outcomes and estimation</title><p>Analysis of internal consistency of scale items was repeated on the pre- and post-test material yielding an alpha between 0.73 and 0.90 at post-test (Table <xref ref-type="table" rid="T2">2</xref>). The weighted Kappa scores for interrater agreement on use of research information for reports, hypothetical assignment and additional questions were 0.50, 0.91 and 0.87 at pre-test respectively and 0.89, 0.75 and 0.74 at post-test.</p><p>In the discriminative analysis the instrument for attitude demonstrated a small, though significant correlation to the self-efficacy, decision-to-adopt and job-satisfaction instruments (Table <xref ref-type="table" rid="T5">5</xref>). No other correlations were demonstrated.</p><table-wrap position="float" id="T5"><label>Table 5</label><caption><p>Discriminant analysis using Spearman's correlation coefficient</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="left">Attitudes</td><td align="left">Self-efficacy</td><td align="left">Decision-to-adopt</td><td align="left">Job-satisfaction</td></tr></thead><tbody><tr><td align="left">Attitudes</td><td align="left">-</td><td align="left">0.3**</td><td align="left">0.3**</td><td align="left">0.2*</td></tr><tr><td align="left">Self-efficacy</td><td align="left">0.3**</td><td align="left">-</td><td align="left">0.1</td><td align="left">0.2</td></tr><tr><td align="left">Decision-to-adopt</td><td align="left">0.3**</td><td align="left">0.1</td><td align="left">-</td><td align="left">0.1</td></tr><tr><td align="left">Job-satisfaction</td><td align="left">0.2*</td><td align="left">0.2</td><td align="left">0.1</td><td align="left">-</td></tr></tbody></table><table-wrap-foot><p>* Correlation is significant at the 0.05 level (2-tailed) ** Correlation is significant at the 0.01 level (2-tailed)</p></table-wrap-foot></table-wrap></sec><sec><title>Primary outcomes</title><p>No evidence of differences for any of the objective behavioural variables could be observed at follow up, though a slight tendency for the intervention group to use research to a somewhat greater extent could be observed although not to a level that was statistically significant (Tables <xref ref-type="table" rid="T6">6</xref> and <xref ref-type="table" rid="T7">7</xref>).</p><table-wrap position="float" id="T6"><label>Table 6</label><caption><p>Differences between groups for using research to some extent (tested by means of Mann-Whitney)</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="center" colspan="3"><bold>Intervention</bold></td><td align="center" colspan="3"><bold>Control</bold></td><td></td></tr><tr><td align="left"><bold><italic>Behaviour</italic></bold></td><td align="left">Number of<break/> respondents</td><td align="left">Mean<break/> score</td><td align="left">(SD)&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</td><td align="left">Number of<break/> respondents</td><td align="left">Mean<break/> score</td><td align="left">(SD)</td><td align="left">P</td></tr></thead><tbody><tr><td align="left">Hypothetical assignment</td><td align="left">(50)</td><td align="left">2.1</td><td align="left">(1.3)</td><td align="left">(48)</td><td align="left">1.8</td><td align="left">(1.2)</td><td align="left">0.154</td></tr><tr><td align="left">Additional questions</td><td align="left">(46)</td><td align="left">2.2</td><td align="left">(1.4)</td><td align="left">(43)</td><td align="left">1.7</td><td align="left">(1.0)</td><td align="left">0.063</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T7"><label>Table 7</label><caption><p>Differences between groups for using research to some extent</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold><italic>Behaviour</italic></bold></td><td align="center" colspan="3"><bold>Intervention (N = 73)</bold></td><td align="center" colspan="3"><bold>Control (N = 75)</bold></td></tr><tr><td></td><td align="left"><bold>(N) </bold><break/>(= number of<break/> respondents)</td><td align="left"><bold>n </bold><break/>(= number<break/> using research<break/> to some degree)</td><td align="left">(<bold>% </bold>of total = 73)</td><td align="left"><bold>(N)</bold><break/>(= number of respondents)</td><td align="left"><bold>n </bold><break/>(= number<break/>using research<break/>to some degree)</td><td align="left">(<bold>% </bold>of total = 75)</td></tr></thead><tbody><tr><td align="left">Reports</td><td align="left">(17)</td><td align="left">0</td><td align="left">(0)</td><td align="left">(25)</td><td align="left">1</td><td align="left">(1)</td></tr><tr><td align="left"><underline>Postal survey:</underline></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">Advice-giving documents</td><td align="left">(52)</td><td align="left">3</td><td align="left">(4)</td><td align="left">(58)</td><td align="left">0</td><td align="left">(0)</td></tr><tr><td align="left"><underline>Telephone survey:</underline></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">Giving information on hip protectors to nursing homes</td><td align="left">(73)</td><td align="left">2</td><td align="left">(3)</td><td align="left">(75)</td><td align="left">0</td><td align="left">(0)</td></tr></tbody></table></table-wrap><p>The responses to the question ' number of times searching Cochrane' (or Medline) overestimated the number of searches compared to the search logs. It is presumably easier to remember having searched or not searched than how many times. The variables were therefore recoded to 'having made a search' or 'not having made a search' and analysed. There were statistically significant differences between groups for self-reported searching in the Cochrane database (&#x003c7;<sup>2 </sup>= 6.3, df = 1, p = 0.01) but not in Medline (&#x003c7;<sup>2 </sup>= 0.1, df = 1, p = 0.74) (Table <xref ref-type="table" rid="T8">8</xref>). The sensitivity analysis (worst case scenario) rendered a narrowly significant result for searching the Cochrane database (&#x003c7;<sup>2 </sup>= 4.0, p = 0.047). There was no evidence of differences in self-reporting of:</p><table-wrap position="float" id="T8"><label>Table 8</label><caption><p>Differences at post-test between groups for self-reported searching of Cochrane and Medline. Chi square test</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="left"><bold>Intervention</bold></td><td align="left"><bold>Control</bold></td><td align="left"><bold>DF</bold></td><td align="left"><bold>&#x003c7;<sup>2</sup></bold></td><td align="left"><bold>P</bold></td></tr></thead><tbody><tr><td></td><td align="left">(N)</td><td align="left">(N)</td><td></td><td></td><td></td></tr><tr><td align="left">Searched Cochrane</td><td align="left">(55) 34</td><td align="left">(60) 23</td><td align="left">1</td><td align="left">6.3</td><td align="left">0.01</td></tr><tr><td align="left">Searched Medline</td><td align="left">(55) 31</td><td align="left">(60) 32</td><td align="left">1</td><td align="left">0.1</td><td align="left">0.74</td></tr><tr><td align="left" colspan="8"><italic>Searched Cochrane: 'yes' (1), 'no' (0)</italic></td></tr><tr><td align="left" colspan="8"><italic>Searched Medline: 'yes' (1), 'no' (0)</italic></td></tr></tbody></table></table-wrap><p>- number of articles ordered or critically appraised,</p><p>- number of problems identified as relevant for the use of research,</p><p>- number of instances when research was of help in decision-making,</p><p>- or number of cases where the physician experienced that the advice given was followed.</p></sec><sec><title>Secondary outcomes</title><p>Table <xref ref-type="table" rid="T9">9</xref> describes the effect of the intervention at post-test for the secondary outcomes. There were statistically significant differences between the groups for knowledge about information sources (mean diff = 0.4, 95% CI = 0.2 to 0.6) and knowledge about concepts (mean diff = 0.2, 95% CI = 0.0 to 0.3) but not for attitudes, self-efficacy, decision-to-adopt or job-satisfaction. Assigning the lowest value in the control group (0) to the missing values of the knowledge variables of both groups still rendered significant results for source knowledge (mean diff = 0.3, 95% CI = 0.1 to 0.5). The results for concept knowledge, however, became non-significant (mean diff = 0.1, 95% CI = -0.1 to 0.3). Assigning the mean value of the control group (1.1) to missing values of concept knowledge rendered a significant difference (mean diff = 0.2, 95% CI = 0.0 to 0.3).</p><table-wrap position="float" id="T9"><label>Table 9</label><caption><p>Student t test of differences between groups at post-test</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="left"><bold>Intervention</bold></td><td align="left"><bold>Control</bold></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td align="left">(N = 58</td><td align="left" colspan="6">N = 61 unless otherwise stated)</td></tr><tr><td></td><td align="left">Mean (SD)</td><td align="left">Mean (SD)</td><td align="left">Mean diff</td><td align="left">95% CI</td><td align="left">t</td><td align="left">DF</td><td align="left">P</td></tr></thead><tbody><tr><td align="left">Source knowledge</td><td align="left">1.1 (0.6)</td><td align="left">0.7 (0.5)</td><td align="left">0.4</td><td align="left">0.2&#x02013;0.6</td><td align="left">4.3</td><td align="left">111.5</td><td align="left">0.00</td></tr><tr><td align="left">Concept knowledge</td><td align="left">1.3 (0.4)</td><td align="left">1.1 (0.4)</td><td align="left">0.2</td><td align="left">0.0&#x02013;0.3</td><td align="left">2.6</td><td align="left">115.3</td><td align="left">0.01</td></tr><tr><td align="left">Attitudes</td><td align="left">5.4 (0.8)</td><td align="left">5.2 (0.7)</td><td align="left">0.1</td><td align="left">-0.2&#x02013;0.4</td><td align="left">0.9</td><td align="left">115</td><td align="left">0.37</td></tr><tr><td align="left"></td><td align="left">(n = 56)</td><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td></tr><tr><td align="left">Decision-to-adopt</td><td align="left">4.9 (1.2)</td><td align="left">5.1 (0.9)</td><td align="left">-0.2</td><td align="left">-0.6&#x02013;0.2</td><td align="left">-0.9</td><td align="left">97.8</td><td align="left">0.35</td></tr><tr><td align="left">Self-efficacy</td><td align="left">4.0 (0.9)</td><td align="left">3.9 (0.9)</td><td align="left">0.1</td><td align="left">-0.2&#x02013;0.4</td><td align="left">0.5</td><td align="left">116.9</td><td align="left">0.60</td></tr><tr><td align="left">Job-satisfaction</td><td align="left">4.3 (1.3)</td><td align="left">4.0 (1.2)</td><td align="left">0.3</td><td align="left">-0.1&#x02013;0.8</td><td align="left">1.5</td><td align="left">114.6</td><td align="left">0.13</td></tr></tbody></table><table-wrap-foot><p><italic>Knowledge of sources: </italic>Mean of additive score of 0 = 'unknown', 1 = 'known, but not used', 2 = 'read', 3 = 'used in a public health decision-making situation'. <italic>Knowledge of concepts </italic>: Mean of additive score of 0 = 'unknown', 1 ='known', 2 = 'so known that I can explain to others' + an extra point (1) if correctly answering "Method chapter" as to what is the most important chapter for deciding scientific quality of an article. <italic>Attitudes: </italic>Likert scale: 1 = 'totally disagree', 2 = 'disagree', 3 = 'partly disagree', 4 = 'neither agree nor disagree', 5 = 'partly agree', 6 = 'agree', 7 = 'totally disagree'. Decision-to-adopt: Likert scale: 1 = 'totally incorrect', 2 = 'incorrect', 3 = 'Somewhat incorrect' 4 = 'neither right nor wrong', 5 = 'somewhat correct', 6 = 'correct', 7 = 'totally correct'. <italic>Job-satisfaction: </italic>Same Likert scale as attitudes.</p></table-wrap-foot></table-wrap></sec><sec><title>Ancillary analyses</title><p>The variables in the regression model were the group variable, baseline score and the variables demonstrating a potential important imbalance between the groups. The analysis changed the result for the self-reported variable 'searching Cochrane', which became non-significant. There was no substantial change for the other two significant results (data not shown).</p></sec></sec><sec><title>Discussion</title><sec><title>Interpretation</title><p>This study is of interest because it is the first empirically and theoretically based tailored multifaceted intervention for diffusing the whole process of evidence-based practice in a randomised-controlled design. The intervention had some effect on knowledge reported. This supports the conclusion from a recent systematic review [<xref ref-type="bibr" rid="B21">21</xref>] that teaching critical appraisal skills in health care settings has positive effects on participants' knowledge. However, even when combining teaching with an intervention encompassing the whole process of evidence-based practice (and not just critical appraisal) including supportive elements like an information service, discussion list and newsletter, there was no evidence of impact on decision-making. Most importantly, this study does not support the hypothesis that a multifaceted intervention targeted at selected barriers changes professional behaviour [<xref ref-type="bibr" rid="B22">22</xref>].</p><p>According to diffusion-theory "the rate of awareness-knowledge for an innovation is more rapid than its rate of adoption" [<xref ref-type="bibr" rid="B8">8</xref>]. Innovations that can be tested and are simple and compatible with previous experience and practice have a shorter innovation-decision period. Measuring performance after a period of 1.5 year may still have been a too short time perspective. It appears that our intervention successfully led the participants through the stage of increasing knowledge, but did not reach the stage of persuasion. A change in knowledge is a necessary but insufficient criterion for changing practice, and, as it seems, also for changing attitudes and feeling of self-efficacy. The lack of evidence of effect on the variables 'advice followed' and 'job satisfaction' (Figure <xref ref-type="fig" rid="F1">1</xref>) is predictable from the lack of evidence of effect on practice. Although 43 out of 47 (3 missing) stated goals on leaving the workshop for how they would adopt evidence-based practice, this did not seem to strengthen the change process. A meta-analysis by Wood et al. [<xref ref-type="bibr" rid="B23">23</xref>] reported that goal-setting effects are maximised for easy tasks. Since the majority of public health tasks are complex, one might anticipate a modest effect.</p><p>The adjustment analysis by multiple regression analysis did not change the interpretation of our results regarding the intermediate variables. The logistic regression analysis of the self-reported searching of Cochrane is more difficult to interpret, since the change in results may be due to a loss in power when including only those who have answered both pre- and post tests.</p></sec><sec><title>Limitations of the study</title><sec><title>Statistical validity</title><p>Some relevant potential threats to the statistical conclusion validity of our study could be: low statistical power, unreliability of measures and unreliability of treatment implementation [<xref ref-type="bibr" rid="B24">24</xref>]. As for the first threat, the probability of making a faulty no-difference conclusion, i.e. a Type II error, increases when sample sizes are small. In our study the response rate for reports at post-test was especially low (Table <xref ref-type="table" rid="T7">7</xref>). We could have made a greater effort to obtain more documents and thus increased the amount of data collected. However, we chose not to pursue this matter, since we received the same information through the postal survey: We are reasonably confident that the physicians would have reported being involved in writing either types of documents (reports and advice-giving documents). In addition, behaviour was also measured by the telephone survey.</p><p>The reliability of the instruments measuring the constructs; attitudes, self-efficacy, decision-to-adopt and job-satisfaction was tested for internal consistency and was satisfactory. Likewise, the weighted Kappa measure of inter-rater consistency for the use of criteria lists was of adequate size. The variables 'searching Cochrane/Medline' (Table <xref ref-type="table" rid="T8">8</xref>) were checked against the search logs.</p><p>Several of the null hypotheses regarding outcome variables were not rejected (Table <xref ref-type="table" rid="T9">9</xref>). Recalculating the power with the variances obtained in the study shows that the size of the study was big enough to detect 0.5 SD changes with more than 80% power, as intended. Though the changes in the non-significant results are less than 0.5 SD, the confidence intervals are so wide (Table <xref ref-type="table" rid="T9">9</xref>) that we cannot accept the null hypothesis on the basis of the statistical analysis. On the other hand, the 'Users' guide to the medical literature' states that if the upper boundary of the confidence interval excludes any important benefit of the intervention, one may conclude that the trial is negative [<xref ref-type="bibr" rid="B25">25</xref>].</p><p>With this type of study there is always some difficulty of standardising the implementation of the intervention. According to Cook and Campbell [<xref ref-type="bibr" rid="B24">24</xref>] lack of standardisation will inflate error variance and decrease the chance of obtaining true differences. On the other hand, lack of standardisation is typical for pragmatic trials and reflects real situations [<xref ref-type="bibr" rid="B26">26</xref>]. There is a theoretical possibility that the intervention was never really adequately implemented, e.g. the quality of the educational part of the intervention may have been insufficient regarding both teaching methods and duration.</p></sec><sec><title>Internal validity</title><p>The risk of contamination between groups was felt to be limited since public health physicians in Norway are geographically scattered; one physician in each of the country's 435 municipalities. This initial assumption was supported by the fact that none of the physicians in the control group were recorded to use the library services offered. However, during the intervention period evidence-based practice was discussed in other public health settings. This may have influenced the general level of knowledge on the topic.</p><p>For those who provided post-test data, the response rates were fairly similar between the groups. Some physicians had changed jobs and some stated they did not have time, but there was no evidence of a differential attrition between the groups.</p></sec><sec><title>Construct validity</title><p>It is debatable how far the operalisations of the theoretical construct 'multifaceted intervention' on the input side, actually reflected this construct and whether the measurements of dependent variables really did measure what they were meant to measure. However, the theoretical foundation should to some extent account for face and content validity. Moreover, the discriminant validity of the instruments measuring attitudes, self-efficacy, decision-to-adopt and job-satisfaction was shown to be satisfactory by the low correlation between each of these indexes.</p><p>By using alternative measures of the primary outcome, with different means of recording responses (Tables <xref ref-type="table" rid="T6">6</xref>,<xref ref-type="table" rid="T7">7</xref>), a potential threat from mono-method bias should have been met. The experiment group could, however, have guessed the hypothesis of the study to a greater extent than the control group. The differences we found in knowledge might reflect either this or the greater attention given to the experiment group.</p></sec><sec><title>Generalisability</title><p>The study sample contained highly motivated and interested physicians with some skills in data technology and working experience in rural and urban settings. Considering that this group could be characterized with Rogers' terminology as 'innovators' or 'early adopters' the results are rather disappointing.</p></sec></sec></sec><sec><title>Conclusion</title><p>The multi-faceted intervention demonstrated effect on knowledge, but failed to demonstrate any other positive effects on the intermediate steps required to disseminate and implement (diffuse) new practice according to Roger's theoretical model. It is therefore not surprising that practitioners did not increase the use of evidence in practice.</p><p>Efforts to promote evidence-based practice could be strengthened by utilising networks and infrastructures that already exist. First and foremost, evidence-based methodology should become an integral part of undergraduate and continuing medical education. Central and local authorities, which support public health physicians, should use evidence-based methods to inform decision-making, for example in central strategy documents. We suspect, however, that this requires a culture shift regarding the perceived necessity for utilising research information on health issues.</p><p>The reasons underlying the program's failure to demonstrate any further effect cannot be illuminated by a randomised controlled design. As discussed by Wolff [<xref ref-type="bibr" rid="B27">27</xref>] and others [<xref ref-type="bibr" rid="B28">28</xref>,<xref ref-type="bibr" rid="B29">29</xref>] there may be some inherent problems in using the randomised trial design to evaluate social complex interventions. Moreover, effectiveness evaluations do not give much information on or understanding of the processes involved between program delivery and outcome [<xref ref-type="bibr" rid="B30">30</xref>]. A qualitative investigation of these processes may increase understanding and is, in this case, already in progress.</p></sec><sec><title>Competing interests</title><p>None declared.</p></sec><sec><title>Authors' contributions</title><p>LForsetlund participated in the conception and design of the trial, as well as analysing and interpreting data and writing the article. PB participated in the trial intervention, in the drafting, editing and critical revision of the article. LForsen participated in the analysis and interpretation of the data and in the critical revision of the article. LN participated in the trial intervention, collecting of data and in the critical revision of the article. GJ participated in the trial intervention and in the critical revision of the article. AB was responsible for the conception and design of the whole trial, and participated in the drafting and critical revision of the article. All authors read and approved the final manuscript.</p></sec><sec><title>Pre-publication history</title><p>The pre-publication history for this paper can be accessed here:</p><p><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6920/3/2/prepub"/></p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="S1"><caption><title>Additional file 1</title><p>A description of the goal, timing and content of the intervention and which media we used.</p></caption><media xlink:href="1472-6920-3-2-S1.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material></sec></body><back><ack><sec><title>Acknowledgements</title><p>We thank Einar Braaten, Tore Ytterdahl and Jon Hilmar Iversen for their help and support. Also we would like to extend our thanks to the participating public health physicians and The Norwegian Research Council who funded the project.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grol</surname><given-names>R</given-names></name><name><surname>Grimshaw</surname><given-names>J</given-names></name></person-group><article-title>Evidence-based implementation of evidence-based medicine.</article-title><source>Jt Comm J Qual Improv</source><year>1999</year><volume>25</volume><fpage>503</fpage><lpage>513</lpage><pub-id pub-id-type="pmid">10522231</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><collab>NHS Centre for Reviews and Dissemination</collab></person-group><article-title>Getting evidence into practice.</article-title><source>Effective Health Care</source><year>1999</year><volume>5</volume><fpage>1</fpage><lpage>16</lpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moulding</surname><given-names>NT</given-names></name><name><surname>Silagy</surname><given-names>CA</given-names></name><name><surname>Weller</surname><given-names>DP</given-names></name></person-group><article-title>A framework for effective management of change in clinical practice: dissemination and implementation of clinical practice guidelines.</article-title><source>Qual Health Care</source><year>1999</year><volume>8</volume><fpage>177</fpage><lpage>183</lpage><pub-id pub-id-type="pmid">10847875</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>M</given-names></name><name><surname>Fitzpatrick</surname><given-names>R</given-names></name><name><surname>Haines</surname><given-names>A</given-names></name><name><surname>Kinmonth</surname><given-names>AL</given-names></name><name><surname>Sandercock</surname><given-names>P</given-names></name><name><surname>Spiegelhalter</surname><given-names>D</given-names></name><name><surname>Tyrer</surname><given-names>P</given-names></name></person-group><article-title>Framework for design and evaluation of complex interventions to improve health.</article-title><source>BMJ</source><year>2000</year><volume>321</volume><fpage>694</fpage><lpage>696</lpage><pub-id pub-id-type="pmid">10987780</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Forsetlund</surname><given-names>L</given-names></name><name><surname>Bj&#x000f8;rndal</surname><given-names>A</given-names></name></person-group><article-title>Har samfunnsmedisinere tilfredsstillende tilgang til viktige informasjonskilder? [Do public health practitioners have satisfactory access to important information sources?]</article-title><source>Tidsskrift for Den Norske Laegeforening</source><year>1999</year><volume>119</volume><fpage>2456</fpage><lpage>2462</lpage><pub-id pub-id-type="pmid">10425895</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Forsetlund</surname><given-names>L</given-names></name><name><surname>Bj&#x000f8;rndal</surname><given-names>A</given-names></name></person-group><article-title>The potential for research-based information in public health: identifying unrecognised information needs.</article-title><source>BMC Public Health</source><year>2001</year><volume>1</volume><fpage>1</fpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2458/1/1"/><pub-id pub-id-type="pmid">11208260</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Forsetlund</surname><given-names>L</given-names></name><name><surname>Bj&#x000f8;rndal</surname><given-names>A</given-names></name></person-group><article-title>Identifying barriers to the use of research faced by public health physicians in Norway and developing an intervention to reduce them.</article-title><source>J Health Serv Res and Pol</source><year>2002</year><volume>7</volume><fpage>10</fpage><lpage>18</lpage></citation></ref><ref id="B8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>EM</given-names></name></person-group><article-title>Diffusion of innovation.</article-title><source>New York, The Free Press</source><year>1995</year><edition>4</edition></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>D</given-names></name><name><surname>Thomson O'Brien</surname><given-names>MA</given-names></name><name><surname>Freemantle</surname><given-names>N</given-names></name><name><surname>Wolf</surname><given-names>FM</given-names></name><name><surname>Mazmanian</surname><given-names>P</given-names></name><name><surname>Taylor-Vaisey</surname><given-names>A</given-names></name></person-group><article-title>Impact of formal continuing medical education: do conferences, workshops, rounds, and other traditional continuing education activities change physician behavior or health care outcomes?</article-title><source>JAMA</source><year>1999</year><volume>282</volume><fpage>867</fpage><lpage>874</lpage><pub-id pub-id-type="pmid">10478694</pub-id></citation></ref><ref id="B10"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Locke</surname><given-names>EA</given-names></name><name><surname>Latham</surname><given-names>GP</given-names></name></person-group><article-title>A theory of goal setting &#x00026; task performance.</article-title><source>Englewood Cliffs, Prentice-hall</source><year>1990</year></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>AM</given-names></name><name><surname>Young</surname><given-names>DM</given-names></name><name><surname>Dela Cruz</surname><given-names>FA</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Strickland OL, Waltz FC</surname></name></person-group><article-title>Evaluating prototype nursing continuing education programs.</article-title><source>Measurement of nursing outcomes: Measuring nursing performance</source><year>1988</year><volume>2</volume><publisher-name>New York, Springer</publisher-name><fpage>349</fpage><lpage>363</lpage></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>McColl</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>H</given-names></name><name><surname>White</surname><given-names>P</given-names></name><name><surname>Field</surname><given-names>J</given-names></name></person-group><article-title>General practitioners' perceptions of the route to evidence based medicine: a questionnaire survey.</article-title><source>BMJ</source><year>1998</year><volume>316</volume><fpage>361</fpage><lpage>365</lpage><pub-id pub-id-type="pmid">9487174</pub-id></citation></ref><ref id="B13"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Schwarzer</surname><given-names>R</given-names></name><name><surname>Fuchs</surname><given-names>R</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Conner M, Norman P</surname></name></person-group><article-title>Self-efficacy and health behaviours.</article-title><source>Predicting health behaviour: research and practice with social cognition models</source><year>1996</year><publisher-name>Buckingham, Open University Press</publisher-name><fpage>163</fpage><lpage>196</lpage></citation></ref><ref id="B14"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Conner</surname><given-names>M</given-names></name><name><surname>Sparks</surname><given-names>P</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Conner M, Norman P</surname></name></person-group><article-title>The theory of planned behaviour and health behaviours.</article-title><source>Predicting health behaviour: research and practice with social cognition models</source><year>1996</year><publisher-name>Buckingham, Open University Press</publisher-name><fpage>121</fpage><lpage>155</lpage></citation></ref><ref id="B15"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Spector</surname><given-names>PE</given-names></name></person-group><article-title>Summated rating scale construction.</article-title><source>London, Sage Publications 1992 Sage university papers series: Quantitative applications in the social sciences, no82</source></citation></ref><ref id="B16"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Henerson</surname><given-names>ME</given-names></name><name><surname>Morris</surname><given-names>LL</given-names></name><name><surname>Fitz-Gibbon</surname><given-names>CT</given-names></name></person-group><article-title>How to measure attitudes.</article-title><source>London, Sage</source><year>1987</year></citation></ref><ref id="B17"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>GL</given-names></name></person-group><article-title>MIS/DSS success measure: Systems objectives and solutions</article-title><year>1984</year><volume>4</volume><fpage>29</fpage><lpage>34</lpage><ext-link ext-link-type="uri" xlink:href="http://wings.buffalo.edu/mgmt/courses/mgtsand/success/success.html"/><comment>[cited 2001 Oct 18].</comment></citation></ref><ref id="B18"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Seashore</surname><given-names>SE</given-names></name><name><surname>Lawler III</surname><given-names>EE</given-names></name><name><surname>Mirvis</surname><given-names>PH</given-names></name><name><surname>Camman</surname><given-names>C</given-names></name><collab>editors</collab></person-group><article-title>Assessing organizational change: A guide to methods, measures, and practices.</article-title><source>New York, Wiley 1983 Wiley series on organizational assessment and change</source></citation></ref><ref id="B19"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Hinkle</surname><given-names>DW</given-names></name><name><surname>Wiersma</surname><given-names>W</given-names></name><name><surname>Jurs</surname><given-names>SG</given-names></name></person-group><article-title>Applied statistics for the behavioral sciences.</article-title><source>Boston, Houghton Mifflin Company</source><year>1988</year></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>AJ</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><article-title>Analysing controlled trials with baseline and follow up measurements.</article-title><source>BMJ</source><year>2001</year><volume>323</volume><fpage>1123</fpage><lpage>1124</lpage><pub-id pub-id-type="pmid">11701584</pub-id></citation></ref><ref id="B21"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Parkes</surname><given-names>J</given-names></name><name><surname>Hyde</surname><given-names>C</given-names></name><name><surname>Deeks</surname><given-names>J</given-names></name><name><surname>Milne</surname><given-names>R</given-names></name></person-group><article-title>Teaching critical appraisal skills in health care settings (Cochrane Review):</article-title><source>The Cochrane Library, Issue 3, 2001. Oxford: Update Software</source></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Shirran</surname><given-names>L</given-names></name><name><surname>Thomas</surname><given-names>R</given-names></name><name><surname>Mowatt</surname><given-names>G</given-names></name><name><surname>Fraser</surname><given-names>C</given-names></name><name><surname>Bero</surname><given-names>L</given-names></name><name><surname>Grilli</surname><given-names>R</given-names></name><name><surname>Harvey</surname><given-names>E</given-names></name><name><surname>Oxman</surname><given-names>A</given-names></name><name><surname>O'Brien</surname><given-names>MA</given-names></name></person-group><article-title>Changing provider behavior: an overview of systematic reviews of interventions.</article-title><source>Med Care</source><year>2001</year><volume>39</volume><fpage>II2</fpage><lpage>45</lpage><pub-id pub-id-type="pmid">11583120</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>RE</given-names></name><name><surname>Mento</surname><given-names>AJ</given-names></name><name><surname>Locke</surname><given-names>EA</given-names></name></person-group><article-title>Task complexity as a moderator of goal effects: A meta-analysis.</article-title><source>J Appl Psychol</source><year>1987</year><volume>72</volume><fpage>416</fpage><lpage>425</lpage></citation></ref><ref id="B24"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>TD</given-names></name><name><surname>Campbell</surname><given-names>DT</given-names></name></person-group><article-title>Quasi-experimentation: Design &#x00026; analysis issues for field settings.</article-title><source>London, Houghton Mifflin Company</source><year>1979</year></citation></ref><ref id="B25"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Guyatt</surname><given-names>G</given-names></name><name><surname>Rennie</surname><given-names>D</given-names></name></person-group><article-title>Users' guides to the medical literature: a manual for evidence-based clinical practice.</article-title><source>Chicago, AMA Press</source><year>2002</year></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roland</surname><given-names>M</given-names></name><name><surname>Torgerson</surname><given-names>DJ</given-names></name></person-group><article-title>Understanding controlled trials: what are pragmatic trials?</article-title><source>BMJ</source><year>1998</year><volume>316</volume><fpage>285</fpage><pub-id pub-id-type="pmid">9472515</pub-id></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>N</given-names></name></person-group><article-title>Randomised trials of socially complex interventions: promise or peril?</article-title><source>J Health Serv Res Policy</source><year>2001</year><volume>6</volume><fpage>123</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">11357244</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>GR</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name></person-group><article-title>Effectiveness of problem-based learning curricula: theory practice and paper darts.</article-title><source>Med Ed</source><year>2000</year><volume>34</volume><fpage>721</fpage><lpage>728</lpage></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Prideaux</surname><given-names>D</given-names></name></person-group><article-title>Researching outcomes of educational interventions: a matter of design.</article-title><source>BMJ</source><year>2002</year><volume>324</volume><fpage>126</fpage><lpage>127</lpage><pub-id pub-id-type="pmid">11799017</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lipsey</surname><given-names>MW</given-names></name></person-group><article-title>Theory as method: Small theories of treatments.</article-title><source>New Directions for Program Evaluation</source><year>1993</year><volume>Spring</volume><fpage>5</fpage><lpage>38</lpage></citation></ref></ref-list></back></article>


