<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Aging Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Aging Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Aging Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Aging Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1663-4365</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25360112</article-id><article-id pub-id-type="pmc">4197792</article-id><article-id pub-id-type="doi">10.3389/fnagi.2014.00284</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>The cognitive effects of listening to background music on older adults: processing speed improves with upbeat music, while memory seems to benefit from both upbeat and downbeat music</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bottiroli</surname><given-names>Sara</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/174931"/></contrib><contrib contrib-type="author"><name><surname>Rosi</surname><given-names>Alessia</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/167292"/></contrib><contrib contrib-type="author"><name><surname>Russo</surname><given-names>Riccardo</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/123649"/></contrib><contrib contrib-type="author"><name><surname>Vecchi</surname><given-names>Tomaso</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/79914"/></contrib><contrib contrib-type="author"><name><surname>Cavallini</surname><given-names>Elena</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/135125"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Brain Connectivity Center, National Neurological Institute C. Mondino</institution><country>Pavia, Italy</country></aff><aff id="aff2"><sup>2</sup><institution>Brain and Behavioral Sciences Department, University of Pavia</institution><country>Pavia, Italy</country></aff><aff id="aff3"><sup>3</sup><institution>Department of Psychology, University of Essex</institution><country>Essex, UK</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Nicola Mammarella, University of Chieti, Italy</p></fn><fn fn-type="edited-by"><p>Reviewed by: Harry J. Witchel, University of Sussex, UK; Richard Camicioli, McGill University, Canada</p></fn><corresp id="fn001">*Correspondence: Sara Bottiroli, Brain and Behavioral Sciences Department, University of Pavia, Piazza Botta, 6 Pavia, PV 27100, Italy e-mail: <email xlink:type="simple">sara.bottiroli@unipv.it</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to the journal Frontiers in Aging Neuroscience.</p></fn></author-notes><pub-date pub-type="epreprint"><day>31</day><month>8</month><year>2014</year></pub-date><pub-date pub-type="epub"><day>15</day><month>10</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>6</volume><elocation-id>284</elocation-id><history><date date-type="received"><day>24</day><month>7</month><year>2014</year></date><date date-type="accepted"><day>26</day><month>9</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Bottiroli, Rosi, Russo, Vecchi and Cavallini.</copyright-statement><copyright-year>2014</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution and reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Background music refers to any music played while the listener is performing another activity. Most studies on this effect have been conducted on young adults, while little attention has been paid to the presence of this effect in older adults. Hence, this study aimed to address this imbalance by assessing the impact of different types of background music on cognitive tasks tapping declarative memory and processing speed in older adults. Overall, background music tended to improve performance over no music and white noise, but not always in the same manner. The theoretical and practical implications of the empirical findings are discussed.</p></abstract><kwd-group><kwd>background music</kwd><kwd>arousal</kwd><kwd>mood</kwd><kwd>processing speed</kwd><kwd>episodic memory</kwd><kwd>semantic memory</kwd><kwd>aging</kwd></kwd-group><counts><fig-count count="0"/><table-count count="2"/><equation-count count="0"/><ref-count count="55"/><page-count count="7"/><word-count count="6319"/></counts></article-meta></front><body><sec sec-type="introduction" id="s1"><title>Introduction</title><p>Background music refers to any music that is played while the listener&#x02019;s primary attention is focused on another task or activity (Radocy and Boyle, <xref rid="B40" ref-type="bibr">1988</xref>). This background music effect differs from the so-called Mozart effect (Rauscher et al., <xref rid="B41" ref-type="bibr">1993</xref>), which refers to the changes in cognitive abilities following listening to music. Despite the above difference, there is consensus on these effects to operate on common mechanisms (Schellenberg and Weiss, <xref rid="B48" ref-type="bibr">2013</xref>). The present study primarily focused on the background music effect.</p><p>Some studies on the effect of background music on performance in cognitive tasks have shown improvements in episodic memory (Ferreri et al., <xref rid="B11" ref-type="bibr">2013</xref>), IQ scores (Cockerton et al., <xref rid="B6" ref-type="bibr">1997</xref>), verbal and visual processing speed (Angel et al., <xref rid="B1" ref-type="bibr">2010</xref>), arithmetic skill (Hallam and Price, <xref rid="B16" ref-type="bibr">1998</xref>), reading (Oliver, <xref rid="B34" ref-type="bibr">1997</xref>), and second languages learning (Kang and Williamson, <xref rid="B24" ref-type="bibr">2013</xref>). However, there is also evidence of reduced performance when background music is present (see K&#x000e4;mpfe et al., <xref rid="B23" ref-type="bibr">2010</xref> for a review).</p><p>According to the &#x0201c;arousal and mood hypothesis&#x0201d; (Thompson et al., <xref rid="B55" ref-type="bibr">2001</xref>), the positive effect of music on human behavior is considered to be a consequence of the impact of music on mood and arousal. In particular, listening to music affects arousal (degree of physiological activation), mood (long lasting emotions), and listener&#x02019;s enjoyment, which in turn influence cognitive performance (Hallam et al., <xref rid="B17" ref-type="bibr">2002</xref>). The impact of music on arousal and on mood of listeners seems to be determined by the tempo (fast vs. slow) and the mode (major vs. minus) of the music itself, respectively (Gabrielsson and Lindstr&#x000f6;m, <xref rid="B15" ref-type="bibr">2010</xref>). In particular, as reported in the context of the Mozart effect, fast tempo and major mode music tend to induce a positive/happy mood and higher arousal levels, whereas slow tempo and minor mode music induce a more negative/sad mood and lower arousal levels (e.g., Husain et al., <xref rid="B19" ref-type="bibr">2002</xref>; Hunter and Schellenberg, <xref rid="B18" ref-type="bibr">2010</xref>). Moreover, the effects of these different levels of mood and arousal seem to vary depending on the cognitive abilities considered. In particular, several studies investigating the Mozart effect reported benefits primarily using tasks tapping processing speed and visuo-spatial abilities but only when the music had a fast tempo and a major mode (e.g., Thompson et al., <xref rid="B55" ref-type="bibr">2001</xref>; Husain et al., <xref rid="B19" ref-type="bibr">2002</xref>; Schellenberg et al., <xref rid="B47" ref-type="bibr">2007</xref>).</p><p>Conversely, disturbing and interfering effects of background music have been reported for multimedia learning (Moreno and Mayer, <xref rid="B30" ref-type="bibr">2000</xref>), surgeons learning of new procedures (Miskovic et al., <xref rid="B29" ref-type="bibr">2008</xref>), mathematics (Bloor, <xref rid="B4" ref-type="bibr">2009</xref>), and reading (Madsen, <xref rid="B26" ref-type="bibr">1987</xref>). These negative findings could be explained by the &#x0201c;cognitive-capacity hypothesis&#x0201d; (Kahneman, <xref rid="B22" ref-type="bibr">1973</xref>), positing that a limited pool of resources is available for cognitive processing at any given moment (Baddeley, <xref rid="B2" ref-type="bibr">2003</xref>), thus background music can disrupt cognitive tasks when there is a potential for interference (e.g., Polzella and Schoeling, <xref rid="B38" ref-type="bibr">2004</xref>) due to an overtax of resources (Norman and Bobrow, <xref rid="B33" ref-type="bibr">1975</xref>). In particular, detrimental effects related to background music seem to be modulated by task complexity: the more complex and demanding the task, the stronger is the detrimental effect of music (Furnham and Bradley, <xref rid="B14" ref-type="bibr">1997</xref>; Furnham and Allass, <xref rid="B13" ref-type="bibr">1999</xref>). In summary, with respect to the background music effect there are conflicting results as well as conflicting theoretical approaches that may, in principle, provide a unified account of the effect (or lack of it) on the basis of task complexity. When task complexity surpasses some critical threshold, then performance is impaired. Conversely, below a certain level of task complexity the arousal and mood hypothesis may account for some beneficial effects of background music on task performance. While this theoretical stance may be appealing, it is not clear why background music, below certain levels of task complexity, it is not simply neutral, but it is indeed beneficial.</p><p>An interesting way to test the potential merit of the above hypotheses consists of assessing the background music effect on older adults. Given that normal aging is particularly associated with deficits in inhibiting irrelevant information and with deficits in tasks performed under divided attention (e.g., Parks, <xref rid="B37" ref-type="bibr">2007</xref>), background music should negatively affect performance in cognitive tasks in older adults. Hence, if background music does provide a beneficial effect to performance in cognitive tasks in older adults, then the validity of the &#x0201c;cognitive capacity hypothesis&#x0201d; would be weakened. Therefore, the present study intended to assess the impact of background music on the performance of older adults in cognitive tasks.</p><p>To the best of our knowledge, only three studies had been conducted on normal aging (Thompson et al., <xref rid="B54" ref-type="bibr">2005</xref>; Mammarella et al., <xref rid="B27" ref-type="bibr">2007</xref>; Ferreri et al., <xref rid="B12" ref-type="bibr">2014</xref>). These compared the effects of listening to music excerpt with high tempo and major mode vs. no-music on word fluency (Thompson et al., <xref rid="B54" ref-type="bibr">2005</xref>; Mammarella et al., <xref rid="B27" ref-type="bibr">2007</xref>), on working memory (Mammarella et al., <xref rid="B27" ref-type="bibr">2007</xref>), and on recognition memory (Ferreri et al., <xref rid="B12" ref-type="bibr">2014</xref>). Interestingly, they all reported a specific positive effect of the background music that was able to enhance performance on the cognitive abilities examined. However, these studies in failing to include a negative emotional-valence background music (low tempo in minor mode), did not provide a thorough assessment of the impact of background music on cognitive tasks. Hence, in the present study we included two different types of background music. We selected Mozart&#x02019;s Eine Kleine Nachtmusik (positive background music with fast tempo and major mode) and Mahler&#x02019;s 5th Symphony Adagietto (negative background music with slow tempo and minor mode), on the basis that these two pieces of music have been shown to induce happy and sad moods, and high and low arousal levels, respectively (Niedenthal and Setterlund, <xref rid="B31" ref-type="bibr">1994</xref>; Storbeck and Clore, <xref rid="B53" ref-type="bibr">2005</xref>; Riener et al., <xref rid="B44" ref-type="bibr">2011</xref>). Furthermore, we also used two control conditions: a no-music and a white noise control conditions to assess whether music improves (impairs) performance over baseline conditions. In particular, the white noise refers to a special type of environmental stimulation consisting in the exposure to a continuous auditory signal. Previous evidences on white noise have produced mixed findings, reporting some instances of disturbing effects due to a competition for cognitive resources (e.g., Hygge et al., <xref rid="B20" ref-type="bibr">2003</xref>; Boman et al., <xref rid="B5" ref-type="bibr">2005</xref>) and others demonstrating that it was able to promote learning in those subjects with attentional deficits thanks to an increase of arousal levels (e.g., S&#x000f6;derlund et al., <xref rid="B52" ref-type="bibr">2007</xref>, <xref rid="B51" ref-type="bibr">2010</xref>).</p><p>In order to evaluate the effects of background music on different cognitive abilities, we used tests tapping processing speed and declarative memory. Our decision was driven by three main reasons. Firstly, processing speed is one of those abilities sensitive to the tempo and the mode of the music in those studies involving students (e.g., Schellenberg et al., <xref rid="B47" ref-type="bibr">2007</xref>; Angel et al., <xref rid="B1" ref-type="bibr">2010</xref>), thus it could represent a clear probe of the possible different effects of positive and negative background music in older adults. Second, the effect of background music on memory is rather controversial in the literature on young adults, with evidences of both beneficial effects (e.g., Ferreri et al., <xref rid="B11" ref-type="bibr">2013</xref>) and detrimental effects (e.g., Moreno and Mayer, <xref rid="B30" ref-type="bibr">2000</xref>; Miskovic et al., <xref rid="B29" ref-type="bibr">2008</xref>). Hence, we intended to assess the impact of different types of background music on tests tapping what are nominally called episodic memory (free recall) and semantic memory (phonemic fluency). Third, both processing speed and memory are cognitive abilities mostly affected by aging (see Salthouse, <xref rid="B46" ref-type="bibr">2004</xref>), thus it is of interest to assess whether background music may have a negative or positive effects on these tasks among older adults.</p><p>Because of the above theoretical considerations, some speculations could be put forward. On one hand, if older adults are sensitive to the &#x0201c;arousal and mood&#x0201d; effect of music (Thompson et al., <xref rid="B55" ref-type="bibr">2001</xref>), their performance should be enhanced by background music in comparison to the two control conditions (no-music and white noise) with different effects between the positive and the negative condition. With respect to processing speed, performance should improve while listening to the fast tempo and major background music compared to a slow tempo and minor mode background music (e.g., Schellenberg et al., <xref rid="B47" ref-type="bibr">2007</xref>). With respect to memory, prior research suggested that fast tempo and major mode background music should improve performance in the elderly (Mammarella et al., <xref rid="B27" ref-type="bibr">2007</xref>; Ferreri et al., <xref rid="B12" ref-type="bibr">2014</xref>). To the best of our knowledge the effect of a slow tempo and minor mode background music on memory among older adults has not been investigated.</p><p>On the other hand, according to the &#x0201c;cognitive-capacity hypothesis&#x0201d; (Kahneman, <xref rid="B22" ref-type="bibr">1973</xref>), we should expect that in the tasks used performance among older adults when exposed to no-music will be significantly greater than in the other experimental conditions.</p></sec><sec id="s2"><title>Material and method</title><sec id="s2-1"><title>Participants</title><p>Sixty-five non musicians older adults took part in the study. Their mean age was 69.03 (<italic>SD</italic> = 5.79; age range 60&#x02013;84 years; 51 females and 14 males) and mean of education was 12.29 years (<italic>SD</italic> = 3.88). Exclusion criteria included history of psychiatric or neurological disorders, substance abuse and a score of 23 or higher on the Center for Epidemiological Studies Depression Scale (CES-D; Radloff, <xref rid="B39" ref-type="bibr">1977</xref>; Italian version, Fava, <xref rid="B10" ref-type="bibr">1983</xref>). None of the participants was excluded on the basis of the above criteria. A Vocabulary test (PMA; Thurstone and Thurstone, <xref rid="B56" ref-type="bibr">1963</xref>) was also included in the study to assess crystallized intelligence. They had a mean score of 45.69 on Vocabulary test (<italic>SD</italic> = 3.67) out of a maximum of 50, and a mean score of 15.56 on the CES-D (<italic>SD</italic> = 6.83). All participants completed and accepted an informed consent form prior to the beginning of the experiment.</p></sec><sec id="s2-2"><title>Instruments</title><p>All participants undertook the Vocabulary subtest and the CES-D as control variable measures and three paper-and-pencil cognitive tasks to assess, respectively, declarative memory (episodic memory and semantic memory) and processing speed.</p><sec id="s2-2-1"><title>Vocabulary</title><p>In the Vocabulary subtest participants were asked to identify the correct synonym of 50 target words within 8 min. Total scores could range from 0 to 50.</p></sec><sec id="s2-2-2"><title>Depression</title><p>The CES-D consisted of 20 multiple-choices questions, asking participants to rate the frequency with which they have experienced depressive symptoms during the past week. Responses for each questions range from 0 (<italic>rarely or none of the time</italic>) to 3 (<italic>most or all of the time</italic>). Possible scores could range from 0 to 60.</p></sec><sec id="s2-2-3"><title>Declarative memory</title><p><italic>Episodic memory</italic>. Participants were presented with a list of 15 concrete words in order to assess the episodic memory. Lists of word were presented visually on the screen. Participants were instructed to commit to memory the list in a study period of 2 min and, immediately after presentation, were given 2 min to write down, in any order, as many words as could they remembered. We developed four parallel versions of the words-lists in order to assess the same task in the four different conditions. The words were taken from Paivio et al. (<xref rid="B35" ref-type="bibr">1968</xref>) words norms and the four parallel versions did not significantly differ in term of imagery, concreteness and frequency of use. The episodic memory score used was obtained by subtracting the intrusion words from the number of correctly recalled words.</p><p><italic>Semantic memory</italic>. To assess semantic memory, a phonemic fluency task was used. Participants were asked to write down on an answer sheet, as many words as possible beginning with three different letters of the alphabet. They were instructed that proper names, place and words with the same suffix were not credited. We developed four parallel versions of the phonemic fluency task, by changing the starting letters, in order to assess the same task in the four different conditions. Participants were given 90 s for each letter, and semantic memory score used was obtained by subtracting the words erroneously produced (e.g., proper nouns and repetition) from the number of correct words.</p></sec><sec id="s2-2-4"><title>Processing speed</title><p>To assess processing speed in the visual modality, the Symbol Digit Modalities Test (SDMT; Smith, <xref rid="B49" ref-type="bibr">1982</xref>; Italian version, Nocentini et al., <xref rid="B32" ref-type="bibr">2006</xref>) was used. At the top of an A4 sheet of paper, nine abstract geometric shapes were associated with the digits 1&#x02013;9. Participants had been instructed to write the digit, as quickly as possible, corresponding to the appropriate symbol into rows of empty boxes with symbols above them. In order to assess the same task in the four different conditions, we developed four parallel versions of the SDMT, by changing the associations between digits and symbols. Participants were given 90 s to fill as many empty boxes as possible. Scores for this task were obtained by subtracting the errors from the number of correctly filled boxes.</p></sec><sec id="s2-2-5"><title>Mood questionnaire</title><p>To assess how participants rated positive and negative emotions induced by Mozart&#x02019;s, Mahler&#x02019;s and the white noise backgrounds, participants completed for each ones a brief mood questionnaire. The questionnaire included three items assessing: (1) how much participants evaluated the music as happy; (2) how much they evaluated the music as sad; and (3) how much the amount of emotion experienced to listen each music, using a 10-point rating-scale anchored at 1 (very <italic>little</italic>) and 10 (very <italic>much</italic>).</p></sec></sec><sec id="s2-3"><title>Procedure</title><p>Participants performed the three cognitive tests in all of the four different background conditions: (1) no-music; (2) white noise; (3) Mozart&#x02019;s <italic>Eine Kleine Nachtmmusik</italic> aimed to induce a positive emotion/mood and high arousal levels; and (4) Mahler&#x02019;s <italic>Adagietto Symphony 5</italic> aimed to induce a negative emotion/mood and lower arousal levels. Participants were tested in groups of about 10 in two 2-h sessions a week apart. The type of backgrounds used (no-music, white noise, Mozart, Mahler) were counterbalanced across participants, so that half of participants were randomly allocated to the condition where first listened to classical music (either Mozart or Mahler) and then to either white noise or no-music condition, and for the other half of participants the order was reversed. In addition, within each background conditions, the order of the cognitive tests was counterbalanced across participants and subjects were randomly allocated to different tasks order.</p><p>In the first session all participants completed, in order, (a) the informed consent form; (b) demographic questionnaire; (c) Vocabulary test; (d) CES-D. Subsequently, both in the first and in the second sessions, they performed, for each background conditions, the parallel versions of the three cognitive tests. In this way, participants performed the same tasks in the four different background conditions. For example, half of participants in the first session performed the cognitive tests listening first to Mozart then the no-music condition (or first listening to Mahler and to white noise secondly), and in the second session performed the cognitive tests listening first to Mahler and then to white noise (or first Mozart followed by the no-music condition). Instead, in the first session, the other half of participants performed the cognitive tests listening first to white noise and secondly to Mozart (or first listening to white noise and to Mahler secondly) and, in the second session, performed the cognitive tests first with no-music in the background and then listening to Mahler (or first the no-music condition followed by Mozart).</p><p>Background music was played during the entire task, i.e., before and during tasks&#x02019; execution. For this reason, the two classical music and the white noise audio tracks started 1 min before each task, continued during the task, and ended as soon as each task ended. In order to make the experimental conditions comparable, in the silence condition too, participants were asked to be silent for 1 min before starting and during the execution of each task. Before the start of each background condition the experimenter verbally provided the instructions and the entire procedure to the participants. Finally, at the end of the second session, participants completed the mood questionnaire for Mozart, Mahler and white noise backgrounds.</p></sec><sec id="s2-4"><title>Statistical analysis</title><p>We conducted a series one-way Analyses of Variance (ANOVAs) with background conditions (4 levels: Mozart, Mahler, white noise, and no-music) as a within-subjects factor. A significant level of 0.05 was adopted. Paired <italic>t</italic>-test were used to follow-up significant <italic>F</italic> ratios. Since there were at most six pairwise comparisons, the significance level adopted for these follow-up tests was 0.008, unless otherwise stated. Mean values and standard deviations for the cognitive tasks are reported in Table <xref ref-type="table" rid="T1">1</xref>.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Means value and standard deviations for cognitive task as a function of background conditions</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="4" rowspan="1">Background condition</th></tr><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Mozart</th><th align="center" rowspan="1" colspan="1">Mahler</th><th align="center" rowspan="1" colspan="1">White noise</th><th align="center" rowspan="1" colspan="1">No-music</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Cognitive tasks</bold></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Episodic memory</td><td align="center" rowspan="1" colspan="1">9.82 (2.41)<sup><italic>ab</italic>*</sup></td><td align="center" rowspan="1" colspan="1">9.92 (2.38)<sup><italic>cd</italic></sup></td><td align="center" rowspan="1" colspan="1">9.11 (2.32)<sup><italic>bd</italic></sup></td><td align="center" rowspan="1" colspan="1">8.71 (2.45)<sup><italic>ac</italic></sup></td></tr><tr><td align="left" rowspan="1" colspan="1">Semantic memory</td><td align="center" rowspan="1" colspan="1">41.61 (11.55)<sup><italic>ab</italic></sup></td><td align="center" rowspan="1" colspan="1">39.80 (9.78)<sup><italic>c</italic></sup></td><td align="center" rowspan="1" colspan="1">36.39 (11.42)<sup><italic>bc</italic></sup></td><td align="center" rowspan="1" colspan="1">38.34 (9.22)<sup><italic>a</italic></sup></td></tr><tr><td align="left" rowspan="1" colspan="1">Processing speed</td><td align="center" rowspan="1" colspan="1">38.89 (10.31)<sup><italic>abc</italic>+</sup></td><td align="center" rowspan="1" colspan="1">35.51 (9.45)<sup><italic>b</italic></sup></td><td align="center" rowspan="1" colspan="1">34.65 (11.17)<sup><italic>a</italic></sup></td><td align="center" rowspan="1" colspan="1">36.76 (11.63)<sup><italic>c</italic>+</sup></td></tr></tbody></table><table-wrap-foot><p><italic>Note: Scores in parenthesis refer to Standard Deviation. For each row, same supra-scripts indicate significant differences at an alpha level of 0.008. * p = 0.014; <sup>+</sup> p = 0.068</italic>.</p></table-wrap-foot></table-wrap></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec id="s3-1"><title>Cognitive performance</title><sec id="s3-1-1"><title>Declarative memory</title><p>Results on <italic>episodic memory</italic> showed a significant main effect of background conditions, <italic>F</italic><sub>(3, 192)</sub> = 7.68, <italic>MSE</italic> = 2.85, <italic>&#x003b7;</italic><sup>2</sup> = 0.11. Pairwise comparisons showed a significant advantage for the Mozart condition over no-music, <italic>t</italic><sub>(64)</sub> = 3.64, and a marginally significant increase over the white noise, <italic>t</italic><sub>(64)</sub> = 2.53, <italic>p</italic> = 0.014. A significant advantage was also found for the Mahler condition over no-music,<italic> t</italic><sub>(64)</sub> = 4.01, and the white noise condition, <italic>t</italic><sub>(64)</sub> = 3.24. The white noise did not differ from no-music,<italic> t</italic><sub>(64)</sub> = 1.14, as well as the Mozart condition from the Mahler condition, <italic>t</italic><sub>(64)</sub> = 0.39. Overall, episodic memory performance increased when classical music was played in the background compared to white noise and no music conditions. No significant difference emerged between the two classical music conditions nor between the two non-music conditions.</p><p>From the analysis of <italic>semantic memory</italic>, emerged a significant main effect of background condition, <italic>F</italic><sub>(3, 192)</sub> = 9.70, <italic>MSE</italic> = 32.95, <italic>&#x003b7;</italic><sup>2</sup> = 0.13. Follow-up analyses revealed a significant advantage of the Mozart condition over no-music, <italic>t</italic><sub>(64)</sub> = 3.02, and white noise, <italic>t</italic><sub>(64)</sub> = 5.21. Performance in the Mahler condition was significantly higher than in the white noise condition,<italic> t</italic><sub>(64)</sub> = 3.36. The Mahler condition neither differ significantly from the no-music condition, <italic>t</italic><sub>(64)</sub> = 1.93, nor from the Mozart condition, <italic>t</italic><sub>(64)</sub>= 2.07. Finally, there was not significant difference between the two control conditions,<italic> t</italic><sub>(64)</sub> = 1.58. Overall, listening to classical music increased semantic memory performance compared to white noise and no-music. The overall pattern of the impact of the independent variable on semantic memory is comparable to the one obtained in the free recall task.</p><p>To further assess whether the effects of background music on episodic and semantic memory were comparable, we carried out a repeated-measure factorial ANOVA 4 (background condition: Mozart, Mahler, white noise, and no-music) as within-subject variable by 2 (task: episodic memory vs. semantic memory) as between-subject variable. Given that the two tasks utilized different scoring options, the dependent variable was the z-score calculated for each subjects for each background music conditions for the episodic and semantic memory tasks (so each participant had a mean of zero). Means and standard deviations for the two declarative memory tasks performance are provided in Table <xref ref-type="table" rid="T2">2</xref>. The analysis showed a significant main effect of background condition, <italic>F</italic><sub>(3, 192)</sub> = 12.62, <italic>MSE</italic> = 0.65, <italic>&#x003b7;</italic><sup>2</sup> = 0.16. It can be noticed from Table <xref ref-type="table" rid="T2">2</xref> that this reflects higher memory performance in the music conditions compared to the no-music conditions. The significant interaction, <italic>F</italic><sub>(3, 192)</sub> = 2.96, <italic>MSE</italic> = 0.52, <italic>&#x003b7;</italic><sup>2</sup> = 0.04, is not particularly interesting since it is simply a consequence of larger scores for Mahler (0.28) than Mozart (0.23) in episodic memory, while the reverse occurred in the semantic memory task (0.08 vs. 0.28, respectively). Similarly higher scores were associated with the white noise conditions (&#x02212;0.15) than the no-music condition (&#x02212;0.36) in the episodic memory task, while the reverse occurred in the semantic memory task (&#x02212;0.29 vs. &#x02212;0.08, respectively).</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Means value and standard deviations for the <italic>z</italic>-score of the two declarative memory tasks (episodic and semantic memory) as a function of background conditions</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="4" rowspan="1">Background condition</th></tr><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Mozart</th><th align="center" rowspan="1" colspan="1">Mahler</th><th align="center" rowspan="1" colspan="1">White noise</th><th align="center" rowspan="1" colspan="1">No-music</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>Declarative memory tasks</bold></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Episodic memory</td><td align="center" rowspan="1" colspan="1">0.23 (1.27)</td><td align="center" rowspan="1" colspan="1">0.28 (1.26)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.15 (1.22)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.36 (1.30)</td></tr><tr><td align="left" rowspan="1" colspan="1">Semantic memory</td><td align="center" rowspan="1" colspan="1">0.28 (1.24)</td><td align="center" rowspan="1" colspan="1">0.08 (1.05)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.29 (1.23)</td><td align="center" rowspan="1" colspan="1">&#x02212;0.08 (0.99)</td></tr></tbody></table><table-wrap-foot><p><italic>Note: Scores in parenthesis refer to Standard Deviation</italic>.</p></table-wrap-foot></table-wrap></sec><sec id="s3-1-2"><title>Processing speed</title><p>Regarding the SDMT, the main effect of background conditions was significant, <italic>F</italic><sub>(3, 192)</sub> = 5.70,<italic> MSE</italic> = 37.06, <italic>&#x003b7;</italic><sup>2</sup> = 0.08. Follow-up analyses showed a significant advantage of the Mozart condition over the white noise, <italic>t</italic><sub>(64)</sub> = 4.34, the Mahler condition, <italic>t</italic><sub>(64)</sub> = 3.75, and an advantage over the no-music condition that did not reach significance, <italic>t</italic><sub>(64)</sub> = 1.86. The Mahler condition neither differ significantly from the white noise, <italic>t</italic><sub>(64)</sub> = 0.90, nor from the no-music condition, <italic>t</italic><sub>(64)</sub> = 1.20. Finally, there was not significant difference between two control conditions, <italic>t</italic><sub>(64)</sub> = 1.51. Overall, it appears that the Mozart condition was associated with the highest performance and that this condition seemed to differ from the others which were comparable.</p></sec></sec><sec id="s3-2"><title>Mood questionnaire</title><p>Finally, to ensure that the two classical music induced positive and negative emotions, we analyzed scores obtained by the brief mood questionnaire for Mozart, Mahler and white noise backgrounds. To this end, we conducted a series one-way ANOVAs with background conditions (3 levels: Mozart, Mahler, and white noise) as a within-subjects factor. Paired <italic>t</italic>-test were used to follow-up significant <italic>F</italic> ratios. For technical reasons a smaller than the full sample provided the mood ratings.</p><p>Results on how music was evaluated as <italic>happy</italic> showed a significant main effect of background conditions, <italic>F</italic><sub>(2, 52)</sub> = 236.72, <italic>MSE</italic> = 1.65, <italic>&#x003b7;</italic><sup>2</sup> = 0.90. Pairwise comparisons showed that Mozart&#x02019;s excerpt was considered happier than Mahler&#x02019;s Adagietto (<italic>M</italic><sub>Mozart</sub> = 8.63; <italic>M</italic><sub>Mahler</sub> = 2.33),<italic> t</italic><sub>(26)</sub> = 18.24, and than the white noise condition (<italic>M</italic><sub>white noise</sub> = 1.78), <italic>t</italic><sub>(26)</sub> = 18.21. Mahler and the white noise condition did not differ significantly, <italic>t</italic><sub>(26)</sub> = 1.70.</p><p>From the analysis of how music was evaluated as <italic>sad</italic>, a significant main effect of background condition emerged, <italic>F</italic><sub>(2, 52)</sub> = 19.78, <italic>MSE</italic> = 5.95, <italic>&#x003b7;</italic><sup>2</sup> = 0.43. Follow-up analyses revealed that Mahler was rated as more sad than Mozart (<italic>M</italic><sub>Mozart</sub> = 1.41; <italic>M</italic><sub>Mahler</sub> = 5.41), <italic>t</italic><sub>(26)</sub> = 7.61, but comparable to white noise condition (<italic>M</italic><sub>white noise</sub> = 4.44), <italic>t</italic><sub>(26)</sub> = 1.27, Finally, the white noise condition was rated more sad than Mozart (<italic>M</italic><sub>Mozart</sub> = 1.41), <italic>t</italic><sub>(26)</sub> = 4.42.</p><p>Regarding the assessment of <italic>emotion</italic>, the main effect of background condition was also significant, <italic>F</italic><sub>(2, 52)</sub> = 79.88, <italic>MSE</italic> = 3.69, <italic>&#x003b7;</italic><sup>2</sup> = 0.75. Follow-up analyses showed that participants reported that Mozart induced greater emotionality than Mahler (<italic>M</italic><sub>Mozart</sub> = 8.70; <italic>M</italic><sub>Mahler</sub> = 6.89), <italic>t</italic><sub>(26)</sub> = 3.69, and the white noise conditions (<italic>M</italic><sub>white noise</sub> = 2.30), <italic>t</italic><sub>(26)</sub> = 12.50. Finally, Mahler was significantly different from the white noise condition, <italic>t</italic><sub>(26)</sub> = 8.19.</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>The present study examined the impact of different types of background music on tasks tapping declarative memory and processing speed in a sample of healthy older adults. From the obtained results it appeared that performance in the processing speed task, was enhanced when Mozart&#x02019;s music was played in the background compared to the other three conditions, Mahler included. Conversely, background music affected differently memory performance. Unlike the processing speed task, in the case of episodic and semantic memory tasks both &#x0201c;positive&#x0201d; and &#x0201c;negative&#x0201d; background music conditions induced a significant performance advantage over the silence and white noise conditions, which did not significantly differ in their effect.</p><p>The results obtained in the processing speed task could, in principle, be accommodated by the &#x0201c;arousal and mood hypothesis&#x0201d; (Thompson et al., <xref rid="B55" ref-type="bibr">2001</xref>) since performance increased systematically in the condition that induced increased positive mood and arousal. However, the above result in conjunction with those obtained in the memory tasks do not appear to support the view that increased positive mood and arousal necessarily lead to improved performance. Indeed, free recall and phonemic fluency also benefitted from a background music inducing a more negative mood. Hence, we cannot consider valid those approaches retaining that background music leads to improved performance only if it increases positive mood and arousal levels.</p><p>A <italic>post hoc</italic> interpretation may consist in retaining that background music improves performance when the mood and arousal induced by the music are optimal to support the processes involved in the cognitive task being performed. For example, processing speed tasks, due to their nature, may benefit more from a more alert mood and state. These tasks comprise a motor tracking valence that could have benefitted from a synchronization between movement and auditory rhythms (McElrea and Standing, <xref rid="B28" ref-type="bibr">1992</xref>; Repp and Penel, <xref rid="B43" ref-type="bibr">2004</xref>). The fast and major music could have in turn produced the best condition to support older adults&#x02019; performance, as reported by other research (e.g., Konz and McDougal, <xref rid="B25" ref-type="bibr">1968</xref>; McElrea and Standing, <xref rid="B28" ref-type="bibr">1992</xref>; Repp, <xref rid="B42" ref-type="bibr">2006</xref>).</p><p>Conversely, memory tasks may be positively affected by any type of background music inducing emotive states. The fact that music is able to evoke emotions is well known (e.g., Panksepp, <xref rid="B36" ref-type="bibr">1995</xref>). For instance, Sacks (<xref rid="B45" ref-type="bibr">2006</xref>) refers to the evocative power of music in evoking transcendent emotions. Given that emotions enhance memory processes and music evokes strong emotions (J&#x000e4;ncke, <xref rid="B21" ref-type="bibr">2008</xref>), our findings highlight the possibility that any type of background music can facilitate memory performance. An explanation is that music activates the limbic system, which is involved in processing the emotions and in controlling memory (e.g., Blood et al., <xref rid="B3" ref-type="bibr">1999</xref>). Evidence supporting this come from those studies using therapeutically music to enhance memory in Alzheimer&#x02019;s disease patients by provoking emotional responses (e.g., El Haj et al., <xref rid="B9" ref-type="bibr">2012</xref>).</p><p>A further consideration may be made. If emotional experience comprises two dimensions, valence and intensity (e.g., Duffy, <xref rid="B8" ref-type="bibr">1941</xref>), our data seem to suggest that the effects of music on memory are due primarily to the intensity of the emotions induced by music, rather than their specific valence. This purely <italic>post hoc</italic> speculation obviously requires empirical testing before being considered as a valid explanation of the background music effect.</p><p>Furthermore, it is relevant to notice that a context dependent learning effect (e.g., Smith, <xref rid="B50" ref-type="bibr">1985</xref>) should not be considered as a valid explanation of the results obtained in the memory tasks for two reasons. Firstly, in the white noise condition, as well in the music conditions, some comparable background sound was presented during the study and test phase of the free recall task. Nevertheless, performance was significantly lower than in the classical background music conditions. Secondly, due to the nature of the semantic memory task, there were no distinctive study and retrieval phases. Despite this feature of the task, classical music in the background led to the highest performance.</p><p>Given the cognitive changes associated to normal aging (e.g., Parks, <xref rid="B37" ref-type="bibr">2007</xref>), the lack of a disruptive effect of background music on task performance in our older adults sample seems at variance with the &#x0201c;cognitive-capacity hypothesis&#x0201d; (Kahneman, <xref rid="B22" ref-type="bibr">1973</xref>). According to this view, background music should have negatively affected cognitive performance in older adults. This clearly was not the case in the present study.</p><p>It is important to note that our background music conditions did not involve information that could have directly competed with processing target information (e.g., the music was instrumental and it was not aversively loud), hence the lack of interference we observed. For instance, if cognitive tasks involve the same auditory channel (e.g., Moreno and Mayer, <xref rid="B30" ref-type="bibr">2000</xref>) of the background music, the likelihood of interference should increase, in contrast to stimuli processed in separate channels.</p><p>In summary, the different patterns of results found for processing speed and memory seem to suggest that the influence of music is not homogeneous. The impact could depend on the kind of music background but also on features of the task and/or abilities involved. Future studies should better clarify this issue evaluating the impact of background music on cognitive abilities using different channels (e.g., visual vs. verbal) and possibly using tasks marked by increasing levels of complexity. Clearly the background music effect is in need of a valid theoretical explanation.</p><p>This study had two main strengths. First, it evaluated the impact of background music on the aging population. Second, it used a more thorough methodology than the one used in previous studies in this field (Thompson et al., <xref rid="B54" ref-type="bibr">2005</xref>; Mammarella et al., <xref rid="B27" ref-type="bibr">2007</xref>; Ferreri et al., <xref rid="B12" ref-type="bibr">2014</xref>).</p><p>Finally, considering a more pragmatic approach, the results of this study provide a positive message. Listening to music could indeed represent a relatively inexpensive and non-invasive method to enhance those cognitive abilities that are crucial to the daily living in elderly adults.</p></sec><sec id="s5"><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationship that could be construed as a potential conflict of interest.</p></sec></body><back><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angel</surname><given-names>L. A.</given-names></name><name><surname>Polzella</surname><given-names>D. J.</given-names></name><name><surname>Elvers</surname><given-names>G. C.</given-names></name></person-group> (<year>2010</year>). <article-title>Background music and cognitive performance</article-title>. <source>Percept. Mot. Skills</source>
<volume>11</volume>, <fpage>1059</fpage>&#x02013;<lpage>1064</lpage>
<pub-id pub-id-type="doi">10.2466/pms.110.3c.1059-1064</pub-id><pub-id pub-id-type="pmid">20865993</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Working memory: looking back and looking forward</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>4</volume>, <fpage>829</fpage>&#x02013;<lpage>839</lpage>
<pub-id pub-id-type="doi">10.1038/nrn1201</pub-id><pub-id pub-id-type="pmid">14523382</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blood</surname><given-names>A. J.</given-names></name><name><surname>Zatorre</surname><given-names>R. J.</given-names></name><name><surname>Bermudez</surname><given-names>P.</given-names></name><name><surname>Evans</surname><given-names>A. C.</given-names></name></person-group> (<year>1999</year>). <article-title>Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions</article-title>. <source>Nat. Neurosci.</source>
<volume>2</volume>, <fpage>382</fpage>&#x02013;<lpage>387</lpage>
<pub-id pub-id-type="doi">10.1038/7299</pub-id><pub-id pub-id-type="pmid">10204547</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bloor</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>The rhythm&#x02019;s gonna get ya&#x02019;&#x02014;background music in primary classrooms and its effect on behaviour and attainment</article-title>. <source>J. Emot. Behav. Disord.</source>
<volume>14</volume>, <fpage>261</fpage>&#x02013;<lpage>274</lpage>
<pub-id pub-id-type="doi">10.1080/13632750903303070</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boman</surname><given-names>E.</given-names></name><name><surname>Enmarker</surname><given-names>I.</given-names></name><name><surname>Hygge</surname><given-names>S.</given-names></name></person-group> (<year>2005</year>). <article-title>Strength of noise effects on memory as a function of noise source and age</article-title>. <source>Noise Health</source>
<volume>7</volume>, <fpage>11</fpage>&#x02013;<lpage>26</lpage>
<pub-id pub-id-type="doi">10.4103/1463-1741.31636</pub-id><pub-id pub-id-type="pmid">16105246</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cockerton</surname><given-names>T.</given-names></name><name><surname>Moore</surname><given-names>S.</given-names></name><name><surname>Norman</surname><given-names>D.</given-names></name></person-group> (<year>1997</year>). <article-title>Cognitive test performance and background music</article-title>. <source>Percept. Mot. Skills</source>
<volume>85</volume>, <fpage>1435</fpage>&#x02013;<lpage>1438</lpage>
<pub-id pub-id-type="doi">10.2466/pms.1997.85.3f.1435</pub-id><pub-id pub-id-type="pmid">9450304</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duffy</surname><given-names>E.</given-names></name></person-group> (<year>1941</year>). <article-title>An explanation of &#x0201c;emotional&#x0201d; phenomena without the use of the concept &#x0201c;emotion.&#x0201d;</article-title>
<source>J. Gen. Psychol.</source>
<volume>25</volume>, <fpage>283</fpage>&#x02013;<lpage>293</lpage>
<pub-id pub-id-type="doi">10.1080/00221309.1941.10544400</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Haj</surname><given-names>M.</given-names></name><name><surname>Postal</surname><given-names>V.</given-names></name><name><surname>Allain</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Music enhances autobiographical memory in mild Alzheimer&#x02019;s disease</article-title>. <source>Educ. Gerontol.</source>
<volume>38</volume>, <fpage>30</fpage>&#x02013;<lpage>41</lpage>
<pub-id pub-id-type="doi">10.1080/03601277.2010.515897</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fava</surname><given-names>G. A.</given-names></name></person-group> (<year>1983</year>). <article-title>Assessing depressive symptoms across cultures: Italian validation of the CES-D self-rating scale</article-title>. <source>J. Clin. Psychol.</source>
<volume>39</volume>, <fpage>249</fpage>&#x02013;<lpage>251</lpage>
<pub-id pub-id-type="doi">10.1002/1097-4679(198303)39:2&#x0003c;249::aid-jclp2270390218&#x0003e;3.0.co;2-y</pub-id><pub-id pub-id-type="pmid">6841626</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferreri</surname><given-names>L.</given-names></name><name><surname>Aucouturier</surname><given-names>J. J.</given-names></name><name><surname>Muthalib</surname><given-names>M.</given-names></name><name><surname>Bigand</surname><given-names>E.</given-names></name><name><surname>Bugaiska</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>). <article-title>Music improves verbal memory encoding while decreasing prefrontal cortex activity: an fNIRS study</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>7</volume>:<fpage>779</fpage>
<pub-id pub-id-type="doi">10.3389/fnhum.2013.00779</pub-id><pub-id pub-id-type="pmid">24339807</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferreri</surname><given-names>L.</given-names></name><name><surname>Bigand</surname><given-names>E.</given-names></name><name><surname>Perrey</surname><given-names>S.</given-names></name><name><surname>Muthalib</surname><given-names>M.</given-names></name><name><surname>Bard</surname><given-names>P.</given-names></name><name><surname>Bugaiska</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Less effort, better results: how does music act on prefrontal cortex in older adults during verbal encoding? An fNIRS study</article-title>. <source>Front. Neurosci.</source>
<volume>8</volume>:<fpage>301</fpage>
<pub-id pub-id-type="doi">10.3389/fnhum.2014.00301</pub-id><pub-id pub-id-type="pmid">25285066</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furnham</surname><given-names>A.</given-names></name><name><surname>Allass</surname><given-names>K.</given-names></name></person-group> (<year>1999</year>). <article-title>The influence of musical distraction of varying complexity on the cognitive performance of extraverts and introverts</article-title>. <source>Eur. J. Pers.</source>
<volume>13</volume>, <fpage>27</fpage>&#x02013;<lpage>38</lpage>
<pub-id pub-id-type="doi">10.1002/(sici)1099-0984(199901/02)13:1&#x0003c;27::aid-per318&#x0003e;3.0.co;2-r</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furnham</surname><given-names>A.</given-names></name><name><surname>Bradley</surname><given-names>A.</given-names></name></person-group> (<year>1997</year>). <article-title>Music while you work: the differential distraction of background music on the cognitive test performance of introverts and extraverts</article-title>. <source>Appl. Cogn. Psychol.</source>
<volume>11</volume>, <fpage>445</fpage>&#x02013;<lpage>455</lpage>
<pub-id pub-id-type="doi">10.1002/(sici)1099-0720(199710)11:5&#x0003c;445::aid-acp472&#x0003e;3.3.co;2-i</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gabrielsson</surname><given-names>A.</given-names></name><name><surname>Lindstr&#x000f6;m</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). &#x0201c;<article-title>The role of structure in the musical expression of emotions</article-title>,&#x0201d; in <source>Handbook of Music and Emotion: Theory, Research, Applications</source>, eds <person-group person-group-type="editor"><name><surname>Juslin</surname><given-names>P.</given-names></name><name><surname>Sloboda</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>New York, NY, US</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>), <fpage>367</fpage>&#x02013;<lpage>400</lpage></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallam</surname><given-names>S.</given-names></name><name><surname>Price</surname><given-names>J.</given-names></name></person-group> (<year>1998</year>). <article-title>Research section: can the use of background music improve the behaviour and academic performance of children with emotional and behavioural difficulties?</article-title>
<source>Br. J. Spec. Educ.</source>
<volume>25</volume>, <fpage>88</fpage>&#x02013;<lpage>91</lpage>
<pub-id pub-id-type="doi">10.1111/1467-8527.t01-1-00063</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallam</surname><given-names>S.</given-names></name><name><surname>Price</surname><given-names>J.</given-names></name><name><surname>Katsarou</surname><given-names>G.</given-names></name></person-group> (<year>2002</year>). <article-title>The effect of background music on primary school pupils&#x02019; task performance</article-title>. <source>Educ. Stud.</source>
<volume>28</volume>, <fpage>111</fpage>&#x02013;<lpage>122</lpage>
<pub-id pub-id-type="doi">10.1080/03055690220124551</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>P. G.</given-names></name><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name></person-group> (<year>2010</year>). &#x0201c;<article-title>Music and emotion</article-title>,&#x0201d; in <source>Music Perception</source>, eds <person-group person-group-type="editor"><name><surname>Jones</surname><given-names>M. R.</given-names></name><name><surname>Fay</surname><given-names>R. R.</given-names></name><name><surname>Popper</surname><given-names>A. N.</given-names></name></person-group> (<publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>129</fpage>&#x02013;<lpage>164</lpage></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Husain</surname><given-names>G.</given-names></name><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Shellenberg</surname><given-names>E. G.</given-names></name></person-group> (<year>2002</year>). <article-title>Effects of musical tempo and mode on arousal, mood and spatial abilities</article-title>. <source>Music Percept.</source>
<volume>20</volume>, <fpage>151</fpage>&#x02013;<lpage>171</lpage>
<pub-id pub-id-type="doi">10.1525/mp.2002.20.2.151</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hygge</surname><given-names>S.</given-names></name><name><surname>Boman</surname><given-names>E.</given-names></name><name><surname>Enmarker</surname><given-names>I.</given-names></name></person-group> (<year>2003</year>). <article-title>The effects of road traffic noise and meaningful irrelevant speech on different memory systems</article-title>. <source>Scand. J. Psychol.</source>
<volume>44</volume>, <fpage>13</fpage>&#x02013;<lpage>21</lpage>
<pub-id pub-id-type="doi">10.1111/1467-9450.00316</pub-id><pub-id pub-id-type="pmid">12602999</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>J&#x000e4;ncke</surname><given-names>L.</given-names></name></person-group> (<year>2008</year>). <article-title>Music, memory and emotion</article-title>. <source>J. Biol.</source>
<volume>7</volume>:<fpage>21</fpage>
<pub-id pub-id-type="doi">10.1186/jbiol82</pub-id><pub-id pub-id-type="pmid">18710596</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D.</given-names></name></person-group> (<year>1973</year>). <source>Attention and Effort.</source>
<publisher-loc>Englewood Cliffs. NJ</publisher-loc>: <publisher-name>Prentice-Hall</publisher-name></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000e4;mpfe</surname><given-names>J.</given-names></name><name><surname>Sedlmeier</surname><given-names>P.</given-names></name><name><surname>Renkewitz</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>The impact of background music on adult listeners: a meta-analysis</article-title>. <source>Psychol. Music</source>
<volume>39</volume>, <fpage>424</fpage>&#x02013;<lpage>448</lpage>
<pub-id pub-id-type="doi">10.1177/0305735610376261</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>H. J.</given-names></name><name><surname>Williamson</surname><given-names>J. W.</given-names></name></person-group> (<year>2013</year>). <article-title>Background can aid second language learning</article-title>. <source>Psychol. Music</source>
<volume>42</volume>, <fpage>728</fpage>&#x02013;<lpage>747</lpage>
<pub-id pub-id-type="doi">10.1177/0305735613485152</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konz</surname><given-names>S.</given-names></name><name><surname>McDougal</surname><given-names>D.</given-names></name></person-group> (<year>1968</year>). <article-title>The effect of background music on the control activity of an automobile driver</article-title>. <source>Hum. Factors</source>
<volume>10</volume>, <fpage>233</fpage>&#x02013;<lpage>244</lpage>
<pub-id pub-id-type="pmid">5674359</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Madsen</surname><given-names>C. K.</given-names></name></person-group> (<year>1987</year>). &#x0201c;<article-title>Background music: competition for focus of attention</article-title>,&#x0201d; in <source>Applications of Research in Music Behavior</source>, eds <person-group person-group-type="editor"><name><surname>Madsen</surname><given-names>C. K.</given-names></name><name><surname>Prickett</surname><given-names>C. A.</given-names></name></person-group> (<publisher-loc>Tuscaloosa, AL</publisher-loc>: <publisher-name>The University of Alabama Press</publisher-name>), <fpage>315</fpage>&#x02013;<lpage>325</lpage></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mammarella</surname><given-names>N.</given-names></name><name><surname>Fairfield</surname><given-names>B.</given-names></name><name><surname>Cornoldi</surname><given-names>C.</given-names></name></person-group> (<year>2007</year>). <article-title>Does music enhance cognitive performance in healthy older adults? The Vivaldi effect</article-title>. <source>Aging Clin. Exp. Res.</source>
<volume>19</volume>, <fpage>394</fpage>&#x02013;<lpage>399</lpage>
<pub-id pub-id-type="doi">10.1007/bf03324720</pub-id><pub-id pub-id-type="pmid">18007118</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McElrea</surname><given-names>M.</given-names></name><name><surname>Standing</surname><given-names>L.</given-names></name></person-group> (<year>1992</year>). <article-title>Fast music causes fast drinking</article-title>. <source>Percept. Mot. Skills</source>
<volume>75</volume>:<fpage>362</fpage>
<pub-id pub-id-type="doi">10.2466/pms.1992.75.2.362</pub-id><pub-id pub-id-type="pmid">1408589</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miskovic</surname><given-names>D.</given-names></name><name><surname>Rosenthal</surname><given-names>R.</given-names></name><name><surname>Zingg</surname><given-names>U.</given-names></name><name><surname>Oertli</surname><given-names>D.</given-names></name><name><surname>Metzger</surname><given-names>U.</given-names></name><name><surname>Jancke</surname><given-names>L.</given-names></name></person-group> (<year>2008</year>). <article-title>Randomized controlled trial investigating the effect of music on the virtual reality laparoscopic learning performance of novice surgeons</article-title>. <source>Surg. Endosc.</source>
<volume>22</volume>, <fpage>2416</fpage>&#x02013;<lpage>2420</lpage>
<pub-id pub-id-type="doi">10.1007/s00464-008-0040-8</pub-id><pub-id pub-id-type="pmid">18622551</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>R.</given-names></name><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2000</year>). <article-title>A coherence effect in multimedia learning: the case for minimizing irrelevant sounds in the design of multimedia instructional messages</article-title>. <source>J. Educ. Psychol.</source>
<volume>92</volume>, <fpage>117</fpage>&#x02013;<lpage>125</lpage>
<pub-id pub-id-type="doi">10.1037//0022-0663.92.1.117</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niedenthal</surname><given-names>P. M.</given-names></name><name><surname>Setterlund</surname><given-names>M. B.</given-names></name></person-group> (<year>1994</year>). <article-title>Emotion congruence in perception</article-title>. <source>Pers. Soc. Psychol. B.</source>
<volume>20</volume>, <fpage>401</fpage>&#x02013;<lpage>411</lpage>
<pub-id pub-id-type="doi">10.1177/0146167294204007</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nocentini</surname><given-names>U.</given-names></name><name><surname>Giordano</surname><given-names>A.</given-names></name><name><surname>Di Vincenzo</surname><given-names>S.</given-names></name><name><surname>Panella</surname><given-names>M.</given-names></name><name><surname>Pasqualetti</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>The symbol digit modalities test-oral version: Italian normative data</article-title>. <source>Funct. Neurol.</source>
<volume>21</volume>, <fpage>93</fpage>&#x02013;<lpage>96</lpage>
<pub-id pub-id-type="pmid">16796824</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>D. A.</given-names></name><name><surname>Bobrow</surname><given-names>D. G.</given-names></name></person-group> (<year>1975</year>). <article-title>On data-limited and resource-limited processes</article-title>. <source>Cogn. Psychol.</source>
<volume>7</volume>, <fpage>44</fpage>&#x02013;<lpage>64</lpage>
<pub-id pub-id-type="doi">10.1016/0010-0285(75)90004-3</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliver</surname><given-names>M.</given-names></name></person-group> (<year>1997</year>). <article-title>The effect of background music on mood and reading comprehension performance of at-risk college freshmen</article-title>. <source>Dissertation Abstr.</source>
<volume>57</volume>, <fpage>5039</fpage></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paivio</surname><given-names>A.</given-names></name><name><surname>Yuille</surname><given-names>J. C.</given-names></name><name><surname>Madigan</surname><given-names>S. A.</given-names></name></person-group> (<year>1968</year>). <article-title>Concreteness, imagery and meaningfulness value for 925 nouns</article-title>. <source>J. Exp. Psychol.</source>
<volume>76</volume>, <fpage>1</fpage>&#x02013;<lpage>25</lpage>
<pub-id pub-id-type="doi">10.1037/h0025327</pub-id><pub-id pub-id-type="pmid">5672258</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panksepp</surname><given-names>J.</given-names></name></person-group> (<year>1995</year>). <article-title>The emotional sources of &#x0201c;chills&#x0201d; induced by music</article-title>. <source>Music Percept.</source>
<volume>13</volume>, <fpage>171</fpage>&#x02013;<lpage>207</lpage>
<pub-id pub-id-type="doi">10.2307/40285693</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parks</surname><given-names>C. M.</given-names></name></person-group> (<year>2007</year>). <article-title>The role of noncriterial recollection in estimating recollection and familiarity</article-title>. <source>J. Mem. Lang.</source>
<volume>57</volume>, <fpage>81</fpage>&#x02013;<lpage>100</lpage>
<pub-id pub-id-type="doi">10.1016/j.jml.2007.03.003</pub-id><pub-id pub-id-type="pmid">18591986</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Polzella</surname><given-names>D. J.</given-names></name><name><surname>Schoeling</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). &#x0201c;<article-title>Effects of familiar background music on working memory and motor tracking</article-title>,&#x0201d; in <conf-name>Poster session presented at the meeting of the Psychonomic Society</conf-name> (<conf-loc>Minneapolis, MN</conf-loc>).</mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radloff</surname><given-names>L. S.</given-names></name></person-group> (<year>1977</year>). <article-title>The CES-D scale: a self-report depression sale for research in the general population</article-title>. <source>Appl. Psychol. Meas.</source>
<volume>1</volume>, <fpage>385</fpage>&#x02013;<lpage>401</lpage>
<pub-id pub-id-type="doi">10.1177/014662167700100306</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Radocy</surname><given-names>R. E.</given-names></name><name><surname>Boyle</surname><given-names>J. D.</given-names></name></person-group> (<year>1988</year>). <source>Psychological Foundations of Musical Behaviour.</source>
<publisher-loc>Sprinfield, IL</publisher-loc>: <publisher-name>Charles C. Thomas</publisher-name></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauscher</surname><given-names>F. H.</given-names></name><name><surname>Shaw</surname><given-names>G. L.</given-names></name><name><surname>Ky</surname><given-names>K. N.</given-names></name></person-group> (<year>1993</year>). <article-title>Music and spatial task performance</article-title>. <source>Nature</source>
<volume>365</volume>:<fpage>611</fpage>
<pub-id pub-id-type="doi">10.1038/365611a0</pub-id><pub-id pub-id-type="pmid">8413624</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repp</surname><given-names>B. H.</given-names></name></person-group> (<year>2006</year>). <article-title>Does auditory distractor sequence affect self-paced tapping?</article-title>
<source>Acta Psychol. (Amst)</source>
<volume>121</volume>, <fpage>81</fpage>&#x02013;<lpage>107</lpage>
<pub-id pub-id-type="doi">10.1016/j.actpsy.2005.06.006</pub-id><pub-id pub-id-type="pmid">16098944</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repp</surname><given-names>B. H.</given-names></name><name><surname>Penel</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Rhythmic movement is attracted more strongly to auditory than to visual rhythms</article-title>. <source>Psychol. Res.</source>
<volume>68</volume>, <fpage>252</fpage>&#x02013;<lpage>270</lpage>
<pub-id pub-id-type="doi">10.1007/s00426-003-0143-8</pub-id><pub-id pub-id-type="pmid">12955504</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riener</surname><given-names>C. R.</given-names></name><name><surname>Stefanucci</surname><given-names>J. K.</given-names></name><name><surname>Proffitt</surname><given-names>D. R.</given-names></name><name><surname>Clore</surname><given-names>G.</given-names></name></person-group> (<year>2011</year>). <article-title>An effect of mood on the perception of geographical slant</article-title>. <source>Cogn. Emot.</source>
<volume>25</volume>, <fpage>174</fpage>&#x02013;<lpage>182</lpage>
<pub-id pub-id-type="doi">10.1080/02699931003738026</pub-id><pub-id pub-id-type="pmid">21432665</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sacks</surname><given-names>O.</given-names></name></person-group> (<year>2006</year>). <article-title>The power of music</article-title>. <source>Brain</source>
<volume>129</volume>, <fpage>2528</fpage>&#x02013;<lpage>2532</lpage>
<pub-id pub-id-type="doi">10.1093/brain/awl234</pub-id><pub-id pub-id-type="pmid">17000872</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>T. A.</given-names></name></person-group> (<year>2004</year>). <article-title>What and when of cognitive aging</article-title>. <source>Curr. Dir. Psychol. Sci.</source>
<volume>13</volume>, <fpage>140</fpage>&#x02013;<lpage>144</lpage>
<pub-id pub-id-type="doi">10.1111/j.0963-7214.2004.00293.x</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name><name><surname>Nakata</surname><given-names>T.</given-names></name><name><surname>Hunter</surname><given-names>P. G.</given-names></name><name><surname>Tamoto</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Exposure to music and cognitive performance: tests of children and adults</article-title>. <source>Psychol. Music</source>
<volume>35</volume>, <fpage>5</fpage>&#x02013;<lpage>19</lpage>
<pub-id pub-id-type="doi">10.1177/0305735607068885</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name><name><surname>Weiss</surname><given-names>M. W.</given-names></name></person-group> (<year>2013</year>). &#x0201c;<article-title>Music and cognitive abilities</article-title>,&#x0201d; in <source>The Psychology of Music</source>
<edition>3rd Edn</edition> ed <person-group person-group-type="editor"><name><surname>Deutsch</surname><given-names>D.</given-names></name></person-group> (<publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>), <fpage>499</fpage>&#x02013;<lpage>550</lpage></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>A.</given-names></name></person-group> (<year>1982</year>). <source>Symbol Digit Modalities Test. Manual.</source>
<publisher-loc>Los Angeles, CA</publisher-loc>: <publisher-name>Western Psychological Services</publisher-name></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>1985</year>). <article-title>Background music and context-dependent memory</article-title>. <source>Am. J. Psychol.</source>
<volume>98</volume>, <fpage>591</fpage>&#x02013;<lpage>603</lpage>
<pub-id pub-id-type="doi">10.2307/1422512</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000f6;derlund</surname><given-names>G. B. W.</given-names></name><name><surname>Sikstr&#x000f6;m</surname><given-names>S.</given-names></name><name><surname>Loftesnes</surname><given-names>J. M.</given-names></name><name><surname>Sonuga-Barke</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>The effects of background white noise on memory performance in inattentive school children</article-title>. <source>Behav. Brain Funct.</source>
<volume>6</volume>:<fpage>55</fpage>
<pub-id pub-id-type="doi">10.1186/1744-9081-6-55</pub-id><pub-id pub-id-type="pmid">20920224</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000f6;derlund</surname><given-names>G. B. W.</given-names></name><name><surname>Sikstr&#x000f6;m</surname><given-names>S.</given-names></name><name><surname>Smart</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Listen to the noise: noise is beneficial for cognitive performance in ADHD</article-title>. <source>J. Child Psychol. Psychiatry</source>
<volume>48</volume>, <fpage>840</fpage>&#x02013;<lpage>847</lpage>
<pub-id pub-id-type="doi">10.1111/j.1469-7610.2007.01749.x</pub-id><pub-id pub-id-type="pmid">17683456</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Storbeck</surname><given-names>J.</given-names></name><name><surname>Clore</surname><given-names>G. L.</given-names></name></person-group> (<year>2005</year>). <article-title>With sadness come accuracy; with happiness, false memory mood and the false memory effect</article-title>. <source>Psychol. Sci.</source>
<volume>16</volume>, <fpage>785</fpage>&#x02013;<lpage>791</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2005.01615.x</pub-id><pub-id pub-id-type="pmid">16181441</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>R. G.</given-names></name><name><surname>Moulin</surname><given-names>C. J. A.</given-names></name><name><surname>Hayre</surname><given-names>S.</given-names></name><name><surname>Jones</surname><given-names>R. W.</given-names></name></person-group> (<year>2005</year>). <article-title>Music enhances category fluency in healthy older adults and Alzheimer&#x02019;s disease patients</article-title>. <source>Exp. Aging Res.</source>
<volume>31</volume>, <fpage>91</fpage>&#x02013;<lpage>99</lpage>
<pub-id pub-id-type="doi">10.1080/03610730590882819</pub-id><pub-id pub-id-type="pmid">15842075</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name><name><surname>Husain</surname><given-names>G.</given-names></name></person-group> (<year>2001</year>). <article-title>Arousal, mood and the Mozart effect</article-title>. <source>Psychol. Sci.</source>
<volume>12</volume>, <fpage>248</fpage>&#x02013;<lpage>251</lpage>
<pub-id pub-id-type="doi">10.1111/1467-9280.00345</pub-id><pub-id pub-id-type="pmid">11437309</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thurstone</surname><given-names>T. G.</given-names></name><name><surname>Thurstone</surname><given-names>L. L.</given-names></name></person-group> (<year>1963</year>). <source>Primary Mental Ability.</source>
<publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>Science Research Associates</publisher-name></mixed-citation></ref></ref-list></back></article>