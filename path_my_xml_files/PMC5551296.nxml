<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Signals Sens</journal-id><journal-id journal-id-type="iso-abbrev">J Med Signals Sens</journal-id><journal-id journal-id-type="publisher-id">JMSS</journal-id><journal-title-group><journal-title>Journal of Medical Signals and Sensors</journal-title></journal-title-group><issn pub-type="epub">2228-7477</issn><publisher><publisher-name>Medknow Publications &#x00026; Media Pvt Ltd</publisher-name><publisher-loc>India</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28840113</article-id><article-id pub-id-type="pmc">5551296</article-id><article-id pub-id-type="publisher-id">JMSS-7-123</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Quantitative EEG Signatures through Amplitude and Phase Modulation Patterns</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Myers</surname><given-names>Mark H.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"/></contrib><contrib contrib-type="author"><name><surname>Padmanabha</surname><given-names>Akaash</given-names></name><xref ref-type="aff" rid="aff1"/></contrib></contrib-group><aff id="aff1"><italic>Department of Anatomy and Neurobiology, University of Tennessee Health Science Center, Memphis, TN, USA</italic></aff><author-notes><corresp id="cor1"><italic><bold>Address for correspondence:</bold> Dr. Mark H. Myers, 7000 Corsica Dr Germantown, TN 38138, USA. E-mail: <email xlink:href="mhmyers@uthsc.edu">mhmyers@uthsc.edu</email></italic></corresp></author-notes><pub-date pub-type="ppub"><season>Jul-Sep</season><year>2017</year></pub-date><volume>7</volume><issue>3</issue><fpage>123</fpage><lpage>129</lpage><permissions><copyright-statement>Copyright: &#x000a9; 2017 Journal of Medical Signals &#x00026; Sensors</copyright-statement><copyright-year>2017</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc-sa/3.0"><license-p>This is an open access article distributed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License, which allows others to remix, tweak, and build upon the work non-commercially, as long as the author is credited and the new creations are licensed under the identical terms.</license-p></license></permissions><abstract><p>Cortical spatiotemporal signal patterns based on object recognition can be discerned from visual stimulation. These are in the form of amplitude modulation (AM) and phase modulation (PM) patterns, which contain perceptual information gathered from sensory input. A high-density Electroencephalograph (EEG) device consisting of 48 electrodes with a spacing of 5 mm was utilized to measure frontal lobe activity in order to capture event-related potentials from visual stimuli. Four randomized stimuli representing different levels of salient responsiveness were measured to determine if mild stimuli can be discerned from more extreme stimuli. AM/PM response patterns were detected between mild and more salient stimuli across participants. AM patterns presented distinct signatures for each stimulus. AM patterns had the highest number of incidents detected in the middle of the frontal lobe. Through this work, we can expand our encyclopedia of neural signatures to object recognition, and provide a broader understanding of quantitative neural responses to external stimuli. The results provide a quantitative approach utilizing spatiotemporal patterns to analyze where distinct AM patterns can be linked to object perception.</p></abstract><kwd-group><kwd><italic>Analytic amplitude</italic></kwd><kwd><italic>analytic phase</italic></kwd><kwd><italic>frontal lobe</italic></kwd><kwd><italic>object saliency</italic></kwd><kwd><italic>spatio temporal patterns</italic></kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-1"><title>Introduction</title><p>Object saliency has been a crucial aspect of our survival and evolutionary process. The weighted values the brain places on objects have provided various degrees of neural responses, which eventually correlate to emotional, behavioral, and learned responses.[<xref rid="ref1" ref-type="bibr">1</xref><xref rid="ref2" ref-type="bibr">2</xref>] Appetitive (positive) or aversive (negative) responses to stimuli are learned responses, where conditioned stimulus is associated to our perception of the world.</p><p>Studies in positive/negative task experiments elicited different states of neural activity, where negative incentive-based tasks produced higher neural activity vs. positive incentive based tasks. The latter neural activity (positive based tasks) was influenced by perceptual processing stages, i.e. P300 vs P100 in V1.[<xref rid="ref3" ref-type="bibr">3</xref>] Other studies featuring fear-related object saliency focused on the neural activity between visual cortical pathways and fast subcortical pathways. Functional magnetic resonance imaging was performed on patients with spider phobia and found strong aberrant functional connectivity of fast subcortical pathways when they are exposed to phobia-related stimuli.[<xref rid="ref4" ref-type="bibr">4</xref>]</p><p>Previous work has focused on several methodologies to understand feature selection and object saliency. The concept of the saliency map proposed by Itti <italic>et al</italic>.[<xref rid="ref5" ref-type="bibr">5</xref>] discusses how image features are decomposed into a series of topographical features. The location of these features is compared to the other features of the image to determine which area on the image presents a starker contrast to the rest of the image. This type of approach presents the idea that there are aspects of an image that generate higher attentional responses. This work leads to feature selection techniques by Hou and Zhang[<xref rid="ref6" ref-type="bibr">6</xref>] which have demonstrated that the individual does not need previous dispositions of an object to perform object recognition. Their approach utilized log-spectrum of an input image to determine if there are features in an object that are starkly different than its background. Both approaches leads to fast detection of an object, but not necessarily object saliency. Additionally, both approaches do not rely on previous object learning to produce object recognition. Additional work in neural saliency processing has found attention-related visual pathways based on neurophysiology imaging. Saliency processing involves two partly segregated pathways for salience computation, namely the cortical and subcortical pathways. The subcortical pathways represent a visual saliency map where interactions in the subcortical circuit influence active populations of neurons.[<xref rid="ref7" ref-type="bibr">7</xref>] Contrast changes and embedded noise in images influence neural activity and object perception. This type of interference causes differing levels of neural response saliency.[<xref rid="ref8" ref-type="bibr">8</xref>]</p><p>Specific areas of the brain have been implicated in object recognition. Frontal lobe processing focuses on integrating spatial-object information from working memory.[<xref rid="ref9" ref-type="bibr">9</xref><xref rid="ref10" ref-type="bibr">10</xref>] Electrophysiological studies have found frontal lobe activation while an individual was focusing on an array of input items, that is, letters, numbers, objects, locations, and facial recognition. The medial prefrontal cortex has been shown to be active during emotion-related cortical processing. This is specifically the case found in emotionally salient stimuli, which includes induced emotions and memory retrieval.[<xref rid="ref11" ref-type="bibr">11</xref>]</p><p>Classic neurological analysis has featured the averaging of event-related potentials to multiple trials of object stimuli. Through signal processing techniques, we can further isolate and find neural response incidents related to visual stimuli. Previous work by Freeman[<xref rid="ref12" ref-type="bibr">12</xref>] isolated the amplitude and phase component of the Electroencephalograph (EEG) signal utilizing Hilbert transformations. According to Freeman, the analytic amplitude (AA) provides temporal patterns after sensory stimulation. Neuron populations can be expressed as a &#x0201c;wave packet&#x0201d; of synchronized activity after a stimulus is applied. The wave packet has an amplitude modulation (AM) pattern that relates to the axonal firing intensities of mesoscopic neural populations. When sensory input enters the cortex, neural activation rises above the basal noisy state. Neural intensity achieves a threshold that induces a phase transition denoting a new cortical state.[<xref rid="ref13" ref-type="bibr">13</xref><xref rid="ref14" ref-type="bibr">14</xref>] Action potentials, as depicted as the peaks of Event-related potential (ERP) waveforms, can be quantified as spatial patterns of AM and phase modulation (PM). Classification of AM patterns can enable the discrimination of conditioned stimuli and perceptual processing.[<xref rid="ref15" ref-type="bibr">15</xref><xref rid="ref16" ref-type="bibr">16</xref><xref rid="ref17" ref-type="bibr">17</xref>]</p><p>We intend to provide a quantitative approach utilizing spatiotemporal patterns to analyze where distinct AM patterns can be linked to object perception. Our focus is on the frontal cortex due to its feature selection capabilities which have been tied to emotion-related cortical processing. In this manner, we accurately capture the neural responses to emotionally based object saliency.</p></sec><sec sec-type="materials|methods" id="sec1-2"><title>Materials and Methods</title><p>The experiments for this project were held in the Computational Neurodynamics Lab at the FedEx institute of Technology at the University of Memphis. This study has been approved by the University of Memphis Institutional Review Board (IRB-071411-790). We utilized the electrode array prototype MINDO-48S-001AFF0900A7, produced by BRC/NCTU, Hsinchu, Taiwan.[<xref rid="ref18" ref-type="bibr">18</xref>] MINDO-48S oversamples EEG + Electromyograph (EMG) by 48 closely spaced spring-loaded electrodes in a flexible curvilinear array that could be quickly fixed on the scalp of a volunteer in any orientation. The electrodes have a length of 3 mm and a diameter of 1 mm, and they have been developed based on MINDO's patented technology using a special golden alloy. MINDO-48S uses wireless transmission through Bluetooth to communicate with a laptop computer, which serves as portal with a GUI and saves the measured data. The sampling frequency was 512 Hz.</p><sec id="sec2-1"><title>Stimuli</title><p>Two females and one male whose mean age was 30 participated in this study. After an initial 30-s period, four randomized stimuli were presented over five trials separated by 5-s intervals [<xref ref-type="fig" rid="F1">Figure 1</xref>]. The stimuli consisted of an apple, orange, spider, and angler fish.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Randomized stimuli presented as low/high salient objects consisting of spiders/angular fish and apples/orange<italic>s</italic></p></caption><graphic xlink:href="JMSS-7-123-g001"/></fig><p>In order to measure neural responses to object saliency, we have the subjects focus on the randomized objects and measure their event-related potentials via the MINDO EEG acquisition device. The complete set includes three motherboards, where only the top board is visible. Each motherboard processes 16 channels and transmits the data via wireless Bluetooth communication to a laptop personal computer (PC) equipped with the MINDO GUI software. Every cable from each electrode to the motherboard is labeled and color-coded from 1 to 48 for channel identification [<xref ref-type="fig" rid="F2">Figure 2</xref>].</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>The MINDO-48S has a dense array of 48 dry electrodes, with an approximate length of a linear array of 250 mm. The spring-loaded electrodes are made of a golden alloy; with a diameter of 1 mm and length of 3 mm. One motherboard is shown as well as ground and reference connections</p></caption><graphic xlink:href="JMSS-7-123-g002"/></fig><p>The stimulus was presented via a 17-inch liquid crystal display (LCD) monitor with 1280 &#x000d7; 800 resolutions. The images were presented as a movie using Windows Movie Maker. Each image was presented for 5 s, and the rest time or blank screen interval between two images was 5 s. All images were centrally shown on a CRT LCD monitor. Image presentation was controlled via a computer Pentium 4 with 512 MB RAM and 40 GB HDD PC. [<xref ref-type="fig" rid="F3">Figure 3</xref>] features a participant wearing the MINDO device as object stimuli are presented.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>Visual stimuli presented to participant wearing Mindo device. The participant views a series of various objects while frontal lobe activity is captured via device</p></caption><graphic xlink:href="JMSS-7-123-g003"/></fig></sec><sec id="sec2-2"><title>Location of the amplitude modulation patterns</title><p>The EEG signals were decomposed into amplitude and phase values. Before the application of the Hilbert transformation, a band-pass filter is desirable to select the optimum frequency under this study.[<xref rid="ref20" ref-type="bibr">20</xref><xref rid="ref21" ref-type="bibr">21</xref>] In this work, the beta-gamma band-pass range is selected, which has enabled AM patterns found in EEGs to have a high degree of coherence, stability, and intensity. This band-pass range enabled the optimization of quantifying amplitude and phase thresholds of the EEG signal.</p><p>The dataset is broken into 10-s windows, that is, 5-s image stimuli, followed by 5-s rest periods. For each window, the following six steps were required to localize temporal frames so that amplitude feature vectors and phase values could be calculated for EEG quantification:</p><p>Step 1: EEG data were pre-processed using a notch filter to remove 60 Hz ambient machine noise, and low-pass filtered to remove unnecessary frequencies above 100 Hz since lower frequencies will be focused on in this study.</p><p>Step 2: EEG signals were band-pass filtered by convolution in the time domain with a Remez filter. A beta-gamma band pass filter was applied to find the optimal AA and analytic phase (AP) threshold values as they relate to active states in the cortex.</p><p>Step 3: The Hilbert transform was applied to the filtered signal to obtain the real and imaginary parts of the analytic signal.[<xref rid="ref22" ref-type="bibr">22</xref><xref rid="ref23" ref-type="bibr">23</xref>] Analytic power was the squared sum of the real and imaginary parts of the analytic signal. AA was the square root of analytic power. AP was the ratio of the arctangent of the imaginary part of the analytic signal to the arctangent of the real part of the analytic signal. The AP was unwrapped using the MATLAB &#x0201c;unwrap&#x0201d; function. For an arbitrary signal <italic>v</italic>, the Hilbert transform is defined as follows:</p><p><inline-graphic xlink:href="JMSS-7-123-g004.jpg"/></p><p>where PV corresponds to the Cauchy principal value. Using <italic>v</italic>&#x02032;(<italic>t</italic>), the complex analytic signal <italic>V</italic>(<italic>t</italic>) is defined as: <italic>V</italic>(<italic>t</italic>) = <italic>v</italic>(<italic>t</italic>) + <italic>iv</italic>&#x02032;(<italic>t</italic>), where <italic>i</italic> has the usual meaning of <inline-graphic xlink:href="JMSS-7-123-g005.jpg"/>. The AA is given by:</p><p>AA(<italic>t</italic>) = [<italic>v</italic><sup>2</sup>(<italic>t</italic>)+<italic>v</italic>&#x02032;<sup>2</sup>(<italic>t</italic>)]<sup>0.5</sup> &#x02003;&#x02003;&#x02003;&#x02003; (2)</p><p>Step 4: Instantaneous frequency, the rate of change in phase with time (Hz), was estimated as the successive differences of the mean unwrapped AP divided by the digitizing step and 2&#x003c0;.[<xref rid="ref24" ref-type="bibr">24</xref>] The standard deviation of phase differences was calculated to find the instances where phase differences demarcated the instances of AA to show cinematic frames of cortical information.</p><p>Step 5: Threshold values were applied to log(AA), unwrapped phase differences (UD), and the standard deviation of phase differences (US). US values segmented the EEG into temporal frames and the AA, which expressed the pattern in each frame, as a feature vector (log(AA)).</p><p>Step 6: AA, UD, and US values were analyzed to determine which output of these threshold values enabled the clear delineation of temporal grouping as it relates to cognitive tasking and resting areas.</p></sec><sec id="sec2-3"><title>Data processing</title><p>For each 10-s window, AM patterns are found through neural amplitude spike thresholds. Threshold selection separates neural responses to stimuli from background neural activity. Four sets of stimuli were presented five times per trial for three trials per participant. For each window, AM patterns were averaged into 10 point segments, and each segment was counted if it reached above an AM threshold. There may be multiple spikes per window for each object stimulus.</p><p>Additionally, all segments were grouped per object stimuli. For each segment, there were five instances per object within a group. For each segment grouping, if 3/5 (60%) of the AM patterns were greater than the threshold, that group was counted. In this manner, similar neural spiking patterns for each object were compared across a given trial. The statistical significance of object saliency between the different stimuli was measured through chi-square (<italic>X</italic><sup>2</sup>) analysis.</p></sec></sec><sec sec-type="results" id="sec1-3"><title>Results</title><p>Our goal was to find quantitative neurological signals that were produced from different levels of visual stimuli. The analytic amplitude and phase values were found to capture distinctive signal responses to stimuli as seen in [<xref ref-type="fig" rid="F4">Figure 4</xref>]. <xref ref-type="fig" rid="F4">Figure 4(a)</xref> &#x0201c;orange&#x0201d; stimuli produces an early AA/AP signature as opposed to late responses found in Figure <xref ref-type="fig" rid="F4">4(b)</xref> and <xref ref-type="fig" rid="F4">(d)</xref> which correspond to &#x0201c;apple&#x0201d; and &#x0201c;angler fish.&#x0201d; <xref ref-type="fig" rid="F4">Figure 4(c)</xref> &#x0201c;spider&#x0201d; produces a response midway through the time window.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p>The analytic amplitude of the EEG signal provides distinct quantitative responses to: (a) orange, (b) apple, (c) spider, and (d) angler <italic>fish</italic></p></caption><graphic xlink:href="JMSS-7-123-g006"/></fig><p>Across each participant, each AA response was summed and averaged to determine which stimuli produced the most salient response. For participant 2201, the &#x0201c;orange&#x0201d; stimulus produced the highest average of AA response with the smallest standard error of the mean (SEM), followed by the &#x0201c;apple&#x0201d; stimuli (<italic>X</italic><sup>2</sup> = 13.92, <italic>P</italic> = 0.003). However, for participant 4942, the &#x0201c;angler fish&#x0201d; and &#x0201c;spider&#x0201d; stimuli produced the highest averages of AA responses (<italic>X</italic><sup>2</sup> = 15.06, <italic>P</italic> = 0.002), yet with relatively high SEM. Again, for participant 3250, the &#x0201c;spider&#x0201d; stimulus presented the highest averages with a low SEM, along with &#x0201c;apple&#x0201d; having a high count but with a relatively high SEM (<italic>X</italic><sup>2</sup> = 5.27, <italic>P</italic> = 0.152) [<xref ref-type="fig" rid="F5">Figure 5</xref>].</p><fig id="F5" position="float"><label>Figure 5</label><caption><p>Averages and standard error of the mean of analytic amplitudes of the EEG waveform per participant per stimuli</p></caption><graphic xlink:href="JMSS-7-123-g007"/></fig><p>Overall AA averages [<xref ref-type="fig" rid="F6">Figure 6</xref>] demonstrate that the most salient stimuli response was predominantly &#x0201c;oranges&#x0201d; followed by &#x0201c;spider&#x0201d; stimuli. It is worth noting that, while the &#x0201c;orange&#x0201d; stimulus produced an overwhelming number of AA responses for one participant, the &#x0201c;spider&#x0201d; stimulus maintained a consistent count throughout all the trials across all participants (<italic>X</italic><sup>2</sup> = 30.99, <italic>P</italic> = 0.001).</p><fig id="F6" position="float"><label>Figure 6</label><caption><p>Total number of analytic amplitudes of the EEG waveform per participant per stimul<italic>i</italic></p></caption><graphic xlink:href="JMSS-7-123-g008"/></fig><p>Event-related potentials were acquired in three sections of the frontal lobe, consisting of 16 electrodes each. Each of these sections corresponded to left, center, and right areas of the MINDO device. We wanted to determine where the most dominant areas of the frontal cortex produced the responses to stimuli. The midrange frontal cortex produced the highest number of responses to stimuli presented to the participants versus the left and right areas. &#x0201c;spider&#x0201d; and &#x0201c;orange&#x0201d; stimuli were, once again, the most salient types of stimuli, which produced midrange frontal activation (<italic>X</italic><sup>2</sup> = 4.19, <italic>P</italic> = 0.004) [<xref ref-type="fig" rid="F7">Figure 7</xref>].</p><fig id="F7" position="float"><label>Figure 7</label><caption><p>Total number of analytic amplitude values associated with the EEG waveform per participant per stimuli from the left, right, and middle areas of the frontal corte<italic>x</italic></p></caption><graphic xlink:href="JMSS-7-123-g009"/></fig></sec><sec sec-type="discussion" id="sec1-4"><title>Discussion</title><p>Our approach can differentiate between high and low salient objects. The AA/AP calculations have distinct and repeatable neuro-markers per participants that relate to object recognition. Although our analysis did not display reproducible neural responses between less salient objects such as apples and oranges, it did achieve differentiating between two types of object saliency, that is, low and high salient object such as spiders vs. oranges [Figures <xref ref-type="fig" rid="F5">5</xref> and <xref ref-type="fig" rid="F6">6</xref>]. Our methodology randomized objects so that there were no repeatable images across the trials. Therefore, the participant did not become acclimated to viewing similar objects.</p><p>High-resolution or high-contrast images did not seem to play an important role in perceptual object responses.[<xref rid="ref25" ref-type="bibr">25</xref>] One important aspect of visual neural processing to consider is non-classical receptive field inhibition,[<xref rid="ref26" ref-type="bibr">26</xref>] whereas if all the attributes of an object are non-homogeneous, that is, the parts of the object are not the same in the focal area as they are in the neighboring areas of the central part of the object, then neural responses are less modulated or inhibited. This idea may correspond to higher neural activity found in the spider stimuli, since its appendages differ from the roundness of its body. Additionally, object association seems to play a greater part in neural responses, such that a low-resolution image of a threatening object may produce a higher neural response than a high-resolution image of fresh fruit.</p><p>The middle frontal cortex presented the highest responses to object saliency [<xref ref-type="fig" rid="F7">Figure 7</xref>], specifically in higher saliency objects such as the image of the spider. Our results agree with previous work that entails the frontal cortex in integrating object recognition with working memory. This result confirms that working memory may be implicated in greater neural responses due to learned behavior. Previous studies have also found that emotional binding to object recognition has also been found in the frontal cortex.[<xref rid="ref27" ref-type="bibr">27</xref>] Additionally, several regions of the brain appear to mediate responses to salient stimuli that lead to appetitive and aversive behaviors, areas implicated in object recognition. Neural responses to aversive stimuli have been found to be greater than nonaversive stimuli.[<xref rid="ref28" ref-type="bibr">28</xref>] We see a higher degree of neural responses to aversive stimuli when the participant is subjected to the spider stimuli, whereas the presentation of the orange stimuli has slightly lesser appetitive responses.</p><p>Dendrites convert the axonal pulse they receive into a wave, which is later converted back into a pulse by the axon. This pulse-wave and wave-pulse is an essential function of the neurons and neuron populations. Neural activities produce a &#x0201c;wave&#x0201d; of synchronous activity across dense, larger neural populations. This activity is formed from a neural state, which can be associated to various visual sensory inputs. Freeman[<xref rid="ref12" ref-type="bibr">12</xref>] has found that cortical responses to stimuli can be discerned via the AA of the signal, which is associated to the high or low intensities of the dendritic populations as well as the firing rates of neural neighborhood clusters. The Hilbert transform enables the calculation of the analytical amplitude, which has been found to provide the intensity of neural populations based on the saliency of the visual input. As the brain processes various visual inputs, a phase transition occurs where neural signal modulations capture the activity of perceptual information processing from sensory inputs.[<xref rid="ref23" ref-type="bibr">23</xref>] State transitions involve both the amplitude component and the phase component of the signal, in the form of phase transitions. For each presented object, neurological signals initially undergo a resetting or initialization of the phase component of the signal as predominant beta-gamma activity. Afterwards, a re-synchronization then stabilization of amplitude modulation, followed by an increase in amplitude of the AM pattern, all within 24&#x02013;34 ms.[<xref rid="ref14" ref-type="bibr">14</xref>] We see these effects for each AM activity in the cortical dynamics of object representation. The interaction between the amplitude and phase component of the EEG signal presents a type of cinematographic phenomena where the amplitude component represents the picture or content of the film and the phase component becomes the shutter of the camera.[<xref rid="ref24" ref-type="bibr">24</xref>] Successive AM/PM activity resembles the frames in a black/white cinema with successive spatial patterns held briefly. We see this AM/PM interchange per object stimuli, with each object having its own neural signature depending on appetitive or aversive stimuli.</p></sec><sec sec-type="conclusion" id="sec1-5"><title>Conclusion</title><p>Our work has demonstrated that visual object stimuli have different levels of neural responses that can be consistently measured through the frontal area of the cortex. The interpretation of sensory stimuli is in the form of AM/PM patterns, which exhibit impulse and timing depending on the stimuli. Additionally, learned responses to the stimuli have a large bearing to neural activity. Those objects that have traditionally either instilled fear or are appealing to the viewer will present a different type of neural response than those objects deemed &#x0201c;neutral&#x0201d; to the observer. The analysis presented in this work have shown significant differences in neural responses to aversive and appetitive stimuli, which may support the idea that objects that present a higher emotional response may bypass any habituation to neural activity. It is through the fine-grained signal processing approach in this work that support these types of neural activity.</p><p>Object perception involves the brain to be in a constant state of expectancy, where the external world presents stimuli that are converted to action potentials. Action potentials become pulse trains throughout the cortex that innervate pathways throughout the cortex to the frontal cortex, which enables object recognition with working memory. Sensory input has no meaning by itself &#x02212; a type of &#x0201c;binding&#x0201d; has to occur that translates stimuli to meaningful information, such as through the brain's capability to determine if the objective is appetitive or aversive to the viewer. The conversion of external stimuli to recognition involves the mechanism of learned behaviors that associates objects to neural signatures, which can be deciphered as frames of AM/PM patterns. This mechanism becomes the language of the brain. Through this work, we can expand our encyclopedia of neural signatures to object recognition, and provide a broader understanding of quantitative neural responses to the outside world.</p><sec id="sec2-4"><title>Financial support and sponsorship</title><p>None.</p></sec><sec id="sec2-5" sec-type="COI-statement"><title>Conflicts of interest</title><p>There are no conflicts of interest.</p></sec></sec></body><back><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Edelman</surname><given-names>GM</given-names></name></person-group><source>Neural Darwinism: The Theory of Neuronal Group Selection</source><year>1987</year><publisher-loc>New York</publisher-loc><publisher-name>Basic Books</publisher-name></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name><name><surname>Worsley</surname><given-names>KJ</given-names></name><name><surname>Poline</surname><given-names>JP</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Frackowiak</surname><given-names>RS</given-names></name></person-group><article-title>Statistical parametric maps in functional imaging: A general linear approach</article-title><source>Hum Brain Map</source><year>1994</year><volume>2</volume><fpage>189</fpage><lpage>210</lpage></element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi</surname><given-names>V</given-names></name><name><surname>Vanlessen</surname><given-names>N</given-names></name><name><surname>Bayer</surname><given-names>M</given-names></name><name><surname>Grass</surname><given-names>A</given-names></name><name><surname>Pourtois</surname><given-names>G</given-names></name><name><surname>Schacht</surname><given-names>A</given-names></name></person-group><article-title>Motivational salience modulates early visual cortex responses across task sets</article-title><source>J Cogn Neurosci</source><year>2017</year><fpage>1</fpage><lpage>12</lpage></element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakataki</surname><given-names>M</given-names></name><name><surname>Soravia</surname><given-names>LM</given-names></name><name><surname>Schwab</surname><given-names>S</given-names></name><name><surname>Horn</surname><given-names>H</given-names></name><name><surname>Dierks</surname><given-names>T</given-names></name><name><surname>Strik</surname><given-names>W</given-names></name><etal/></person-group><article-title>Glucocorticoid administration improves aberrant fear-processing networks in spider phobia</article-title><source>Neuropsychopharmacology</source><year>2017</year><volume>42</volume><fpage>485</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">27644128</pub-id></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Niebur</surname><given-names>E</given-names></name></person-group><article-title>A model of saliency-based visual attention for rapid scene analysis</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>1998</year><volume>20</volume><fpage>1254</fpage><lpage>9</lpage></element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hou</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name></person-group><article-title>Saliency detection: A spectral residual approach</article-title><source>2007 IEEE Conference on Computer Vision and Pattern Recognition</source><year>2007</year><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veale</surname><given-names>R</given-names></name><name><surname>Hafed</surname><given-names>ZM</given-names></name><name><surname>Yoshida</surname><given-names>M</given-names></name></person-group><article-title>How is visual salience computed in the brain? Insights from behaviour, neurobiology and modelling</article-title><source>Philos Trans R Soc B: Biol Sci</source><year>2017</year><fpage>372</fpage></element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smout</surname><given-names>CA</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><article-title>Spatial attention enhances the neural representation of invisible signals embedded in noise</article-title><source>bioRxiv</source><year>2017</year><fpage>102731</fpage></element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rainer</surname><given-names>G</given-names></name><name><surname>Asaad</surname><given-names>WF</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Memory fields of neurons in the primate prefrontal cortex</article-title><source>Proc Natl Acad Sci</source><year>1998</year><fpage>15008</fpage><lpage>13</lpage><pub-id pub-id-type="pmid">9844006</pub-id></element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rainer</surname><given-names>G</given-names></name><name><surname>Assad</surname><given-names>WF</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><article-title>Selective representation of relevant information by neurons in the primate prefrontal cortex</article-title><source>Nature</source><year>1998</year><volume>393</volume><fpage>577</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">9634233</pub-id></element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maddock</surname><given-names>RJ</given-names></name></person-group><article-title>The retrosplenial cortex and emotion: New insights from functional neuroimaging of the human brain</article-title><source>Trends Neurosci</source><year>1999</year><volume>22</volume><fpage>310</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">10370255</pub-id></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><article-title>Origin, structure, and role of background EEG activity. Part 1. Analytic amplitude</article-title><source>Clin Neurophysiol</source><year>2004</year><volume>115</volume><fpage>2077</fpage><lpage>88</lpage><pub-id pub-id-type="pmid">15294210</pub-id></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>Barrie</surname><given-names>JM</given-names></name></person-group><article-title>Analysis of spatial patterns of phase in neocortical gamma EEGs in rabbit</article-title><source>J Neurophysiol</source><year>2000</year><volume>84</volume><fpage>1266</fpage><lpage>78</lpage><pub-id pub-id-type="pmid">10980001</pub-id></element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>Burke</surname><given-names>BC</given-names></name><name><surname>Holmes</surname><given-names>MD</given-names></name></person-group><article-title>Aperiodic phase re-setting in scalp EEG of beta-gamma oscillations by state transitions at alpha-theta rates</article-title><source>Hum Brain Map</source><year>2003</year><volume>19</volume><fpage>248</fpage><lpage>72</lpage></element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrie</surname><given-names>JM</given-names></name><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>Lenhart</surname><given-names>M</given-names></name></person-group><article-title>Modulation by discriminative training of spatial patterns of gamma EEG amplitude and phase in neocortex of rabbits</article-title><source>J Neurophysiol</source><year>1996</year><volume>76</volume><fpage>520</fpage><lpage>39</lpage><pub-id pub-id-type="pmid">8836241</pub-id></element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>van Dijk</surname><given-names>BW</given-names></name></person-group><article-title>Spatial patterns of visual cortical fast EEG during conditioned reflex in a rhesus monkey</article-title><source>Brain Res</source><year>1987</year><volume>422</volume><fpage>267</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">3676788</pub-id></element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohl</surname><given-names>FW</given-names></name><name><surname>Scheich</surname><given-names>H</given-names></name><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><article-title>Change in pattern of ongoing cortical activity with auditory category learning</article-title><source>Nature</source><year>2001</year><volume>412</volume><fpage>733</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">11507640</pub-id></element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liao</surname><given-names>LD</given-names></name><name><surname>Lin</surname><given-names>CT</given-names></name><name><surname>McDowell</surname><given-names>K</given-names></name><name><surname>Wickenden</surname><given-names>AE</given-names></name><name><surname>Gramann</surname><given-names>K</given-names></name><name><surname>Jung</surname><given-names>TP</given-names></name><etal/></person-group><article-title>Biosensor technologies for augmented brain&#x02013;computer interfaces in the next decades</article-title><source>Proc IEEE</source><year>2012</year><volume>100</volume><fpage>1553</fpage><lpage>66</lpage><comment>[Special Centennial Issue]</comment></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>JJ</given-names></name><name><surname>Kozma</surname><given-names>R</given-names></name><name><surname>Lin</surname><given-names>CT</given-names></name><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><article-title>Spatio-temporal EEG pattern extraction using high-density scalp arrays</article-title><source>2016 International Joint Conference in Neural Networks (IJCNN)</source><year>2016</year><publisher-name>IEEE</publisher-name><fpage>889</fpage><lpage>96</lpage></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>Rogers</surname><given-names>LJ</given-names></name></person-group><article-title>A neurobiological theory of meaning in perception. Part V: Multicortical patterns of phase modulation in gamma EEG</article-title><source>Int J Bifurc Chaos</source><year>2003</year><volume>13</volume><fpage>2867</fpage><lpage>87</lpage></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Van Quyen</surname><given-names>M</given-names></name><name><surname>Foucher</surname><given-names>J</given-names></name><name><surname>Lachaux</surname><given-names>JP</given-names></name><name><surname>Rodriguez</surname><given-names>E</given-names></name><name><surname>Lutz</surname><given-names>A</given-names></name><name><surname>Martinerie</surname><given-names>J</given-names></name><etal/></person-group><article-title>Comparison of Hilbert transform and wavelet methods for the analysis of neuronal synchrony</article-title><source>J Neurosci Methods</source><year>2001</year><volume>111</volume><fpage>83</fpage><lpage>98</lpage><pub-id pub-id-type="pmid">11595276</pub-id></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>JS</given-names></name></person-group><source>The Electroencephalogram: Its Patterns and Origins</source><year>1993</year><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><article-title>Origin, structure, and role of background EEG activity. Part 2. Analytic phase</article-title><source>Clin Neurophysiol</source><year>2004</year><volume>115</volume><fpage>2089</fpage><lpage>107</lpage><pub-id pub-id-type="pmid">15294211</pub-id></element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><article-title>Origin, structure, and role of background EEG activity. Part 4: Neural frame simulation</article-title><source>Clin Neurophysiol</source><year>2006</year><volume>117</volume><fpage>572</fpage><lpage>89</lpage><pub-id pub-id-type="pmid">16442345</pub-id></element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>JS</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><article-title>Time course of neural signatures of object recognition</article-title><source>J Vis</source><year>2003</year><volume>3</volume><fpage>499</fpage><lpage>512</lpage><pub-id pub-id-type="pmid">14507255</pub-id></element-citation></ref><ref id="ref26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allman</surname><given-names>J</given-names></name><name><surname>Miezin</surname><given-names>F</given-names></name><name><surname>McGuinness</surname><given-names>E</given-names></name></person-group><article-title>Stimulus specific responses from beyond the classical receptive field: Neurophysiological mechanisms for local-global comparisons in visual neurons</article-title><source>Annu Rev Neurosci</source><year>1985</year><volume>8</volume><fpage>407</fpage><lpage>30</lpage><pub-id pub-id-type="pmid">3885829</pub-id></element-citation></ref><ref id="ref27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Reiman</surname><given-names>EM</given-names></name><name><surname>Axelrod</surname><given-names>B</given-names></name><name><surname>Yun</surname><given-names>LS</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name><name><surname>Schwartz</surname><given-names>GE</given-names></name></person-group><article-title>Neural correlates of levels of emotional awareness: Evidence of an interaction between emotion and attention in the anterior cingulate cortex</article-title><source>J Cogn Neurosci</source><year>1998</year><volume>10</volume><fpage>525</fpage><lpage>35</lpage><pub-id pub-id-type="pmid">9712681</pub-id></element-citation></ref><ref id="ref28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Neural responses to salient visual stimuli</article-title><source>Proc R Soc Lond B: Biol Sci</source><year>1997</year><volume>264</volume><fpage>769</fpage><lpage>75</lpage></element-citation></ref></ref-list></back></article>