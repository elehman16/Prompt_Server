<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25365325</article-id><article-id pub-id-type="pmc">4218862</article-id><article-id pub-id-type="publisher-id">PONE-D-14-11991</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0109700</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subject>Evoked Potentials</subject></subj-group></subj-group></subj-group><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>A Novel Algorithm to Enhance P300 in Single Trials: Application to Lie Detection Using F-Score and SVM</article-title><alt-title alt-title-type="running-head">Spatial Denoising Method for P300 to Detect Liars</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Junfeng</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="aff" rid="aff5">
<sup>5</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Tian</surname><given-names>Hongjun</given-names></name><xref ref-type="aff" rid="aff2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Yang</surname><given-names>Yong</given-names></name><xref ref-type="aff" rid="aff3">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Xiaolin</given-names></name><xref ref-type="aff" rid="aff4">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Chenhong</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Rao</surname><given-names>Nini</given-names></name><xref ref-type="aff" rid="aff5">
<sup>5</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib></contrib-group><aff id="aff1">
<label>1</label>
<addr-line>College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, People's Republic of China</addr-line>
</aff><aff id="aff2">
<label>2</label>
<addr-line>Nanjing Fullshare Superconducting Technology Co., Ltd., Nanjing, People's Republic of China</addr-line>
</aff><aff id="aff3">
<label>3</label>
<addr-line>School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, People's Republic of China</addr-line>
</aff><aff id="aff4">
<label>4</label>
<addr-line>Department of Information Engineering, Officers College of CAPF, People's Republic of China</addr-line>
</aff><aff id="aff5">
<label>5</label>
<addr-line>School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, People's Republic of China</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Kestler</surname><given-names>Hans A.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>University of Ulm, Germany</addr-line>
</aff><author-notes><corresp id="cor1">* E-mail: <email>lichen@mail.scuec.edu.cn</email> (CL); <email>raonini@uestc.edu.cn</email> (NR)</corresp><fn fn-type="COI-statement"><p><bold>Competing Interests: </bold>Dr. Hongjun Tian is employed by Nanjing Fullshare Superconducting Technology Co., Ltd., Nanjing, People's Republic of China. The company had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. This does not alter the authors' adherence to all the PLOS ONE policies on sharing data and materials.</p></fn><fn fn-type="con"><p>Conceived and designed the experiments: JFG NNR. Performed the experiments: YY XLY. Analyzed the data: JFG HJT CHL. Contributed reagents/materials/analysis tools: CHL. Wrote the paper: JFG.</p></fn></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>3</day><month>11</month><year>2014</year></pub-date><volume>9</volume><issue>11</issue><elocation-id>e109700</elocation-id><history><date date-type="received"><day>17</day><month>3</month><year>2014</year></date><date date-type="accepted"><day>13</day><month>8</month><year>2014</year></date></history><permissions><copyright-statement>&#x000a9; 2014 Gao et al</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Gao et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><abstract><p>The investigation of lie detection methods based on P300 potentials has drawn much interest in recent years. We presented a novel algorithm to enhance signal-to-noise ratio (SNR) of P300 and applied it in lie detection to increase the classification accuracy. Thirty-four subjects were divided randomly into guilty and innocent groups, and the EEG signals on 14 electrodes were recorded. A novel spatial denoising algorithm (SDA) was proposed to reconstruct the P300 with a high SNR based on independent component analysis. The differences between the proposed method and our/other early published methods mainly lie in the extraction and feature selection method of P300. Three groups of features were extracted from the denoised waves; then, the optimal features were selected by the F-score method. Selected feature samples were finally fed into three classical classifiers to make a performance comparison. The optimal parameter values in the SDA and the classifiers were tuned using a grid-searching training procedure with cross-validation. The support vector machine (SVM) approach was adopted to combine with an F-score because this approach had the best performance. The presented model F-score_SVM reaches a significantly higher classification accuracy for P300 (specificity of 96.05%) and non-P300 (sensitivity of 96.11%) compared with the results obtained without using SDA and compared with the results obtained by other classification models. Moreover, a higher individual diagnosis rate can be obtained compared with previous methods, and the presented method requires only a small number of stimuli in the real testing application.</p></abstract><funding-group><funding-statement>This work was supported by National Nature Science Foundation of China (No. 81271659, 61262034, 61302011, 81171411 and 30972848), and Academic Team of South Central University for Nationalities: Biomedical Signals Processing (No. XTZ09002). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="15"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All raw recording EEG files and software are available from the public repository DRYAD using the DOI doi:10.5061/dryad.2qc64. All raw recording EEG files are without any limitations.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The authors confirm that all data underlying the findings are fully available without restriction. All raw recording EEG files and software are available from the public repository DRYAD using the DOI doi:10.5061/dryad.2qc64. All raw recording EEG files are without any limitations.</p></notes></front><body><sec id="s1"><title>Introduction</title><p>Research into lie detection has drawn a substantial amount of attention over the past several decades and has found many important applications in the legal, moral and clinical fields <xref rid="pone.0109700-Gamer1" ref-type="bibr">[1]</xref>&#x02013;<xref rid="pone.0109700-Ito1" ref-type="bibr">[3]</xref>. Currently, a number of studies that adopt neurophysiological signals have been conducted on lie detection. These methods have used Magnetic Resonance Imaging <xref rid="pone.0109700-Langleben1" ref-type="bibr">[4]</xref>, <xref rid="pone.0109700-Phan1" ref-type="bibr">[5]</xref> and Event-Related Potentials (ERPs) <xref rid="pone.0109700-Rosenfeld1" ref-type="bibr">[6]</xref>, <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>. P300, an endogenous ERP component, has been extensively investigated <xref rid="pone.0109700-Polich1" ref-type="bibr">[8]</xref> and has been successfully used for deception detection <xref rid="pone.0109700-Meijer1" ref-type="bibr">[9]</xref>.</p><p>Widely used P300-based lie detection methods can be roughly divided into three categories: the bootstrapped amplitude difference (BAD) <xref rid="pone.0109700-Rosenfeld2" ref-type="bibr">[10]</xref>, <xref rid="pone.0109700-Rosenfeld3" ref-type="bibr">[11]</xref>, the bootstrapped correlation difference (BCD) <xref rid="pone.0109700-Farwell1" ref-type="bibr">[12]</xref> and machine learning methods <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Abootalebi2" ref-type="bibr">[13]</xref>, <xref rid="pone.0109700-Dvatzikos1" ref-type="bibr">[14]</xref>. For the methods listed above, there are three types of stimuli that are presented to subjects, i.e., Probe (P), Target (T) and Irrelevant (I) stimuli <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>.</p><p>A good lie detection method should use a small number of stimuli to achieve as high accuracy as possible. To realize this goal for the P300-based lie detection, a critical step is to extract the P300 with a high signal/noise ratio (SNR). Although the P300 is time- and phase-locked to experimental stimuli, the extraction of the P300 with a high SNR is still a challenging task because various types of noise are superimposed seriously on P300 <xref rid="pone.0109700-Jung1" ref-type="bibr">[15]</xref>. BAD and BCD use the statistical technique of bootstrapping <xref rid="pone.0109700-Wasserman1" ref-type="bibr">[16]</xref> to generate many different averages of ERP from the same set of stimuli <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>. Using bootstrapping, the SNR of P300 can be increased. However, such a mode involves a large number of stimuli and hence is at the expense of taking a longer time for signal acquisition, which would also increase the fatigue of the subjects. In addition, more recently, a few researchers have investigated single trial-based lie detection methods that were based on machine learning <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Dvatzikos1" ref-type="bibr">[14]</xref>. In these methods, some features were extracted from single trials and then were used to train classifiers to differentiate between different brain states. The testing results showed that machine learning methods could achieve a higher detection accuracy than BAD and BCD methods <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>. However, they typically did not remove the noises embedded in single trials, resulting in unsatisfactory detection accuracy.</p><p>Consider the noises embedded in single trials for P300 extraction. The EEG recording on one sensor consists of two main parts. One part is extra-skull noise, and the other part is the signal produced by intra-skull neuronal sources at specific brain regions, including ERP and spontaneous EEG. Obviously, the ERP cannot be represented by the signal from the sensor directly. Conventional lie detection methods could not separate P300 from the noise and spontaneous EEG because their time courses and scalp projections usually overlap <xref rid="pone.0109700-Jung2" ref-type="bibr">[17]</xref>. Recently, independent component analysis (ICA), a blind source separation (BSS) method <xref rid="pone.0109700-Jung1" ref-type="bibr">[15]</xref>, <xref rid="pone.0109700-Bell1" ref-type="bibr">[18]</xref>&#x02013;<xref rid="pone.0109700-Parra1" ref-type="bibr">[20]</xref>, was used to extract stimulus-related ERP into independent components (ICs) <xref rid="pone.0109700-Peterson1" ref-type="bibr">[21]</xref>&#x02013;<xref rid="pone.0109700-Gao1" ref-type="bibr">[24]</xref>. The results showed that the decomposed ICs were more distinguishable than the &#x0201c;sensor signals&#x0201d; <xref rid="pone.0109700-Hung1" ref-type="bibr">[22]</xref>, <xref rid="pone.0109700-Tang2" ref-type="bibr">[23]</xref>. In our early study <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>, we proposed an ICA-based template matching method, topography-template matching (TTM) algorithm, to enhance the SNR of P300, and we achieved promising results. In TTM, we only consider the P300 independent sources affect in Pz site. In addition, one neurophysiologist was employed to select the P300 independent source by his experience. In this study we present a novel spatial denoising algorithm (SDA) to improve that early study. Comparing with our early study, SDA consider more affecting areas including at P3, P4, Pz, Cz and Oz sites. In addition, SDA recognized P300 independent source automatically, not by experience. Hence, the SDA is more reasonable and objective than the early study. The key innovation is how to automatically identify the P300 ICs (i.e., the ICs accounting for the P300), which will be described in the following section.</p><p>By removing any redundant features, feature selection can help the original classification system to achieve better classification performance including lower computational costs and higher classification accuracy. Polat et al. indicated that feature selection improves the classification accuracy by using a hybrid system of feature selection and several classifiers <xref rid="pone.0109700-Comon1" ref-type="bibr">[26]</xref>. In this study, the F-score <xref rid="pone.0109700-Mrzagora1" ref-type="bibr">[38]</xref>, a simple but effective technique, was used to select the optimal features from the original extracted features. In addition, to select a suitable classifier, all of the training samples with the selected optimal features were fed into three popular classifiers to compare their performance.</p><p>For conventional lie detection like BCD/BAD <xref rid="pone.0109700-Rosenfeld2" ref-type="bibr">[10]</xref>&#x02013;<xref rid="pone.0109700-Farwell1" ref-type="bibr">[12]</xref> and other some lie detection methods <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Abootalebi2" ref-type="bibr">[13]</xref>, a number of stimuli were required to present to the subjects in practical applications, because both of the bootstrapping technique and threshold selection-based classification were based on many stimuli responses. This would limit the real application of lie detection. First, there is often very limited information related to criminal acts. Second, many repeated stimuli with little information would cause two problems. One problem is fatigue, and the other is an increase in the countermeasures <xref rid="pone.0109700-Rosenfeld3" ref-type="bibr">[11]</xref>, because real criminals might be familiar with the stimuli and tend to resist the detection when many stimuli are presented repeatedly. Furthermore, based on the analysis results from a number of stimuli, when the researcher need to make the last judgment, a threshold strategy (see the references <xref rid="pone.0109700-Rosenfeld2" ref-type="bibr">[10]</xref>&#x02013;<xref rid="pone.0109700-Farwell1" ref-type="bibr">[12]</xref>, <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Abootalebi2" ref-type="bibr">[13]</xref> for details) was inevitably used, which was a subjective decision on the individual diagnostic rate. The present method aims at using only a small number of stimuli and having no threshold problem.</p></sec><sec sec-type="materials" id="s2"><title>Materials</title><sec id="s2a"><title>Ethics statement</title><p>The experiment was approved by Psychology Research Ethical Committee (PREC) of the College of Biomedical Engineering in South-Central University for Nationalities. Thirty healthy subjects (15 females, mean age of 21.5) were recruited from the university. The participants provided their written informed consent according to a human research protocol in this study.</p></sec><sec id="s2b"><title>EEG Data Acquisition</title><p>Twelve electrodes (Fp1, Fp2, F3, Fz, F4, C3, Cz, C4, P3, Pz, P4, Oz) from an International 10&#x02013;20 system were used. The vertical EOG (VEOG) signal was recorded from the right eye (2.5 cm below and above the pupil), and the horizontal EOG (HEOG) signal was recorded from the outer canthus. EEG and EOG signals were filtered online with a band pass filter of 0.1&#x02013;30 Hz, and they were digitized at 500 Hz using Neuroscan Synamps. All of the electrodes were referenced to the right earlobe. Electrode impedances did not exceed 2 k<inline-formula><inline-graphic xlink:href="pone.0109700.e001.jpg"/></inline-formula>.</p></sec><sec id="s2c"><title>Experimental Protocol</title><p>The standard three-stimuli protocol <xref rid="pone.0109700-Rosenfeld2" ref-type="bibr">[10]</xref>, <xref rid="pone.0109700-Farwell1" ref-type="bibr">[12]</xref> was employed in this study. The participants were randomly divided into two groups: a guilty group and an innocent group. Six different jewels were prepared, and their pictures served as stimuli during detection. A safe that contained one (for the innocent) or two (for the guilty) jewels was given to each participant. They were instructed to open the safe and memorize the details of the object. We instructed the guilty group to steal only one object which would serve as the P stimulus. The other object in the safe was the T stimulus, and the remaining four pictures were the I stimuli. The object in the safe was not stolen for the innocent, which served as the T stimulus. Then, from the remaining five pictures, one picture was selected randomly and set as the P stimulus, and the remaining four images were set as I stimuli. All of the subjects were instructed to write down the information on the objects in the safe, such as the styles and colors of the jewels.</p><p>After the preparation tasks introduced above, the participants began to perform the detection. They were seated in a chair, facing a video screen that was approximately 1 m away from their eyes. The stimuli pictures were presented randomly on the screen. Each item remained for 0.5 s with 30 iterations for one session, and each session lasted for approximately 5 minutes, with 2 minutes of resting time. The inter-stimulus interval was 1.6 s. Each subject was instructed to perform 5 sessions. The stimuli sequence diagram is given in <xref ref-type="fig" rid="pone-0109700-g001">Figure 1</xref>. One push button was given to each subject, and he or she was asked to press a &#x0201c;Yes&#x0201d; and &#x0201c;No&#x0201d; button when faced with familiar and unknown items, respectively.</p><fig id="pone-0109700-g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g001</object-id><label>Figure 1</label><caption><title>The stimuli sequence diagram.</title></caption><graphic xlink:href="pone.0109700.g001"/></fig><p>The guilty group was instructed to press the &#x0201c;Yes&#x0201d; and &#x0201c;No&#x0201d; button when faced with the T and I stimuli, respectively. With a P stimulus, they were asked to press the &#x0201c;No&#x0201d; button, attempting to hide the stolen act. In contrast, the innocent group made honest responses to all of the stimuli. All of the subjects had practiced the tasks above before the EEG signals were recorded formally. We planned to exclude any subjects that had more than a 5% clicking error, but none fell into this category. Finally, a sketch map is presented and shown in <xref ref-type="fig" rid="pone-0109700-g002">Figure 2</xref> to describe above protocol.</p><fig id="pone-0109700-g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g002</object-id><label>Figure 2</label><caption><title>The sketch map of stimuli protocol.</title><p>The left part and right parts of the dashed line represent the experimental protocol for guilty and innocent subjects, respectively. The pictures with red, blue and green rectangles represents P, T and I stimuli, respectively.</p></caption><graphic xlink:href="pone.0109700.g002"/></fig></sec></sec><sec sec-type="methods" id="s3"><title>Methods</title><sec id="s3a"><title>General description of method</title><p>The present method is separated into the following steps: (1) preprocess the continuous raw EEG recordings, and then, apply SDA on the preprocessed datasets to reconstruct P300 waves that have a higher SNR (from the guilty) and non-P300 waves (from the innocent). For convenience, we hereafter describe the above processed results as reconstructed P300 waves (In fact, the results also contain non-P300 waves); (2) extract original features from the reconstructed waves; (3) adopt the F-score method to select the optimal features; these features were concatenated as a featured vector and fed into three kinds of typical classifiers; (4) train the classifiers using the two classes of training samples, and then, test the samples using testing samples. By the training procedure, the optimal parameter values including the parameter in SDA and in specific classifier can be determined. During a practical application phase, only several stimuli (Five probe stimuli were needed in this study) are presented to the subjects. The flowchart of the presented CIT system is shown in <xref ref-type="fig" rid="pone-0109700-g003">Figure 3</xref>.</p><fig id="pone-0109700-g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g003</object-id><label>Figure 3</label><caption><title>The flowchart of the presented CIT system.</title></caption><graphic xlink:href="pone.0109700.g003"/></fig></sec><sec id="s3b"><title>Preprocessing</title><p>Using EEGLAB toolbox, we segmented the continuous EEG data into epoched datasets, each of which lasted from 0.5 s before to 1.1 s after the stimulus onset. Then, the ocular artifacts <xref rid="pone.0109700-Gao1" ref-type="bibr">[24]</xref> in each set were removed by the software SCAN of Neuroscan, i.e., the datasets that contained single trials with the voltage in excess of <inline-formula><inline-graphic xlink:href="pone.0109700.e002.jpg"/></inline-formula>75<inline-formula><inline-graphic xlink:href="pone.0109700.e003.jpg"/></inline-formula> were discarded. All of the remaining trials were baseline corrected on the pre-stimulus interval. Lastly, the datasets corresponding to P responses were selected, and each 5 datasets within each subject was pooled into one average, resulting in 450 averaged datasets for each subject group.</p></sec><sec id="s3c"><title>Independent component analysis</title><p>Let <bold>X</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e004.jpg"/></inline-formula>)&#x0200a;=&#x0200a;<inline-formula><inline-graphic xlink:href="pone.0109700.e005.jpg"/></inline-formula>denote the observed time series with <inline-formula><inline-graphic xlink:href="pone.0109700.e006.jpg"/></inline-formula> varying from 1 to<inline-formula><inline-graphic xlink:href="pone.0109700.e007.jpg"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="pone.0109700.e008.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0109700.e009.jpg"/></inline-formula>denote the number of samples and sensors, respectively. In ICA method, <bold>X</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e010.jpg"/></inline-formula>) is the result of an unknown mixture of a set of unknown source signals <bold>S</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e011.jpg"/></inline-formula>) &#x0200a;=&#x0200a;<inline-formula><inline-graphic xlink:href="pone.0109700.e012.jpg"/></inline-formula>, and the mixture is viewed as linear: <bold>X</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e013.jpg"/></inline-formula>) &#x0200a;=&#x0200a;<bold>AS</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e014.jpg"/></inline-formula>). Based on the principle of statistical independence <xref rid="pone.0109700-Comon1" ref-type="bibr">[26]</xref>&#x02013;<xref rid="pone.0109700-Makeig1" ref-type="bibr">[27]</xref>, ICA estimates <bold>S</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e015.jpg"/></inline-formula>) by introducing the unmixing matrix <bold>W</bold>, i.e., <bold>Z</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e016.jpg"/></inline-formula>) &#x0200a;=&#x0200a;<bold>WX</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e017.jpg"/></inline-formula>) where <bold>Z</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e018.jpg"/></inline-formula>) (which is the decomposed ICs) is the estimation of signals <bold>S</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e019.jpg"/></inline-formula>). Accordingly, <inline-formula><inline-graphic xlink:href="pone.0109700.e020.jpg"/></inline-formula> is referred to as a mixing matrix. Once the signals <bold>S</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e021.jpg"/></inline-formula>) are estimated by an ICA algorithm, a column of the matrix <inline-formula><inline-graphic xlink:href="pone.0109700.e022.jpg"/></inline-formula> provides the projection strengths of the corresponding IC onto each electrode.</p></sec><sec id="s3d"><title>Spatial denoising algorithm for P300 enhancement</title><p>The spatial denoising algorithm, referred to as SDA hereafter, is described in this section. First, each averaged dataset was decomposed by ICA, resulting in mixing matrix <inline-formula><inline-graphic xlink:href="pone.0109700.e023.jpg"/></inline-formula> and decomposed ICs <bold>Z</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e024.jpg"/></inline-formula>). The extended infomax algorithm (EICA) was used in ICA because it can allow some sources to have sub-Gaussian distributions <xref rid="pone.0109700-Jung3" ref-type="bibr">[28]</xref>, <xref rid="pone.0109700-Lee1" ref-type="bibr">[29]</xref>. By accommodating sub-Gaussian distributions in the data, EICA could provide a more accurate decomposition of multi-channel EEG signals, especially when various neurophysiological signals follow different distributions.</p><p>Many investigators have found that P300 was usually the largest at Pz, the smallest at Fz, and takes intermediate values at Cz <xref rid="pone.0109700-Rosenfeld4" ref-type="bibr">[30]</xref>, <xref rid="pone.0109700-Polich2" ref-type="bibr">[32]</xref>. They typically acquired the P300 on one of the electrodes listed above <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Meijer1" ref-type="bibr">[9]</xref>, <xref rid="pone.0109700-Rosenfeld3" ref-type="bibr">[11]</xref>, <xref rid="pone.0109700-Xu1" ref-type="bibr">[31]</xref>. According to the <italic>a priori</italic> physiological knowledge described above and the spatial distribution of an IC, SDA is divided into the following four steps:</p><list list-type="order"><list-item><p>Let <inline-formula><inline-graphic xlink:href="pone.0109700.e025.jpg"/></inline-formula> denote the <italic>j</italic>th IC in matrix <bold>Z</bold>(<inline-formula><inline-graphic xlink:href="pone.0109700.e026.jpg"/></inline-formula>). Denote the <italic>i</italic>th row <italic>j</italic>th column element in<inline-formula><inline-graphic xlink:href="pone.0109700.e027.jpg"/></inline-formula> by <inline-formula><inline-graphic xlink:href="pone.0109700.e028.jpg"/></inline-formula>, and accordingly the <italic>j</italic>th column by <inline-formula><inline-graphic xlink:href="pone.0109700.e029.jpg"/></inline-formula>. First, each matrix<inline-formula><inline-graphic xlink:href="pone.0109700.e030.jpg"/></inline-formula>is normalized to the matrix <inline-formula><inline-graphic xlink:href="pone.0109700.e031.jpg"/></inline-formula> by</p><p>
<disp-formula id="pone.0109700.e032"><graphic xlink:href="pone.0109700.e032.jpg" position="anchor" orientation="portrait"/><label>(1)</label></disp-formula>where symbol <inline-formula><inline-graphic xlink:href="pone.0109700.e033.jpg"/></inline-formula> denotes an absolute calculation. Let <inline-formula><inline-graphic xlink:href="pone.0109700.e034.jpg"/></inline-formula> denote a new EEG dataset, which was defined by<disp-formula id="pone.0109700.e035"><graphic xlink:href="pone.0109700.e035.jpg" position="anchor" orientation="portrait"/><label>(2)</label></disp-formula>
</p></list-item><list-item><p>Let <italic>Pz</italic>, <italic>P3, P4, Cz</italic> and <italic>Oz</italic> equal their respective sequence number in the electrode set (e.g., <italic>Pz</italic> equals 10 in this study). For the <italic>j</italic>th column in each matrix <bold>U</bold>, we calculate a value <inline-formula><inline-graphic xlink:href="pone.0109700.e036.jpg"/></inline-formula> using the following formula:</p><p>
<disp-formula id="pone.0109700.e037"><graphic xlink:href="pone.0109700.e037.jpg" position="anchor" orientation="portrait"/><label>(3)</label></disp-formula>where the parameters <italic>k1, k2</italic> and <italic>k3</italic> denote the weighted parameters on different element <inline-formula><inline-graphic xlink:href="pone.0109700.e038.jpg"/></inline-formula>. A grid-search procedure (see <xref ref-type="fig" rid="pone-0109700-g003">Figure 3</xref>) would be used to obtain optimal values of these parameters. In this equation, <inline-formula><inline-graphic xlink:href="pone.0109700.e039.jpg"/></inline-formula>denote the integrated distribution-strength on several interested brain areas from <italic>j</italic>th IC. The bigger <inline-formula><inline-graphic xlink:href="pone.0109700.e040.jpg"/></inline-formula> is, the bigger probability <italic>j</italic>th IC is the P300 ICs.</p></list-item><list-item><p>Sort the 14 values in <inline-formula><inline-graphic xlink:href="pone.0109700.e041.jpg"/></inline-formula> in descending order, resulting in a sorted vector <bold>E</bold> and a sorted index vector <inline-formula><inline-graphic xlink:href="pone.0109700.e042.jpg"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="pone.0109700.e043.jpg"/></inline-formula> being the position of the element in vector <bold>S</bold>.</p></list-item><list-item><p>Back projection: Let <italic>m</italic> denote how many P300 ICs should be selected to reconstruct the P300 wave. Suppose that <inline-formula><inline-graphic xlink:href="pone.0109700.e044.jpg"/></inline-formula> is the reconstructed P300 wave on the Pz electrode. The procedure of back projection for <inline-formula><inline-graphic xlink:href="pone.0109700.e045.jpg"/></inline-formula> can be given by</p></list-item></list><p>
<disp-formula id="pone.0109700.e046"><graphic xlink:href="pone.0109700.e046.jpg" position="anchor" orientation="portrait"/><label>(4)</label></disp-formula>i.e., only <italic>m</italic> ICs are considered as P300 ICs and are back projected to the scalp.</p><p>A grid-search procedure (see <xref ref-type="fig" rid="pone-0109700-g003">Figure 3</xref>) will be used to determine the optimal value of parameter <italic>m</italic>, which will be discussed later.</p><p>Lastly, for two groups of subjects, two sets of the reconstructed waves can be obtained, respectively. Let <bold>R&#x02013;G</bold> denote the vector set for the guilty group, and let <bold>R&#x02013;I</bold> denote for the innocent group. We expect that the SNR of P300 in the set <bold>R&#x02013;G</bold> would be enhanced compared with the raw ERP signal, using the above SDA.</p></sec><sec id="s3e"><title>Feature extraction</title><p>Let <inline-formula><inline-graphic xlink:href="pone.0109700.e047.jpg"/></inline-formula> denote a time wave in the set <bold>R&#x02013;G</bold> or <bold>R&#x02013;I</bold>, with <italic>t</italic> varying from stimulus onset to 1.1 s after the stimulus onset. Time-domain, frequency-domain and wavelet features were selected as three groups of features in this study. Most of them have been demonstrated to be effective by many researchers <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>, <xref rid="pone.0109700-Demiralp1" ref-type="bibr">[33]</xref>&#x02013;<xref rid="pone.0109700-Hsu1" ref-type="bibr">[35]</xref>. The features are extracted from each signal <inline-formula><inline-graphic xlink:href="pone.0109700.e048.jpg"/></inline-formula> by the following procedure.</p><sec id="s3e1"><title>Time-domain features</title><p>Four time-domain features are defined as follows:</p><list list-type="order"><list-item><p> Maximum amplitude, which is defined as<disp-formula id="pone.0109700.e049"><graphic xlink:href="pone.0109700.e049.jpg" position="anchor" orientation="portrait"/><label>(5)</label></disp-formula>
</p></list-item><list-item><p>Latency, which is the time where <inline-formula><inline-graphic xlink:href="pone.0109700.e050.jpg"/></inline-formula> occurs. It takes the form<disp-formula id="pone.0109700.e051"><graphic xlink:href="pone.0109700.e051.jpg" position="anchor" orientation="portrait"/><label>(6)</label></disp-formula>
</p></list-item><list-item><p>Peak-to-Peak, which is defined as<disp-formula id="pone.0109700.e052"><graphic xlink:href="pone.0109700.e052.jpg" position="anchor" orientation="portrait"/><label>(7)</label></disp-formula>
</p></list-item><list-item><p>Positive area, which is the sum of the positive signal values. It can be expressed as<disp-formula id="pone.0109700.e053"><graphic xlink:href="pone.0109700.e053.jpg" position="anchor" orientation="portrait"/><label>(8)</label></disp-formula>
</p></list-item></list></sec><sec id="s3e2"><title>Frequency-domain features.</title><p>The power spectrum density (PSD) is <italic>first</italic> calculated on each <inline-formula><inline-graphic xlink:href="pone.0109700.e054.jpg"/></inline-formula> by the Bartlett algorithm. Let <inline-formula><inline-graphic xlink:href="pone.0109700.e055.jpg"/></inline-formula> be the resultant PSD. Suppose that <inline-formula><inline-graphic xlink:href="pone.0109700.e056.jpg"/></inline-formula> denotes the maximum amplitude value of the PSD. Then 3 frequency-domain features can be calculated as follows:</p><list list-type="order"><list-item><p>Maximum frequency, i.e.,<disp-formula id="pone.0109700.e057"><graphic xlink:href="pone.0109700.e057.jpg" position="anchor" orientation="portrait"/><label>(9)</label></disp-formula>
</p></list-item><list-item><p>Mean frequency, calculated by the weighted average of the frequency. The weighted coefficient is the PSD value. It can be expressed as<disp-formula id="pone.0109700.e058"><graphic xlink:href="pone.0109700.e058.jpg" position="anchor" orientation="portrait"/><label>(10)</label></disp-formula>
</p></list-item><list-item><p>The power of the main frequency band that involves the P300, which is calculated by</p></list-item></list><disp-formula id="pone.0109700.e059"><graphic xlink:href="pone.0109700.e059.jpg" position="anchor" orientation="portrait"/><label>(11)</label></disp-formula></sec><sec id="s3e3"><title>Wavelet features</title><p>Many authors have indicated that ERPs are transient signals that include some typical frequency components in a different frequency range, such as delta, theta, alpha, beta and gamma <xref rid="pone.0109700-Herrmann1" ref-type="bibr">[36]</xref>. Recently, the wavelet transform (WT) has been widely used to analyze ERPs <xref rid="pone.0109700-Herrmann1" ref-type="bibr">[36]</xref>&#x02013;<xref rid="pone.0109700-Mrzagora1" ref-type="bibr">[38]</xref>. The WT is achieved by the breaking up of a signal into shifted and scaled versions of the mother wavelet, which is a waveform that has a limited duration and a zero mean.</p><p>In this study, a fast algorithm for the Discrete WT (DWT) was adopted to decompose those averaged single trials <xref rid="pone.0109700-Ademoglu1" ref-type="bibr">[39]</xref>. We selected Quadratic B-Spline functions as mother wavelets because they have a near-optimal time-frequency localization property and good similarity with the P300 components <xref rid="pone.0109700-Unser1" ref-type="bibr">[40]</xref>&#x02013;<xref rid="pone.0109700-Quiroga1" ref-type="bibr">[41]</xref>. The wavelet coefficients were computed by a high-pass filter <bold>h</bold> and a low-pass filter <bold>g</bold>. The coefficients of two filters are given in the first and second columns of <xref ref-type="table" rid="pone-0109700-t001">Table 1</xref>, respectively. The reconstruction filters <bold>H</bold> and <bold>G</bold> can be used to inversely transform the wavelet coefficients to time-domain waveforms. The third and fourth columns of <xref ref-type="table" rid="pone-0109700-t001">Table 1</xref> give the coefficients of the two reconstruction filters, respectively.</p><table-wrap id="pone-0109700-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.t001</object-id><label>Table 1</label><caption><title>Coefficients of the truncated decomposition filters <italic>h</italic>, <italic>g</italic> (IIR) and reconstruction filters H, G (FIR) for quadratic spline filters.</title></caption><alternatives><graphic id="pone-0109700-t001-1" xlink:href="pone.0109700.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">
<italic>e</italic>
</td><td align="left" rowspan="1" colspan="1">
<italic>h(e)</italic>
</td><td align="left" rowspan="1" colspan="1">
<italic>g(e)</italic>
</td><td align="left" rowspan="1" colspan="1">
<italic>H(e)</italic>
</td><td align="left" rowspan="1" colspan="1">
<italic>G(e)</italic>
</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">&#x02212;10</td><td align="left" rowspan="1" colspan="1">+0.00157</td><td align="left" rowspan="1" colspan="1">&#x02212;0.00388</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;9</td><td align="left" rowspan="1" colspan="1">+0.01909</td><td align="left" rowspan="1" colspan="1">&#x02212;0.03416</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;8</td><td align="left" rowspan="1" colspan="1">&#x02212;0.00503</td><td align="left" rowspan="1" colspan="1">+0.00901</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;7</td><td align="left" rowspan="1" colspan="1">&#x02212;0.04440</td><td align="left" rowspan="1" colspan="1">+0.07933</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;6</td><td align="left" rowspan="1" colspan="1">+0.01165</td><td align="left" rowspan="1" colspan="1">&#x02212;0.02096</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;5</td><td align="left" rowspan="1" colspan="1">+0.10328</td><td align="left" rowspan="1" colspan="1">&#x02212;0.18408</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;4</td><td align="left" rowspan="1" colspan="1">&#x02212;0.02593</td><td align="left" rowspan="1" colspan="1">+0.04977</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">+1/480</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;3</td><td align="left" rowspan="1" colspan="1">&#x02212;0.24373</td><td align="left" rowspan="1" colspan="1">+0.42390</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">&#x02212;29/480</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;2</td><td align="left" rowspan="1" colspan="1">+0.03398</td><td align="left" rowspan="1" colspan="1">&#x02212;0.14034</td><td align="left" rowspan="1" colspan="1">0.25</td><td align="left" rowspan="1" colspan="1">+147/480</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x02212;1</td><td align="left" rowspan="1" colspan="1">+0.65523</td><td align="left" rowspan="1" colspan="1">&#x02212;0.90044</td><td align="left" rowspan="1" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">&#x02212;303/480</td></tr><tr><td align="left" rowspan="1" colspan="1">0</td><td align="left" rowspan="1" colspan="1">+0.65523</td><td align="left" rowspan="1" colspan="1">+0.90044</td><td align="left" rowspan="1" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">+303/480</td></tr><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">+0.03398</td><td align="left" rowspan="1" colspan="1">+0.14034</td><td align="left" rowspan="1" colspan="1">0.25</td><td align="left" rowspan="1" colspan="1">&#x02212;147/480</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">&#x02212;0.24373</td><td align="left" rowspan="1" colspan="1">&#x02212;0.42390</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">+29/480</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">&#x02212;0.02593</td><td align="left" rowspan="1" colspan="1">&#x02212;0.04977</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">&#x02212;1/480</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">+0.10328</td><td align="left" rowspan="1" colspan="1">+0.18408</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">+0.01165</td><td align="left" rowspan="1" colspan="1">+0.02096</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">&#x02212;0.04440</td><td align="left" rowspan="1" colspan="1">&#x02212;0.07933</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">&#x02212;0.00503</td><td align="left" rowspan="1" colspan="1">&#x02212;0.00901</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">+0.01909</td><td align="left" rowspan="1" colspan="1">+0.03416</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">9</td><td align="left" rowspan="1" colspan="1">+0.00157</td><td align="left" rowspan="1" colspan="1">+0.00388</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr></tbody></table></alternatives></table-wrap><p>DWT was performed on each wave <inline-formula><inline-graphic xlink:href="pone.0109700.e060.jpg"/></inline-formula>, which resulted in seven sets of wavelet coefficients corresponding to different frequency bands: 0.3&#x02013;3.9, 3.9&#x02013;7.8, 7.8&#x02013;15.6, 15.6&#x02013;31.2, 31.2&#x02013;62.5, 62.5&#x02013;125 and 125&#x02013;250 Hz. Only the first four bands were useful due to the earlier filtering. Because the <italic>delta</italic> band was the main frequency range for the P300 component, the coefficient set corresponding to the first frequency band was selected as the final wavelet features for each wave <inline-formula><inline-graphic xlink:href="pone.0109700.e061.jpg"/></inline-formula>.</p><p>Following the feature extraction, these feature samples were divided into two sample sets: the first set contained all of the <italic>P300 samples</italic> for the guilty group, and the second set contained <italic>non-P300 samples</italic> for the innocent group, with the class label being 1 and &#x02212;1, respectively.</p></sec></sec><sec id="s3f"><title>Feature Selection</title><p>In this study, we adopted the F-score method to further select the best subset of features for classification. The F-score method is a very simple but robust feature-evaluating technique. Recently, many researchers have successfully used this method in pattern recognition systems to select the optimal feature subset <xref rid="pone.0109700-Chen1" ref-type="bibr">[42]</xref>, <xref rid="pone.0109700-Polat1" ref-type="bibr">[43]</xref>.</p><p>Given the <italic>i</italic>th feature vector <inline-formula><inline-graphic xlink:href="pone.0109700.e062.jpg"/></inline-formula> with the number of positive instances <italic>n<sub>+</sub></italic> and the number of all of the instances <italic>B</italic>, the <italic>F-score</italic> value of the <italic>i</italic>th feature is defined by</p><p>
<disp-formula id="pone.0109700.e063"><graphic xlink:href="pone.0109700.e063.jpg" position="anchor" orientation="portrait"/><label>(12)</label></disp-formula>
</p><p>where <inline-formula><inline-graphic xlink:href="pone.0109700.e064.jpg"/></inline-formula> are the average of the positive, negative, and whole samples, respectively, and <inline-formula><inline-graphic xlink:href="pone.0109700.e065.jpg"/></inline-formula> is the <italic>k</italic>th feature value in the <italic>i</italic>th feature vector. Positive and negative represent two classes of identification, respectively. A larger <italic>F-score</italic> value indicates that the feature has more discriminative power. For the application of this method, the <italic>F-score</italic> value of all of the features will be sorted. Hence, in this study, those features that have relatively larger F-score values were selected to construct the feature subset.</p><p>There are two main methods used to select the appropriate feature subset: the filter method <xref rid="pone.0109700-Jouve1" ref-type="bibr">[44]</xref> and the wrapper method <xref rid="pone.0109700-Kohavi1" ref-type="bibr">[45]</xref>, <xref rid="pone.0109700-Huang1" ref-type="bibr">[46]</xref>. To obtain simplicity and a lower computation cost, we used the former method to select the feature number for the optimal feature subset.</p></sec><sec id="s3g"><title>Classification</title><p>The fisher discriminant analysis (FDA) <xref rid="pone.0109700-Chiang1" ref-type="bibr">[47]</xref>, back propagation neural network (BPNN) <xref rid="pone.0109700-Tarassenko1" ref-type="bibr">[48]</xref> and support vector machine (SVM) <xref rid="pone.0109700-Kaper1" ref-type="bibr">[49]</xref>, <xref rid="pone.0109700-Shoker1" ref-type="bibr">[50]</xref> were compared in this study to select an optimal classifier. The details of the three classifiers are given in Supporting information files (see Section S1&#x02013;S3 in <xref ref-type="supplementary-material" rid="pone.0109700.s001">File S1</xref>). The hybrid models integrating with F-score feature selection is referred to as F-score_FDA, F-score_BPNN and F-score_SVM in this study. Accordingly, three individual classification models (FDA, BPNN and SVM) were also utilized.</p><p>A Subject-Wise CV (SWCV) <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>, <xref rid="pone.0109700-Shao1" ref-type="bibr">[51]</xref> was performed on the two classes of optimal feature sample sets. For each set, samples from 14 subjects were grouped into a training set and the samples from the remaining were used as a testing set. Thus by this SWCV, 15 pairs of training sets and testing sets were obtained. For each pair, the training set consisted of the samples from 28 subjects, and the testing set from 2 subjects (i.e., a guilty and an innocent subject). We would like to emphasize the importance of the SWCV procedure. In fact, a statistical classification model that could explain the data for some subjects did not necessarily generalize well to other subjects, even if those were draw from the same distribution. Accordingly, the SWCV procedure was used to assess the generalization ability not only from the different data within one subject but from the data in different subjects. Hence, the advantage of SWCV compared with common CV is that the test accuracy can simulate the generalization performance on other unseen subjects. Accordingly, we can obtain the testing results not only on the level of single-trials, but also on the level of subjects, i.e., to test whether one subject can be recognized correctly.</p><p>For each training set yielding by SWCV, the feature samples were mixed to obtain two classes of samples: one is lying group (it was considered as P300 feature samples) and the other is truth-telling group (it was considered as non-P300 feature samples). Subsequently, a common 10-fold CV procedure <xref rid="pone.0109700-Burges1" ref-type="bibr">[52]</xref> was performed on each training set, resulting in 10 pairs of sub-training sets and sub-validation sets. <xref ref-type="fig" rid="pone-0109700-g004">Figure 4</xref> shows the schematic diagram of the division of samples and cross validation procedure.</p><fig id="pone-0109700-g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g004</object-id><label>Figure 4</label><caption><title>The division of feature samples using SWCV and 10-fold CV.</title><p>The red rectangle denotes training set, whereas the green rectangle denotes testing set by the division of SWCV; Training set is further divided into sub-training set and sub-validation set by common 10-fold CV.</p></caption><graphic xlink:href="pone.0109700.g004"/></fig></sec><sec id="s3h"><title>Selection of optimal parameters</title><p>For the proposed lie detection method, two groups of parameters must be tuned: 1) The parameters in SDA: <italic>m</italic>, <italic>k1</italic>, <italic>k2</italic> and <italic>k3</italic>, and 2) The specific hyperparameters for each classifier. Considering that the parameters in SDA can affect the optimal values of the hyperparameters, the two groups of parameters were tuned together using a multi-dimension grid searching. During the turning, <italic>m varied</italic> from 1 to 14; and <italic>k1</italic>, <italic>k2</italic> and <italic>k3</italic> varied from 0.2 to 1 with a step size of 0.15, by the suggestion of an independent EEG expert. In the tuning procedure above, for BPNN, the number of sigmoid hidden nodes <inline-formula><inline-graphic xlink:href="pone.0109700.e066.jpg"/></inline-formula> and the learning rate <inline-formula><inline-graphic xlink:href="pone.0109700.e067.jpg"/></inline-formula> were tuned (the control precision was set to be 0.002). For SVM, the penalty parameter <italic>C</italic> and the radial width <inline-formula><inline-graphic xlink:href="pone.0109700.e068.jpg"/></inline-formula>for radial basis function (RBF) (<inline-formula><inline-graphic xlink:href="pone.0109700.e069.jpg"/></inline-formula>, <xref rid="pone.0109700-Burges1" ref-type="bibr">[52]</xref>) were tuned. The procedure of training and testing is described as follows:</p><list list-type="order"><list-item><p>The classifiers were trained on each sub-training set with different combinations of tuning parameters. By the 10-fold CV, an averaged sensitivity and an averaged specificity can be obtained for the <italic>j</italic>th training set. Then, the <italic>mean</italic> and <italic>Standard Deviation</italic> (<italic>SD</italic>) of the 15 sensitivities (15 training sets), referred to as <inline-formula><inline-graphic xlink:href="pone.0109700.e070.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0109700.e071.jpg"/></inline-formula> respectively, are calculated. Similarly, the <inline-formula><inline-graphic xlink:href="pone.0109700.e072.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0109700.e073.jpg"/></inline-formula> for specificity are obtained. Lastly, <italic>balanced accuracy</italic>
<inline-formula><inline-graphic xlink:href="pone.0109700.e074.jpg"/></inline-formula> is calculated for the specific combination of tuning parameters.</p></list-item><list-item><p>Repeat the above steps using a different combination of tuning parameters. Thus, the optimal parameter values were selected when <inline-formula><inline-graphic xlink:href="pone.0109700.e075.jpg"/></inline-formula> reached the highest value.</p></list-item><list-item><p>On the 15 testing sets, calculate the generalization performance of the trained classifiers with the optimal parameter values. Similar to step 1, <inline-formula><inline-graphic xlink:href="pone.0109700.e076.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0109700.e077.jpg"/></inline-formula> (<italic>mean</italic> and <italic>SD</italic> on the 15 sensitivities), <inline-formula><inline-graphic xlink:href="pone.0109700.e078.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0109700.e079.jpg"/></inline-formula> (on the 15 sensitivities) can be obtained. Finally, calculate the balanced testing accuracy<inline-formula><inline-graphic xlink:href="pone.0109700.e080.jpg"/></inline-formula>. This accuracy is the final testing measure of the performance evaluation.</p></list-item></list></sec></sec><sec id="s4"><title>Results</title><sec id="s4a"><title>Preprocessing</title><p>The grand average ERPs on the Fz, Cz, Pz and Oz sites as a function of stimulus type were first calculated within each subject. <xref ref-type="fig" rid="pone-0109700-g005">Figure 5</xref> gives the boxplot of the maximum amplitude at the Pz site for three types of stimuli and the two subject groups, during which 450 samples for each type of stimuli and each group were used to statistical analysis. Using ANOVA on the guilty subject, there is no significant difference (<italic>p</italic>&#x0003e;0.05) for the maximum amplitude between the P and T stimuli. However, there is a significant difference (<italic>p</italic>&#x0003c;0.001) between P and I stimuli. In contrast, there is no significant difference (<italic>p</italic>&#x0003e;0.05) between the P and I stimuli for an innocent subject.</p><fig id="pone-0109700-g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g005</object-id><label>Figure 5</label><caption><title>Boxplot of the maximum amplitude of P300 at Pz in different stimuli and subject groups.</title></caption><graphic xlink:href="pone.0109700.g005"/></fig><p>A <inline-formula><inline-graphic xlink:href="pone.0109700.e081.jpg"/></inline-formula> mixed model ANOVA (P vs. I <inline-formula><inline-graphic xlink:href="pone.0109700.e082.jpg"/></inline-formula> innocent vs. guilty) was performed on the maximum amplitude at the Pz site. The result shown in <xref ref-type="fig" rid="pone-0109700-g006">Figure 6</xref> revealed significant main effect of innocent versus guilty, <italic>F</italic>(1, 28)&#x0200a;=&#x0200a;772.467, <italic>p</italic>&#x0003c;.0005 and P versus I, <italic>F</italic>(1, 28)&#x0200a;=&#x0200a;761.201, <italic>p</italic>&#x0003c;.005. There is also significant interaction between innocent versus guilty and P versus I, <italic>F</italic>(1, 28)&#x0200a;=&#x0200a;753.430, <italic>p</italic>&#x0003c;.005.</p><fig id="pone-0109700-g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g006</object-id><label>Figure 6</label><caption><title>Maximum P300 amplitude at Pz as functions of person type (guilty and innocent) and stimuli type.</title></caption><graphic xlink:href="pone.0109700.g006"/></fig><p>More importantly, by a further independent effect analysis of innocent versus guilty when P stimuli was used, the person type effect is significant and yields <italic>F</italic>(1,28)&#x0200a;=&#x0200a;1514.68, <italic>p</italic>&#x0003c;.0005. The amplitude of P300 for the guilty is higher than that for the innocent. In contrast, when using I stimuli, there is no significant person effect (<italic>F</italic>&#x0003c;1). Hence, P responses at the Pz site were finally selected for further processing to enhance the feature difference of the P300 waves between the two classes of subjects.</p></sec><sec id="s4b"><title>SDA</title><p>First, the enhancement of the SNR of P300 by SDA is illustrated in <xref ref-type="fig" rid="pone-0109700-g007">Figure 7</xref>. A guilty subject's five raw EEG datasets were randomly taken as an example. The raw waves on the Pz with solid thin line and their averaged wave with dashed thick lines are shown in <xref ref-type="fig" rid="pone-0109700-g007">Figure 7A</xref>. Similarly, we randomly selected an innocent subject, and the raw waves and averaged wave on Pz are shown in <xref ref-type="fig" rid="pone-0109700-g007">Figure 7B</xref>. Applying SDA to the two averaged datasets respectively, the two reconstructed P300 waveforms on Pz are shown in <xref ref-type="fig" rid="pone-0109700-g007">Figure 7C</xref>. There is no distinct P300 (dashed lines) in <xref ref-type="fig" rid="pone-0109700-g007">Figure 7A and 7B</xref>. As <xref ref-type="fig" rid="pone-0109700-g007">Figure 7C</xref> shows, however, there is a clear P300 with a latency of approximately 280 ms for the guilty subject, and the two lines can be differentiated easily. During this evaluation, the parameters <italic>m</italic>, <italic>k1</italic>, <italic>k2</italic> and <italic>k3</italic> were set to 3, 0.9, 0.8, 0.6 by <italic>a priori</italic> knowledge of an independent physiology expert.</p><fig id="pone-0109700-g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g007</object-id><label>Figure 7</label><caption><title>Response waveforms and reconstructed waveforms on Pz after applying SDA for a guilty and an innocent subject.</title><p>7A: Single trials (solid lines) and averaged waveform (dashed line) on Pz for a guilty subject before applying SDA. 7B: Single trials (solid lines) and averaged waveform (dashed line) on Pz for a guilty subject before applying SDA. 7C: Reconstructed waveforms (a P300 for the guilty subject and a non-P300 for the innocent subject) by applying SDA on the averaged datasets.</p></caption><graphic xlink:href="pone.0109700.g007"/></fig></sec><sec id="s4c"><title>Extraction of Wavelet Features</title><p>After SDA, the features were extracted from the reconstructed waves for the Pz. Here, we randomly selected a guilty and an innocent subject, and then conducted the wavelet transform on two subjects' denoised P300 signals, respectively. The results of DWT are shown in <xref ref-type="fig" rid="pone-0109700-g008">Figure 8A and 8B</xref> respectively. The most distinct difference in the wavelet features and reconstruction waves between the two subjects is in the 0.3&#x02013;3.9 Hz band (the delta band). For the guilty subject, it can be seen from the bottom row in <xref ref-type="fig" rid="pone-0109700-g008">Figure 8A</xref> that there are obvious peaks in the wavelet coefficients and reconstruction waves at approximately 500 ms post-stimulus for this band. This approach is in accordance with the time-domain features of the P300 waveform. In contrast, there are no obviously corresponding features in <xref ref-type="fig" rid="pone-0109700-g008">Figure 8B</xref>. The results above suggest that the wavelet coefficients corresponding to the delta band, as a class of P300 features, are suitable for differentiating the P responses between the two groups of subjects.</p><fig id="pone-0109700-g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g008</object-id><label>Figure 8</label><caption><title>The wavelet coefficients in 4 bands and corresponding reconstructed waveforms.</title><p>8A: The original EEG waveforms on Pz for a guilty subject (above panel), its wavelet coefficients (left column) and corresponding reconstruction waves (right column). 8B: The original EEG waveforms on Pz for an innocent subject (above panel), its wavelet coefficients (left column) and corresponding reconstruction waves (right column).</p></caption><graphic xlink:href="pone.0109700.g008"/></fig></sec><sec id="s4d"><title>Result of the feature selection</title><p>
<xref ref-type="table" rid="pone-0109700-t002">Table 2</xref> shows the results of the feature selection by the F-score method. <italic>W<sub>1</sub></italic>&#x02013;<italic>W<sub>22</sub></italic> denotes 22 WT coefficients. From this table, we can see the <italic>F-score</italic> values of the 29 original features. Those features with relatively larger <italic>F-score</italic> values were selected to construct a feature subset. For simplicity, we directly selected 10 features whose <italic>F-score</italic> values were larger than 0.85 to form the optimal feature subset.</p><table-wrap id="pone-0109700-t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.t002</object-id><label>Table 2</label><caption><title>The results of feature selection on original 29 features using F-score.</title></caption><alternatives><graphic id="pone-0109700-t002-2" xlink:href="pone.0109700.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Features</td><td align="left" rowspan="1" colspan="1">
<italic>F-score</italic> values</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">
<italic>V</italic>
<sub>max</sub>
</td><td align="left" rowspan="1" colspan="1">0.937</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>t</italic>
<sub>max</sub>
</td><td align="left" rowspan="1" colspan="1">0.567</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>V</italic>
<sub>ptp</sub>
</td><td align="left" rowspan="1" colspan="1">0.877</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>A</italic>
<sub>p</sub>
</td><td align="left" rowspan="1" colspan="1">0.268</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>f</italic>
<sub>max</sub>
</td><td align="left" rowspan="1" colspan="1">0.049</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>f</italic>
<sub>mean</sub>
</td><td align="left" rowspan="1" colspan="1">0.340</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>A</italic>
<sub>lf</sub>
</td><td align="left" rowspan="1" colspan="1">0.873</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>W</italic>
<sub>1</sub>&#x02013;<italic>W</italic>
<sub>5</sub>
</td><td align="left" rowspan="1" colspan="1">0.085, 0.005, 0.311, 0.011, 0.099</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>W</italic>
<sub>6</sub>&#x02013;<italic>W</italic>
<sub>10</sub>
</td><td align="left" rowspan="1" colspan="1">0.008, 0.184, 0.106, 0.077, 0.381</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>W</italic>
<sub>11</sub>&#x02013;<italic>W</italic>
<sub>16</sub>
</td><td align="left" rowspan="1" colspan="1">0.977, 0.524, 0.255, 0.835, 0.820, 0.947</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>W</italic>
<sub>17</sub>&#x02013;<italic>W</italic>
<sub>22</sub>
</td><td align="left" rowspan="1" colspan="1">0.905, 0.937, 0.881, 0.959, 0.871, 0.838</td></tr></tbody></table></alternatives></table-wrap><p>Observing these 10 features, we can see that two optimal time-domain features are closely related to the peak value of P300. Second, one feature (A<sub>lf</sub>) is related to the main frequency range of P300 (0.3&#x02013;3.9 Hz). Most importantly, the most of optimal features are selected from the original wavelet features. This indicates the wavelet feature has the better classification capability than the other two kinds of features.</p></sec><sec id="s4e"><title>Classification Performance</title><p>Using SWCV, <inline-formula><inline-graphic xlink:href="pone.0109700.e083.jpg"/></inline-formula> reaches the highest value, 96.18%, using the F-score_SVM, and the optimal parameters of <italic>m</italic>, <italic>k1</italic>, <italic>k2</italic>, <italic>k3</italic>, which are determined by grid searching, are as follows: <italic>m</italic>&#x0200a;=&#x0200a;2, <italic>k1&#x0200a;=&#x0200a;</italic>0.85, <italic>k2&#x0200a;=&#x0200a;</italic>0.70 and <italic>k3</italic>&#x0200a;=&#x0200a;0.40. The training accuracies as a function of the parameter <italic>m</italic> were shown in <xref ref-type="fig" rid="pone-0109700-g009">Figure 9A and 9B</xref> for the three hybrid models when <italic>k1&#x0200a;=&#x0200a;</italic>0.85, <italic>k2&#x0200a;=&#x0200a;</italic>0.70 and <italic>k3</italic>&#x0200a;=&#x0200a;0.40. As shown in <xref ref-type="fig" rid="pone-0109700-g009">Figure 9</xref>, the accuracy rates increase significantly when <italic>m</italic> changes from 1 to 2 for all of the models. For example, the increased rate for F-score_SVM is approximately 5%. In addition, the accuracies of F-score_FDA and F-score_SVM reach a maximum when <italic>m</italic>&#x0200a;=&#x0200a;2 except for F-score_BPNN, whose accuracy still increases slightly as <italic>m</italic> varies from 2 to 3. More importantly, the accuracy rates decrease when more than 3 ICs are used in SDA. This result is basically consistent with the report of Lin et al. <xref rid="pone.0109700-Lin1" ref-type="bibr">[53]</xref>. Note that the accuracies with <italic>m</italic>&#x0200a;=&#x0200a;14 denote the performance without the SDA. For every classification model, those accuracies are distinctly much lower than those when <italic>m</italic>&#x0200a;=&#x0200a;2. The results discussed above indicate the remarkable performance of SDA.</p><fig id="pone-0109700-g009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g009</object-id><label>Figure 9</label><caption><title>The accuracy (mean</title><p>
<inline-formula><inline-graphic xlink:href="pone.0109700.e084.jpg"/></inline-formula>
<bold>SD) of classifying P300 (sensitivity) and non-P300 (specificity) for three classification models with different parameter value </bold>
<bold><italic>m</italic></bold>
<bold> on training sets (when </bold>
<bold><italic>k1&#x0200a;=&#x0200a;</italic></bold>
<bold>0.85, </bold>
<bold><italic>k2&#x0200a;=&#x0200a;</italic></bold>
<bold>0.70 and </bold>
<bold><italic>k3</italic></bold>
<bold>&#x0200a;=&#x0200a;0.40).</bold> 9A: Sensitivity for the training sets. 9B: Specificity for the training sets.</p></caption><graphic xlink:href="pone.0109700.g009"/></fig><p>Furthermore, <xref ref-type="table" rid="pone-0109700-t003">Table 3</xref> gives the training accuracies (<inline-formula><inline-graphic xlink:href="pone.0109700.e085.jpg"/></inline-formula>,<inline-formula><inline-graphic xlink:href="pone.0109700.e086.jpg"/></inline-formula>) and testing accuracies (<inline-formula><inline-graphic xlink:href="pone.0109700.e087.jpg"/></inline-formula>,<inline-formula><inline-graphic xlink:href="pone.0109700.e088.jpg"/></inline-formula>) of the six classification models with the optimal grid searching result. First, the accuracy of the model using FDA is obviously lower than the models using BPNN and SVM. This finding suggests that the data from the two types of subjects in the lie detection cannot be separated linearly. Additionally, the performance of the models that use SVM significantly exceeds those of the models that use FDA and BPNN. Using ANOVA, the statistical results (<italic>F</italic>(1, 28) &#x0200a;=&#x0200a;7396.689 and p&#x0003c;0.001) confirm that the testing accuracy for SVM is significantly greater than that for BPNN. The <italic>BA_test</italic> of 96.08% for F-score_SVM strongly suggests that it is suitable for the classification of the two classes of subjects. Additionally, we can see from <xref ref-type="table" rid="pone-0109700-t003">Table 3</xref> that each hybrid model achieves significantly higher accuracy than the corresponding individual model. For example, on the training sets, SVM reaches a sensitivity and specificity of 91% and 90.98%, respectively. In contrast, F-score_SVM obtains 96.07% and 96.30%, respectively. Based on the above experimental results, the model F-score_SVM reaches the highest classification performance of all of the models.</p><table-wrap id="pone-0109700-t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.t003</object-id><label>Table 3</label><caption><title>Sensitivity/specificity on the training and testing sets for different classification models with the optimal parameter combination.</title></caption><alternatives><graphic id="pone-0109700-t003-3" xlink:href="pone.0109700.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Classifier models</td><td colspan="2" align="left" rowspan="1">Sensitivity/specificity (%)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Training (<inline-formula><inline-graphic xlink:href="pone.0109700.e089.jpg"/></inline-formula>)</td><td align="left" rowspan="1" colspan="1">Testing (<inline-formula><inline-graphic xlink:href="pone.0109700.e090.jpg"/></inline-formula>)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">FDA</td><td align="left" rowspan="1" colspan="1">68.38&#x000b1;2.13/67.22&#x000b1;1.94</td><td align="left" rowspan="1" colspan="1">FDA</td></tr><tr><td align="left" rowspan="1" colspan="1">BPNN</td><td align="left" rowspan="1" colspan="1">79.27&#x000b1;1.66/78.78&#x000b1;1.72</td><td align="left" rowspan="1" colspan="1">BPNN</td></tr><tr><td align="left" rowspan="1" colspan="1">SVM</td><td align="left" rowspan="1" colspan="1">91.00&#x000b1;1.80/90.98&#x000b1;1.85</td><td align="left" rowspan="1" colspan="1">SVM</td></tr><tr><td align="left" rowspan="1" colspan="1">F-score_FDA</td><td align="left" rowspan="1" colspan="1">74.65&#x000b1;1.57/74.19&#x000b1;1.70(<sup>&#x025b4;</sup>)</td><td align="left" rowspan="1" colspan="1">F-score_FDA</td></tr><tr><td align="left" rowspan="1" colspan="1">F-score_ BPNN</td><td align="left" rowspan="1" colspan="1">85.97&#x000b1;1.60/85.60&#x000b1;1.66(*)</td><td align="left" rowspan="1" colspan="1">F-score_ BPNN</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>&#x0201c;&#x025b4;&#x0201d; denotes that a p-value of &#x0003c;0.001 was obtained by ANOVA between F-score_FDA and F-score_SVM; &#x0201c;<bold>*</bold>&#x0201d; denotes that a p-value of &#x0003c;0.001 was obtained by ANOVA between F-score_BPNN and F-score_SVM; for BPNN, the number of hidden nodes<inline-formula><inline-graphic xlink:href="pone.0109700.e091.jpg"/></inline-formula>&#x0200a;=&#x0200a;5, and the learning rate <inline-formula><inline-graphic xlink:href="pone.0109700.e092.jpg"/></inline-formula> &#x0200a;=&#x0200a;0.03; for SVM, radial<inline-formula><inline-graphic xlink:href="pone.0109700.e093.jpg"/></inline-formula>&#x0200a;=&#x0200a; 32, and penalty parameter <italic>C</italic>&#x0200a;=&#x0200a;2<sup>8</sup>.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s4f"><title>Comparison with previous methods</title><p>The individual diagnostic rates of the presented and previous methods were calculated, and they were compared in this section. In the BAD/BCD method, each 10 waveforms of each type of response on the Pz electrode were selected to average into a waveform, based on the technique of bootstrapping. In the BAD method, the P300 amplitudes of the three types of responses were calculated based on the Peak-to-Peak method <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Abootalebi2" ref-type="bibr">[13]</xref>, <xref rid="pone.0109700-Soskins1" ref-type="bibr">[54]</xref>. For the BCD method, the time lag was equal to 0 when the CV was calculated.</p><p>For the BAD and BCD methods, we calculated 100 <italic>D-</italic>values obtained by 100 iterations for each subject. Let <inline-formula><inline-graphic xlink:href="pone.0109700.e094.jpg"/></inline-formula> denote the times when the <italic>D-</italic>values were larger than zero. Then <inline-formula><inline-graphic xlink:href="pone.0109700.e095.jpg"/></inline-formula> and the percentage of <inline-formula><inline-graphic xlink:href="pone.0109700.e096.jpg"/></inline-formula> were calculated for each subject, respectively. If the percentage of <inline-formula><inline-graphic xlink:href="pone.0109700.e097.jpg"/></inline-formula> was greater than a threshold <inline-formula><inline-graphic xlink:href="pone.0109700.e098.jpg"/></inline-formula>, then this subject would be considered to be a guilty subject <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Farwell1" ref-type="bibr">[12]</xref>. Lastly, the error rates of an individual diagnosis as a function of the setting threshold are shown in <xref ref-type="fig" rid="pone-0109700-g010">Figure 10A and 10B</xref>, respectively. Considering the equal importance of the detection rates of the two groups of subjects, the individual diagnostic rates of 92% and 88.71% are reached when the thresholds are set to 83.6% and 85.5% for the BAD and BCD methods, respectively.</p><fig id="pone-0109700-g010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0109700.g010</object-id><label>Figure 10</label><caption><title>The detection error rates of two groups of subjects.</title><p>10A: The detection error rate of the guilty and innocent groups for BAD method. 10B: The detection error rate of the guilty and innocent groups for BCD method.</p></caption><graphic xlink:href="pone.0109700.g010"/></fig><p>Based on the results in the above section, for our method, in fact, the individual diagnostic rate can reach 100% when choosing the test accuracy of 90% as a decision criterion for a subject. That is, one was identified as a liar when the percentage of reconstructed samples classified as P300 was larger than 90%. In contrast, one was a truth-teller if the percentage of reconstructed samples classified as <italic>non-P300</italic> was larger than 90%. Obviously, this diagnostic rate is higher than the rates of the BAD and BCD methods, and is also higher than those reported using other machine learning-based methods. For example, Abootalebi et al. <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref> reported that the best detection rates are 74%, 80% and 79% for BAD, BCD and the machine learning methods, respectively.</p></sec></sec><sec id="s5"><title>Discussion and conclusions</title><p>Lie detection methods using a large number of stimuli suffer from several inherent drawbacks such as more fatigue for subjects, more workload for examiners, increased probability of countermeasure behavior and lower flexibility <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>, <xref rid="pone.0109700-Gao3" ref-type="bibr">[55]</xref>. Obviously, a lie detection method with only a small number of stimuli will be crucial for practical lie detection. The purpose of this study is to develop a novel detection method that uses several stimuli to identify the liars, and at the same time, to further increase the individual diagnostic rate and robustness compared to previous studies. For this purpose, we proposed a novel ICA-based SDA to enhance the SNR of P300, and then, we used a machine learning method to distinguish the P300 evoked by guilty subjects from the non-P300 in innocent subjects.</p><p>Some recent studies suggested that machine learning-based lie detection methods are more reliable than the BAD and BCD methods. One advantage is that the investigation of the dynamic variation of single trials might help us to study more cognitive information on lying. The second major advantage lies in that the failure of one trial will not affect the classification results of the other trials. In contrast, for BAD and BCD, the failure will change many bootstrapping averages and hence, the overall result of the lie detection <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>. Third, one can utilize more features of P300 in addition to the time-domain features that are used in the BAD/BCD method. Lastly, note that, in previous methods, it is difficult to decide the related thresholds such as the <inline-formula><inline-graphic xlink:href="pone.0109700.e099.jpg"/></inline-formula> described earlier because this decision involves the tradeoff between the two individual diagnostic rates from the two groups of subjects. In contrast, we can see that this problem does not exist in our method.</p><p>In the present study, we assumed that for a P300-based lie detection method, the noise in the single trials could be divided into two categories: one is the ill-assorted responses to a certain type of stimulus, which results from a variation of cognitive state during detection <xref rid="pone.0109700-Gao3" ref-type="bibr">[55]</xref>; the other is normal noise such as EOG artifacts and spontaneous EEG. Hence, before applying SAD, we first averaged each 5 raw EEG datasets to decrease the impact of ill-resorted P300&#x02032;s on the SNR of P300, which would increase the robustness of the entire system for lie detection. The efficiency of this preprocessing method for lie detection is not addressed in this study because it has already been proven in the previous report <xref rid="pone.0109700-Gao3" ref-type="bibr">[55]</xref>. To reduce the influence of the second type of noise on the performance of the detection to the greatest extent, we proposed a novel SDA to separate the P300 components from the other noise signals, constructing new Pz waves with the more obvious P300 features; this process can be viewed as a spatial filter for the P300.</p><p>Previously, we introduced a topography-template matching (TTM) method <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref> to reconstruct P300 waveforms that have a higher SNR. TTM was based on correlation theory of the topography of the ICs. SDA differs from the TTM method in the construction algorithm. SDA is computationally efficient to implement. Hence SDA could decrease the training and testing time. In addition, the classification accuracy of the presented method is higher than that in the report <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>. For the sake of brevity, we have not compared the efficiency of these two methods here and the comparison will be addressed in future studies.</p><p>For SDA, the experiment results show that the detection accuracy is the highest when 2 (or 3) P300 ICs are selected to reconstruct the Pz waveform. This finding might indicate that 2 or 3 neural sources are responsible for the task of responding to the P stimuli. This inference deserves further study. In addition, we deemed that the physiology meaning of three parameter values of <italic>k1</italic>, <italic>k2</italic>and <italic>k3</italic> can be interpreted as follows. A realistic P300 IC (unknown P300 independent neural source under scalp) should have different distributed weight on different brain scalp areas. Comparing three <italic>k</italic> values, P300 IC has biggest distributed weight on P3 and P4, medium on Cz and least on Oz scalp areas.</p><p>It is worth mentioning that, even though only the waves on the Pz were finally used to extract features, 14 electrodes were still selected to run ICA in order to guarantee the efficiency of the EICA algorithm and SDA. Using ICA has another advantage in that it can help remove the ocular artifacts automatically in the preprocessing phase <xref rid="pone.0109700-Gao1" ref-type="bibr">[24]</xref>, which few previous studies of lie detection have addressed <xref rid="pone.0109700-Matsuda1" ref-type="bibr">[56]</xref>&#x02013;<xref rid="pone.0109700-Matsuda3" ref-type="bibr">[58]</xref>. Using SDA to remove ocular artifacts simultaneously will be investigated in the future.</p><p>It should be acknowledged that the procedure for tuning parameters in the present study is complicated and time-consuming. However, once these optimal parameter values were selected by the grid searching method on the training sets, they would be kept stable for the testing and real applications. We assumed, for example, that the parameter <italic>m</italic> represents the volume conduction feature of the neurons accounting for the P300 on the scalp, which is thought to be relatively stable spatially <xref rid="pone.0109700-Xu1" ref-type="bibr">[31]</xref>. Using other parameter optimization methods <xref rid="pone.0109700-Burges1" ref-type="bibr">[52]</xref>, <xref rid="pone.0109700-Friedrichs1" ref-type="bibr">[59]</xref> is also possible. We will evaluate this approach in future work.</p><p>Using the presented method, only 5 Probe stimuli (together with some Target and Irrelevant stimuli) must be presented to the subject in real applications. This arrangement is attractive and promising for practical applications. Moreover, to increase the reliability of the diagnoses, the examiner could perform our testing procedure multiple times and, then, make a more accurate decision by combining several independent testing results.</p><p>The F-score, which is a simple feature-selection method, was combined with classifiers to choose the optimal features. The F-score helps to decrease the feature number and, hence, to decrease the computational burden. More importantly, the experimental results show that it helps to enhance the classification accuracy compared with the individual classification models, indicating the importance of the feature selection for the classification performance. For the sake of simplicity, we remove redundant features by a commonly used threshold strategy. In the future, the wrapper method should be used to improve the proposed method.</p><p>Different kernel functions for SVM were not tested in this study. It can be found that the training procedure in this study is very complex. Hence, the selection of kernel functions was not considered for the simplicity of the training procedure. In our early other studies <xref rid="pone.0109700-Gao2" ref-type="bibr">[25]</xref>, <xref rid="pone.0109700-Gao3" ref-type="bibr">[55]</xref>, we had tested that the radial basis function (RBF) had the best performance than the other kernel functions. Hence, RBF was directly used in SVM method considering the similar lie detection researches.</p><p>The proposed method is not specific to research into lie detection and could be extended to other fields of the ERP classification. We believe that more sophisticated feature selection approaches, such as genetic algorithm <xref rid="pone.0109700-Abootalebi1" ref-type="bibr">[7]</xref>, <xref rid="pone.0109700-Wu1" ref-type="bibr">[60]</xref>, could further improve the performance of the classifier.</p></sec><sec sec-type="supplementary-material" id="s6"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0109700.s001"><label>File S1</label><caption><p>Section S1. FDA classifier. Section S2. BPNN. Section S3. SVM.</p><p>(DOC)</p></caption><media xlink:href="pone.0109700.s001.doc"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pone.0109700-Gamer1"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Gamer</surname><given-names>M</given-names></name>, <name><surname>Berti</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>Task relevance and recognition of concealed information have different influences on electrodermal activity and event-related brain potentials</article-title>. <source>Psychophysiology</source>
<volume>47(2)</volume>: <fpage>355</fpage>&#x02013;<lpage>364</lpage>.<pub-id pub-id-type="pmid">20003148</pub-id></mixed-citation></ref><ref id="pone.0109700-Ambach1"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Ambach</surname><given-names>W</given-names></name>, <name><surname>Bursch</surname><given-names>S</given-names></name>, <name><surname>Stark</surname><given-names>R</given-names></name>, <name><surname>Vaitl</surname><given-names>D</given-names></name> (<year>2010</year>) <article-title>A Concealed Information Test with multimodal measurement</article-title>. <source>Int J Psychophysi</source>
<volume>75</volume>: <fpage>258</fpage>&#x02013;<lpage>26</lpage>.</mixed-citation></ref><ref id="pone.0109700-Ito1"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Ito</surname><given-names>A</given-names></name>, <name><surname>Abe</surname><given-names>N</given-names></name>, <name><surname>Fujii</surname><given-names>T</given-names></name>, <name><surname>Ueno</surname><given-names>A</given-names></name>, <name><surname>Koseki</surname><given-names>Y</given-names></name>, <etal>et al</etal> (<year>2011</year>) <article-title>The role of the dorsolateral prefrontal cortex in deception when remembering neutral and emotional events</article-title>. <source>Neurosci Res</source>
<volume>69(2)</volume>: <fpage>121</fpage>&#x02013;<lpage>128</lpage>.<pub-id pub-id-type="pmid">21074583</pub-id></mixed-citation></ref><ref id="pone.0109700-Langleben1"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Langleben</surname><given-names>DD</given-names></name>, <name><surname>Loughead</surname><given-names>JW</given-names></name>, <name><surname>Bilker</surname><given-names>WB</given-names></name>, <name><surname>Ruparel</surname><given-names>K</given-names></name>, <name><surname>Childress</surname><given-names>AR</given-names></name>, <etal>et al</etal> (<year>2005</year>) <article-title>Telling truth from lie in individual subjects with fast event-related fMRI</article-title>. <source>Hum Brain Mapp</source>
<volume>26(4)</volume>: <fpage>262</fpage>&#x02013;<lpage>272</lpage>.<pub-id pub-id-type="pmid">16161128</pub-id></mixed-citation></ref><ref id="pone.0109700-Phan1"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Phan</surname><given-names>KL</given-names></name>, <name><surname>Magalhaes</surname><given-names>A</given-names></name>, <name><surname>Ziemlewicz</surname><given-names>TJ</given-names></name>, <name><surname>Fitzgerald</surname><given-names>DA</given-names></name>, <name><surname>Green</surname><given-names>C</given-names></name>, <etal>et al</etal> (<year>2005</year>) <article-title>Neural correlates of telling lies: a functional magnetic resonance imaging study at 4 Tesla</article-title>. <source>Acad Radiol</source>
<volume>12(2)</volume>: <fpage>164</fpage>&#x02013;<lpage>172</lpage>.<pub-id pub-id-type="pmid">15721593</pub-id></mixed-citation></ref><ref id="pone.0109700-Rosenfeld1"><label>6</label><mixed-citation publication-type="other">Rosenfeld JP (2002) Event-related potentials in the detection of deception. Handbook of Polygraph Testing. Academic Press, New York, 265&#x02013;286.</mixed-citation></ref><ref id="pone.0109700-Abootalebi1"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Abootalebi</surname><given-names>V</given-names></name>, <name><surname>Moradi</surname><given-names>MH</given-names></name>, <name><surname>Khalilzadeh</surname><given-names>MA</given-names></name> (<year>2009</year>) <article-title>A new approach for EEG feature extraction in P300-based lie detection</article-title>. <source>Comput Methods and Programs in Biomed</source>
<volume>94(1)</volume>: <fpage>48</fpage>&#x02013;<lpage>57</lpage>.</mixed-citation></ref><ref id="pone.0109700-Polich1"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Polich</surname><given-names>J</given-names></name>, <name><surname>Herbst</surname><given-names>KL</given-names></name> (<year>2000</year>) <article-title>P300 as a clinical assay: rational, evaluation, and findings</article-title>. <source>Int J Psychophysi</source>
<volume>38(1)</volume>: <fpage>3</fpage>&#x02013;<lpage>19</lpage>.</mixed-citation></ref><ref id="pone.0109700-Meijer1"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Meijer</surname><given-names>EH</given-names></name>, <name><surname>Smulders</surname><given-names>FTY</given-names></name>, <name><surname>Merckelbach</surname><given-names>HLGJ</given-names></name>, <name><surname>Wolf</surname><given-names>AG</given-names></name> (<year>2007</year>) <article-title>The P300 is sensitive to concealed face recognition</article-title>. <source>Int J Psychophysi</source>
<volume>66(3)</volume>: <fpage>231</fpage>&#x02013;<lpage>237</lpage>.</mixed-citation></ref><ref id="pone.0109700-Rosenfeld2"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Rosenfeld</surname><given-names>JP</given-names></name>, <name><surname>Soskins</surname><given-names>M</given-names></name>, <name><surname>Bosh</surname><given-names>G</given-names></name>, <name><surname>Ryan</surname><given-names>A</given-names></name> (<year>2004</year>) <article-title>Simple, effective countermeasures to P300-based tests of detection of concealed information</article-title>. <source>Psychophysiology</source>
<volume>41(2)</volume>: <fpage>205</fpage>&#x02013;<lpage>219</lpage>.<pub-id pub-id-type="pmid">15032986</pub-id></mixed-citation></ref><ref id="pone.0109700-Rosenfeld3"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Rosenfeld</surname><given-names>JP</given-names></name>, <name><surname>Labkovsky</surname><given-names>E</given-names></name>, <name><surname>Winograd M. Lui</surname><given-names>MA</given-names></name>, <name><surname>Vandenboom</surname><given-names>C</given-names></name>, <etal>et al</etal> (<year>2008</year>) <article-title>The Complex Trial Protocol (CTP): A new, countermeasure-resistant, accurate, P300-based method for detection of concealed information</article-title>. <source>Psychophysiology</source>
<volume>45(6)</volume>: <fpage>906</fpage>&#x02013;<lpage>919</lpage>.<pub-id pub-id-type="pmid">18823418</pub-id></mixed-citation></ref><ref id="pone.0109700-Farwell1"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Farwell</surname><given-names>LA</given-names></name>, <name><surname>Donchin</surname><given-names>E</given-names></name> (<year>1991</year>) <article-title>The truth will out: interrogative polygraphy (&#x02018;&#x02018;lie detection&#x02019;&#x02019;) with event-related potentials</article-title>. <source>Psychophysiology</source>
<volume>28(5)</volume>: <fpage>531</fpage>&#x02013;<lpage>547</lpage>.<pub-id pub-id-type="pmid">1758929</pub-id></mixed-citation></ref><ref id="pone.0109700-Abootalebi2"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Abootalebi</surname><given-names>V</given-names></name>, <name><surname>Moradi</surname><given-names>MH</given-names></name>, <name><surname>Khalilzadeh</surname><given-names>MA</given-names></name> (<year>2006</year>) <article-title>A comparison of methods for ERP assessment in a P300-based GKT</article-title>. <source>Int J Psychophysi</source>
<volume>62(2)</volume>: <fpage>309</fpage>&#x02013;<lpage>320</lpage>.</mixed-citation></ref><ref id="pone.0109700-Dvatzikos1"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Dvatzikos</surname><given-names>C</given-names></name>, <name><surname>Ruparel</surname><given-names>K</given-names></name>, <name><surname>Fan</surname><given-names>Y</given-names></name>, <name><surname>Shen</surname><given-names>DG</given-names></name>, <name><surname>Acharyya</surname><given-names>M</given-names></name>, <etal>et al</etal> (<year>2005</year>) <article-title>Classifying spatial patterns of brain activity with machine learning methods: Application to lie detection</article-title>. <source>NeuroImage</source>
<volume>28(3)</volume>: <fpage>663</fpage>&#x02013;<lpage>668</lpage>.<pub-id pub-id-type="pmid">16169252</pub-id></mixed-citation></ref><ref id="pone.0109700-Jung1"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Jung</surname><given-names>TP</given-names></name>, <name><surname>Makeig</surname><given-names>S</given-names></name>, <name><surname>Humphries</surname><given-names>C</given-names></name>, <name><surname>Lee</surname><given-names>TW</given-names></name>, <name><surname>McKeown</surname><given-names>MJ</given-names></name>, <etal>et al</etal> (<year>2000a</year>) <article-title>Removing electroencephalographic artifacts by blind source separation</article-title>. <source>Psychophysiology</source>
<volume>37(2)</volume>: <fpage>163</fpage>&#x02013;<lpage>178</lpage>.<pub-id pub-id-type="pmid">10731767</pub-id></mixed-citation></ref><ref id="pone.0109700-Wasserman1"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Wasserman</surname><given-names>S</given-names></name>, <name><surname>Bockenholt</surname><given-names>U</given-names></name> (<year>1989</year>) <article-title>Bootstrapping: applications to psychophysiology</article-title>. <source>Psychophysiology</source>
<volume>26(2)</volume>: <fpage>208</fpage>&#x02013;<lpage>221</lpage>.<pub-id pub-id-type="pmid">2727223</pub-id></mixed-citation></ref><ref id="pone.0109700-Jung2"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Jung</surname><given-names>TP</given-names></name>, <name><surname>Makeig</surname><given-names>S</given-names></name>, <name><surname>Waterfield</surname><given-names>M</given-names></name>, <name><surname>Townsend</surname><given-names>J</given-names></name>, <name><surname>Courchesne</surname><given-names>U</given-names></name>, <etal>et al</etal> (<year>2000b</year>) <article-title>Removing of eye activity artifacts from visual event-related potentials in normal and clinical subjects</article-title>. <source>Clin Neurophysiol</source>
<volume>111(10)</volume>: <fpage>1745</fpage>&#x02013;<lpage>1758</lpage>.<pub-id pub-id-type="pmid">11018488</pub-id></mixed-citation></ref><ref id="pone.0109700-Bell1"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Bell</surname><given-names>AJ</given-names></name>, <name><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1995</year>) <article-title>An information-maximization approach to blind separation and blind deconvolution</article-title>. <source>Neural Computation, MIT Press, Cambridge, MA</source>
<volume>7(6)</volume>: <fpage>1129</fpage>&#x02013;<lpage>1159</lpage>.</mixed-citation></ref><ref id="pone.0109700-Tang1"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Tang</surname><given-names>AC</given-names></name>, <name><surname>Pearlmutter</surname><given-names>BA</given-names></name>, <name><surname>Zibulevsky</surname><given-names>M</given-names></name>, <name><surname>Carter</surname><given-names>SA</given-names></name> (<year>2000</year>) <article-title>Blind source separation of multichannel neuromagnetic responses</article-title>. <source>Neurocomput</source>
<volume>32</volume>: <fpage>1115</fpage>&#x02013;<lpage>1120</lpage>.</mixed-citation></ref><ref id="pone.0109700-Parra1"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Parra</surname><given-names>L</given-names></name>, <name><surname>Sajda</surname><given-names>P</given-names></name> (<year>2003</year>) <article-title>Blind source separation via generalized eigenvalue decomposition</article-title>. <source>J Mach Learn Res</source>
<volume>4</volume>: <fpage>1261</fpage>&#x02013;<lpage>1269</lpage>.</mixed-citation></ref><ref id="pone.0109700-Peterson1"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Peterson</surname><given-names>DA</given-names></name>, <name><surname>Anderson</surname><given-names>CW</given-names></name> (<year>1999</year>) <article-title>EEG-based Cognitive Task Classification with ICA and Neural Networks. Engineering Applications of Bio-Inspired Artificial Neural Networks</article-title>. <source>Springer Berlin Heidelberg</source>
<volume>1999</volume>: <fpage>265</fpage>&#x02013;<lpage>272</lpage>.</mixed-citation></ref><ref id="pone.0109700-Hung1"><label>22</label><mixed-citation publication-type="journal">
<name><surname>Hung</surname><given-names>CI</given-names></name>, <name><surname>Lee</surname><given-names>PL</given-names></name>, <name><surname>Wu</surname><given-names>YT</given-names></name>, <name><surname>Chen</surname><given-names>LF</given-names></name>, <name><surname>Yeh</surname><given-names>TCH</given-names></name>, <etal>et al</etal> (<year>2005</year>) <article-title>Recognition of Motor Imagery Electroencephalography Using Independent Component Analysis and Machine Classifiers</article-title>. <source>Ann Biomed Eng</source>
<volume>33(8)</volume>: <fpage>1053</fpage>&#x02013;<lpage>1070</lpage>.<pub-id pub-id-type="pmid">16133914</pub-id></mixed-citation></ref><ref id="pone.0109700-Tang2"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Tang</surname><given-names>AC</given-names></name>, <name><surname>Sutherland</surname><given-names>MT</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name> (<year>2006</year>) <article-title>Contrasting single-trial ERPs between experimental manipulations: Improving differentiability by blind source separation</article-title>. <source>NeuroImage</source>
<volume>29(1)</volume>: <fpage> 335</fpage>&#x02013;<lpage>346</lpage>.<pub-id pub-id-type="pmid">16256373</pub-id></mixed-citation></ref><ref id="pone.0109700-Gao1"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Gao</surname><given-names>JF</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>, <name><surname>Lin</surname><given-names>P</given-names></name>, <name><surname>Wang</surname><given-names>P</given-names></name>, <name><surname>Zheng</surname><given-names>CX</given-names></name> (<year>2010</year>) <article-title>Automatic Removal of Eye-movement and Blink Artifacts from EEG Signals</article-title>. <source>Brain Topo</source>
<volume>23(1)</volume>: <fpage>105</fpage>&#x02013;<lpage>114</lpage>.</mixed-citation></ref><ref id="pone.0109700-Gao2"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Gao</surname><given-names>JF</given-names></name>, <name><surname>Lu</surname><given-names>L</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>, <name><surname>Yu</surname><given-names>G</given-names></name>, <name><surname>Na</surname><given-names>LT</given-names></name>, <etal>et al</etal> (<year>2012</year>) <article-title>A Novel Concealed Information Test Method Based on Independent Component Analysis and Support Vector Machine</article-title>. <source>Clin EEG Neurosci</source>
<volume>43(1)</volume>: <fpage>54</fpage>&#x02013;<lpage>63</lpage>.<pub-id pub-id-type="pmid">22423552</pub-id></mixed-citation></ref><ref id="pone.0109700-Comon1"><label>26</label><mixed-citation publication-type="journal">
<name><surname>Comon</surname><given-names>P</given-names></name> (<year>1994</year>) <article-title>Independent component analysis, a new concept?</article-title>
<source>Signal Process</source>
<volume>36(3)</volume>: <fpage>287</fpage>&#x02013;<lpage>314</lpage>.</mixed-citation></ref><ref id="pone.0109700-Makeig1"><label>27</label><mixed-citation publication-type="other">Makeig S, Bell AJ, Jung TP, Sejnowski TJ (1996) Independent Component Analysis of Electroencephalgraphic Data. Adv Neural Inform Process Systems 8, MIT press, Cambridge MA, <fpage>145</fpage>&#x02013;&#x02013;<lpage>151</lpage>.</mixed-citation></ref><ref id="pone.0109700-Jung3"><label>28</label><mixed-citation publication-type="other">Jung TP, Humphries C, Lee TW, Makeig S, McKeown MJ, <etal>et al</etal>.. (1998) Extended ica removes artifacts from electroencephalographic recordings. Adv Neural Inform Process Systems, 894&#x02013;900.</mixed-citation></ref><ref id="pone.0109700-Lee1"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Lee</surname><given-names>TW</given-names></name>, <name><surname>Girolami</surname><given-names>M</given-names></name>, <name><surname>Sejnowski</surname><given-names>EJ</given-names></name> (<year>1999</year>) <article-title>Independent component analysis using an extended informax algorithm for mixed subgaussian and supergaussian sources</article-title>. <source>Neural Comput</source>
<volume>11(2)</volume>: <fpage>409</fpage>&#x02013;<lpage>433</lpage>.</mixed-citation></ref><ref id="pone.0109700-Rosenfeld4"><label>30</label><mixed-citation publication-type="journal">
<name><surname>Rosenfeld</surname><given-names>JP</given-names></name>, <name><surname>Ellwanger</surname><given-names>JW</given-names></name>, <name><surname>Nolana</surname><given-names>K</given-names></name>, <name><surname>Wua</surname><given-names>S</given-names></name>, <name><surname>Bermanna</surname><given-names>RG</given-names></name>, <etal>et al</etal> (<year>1999</year>) <article-title>P300 Scalp amplitude distribution as an index of deception in a simulated cognitive deficit model</article-title>. <source>Int J Psychophysi</source>
<volume>33(1)</volume>: <fpage>3</fpage>&#x02013;<lpage>19</lpage>.</mixed-citation></ref><ref id="pone.0109700-Xu1"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Xu</surname><given-names>N</given-names></name>, <name><surname>Gao</surname><given-names>XR</given-names></name>, <name><surname>Hong</surname><given-names>B</given-names></name>, <name><surname>Miao</surname><given-names>XB</given-names></name>, <name><surname>Gao</surname><given-names>SK</given-names></name>, <etal>et al</etal> (<year>2004</year>) <article-title>BCI Competition 2003&#x02014;Data Set IIb: Enhancing P300 Wave Detection Using ICA-Based Subspace Projections for BCI Applications</article-title>. <source>IEEE Trans Biomed Eng</source>
<volume>51(6)</volume>: <fpage>1067</fpage>&#x02013;<lpage>1072</lpage>.<pub-id pub-id-type="pmid">15188880</pub-id></mixed-citation></ref><ref id="pone.0109700-Polich2"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Polich</surname><given-names>J</given-names></name> (<year>2007</year>) <article-title>Updating P300: An integrative theory of P3a and P3b</article-title>. <source>Clin Neurophysiol</source>
<volume>118</volume>: <fpage>2128</fpage>&#x02013;<lpage>2148</lpage>.<pub-id pub-id-type="pmid">17573239</pub-id></mixed-citation></ref><ref id="pone.0109700-Demiralp1"><label>33</label><mixed-citation publication-type="journal">
<name><surname>Demiralp</surname><given-names>T</given-names></name>, <name><surname>Ademoglu</surname><given-names>A</given-names></name>, <name><surname>Schurmann</surname><given-names>M</given-names></name>, <name><surname>Eroglu</surname><given-names>CB</given-names></name>, <name><surname>Basar</surname><given-names>E</given-names></name> (<year>1999</year>) <article-title>Detection of P300 waves in single trials by the Wavelet Transform (WT)</article-title>. <source>Brain Lang</source>
<volume>66(1)</volume>: <fpage>108</fpage>&#x02013;<lpage>128</lpage>.<pub-id pub-id-type="pmid">10080867</pub-id></mixed-citation></ref><ref id="pone.0109700-Kalatzis1"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Kalatzis</surname><given-names>I</given-names></name>, <name><surname>Piliouras</surname><given-names>N</given-names></name>, <name><surname>Ventouras</surname><given-names>E</given-names></name>, <name><surname>Papageorgiou</surname><given-names>CC</given-names></name>, <name><surname>Rabavilas</surname><given-names>AD</given-names></name>, <etal>et al</etal> (<year>2004</year>) <article-title>Design and implementation of an SVM-based computer classification system for discriminating depressive patients from healthy controls using the P600 component of ERP signals, Comput Meth Prog Biomed</article-title>. <volume>75(1)</volume>: <fpage>11</fpage>&#x02013;<lpage>22</lpage>.</mixed-citation></ref><ref id="pone.0109700-Hsu1"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Hsu</surname><given-names>WY</given-names></name>, <name><surname>Lin</surname><given-names>CC</given-names></name>, <name><surname>Ju</surname><given-names>MS</given-names></name>, <name><surname>Sun</surname><given-names>YN</given-names></name> (<year>2007</year>) <article-title>Wavelet-based fractal features with active segment selection: Application to single-trial EEG data</article-title>. <source>J Neurosci Meth</source>
<volume>163(1)</volume>: <fpage>145</fpage>&#x02013;<lpage>160</lpage>.</mixed-citation></ref><ref id="pone.0109700-Herrmann1"><label>36</label><mixed-citation publication-type="journal">
<name><surname>Herrmann</surname><given-names>CS</given-names></name>, <name><surname>Knight</surname><given-names>RT</given-names></name> (<year>2001</year>) <article-title>Mechanisms of human attention: event-related potentials and oscillations</article-title>. <source>Neurosci and Biobehav Rev</source>
<volume>25(6)</volume>: <fpage>465</fpage>&#x02013;<lpage>476</lpage>.<pub-id pub-id-type="pmid">11595268</pub-id></mixed-citation></ref><ref id="pone.0109700-Yong1"><label>37</label><mixed-citation publication-type="other">Yong YPA, Hurley NJ, Silvestre GCM (2005) Single-trial EEG classification for brain-computer interface using wavelet decomposition. Eur Signal Process.</mixed-citation></ref><ref id="pone.0109700-Mrzagora1"><label>38</label><mixed-citation publication-type="other">Mrzagora AC, Bunce S, Izzetoglu M, Onaral B (2006) Wavelet analysis for EEG feature extraction in deception detection Proceedings of the 28th IEEE EMBS Annual International Conference. New York City, USA, Aug 30.</mixed-citation></ref><ref id="pone.0109700-Ademoglu1"><label>39</label><mixed-citation publication-type="journal">
<name><surname>Ademoglu</surname><given-names>A</given-names></name>, <name><surname>Micheli-Tzanakou</surname><given-names>E</given-names></name>, <name><surname>Istefanopulos</surname><given-names>Y</given-names></name> (<year>1997</year>) <article-title>Analysis of pattern reversal visual evoked potentials (PRVEPs) by spline wavelets</article-title>. <source>IEEE Trans on Biomed Eng</source>
<volume>44(9)</volume>: <fpage>881</fpage>&#x02013;<lpage>890</lpage>.</mixed-citation></ref><ref id="pone.0109700-Unser1"><label>40</label><mixed-citation publication-type="journal">
<name><surname>Unser</surname><given-names>M</given-names></name>, <name><surname>Aldroubi</surname><given-names>A</given-names></name>, <name><surname>Eden</surname><given-names>M</given-names></name> (<year>1992</year>) <article-title>On the asymptotic convergence of B-spline wavelets to Gabor functions</article-title>. <source>IEEE Trans on Information Theory</source>
<volume>38(2)</volume>: <fpage>864</fpage>&#x02013;<lpage>872</lpage>.</mixed-citation></ref><ref id="pone.0109700-Quiroga1"><label>41</label><mixed-citation publication-type="journal">
<name><surname>Quiroga</surname><given-names>RQ</given-names></name>, <name><surname>Sakowitz</surname><given-names>OW</given-names></name>, <name><surname>Basar</surname><given-names>E</given-names></name>, <name><surname>Schurmann</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Wavelet transform in the analysis of the frequency composition of evoked potentials</article-title>. <source>Brain Res Protoc</source>
<volume>8(1)</volume>: <fpage>16</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="pone.0109700-Chen1"><label>42</label><mixed-citation publication-type="journal">
<name><surname>Chen</surname><given-names>FL</given-names></name>, <name><surname>Li</surname><given-names>FC</given-names></name> (<year>2010</year>) <article-title>Combination of feature selection approaches with SVM in credit scoring</article-title>. <source>Expert Syst Appl</source>
<volume>37</volume>: <fpage>4902</fpage>&#x02013;<lpage>4909</lpage>.</mixed-citation></ref><ref id="pone.0109700-Polat1"><label>43</label><mixed-citation publication-type="journal">
<name><surname>Polat</surname><given-names>K</given-names></name>, <name><surname>G&#x000fc;ne&#x0015f;</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>A new feature selection method on classification of medical datasets: Kernel F-score feature selection</article-title>. <source>Expert Syst Appl</source>
<volume>36(7)</volume>: <fpage>10367</fpage>&#x02013;<lpage>10373</lpage>.</mixed-citation></ref><ref id="pone.0109700-Jouve1"><label>44</label><mixed-citation publication-type="other">Jouve PE, Nicoloyannis N (2005) A filter feature selection method for clustering Foundations of Intelligent Systems. Springer Berlin Heidelberg, 583&#x02013;593.</mixed-citation></ref><ref id="pone.0109700-Kohavi1"><label>45</label><mixed-citation publication-type="journal">
<name><surname>Kohavi</surname><given-names>R</given-names></name>, <name><surname>John</surname><given-names>GH</given-names></name> (<year>1997</year>) <article-title>Wrappers for feature subset selection</article-title>. <source>Arti Intell</source>
<volume>97(1)</volume>: <fpage>273</fpage>&#x02013;<lpage>324</lpage>.</mixed-citation></ref><ref id="pone.0109700-Huang1"><label>46</label><mixed-citation publication-type="journal">
<name><surname>Huang</surname><given-names>CJ</given-names></name>, <name><surname>Dian</surname><given-names>X</given-names></name>, <name><surname>Chuang</surname><given-names>YT</given-names></name> (<year>2007</year>) <article-title>Application of wrapper approach and composite classifier to the stock trend prediction</article-title>. <source>Expert Syst Appl</source>
<volume>34(4)</volume>: <fpage>2870</fpage>&#x02013;<lpage>2878</lpage>.</mixed-citation></ref><ref id="pone.0109700-Chiang1"><label>47</label><mixed-citation publication-type="journal">
<name><surname>Chiang</surname><given-names>L</given-names></name>, <name><surname>Russell</surname><given-names>E</given-names></name>, <name><surname>Braatz</surname><given-names>R</given-names></name> (<year>2000</year>) <article-title>Fault diagnosis in chemical processes using Fisher discriminant analysis, discriminant partial least squares, and principal component analysis</article-title>. <source>Chemomet Intell Lab Syst</source>
<volume>50(2)</volume>: <fpage>243</fpage>&#x02013;<lpage>252</lpage>.</mixed-citation></ref><ref id="pone.0109700-Tarassenko1"><label>48</label><mixed-citation publication-type="journal">
<name><surname>Tarassenko</surname><given-names>L</given-names></name>, <name><surname>Khan</surname><given-names>YU</given-names></name>, <name><surname>Holt</surname><given-names>MRG</given-names></name> (<year>1998</year>) <article-title>Identification of inter-ictal spikes in the EEG using neural network analysis</article-title>. <source>IEE Proceedings Science, Measurement &#x00026; Technology</source>
<volume>145(6)</volume>: <fpage>270</fpage>&#x02013;<lpage>278</lpage>.</mixed-citation></ref><ref id="pone.0109700-Kaper1"><label>49</label><mixed-citation publication-type="journal">
<name><surname>Kaper</surname><given-names>M</given-names></name>, <name><surname>Meinicke</surname><given-names>P</given-names></name>, <name><surname>Grossekathoefer</surname><given-names>U</given-names></name>, <name><surname>Lingner</surname><given-names>T</given-names></name>, <name><surname>Ritter</surname><given-names>H</given-names></name> (<year>2004</year>) <article-title>BCI competition 2003-data set IIb: support vector machines for the P300 speller paradigm, IEEE Trans on Biomed Eng</article-title>. <volume>51(6)</volume>: <fpage>1073</fpage>&#x02013;<lpage>1076</lpage>.</mixed-citation></ref><ref id="pone.0109700-Shoker1"><label>50</label><mixed-citation publication-type="journal">
<name><surname>Shoker</surname><given-names>L</given-names></name>, <name><surname>Sanei</surname><given-names>S</given-names></name>, <name><surname>Chambers</surname><given-names>J</given-names></name> (<year>2005</year>) <article-title>Artifact removal from electroencephalograms using a hybrid BSS-SVM algorithm</article-title>. <source>IEEE Sig Process Letters</source>
<volume>12(10)</volume>: <fpage>721</fpage>&#x02013;<lpage>724</lpage>.</mixed-citation></ref><ref id="pone.0109700-Shao1"><label>51</label><mixed-citation publication-type="journal">
<name><surname>Shao</surname><given-names>SY</given-names></name>, <name><surname>Shen</surname><given-names>KQ</given-names></name>, <name><surname>On</surname><given-names>CJ</given-names></name>, <name><surname>Wilder-Smith</surname><given-names>EPV</given-names></name>, <name><surname>Li</surname><given-names>XP</given-names></name> (<year>2009</year>) <article-title>Automatic EEG artifact removal: A weighted support vector machine approach with error correction</article-title>. <source>IEEE Trans Biomed Eng</source>
<volume>56(2)</volume>: <fpage>336</fpage>&#x02013;<lpage>344</lpage>.<pub-id pub-id-type="pmid">19272915</pub-id></mixed-citation></ref><ref id="pone.0109700-Burges1"><label>52</label><mixed-citation publication-type="journal">
<name><surname>Burges</surname><given-names>C</given-names></name> (<year>1998</year>) <article-title>A tutorial on support vector machines for pattern recognition</article-title>. <source>Data Mining and Knowl Discov</source>
<volume>2(2)</volume>: <fpage>121</fpage>&#x02013;<lpage>167</lpage>.</mixed-citation></ref><ref id="pone.0109700-Lin1"><label>53</label><mixed-citation publication-type="journal">
<name><surname>Lin</surname><given-names>CT</given-names></name>, <name><surname>Chung</surname><given-names>IF</given-names></name>, <name><surname>Ko</surname><given-names>LW</given-names></name>, <name><surname>Chen</surname><given-names>YC</given-names></name>, <name><surname>Liang</surname><given-names>SF</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>EEG-Based Assessment of Driver Cognitive Responses in a Dynamic Virtual-Reality Driving Environment</article-title>. <source>IEEE Trans Biomed Eng</source>
<volume>54(7)</volume>: <fpage>1394</fpage>&#x02013;<lpage>1352</lpage>.</mixed-citation></ref><ref id="pone.0109700-Soskins1"><label>54</label><mixed-citation publication-type="journal">
<name><surname>Soskins</surname><given-names>M</given-names></name>, <name><surname>Rosenfeld</surname><given-names>JP</given-names></name>, <name><surname>Niendam</surname><given-names>T</given-names></name> (<year>2001</year>) <article-title>The case for peak-to-peak measurement of P300 recorded at.3 Hz high pass filter settings in detection of deception</article-title>. <source>Int J Psychophysi</source>
<volume>40(17)</volume>: <fpage>173</fpage>&#x02013;<lpage>1800</lpage>.</mixed-citation></ref><ref id="pone.0109700-Gao3"><label>55</label><mixed-citation publication-type="journal">
<name><surname>Gao</surname><given-names>JF</given-names></name>, <name><surname>Yan</surname><given-names>XG</given-names></name>, <name><surname>Sun</surname><given-names>JC</given-names></name>, <name><surname>Zheng</surname><given-names>CX</given-names></name> (<year>2011</year>) <article-title>Denoised P300 and Machine Learning-based Concealed Information Test Method</article-title>. <source>Comput Meth Prog Bio</source>
<volume>104</volume>: <fpage>410</fpage>&#x02013;<lpage>417</lpage>.</mixed-citation></ref><ref id="pone.0109700-Matsuda1"><label>56</label><mixed-citation publication-type="journal">
<name><surname>Matsuda</surname><given-names>I</given-names></name>, <name><surname>Nittono</surname><given-names>H</given-names></name>, <name><surname>Hirota</surname><given-names>A</given-names></name>, <name><surname>Ogawa</surname><given-names>T</given-names></name>, <name><surname>Takasawa</surname><given-names>N</given-names></name> (<year>2009</year>) <article-title>Event-related brain potentials during the standard autonomic-based concealed information test</article-title>. <source>Int J Psychophysi</source>
<volume>74(1)</volume>: <fpage>58</fpage>&#x02013;<lpage>68</lpage>.</mixed-citation></ref><ref id="pone.0109700-Matsuda2"><label>57</label><mixed-citation publication-type="journal">
<name><surname>Matsuda</surname><given-names>I</given-names></name>, <name><surname>Nittono</surname><given-names>H</given-names></name>, <name><surname>Ogawa</surname><given-names>T</given-names></name> (<year>2011</year>) <article-title>Event-related potentials increase the discrimination performance of the autonomic-based concealed information test</article-title>. <source>Psychophysiology</source>
<volume>48(12)</volume>: <fpage>1701</fpage>&#x02013;<lpage>1710</lpage>.<pub-id pub-id-type="pmid">21806637</pub-id></mixed-citation></ref><ref id="pone.0109700-Matsuda3"><label>58</label><mixed-citation publication-type="journal">
<name><surname>Matsuda</surname><given-names>I</given-names></name>, <name><surname>Nittono</surname><given-names>H</given-names></name>, <name><surname>Ogawa</surname><given-names>T</given-names></name> (<year>2013</year>) <article-title>Identifying concealment-related responses in the concealed information test</article-title>. <source>Psychophysiology</source>
<volume>50</volume>: <fpage>617</fpage>&#x02013;<lpage>626</lpage>.<pub-id pub-id-type="pmid">23560794</pub-id></mixed-citation></ref><ref id="pone.0109700-Friedrichs1"><label>59</label><mixed-citation publication-type="journal">
<name><surname>Friedrichs</surname><given-names>F</given-names></name>, <name><surname>lgel</surname><given-names>C</given-names></name> (<year>2005</year>) <article-title>Evolutionary tuning of multiple SVM parameters</article-title>. <source>Neurocomput</source>
<volume>24</volume>: <fpage>107</fpage>&#x02013;<lpage>117</lpage>.</mixed-citation></ref><ref id="pone.0109700-Wu1"><label>60</label><mixed-citation publication-type="journal">
<name><surname>Wu</surname><given-names>CH</given-names></name>, <name><surname>Tzeng</surname><given-names>GH</given-names></name>, <name><surname>Lin</surname><given-names>RH</given-names></name> (<year>2009</year>) <article-title>A novel hybrid genetic algorithm for kernel function and parameter optimization in support vector regression</article-title>. <source>Expert Syst Appl</source>
<volume>36</volume>: <fpage>4725</fpage>&#x02013;<lpage>4735</lpage>.</mixed-citation></ref></ref-list></back></article>