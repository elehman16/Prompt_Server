<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Integr Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Integr Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Integr. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Integrative Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1662-5145</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24391557</article-id><article-id pub-id-type="pmc">3866588</article-id><article-id pub-id-type="doi">10.3389/fnint.2013.00095</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Reinforcement learning modulates the stability of cognitive control settings for object selection</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sali</surname><given-names>Anthony W.</given-names></name><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib><contrib contrib-type="author"><name><surname>Anderson</surname><given-names>Brian A.</given-names></name></contrib><contrib contrib-type="author"><name><surname>Yantis</surname><given-names>Steven</given-names></name></contrib></contrib-group><aff id="aff"><institution>Department of Psychological and Brain Sciences, Johns Hopkins University</institution><country>Baltimore MD, USA</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Gene Stoner, Salk Institute, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: Hao Zhang, Duke University Medical Center, USA; Elyse S. Sussman, Albert Einstein College of Medicine, USA</p></fn><corresp id="fn001">*Correspondence: Anthony W. Sali, Department of Psychological and Brain Sciences, Johns Hopkins University, 3400 N. Charles St., Baltimore, MD 21218-2686, USA e-mail: <email xlink:type="simple">asali1@jhu.edu</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to the journal Frontiers in Integrative Neuroscience.</p></fn></author-notes><pub-date pub-type="epreprint"><day>28</day><month>8</month><year>2013</year></pub-date><pub-date pub-type="epub"><day>18</day><month>12</month><year>2013</year></pub-date><pub-date pub-type="collection"><year>2013</year></pub-date><volume>7</volume><elocation-id>95</elocation-id><history><date date-type="received"><day>12</day><month>7</month><year>2013</year></date><date date-type="accepted"><day>29</day><month>11</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2013 Sali, Anderson and Yantis.</copyright-statement><copyright-year>2013</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Cognitive flexibility reflects both a trait that reliably differs between individuals and a state that can fluctuate moment-to-moment. Whether individuals can undergo persistent changes in cognitive flexibility as a result of reward learning is less understood. Here, we investigated whether reinforcing a periodic shift in an object selection strategy can make an individual more prone to switch strategies in a subsequent unrelated task. Participants completed two different choice tasks in which they selected one of four objects in an attempt to obtain a hidden reward on each trial. During a training phase, objects were defined by color. Participants received either consistent reward contingencies in which one color was more often rewarded, or contingencies in which the color that was more often rewarded changed periodically and without warning. Following the training phase, all participants completed a test phase in which reward contingencies were defined by spatial location and the location that was more often rewarded remained constant across the entire task. Those participants who received inconsistent contingencies during training continued to make more variable selections during the test phase in comparison to those who received the consistent training. Furthermore, a difference in the likelihood to switch selections on a trial-by-trial basis emerged between training groups: participants who received consistent contingencies during training were less likely to switch object selections following an unrewarded trial and more likely to repeat a selection following reward. Our findings provide evidence that the extent to which priority shifting is reinforced modulates the stability of cognitive control settings in a persistent manner, such that individuals become generally more or less prone to shifting priorities in the future.</p></abstract><kwd-group><kwd>cognitive flexibility</kwd><kwd>reinforcement learning</kwd><kwd>attentional selection</kwd><kwd>decision making</kwd><kwd>impulsivity</kwd></kwd-group><counts><fig-count count="6"/><table-count count="0"/><equation-count count="0"/><ref-count count="52"/><page-count count="8"/><word-count count="7024"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>An important component of adaptive behavior is the ability to flexibly update cognitive operations such as the deployment of attention or the selection of a behavioral strategy. Attentional selection is governed by cognitive control settings (e.g., Wolfe et al., <xref ref-type="bibr" rid="B50">1989</xref>; Folk et al., <xref ref-type="bibr" rid="B21">1992</xref>; Corbetta and Shulman, <xref ref-type="bibr" rid="B18">2002</xref>) and determines which information from the environment receives cognitive processing and influences decision making (Yantis and Johnston, <xref ref-type="bibr" rid="B52">1990</xref>; Desimone and Duncan, <xref ref-type="bibr" rid="B20">1995</xref>; Reynolds et al., <xref ref-type="bibr" rid="B44">1999</xref>; Yantis and Egeth, <xref ref-type="bibr" rid="B51">1999</xref>). In order to promote survival and well-being, cognitive control settings must prioritize stimuli that will yield rewarding outcomes when selected. As task demands and reward contingencies change, individuals must be able to flexibly update these control settings. Converging evidence suggests that previous experiences as well as trait individual differences contribute to between-subject variance in cognitive flexibility (Hertwig et al., <xref ref-type="bibr" rid="B25">2004</xref>; Cools, <xref ref-type="bibr" rid="B17">2008</xref>; Hertwig and Ervev, <xref ref-type="bibr" rid="B26">2009</xref>). In particular, search history influences future control settings both within the same task as well as across seemingly diverse domains of cognition (Hills and Hertwig, <xref ref-type="bibr" rid="B31">2010</xref>; Hills et al., <xref ref-type="bibr" rid="B32">2010</xref>). However, the degree to which the stability of an environment's reward structure may persistently influence future cognitive control states remains poorly understood. In the current study, we therefore examined whether the rate at which reward contingencies unpredictably changed in the past influences future selection behavior, making an individual more or less prone to switch strategies.</p><p>When searching for a hidden reward, individuals may choose to explore the environment by testing new behavioral selections or to exploit selections that were rewarded in the past (see Cohen et al., <xref ref-type="bibr" rid="B16">2007</xref>). With limited time and resources, individuals must set a criterion for the amount of evidence required to stop selecting one option and begin selecting another in order to maximize reward. Recent evidence suggests that human observers follow Charnov's Marginal Value Theorem, a model of animal behavior, when searching for hidden rewards such that selection switches occur when the reward yield from the currently exploited selection falls below the overall average reward yield (Charnov, <xref ref-type="bibr" rid="B15">1976</xref>; Wolfe, <xref ref-type="bibr" rid="B49">2013</xref>). Individuals therefore tend to switch to an exploration strategy once an exploited selection begins to yield rewards at a rate that is below the expected value of the other options as a whole.</p><p>An individual's adoption of either exploration or exploitation strategies in the past primes future behavior. Hills and Hertwig (<xref ref-type="bibr" rid="B31">2010</xref>) had participants make selections between two alternatives with differing reward distributions. Participants were given feedback after each selection to allow for learning, but critically there were no monetary consequences based on participants' choices. Participants who frequently switched targets during this evaluation period tended to base a final consequential selection on discrete comparisons of individual trials and to underweight rare events. Conversely, those participants who did not switch frequently were more likely to choose whichever target had the overall larger average yield across the entire evaluation phase. Similarly, in another study, participants who engaged in exploitative search demonstrated more stable behaviors in a later lexical decision task than those who had previously engaged in explorative search (Hills et al., <xref ref-type="bibr" rid="B32">2010</xref>). Taken together, both studies provide evidence that individuals' previous selection strategies modulate current states of cognitive flexibility.</p><p>Existing tasks such as those used by Hills et al. (<xref ref-type="bibr" rid="B32">2010</xref>) and Hills and Hertwig (<xref ref-type="bibr" rid="B31">2010</xref>) do not account for situations in which reward contingencies in the environment change periodically and without warning. Under such changing conditions, individuals must decide when to update their predictions regarding the value of each potential selection. In a dynamic environment, any non-rewarded selection may be indicative of a decrement in the true underlying value of the selected object to below that of alternatives, or could simply result from a probabilistic instance of no reward following optimal selection. A stable strategy of cognitive control in which a particular object remains prioritized despite periodically missed rewards may be advantageous when the object-reward contingencies remain reliable and consistent. At the same time, this stable strategy may be disadvantageous under conditions in which such contingencies are subject to change unpredictably. Consequently, in the current experiment, we exposed participants to either an initial learning environment in which reward contingencies were held constant, or an environment in which contingencies could change without warning.</p><p>Although the influence of previously experienced reward contingency stability on future states of cognitive control remains unclear, both attentional priority and cognitive control processes are sensitive to reward learning (e.g., Anderson et al., <xref ref-type="bibr" rid="B3">2011b</xref>). Reward plays an important role in modulating attentional processing (e.g., Della Libera and Chelazzi, <xref ref-type="bibr" rid="B19">2009</xref>; Raymond and O'Brien, <xref ref-type="bibr" rid="B43">2009</xref>; Hickey et al., <xref ref-type="bibr" rid="B29">2010a</xref>,<xref ref-type="bibr" rid="B30">b</xref>) and through associative learning can create persistent changes in the attentional priority of stimuli (Anderson et al., <xref ref-type="bibr" rid="B2">2011a</xref>,<xref ref-type="bibr" rid="B3">b</xref>, <xref ref-type="bibr" rid="B4">2012</xref>, <xref ref-type="bibr" rid="B5">2013</xref>; Anderson and Yantis, <xref ref-type="bibr" rid="B6">2012</xref>, <xref ref-type="bibr" rid="B7">2013</xref>; see Anderson, <xref ref-type="bibr" rid="B1">2013</xref>, for a review). Furthermore, Jimura et al. (<xref ref-type="bibr" rid="B33">2010</xref>) found that reward influences proactive cognitive control: participants made faster judgments in a working memory task for experimental blocks in which accurate performance was sometimes rewarded than in blocks for which there was no available reward. This reward-based facilitation in response time as well as a corresponding neural correlate of sustained proactive control were both positively associated with individual differences in reward sensitivity. In the current experiment, we extend these previous findings regarding the role of reward learning on attentional priority and cognitive control to examine whether persistent changes in the stability of cognitive control settings can result from learned expectations concerning the consistency of object-reward contingencies.</p><p>Individual differences serve as a second potential source of variability in cognitive selection strategies. In particular, the construct of impulsivity has been linked to variation in cognitive flexibility (e.g., Cools, <xref ref-type="bibr" rid="B17">2008</xref>). Between-subject variation in impulsivity is attributed to concentrations of dopamine within the prefrontal cortex and striatum, which is governed by polymorphisms of the catechol-<italic>O</italic>-methyltransferase (COMT) and dopamine transporter (DAT) genes, respectively (Nolan et al., <xref ref-type="bibr" rid="B39">2004</xref>; Bertolino et al., <xref ref-type="bibr" rid="B10">2006</xref>; Cools, <xref ref-type="bibr" rid="B17">2008</xref>; B&#x000e9;dard et al., <xref ref-type="bibr" rid="B9">2010</xref>; Heatherton and Wagner, <xref ref-type="bibr" rid="B24">2011</xref>). Although previous research has associated impulsivity with a range of behavioral deficits and disorders such as drug abuse (Hester and Garavan, <xref ref-type="bibr" rid="B28">2004</xref>; Nielsen et al., <xref ref-type="bibr" rid="B38">2012</xref>; Papachristou et al., <xref ref-type="bibr" rid="B40">2012</xref>) and attention deficit hyperactivity disorder (ADHD; Cools, <xref ref-type="bibr" rid="B17">2008</xref>; B&#x000e9;dard et al., <xref ref-type="bibr" rid="B9">2010</xref>), healthy adults also demonstrate considerable variability in trait impulsivity (Patton et al., <xref ref-type="bibr" rid="B41">1995</xref>). Individual differences in impulsivity are associated with a preference for immediate reward and may therefore influence individuals' willingness to switch behavioral strategies following an unrewarded selection (Barkley, <xref ref-type="bibr" rid="B8">1997</xref>; Sonuga-Barke, <xref ref-type="bibr" rid="B45">2003</xref>; Tripp and Wickens, <xref ref-type="bibr" rid="B46">2008</xref>).</p><p>Given the existing evidence that previous experiences and trait impulsivity both influence future states of cognitive flexibility, in the current study, we investigated the unique contribution of both factors when accounting for behavioral selection strategies. Unlike previous studies of the impact of selection history on future control settings, we chose to manipulate across subjects the frequency with which participants needed to update reward predictions in an initial training phase. Specifically, we manipulated the frequency with which the more-highly rewarded object switched identity across participants. Participants selected a square on each trial, after which the location of a hidden reward was revealed. If they had selected the rewarded square, they obtained the reward. Half of the participants learned that the selection of a particularly colored square would lead to a monetary reward for the majority of trials throughout the entirety of the training phase. For the remainder of the participants, the most frequently rewarded color switched periodically and without warning. We refer to these two training conditions as stable and flexible, respectively. Immediately following the training phase, all participants completed a novel decision making task (test phase) in which the more-often rewarded object was defined by its spatial location. Critically, there was a consistent relationship between stimulus location and the likelihood of receiving reward for all participants, thus allowing comparison of choice strategy stability as a function of training history. First, we hypothesized that more impulsive individuals would make more variable choices during the test phase, being more influenced by recently missed rewards, regardless of training condition. Furthermore, we predicted that when statistically controlling for any variance in choice behavior associated with trait impulsivity, test phase selections would vary as a function of training history. Specifically, we predicted that participants in the stable training condition would engage in less variable choice behavior during the test phase and be less likely to switch object selections on a trial-by-trial basis than those in the flexible training group, reflecting a persistent shift in cognitive flexibility.</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and methods</title><sec><title>Participants</title><p>Sixty-two individuals (41 females) ranging in age from 18 to 33 (<italic>M</italic> = 21.3, <italic>SD</italic> = 3.21) completed the study in exchange for monetary compensation. All participants signed a consent form that was approved by the Johns Hopkins University Institutional Review Board. Participants were randomly assigned to the stable and flexible training groups. Data from one participant was excluded due to prior participation in a pilot study involving the same test phase. Data from a second participant was also excluded from all analyses because they produced no variability in selection (the same object was selected on every trial) in both the training and test phases despite being in the flexible training group.</p></sec><sec><title>Apparatus</title><p>Participants were seated facing an Asus VE247 LCD monitor that was connected to a Mac Mini computer. Stimulus presentation and response collection was controlled by the Psychophysics toolbox for Matlab (Brainard, <xref ref-type="bibr" rid="B12">1997</xref>). The monitor was positioned approximately 76 cm from the participant. Participants made all responses during the training phase using a standard computer mouse. Responses during the test phase were made using the four arrow keys of a standard keyboard. Both the keyboard and the mouse were positioned on a table in front of the participant.</p></sec><sec><title>Stimuli</title><sec><title>Training phase</title><p>On each trial, four colored squares (each 2.03 &#x000d7; 2.03<sup>&#x000b0;</sup> visual angle with an 2.03&#x000b0; gap between stimuli edge-to-edge) appeared along the horizontal meridian of the computer screen against a black background. These squares were positioned to the left and right of a central crosshairs and were rendered in red, green, blue, and yellow. A running total of the participant's earnings in the study was continuously displayed beneath the crosshairs, centered on the vertical meridian (see Figure <xref ref-type="fig" rid="F1">1A</xref>). After the selection of a square, reward feedback followed that consisted of a dollar sign appearing in one of the four squares along with either &#x0201c;+8&#x000a2;&#x0201d; or &#x0201c;+0&#x000a2;&#x0201d; indicated above the total earnings. The selected square became bold (line width increased from 1 to 10 pixels) to indicate its selection.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Sequence of events for training and test phase trials. (A)</bold> During training, participants selected a colored square to uncover a hidden reward. Participants accumulated money for each reward-containing square they selected. <bold>(B)</bold> During test, participants selected a square based on location. As in the training phase, they accumulated money for selecting a square containing a hidden reward.</p></caption><graphic xlink:href="fnint-07-00095-g0001"/></fig></sec><sec><title>Test phase</title><p>The stimuli were identical to those in the training phase with the exception that all four squares were white and positioned above, below, to the left, and to the right of the central crosshairs (7.17&#x000b0; center-to-center). A running total of the participant's earnings was again continuously displayed beneath the crosshairs, and the same feedback sequence again followed selection of a square (see Figure <xref ref-type="fig" rid="F1">1B</xref>).</p></sec><sec><title>Barratt impulsivity scale</title><p>Participants completed the Barratt Impulsivity Scale (BIS-11; Patton et al., <xref ref-type="bibr" rid="B41">1995</xref>). All but two participants completed the measure immediately prior to the training phase of the experimental task; one completed the BIS-11 5 days prior to participating in the current experiment and the other completed it 2 days after participating in the experimental task. The BIS-11 consists of 30 items such as &#x0201c;I say things without thinking,&#x0201d; and &#x0201c;I act on the spur of the moment.&#x0201d; For each item, participants rated the degree to which they engaged in the described behavior on a four-point scale ranging from (1) &#x0201c;Rarely/Never&#x0201d; to (4) &#x0201c;Almost Always.&#x0201d; We computed the total impulsivity score for each participant by summing the responses to all items. Omitted items on the questionnaire were assigned that subject's mean response; items for which a single participant selected more than one response were assigned the average of the two items. Scores on the BIS-11 ranged from 46 to 88 (<italic>M</italic> = 59.42, <italic>SD</italic> = 9.02).</p></sec></sec><sec><title>Procedure</title><sec><title>Training phase</title><p>Each of 240 trials began with the presentation of four colored squares, the arrangement of which was randomly determined. Participants moved a cursor on the screen using a computer mouse and selected a single square by clicking the left mouse button. Clicks outside of a colored square were not counted or recorded. Following the mouse click, the selected square's color outline was bolded for 1.5 s to indicate to the participant that the selection was registered. Next, a dollar sign appeared inside one of the four squares and was presented along with the bold outline of the selected square for an additional 1.5 s. If the participant had selected the square that had the dollar sign, 8&#x000a2; was added to their total earnings. Participants viewed reward feedback of either &#x0201c;+8&#x000a2;&#x0201d; or &#x0201c;+0&#x000a2;&#x0201d; for 1 s following the presentation of the dollar sign (see Figure <xref ref-type="fig" rid="F1">1A</xref>). At no point during the task was fixation enforced. If participants did not make a selection within 5 s, all of the squares became bolded for 1.5 s. All other aspects of the trial were the same as in those in which a response was made.</p><p>We manipulated, between subjects, the likelihood that each square would receive the hidden reward. For half of the participants (the stable training group), selection of a single color (counterbalanced across participants) was associated with the receipt of the reward on 70% of the training phase trials. The remaining three colored squares each contained the hidden reward on 10% of all trials. Participants in this first condition therefore received consistent contingencies in which one color was always the most likely to contain the hidden reward. Conversely, the remainder of participants received a flexible training schedule in which the color frequently containing the hidden reward was updated periodically and without notification. For participants in this condition, each of the four colored squares contained the hidden reward for 70% of all trials occurring during one of four 60 trial blocks. There was no break between blocks to indicate to participants when this switch occurred and we counterbalanced which color was most-often rewarded in the first block. The order in which the remaining colors were most-often rewarded was consistent across participants such that the order was always red, yellow, blue, green (red followed green such that one potential order was blue, green, red, yellow).</p></sec><sec><title>Test phase</title><p>Immediately following the training phase, all participants completed a 240 trial test phase in which we examined whether training history influenced choice behavior. Participants selected squares based on location using the four arrow keys of a standard keyboard (e.g., the right arrow key selected the square to the right of the central crosshairs). As in the training phase, the outline of the selected square became bold for 1.5 s and then a dollar sign was presented inside one of the squares for 1.5 s (see Figure <xref ref-type="fig" rid="F1">1B</xref>). Reward feedback was presented for 1 s prior to the onset of the next trial. All of the squares became bolded for 1.5 s following trials in which participants failed to make a selection within 5 s. A single square location (counterbalanced across participants) contained the hidden reward on 40% of all test phase trials; the remaining three locations each contained the hidden reward on 20% of trials. We set the reward contingencies among the four squares to be more similar in the test phase than in the training phase to make the optimal strategy less clear for the participants. Following completion of the test phase, participants were debriefed.</p></sec></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Training phase</title><p>We first examined choice behavior in the training phase. For participants in the flexible training group, there were three switches in the underlying reward structure, with each occurring after 60 trials of consistent reward contingencies. For each trial, we computed the percentage of participants who selected the most frequently rewarded square (referred to here as the optimal selection) within each block. The percentage of optimal selections across individuals on any trial therefore provided an estimation of when participants had converged on the optimal strategy according to the current contingencies. As illustrated in Figure <xref ref-type="fig" rid="F2">2</xref>, participants in both the flexible and stable conditions quickly learned the selection rule, settling on the optimal square. With the start of a new block, participants in the flexible training condition quickly adapted to the new reward contingencies and showed a strong tendency to select the newly-defined optimal square after a small number of trials. This rapid adjustment of behavior in response to a shift in reward contingencies provides evidence that our manipulation was effective.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Percentage of participants who selected the optimal square on each trial of the training phase</bold>. Participants who received flexible training quickly adjusted their behavior to the new reward contingencies within each block after a switch. Participants who received stable training maintained a single selection rule throughout the task.</p></caption><graphic xlink:href="fnint-07-00095-g0002"/></fig></sec><sec><title>Test phase</title><p>We next plotted the percentage of participants who selected the optimal target according to the test phase probabilities for each trial (see Figure <xref ref-type="fig" rid="F3">3</xref>). In order for any observed differences in how frequently participants deviate from the optimal strategy as a function of training condition to be meaningful, it is important that both training groups show evidence of rule learning. To determine the time course of rule learning in the test phase, we split the data into groups of 60 trials each. Beginning with the first 60 trials, and continuing throughout the entirety of the test phase, participants in both training groups were substantially more likely to pick the optimal target than would be expected if they had made all selections randomly (<italic>p</italic>'s &#x0003c; 0.001), demonstrating learning.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Percentage of participants who selected the optimal square on each trial of the test phase</bold>. Participants selected the optimal target at a greater rate than would be expected due to random guessing throughout the test phase following both stable and flexible training.</p></caption><graphic xlink:href="fnint-07-00095-g0003"/></fig><p>We computed three measures of choice flexibility to determine whether performance in the test phase varied as a function of the reward contingencies experienced during the training phase. First, we computed an index of choice variability for each participant, here referred to as the choice stability index. To compute the choice stability index, we calculated the total number of selections for each of the location-defined squares across the entire test phase. We then computed the standard deviation of the four square-selection sums as a measure of choice variability. A greater choice stability index means that a participant tended to select certain squares more frequently than others, while a low choice stability index reflects a more equal spread of selections across the four squares.</p><p>For the remaining two measures of choice flexibility, we categorized trials based on whether the participant's selection on the previous trial was rewarded. Out of the total number of trials following an unrewarded selection, we computed the percentage for which participants selected an object that differed from their previous selection. Similarly, for trials following a rewarded selection, we calculated the percentage of trials for which participants selected the same object as they had on the previous trial.</p><p>We first examined whether individual differences in impulsivity, as assessed with the BIS-11, were associated with variability in each of the three choice flexibility measures regardless of training history. As illustrated in Figures <xref ref-type="fig" rid="F4">4A,B</xref>, high impulsivity was associated with a greater percentage of selection switches following unrewarded selections, <italic>r</italic><sub>(58)</sub> = 0.32, <italic>p</italic> = 0.012, as well as a smaller percentage of selection repeats following rewarded selections, <italic>r</italic><sub>(58)</sub> = &#x02212;0.36, <italic>p</italic> = 0.005. Furthermore, there was a trend between trait impulsivity and choice stability index scores, <italic>r</italic><sub>(58)</sub> = &#x02212;0.25, <italic>p</italic> = 0.055, such that participants with greater trait impulsivity tended to make less stable selections during the test phase (see Figure <xref ref-type="fig" rid="F4">4C</xref>). Given the relationship between impulsivity and choice flexibility regardless of training condition, we report all group comparisons below with impulsivity score entered as a covariate to determine whether group differences exist when statistically controlling for individual differences in impulsivity.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Individual differences in trait impulsivity and selection behavior. (A)</bold> Relationship between individual differences in trait impulsivity and the percentage of object selection switches following an unrewarded selection during test. <bold>(B)</bold> Relationship between individual differences in trait impulsivity and the percentage of object selection repeats following a rewarded selection during test. <bold>(C)</bold> Relationship between individual differences in trait impulsivity and choice stability index during test. Each line denotes the best-fit linear regression equation when collapsing across training groups.</p></caption><graphic xlink:href="fnint-07-00095-g0004"/></fig><p>We conducted a 2 &#x000d7; 2 analysis of covariance (ANCOVA) with factors of training condition (stable vs. flexible) and experimental half (first vs. second) to determine the impact of reward history on future selection strategies. As mentioned above, impulsivity scores were entered into the model as a covariate. As illustrated in Figure <xref ref-type="fig" rid="F5">5A</xref>, there was a significant main effect of training condition, <italic>F</italic><sub>(1, 57)</sub> = 5.38, <italic>p</italic> = 0.024, such that participants made more variable selections in the test phase following the flexible training than following stable training. The main effect of experimental half failed to reach significance, <italic>F</italic><sub>(1, 57)</sub> &#x0003c; 0.01, <italic>p</italic> = 0.957, as did the interaction of experimental half and training condition, <italic>F</italic><sub>(1, 57)</sub> = 2.21, <italic>p</italic> = 0.142. As hypothesized, individuals who received unpredictably changing reward contingencies in the past made more variable selections during the test phase object selection task.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Behavioral results from the test phase. (A)</bold> Choice stability index as a function of training group. Participants continued to make less variable responses following the stable training than following the flexible training. <bold>(B)</bold> Percentage of trials following an unrewarded selection in which participants selected a different object than their previous selection, as a function of training group. <bold>(C)</bold> Percentage of trials following a rewarded selection in which participants made the same selection as they had on the previous trial, as a function of training group. Error bars denote 1 SE above and below the mean.</p></caption><graphic xlink:href="fnint-07-00095-g0005"/></fig><p>We next examined whether training history influenced the likelihood that individuals selected a different square than they had on the previous trial. First we investigated whether the percentage of selection switches made following an unrewarded selection varied as a function of training history or experimental half with a 2 &#x000d7; 2 ANCOVA with impulsivity added as a covariate. There were no significant main effects of training condition, <italic>F</italic><sub>(1, 57)</sub> = 1.69, <italic>p</italic> = 0.199, or experimental half, <italic>F</italic><sub>(1, 57)</sub> = 0.70, <italic>p</italic> = 0.408. As illustrated in Figure <xref ref-type="fig" rid="F5">5B</xref>, there was a significant interaction between experimental half and training condition, <italic>F</italic><sub>(1, 57)</sub> = 5.53, <italic>p</italic> = 0.022, such that although there was little difference between groups in the likelihood to switch following an unrewarded selection in the first half, a difference emerged in the second half. Participants who received stable training were less likely to switch following an unrewarded selection in the second half than participants who received flexible training. Next, we tested whether the percentage of selection repeats following a rewarded selection varied as a function of training history or experimental half with another 2 &#x000d7; 2 repeated measures ANCOVA. As above, impulsivity scores were again entered into the model as a covariate. The main effect of training condition, <italic>F</italic><sub>(1, 57)</sub> = 3.12, <italic>p</italic> = 0.083, as well as the main effect of experimental half, <italic>F</italic><sub>(1, 57)</sub> = 0.27, <italic>p</italic> = 0.605, again failed to reach statistical significance. However, there was a significant interaction between training condition and experimental half, <italic>F</italic><sub>(1, 57)</sub> = 4.55, <italic>p</italic> = 0.037, such that a group difference again emerged in the second half of the test phase (see Figure <xref ref-type="fig" rid="F5">5C</xref>). Participants who received stable training were more likely to repeat a selection following a rewarded trial than those who received flexible training.</p><p>Lastly, we examined the relationship between switching behavior in the training phase and choice variability in the test phase collapsed across both halves. There was a negative correlation between the percentage of switches made following unrewarded selections during training and the choice stability index during test, <italic>r</italic><sub>(58)</sub> = &#x02212;0.48, <italic>p</italic> &#x0003c; 0.001, and a positive correlation between the percentage of selection repeats following rewarded selections during training and the choice stability index during test, <italic>r</italic><sub>(58)</sub> = 0.38, <italic>p</italic> = 0.003 (see Figures <xref ref-type="fig" rid="F6">6A,B</xref>). These relationships were not specific to either the flexible or stable training condition, as indicated by direct comparison (<italic>p</italic>'s &#x0003e; 0.780). These correlations indicate that on an individual level, shifting strategy more often during training was associated with more variable selections during test.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Comparison of individuals' performance during training and test. (A)</bold> Relationship between the percentage of object selection switches following an unrewarded selection during training and choice stability index at test. <bold>(B)</bold> Relationship between the percentage of object selection repeats following a rewarded selection during training and choice stability index at test. Each line denotes the best-fit linear regression equation when collapsing across training groups.</p></caption><graphic xlink:href="fnint-07-00095-g0006"/></fig></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>In the current study, we examined whether the consistency of previous reward contingencies in a choice task influenced later selection strategies independent of individual differences in impulsivity. Across two phases of the experiment, participants selected stimuli in an attempt to acquire a hidden reward. We found that individual differences in trait impulsivity accounted for variability in selection behavior, such that participants with high trait impulsivity were more likely to switch selections following a trial in which they did not receive a reward and less likely to select the same object again after receiving reward than participants with low impulsivity. Furthermore, although the reward contingencies were identical for all participants in the test phase of the experiment, selection patterns differed as a function of reward history. When statistically controlling for impulsivity, we found that participants who learned that the reward contingencies changed periodically and without warning in the training phase (flexible training group) made more variable selections in the test phase than those who experienced consistent training contingencies (stable training group). Furthermore, we found evidence in the second half of the test phase that flexible training participants were more likely to switch object selections on a trial-by-trial basis regardless of whether their selection was rewarded on the previous trial.</p><p>Our results suggest that the consistency of reward contingencies in the past influenced the weighting of reward outcomes for guiding behavior in the test phase. Participants did not vary in the likelihood that they switched object selections on a trial-by-trial basis when collapsing across the entire test phase. However, we found an interaction with experimental half for both measures such that participants who received the consistent reward contingency training demonstrated a greater shift toward stable behavior as the experiment progressed than participants who received the changing reward consistency training. Performance was similar early in the test phase, as participants gained experience with the current location-based reward contingencies. As the test phase progressed and learning continued, participants could develop expectations concerning the underlying reward structure to guide behavior. Our results suggest that the gradual accumulation of evidence that a consistent object was more-often rewarded in the test phase was weighted differently in the determination of strategy selection depending on training history. Participants who received stable training were more likely to adopt and maintain a stable test phase selection strategy in response to the consistent contingencies despite periodically missed rewards.</p><p>Our findings are consistent with recent research on search and decision making in humans (Hertwig et al., <xref ref-type="bibr" rid="B25">2004</xref>; Hertwig and Ervev, <xref ref-type="bibr" rid="B26">2009</xref>; Hertwig and Pleskac, <xref ref-type="bibr" rid="B27">2010</xref>; Hills and Hertwig, <xref ref-type="bibr" rid="B31">2010</xref>; Hills et al., <xref ref-type="bibr" rid="B32">2010</xref>). Consistent with Hills and Hertwig (<xref ref-type="bibr" rid="B31">2010</xref>), we found that the experience of switching during an initial learning phase influenced later decisions. A difference between our paradigm and the search task used by Hills et al. (<xref ref-type="bibr" rid="B32">2010</xref>) was the content of the reward learning. Although participants learned to either exploit a single area or explore a wider range of areas in Hills and colleagues' previous search task, participants in the current study learned the likelihood that they would need to update a behavioral selection strategy. Monetary reinforcement therefore facilitated learning regarding the stability of the environment. Collectively, these findings provide converging evidence in favor of domain general reward-based modulations of cognitive control.</p><p>Our findings also build on recent research tying reward learning to the control of attention (e.g., Anderson et al., <xref ref-type="bibr" rid="B3">2011b</xref>). The voluntary and involuntary selection of objects based on reward history has been a topic of considerable interest in investigations of both animal and human cognition (Glimcher, <xref ref-type="bibr" rid="B22">2003</xref>; Della Libera and Chelazzi, <xref ref-type="bibr" rid="B19">2009</xref>; Peck et al., <xref ref-type="bibr" rid="B42">2009</xref>; Raymond and O'Brien, <xref ref-type="bibr" rid="B43">2009</xref>; Gottlieb and Balan, <xref ref-type="bibr" rid="B23">2010</xref>; Hickey et al., <xref ref-type="bibr" rid="B29">2010a</xref>,<xref ref-type="bibr" rid="B30">b</xref>; Anderson et al., <xref ref-type="bibr" rid="B2">2011a</xref>,<xref ref-type="bibr" rid="B3">b</xref>, <xref ref-type="bibr" rid="B4">2012</xref>, <xref ref-type="bibr" rid="B5">2013</xref>; Louie et al., <xref ref-type="bibr" rid="B36">2011</xref>; Anderson and Yantis, <xref ref-type="bibr" rid="B6">2012</xref>, <xref ref-type="bibr" rid="B7">2013</xref>). The results of the current study provide evidence that reward history not only serves a modulatory role for computations of attentional priority, but also modulates the flexibility of cognitive control. Importantly, in the current study, participants did not learn to associate value with any particular stimulus feature. Rather, participants across the two training groups learned the consistency of reward contingencies. This learned knowledge from the training phase influenced object selection in a novel test phase. Our findings therefore suggest that monetary reinforcement may modulate attentional selection and decision making even when reward learning is not directly tied to a stimulus feature.</p><p>Reward-based modulations of cognitive flexibility have important implications for the study of top-down attentional control. Sustained and transient components of cognitive control are sensitive to task demands as well as reward-induced motivation (Botvinick et al., <xref ref-type="bibr" rid="B11">2001</xref>; Braver et al., <xref ref-type="bibr" rid="B13">2003</xref>; Brown and Braver, <xref ref-type="bibr" rid="B14">2005</xref>; Jimura et al., <xref ref-type="bibr" rid="B33">2010</xref>). Furthermore, control processes are known to fluctuate such that individuals are at times in a greater state of preparation to perform a cognitive operation such as a task switch or shift of spatial attention (Leber et al., <xref ref-type="bibr" rid="B35">2008</xref>; Leber, <xref ref-type="bibr" rid="B34">2010</xref>). The results of our study suggest that reward history also influences preparatory cognitive control. Thus, reward learning may serve as one additional mechanism through which individuals update preparatory control based on previous experiences.</p><p>The results of the current study also have important implications for understanding deficits of attentional control, such as ADHD and drug abuse, in which individuals demonstrate a sensitivity to immediate rather than delayed reward (Barkley, <xref ref-type="bibr" rid="B8">1997</xref>; Cools, <xref ref-type="bibr" rid="B17">2008</xref>). Given our findings that reward history influences the flexibility of goal-directed selection, such sensitivity to reward may contribute to large modulations of cognitive control based on previous experiences. Furthermore, we found evidence that trait impulsivity scores predicted participants' tendency to switch selections, and deficits in impulsiveness have been linked to both ADHD (e.g., Barkley, <xref ref-type="bibr" rid="B8">1997</xref>; Mostofsky and Simmonds, <xref ref-type="bibr" rid="B37">2008</xref>) and drug addiction (e.g., Hester and Garavan, <xref ref-type="bibr" rid="B28">2004</xref>; Nielsen et al., <xref ref-type="bibr" rid="B38">2012</xref>; Papachristou et al., <xref ref-type="bibr" rid="B40">2012</xref>). Future research is needed to explore how dopaminergic dysfunctions in disorders such as ADHD (e.g., B&#x000e9;dard et al., <xref ref-type="bibr" rid="B9">2010</xref>; Heatherton and Wagner, <xref ref-type="bibr" rid="B24">2011</xref>), drug abuse (e.g., Volkow et al., <xref ref-type="bibr" rid="B47">2009</xref>), and obesity (e.g., Volkow et al., <xref ref-type="bibr" rid="B48">2011</xref>) are related to individual differences in impulsivity in healthy individuals and whether the neural mechanisms implicated in these disorders are influenced by rewards linked with states of cognitive control.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We thank H. Egeth for helpful comments on an earlier version of this manuscript, M. Hall for assistance with data collection, and N. Chan for assistance with BIS-11 scoring. The research was supported by U.S. National Institutes of Health grant R01-DA013165 to Steven Yantis, National Science Foundation GRFP DGE-0707427 to Anthony W. Sali, and U.S. National Institutes of Health NRSA Fellowship F31-DA033754 to Brian A. Anderson.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name></person-group> (<year>2013</year>). <article-title>A value-driven mechanism of attentional selection</article-title>. <source>J. Vis</source>. <volume>13</volume>, <fpage>1</fpage>&#x02013;<lpage>16</lpage>
<pub-id pub-id-type="doi">10.1167/13.3.7</pub-id><pub-id pub-id-type="pmid">23589803</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Laurent</surname><given-names>P. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2011a</year>). <article-title>Learned value magnifies salience-based attentional capture</article-title>. <source>PLoS ONE</source>
<volume>6</volume>:<issue>e27926</issue>
<pub-id pub-id-type="doi">10.1371/journal.pone.0027926</pub-id><pub-id pub-id-type="pmid">22132170</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Laurent</surname><given-names>P. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2011b</year>). <article-title>Value driven attentional capture</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>108</volume>, <fpage>10367</fpage>&#x02013;<lpage>10371</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1104047108</pub-id><pub-id pub-id-type="pmid">21646524</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Laurent</surname><given-names>P. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Generalization of value-based attentional priority</article-title>. <source>Vis. Cogn</source>. <volume>20</volume>, <fpage>647</fpage>&#x02013;<lpage>658</lpage>
<pub-id pub-id-type="doi">10.1080/13506285.2012.679711</pub-id><pub-id pub-id-type="pmid">24294102</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Laurent</surname><given-names>P. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>Reward predictions bias attentional selection</article-title>. <source>Front. Hum. Nuerosci</source>. <volume>7</volume>:<issue>262</issue>
<pub-id pub-id-type="doi">10.3389/fnhum.2013.00262</pub-id><pub-id pub-id-type="pmid">23781185</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <article-title>Value-driven attentional and oculomotor capture during goal-directed, unconstrained viewing</article-title>. <source>Atten. Percept. Psychophys</source>. <volume>74</volume>, <fpage>1644</fpage>&#x02013;<lpage>1653</lpage>
<pub-id pub-id-type="doi">10.3758/s13414-012-0348-2</pub-id><pub-id pub-id-type="pmid">22810561</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>B. A.</given-names></name><name><surname>Yantis</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>Persistence of value-driven attentional capture</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>39</volume>, <fpage>6</fpage>&#x02013;<lpage>9</lpage>
<pub-id pub-id-type="doi">10.1037/a0030860</pub-id><pub-id pub-id-type="pmid">23181684</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barkley</surname><given-names>R. A.</given-names></name></person-group> (<year>1997</year>). <article-title>Behavioral inhibition, sustained attention, and executive functions: constructing a unifying theory of ADHD</article-title>. <source>Psychol. Bull</source>. <volume>121</volume>, <issue>65</issue>&#x02013;<lpage>94</lpage>
<pub-id pub-id-type="doi">10.1037/0033-2909.121.1.65</pub-id><pub-id pub-id-type="pmid">9000892</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000e9;dard</surname><given-names>A.-C.</given-names></name><name><surname>Schulz</surname><given-names>K. P.</given-names></name><name><surname>Cook</surname><given-names>E. H.</given-names></name><name><surname>Fan</surname><given-names>J.</given-names></name><name><surname>Clerkin</surname><given-names>S. M.</given-names></name><name><surname>Ivanov</surname><given-names>I.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Dopamine transporter gene variation modulates activation of striatum in youth with ADHD</article-title>. <source>Neuroimage</source>
<volume>53</volume>, <fpage>935</fpage>&#x02013;<lpage>942</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.041</pub-id><pub-id pub-id-type="pmid">20026227</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bertolino</surname><given-names>A.</given-names></name><name><surname>Blasi</surname><given-names>G.</given-names></name><name><surname>Latorre</surname><given-names>V.</given-names></name><name><surname>Rubino</surname><given-names>V.</given-names></name><name><surname>Rampino</surname><given-names>A.</given-names></name><name><surname>Sinibaldi</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2006</year>). <article-title>Additive effects of genetic variation in dopamine regulating genes on working memory cortical activity in human brain</article-title>. <source>J. Neurosci</source>. <volume>26</volume>, <fpage>3918</fpage>&#x02013;<lpage>3922</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4975-05.2006</pub-id><pub-id pub-id-type="pmid">16611807</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M. M.</given-names></name><name><surname>Braver</surname><given-names>T. S.</given-names></name><name><surname>Barch</surname><given-names>D. M.</given-names></name><name><surname>Carter</surname><given-names>C. S.</given-names></name><name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2001</year>). <article-title>Conflict monitoring and cognitive control</article-title>. <source>Psychol. Rev</source>. <volume>108</volume>, <issue>624</issue>&#x02013;<lpage>652</lpage>
<pub-id pub-id-type="doi">10.1037/0033-295X.108.3.624</pub-id><pub-id pub-id-type="pmid">11488380</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>D. H.</given-names></name></person-group> (<year>1997</year>). <article-title>The psychophysics toolbox</article-title>. <source>Spat. Vis</source>. <volume>10</volume>, <fpage>433</fpage>&#x02013;<lpage>436</lpage>
<pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braver</surname><given-names>T. S.</given-names></name><name><surname>Reynolds</surname><given-names>J. R.</given-names></name><name><surname>Donaldson</surname><given-names>D. I.</given-names></name></person-group> (<year>2003</year>). <article-title>Neural mechanisms of transient and sustained cognitive control during task switching</article-title>. <source>Neuron</source>
<volume>39</volume>, <fpage>713</fpage>&#x02013;<lpage>726</lpage>
<pub-id pub-id-type="doi">10.1016/S0896-6273(03)00466-5</pub-id><pub-id pub-id-type="pmid">12925284</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J. W.</given-names></name><name><surname>Braver</surname><given-names>T. S.</given-names></name></person-group> (<year>2005</year>). <article-title>Learned predictions of error likelihood in the anterior cingulate cortex</article-title>. <source>Science</source>
<volume>307</volume>, <fpage>1118</fpage>&#x02013;<lpage>1121</lpage>
<pub-id pub-id-type="doi">10.1126/science.1105783</pub-id><pub-id pub-id-type="pmid">15718473</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charnov</surname><given-names>E. L.</given-names></name></person-group> (<year>1976</year>). <article-title>Optimal foraging, the marginal value theorem</article-title>. <source>Theor. Popul. Biol</source>. <volume>9</volume>, <fpage>129</fpage>&#x02013;<lpage>136</lpage>
<pub-id pub-id-type="doi">10.1016/0040-5809(76)90040-X</pub-id><pub-id pub-id-type="pmid">1273796</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J. D.</given-names></name><name><surname>McClure</surname><given-names>S. M.</given-names></name><name><surname>Yu</surname><given-names>A. J.</given-names></name></person-group> (<year>2007</year>). <article-title>Should I stay or should I go? How the human brain manages the trade-off between exploration and exploitation</article-title>. <source>Philos. Trans. R. Soc. B. Biol. Sci</source>. <volume>362</volume>, <fpage>933</fpage>&#x02013;<lpage>942</lpage>
<pub-id pub-id-type="doi">10.1098/rstb.2007.2098</pub-id><pub-id pub-id-type="pmid">17395573</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Role of dopamine in the motivational and cognitive control of behaviors</article-title>. <source>Neuroscientist</source>
<volume>14</volume>, <fpage>381</fpage>&#x02013;<lpage>395</lpage>
<pub-id pub-id-type="doi">10.1177/1073858408317009</pub-id><pub-id pub-id-type="pmid">18660464</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M.</given-names></name><name><surname>Shulman</surname><given-names>G. L.</given-names></name></person-group> (<year>2002</year>). <article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>3</volume>, <fpage>201</fpage>&#x02013;<lpage>215</lpage>
<pub-id pub-id-type="doi">10.1038/nrn755</pub-id><pub-id pub-id-type="pmid">11994752</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Della Libera</surname><given-names>C.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name></person-group> (<year>2009</year>). <article-title>Learning to attend and to ignore is a matter of gains and losses</article-title>. <source>Psychol. Sci</source>. <volume>20</volume>, <fpage>778</fpage>&#x02013;<lpage>784</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02360.x</pub-id><pub-id pub-id-type="pmid">19422618</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Duncan</surname><given-names>J.</given-names></name></person-group> (<year>1995</year>). <article-title>Neural mechanisms of selective visual attention</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>18</volume>, <fpage>193</fpage>&#x02013;<lpage>222</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.ne.18.030195.001205</pub-id><pub-id pub-id-type="pmid">7605061</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Folk</surname><given-names>C. L.</given-names></name><name><surname>Remington</surname><given-names>R. W.</given-names></name><name><surname>Johnston</surname><given-names>J. C.</given-names></name></person-group> (<year>1992</year>). <article-title>Involuntary covert orienting is contingent on attentional control settings</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>18</volume>, <issue>1030</issue>&#x02013;<lpage>1044</lpage>
<pub-id pub-id-type="doi">10.1037/0096-1523.18.4.1030</pub-id><pub-id pub-id-type="pmid">1431742</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>2003</year>). <article-title>The neurobiology of visual-saccadic decision making</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>26</volume>, <fpage>133</fpage>&#x02013;<lpage>179</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.neuro.26.010302.081134</pub-id><pub-id pub-id-type="pmid">14527268</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottlieb</surname><given-names>J.</given-names></name><name><surname>Balan</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>). <article-title>Attention as a decision in information space</article-title>. <source>Trends Cogn. Sci</source>. <volume>14</volume>, <fpage>240</fpage>&#x02013;<lpage>248</lpage>
<pub-id pub-id-type="doi">10.1016/j.tics.2010.03.001</pub-id><pub-id pub-id-type="pmid">20399701</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heatherton</surname><given-names>T. F.</given-names></name><name><surname>Wagner</surname><given-names>D. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Cognitive neuroscience of self-regulation failure</article-title>. <source>Trends Cogn. Sci</source>. <volume>15</volume>, <fpage>132</fpage>&#x02013;<lpage>139</lpage>
<pub-id pub-id-type="doi">10.1016/j.tics.2010.12.005</pub-id><pub-id pub-id-type="pmid">21273114</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertwig</surname><given-names>R.</given-names></name><name><surname>Barron</surname><given-names>G.</given-names></name><name><surname>Weber</surname><given-names>E. U.</given-names></name><name><surname>Erev</surname><given-names>I.</given-names></name></person-group> (<year>2004</year>). <article-title>Decisions from experience and the effect of rare events in risky choice</article-title>. <source>Psychol. Sci</source>. <volume>15</volume>, <fpage>534</fpage>&#x02013;<lpage>539</lpage>
<pub-id pub-id-type="doi">10.1111/j.0956-7976.2004.00715.x</pub-id><pub-id pub-id-type="pmid">15270998</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertwig</surname><given-names>R.</given-names></name><name><surname>Ervev</surname><given-names>I.</given-names></name></person-group> (<year>2009</year>). <article-title>The description-experience gap in risky choice</article-title>. <source>Trends Cogn. Sci</source>. <volume>13</volume>, <fpage>517</fpage>&#x02013;<lpage>523</lpage>
<pub-id pub-id-type="doi">10.1016/j.tics.2009.09.004</pub-id><pub-id pub-id-type="pmid">19836292</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertwig</surname><given-names>R.</given-names></name><name><surname>Pleskac</surname><given-names>T. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Decisions from experience: why small samples?</article-title>
<source>Cognition</source>
<volume>115</volume>, <fpage>225</fpage>&#x02013;<lpage>237</lpage>
<pub-id pub-id-type="doi">10.1016/j.cognition.2009.12.009</pub-id><pub-id pub-id-type="pmid">20092816</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hester</surname><given-names>R.</given-names></name><name><surname>Garavan</surname><given-names>H.</given-names></name></person-group> (<year>2004</year>). <article-title>Executive dysfunction in cocaine addiction: evidence for discordant frontal, cingulate, and cerebellar activity</article-title>. <source>J. Neurosci</source>. <volume>24</volume>, <fpage>11017</fpage>&#x02013;<lpage>11022</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3321-04.2004</pub-id><pub-id pub-id-type="pmid">15590917</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickey</surname><given-names>C.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Theeuwes</surname><given-names>J.</given-names></name></person-group> (<year>2010a</year>). <article-title>Reward changes salience in human vision via the anterior cingulate</article-title>. <source>J. Neurosci</source>. <volume>30</volume>, <fpage>11096</fpage>&#x02013;<lpage>11103</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1026-10.2010</pub-id><pub-id pub-id-type="pmid">20720117</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickey</surname><given-names>C.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Theeuwes</surname><given-names>J.</given-names></name></person-group> (<year>2010b</year>). <article-title>Reward guides vision when it's your thing: trait reward-seeking in reward-mediated visual priming</article-title>. <source>PLoS ONE</source>
<volume>5</volume>:<issue>e14087</issue>
<pub-id pub-id-type="doi">10.1371/journal.pone.0014087</pub-id><pub-id pub-id-type="pmid">21124893</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hills</surname><given-names>T. T.</given-names></name><name><surname>Hertwig</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Information search in decisions from experience: do our patterns of sampling foreshadow our decisions</article-title>. <source>Psychol. Sci</source>. <volume>21</volume>, <fpage>1787</fpage>&#x02013;<lpage>1792</lpage>
<pub-id pub-id-type="doi">10.1177/0956797610387443</pub-id><pub-id pub-id-type="pmid">20974711</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hills</surname><given-names>T. T.</given-names></name><name><surname>Todd</surname><given-names>P. M.</given-names></name><name><surname>Goldstone</surname><given-names>R. L.</given-names></name></person-group> (<year>2010</year>). <article-title>The central executive as a search process: priming exploration and exploitation across domains</article-title>. <source>J. Exp. Psychol. Gen</source>. <volume>139</volume>, <fpage>590</fpage>&#x02013;<lpage>609</lpage>
<pub-id pub-id-type="doi">10.1037/a0020666</pub-id><pub-id pub-id-type="pmid">21038983</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jimura</surname><given-names>K.</given-names></name><name><surname>Locke</surname><given-names>H. S.</given-names></name><name><surname>Braver</surname><given-names>T. S.</given-names></name></person-group> (<year>2010</year>). <article-title>Prefrontal cortex mediation of cognitive enhancement in rewarding motivational contexts</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>107</volume>, <fpage>8871</fpage>&#x02013;<lpage>8876</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1002007107</pub-id><pub-id pub-id-type="pmid">20421489</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leber</surname><given-names>A. B.</given-names></name></person-group> (<year>2010</year>). <article-title>Neural predictors of within-subject fluctuations in attentional control</article-title>. <source>J. Neurosci</source>. <volume>30</volume>, <fpage>11458</fpage>&#x02013;<lpage>11465</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0809-10.2010</pub-id><pub-id pub-id-type="pmid">20739567</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leber</surname><given-names>A. B.</given-names></name><name><surname>Turk-Browne</surname><given-names>N. B.</given-names></name><name><surname>Chun</surname><given-names>M. M.</given-names></name></person-group> (<year>2008</year>). <article-title>Neural predictors of moment-to-moment fluctuations in cognitive flexibility</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>105</volume>, <fpage>13592</fpage>&#x02013;<lpage>13597</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.0805423105</pub-id><pub-id pub-id-type="pmid">18757744</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Louie</surname><given-names>K.</given-names></name><name><surname>Grattan</surname><given-names>L. E.</given-names></name><name><surname>Glimcher</surname><given-names>P. W.</given-names></name></person-group> (<year>2011</year>). <article-title>Reward value-based gain control: divisive normalization in parietal cortex</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>10627</fpage>&#x02013;<lpage>10639</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1237-11.2011</pub-id><pub-id pub-id-type="pmid">21775606</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mostofsky</surname><given-names>S. H.</given-names></name><name><surname>Simmonds</surname><given-names>D. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Response inhibition and response selection: two sides of the same coin</article-title>. <source>J. Cogn. Neurosci</source>. <volume>20</volume>, <fpage>751</fpage>&#x02013;<lpage>761</lpage>
<pub-id pub-id-type="doi">10.1162/jocn.2008.20500</pub-id><pub-id pub-id-type="pmid">18201122</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>D. A.</given-names></name><name><surname>Ho</surname><given-names>A.</given-names></name><name><surname>Bahl</surname><given-names>A.</given-names></name><name><surname>Varma</surname><given-names>P.</given-names></name><name><surname>Kellogg</surname><given-names>S.</given-names></name><name><surname>Borg</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Former heroin addicts with and without a history of cocaine dependence are more impulsive than controls</article-title>. <source>Drug Alcohol Depend</source>. <volume>124</volume>, <fpage>113</fpage>&#x02013;<lpage>120</lpage>
<pub-id pub-id-type="doi">10.1016/j.drugalcdep.2011.12.022</pub-id><pub-id pub-id-type="pmid">22265192</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nolan</surname><given-names>K.</given-names></name><name><surname>Bilder</surname><given-names>R.</given-names></name><name><surname>Lachman</surname><given-names>H.</given-names></name><name><surname>Volavka</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>Catechol O-methyl- transferase Val158Met polymorphism in schizophrenia: differential effects of Val and Met alleles on cognitive stability and flexibility</article-title>. <source>Am. J. Psychiatry</source>
<volume>161</volume>, <issue>359</issue>&#x02013;<lpage>361</lpage>
<pub-id pub-id-type="doi">10.1176/appi.ajp.161.2.359</pub-id><pub-id pub-id-type="pmid">14754787</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papachristou</surname><given-names>H.</given-names></name><name><surname>Nederkoorn</surname><given-names>C.</given-names></name><name><surname>Havermans</surname><given-names>R.</given-names></name><name><surname>van der Horst</surname><given-names>M.</given-names></name><name><surname>Jansen</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>Can't stop the craving: the effect of impulsivity on cue-elicited craving for alcohol in heavy and light social drinkers</article-title>. <source>Psychopharmacology (Berlin)</source>
<volume>219</volume>, <fpage>511</fpage>&#x02013;<lpage>518</lpage>
<pub-id pub-id-type="doi">10.1007/s00213-011-2240-5</pub-id><pub-id pub-id-type="pmid">21384105</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patton</surname><given-names>J. H.</given-names></name><name><surname>Stanford</surname><given-names>M. S.</given-names></name><name><surname>Barratt</surname><given-names>E. S.</given-names></name></person-group> (<year>1995</year>). <article-title>Factor structure of the Barratt Impulsiveness Scale</article-title>. <source>J. Clin. Psychol</source>. <volume>51</volume>, <fpage>768</fpage>&#x02013;<lpage>774</lpage>
<pub-id pub-id-type="doi">10.1002/1097-4679(199511)51:6&#x0003c;768::AID-JCLP2270510607&#x0003e;3.0.CO;2-1</pub-id><pub-id pub-id-type="pmid">8778124</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peck</surname><given-names>C. J.</given-names></name><name><surname>Jangraw</surname><given-names>D. C.</given-names></name><name><surname>Suzuki</surname><given-names>M.</given-names></name><name><surname>Efem</surname><given-names>R.</given-names></name><name><surname>Gottlieb</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>Reward modulates attention independently of action value in posterior parietal cortex</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>11182</fpage>&#x02013;<lpage>11191</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1929-09.2009</pub-id><pub-id pub-id-type="pmid">19741125</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname><given-names>J. E.</given-names></name><name><surname>O'Brien</surname><given-names>J. L.</given-names></name></person-group> (<year>2009</year>). <article-title>Selective visual attention and motivation: the consequences of value learning in an attentional blink task</article-title>. <source>Psychol. Sci</source>. <volume>20</volume>, <fpage>981</fpage>&#x02013;<lpage>988</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02391.x</pub-id><pub-id pub-id-type="pmid">19549080</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>J. H.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1999</year>). <article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4</article-title>. <source>J. Neurosci</source>. <volume>19</volume>, <fpage>1736</fpage>&#x02013;<lpage>1753</lpage>
<pub-id pub-id-type="pmid">10024360</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sonuga-Barke</surname><given-names>E. J.</given-names></name></person-group> (<year>2003</year>). <article-title>The dual pathway model of AD/HD: an elaboration of neuro-developmental characteristics</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>27</volume>, <fpage>593</fpage>&#x02013;<lpage>604</lpage>
<pub-id pub-id-type="doi">10.1016/j.neubiorev.2003.08.005</pub-id><pub-id pub-id-type="pmid">14624804</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tripp</surname><given-names>G.</given-names></name><name><surname>Wickens</surname><given-names>J. R.</given-names></name></person-group> (<year>2008</year>). <article-title>Research review: dopamine transfer deficit: a neurobiological theory of altered reinforcement mechanisms in ADHD</article-title>. <source>J. Child Psychol. Psychiatry</source>
<volume>49</volume>, <fpage>691</fpage>&#x02013;<lpage>704</lpage>
<pub-id pub-id-type="doi">10.1111/j.1469-7610.2007.01851.x</pub-id><pub-id pub-id-type="pmid">18081766</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volkow</surname><given-names>N. D.</given-names></name><name><surname>Wang</surname><given-names>G. L.</given-names></name><name><surname>Kollins</surname><given-names>S. H.</given-names></name><name><surname>Wigal</surname><given-names>T. L.</given-names></name><name><surname>Newcorn</surname><given-names>J. H.</given-names></name><name><surname>Telang</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>Evaluating dopamine reward pathway in ADHD: clinical implications</article-title>. <source>JAMA</source>
<volume>302</volume>, <fpage>1084</fpage>&#x02013;<lpage>1091</lpage>
<pub-id pub-id-type="doi">10.1001/jama.2009.1308</pub-id><pub-id pub-id-type="pmid">19738093</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volkow</surname><given-names>N. D.</given-names></name><name><surname>Wang</surname><given-names>G.-J.</given-names></name><name><surname>Baler</surname><given-names>R. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Reward, dopamine and the control of food intake: implications for obesity</article-title>. <source>Trends Cogn. Sci</source>. <volume>15</volume>, <fpage>37</fpage>&#x02013;<lpage>46</lpage>
<pub-id pub-id-type="doi">10.1016/j.tics.2010.11.001</pub-id><pub-id pub-id-type="pmid">21109477</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>J. M.</given-names></name></person-group> (<year>2013</year>). <article-title>When is it time to move to the next raspberry bush? Foraging rules in human visual search</article-title>. <source>J. Vis</source>. <volume>13</volume>, <fpage>1</fpage>&#x02013;<lpage>17</lpage>
<pub-id pub-id-type="doi">10.1167/13.3.10</pub-id><pub-id pub-id-type="pmid">23641077</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>J. M.</given-names></name><name><surname>Cave</surname><given-names>K. R.</given-names></name><name><surname>Franzel</surname><given-names>S. L.</given-names></name></person-group> (<year>1989</year>). <article-title>Guided search: an alternative to the feature integration model for visual search</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>15</volume>, <issue>419</issue>&#x02013;<lpage>433</lpage>
<pub-id pub-id-type="doi">10.1037/0096-1523.15.3.419</pub-id><pub-id pub-id-type="pmid">2527952</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yantis</surname><given-names>S.</given-names></name><name><surname>Egeth</surname><given-names>H. E.</given-names></name></person-group> (<year>1999</year>). <article-title>On the distinction between visual salience and stimulus-driven attentional capture</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>25</volume>, <issue>661</issue>&#x02013;<lpage>676</lpage>
<pub-id pub-id-type="doi">10.1037/0096-1523.25.3.661</pub-id><pub-id pub-id-type="pmid">10385983</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yantis</surname><given-names>S.</given-names></name><name><surname>Johnston</surname><given-names>J. C.</given-names></name></person-group> (<year>1990</year>). <article-title>On the locus of visual selection: evidence from focused attention tasks</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>16</volume>, <issue>135</issue>&#x02013;<lpage>149</lpage>
<pub-id pub-id-type="doi">10.1037/0096-1523.16.1.135</pub-id><pub-id pub-id-type="pmid">2137515</pub-id></mixed-citation></ref></ref-list></back></article>