<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Alzheimers Dement (N Y)</journal-id><journal-id journal-id-type="iso-abbrev">Alzheimers Dement (N Y)</journal-id><journal-title-group><journal-title>Alzheimer's &#x00026; Dementia : Translational Research &#x00026; Clinical Interventions</journal-title></journal-title-group><issn pub-type="epub">2352-8737</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29067328</article-id><article-id pub-id-type="pmc">5651423</article-id><article-id pub-id-type="publisher-id">S2352-8737(17)30006-9</article-id><article-id pub-id-type="doi">10.1016/j.trci.2017.01.006</article-id><article-categories><subj-group subj-group-type="heading"><subject>Featured Article</subject></subj-group></article-categories><title-group><article-title>Predicting mild cognitive impairment from spontaneous spoken utterances</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Asgari</surname><given-names>Meysam</given-names></name><email>asgari@ohsu.edu</email><xref rid="aff1" ref-type="aff">a</xref><xref rid="cor1" ref-type="corresp">&#x02217;</xref></contrib><contrib contrib-type="author"><name><surname>Kaye</surname><given-names>Jeffrey</given-names></name><xref rid="aff2" ref-type="aff">b</xref></contrib><contrib contrib-type="author"><name><surname>Dodge</surname><given-names>Hiroko</given-names></name><xref rid="aff2" ref-type="aff">b</xref><xref rid="aff3" ref-type="aff">c</xref></contrib></contrib-group><aff id="aff1"><label>a</label>Center for Spoken Language Understanding, Oregon Health &#x00026; Science University (OHSU), Portland, Oregon, USA</aff><aff id="aff2"><label>b</label>Department of Neurology, Layton Aging and Alzheimer's Disease Center, Oregon Health &#x00026; Science University (OHSU), Portland, Oregon, USA</aff><aff id="aff3"><label>c</label>Department of Neurology, Michigan Alzheimer's Disease Center, University of Michigan, Ann Arbor, Michigan, USA</aff><author-notes><corresp id="cor1"><label>&#x02217;</label>Corresponding author. Tel.: 503-346-3752; Fax: 503-346-3754. <email>asgari@ohsu.edu</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>27</day><month>2</month><year>2017</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>6</month><year>2017</year></pub-date><pub-date pub-type="epub"><day>27</day><month>2</month><year>2017</year></pub-date><volume>3</volume><issue>2</issue><fpage>219</fpage><lpage>228</lpage><permissions><copyright-statement>&#x000a9; 2017 The Authors</copyright-statement><copyright-year>2017</copyright-year><license license-type="CC BY-NC-ND" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><abstract id="abs0010"><sec><title>Introduction</title><p>Trials in Alzheimer's disease are increasingly focusing on prevention in asymptomatic individuals. We hypothesized that indicators of mild cognitive impairment (MCI) may be present in the content of spoken language in older adults and be useful in distinguishing those with MCI from those who are cognitively intact. To test this hypothesis, we performed linguistic analyses of spoken words in participants with MCI and those with intact cognition participating in a clinical trial.</p></sec><sec><title>Methods</title><p>Data came from a randomized controlled behavioral clinical trial to examine the effect of unstructured conversation on cognitive function among older adults with either normal cognition or MCI (<ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov" id="intref0010">ClinicalTrials.gov</ext-link>: <ext-link ext-link-type="uri" xlink:href="ctgov:NCT01571427" id="intref0015">NCT01571427</ext-link>). Unstructured conversations (but with standardized preselected topics across subjects) were recorded between interviewers and interviewees during the intervention sessions of the trial from 14 MCI and 27 cognitively intact participants. From the transcription of interviewees recordings, we grouped spoken words using Linguistic Inquiry and Word Count (LIWC), a structured table of words, which categorizes 2500 words into 68 different word subcategories such as positive and negative words, fillers, and physical states. The number of words in each LIWC word subcategory constructed a vector of 68 dimensions representing the linguistic features of each subject. We used support vector machine and random forest classifiers to distinguish MCI from cognitively intact participants.</p></sec><sec><title>Results</title><p>MCI participants were distinguished from those with intact cognition using linguistic features obtained by LIWC with 84% classification accuracy which is well above chance 60%.</p></sec><sec><title>Discussion</title><p>Linguistic analyses of spoken language may be a powerful tool in distinguishing MCI subjects from those with intact cognition. Further studies to assess whether spoken language derived measures could detect changes in cognitive functions in clinical trials are warrented.</p></sec></abstract><kwd-group id="kwrds0010"><title>Keywords</title><kwd>Biomarkers</kwd><kwd>Conversational interactions</kwd><kwd>Early identification</kwd><kwd>Mild cognitive impairment (MCI)</kwd><kwd>Social markers</kwd><kwd>Speech characteristics</kwd></kwd-group></article-meta></front><body><sec id="sec1"><label>1</label><title>Introduction and motivation</title><p>A well-documented literature has identified characteristic early disruption of normative patterns and processing of speech and language in patients with Alzheimer's disease (AD) as well as in prodromal dementia states such as mild cognitive impairment (MCI) <xref rid="bib1" ref-type="bibr">[1]</xref>. Early foundational clinical studies of language have highlighted changes in verbal fluency and naming <xref rid="bib2" ref-type="bibr">[2]</xref>, <xref rid="bib3" ref-type="bibr">[3]</xref>, <xref rid="bib4" ref-type="bibr">[4]</xref>. More recent studies using automated or semiautomated speech and language analysis approaches have identified linguistic as well as acoustic features that characterize early AD or MCI such as pause frequency and duration, and linguistic complexity measures <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib6" ref-type="bibr">[6]</xref>.</p><p>Almost all of these latter studies have used elicited speech paradigms to generate speech and language samples, for example, asking patients to describe what they observe in pictures briefly presented to them or to recall specific stories they are exposed to during a testing session. In addition to analyzing the conversations in these structured, mostly constrained within a clinical setting, there are some studies which have used more spontaneous speech <xref rid="bib7" ref-type="bibr">[7]</xref>, <xref rid="bib8" ref-type="bibr">[8]</xref>. In spite of the potential advantages of capturing spontaneous speech in conversations, major barriers have existed to implementing this approach for persons with MCI or AD in more natural settings. A major impediment has been limitations in the recording technology paradigms that could be deployed. This has been both a problem of practicality such as the form factor of recording devices and power requirements for long-term recording, as well as automated speech and linguistic analysis challenges. Despite these challenges, pioneering early studies using somewhat obtrusive worn or carried recording devices have shown the potential power of this approach in younger populations. For example, Pennebaker and Mehl have illustrated the value of inferring social contexts from audio life logs using a lexicon of salient words, termed Linguistic Inquiry and Word Count (LIWC) 2001 <xref rid="bib9" ref-type="bibr">[9]</xref>. They demonstrated that social context and other information from audio life logs can be used to quantify participants' social life (interaction and engagement), cognitive function, emotional conditions, and even health status <xref rid="bib10" ref-type="bibr">[10]</xref>. To the best of our knowledge, LIWC analyses have not been used to examine the cognitive status of older adults. In this study, we use LIWC on a corpus of spontaneous speech samples generated during the course of a 6-week randomized clinical trial of daily online video chats to improve social engagement and cognition in older adults with and without MCI <xref rid="bib11" ref-type="bibr">[11]</xref>, <xref rid="bib12" ref-type="bibr">[12]</xref>. These conversations between the interviewer and the participant provided an opportunity to analyze potential differences in the conversational output of persons with MCI and cognitively intact adults.</p><sec id="sec1.1"><label>1.1</label><title>Language and mild cognitive impairment</title><p>Although the most typical early cognitive deficit observed in Alzheimer's disease involves the memory domain, linguistic ability is also clearly affected. For example, secondary verbs per utterance, percentage of clauses, percentage of right-branching and left-branching clauses, propositions per utterance, conjunctions per utterance, mean duration of pauses, and standardized phonation time have all been reported to show significant differences between healthy older adults and subjects with MCI or AD <xref rid="bib5" ref-type="bibr">[5]</xref>, <xref rid="bib13" ref-type="bibr">[13]</xref>, <xref rid="bib14" ref-type="bibr">[14]</xref>, <xref rid="bib15" ref-type="bibr">[15]</xref>, <xref rid="bib16" ref-type="bibr">[16]</xref>, <xref rid="bib17" ref-type="bibr">[17]</xref>, <xref rid="bib18" ref-type="bibr">[18]</xref>, <xref rid="bib19" ref-type="bibr">[19]</xref>, <xref rid="bib20" ref-type="bibr">[20]</xref>. A major barrier to taking advantage of these language-based discriminators has been the effort required to manually score relevant features from speech samples; the proposed work addresses this through automatic scoring.</p><sec id="sec1.1.1"><label>1.1.1</label><title>Related computational works</title><p>Recently, there has been considerable interest in automatically analyzing acoustic and language properties of speech samples to create more sensitive quantitative assessments of patients with cognitive impairment <xref rid="bib1" ref-type="bibr">[1]</xref>, <xref rid="bib21" ref-type="bibr">[21]</xref>, <xref rid="bib22" ref-type="bibr">[22]</xref>, <xref rid="bib23" ref-type="bibr">[23]</xref>. For example, Jerrold and colleagues <xref rid="bib24" ref-type="bibr">[24]</xref> evaluated the ability of machine learning methods to differentiate dementia subtypes, including AD, based on semistructured conversational speech recordings. Their proposed method uses both acoustic features such as duration of consonants, vowels, and pauses, as well as lexical features such as frequency of nouns and verbs derived from automatic transcriptions provided by a speaker-independent automatic speech recognition (ASR) system.</p><p>Combining these two profiles of features derived from 48 participants, including nine healthy controls, nine AD patients, and 30 frontotemporal lobar degeneration (FTLD) patients (nine with behavioral variant frontotemporal dementia, 13 with semantic dementia, and eight with progressive nonfluent aphasia), they obtained 61% accuracy in detecting the subjects' FTLD subtype, significantly better than the random diagnosis condition, which had 20% accuracy. In a binary classification setting, they obtained 88% accuracy in distinguishing nine participants with AD from nine healthy controls. Similarly, Lehr et&#x000a0;al. <xref rid="bib25" ref-type="bibr">[25]</xref> developed an automated assessment system and applied it to spoken responses of subjects on a delayed recall test (Wechsler Logical Memory test). First, they automatically transcribed the recordings using an ASR system, then they extracted the story elements using the Berkeley aligner <xref rid="bib26" ref-type="bibr">[26]</xref>, and finally they compared those to the story elements manually identified by the expert examiner. Using a support vector machine (SVM) classifier applied to 72 participants, they showed ASR-derived features can distinguish 35 participants with MCI from 37 healthy controls with a classification accuracy of 81%. More recently, Toth et&#x000a0;al. <xref rid="bib27" ref-type="bibr">[27]</xref> presented an automatic approach for detecting MCI from speech samples in which participants were asked to talk about a 1-minute long animated film. They used an ASR system to transcribe the recordings and extract acoustic biomarkers including articulation rate, speech tempo, length of utterance, duration, and number of silent and filled pauses (hesitation). Their results show that the SVM classifier trained on the aforementioned acoustic features can distinguish 32 participants with MCI from 19 healthy controls with an accuracy of about 80%. Based on this prior work, we sought to improve the ability to extract meaningful markers of cognitive change from the spontaneous speech of individuals with MCI or those at risk for MCI.</p></sec></sec></sec><sec id="sec2"><label>2</label><title>Methods</title><sec id="sec2.1"><label>2.1</label><title>Data collection and corpus</title><p>The present study was a part of a larger randomized controlled clinical trial that assessed whether frequent conversations conducted via webcam and Internet-enabled personal computers could improve cognitive function in older persons with either normal cognition or MCI (<ext-link ext-link-type="uri" xlink:href="http://ClinicalTirals.gov" id="intref0020">ClinicalTirals.gov</ext-link> registration number: <ext-link ext-link-type="uri" xlink:href="ctgov:NCT01571427" id="intref0025">NCT01571427</ext-link>). The study protocol and the results have been described in detail elsewhere <xref rid="bib12" ref-type="bibr">[12]</xref>. Briefly, in the larger intervention trial, social interaction sessions were conducted using semistructured conversations with trained interviewers for 30&#x000a0;minutes a day, 5 days a week for 6 weeks (i.e., 30 sessions) among the intervention group; the control group did not have daily video-chat sessions. Inclusion and exclusion criteria are listed in <xref rid="tbl1" ref-type="table">Table&#x000a0;1</xref>. There was high adherence to the daily video-chat protocol (89%; range, 77%&#x02013;100%).<table-wrap id="tbl1" position="float"><label>Table&#x000a0;1</label><caption><p>Inclusion and exclusion criteria used in the trial</p></caption><table frame="hsides" rules="groups"><tbody><tr><td><list list-type="simple"><title>Inclusion criteria</title><list-item id="o0010"><label>1.</label><p>Age 70&#x000a0;years or older</p></list-item><list-item id="o0015"><label>2.</label><p>CDR&#x000a0;=&#x000a0;0 or 0.5</p></list-item><list-item id="o0020"><label>3.</label><p>Sufficient vision and hearing to engage in conversation by personal computer system.</p></list-item><list-item id="o0025"><label>4.</label><p>Sufficient English language skills to complete all testing.</p></list-item><list-item id="o0030"><label>5.</label><p>General health status that will not interfere with ability to complete longitudinal study. Conditions that will likely lead to this problem are listed in the following in the study exclusions list.</p></list-item></list><list list-type="simple"><title>Exclusion criteria</title><list-item id="o0035"><label>1.</label><p>Plan to start taking new classes, traveling which requires more than two nights of stay away, or having significant social events such as a family wedding or a family reunion, during the scheduled prevention trial.</p></list-item><list-item id="o0040"><label>2.</label><p>Diseases associated with dementia such as AD, ischemic vascular dementia, normal pressure hydrocephalus, or Parkinson's disease.</p></list-item><list-item id="o0045"><label>3.</label><p>Significant disease of the central nervous system such as brain tumor, seizure disorder, subdural hematoma, cranial arteritis.</p></list-item><list-item id="o0050"><label>4.</label><p>Current (within the last 2&#x000a0;years) alcohol or substance abuse</p></list-item><list-item id="o0055"><label>5.</label><p>Current major depression, schizophrenia, or other major psychiatric disorder</p></list-item><list-item id="o0060"><label>6.</label><p>Unstable or significantly symptomatic cardiovascular disease such as coronary artery disease with frequent angina, or congestive heart failure with shortness of breath at rest.</p></list-item><list-item id="o0065"><label>7.</label><p>Active systemic cancer within 5&#x000a0;years of study entry.</p></list-item><list-item id="o0070"><label>8.</label><p>Illness that requires &#x0003e;1 visit per month to a clinician.</p></list-item><list-item id="o0075"><label>9.</label><p>Progressive vision loss (age-related macular degeneration already beginning to significantly degrade vision).</p></list-item><list-item id="o0080"><label>10.</label><p>Need for oxygen supplementation for adequate function.</p></list-item><list-item id="o0085"><label>11.</label><p>Medications:<list list-type="simple"><list-item id="o0090"><label>A.</label><p>Frequent use of high doses of analgesics.</p></list-item><list-item id="o0095"><label>B.</label><p>Sedative medications except for those used occasionally for sleep (use limited to no more than twice per week).</p></list-item><list-item id="o0100"><label>C.</label><p>Applicable to CDR&#x000a0;=&#x000a0;0.5 group only: subjects on unstable dosing of cholinesterase inhibitors (need to be stable dosing for 2&#x000a0;months).</p></list-item></list></p></list-item></list></td></tr></tbody></table><table-wrap-foot><fn><p>Abbreviations: CDR, Clinical Dementia Rating; AD, Alzheimer's disease.</p></fn></table-wrap-foot></table-wrap></p><p>The Clinical Dementia Rating (CDR) scale <xref rid="bib28" ref-type="bibr">[28]</xref> was used to classify participants into groups and defined MCI as CDR 0.5 and cognitively intact as CDR 0. Out of 41 participants randomized to the intervention group, 33 consented to allow their daily conversational intervention sessions to be transcribed for speech characteristic analyses (21 cognitively intact; 12 MCI). In addition, eight participants (six cognitively intact, two MCI) recruited during a pilot-testing study who went through the same intervention protocol also consented and were included in the study described here, resulting in a total of 41 participants. The transcribed interviewees' speech during their daily chat sessions over 6 weeks was analyzed in this study. <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref> reports the baseline characteristics of participants including age, education, gender, and Mini&#x02013;Mental State Examination scores.<table-wrap id="tbl2" position="float"><label>Table&#x000a0;2</label><caption><p>Baseline characteristics of participants</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Variable</th><th>Intact, <italic>n</italic>&#x000a0;=&#x000a0;27</th><th>MCI, <italic>n</italic>&#x000a0;=&#x000a0;14</th><th><italic>P</italic>-value</th></tr></thead><tbody><tr><td>Age</td><td align="char">78.9 (5.5)</td><td align="char">83.4 (8.8)</td><td align="char">.10</td></tr><tr><td>Gender (% women)</td><td>63</td><td>86</td><td align="char">.17</td></tr><tr><td>Years of education</td><td align="char">16.6 (2.4)</td><td align="char">14.0 (2.6)</td><td align="char">.003</td></tr><tr><td>MMSE</td><td align="char">28.7 (1.3)</td><td align="char">26.9 (2.1)</td><td align="char">.008</td></tr></tbody></table><table-wrap-foot><fn><p>Abbreviations: MCI, mild cognitive impairment; MMSE, Mini&#x02013;Mental State Examination.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="sec2.2"><label>2.2</label><title>Language analysis using LIWC</title><p>Our proposed method explores automating the identification of individuals with MCI using computational analysis of narrative language samples. We extract linguistic features using LIWC from manual transcription of unstructured conversations between interviewers and participating older adults as indicators of how participants and interviewers interact during the conversation.</p><p>LIWC2001, which we refer to as LIWC in this study, includes more than 2500 words or word stems categorized into groups of words known as &#x0201c;word subcategories&#x0201d; that tap a particular cluster of related words (e.g., negative emotion words). There are 68 word subcategories in LIWC each titled with a representative term that generates an overall &#x0201c;subcategory scale.&#x0201d; For example, a group of job-related words such as &#x0201c;Employ,&#x0201d; &#x0201c;Boss,&#x0201d; and &#x0201c;Career&#x0201d; are grouped into a word subcategory of &#x0201c;Occupation.&#x0201d; These word subcategories further cluster into five broader domains termed &#x0201c;word categories&#x0201d;: (1) Linguistic Dimensions, (2) Psychological Processes, (3) Relativity, (4) Personal Concerns, and (5) Spoken Categories <xref rid="bib9" ref-type="bibr">[9]</xref>. Each of these broad word categories includes words that represent a particular conceptual domain; for example, Linguistic Dimensions groups all personal and impersonal pronouns. Psychological processes denotes affective or emotional categories of words such as &#x0201c;Positive Emotion&#x0201d; and &#x0201c;Negative Emotion&#x0201d; subcategories, as well as cognitive processes such as a &#x0201c;Causation&#x0201d; subcategory, and social processes such as &#x0201c;Family&#x0201d; and &#x0201c;Friends&#x0201d; subcategories. Relativity includes a group of words that denote &#x0201c;Time&#x0201d; such as the tense of verbs, &#x0201c;Space,&#x0201d; and &#x0201c;Motion.&#x0201d; Personal Concerns includes a group of categories associated with personal matters such as occupation, financial issues, and so forth. Finally, the Spoken Categories class includes three categories of &#x0201c;Swear Words&#x0201d; such as <italic>crap</italic> and <italic>goddam</italic>, &#x0201c;Nonfluencies&#x0201d; such as <italic>hm</italic> and <italic>umm</italic>, and &#x0201c;Fillers&#x0201d; such as <italic>youknow</italic>. <xref rid="tbl3" ref-type="table">Table&#x000a0;3</xref> provides a comprehensive list of the default LIWC word categories, subcategory scales, examples from word subcategories, and count of words that exist in each word subcategory. The selection of words defining the LIWC categories involved multiple steps over several years, initially, to collect groups of words representing basic emotional and cognitive dimensions. Here, we briefly review the development steps of LIWC and refer readers to the LIWC user's manual <xref rid="bib9" ref-type="bibr">[9]</xref> for more detail.<table-wrap id="tbl3" position="float"><label>Table&#x000a0;3</label><caption><p>LIWC2001 output variable information</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Category</th><th>Subcategory scale</th><th>Examples</th><th>Count of words</th></tr></thead><tbody><tr><td rowspan="11">Linguistic processes</td><td>Total pronouns</td><td>I, our, they</td><td align="char">70</td></tr><tr><td>1st person singular</td><td>I, me, my</td><td align="char">9</td></tr><tr><td>1st person plural</td><td>we, us, our</td><td align="char">11</td></tr><tr><td>Total 1st person</td><td>I, we, me</td><td align="char">20</td></tr><tr><td>Total 2nd person</td><td>you, you'll</td><td align="char">14</td></tr><tr><td>Total 3rd person</td><td>she, their, them</td><td align="char">22</td></tr><tr><td>Negations</td><td>no, not, never</td><td align="char">31</td></tr><tr><td>Assent</td><td>agree, OK, yes</td><td align="char">18</td></tr><tr><td>Articles</td><td>a, an, the</td><td align="char">3</td></tr><tr><td>Prepositions</td><td>to, with, above</td><td align="char">43</td></tr><tr><td>Numbers</td><td>Second, thousand</td><td align="char">34</td></tr><tr><td rowspan="19">Personal concerns</td><td>Occupation</td><td>work, class, boss</td><td align="char">213</td></tr><tr><td>School</td><td>class, student, college</td><td align="char">100</td></tr><tr><td>Job</td><td>employ, boss, career</td><td align="char">62</td></tr><tr><td>Achievement</td><td>goal, hero, win</td><td align="char">60</td></tr><tr><td>Leisure activity</td><td>TV, chat, movie</td><td align="char">102</td></tr><tr><td>Home</td><td>apartment, kitchen</td><td align="char">26</td></tr><tr><td>Sports</td><td>football, game, play</td><td align="char">28</td></tr><tr><td>TV and movies</td><td>TV, sitcom, cinema</td><td align="char">19</td></tr><tr><td>Music</td><td>tunes, song, CD</td><td align="char">31</td></tr><tr><td>Money</td><td>income, cash, owe</td><td align="char">75</td></tr><tr><td>Metaphysical</td><td>God, church, coffin</td><td align="char">85</td></tr><tr><td>Religion</td><td>altar, church, mosque</td><td align="char">56</td></tr><tr><td>Death</td><td>dead, coffin, kill</td><td align="char">29</td></tr><tr><td>Physical states</td><td>ache, breast, sleep</td><td align="char">285</td></tr><tr><td>Body states</td><td>ache, heart, cough</td><td align="char">200</td></tr><tr><td>Sex and sexuality</td><td>lust, penis, fuck</td><td align="char">49</td></tr><tr><td>Eating</td><td>eat, swallow, taste</td><td align="char">52</td></tr><tr><td>Sleeping</td><td>sleep, bed, dreams</td><td align="char">21</td></tr><tr><td>Grooming</td><td>wash, bath, clean</td><td align="char">15</td></tr><tr><td rowspan="25">Psychological processes</td><td>Affective</td><td>happy, ugly, bitter</td><td align="char">6</td></tr><tr><td>Positive emotion</td><td>happy, pretty, good</td><td align="char">261</td></tr><tr><td>Positive feelings</td><td>happy, joy, love</td><td align="char">43</td></tr><tr><td>Optimism</td><td>Certainty, pride, win</td><td align="char">69</td></tr><tr><td>Negative emotion</td><td>hate, worthless, enemy</td><td align="char">345</td></tr><tr><td>Anxiety</td><td>nervous, afraid, tense</td><td align="char">62</td></tr><tr><td>Anger</td><td>hate, kill, pissed</td><td align="char">121</td></tr><tr><td>Sadness</td><td>grief, cry, sad</td><td align="char">72</td></tr><tr><td>Cognitive process</td><td>cause, know, ought</td><td align="char">312</td></tr><tr><td>Causation</td><td>because, effect, hence</td><td align="char">49</td></tr><tr><td>Insight</td><td>think, know, consider</td><td align="char">116</td></tr><tr><td>Discrepancy</td><td>should, would, could</td><td align="char">32</td></tr><tr><td>Inhibition</td><td>block, constrain</td><td align="char">64</td></tr><tr><td>Tentative</td><td>maybe, perhaps, guess</td><td align="char">79</td></tr><tr><td>Certainty</td><td>always, never</td><td align="char">30</td></tr><tr><td>Sensory process</td><td>see, touch, listen</td><td align="char">111</td></tr><tr><td>Seeing</td><td>view, saw, look</td><td align="char">31</td></tr><tr><td>Hearing</td><td>heard, listen, sound</td><td align="char">36</td></tr><tr><td>Feeling</td><td>touch, hold, felt</td><td align="char">30</td></tr><tr><td>Social process</td><td>talk, us, friend</td><td align="char">314</td></tr><tr><td>Communication</td><td>talk, share, converse</td><td align="char">124</td></tr><tr><td>Other references</td><td>1st, 2nd, 3rd</td><td align="char">54</td></tr><tr><td>Friends</td><td>pal, buddy, coworker</td><td align="char">28</td></tr><tr><td>Family</td><td>mom, brother, cousin</td><td align="char">43</td></tr><tr><td>Humans</td><td>boy, woman, group</td><td align="char">43</td></tr><tr><td rowspan="10">Relativity</td><td>Time</td><td>hour, day, o'clock</td><td align="char">113</td></tr><tr><td>Past verb</td><td>walked, were, had</td><td align="char">144</td></tr><tr><td>Present verb</td><td>walk, is, be</td><td align="char">256</td></tr><tr><td>Future verb</td><td>will, might, shall</td><td align="char">14</td></tr><tr><td>Space</td><td>around, over, up</td><td align="char">71</td></tr><tr><td>Up</td><td>up, above, over</td><td align="char">12</td></tr><tr><td>Down</td><td>down, below, under</td><td align="char">7</td></tr><tr><td>Inclusive</td><td>with, and, include</td><td align="char">16</td></tr><tr><td>Exclusive</td><td>but, except, without</td><td align="char">19</td></tr><tr><td>Motion</td><td>walk, move, go</td><td align="char">73</td></tr><tr><td rowspan="3">Spoken categories</td><td>Swear words</td><td>damn, fuck, piss</td><td align="char">29</td></tr><tr><td>Nonfluencies</td><td>uh, rr*</td><td align="char">6</td></tr><tr><td>Fillers</td><td>youknow, Imean</td><td align="char">6</td></tr></tbody></table><table-wrap-foot><fn id="tspara0035"><p>Abbreviation: LIWC, Linguistic Inquiry and Word Count.</p></fn><fn id="tspara0040"><p>NOTE. List of the default LIWC word categories (first column), subcategory scales (second column), a few examples from word subcategories (third column), and frequency of words found in each word subcategory (forth column).</p></fn></table-wrap-foot></table-wrap></p><p>First, sets of words were generated for each word subcategory. Next, using several sources, such as the positive and negative affect scales <xref rid="bib29" ref-type="bibr">[29]</xref> for the Psychological Processes word category, relevant words were generated by a group of 3&#x02013;6 judges for all word subcategories. Then, three independent judges indicated whether each suggested word properly fits within its word subcategory. Words for which judges could not decide on appropriate category placement were discarded. A majority voting among judges determined final candidates to each word subcategory. Percentages of agreement for judges ratings were acceptable for all LIWC word subcategories ranging from a low of 86% agreement for the subcategory of &#x0201c;Optimism&#x0201d; to 100% agreement for the subcategory of &#x0201c;Humans.&#x0201d; One should note that each word or word stem may be part of one or more word subcategories in LIWC. For example, the word &#x0201c;cried&#x0201d; is part of four word subcategories: &#x0201c;Sadness,&#x0201d; &#x0201c;Negative Emotion,&#x0201d; &#x0201c;Affective,&#x0201d; and &#x0201c;Past Tense Verb.&#x0201d; Detailed information about LIWC word categories can be found in <xref rid="bib30" ref-type="bibr">[30]</xref>. LIWC has been widely used in a range of applications, and its reliability has been validated for a range of problems such as linguistic analysis of social media <xref rid="bib31" ref-type="bibr">[31]</xref> or analyzing and discovering personality traits <xref rid="bib32" ref-type="bibr">[32]</xref>. In this study, we use LIWC to automatically distinguish participants with MCI from healthy controls using linguistic features extracted from the content of spontaneous conversation.</p><p>Our linguistic analysis of transcriptions began with grouping spoken words into 68 LIWC word subcategories. Note that raw transcriptions are stemmed before splitting into word categories. The stemming process refers to extracting the stem or root of words so that words with the same roots such as &#x0201c;book&#x0201d; and &#x0201c;books&#x0201d; fall into the same word subcategory. Next, we count the number of words that fall into each word subcategory. This generates a vector of 68 dimensions referring to 68 word counts on each word subcategory. Some words may not belong to any of LIWC word categories and these are discarded; 39.8% of words were found unclassifiable to any of the 68 word categories. Because the total number of words spoken by participants at interview sessions is not equal, the dynamic range of features may vary among participants and this may confound classification performance. To address this issue, we normalize each count by dividing it by the total number of words. We treat this vector as an input feature vector to our classification algorithm. Moreover, to study the relative importance of each group of the five word categories for distinguishing participants with MCI from those with intact cognition, we train five different classifiers each with linguistic features derived only from one of the main groups of word categories in a secondary analysis. <xref rid="fig1" ref-type="fig">Fig.&#x000a0;1</xref> represents the block diagram of our proposed method for extracting and modeling linguistic features of participants' transcriptions to distinguish participants with MCI from those with intact cognition. In the next section, we present the learning strategies and experimental setup.<fig id="fig1"><label>Fig.&#x000a0;1</label><caption><p>Block diagram of extracting and modeling linguistic features of participants' transcriptions to distinguish participants with MCI from those with intact cognition. Abbreviation: MCI, mild cognitive impairment.</p></caption><graphic xlink:href="gr1"/></fig></p></sec><sec id="sec2.3"><label>2.3</label><title>Learning strategies</title><p>To explore the effectiveness of different learning methods in distinguishing participants with MCI from those with intact cognition, we trained statistical models based on extracted linguistic features using two widely employed machine learning algorithms: (1) SVM <xref rid="bib33" ref-type="bibr">[33]</xref> and (2) random forest classifier (RFC) <xref rid="bib34" ref-type="bibr">[34]</xref>.</p><sec id="sec2.3.1"><label>2.3.1</label><title>Problem definition</title><p>Distinguishing participants with MCI from those with intact cognition can be cast into a hypothesis test problem, in which true and null hypotheses, <italic>H</italic><sub>1</sub> and <italic>H</italic><sub>0</sub>, are the prediction of the participant as MCI and cognitively intact, respectively. Given a set of linguistic features derived from the transcription of conversational interviews, one must first train statistical models of MCI and cognitively intact classes that well represent inherent characteristics of both <italic>H</italic><sub>1</sub> and <italic>H</italic><sub>0</sub> hypotheses. The efficiency of this process, known as model training, depends on the quality of extracted features as well as the discriminant power of the learning algorithm that separates classes with the highest margin. Let the D-dimensional linguistic feature vectors (D is total number of features) extracted from the transcription of a participant be x<sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub>&#x02208;{+1,&#x02212;1} his or her class label where 1 and &#x02212;1 represent the participant's cognitive status (MCI vs. intact). Thus, we need to learn a classification function <italic>f</italic>(x), that predicts&#x000a0;the subject's label from the available training data&#x000a0;<italic>D</italic> = (x<sub><italic>i</italic></sub>,<italic>y</italic><sub><italic>i</italic></sub>); <italic>i</italic> = 1,&#x02026;,<italic>n</italic>, where <italic>n</italic> is the total number of participants.</p></sec><sec id="sec2.3.2"><label>2.3.2</label><title>Classification algorithms</title><p>SVMs <xref rid="bib33" ref-type="bibr">[33]</xref> are among the best supervised learning methods widely used in pattern recognition, classification, and regression problems. A SVM classifier constructs a hyperplane&#x000a0;in a high-dimensional space to best discriminate data points belonging to different classes. In nonlinear cases, SVM leverages from a mathematical technique called Kernel trick <xref rid="bib35" ref-type="bibr">[35]</xref> to first map input features into a high-dimensional space and then find a hyperplane that maximizes the class margin. One of the main advantages of SVM is its effectiveness in cases where the dimension of feature vectors is greater than the number of training samples. This makes the use of SVM particularly suitable in our experiment where there is a relatively small pool of subjects versus the minimum feature dimension of 68. We train a linear SVM classifier as well as a nonlinear SVM classifier with a radial basis function (RBF) kernel used from the open-source Scikit-learn toolkit <xref rid="bib36" ref-type="bibr">[36]</xref> independently for different sets of features from LIWC. In the machine learning literature <xref rid="bib35" ref-type="bibr">[35]</xref>, a nonlinear SVM is recommended for classifying data points that are not linearly separable. We also use an RFC <xref rid="bib34" ref-type="bibr">[34]</xref> that trains a number of decision tree classifiers on randomly drawn subsamples of the data set and then combine these decision tree classifiers to improve the predictive accuracy and to control overfitting. When a new input sample is entered into the RFC, it is first classified by all of the decision trees and then voting majority criteria will estimate the class label of the input sample. The simplest classification function, referred to as &#x0201c;Chance&#x0201d; in our experiments, is a random classifier that corresponds to randomly classifying all subjects into two classes.</p></sec><sec id="sec2.3.3"><label>2.3.3</label><title>LIWC features</title><p>Before describing our different modeling strategies, we outline the feature extraction procedure in this task. Transcriptions of the recordings were produced by nonprofessional transcribers via the Amazon Mechanical Turk (AMT) crowd-sourcing platform. To assess the quality of transcriptions, we randomly picked four interview sessions (125&#x000a0;minutes total) and evaluated the word error rate (WER) between transcriptions provided by AMT nonprofessional and professional transcribers. The WER that measured the percentage of deleted, inserted, and substituted words in the AMT transcriptions with respect to the reference (gold standard) professional transcriptions was approximately 15% suggesting an acceptable agreement between AMT-derived and reference transcription. From the transcription of interviewees recordings, we grouped spoken words using the LIWC lexicon into 68 different subcategories and counted the number of words grouped in each subcategory of LIWC as a representative feature. This resulted&#x000a0;in a 68-dimensional feature vector representing the linguistic information of each participant. As noted earlier, each feature was normalized by the total word count of each participant. In addition, we examined the relative importance of each main group of word categories of LIWC in our classification problem.</p></sec><sec id="sec2.3.4"><label>2.3.4</label><title>Cross-validation</title><p>To validate how our statistical analyses and experimental results were independent of our data sets, we used cross-validation (CV) techniques in which the train and test sets are rotated over the entire data set. We used a five-fold cross-validation scheme, setting all model parameters using four of the sets as the training set, and using the fifth one only for reporting the performance estimates. Parameters&#x000a0;of the optimal SVM model were determined on the training set separately for each fold via grid search and cross-validation.</p></sec><sec id="sec2.3.5"><label>2.3.5</label><title>Performance criteria</title><p>To evaluate the performance of the proposed classifier, we adopted the following evaluation metrics: (1) Accuracy&#x02014;in our binary classification, accuracy is the proportion of participants that are correctly identified in both intact and MCI classes divided by the total number of participants. The accuracy itself does not represent the performance of the model due to the imbalanced number of participants in our cohort; (2) Sensitivity&#x02014;the portion of correctly identified MCI participants (true positives). Sensitivity (SE) assesses the capability of the model to distinguish MCI from cognitively intact participants; (3) Specificity&#x02014;the portion of correctly identified cognitively intact participants (true negative). Specificity (SP) measures how well the model is at avoiding false positives; (4) Area under the curve of receiver operating characteristics (AUC-ROC)&#x02014;the most common method for evaluating the performance of a binary classifier is the receiver operating characteristics <xref rid="bib37" ref-type="bibr">[37]</xref>, which plots the sensitivity (true positive rate) of the classifier versus 1 &#x02212; specificity (false positive rate) of the classifier as the classification threshold varies. We use a classification threshold in a grid search schema to cover the most positive threshold (everything true) to the most negative threshold (everything false). In our experimental setup, we report the average over five iterations of the CV for every performance criteria.</p></sec><sec id="sec2.3.6"><label>2.3.6</label><title>Imbalanced data</title><p>Because of the imbalanced number of participants in our cohort, partitioning data into train and test sets via CV could result in an imbalanced test set. For example, in a five-fold scenario, randomly assigning 20% of 41 participants, 14 with MCI and 27 cognitively intact, into the test set might result in a case where one MCI participant coincides with seven cognitively intact participants in the test set. This will result in a highly imbalanced test set in which performing CV will negatively affect the overall conclusion on the performance of the classifier. We tackle this potential issue through an iterative process. First, we randomly permute the entire data, perform five-fold CV, and accumulate averaged scores at the end of each iteration. Next, we calculate the overall performance by taking the average of 5-fold CV scores across iterations. The iteration is repeated until the overall performance converges to a steady state. Our experiments showed that after about 200 iterations of 5-fold CV, the overall performance converged.</p></sec></sec></sec><sec id="sec3"><label>3</label><title>Results</title><p>Using features extracted from the LIWC lexicon, we compared the performance of the aforementioned classifiers for distinguishing participants with MCI from those cognitively intact controls. As discussed earlier, the number of linguistic features extracted from transcriptions here is larger than the number of participants. Given this scenario, the learning task is an ill-posed problem without a unique solution for the linear function. The simplest solution to this problem is to automatically eliminate those features that are not informative. This can be performed by augmenting the cost function of the SVM classifier with a regularization term that penalizes large values of the regression coefficients, driving them to zero when they are not useful. In our experiments, we used a L1-norm regularization term that is well known in applications requiring sparse solutions, assigning zero values to useless regression coefficients <xref rid="bib38" ref-type="bibr">[38]</xref>.</p><p>The results are reported in <xref rid="tbl4" ref-type="table">Table&#x000a0;4</xref> for the five-fold cross-validations. The performance of SVM classifiers with linear and RBF kernels as well as RFC in terms of Sensitivity, Specificity, Accuracy, and AUC-ROC are shown. We also repeated the experiment using a Chance classifier which randomly assigned participants into MCI and intact classes. Results indicate that all SVM classifiers and RFC perform significantly better than &#x0201c;Chance&#x0201d; (<italic>P</italic>-value of &#x0003c;.05), according to the cross-validated paired t-test <xref rid="bib39" ref-type="bibr">[39]</xref> (<sup>&#x02020;</sup> denotes statistically significant results). As it is shown in <xref rid="tbl4" ref-type="table">Table&#x000a0;4</xref>, the SVM model with linear kernel and a L1-norm regularization term outperforms nonlinear SVM with an RBF kernel as well as the RFC in terms of AUC-ROC.<table-wrap id="tbl4" position="float"><label>Table&#x000a0;4</label><caption><p>Comparison of performance of different classifiers distinguishing participants with MCI from those with intact cognition</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Classifier</th><th>Sensitivity</th><th>Specificity</th><th>Accuracy</th><th>AUC-ROC</th></tr></thead><tbody><tr><td>Chance</td><td align="char">30.0</td><td align="char">76.0</td><td align="char">60.0</td><td align="char">52.2</td></tr><tr><td>Nonlinear SVM (RBF)</td><td align="char">53.2</td><td align="char">88.2</td><td align="char">76.2</td><td align="char">71.2<sup>&#x02020;</sup></td></tr><tr><td>Linear SVM</td><td align="char">60.96</td><td align="char">77.5</td><td align="char">71.9</td><td align="char">69.2<sup>&#x02020;</sup></td></tr><tr><td>Linear SVM&#x000a0;+&#x000a0;L1-norm</td><td align="char">72.7</td><td align="char">72.4</td><td align="char">72.4</td><td align="char">72.5<sup>&#x02020;</sup></td></tr><tr><td>RFC</td><td align="char">6.51</td><td align="char">72.3</td><td align="char">74.7</td><td align="char">68.2<sup>&#x02020;</sup></td></tr></tbody></table><table-wrap-foot><fn id="tspara0050"><p>Abbreviations: MCI, mild cognitive impairment; AUC-ROC, area under the curve of receiver operating characteristics; SVM, support vector machine; RBF, radial basis function; RFC, random forest classifier.</p></fn><fn id="tspara0055"><p>NOTE. <sup>&#x02020;</sup><italic>P</italic>&#x000a0;&#x0003c;&#x000a0;.05.</p></fn></table-wrap-foot></table-wrap></p><sec id="sec3.1"><label>3.1</label><title>Effectiveness of LIWC dimensions in extracted linguistic features</title><p>Word categories in the LIWC2001 are generally arranged hierarchically, composed of five main classes of word categories: Personal Concerns, Relativity, Psychological Processes, Linguistic Dimensions, and Spoken Categories. In our initial experiment, we simply grouped spoken words into 68 LIWC word categories, and the resulting 68-dimensional linguistic features were used for learning MCI and intact SVM models. To study the relative importance of each group of the five word categories for distinguishing participants with MCI from intact volunteers, we used five different SVM models each with linguistic features derived only from one of the main groups of word categories in a secondary analysis.</p><p>The results for five-fold cross-validation are reported in <xref rid="tbl5" ref-type="table">Table&#x000a0;5</xref> for the SVM model with the linear kernel and L1-norm regularization term. In this analysis, linguistic features extracted from the Linguistic Dimensions category by itself are not particularly effective at this task. Features from Spoken Categories are also not informative and underperform noticeably compared to other classes of features. This might be due to the small size of the feature set (only three features) derived from this category. In contrast, results show that features derived from Psychological Processes and Personal Concerns significantly outperformed the &#x0201c;Chance&#x0201d; classifier. Features from the Relativity class are best at distinguishing participants with MCI with sensitivity of 81% and AUC-ROC of 80%. Interestingly, this category alone noticeably outperforms the system in which all 68 features are used.<table-wrap id="tbl5" position="float"><label>Table&#x000a0;5</label><caption><p>Comparison of performance using linguistic features extracted from five LIWC main groups of word categories, for distinguishing MCI subjects</p></caption><table frame="hsides" rules="groups"><thead><tr><th>LIWC categories</th><th>Number of features</th><th>Sensitivity</th><th>Specificity</th><th>Accuracy</th><th>AUC-ROC</th></tr></thead><tbody><tr><td>Linguistic dimensions</td><td align="char">17</td><td align="char">64.37</td><td align="char">55.43</td><td align="char">69.0</td><td align="char">62.2</td></tr><tr><td>Chance</td><td align="char">17</td><td align="char">30.7</td><td align="char">76.3</td><td align="char">60.9</td><td align="char">53.5</td></tr><tr><td>Psychological processes</td><td align="char">25</td><td align="char">63.93</td><td align="char">67.8</td><td align="char">62.12</td><td align="char">64.96<sup>&#x02020;</sup></td></tr><tr><td>Chance</td><td align="char">25</td><td align="char">32.1</td><td align="char">76.9</td><td align="char">61.8</td><td align="char">54.5</td></tr><tr><td>Relativity</td><td align="char">10</td><td align="char">80.77</td><td align="char">75.83</td><td align="char">83.33</td><td align="char"><bold>79.61</bold><sup>&#x02020;</sup></td></tr><tr><td>Chance</td><td align="char">10</td><td align="char">30.6</td><td align="char">76.2</td><td align="char">60.9</td><td align="char">53.4</td></tr><tr><td>Personal concerns</td><td align="char">19</td><td align="char">70.3</td><td align="char">62.60</td><td align="char">74.60</td><td align="char">68.30<sup>&#x02020;</sup></td></tr><tr><td>Chance</td><td align="char">19</td><td align="char">30.1</td><td align="char">76.1</td><td align="char">60.7</td><td align="char">53.1</td></tr><tr><td>Spoken categories</td><td align="char">3</td><td align="char">43.45</td><td align="char">67.23</td><td align="char">59.11</td><td align="char">55.34</td></tr><tr><td>Chance</td><td align="char">3</td><td align="char">30.7</td><td align="char">76.3</td><td align="char">60.9</td><td align="char">53.5</td></tr></tbody></table><table-wrap-foot><fn id="tspara0065"><p>Abbreviations: LIWC, Linguistic Inquiry and Word Count; MCI, mild cognitive impairment; AUC-ROC, area under the curve of receiver operating characteristics (best result indicated in bold).</p></fn><fn id="tspara0070"><p>NOTE. <sup>&#x02020;</sup><italic>P</italic>&#x000a0;&#x0003c;&#x000a0;.05.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="sec3.2"><label>3.2</label><title>Influence of education level</title><p>According to <xref rid="tbl2" ref-type="table">Table&#x000a0;2</xref>, there was a significant difference in the years of education between participants with MCI and those who are cognitively intact. It is possible that the level of education may significantly influence verbal abilities regardless of cognitive decline <xref rid="bib40" ref-type="bibr">[40]</xref>. To control for education, we repeated the analysis with a subset of participants from the intact group that better matches the education level of participants in the MCI group. <xref rid="tbl6" ref-type="table">Table&#x000a0;6</xref> reports the baseline characteristics of subsampled participants of more equal educational level and results are shown in <xref rid="tbl7" ref-type="table">Table 7</xref>. In this secondary analysis, the classifier trained on the features from the Relativity word category outperformed other classifiers. In addition, comparing results with those previously shown in <xref rid="tbl5" ref-type="table">Table&#x000a0;5</xref> suggests that education plays a significant role in this study. Finally, we performed an analysis using a Student t-test on the averaged percentage of words that fall into the Relativity word category across spoken words of all participants from both MCI and intact classes. MCI participants used significantly more words (<italic>P</italic>&#x000a0;&#x0003c;&#x000a0;.001) than intact participants from word subcategories of the Relativity word category. This also indicates that MCI participants use more &#x0201c;verbs&#x0201d; than healthy controls according to <xref rid="tbl3" ref-type="table">Table&#x000a0;3</xref>. One of our speculations in this regard is that complex sentences could involve more words that just verbs (articles, adjectives, etc.) and therefore, more number of verbs indicate that sentence complexity is simpler among the MCI subjects. However, because of limited literature to support our hypothesis, we can not provide any in-depth explanation.<table-wrap id="tbl6" position="float"><label>Table&#x000a0;6</label><caption><p>Baseline characteristics of subsampled participants</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Variable</th><th>Intact, <italic>n</italic>&#x000a0;=&#x000a0;15</th><th>MCI, <italic>n</italic>&#x000a0;=&#x000a0;14</th><th><italic>P</italic>-value</th></tr></thead><tbody><tr><td>Age</td><td align="char">79.4 (5.1)</td><td align="char">83.4 (8.8)</td><td align="char">.15</td></tr><tr><td>Gender (% women)</td><td>63%</td><td>86%</td><td align="char">.17</td></tr><tr><td>Years of education</td><td align="char">14.8 (1.37)</td><td align="char">14.0 (2.6)</td><td align="char">.31</td></tr></tbody></table><table-wrap-foot><fn><p>Abbreviation: MCI, mild cognitive impairment.</p></fn></table-wrap-foot></table-wrap><table-wrap id="tbl7" position="float"><label>Table&#x000a0;7</label><caption><p>Distinguishing 14 MCI from 15 cognitively intact participants with characteristics reported in <xref rid="tbl6" ref-type="table">Table&#x000a0;6</xref> using LIWC feature sets</p></caption><table frame="hsides" rules="groups"><thead><tr><th>LIWC categories</th><th>Number of features</th><th>Sensitivity</th><th>Specificity</th><th>Accuracy</th><th>AUC-ROC</th></tr></thead><tbody><tr><td>Chance</td><td align="char">68</td><td align="char">57.31</td><td align="char">46.46</td><td align="char">51.47</td><td align="char">51.89</td></tr><tr><td>All categories</td><td align="char">68</td><td align="char">77.55</td><td align="char">47.23</td><td align="char">61.81</td><td align="char">62.39<sup>&#x02020;</sup></td></tr><tr><td>Linguistic dimensions</td><td align="char">17</td><td align="char">59.85</td><td align="char">55.13</td><td align="char">65.28</td><td align="char">57.49</td></tr><tr><td>Psychological processes</td><td align="char">25</td><td align="char">69.93</td><td align="char">37.0</td><td align="char">52.73</td><td align="char">53.46</td></tr><tr><td>Relativity</td><td align="char">10</td><td align="char">74.23</td><td align="char">78.70</td><td align="char">76.42</td><td align="char"><bold>76.46</bold><sup>&#x02020;</sup></td></tr><tr><td>Personal concerns</td><td align="char">19</td><td align="char">65.21</td><td align="char">51.83</td><td align="char">58.11</td><td align="char">58.52</td></tr><tr><td>Spoken categories</td><td align="char">3</td><td align="char">47.8</td><td align="char">51.7</td><td align="char">44.45</td><td align="char">49.75</td></tr></tbody></table><table-wrap-foot><fn id="tspara0090"><p>Abbreviations: MCI, mild cognitive impairment; LIWC, Linguistic Inquiry and Word Count; AUC-ROC, area under the curve of receiver operating characteristics (best result indicated in bold).</p></fn><fn id="tspara0095"><p>NOTE. <sup>&#x02020;</sup><italic>P</italic>&#x000a0;&#x0003c;&#x000a0;.05.</p></fn></table-wrap-foot></table-wrap></p></sec></sec><sec id="sec4"><label>4</label><title>Discussion</title><p>In summary, we have reported our experiments on distinguishing MCI from cognitively intact older adults solely from the spontaneous speech recorded from conversational engagement sessions held for 41 study participants. Our results&#x000a0;show that MCI participants can be distinguished from cognitively intact older adults with an accuracy of 84% using LIWC-driven features. Interestingly, combining all features from 68 word categories resulted in poorer performance suggesting that some word categories in the LIWC are not suitable for this task. We found that the linguistic features derived from word subcategories belonging to the Relativity word category are significantly better at capturing cues with MCI participants as compared to other classes in the LIWC lexicon and give the best classification results. However, this study is not able to explain the cognitive basis for the high performance achieved by the Relativity word category achieve high performance in this task. The linguistic approach used here could be applied to preclinical trials where enriching the study cohort with high-risk subjects and more sensitive outcomes to change are required. Standardized linguistic analysis of spontaneous conversations has the advantage of providing a measure of cognitive function that is inherently person-specific, conveniently captured and ecologically more valid than commonly used constrained psychometric testing sessions However, despite this promise, a current important limitation to this approach is that the analysis relies on high-fidelity transcription of the conversations which is labor intensive. However, we anticipate that there will be continued major advances in the accuracy of automated speech recognition, and thus, this methodology could be widely adopted in clinical practice to screen or identify those at risk of MCI and/or dementia in communities as well as for monitoring progression of disease. In addition to improvements in automated speech recognition for data capture, considerable work remains to improve accuracy of the classification algorithms. Our linguistic analysis did not incorporate many other potentially useful features, relying entirely on the LIWC feature set. This approach ignores sentence structure and other contextual information. The word-based approach using LIWC misses the word context and would miss cases such as &#x0201c;not too bad.&#x0201d; A valuable avenue for future research would be to explore the feasibility of natural language processing techniques to address this drawback using more sophisticated methods of linguistic analysis. Furthermore, when applying this approach in clinical trials or to the general population, one would typically add other potentially predictive features to the classification model such as age, gender, education, and family history of dementia. Future studies will need to examine larger and more diverse populations over time and explore the possible cognitive bases behind&#x000a0;the findings of the present study.<boxed-text id="dtbox1"><caption><title>Research in Context</title></caption><p><list list-type="simple"><list-item id="o0010a"><label>1.</label><p>Systematic review: Early cognitive deficit observed in Alzheimer's affects linguistic ability. Indicators of mild cognitive impairment (MCI) may be present in the content of spoken language in older adults and can be useful in distinguishing those with MCI from those who are cognitively intact.</p></list-item><list-item id="o0015s"><label>2.</label><p>Interpretation: We performed linguistic analysis of spoken words to classify 14 participants with mild cognitive impairment (MCI) from 26 with intact cognition. Applying support vector machine classifier on extracted linguistic features, we classified MCI participants with accuracy of 84%, well above the chance, 60%.</p></list-item><list-item id="o0020d"><label>3.</label><p>Future direction: The linguistic approach used here could be applied to preclinical trials where enriching the study cohort with high-risk subjects and more sensitive outcomes to change are required.</p></list-item></list></p></boxed-text></p></sec></body><back><ref-list id="cebib0010"><title>References</title><ref id="bib1"><label>1</label><element-citation publication-type="journal" id="sref1"><person-group person-group-type="author"><name><surname>Taler</surname><given-names>V.</given-names></name><name><surname>Phillips</surname><given-names>N.A.</given-names></name></person-group><article-title>Language performance in Alzheimer's disease and mild cognitive impairment: A comparative review</article-title><source>J Clin Exp Neuropsychol</source><volume>30</volume><year>2008</year><fpage>501</fpage><lpage>556</lpage><pub-id pub-id-type="pmid">18569251</pub-id></element-citation></ref><ref id="bib2"><label>2</label><element-citation publication-type="journal" id="sref2"><person-group person-group-type="author"><name><surname>Tombaugh</surname><given-names>T.N.</given-names></name></person-group><article-title>Trail making test a and b: normative data stratified by age and education</article-title><source>Arch Clin Neuropsychol</source><volume>19</volume><year>2004</year><fpage>203</fpage><lpage>214</lpage><pub-id pub-id-type="pmid">15010086</pub-id></element-citation></ref><ref id="bib3"><label>3</label><element-citation publication-type="journal" id="sref3"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K.J.</given-names></name><name><surname>Rich</surname><given-names>J.B.</given-names></name><name><surname>Troyer</surname><given-names>A.K.</given-names></name></person-group><article-title>Verbal fluency patterns in amnestic mild cognitive impairment are characteristic of Alzheimer's type dementia</article-title><source>J Int Neuropsychol Soc</source><volume>12</volume><year>2006</year><fpage>570</fpage><lpage>574</lpage><pub-id pub-id-type="pmid">16981610</pub-id></element-citation></ref><ref id="bib4"><label>4</label><mixed-citation publication-type="other" id="sref4">Wechsler D. Wechsler adult intelligence scale&#x02013;fourth edition (wais&#x02013;iv).&#x000a0;London: Pearson; 2014.</mixed-citation></ref><ref id="bib5"><label>5</label><element-citation publication-type="journal" id="sref5"><person-group person-group-type="author"><name><surname>Fraser</surname><given-names>K.C.</given-names></name><name><surname>Meltzer</surname><given-names>J.A.</given-names></name><name><surname>Rudzicz</surname><given-names>F.</given-names></name></person-group><article-title>Linguistic features identify Alzheimers disease in narrative speech</article-title><source>J Alzheimers Dis</source><volume>49</volume><year>2015</year><fpage>407</fpage><lpage>422</lpage></element-citation></ref><ref id="bib6"><label>6</label><element-citation publication-type="book" id="sref6"><person-group person-group-type="author"><name><surname>Roark</surname><given-names>B.</given-names></name><name><surname>Mitchell</surname><given-names>M.</given-names></name><name><surname>Hollingshead</surname><given-names>K.</given-names></name></person-group><chapter-title>Syntactic complexity measures for detecting mild cognitive impairment</chapter-title><source>Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing</source><year>2007</year><publisher-name>Association for Computational Linguistics</publisher-name><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="bib7"><label>7</label><element-citation publication-type="journal" id="sref7"><person-group person-group-type="author"><name><surname>Forbes-McKay</surname><given-names>K.</given-names></name><name><surname>Shanks</surname><given-names>M.F.</given-names></name><name><surname>Venneri</surname><given-names>A.</given-names></name></person-group><article-title>Profiling spontaneous speech decline in Alzheimer's disease: A longitudinal study</article-title><source>Acta Neuropsychiatr</source><volume>25</volume><year>2013</year><fpage>320</fpage><lpage>327</lpage><pub-id pub-id-type="pmid">25287871</pub-id></element-citation></ref><ref id="bib8"><label>8</label><element-citation publication-type="journal" id="sref8"><person-group person-group-type="author"><name><surname>Romero</surname><given-names>B.</given-names></name><name><surname>Kurz</surname><given-names>A.</given-names></name></person-group><article-title>Deterioration of spontaneous speech in ad patients during a 1-year follow-up: Homogeneity of profiles and factors associated with progression</article-title><source>Dement Geriatr Cogn Disord</source><volume>7</volume><year>1996</year><fpage>35</fpage><lpage>40</lpage></element-citation></ref><ref id="bib9"><label>9</label><mixed-citation publication-type="other" id="oref1">Pennebaker JW, Francis ME, Booth RJ. Linguistic Inquiry and Word Count: Liwc 2001. Mahwah: Lawrence Erlbaum Associates; 2001; 71: p. 2001.</mixed-citation></ref><ref id="bib10"><label>10</label><element-citation publication-type="journal" id="sref10"><person-group person-group-type="author"><name><surname>Mehl</surname><given-names>M.R.</given-names></name><name><surname>Gosling</surname><given-names>S.D.</given-names></name><name><surname>Pennebaker</surname><given-names>J.W.</given-names></name></person-group><article-title>Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life</article-title><source>J Pers Soc Psychol</source><volume>90</volume><year>2006</year><fpage>862</fpage><lpage>877</lpage><pub-id pub-id-type="pmid">16737378</pub-id></element-citation></ref><ref id="bib11"><label>11</label><element-citation publication-type="journal" id="sref11"><person-group person-group-type="author"><name><surname>Dodge</surname><given-names>H.H.</given-names></name><name><surname>Mattek</surname><given-names>N.</given-names></name><name><surname>Gregor</surname><given-names>M.</given-names></name><name><surname>Bowman</surname><given-names>M.</given-names></name><name><surname>Seelye</surname><given-names>A.</given-names></name><name><surname>Ybarra</surname><given-names>O.</given-names></name></person-group><article-title>Social markers of mild cognitive impairment: Proportion of word counts in free conversational speech</article-title><source>Curr Alzheimer Res</source><volume>12</volume><year>2014</year><fpage>513</fpage><lpage>519</lpage></element-citation></ref><ref id="bib12"><label>12</label><element-citation publication-type="journal" id="sref12"><person-group person-group-type="author"><name><surname>Dodge</surname><given-names>H.H.</given-names></name><name><surname>Zhu</surname><given-names>J.</given-names></name><name><surname>Mattek</surname><given-names>N.C.</given-names></name><name><surname>Bowman</surname><given-names>M.</given-names></name><name><surname>Ybarra</surname><given-names>O.</given-names></name><name><surname>Wild</surname><given-names>K.V.</given-names></name></person-group><article-title>Web-enabled conversational interactions as a method to improve cognitive functions: Results of a 6-week randomized controlled trial</article-title><source>Alzheimers Dement (N Y)</source><volume>1</volume><year>2015</year><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">26203461</pub-id></element-citation></ref><ref id="bib13"><label>13</label><element-citation publication-type="journal" id="sref13"><person-group person-group-type="author"><name><surname>Kemper</surname><given-names>S.</given-names></name><name><surname>LaBarge</surname><given-names>E.</given-names></name><name><surname>Ferraro</surname><given-names>F.R.</given-names></name><name><surname>Cheung</surname><given-names>H.</given-names></name><name><surname>Cheung</surname><given-names>H.</given-names></name><name><surname>Storandt</surname><given-names>M.</given-names></name></person-group><article-title>On the preservation of syntax in Alzheimer's disease: Evidence from written sentences</article-title><source>Arch Neurol</source><volume>50</volume><year>1993</year><fpage>81</fpage><lpage>86</lpage><pub-id pub-id-type="pmid">8418805</pub-id></element-citation></ref><ref id="bib14"><label>14</label><element-citation publication-type="journal" id="sref14"><person-group person-group-type="author"><name><surname>Lyons</surname><given-names>K.</given-names></name><name><surname>Kemper</surname><given-names>S.</given-names></name><name><surname>LaBarge</surname><given-names>E.</given-names></name><name><surname>Ferraro</surname><given-names>F.R.</given-names></name><name><surname>Balota</surname><given-names>D.</given-names></name><name><surname>Storandt</surname><given-names>M.</given-names></name></person-group><article-title>Oral language and Alzheimer's disease: A reduction in syntactic complexity</article-title><source>Aging Neuropsychol Cogn</source><volume>1</volume><year>1994</year><fpage>271</fpage><lpage>281</lpage></element-citation></ref><ref id="bib15"><label>15</label><element-citation publication-type="journal" id="sref15"><person-group person-group-type="author"><name><surname>Bucks</surname><given-names>R.</given-names></name><name><surname>Singh</surname><given-names>S.</given-names></name><name><surname>Cuerden</surname><given-names>J.M.</given-names></name><name><surname>Wilcock</surname><given-names>G.K.</given-names></name></person-group><article-title>Analysis of spontaneous, conversational speech in dementia of Alzheimer type: Evaluation of an objective technique for analysing lexical performance</article-title><source>Aphasiology</source><volume>14</volume><year>2000</year><fpage>71</fpage><lpage>91</lpage></element-citation></ref><ref id="bib16"><label>16</label><element-citation publication-type="journal" id="sref16"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>S.</given-names></name><name><surname>Bucks</surname><given-names>R.S.</given-names></name><name><surname>Cuerden</surname><given-names>J.M.</given-names></name></person-group><article-title>Evaluation of an objective technique for analysing temporal variables in DAT spontaneous speech</article-title><source>Aphasiology</source><volume>15</volume><year>2001</year><fpage>571</fpage><lpage>583</lpage></element-citation></ref><ref id="bib17"><label>17</label><element-citation publication-type="journal" id="sref17"><person-group person-group-type="author"><name><surname>Oulhaj</surname><given-names>A.</given-names></name><name><surname>Wilcock</surname><given-names>G.K.</given-names></name><name><surname>Smith</surname><given-names>A.D.</given-names></name><name><surname>de Jager</surname><given-names>C.A.</given-names></name></person-group><article-title>Predicting the time of conversion to mci in the elderly role of verbal expression and learning</article-title><source>Neurology</source><volume>73</volume><year>2009</year><fpage>1436</fpage><lpage>1442</lpage><pub-id pub-id-type="pmid">19794124</pub-id></element-citation></ref><ref id="bib18"><label>18</label><element-citation publication-type="book" id="sref18"><person-group person-group-type="author"><name><surname>Fraser</surname><given-names>K.C.</given-names></name><name><surname>Rudzicz</surname><given-names>F.</given-names></name><name><surname>Rochon</surname><given-names>E.</given-names></name></person-group><chapter-title>Using text and acoustic features to diagnose progressive aphasia and its subtypes</chapter-title><source>INTERSPEECH</source><year>2013</year><publisher-name>Citeseer</publisher-name><fpage>2177</fpage><lpage>2181</lpage></element-citation></ref><ref id="bib19"><label>19</label><element-citation publication-type="journal" id="sref19"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>D.</given-names></name><name><surname>Kapur</surname><given-names>P.</given-names></name><name><surname>Geldmacher</surname><given-names>D.</given-names></name><name><surname>Brockington</surname><given-names>J.</given-names></name><name><surname>Harrell</surname><given-names>L.</given-names></name><name><surname>DeRamus</surname><given-names>T.</given-names></name></person-group><article-title>Latent information in fluency lists predicts functional decline in persons at risk for Alzheimer disease</article-title><source>Cortex</source><volume>55</volume><year>2014</year><fpage>202</fpage><lpage>218</lpage><pub-id pub-id-type="pmid">24556551</pub-id></element-citation></ref><ref id="bib20"><label>20</label><element-citation publication-type="journal" id="sref20"><person-group person-group-type="author"><name><surname>Berisha</surname><given-names>V.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>LaCross</surname><given-names>A.</given-names></name><name><surname>Liss</surname><given-names>J.</given-names></name></person-group><article-title>Tracking discourse complexity preceding Alzheimer's disease diagnosis: A case study comparing the press conferences of Presidents Ronald Reagan and George Herbert Walker Bush</article-title><source>J Alzheimers Dis</source><volume>45</volume><year>2015</year><fpage>959</fpage><lpage>963</lpage><pub-id pub-id-type="pmid">25633673</pub-id></element-citation></ref><ref id="bib21"><label>21</label><element-citation publication-type="journal" id="sref21"><person-group person-group-type="author"><name><surname>Ahmed</surname><given-names>S.</given-names></name><name><surname>Haigh</surname><given-names>A.M.</given-names></name><name><surname>de Jager</surname><given-names>C.A.</given-names></name><name><surname>Garrard</surname><given-names>P.</given-names></name></person-group><article-title>Connected speech as a marker of disease progression in autopsy-proven Alzheimers disease</article-title><source>Brain</source><volume>136</volume><year>2013</year><fpage>3727</fpage><lpage>3737</lpage><pub-id pub-id-type="pmid">24142144</pub-id></element-citation></ref><ref id="bib22"><label>22</label><element-citation publication-type="journal" id="sref22"><person-group person-group-type="author"><name><surname>Kempler</surname><given-names>D.</given-names></name></person-group><article-title>Language changes in dementia of the Alzheimer type</article-title><source>Dementia&#x000a0;and Communication</source><year>1995</year><fpage>98</fpage><lpage>114</lpage></element-citation></ref><ref id="bib23"><label>23</label><element-citation publication-type="journal" id="sref23"><person-group person-group-type="author"><name><surname>Salmon</surname><given-names>D.P.</given-names></name><name><surname>Butters</surname><given-names>N.</given-names></name><name><surname>Chan</surname><given-names>A.S.</given-names></name></person-group><article-title>The deterioration of semantic memory in Alzheimer's disease</article-title><source>Can J Exp Psychol</source><volume>53</volume><year>1999</year><fpage>108</fpage><lpage>117</lpage><pub-id pub-id-type="pmid">10389493</pub-id></element-citation></ref><ref id="bib24"><label>24</label><mixed-citation publication-type="other" id="sref24">Jarrold W, Peintner B, Wilkins D, Vergryi D., Richey C, Gorno-Tempini ML, et&#x000a0;al. Aided diagnosis of dementia type through computer-based analysis of spontaneous speech. In: Proceedings of the ACL Workshop on Computational Linguistics and Clinical Psychology. 2014. p. 27&#x02013;36.</mixed-citation></ref><ref id="bib25"><label>25</label><element-citation publication-type="book" id="sref25"><person-group person-group-type="author"><name><surname>Lehr</surname><given-names>M.</given-names></name><name><surname>Prud'hommeaux</surname><given-names>E.T.</given-names></name><name><surname>Shafran</surname><given-names>I.</given-names></name><name><surname>Roark</surname><given-names>B.</given-names></name></person-group><chapter-title>Fully automated neuropsychological assessment for detecting mild cognitive impairment</chapter-title><source>INTERSPEECH</source><year>2012</year><fpage>1039</fpage><lpage>1042</lpage></element-citation></ref><ref id="bib26"><label>26</label><mixed-citation publication-type="other" id="sref26">Liang P, Taskar B, Klein D. Alignment by agreement. In: Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics: Association for Computational Linguistics. 2006. p. 104&#x02013;111.</mixed-citation></ref><ref id="bib27"><label>27</label><element-citation publication-type="book" id="sref27"><person-group person-group-type="author"><name><surname>T&#x000f3;th</surname><given-names>L.</given-names></name><name><surname>Gosztolya</surname><given-names>G.</given-names></name><name><surname>Vincze</surname><given-names>V.</given-names></name><name><surname>Hoffmann</surname><given-names>I.</given-names></name><name><surname>Szatl&#x000f3;czki</surname><given-names>G.</given-names></name></person-group><chapter-title>Automatic detection of mild cognitive impairment from spontaneous speech using asr</chapter-title><year>2015</year><publisher-name>ISCA</publisher-name><publisher-loc>Dresden</publisher-loc></element-citation></ref><ref id="bib28"><label>28</label><element-citation publication-type="journal" id="sref28"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>J.C.</given-names></name><name><surname>Ernesto</surname><given-names>C.</given-names></name><name><surname>Schafer</surname><given-names>K.</given-names></name><name><surname>Coats</surname><given-names>M.</given-names></name><name><surname>Leon</surname><given-names>S.</given-names></name><name><surname>Sano</surname><given-names>M.</given-names></name></person-group><article-title>Clinical dementia rating training and reliability in multicenter studies the Alzheimer's disease cooperative study experience</article-title><source>Neurology</source><volume>48</volume><year>1997</year><fpage>1508</fpage><lpage>1510</lpage><pub-id pub-id-type="pmid">9191756</pub-id></element-citation></ref><ref id="bib29"><label>29</label><element-citation publication-type="journal" id="sref29"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>D.</given-names></name><name><surname>Clark</surname><given-names>L.A.</given-names></name><name><surname>Tellegen</surname><given-names>A.</given-names></name></person-group><article-title>Development and validation of brief measures of positive and negative affect: The PANAS scales</article-title><source>J Pers Soc Psychol</source><volume>54</volume><year>1988</year><fpage>1063</fpage><lpage>1070</lpage><pub-id pub-id-type="pmid">3397865</pub-id></element-citation></ref><ref id="bib30"><label>30</label><element-citation publication-type="book" id="sref30"><person-group person-group-type="author"><name><surname>Pennebaker</surname><given-names>J.W.</given-names></name><name><surname>Booth</surname><given-names>R.J.</given-names></name><name><surname>Francis</surname><given-names>M.E.</given-names></name></person-group><chapter-title>Linguistic inquiry and word count: LIWC [computer software]</chapter-title><year>2007</year><publisher-name>liwc. net</publisher-name><publisher-loc>Austin, TX</publisher-loc></element-citation></ref><ref id="bib31"><label>31</label><mixed-citation publication-type="other" id="sref31">Hutto CJ, Gilbert E. Vader: A parsimonious rule-based model for sentiment analysis of social media text. In: Eighth International AAAI Conference on Weblogs and Social Media.&#x000a0;2014.</mixed-citation></ref><ref id="bib32"><label>32</label><element-citation publication-type="journal" id="sref32"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>H.A.</given-names></name><name><surname>Eichstaedt</surname><given-names>J.C.</given-names></name><name><surname>Kern</surname><given-names>M.L.</given-names></name><name><surname>Dziurzynski</surname><given-names>L.</given-names></name><name><surname>Ramones</surname><given-names>S.M.</given-names></name><name><surname>Agrawal</surname><given-names>M.</given-names></name></person-group><article-title>Personality, gender, and age in the language of social media: The open-vocabulary approach</article-title><source>PLoS One</source><volume>8</volume><year>2013</year><fpage>e73791</fpage><pub-id pub-id-type="pmid">24086296</pub-id></element-citation></ref><ref id="bib33"><label>33</label><element-citation publication-type="journal" id="sref33"><person-group person-group-type="author"><name><surname>Smola</surname><given-names>A.J.</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name></person-group><article-title>A tutorial on support vector regression</article-title><source>Stat Comput</source><volume>14</volume><year>2004</year><fpage>199</fpage><lpage>222</lpage></element-citation></ref><ref id="bib34"><label>34</label><element-citation publication-type="journal" id="sref34"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L.</given-names></name></person-group><article-title>Random forests</article-title><source>Machine Learn</source><volume>45</volume><year>2001</year><fpage>5</fpage><lpage>32</lpage></element-citation></ref><ref id="bib35"><label>35</label><element-citation publication-type="book" id="sref35"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name><name><surname>Smola</surname><given-names>A.J.</given-names></name></person-group><chapter-title>Learning With Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</chapter-title><year>2002</year><publisher-name>MIT press</publisher-name><publisher-loc>Cambridge</publisher-loc></element-citation></ref><ref id="bib36"><label>36</label><element-citation publication-type="journal" id="sref36"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name></person-group><article-title>Scikit-learn: Machine learning in python</article-title><source>The J Machine Learn Res</source><volume>12</volume><year>2011</year><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib37"><label>37</label><element-citation publication-type="journal" id="sref37"><person-group person-group-type="author"><name><surname>Hanley</surname><given-names>J.A.</given-names></name><name><surname>McNeil</surname><given-names>B.J.</given-names></name></person-group><article-title>The meaning and use of the area under a receiver operating characteristic (ROC) curve</article-title><source>Radiology</source><volume>143</volume><year>1982</year><fpage>29</fpage><lpage>36</lpage><pub-id pub-id-type="pmid">7063747</pub-id></element-citation></ref><ref id="bib38"><label>38</label><element-citation publication-type="journal" id="sref38"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group><article-title>Regression shrinkage and selection via the lasso</article-title><source>J R Stat Soc Ser B (Methodol)</source><volume>58</volume><year>1996</year><fpage>267</fpage><lpage>288</lpage></element-citation></ref><ref id="bib39"><label>39</label><element-citation publication-type="journal" id="sref39"><person-group person-group-type="author"><name><surname>Dietterich</surname><given-names>T.G.</given-names></name></person-group><article-title>Approximate statistical tests for comparing supervised classification learning algorithms</article-title><source>Neural Comput</source><volume>10</volume><year>1998</year><fpage>1895</fpage><lpage>1923</lpage><pub-id pub-id-type="pmid">9744903</pub-id></element-citation></ref><ref id="bib40"><label>40</label><element-citation publication-type="journal" id="sref40"><person-group person-group-type="author"><name><surname>Mathuranath</surname><given-names>P.</given-names></name><name><surname>George</surname><given-names>A.</given-names></name><name><surname>Cherian</surname><given-names>P.</given-names></name><name><surname>Alexander</surname><given-names>A.</given-names></name><name><surname>Sarma</surname><given-names>S.G.</given-names></name><name><surname>Sarma</surname><given-names>P.S.</given-names></name></person-group><article-title>Effects of age, education and gender on verbal fluency</article-title><source>J Clin Exp Neuropsychol</source><volume>25</volume><year>2003</year><fpage>1057</fpage><lpage>1064</lpage><pub-id pub-id-type="pmid">14566579</pub-id></element-citation></ref></ref-list><ack id="ack0010"><title>Acknowledgments</title><p>This work was supported by NIH National Institute on Aging&#x000a0;awards R01 AG033581, R01 AG042191, P30 AG008017, P30 AG024978.</p></ack></back></article>