<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Ear Hear</journal-id><journal-id journal-id-type="iso-abbrev">Ear Hear</journal-id><journal-id journal-id-type="publisher-id">AUD</journal-id><journal-title-group><journal-title>Ear and Hearing</journal-title></journal-title-group><issn pub-type="ppub">0196-0202</issn><issn pub-type="epub">1538-4667</issn><publisher><publisher-name>Williams And Wilkins</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24752284</article-id><article-id pub-id-type="pmc">4072445</article-id><article-id pub-id-type="art-access-id">00013</article-id><article-id pub-id-type="doi">10.1097/AUD.0000000000000020</article-id><article-categories><subj-group subj-group-type="heading"><subject>e-Research Articles</subject></subj-group></article-categories><title-group><article-title>Benefits of Phoneme Discrimination Training in a Randomized Controlled Trial of 50- to 74-Year-Olds With Mild Hearing Loss</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Ferguson</surname><given-names>Melanie A.</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Henshaw</surname><given-names>Helen</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Clark</surname><given-names>Daniel P. A.</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Moore</surname><given-names>David R.</given-names></name><xref ref-type="aff" rid="aff1">1,2,3</xref></contrib><aff id="aff1"><label>1</label>National Institute for Health Research Nottingham Hearing Biomedical Research Unit, Nottingham, United Kingdom; <label>2</label>Medical Research Council Institute of Hearing Research, Nottingham, United Kingdom; and <label>3</label>Cincinnati Children&#x02019;s Hospital, Cincinnati, Ohio, USA.</aff></contrib-group><author-notes><corresp id="c1">Address for correspondence: Melanie Ferguson, NIHR Nottingham Hearing Biomedical Research Unit, 113 The Ropewalk, Nottingham, United Kingdom NG1 5DU. E-mail: <email xlink:href="melanie.ferguson@nottingham.ac.uk">melanie.ferguson@nottingham.ac.uk</email></corresp></author-notes><pub-date pub-type="ppub"><month>7</month><year>2014</year></pub-date><pub-date pub-type="epub"><day>23</day><month>6</month><year>2014</year></pub-date><volume>35</volume><issue>4</issue><fpage>e110</fpage><lpage>e121</lpage><permissions><copyright-statement>Copyright &#x000a9; 2014 by Lippincott Williams &#x00026; Wilkins</copyright-statement><copyright-year>2014</copyright-year><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivitives 3.0 License, where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially.</license-p></license></permissions><self-uri xlink:type="simple" xlink:href="aud-35-e110.pdf"/><abstract><sec><title>Objectives:</title><p>The aims of this study were to (i) evaluate the efficacy of phoneme discrimination training for hearing and cognitive abilities of adults aged 50 to 74 years with mild sensorineural hearing loss who were not users of hearing aids, and to (ii) determine participant compliance with a self-administered, computer-delivered, home- and game-based auditory training program.</p></sec><sec><title>Design:</title><p>This study was a randomized controlled trial with repeated measures and crossover design. Participants were trained and tested over an 8- to 12-week period. One group (Immediate Training) trained during weeks 1 and 4. A second waitlist group (Delayed Training) did no training during weeks 1 and 4, but then trained during weeks 5 and 8. On-task (phoneme discrimination) and transferable outcome measures (speech perception, cognition, self-report of hearing disability) for both groups were obtained during weeks 0, 4, and 8, and for the Delayed Training group only at week 12.</p></sec><sec><title>Results:</title><p>Robust phoneme discrimination learning was found for both groups, with the largest improvements in threshold shown for those with the poorest initial thresholds. Between weeks 1 and 4, the Immediate Training group showed moderate, significant improvements on self-report of hearing disability, divided attention, and working memory, specifically for conditions or situations that were more complex and therefore more challenging. Training did not result in consistent improvements in speech perception in noise. There was no evidence of any test-retest effects between weeks 1 and 4 for the Delayed Training group. Retention of benefit at 4 weeks post-training was shown for phoneme discrimination, divided attention, working memory, and self-report of hearing disability. Improved divided attention and reduced self-reported hearing difficulties were highly correlated.</p></sec><sec><title>Conclusions:</title><p>It was observed that phoneme discrimination training benefits some but not all people with mild hearing loss. Evidence presented here, together with that of other studies that used different training stimuli, suggests that auditory training may facilitate cognitive skills that index executive function and the self-perception of hearing difficulty in challenging situations. The development of cognitive skills may be more important than the development of sensory skills for improving communication and speech perception in everyday life. However, improvements were modest. Outcome measures need to be appropriately challenging to be sensitive to the effects of the relatively small amount of training performed.</p></sec></abstract><abstract abstract-type="toc"><p>The efficacy of phoneme discrimination training for enhancing hearing and related cognitive abilities in a typical, pre&#x02013;hearing aid population was evaluated. Significant and robust on-task learning was demonstrated. Benefits of training were seen in reduced hearing disability, particularly in complex listening environments, and in improved attention and working memory. These benefits were retained for at least 4 weeks posttraining. Compliance with home-delivered training was high. Auditory training thus provided modest benefit for complex and challenging skills that are relevant for listening in realistic environments.</p></abstract><kwd-group><kwd>Auditory</kwd><kwd>Cognition</kwd><kwd>Learning</kwd><kwd>Speech perception</kwd><kwd>Training</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>STATUS</meta-name><meta-value>ONLINE-ONLY</meta-value></custom-meta><custom-meta><meta-name>OPEN-ACCESS</meta-name><meta-value>TRUE</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro"><title>INTRODUCTION</title><p>Auditory learning, defined as improved listening through training (<xref rid="R41" ref-type="bibr">Moore et al. 2009</xref>), has been used since the 1950s as a clinical intervention aimed at improving communication abilities in people with hearing loss (<xref rid="R4" ref-type="bibr">Bamford 1981</xref>). The advent in the mid 1990s of commercial auditory training programs, such as Fast ForWord for children with language-based learning impairments (<xref rid="R59" ref-type="bibr">Tallal et al. 1996</xref>), provided widespread, cost-effective, easy-to-deliver training solutions that could be tailored to suit individual needs for home use. This in turn promoted a proliferation of research on individualized, computer-generated auditory training and learning. The general aim of the research was to understand the underlying principles and mechanisms of auditory training in normally hearing listeners (<xref rid="R65" ref-type="bibr">Wright et al. 1997</xref>; <xref rid="R2" ref-type="bibr">Amitay et al. 2005</xref>, <xref rid="R3" ref-type="bibr">2006</xref>) and the efficacy of such interventions to improve receptive speech perception in those with hearing loss (<xref rid="R19" ref-type="bibr">Fu et al. 2004</xref>; <xref rid="R8" ref-type="bibr">Burk et al. 2006</xref>; <xref rid="R55" ref-type="bibr">Stecker et al. 2006</xref>). However, despite a growing increase of training products and research, we still have little clear understanding of how effective auditory training is for improving everyday listening skills.</p><p>A systematic review of the literature (<xref rid="R56" ref-type="bibr">Sweetow &#x00026; Palmer 2005</xref>) examined the evidence that auditory training improves communication skills in adults with hearing loss. The review identified six peer-reviewed articles published between 1970 and 1996, which met the following inclusion criteria (1) randomized controlled trials (RCTs), non-RCTs, cohort, and before/after designs, with or without a control group, (2) adults with hearing loss, but not cochlear implant users, (3) training paradigm as the independent variable, and (4) outcome measures related to speech perception, or self-perception of communication abilities. It was concluded that although there was some evidence to support improved auditory skills trained during the published studies, there was no firm evidence to suggest that auditory training translated to effective, real-world benefits. The review also pointed out that these studies generally lacked scientific rigor. Four of 6 failed to include a control group, necessary to distinguish training-related improvement from test-retest effects (see also <xref rid="R36" ref-type="bibr">McArthur 2007</xref>), and none conducted a power calculation to define the appropriate sample size to detect clinically meaningful post-training differences.</p><p>A recent systematic review of studies since 1996 that used individual computer-based auditory training for adults with hearing loss identified 13 studies of very low to moderate study quality (<xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a). Quality concerns included inadequate control for procedural learning or for placebo effects; very few of the more recent studies included a control group to assess test-retest effects. Furthermore, very few studies included a power calculation. Some did not report results from all the outcome measures obtained, leading to a lack of transparency. Finally, blinding of participant or tester was rarely implemented. A key finding was that &#x0201c;on-task learning&#x0201d; (i.e., improvement on the trained task) usually occurred for a range of stimuli including monosyllables, syllables, words, and phrases in people with hearing loss (<xref rid="R8" ref-type="bibr">Burk et al. 2006</xref>; <xref rid="R7" ref-type="bibr">Burk &#x00026; Humes 2008</xref>; <xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>) and for both hearing aid users (<xref rid="R55" ref-type="bibr">Stecker et al. 2006</xref>; Sweetow &#x00026; Henderson Sabes 2006; <xref rid="R37" ref-type="bibr">Miller et al. 2008</xref>) and cochlear implant users (<xref rid="R19" ref-type="bibr">Fu et al. 2004</xref>; <xref rid="R37" ref-type="bibr">Miller et al. 2008</xref>; <xref rid="R60" ref-type="bibr">Tyler et al. 2010</xref>; <xref rid="R45" ref-type="bibr">Oba et al. 2011</xref>).</p><p>That on-task learning occurs is interesting theoretically, and supports animal models of neuroplasticity (<xref rid="R47" ref-type="bibr">Recanzone et al. 1993</xref>). The evidence to support off-task or &#x0201c;generalization&#x0201d; of learning (i.e., improvements in tasks that are not trained directly) is considerably less clear (<xref rid="R56" ref-type="bibr">Sweetow &#x00026; Palmer 2005</xref>; <xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a). To date, the &#x0201c;gold standard&#x0201d; clinical test for demonstrating generalization has been improvements in speech-in-noise perception, the most common complaint of people with hearing loss. This is reflected in the majority of auditory training studies, which used speech training stimuli as well as speech outcome measures (<xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a) Although there is evidence to suggest that training using multiple talkers promotes greater word-in-noise learning and that word-in-noise training can generalize to unfamiliar speakers (<xref rid="R8" ref-type="bibr">Burk et al. 2006</xref>), such training does not always lead to generalization to unfamiliar words, nor familiar words embedded in unfamiliar sentences (<xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>). Training on syllables or phonemes has been shown to transfer to improvements in word-in-sentence and sentence perception in cochlear implant users (<xref rid="R17" ref-type="bibr">Fu et al. 2005</xref>, <xref rid="R18" ref-type="bibr">2008</xref>) but not in hearing aid users (<xref rid="R55" ref-type="bibr">Stecker et al. 2006</xref>; <xref rid="R64" ref-type="bibr">Woods &#x00026; Yund 2007</xref>).</p><p>While it is important to be able to demonstrate that auditory training results in measurable performance improvements, such as speech perception, it is also important for those doing the training to feel that it is benefiting them in everyday conversation, which may be best shown in self-report questionnaires. Therefore, assessment of benefit should include both subjective and objective measures (<xref rid="R58" ref-type="bibr">Sweetow &#x00026; Henderson Sabes 2010</xref>). Our systematic review noted self-reported outcomes were used in only 3 of the 13 studies, with mixed results. Improvements were shown for hearing handicap, measured by the Hearing Handicap Inventory for the Elderly and the Communication Scale for Older Adults (Sweetow &#x00026; Henderson Sabes 2010), but not by the Speech Spatial and Qualities of Hearing questionnaire (<xref rid="R30" ref-type="bibr">Ingvalson et al. 2013</xref>) or a health status questionnaire, the Glasgow Benefit Inventory (<xref rid="R54" ref-type="bibr">Stacey et al. 2010</xref>).</p><p>An increasing acknowledgment of the importance of cognition (e.g., memory and attention) in listening ability over the last 10 years has been reflected in auditory learning research. <xref rid="R3" ref-type="bibr">Amitay et al. (2006</xref>) showed that robust learning can occur in normally hearing adults attempting to discriminate identical tones; an impossible task. This suggests that the effects of auditory training extend beyond sensory discrimination per se, drawing upon top-down, cognitive mechanisms to improve auditory performance. This is supported by improvements in attention, auditory working memory (Stroop, listening span; Sweetow &#x00026; Henderson Sabes 2006) and global auditory memory (<xref rid="R35" ref-type="bibr">Mahncke et al. 2006</xref>) after training on auditory stimuli.</p><p>For auditory training to be effective, those undertaking it need to comply with the intervention. As with many health-change behaviors, such as cessation of smoking and drinking alcohol (<xref rid="R11" ref-type="bibr">Curry et al. 1991</xref>; <xref rid="R15" ref-type="bibr">DiClemente et al. 1999</xref>), compliance with behavioral interventions over relatively prolonged times can be poor, and auditory training is no exception. For example, compliance rates in the United States with the Listening and Communication Enhancement (LACE) software in a clinical population were low, at 30% (Sweetow &#x00026; Henderson Sabes 2010). Historically, auditory training programs have called for prolonged training (e.g., Fast ForWord with children; typically 1 hr a day, 5 days a week for 8 weeks), but usually without any empirical evidence to support this. Besides the fact that this training is time-consuming and demotivating, it may not be necessary to train for so long. In addition, <xref rid="R39" ref-type="bibr">Molloy et al. (2012</xref>) have shown that for simple auditory stimuli (a frequency discrimination task) there is increased on-task learning when shorter training sessions (~8 min) rather than longer ones (&#x0003e;1 hr) are used. However, systematic studies of visual learning show that outcomes are, in general, related to the amount of training (<xref rid="R33" ref-type="bibr">Levi 2012</xref>).</p><p>One other important factor when considering auditory training as an effective clinical intervention is that speech perception performance and communication are maintained over time (Sweetow &#x00026; Henderson Sabes 2006; <xref rid="R60" ref-type="bibr">Tyler et al. 2010</xref>; <xref rid="R45" ref-type="bibr">Oba et al. 2011</xref>). Current evidence suggests that post-training performance on the trained tasks does not drop back to baseline for periods of up to 6 months, and that post-training performance levels can be regained with top-up training sessions of as little as 1 hr (<xref rid="R8" ref-type="bibr">Burk et al. 2006</xref>).</p><p>There are still a large number of outstanding questions on the benefits of auditory training, some of which are summarized by <xref rid="R5" ref-type="bibr">Boothroyd (2010</xref>). These include establishing which aspects of auditory training protocols contribute to learning, how auditory training generalizes to benefits in everyday communication and quality of life, and how individual characteristics interact with training outcomes to identify candidacy for auditory training. To answer these questions with high-quality evidence, factors to be considered include the clear reporting of results (e.g., according to the CONsolidated Standards Of Reporting Trials [CONSORT] statement; see <xref rid="R50" ref-type="bibr">Schulz et al. 2010</xref>) and the use of outcome measures that are appropriate and sensitive (<xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a). Only one study in our recent systematic review investigated the effects of auditory training on generalization to speech perception, self-report of communication difficulties and cognition (Sweetow &#x00026; Henderson Sabes 2006; <xref rid="R25" ref-type="bibr">Henderson Sabes &#x00026; Sweetow 2007</xref>). Significant improvements were seen in all three areas, although not for all individual tests. As speech perception and cognition underpin communication abilities (<xref rid="R31" ref-type="bibr">Kiessling et al. 2003</xref>), the main focus in the present study was to examine outcomes across speech perception, cognition, and self-report of hearing difficulties to identify whether, and how, auditory training was contributing to communication.</p><p>Most auditory training studies show highly variable outcomes across individual participants (<xref rid="R19" ref-type="bibr">Fu et al. 2004</xref>; <xref rid="R2" ref-type="bibr">Amitay et al. 2005</xref>; <xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>; <xref rid="R54" ref-type="bibr">Stacey et al. 2010</xref>; <xref rid="R38" ref-type="bibr">Millward et al. 2011</xref>), and not everyone benefits from training (<xref rid="R19" ref-type="bibr">Fu et al. 2004</xref>; <xref rid="R45" ref-type="bibr">Oba et al. 2011</xref>). From a clinical intervention perspective, an important goal is to identify accurately who will benefit from auditory training. This could then lead to individually targeted interventions to promote effective remediation of hearing and communication difficulties, resulting in reduced disability and handicap.</p><p>Auditory training has the potential to be a useful clinical intervention to support people with hearing loss. This includes those who are hearing aid users as well as those who choose not to wear hearing aids, or those who have mild hearing loss and would not necessarily benefit from amplification. The present phoneme discrimination training study focused on adults with mild sensorineural hearing loss who were experiencing hearing difficulties, but had not yet sought intervention for their hearing loss. The study&#x02019;s aims were as follows:</p><list list-type="order"><list-item><p>to ascertain whether phoneme discrimination training delivered improvements of trained and untrained hearing and cognitive related skills;</p></list-item><list-item><p>to determine whether improvements were due to learning or to test familiarity (i.e., test-retest) effects;</p></list-item><list-item><p>to investigate whether learning was retained after a period without training; and</p></list-item><list-item><p>to determine participant compliance with a home-based, computerized phoneme discrimination training program.</p></list-item></list></sec><sec><title>PARTICIPANTS AND METHODS</title><p>This study is reported in accordance with the CONSORT statement (<xref rid="R50" ref-type="bibr">Schulz et al. 2010</xref>), which offers guidance for the transparent and unbiased reporting of RCTs. The CONSORT statement is intended to improve the reporting of RCTs, enabling readers to understand a trial&#x02019;s design, conduct, analysis, and interpretation, and to assess the validity of its results.</p><sec><title>Participants</title><p>Adults were initially recruited via three local Nottingham primary care practices, which sent a hearing screening questionnaire (<xref rid="R12" ref-type="bibr">Davis et al. 2007</xref>) to all patients who were aged 50 to 74 years (total n = 3326) on their register. The questionnaire return rate was 42.2% (n = 1471) of whom 1152 indicated a willingness to participate in further research. Of these, 211 people who reported hearing difficulties in both ears agreed to participate and 96 participants attended the initial test session.</p><p>A total of 44 participants (15 female, 29 male) met the inclusion criteria: (1) having symmetrical mild, sensorineural hearing loss (better ear pure-tone average thresholds between 21 and 40 dB HL across 0.5, 1, 2, and 4 kHz), (2) being a non-hearing aid user, (3) being able to run simple computer games or control a mouse if never used a computer before, and (4) having English as first language. Exclusions from the study (n = 52) were on the basis of audiometric results (n = 44), being an existing hearing aid user (n = 3), unwillingness to participate (n = 4), or inability to control a computer mouse (n = 1).</p><p>Participants were allocated to either the Immediate Training group (IT; n = 23) or a wait listed Delayed Training group (DT; n = 21) by the second author using the method of minimization (<xref rid="R1" ref-type="bibr">Altman 1991</xref>). The grouping variables for minimization were age (younger, 50 to 62 years; older, 63 to 74 years), better hearing threshold levels (HTLs) across 0.5 to 4 kHz (better ear, 20 to 29 dB HL; poorer ear, 30 to 39 dB HL), and sex (male; female).</p></sec><sec sec-type="methods"><title>Design and Study Procedure</title><p>The study used a randomized, controlled, quasi-crossover design, shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. Outcome measures were obtained at all visits. Test sessions are labeled so that training occurred between times t1 and t2, and the retention period occurred between times t2 and t3 for both groups. The control (no-training) period for the DT group between t0 and t1 enabled assessment of test-retest effects. The auditory training software was demonstrated to all participants in the lab at t1, before their training. The primary outcome measure was the digit triplets test. On the basis of data from the study by <xref rid="R61" ref-type="bibr">Wagener (2009</xref>), a power calculation to show a 2.5 dB signal to noise ratio (SNR) difference between the two groups, assuming a two-sided significance level of 0.05 and 80% power, indicated a requirement to see 20 participants in each group. On the basis of a paired-sample <italic>t</italic> test, this would result in a large effect size (Cohen&#x02019;s <italic>d</italic> = 0.89).</p><fig id="F1" position="float"><label>Fig. 1.</label><caption><p>Study design. Outcome measures were obtained for Immediate Training (IT) and Delayed Training (DT) groups during up to 4 visits, interspersed either with home-based phoneme discrimination training or an equivalent (control) period without training.</p></caption><graphic xlink:href="aud-35-e110-g001"/></fig><p>The study was approved by the Nottingham Research Ethics Committee and Nottingham University Hospitals Trust Research and Development. Signed, informed consent was obtained. Participants were paid a nominal attendance fee and travel expenses for each visit, and a small inconvenience fee to partly recompense their time for doing the auditory training.</p></sec><sec><title>Outcome Measures</title><sec><title>Audiological Measures</title><p>Pure-tone air conduction thresholds (0.25, 0.5, 1, 2, 3, 4, and 8 kHz) were obtained for each ear and pure-tone bone conduction thresholds as required (0.5, 1, and 2 kHz), following the procedure recommended by the British Society of Audiology (<xref rid="R6" ref-type="bibr">BSA 2004</xref>), using a Siemens (Crawley, West Sussex, UK) Unity PC audiometer, Sennheiser (Hanover, Germany) HDA-200 headphones, and B71 Radioear (New Eagle, PA) transducer in a sound-attenuating booth. Otoscopy was performed and middle ear function was assessed by standard clinical tympanometry by using a GSI Tympstar (Grason-Stadler, Eden Prairie, MN).</p></sec><sec><title>Cognitive Measures</title><p><italic>Nonverbal intelligence quotient</italic> (NVIQ) was established using the Matrix Reasoning subtest of the Wechsler Abbreviated Scale of Intelligence (<xref rid="R63" ref-type="bibr">Wechsler 1999</xref>).</p><p>The Digit Span subtest (forward followed by backward) from the Wechsler Adult Intelligence Scale-Third Edition (<xref rid="R62" ref-type="bibr">Wechsler 1997</xref>) was used to measure <italic>working memory</italic>. Pairs of prerecorded spoken digit (0 to 9) sequences were presented at 70 dBA via Sennheiser HD-25 headphones. On successful recall of each sequence pair, the sequence increased by one digit. Discontinuation occurred when both sequences were recalled incorrectly.</p><p>The Visual Letter Monitoring task (VLM) tested <italic>visual working memory</italic> (<xref rid="R21" ref-type="bibr">Gatehouse et al. 2003</xref>). There were 10 consonant-vowel-consonant words embedded in an 80-letter sequence, and two sequences were alternated between the presentation rates across visits. Individual letters were displayed sequentially on a computer screen and participants pressed the keyboard spacebar (hit) when three consecutive letters formed a recognized consonant-vowel-consonant word (e.g., M-A-T). There were two runs, with the initial presentation rate of 1 letter/2 s, followed by 1 letter/1 s.</p><p><italic>Divided attention</italic> was assessed using the Test of Everyday Attention (TEA) (<xref rid="R48" ref-type="bibr">Robertson et al. 1994</xref>). The Telephone Search (subtest 6; single attention) required symbols (n = 20) to be identified correctly, as fast as possible, while searching a simulated telephone directory. The Telephone Search While Counting (subtest 7; dual attention) required the Telephone Search to be performed while simultaneously counting strings of 1 kHz tones. The time per target for each subtest and the dual-task decrement (DTD; difference between single and dual tasks) were measured using different test versions across visits.</p></sec><sec><title>Speech Perception in Noise Measures</title><p>Two measures of speech perception in noise were presented free-field at a distance of 1 m. The <italic>Adaptive Sentence List</italic> (ASL) test (<xref rid="R34" ref-type="bibr">MacLeod &#x00026; Summerfield 1990</xref>) presented sentence lists each comprising 30 items, mixed with an 8 Hz modulated noise, fixed at 60 dBA (<xref rid="R38" ref-type="bibr">Millward et al. 2011</xref>). Three different sentence lists were used, one at each visit. Sentences consisted of five words, including three key words (e.g., the <italic>lunch</italic> was <italic>very early</italic>), scored correct when all key words were identified. Initial sentence presentation was at 80 dBA, which varied adaptively, in 10 and 5 dB steps over two, one down-one up reversals, changing to a three down-one up paradigm using a 2.5 dB step size. The speech reception threshold (SRT) was the average SNR of the last two reversals in dB.</p><p>The <italic>Digit Triplets test</italic> (<xref rid="R53" ref-type="bibr">Smits &#x00026; Houtgast 2004</xref>; <xref rid="R52" ref-type="bibr">Smits et al. 2005</xref>) presented series of three digits (monosyllables 0 to 9) against steady, speech-shaped background noise. Six digit lists were randomized to minimize order effects. An audibility check was performed at 65 dB SPL in quiet to ensure identification of &#x0003e;80%, which was increased by 5 dB until the criterion was reached. Speech level was typically 65 dB SPL. Initial digit presentation was at +5 dB SNR, and the noise varied adaptively in 2 dB steps with one down-one up reversals, and continued until 27 trials were completed. The SRT in dB was the 50% correct level.</p></sec><sec><title>Self-Report Questionnaires</title><p>The <italic>Glasgow Hearing Aid Benefit Profile</italic> (GHABP; <xref rid="R20" ref-type="bibr">Gatehouse 1999</xref>) assessed hearing disability and handicap using four predefined situations (e.g., having a conversation with 1 other person when there is no background noise; having a conversation with several people in a group) on a five-point scale (1 = no difficulty to 5 = cannot manage at all). The overall hearing Disability and Handicap scores were the mean scores converted to a percentage.</p><p>The <italic>Speech, Spatial and Qualities of Hearing</italic> (SSQ; <xref rid="R22" ref-type="bibr">Gatehouse &#x00026; Noble 2004</xref>) assessed abilities and experience of hearing in different listening situations. It comprises 49 questions across three scales (1) Speech hearing (n = 14) (2) Spatial hearing (n = 17), and (3) Qualities of hearing (n = 18). Participants rated their hearing ability along a 0 to 10 visual analog scale for each question (0 = not at all to 10 = perfectly). Mean scores for each scale were derived.</p></sec><sec><title>Phoneme Probe</title><p>The discrimination threshold (%) for one phoneme continuum (/e/ and /a/) of the training task (given later in the article). Participants completed one track of 30 trials at each visit.</p></sec></sec><sec><title>Auditory Training</title><p>Home-delivered auditory training used a computer game format delivered on the IHR-STAR platform. Training was based on the &#x0201c;Phonomena&#x0201d; phoneme training package, fully described by <xref rid="R2" ref-type="bibr">Moore et al. (2005</xref>), but with graphics designed for adult participants. Eleven phoneme continua (/a/-/uh/, /b/-/d/, /d/-/g/, /e/-/a/, /er/-/or/, /i/-/e/, /l/-/r/, /m/-/n/, /s/-/sh/, /s/-/th/, and /v/-/w/), embedded in syllables where needed for natural articulation, were synthesized from endpoints consisting of real voice recordings. Each continuum transitioned from one phoneme to the other in 96 steps, saved as discrete.wav files. The stimuli were delivered through Sennheiser HD-25 headphones at a fixed level of 75 dBA. A three-interval, three-alternative, forced-choice, oddball paradigm was used; the participant&#x02019;s task was to choose the odd one out from three sequentially presented phonemes. Feedback (correct/incorrect response) was given. Initially, two (identical) phonemes were selected randomly from one end of the continuum and the odd (target) phoneme from the opposite end (i.e., .wav files #1 and #96). Correct detection of the target, delivered randomly in any of the three intervals, resulted on the next trial in the identical and target phonemes being chosen from a more difficult comparison (e.g., files #11 and #86; i.e., step size 10). Trials then varied adaptively over two, one down-one up reversals, step size 10 and 5, changing to a three down-one up paradigm using a step size of 2. Performance was measured in terms of the separation between stimulus file numbers at threshold. Phoneme discrimination threshold (%) was the average of the last two reversals over 35 trials.</p><p>Phoneme pairs were selected sequentially on a rotational basis. Participants were asked to train for 15 min/day, 6 days/week over a 4-week period (360 min in total). The training was delivered, and responses logged, using a Toshiba (Weybridge, Surrey) A300 laptop, locked down to run the training program only. Two initial demonstration tasks of five trials were undertaken before home-delivered training. At the end of each training session a graphical display plotted the average threshold each day and the cumulative training time.</p><p>There was no preselection of participants based on their computer skill levels because a significant proportion of the initial sample responding to the postal questionnaire had never used a personal computer (PC; 22.1%) or the Internet (54.2%; <xref rid="R26" ref-type="bibr">Henshaw et al. 2012a</xref>).</p></sec><sec><title>Analysis of Outcome Measures</title><p>To assess training and test-retest effects and to control for multiple testing that is implicit in repeated univariate analyses of variance, an intercept-only multivariate analysis of variance (MANOVA) for each category of key variables between the first two test sessions (IT, t1&#x02013;t2; DT, t0&#x02013;t1; <xref ref-type="fig" rid="F1">Fig. 1</xref>) was conducted for the IT (training effect) and DT (test-retest effect) groups separately. The key variables were grouped according to speech perception (ASL sentence-in-noise; Digit Triplets), cognition (TEA, single-task decrement and DTD; VLM, 1/s and 1/2s; Digit Span) and hearing-related self-report questionnaires (GHABP, Disability and Handicap; SSQ scales, Speech and Spatial).</p><p>To assess whether the IT group demonstrated any significant training-related improvements (t1&#x02013;t2) compared with the control period for the DT group (t0&#x02013;t1), a between-group MANOVA of the significant measures from the previous analysis was performed, with group (IT and DT) as the between-subjects factor.</p><p>The final analysis assessed training-related effects for the whole sample. If MANOVA showed no significant difference in the pretraining and post-training results (t1&#x02013;t2) between the Immediate and Delayed Training groups, the two groups were combined. A MANOVA was then performed for each set of pre- to post-training outcome measures (t1&#x02013;t2). Where significant training effects were shown, post hoc paired-sample <italic>t</italic> tests were performed to assess which individual outcome measures reached significance.</p><p>Between-group and between-visit improvements were signed to give a positive score. Effect size (Cohen&#x02019;s <italic>d</italic>) was derived for the change between visits based on the standard deviation of differences for repeated measures designs. Effect size was categorized as small, moderate, and large when Cohen&#x02019;s <italic>d</italic> was at 0.2, 0.5, and 0.8, respectively (<xref rid="R10" ref-type="bibr">Cohen 1988</xref>).</p></sec></sec><sec sec-type="results"><title>RESULTS</title><sec><title>Performance Before Training</title><p>At baseline (IT= t1; DT = t0; <xref ref-type="fig" rid="F1">Fig. 1</xref>) there were no significant demographic differences between the IT and DT groups: mean age (IT = 65.0 years; DT = 65.0 years), better ear HTL (0.5 to 4 kHz: IT = 28.2 dB HL; DT = 28.0 dB HL), socioeconomic status (Index of Multiple Deprivation; <xref rid="R43" ref-type="bibr">Noble et al. 2008</xref>; IT = 15,036; DT = 15,317), sex ratio (male:female: IT = 0.70; DT = 0.62), or nonverbal intelligence quotient (IT = 55.7; DT = 57.0). There was no significant difference between the groups for baseline phoneme discrimination thresholds, for any of the baseline performance tests or questionnaire scores (<xref ref-type="table" rid="T1">Table 1</xref>), or for computer skills (<xref ref-type="table" rid="T2">Table 2</xref>).</p><table-wrap id="T1" position="float"><label>TABLE 1.</label><caption><p>Mean (SD) for the on-task and off-task measures for the immediate training and delayed training groups at each visit</p></caption><graphic xlink:href="aud-35-e110-g002"/></table-wrap><table-wrap id="T2" position="float"><label>TABLE 2.</label><caption><p>Computer skill mix for all participants, the Immediate Training and Delayed Training groups</p></caption><graphic xlink:href="aud-35-e110-g003"/></table-wrap></sec><sec><title>Training Compliance</title><p>Compliance with training was high across all participants and there were no dropouts; 80% (35 of 44) of the sample completed the requested duration of training, with 75% (33 of 44) exceeding the required training. Mean training time across the three categories of computer user (never, beginner, and competent) was 384.9, 374.3, and 379.7 min, respectively. All participants completed at least 6 full blocks, and just over two thirds (70.8%) completed at least 10 blocks. The majority of those who did not meet the requested 360 min of training were beginners (n = 6), and the remaining three were competent PC users. All those who had never used a computer exceeded the required amount of training. There was no difference in the mean total training time for each group (IT = 377 min, SD = 50.7; DT = 378 min, SD = 46.3). The compliance rate was higher in the IT group (87%) than in the DT group (72%).</p></sec><sec><title>On-Task Phoneme Learning</title><p>Across both groups of participants there was a highly significant improvement with training in phoneme discrimination threshold for all 11 phoneme pairs (<italic>F</italic>(1, 3931.1) = 479.1, <italic>p</italic> &#x0003c; 0.001), shown in <xref ref-type="fig" rid="F2">Figure 2</xref>. This improvement was also evident for each group when considered separately (IT: <italic>F</italic>(1, 2043.3) = 153.3, <italic>p</italic> &#x0003c; 0.001; DT: <italic>F</italic>(1, 1911.2) = 84.2, <italic>p</italic> &#x0003c; 0.001). For each phoneme continuum, the regression line fitted to all the data points had a shallower slope than the diagonal, indicating the largest improvements occurred for those individuals who had the poorest initial thresholds (<xref ref-type="fig" rid="F3">Fig. 3</xref>). There was a significant correlation between the thresholds for the first and last block for each phoneme continuum, which ranged between <italic>r</italic> = 0.35 and<italic>r</italic> = 0.64, after excluding four outliers (outside the mean &#x000b1;3 SD). The vast majority of individual points fell below the diagonal, which showed that learning was evident for most participants on most of the phonemes. The overall magnitude of improvement was generally greatest for the phoneme continua that participants found most difficult to discriminate at the outset (partial &#x003b7;<sup>2</sup>: /d/-/g/ = 0.25; /s/-/th/ = 0.24; /b/-/d/ = 0.16; /a/-/uh/ = 0.16; /m/-/n/ = 0.16; /s/-/sh/ = 0.15; /er/-/or/ = 0.14; /e/-/a/ = 0.12; /v/-/w/ = 0.12; /i/-/e/ = 0.11; /l/-/r/ = 0.10).</p><fig id="F2" position="float"><label>Fig. 2.</label><caption><p>Phoneme discrimination thresholds improved with training. Mean phoneme discrimination threshold values for all 11 phoneme pairs across the training period (n = 44).</p></caption><graphic xlink:href="aud-35-e110-g004"/></fig><fig id="F3" position="float"><label>Fig. 3.</label><caption><p>The poorest initial phoneme discrimination thresholds improved the most with training. Thresholds for the first and last blocks for each individual participant. Correlation coefficient (r) = phoneme discrimination thresholds between the first and last blocks. Solid line = regression line fitted to all the data points.</p></caption><graphic xlink:href="aud-35-e110-g005"/></fig><p>There was a highly significant reduction in the mean probe threshold (/e/-/a/) after training in both groups (<xref ref-type="table" rid="T1">Table 1</xref>). There was no improvement in the DT group during the no-training control phase (t0&#x02013;t1), indicating that repeated testing on the probe did not itself produce improved performance (i.e., no test-retest effect). Nor did performance change for either group during the 4-week post-training period (IT: t1&#x02013;t2; DT: t2&#x02013;t3), indicating no further learning, or loss of learning.</p></sec><sec><title>Generalization of Learning</title><p>The main analysis compared outcome measures for (1) the within-group difference between the first two visits for the IT (t1&#x02013;t2) and DT groups (t0&#x02013;t1) separately, and (2) the between-group difference for the first two visits (see <xref ref-type="fig" rid="F1">Fig. 1</xref>). The mean and standard deviation of the outcome measures at each test session, for both groups, are shown in <xref ref-type="table" rid="T1">Table 1</xref>.</p><sec><title>Speech Perception</title><p>There was no significant between-visit change in speech-in-noise test SRTs for either the IT group (t1&#x02013;t2: <italic>F</italic>(2, 20) = 1.02, <italic>p</italic> = 0.38) or the DT group (t0&#x02013;t1: <italic>F</italic>(2, 19) = 2.51, <italic>p</italic> = 0.11), shown in <xref ref-type="fig" rid="F4">Figure 4</xref>.</p></sec><sec><title>Cognition</title><p>For the IT group, MANOVA showed a significant overall improvement in performance for all the cognitive measures between t1 and t2 (<italic>F</italic>(5, 13) = 3.43, <italic>p</italic> = 0.03). This improvement was significant for the TEA DTD (<italic>p</italic> = 0.02), VLM for 1/s (VLM<sub>1/s</sub>, <italic>p</italic> = 0.02) and VLM for 1/2s (VLM<sub>1/2s</sub>, <italic>p</italic> = 0.04), but not for the TEA single task (<italic>p</italic> = 0.06) or Digit Span (<italic>p</italic> = 0.12; Fig. 5; <xref ref-type="table" rid="T1">Table 1</xref>). For the DT group, there was no change in performance between t0 and t1 (<italic>F</italic>(5, 10) = 0.61, <italic>p</italic> = 0.69), suggesting no test-retest effects (<xref ref-type="fig" rid="F5">Fig. 5;</xref><xref ref-type="table" rid="T1">Table 1</xref>).</p><p>The between-group MANOVA across the first two test sessions for TEA DTD, VLM<sub>1/s</sub> and VLM<sub>1/2s</sub> showed only weak evidence to support a difference between the two groups (<italic>F</italic>(3, 29) = 2.74, <italic>p</italic> = 0.06), indicating that improvements for the IT group were not significantly greater than those for the DT group. For the combined group (IT and DT; t1&#x02013;t2), there was a significant overall pre- to post-training improvement for the TEA DTD, and both VLM tasks (<italic>F</italic>(3, 34) = 10.35, <italic>p</italic> &#x0003c; 0.001). Post hoc pairwise testing showed a significant effect of training for the TEA DTD (<italic>t</italic>(42) = 3.45, <italic>p</italic> = 0.001, Cohen&#x02019;s <italic>d</italic> = 0.53), VLM<sub>1/s</sub> (<italic>t</italic>(39) = 3.14, <italic>p</italic> = 0.003, <italic>d</italic> = 0.50), and VLM<sub>1/2s</sub> (<italic>t</italic>(37) = 2.10, <italic>p</italic> = 0.04, <italic>d</italic> = 0.34).</p></sec><sec><title>Self-Report Questionnaires</title><p>For the IT group, MANOVA showed a significant overall within-group improvement on GHABP and SSQ scores between t1 and t2 (<italic>F</italic>(4, 18) = 3.25, <italic>p</italic> = 0.03). This was significant for both the Disability (<italic>p</italic> = 0.004) and Handicap (<italic>p</italic> = 0.031) scales, shown in <xref ref-type="fig" rid="F6">Figure 6A</xref>, but not for the SSQ Speech (<italic>p</italic> = 0.28) or Spatial (<italic>p</italic> = 0.72) scales (see <xref ref-type="table" rid="T1">Table 1</xref>). For the DT group, there was no overall within-group change between t0 and t1 (<italic>F</italic>(4, 17) = 0.16, <italic>p</italic> = 0.96), suggesting no test-retest effect for GHABP or SSQ scales.</p><p>The between-group MANOVA across the first two test sessions for Disability and Handicap scores was not significant (<italic>F</italic>(2, 40) = 2.47, <italic>p</italic> = 0.09). For the combined group (IT and DT; t1&#x02013;t2), there was a significant pre- to post-training improvement (<italic>F</italic>(2,41) = 5.87, <italic>p</italic> = 0.006) for Disability and Handicap. Post hoc testing showed a highly significant effect of training for Disability (t(42) = 3.45, <italic>p</italic> = 0.001; <italic>d</italic> = 0.51) but not for Handicap (<italic>t</italic>(43) = 1.53, <italic>p</italic> = 0.13; <italic>d</italic> = 0.23).</p><p>Because significant benefit from training was shown for the overall Disability score, the same analysis was performed for the four individual GHABP Disability situations to assess whether improvements were dependent on situation. For the IT group, there was a significant overall within-group improvement between t1 and t2 (<italic>F</italic>(4, 15) = 4.0, <italic>p</italic> = 0.02), which was significant only for the &#x0201c;having a group conversation&#x0201d; situation (<xref ref-type="fig" rid="F6">Fig. 6B</xref>; <italic>p</italic> = 0.016). For the DT group there was no within-group change between t0 and t1 (<italic>F</italic>(4, 14) = 1.34, <italic>p</italic> = 0.30), suggesting no test-retest effect.</p><p>The between-group ANOVA across the first two test sessions for the &#x0201c;group conversation&#x0201d; situation was significant (<italic>F</italic>(1, 42) = 4.94, <italic>p</italic> = 0.03), indicating a significant improvement for the IT group compared with the DT group. For the combined group, there was a significant pre- to post-training (t1&#x02013;t2) improvement for group conversation (<italic>t</italic>(21) = 3.17, <italic>p</italic> = 0.005; <italic>d</italic> = 0.68; Fig. 6B).</p></sec></sec><sec><title>Retention of Learning</title><p>To assess retention of learning and retention of improvements in generalizable outcome measures from training, it is assumed there is some evidence of improvement. We have defined this as any increase in performance from pre- to post-training (t1&#x02013;t2). Of the measures that showed significant training-related improvement (training probe, GHABP Disability, TEA DTD, VLM tasks), between 52% and 75% of all participants showed some improvement (<xref ref-type="fig" rid="F7">Fig. 7</xref>). On these tasks, significant pre- to post-training improvements were retained to t3 without further training (<xref ref-type="fig" rid="F7">Fig. 7</xref>). The t3 results remained significantly better than pretraining performance (t1), and there was no significant change during the post-training delay period (t2&#x02013;t3) for any measure (see also <xref ref-type="table" rid="T1">Table 1</xref>).</p><p>We predicted that self-report would be related to performance and this was shown in the relationship between the overall GHABP Disability score with the TEA DTD. The 9 participants in the IT group who showed an improvement in both measures (<xref ref-type="fig" rid="F8">Fig. 8</xref>) supported this prediction (<italic>r</italic> = 0.79, <italic>p</italic> &#x0003c; 0.01). It is noteworthy that these 9 participants reported significantly greater Disability at baseline (t1) than the remaining participants in this group on overall GHABP (42.3% versus 29.0%, <italic>p</italic> &#x0003c; 0.05) and SSQ Speech (4.7 versus 6.0, <italic>p</italic> &#x0003c; 0.05) scores. This suggests that training-related improvements in divided attention can be predicted by poorer initial self-report on disability and speech recognition ability. There were no other factors at baseline that predicted benefit from training.</p></sec></sec><sec sec-type="discussion"><title>DISCUSSION</title><p>The overall aim of this study was to evaluate the benefits of a home-delivered, phoneme discrimination training program as a potential clinical intervention for people with mild hearing loss. A specific focus was on 50- to 74-year olds with mild sensorineural hearing loss who experienced hearing difficulties but did not have hearing aids. We found robust on-task learning of the trained phoneme continua, no improvement in speech-in-noise perception, and a mixed picture of positive and null effects on cognitive and self-report measures. Where improvements in outcome measures did occur, they were retained for at least 1 month.</p><p>Robust on-task learning was found on the trained task, consistent with many other training studies (e.g., <xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>; <xref rid="R41" ref-type="bibr">Moore et al. 2009</xref>; <xref rid="R66" ref-type="bibr">Wright et al. 2010</xref>). In the present study, learning was apparent for all 11 phonemic contrasts, and the greatest improvement was seen for those contrasts that had the poorest performance before training at both the group mean and individual levels. Other studies have shown similar results whereby training improved the ability to discriminate difficult consonants (<xref rid="R55" ref-type="bibr">Stecker et al. 2006</xref>), and improvements in the perception of degraded and competing speech were greatest in those with the poorest initial scores (<xref rid="R25" ref-type="bibr">Henderson Sabes &#x00026; Sweetow 2007</xref>). This suggests that the greatest gains on the trained task were made when initial performance was poorest.</p><p>The next and critical question for this study was whether learning transferred to improvements in untrained measures of benefit for those with mild hearing loss. As with many auditory training studies speech perception was included as a generalizable outcome but showed no significant improvement as a result of training. It may be that the high redundancy of sentence and some word stimuli reduced sensitivity to learning. The Digit Triplet test, for example, has only nine distinct speech stimuli, therefore limiting response possibilities. More generally, the evidence for transfer of learning to untrained measures of speech perception is mixed (<xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a), and where it did occur there were only modest gains. <xref rid="R57" ref-type="bibr">Sweetow and Henderson Sabes (2006</xref>) showed the largest effect sizes occurred in the QuickSIN when presented at the more difficult presentation level of 45 dB compared with 70 dB.</p><p>This study, unlike most other training studies, examined cognition, which along with speech perception has consequences for disability and handicap arising from hearing loss. There was a consistent pattern of change in pre- to post-training performance across the cognitive measures. Significant pre- to post-training improvements, with moderate effect sizes, were seen for the complex cognitive tasks (i.e., TEA divided attention, VLM). In contrast, there were no improvements in the simple cognitive tasks (TEA single attention, Digit Span). Performance improvements were retained at 1 month post-training at similar levels to those immediately post-training, suggesting improvements were robust in the participants (approximately two-thirds) who demonstrated them. These results suggest that cognitive outcome measures need to be appropriately complex and therefore challenging to be sensitive to effects of auditory training.</p><p>Although auditory training resulted in improved performance on the complex cognitive tasks, the mechanism underlying this may not be a result of the auditory stimulus per se, but a result of active engagement with the auditory stimulus (i.e., listening). One possible explanation for the difference in observed effects for the cognitive measures used in this study is the role of executive function, an umbrella term for cognitive processes that regulate, control, and manage other processes, such as attention, working memory, inhibition, and task-switching (<xref rid="R9" ref-type="bibr">Chan et al. 2008</xref>). Executive function and working memory have been shown to improve after a period of brain training (&#x0201c;Brain Age&#x0201d;) in young adults (<xref rid="R44" ref-type="bibr">Nouchi et al. 2013</xref>). This is consistent with our results whereby tasks that demonstrate significant post-training improvements also index executive functions (e.g., TEA divided attention [attention switching] and VLM [memory updating]). In contrast, tasks that do not demonstrate significant post-training effects do not index executive function (e.g., TEA single attention, Digit Span). The generality of this principle is further supported by evidence from a large study of multitask cognitive training in over 11,000 participants who demonstrated on-task learning but no generalizable learning on a simple Digit Span test (<xref rid="R46" ref-type="bibr">Owen et al. 2010</xref>). A further study to test the hypothesis that auditory training specifically improves performance on complex cognitive tasks in this population would allow a more definitive conclusion.</p><p>Of the self-report measures, training-related improvements were only demonstrated for overall hearing disability (GHABP), with a moderate effect size. Of the four individual situations that contributed to the GHABP overall score, the only significant pre- to post-training improvement, and the largest at 12.5%, was &#x0201c;having a conversation with several people in a group,&#x0201d; the most complex of the four listening situations. The other three situations improved slightly, between 2 and 6%, but none were significant. One inference from these results is that effects of training are only revealed and beneficial in listening situations that are complex, and therefore challenging. This is consistent with the cognitive results.</p><p>Effects of auditory training are often modest. In this study, pre- to post-training improvements were demonstrated within groups, but the IT group did not show significantly more improvements than the wait list DT group in the control condition. Ideally, a meta-analysis of high-quality published articles would be the best method to address the effectiveness of individual computer-based auditory training as intervention for those who have a hearing impairment. However, high variability in training stimuli (tones, syllables, words, phrases, sentences), training methods (adaptive, fixed level, user- or experimenter-controlled, home- or lab-based), outcome measures (different measures of speech perception, self-report), participant samples (hearing aid and cochlear implants users, range of hearing losses), and study quality is not currently conducive to such an approach.</p><p>Some factors that might contribute to the modest training effects include the unpredictability of task-related and procedural effects, the optimal amount of time to spend on training, and the nature of the training stimuli. In this study we demonstrated that the amount of learning varied for different training stimuli, and the proportion of participants who showed transfer of learning to generalizable outcomes varied for different outcome measures. To date, there is no clear evidence as to who would benefit from auditory training (<xref rid="R5" ref-type="bibr">Boothroyd 2010</xref>), although clearly this would be beneficial from a clinical perspective in terms of managing people with hearing loss. Separating procedural from perceptual learning is also problematic, with some researchers assuming that perceptual learning is a slow process requiring extensive familiarization with the training stimuli (<xref rid="R14" ref-type="bibr">Demany &#x00026; Semal 2002</xref>; <xref rid="R13" ref-type="bibr">Delhommeau et al. 2002</xref>). However, others have demonstrated that perceptual learning can be very rapid, and that procedural learning is often inaccurately confused with this early and rapid perceptual learning (<xref rid="R24" ref-type="bibr">Hawkey et al. 2004</xref>). Different study designs, such as the inclusion of control groups and crossover designs, can attempt to overcome or account for both task-related and procedural effects, but the uncertainty still remains. It is also unclear what the optimal duration of training is (<xref rid="R5" ref-type="bibr">Boothroyd 2010</xref>). It has been demonstrated that generalizable learning lags behind that of on-task learning (<xref rid="R66" ref-type="bibr">Wright et al. 2010</xref>). The duration of training should therefore be long enough to ensure full benefit from the transfer of learning. The vision training literature shows a clear association between the amount of training and generalizable learning effects (e.g., <xref rid="R33" ref-type="bibr">Levi 2012</xref>), that is, the longer the duration of training, the greater the learning. However, it has been shown for auditory frequency discrimination training that, possibly interacting with this effect, greater learning occurred with shorter rather than longer sessions (<xref rid="R39" ref-type="bibr">Molloy et al. 2012</xref>). The duration of training sessions in this study (15 min per day) was shorter than that used in other studies (e.g., <xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>, 75 to 90 min per day) because it was important that the home-based training regimen would be acceptable and achievable in this group of older adults. This was confirmed in follow-up focus groups of study participants who preferred daily sessions of 15 min to alternate-day sessions of 30 min (<xref rid="R28" ref-type="bibr">Henshaw et al. 2012b</xref>).</p><p>A question concerning the training task was whether it was the most suitable for developing phonetic identification. This question has two aspects, whether the use of &#x0201c;odd-one-out&#x0201d; selection promotes acoustic, rather than phonological awareness, and whether training around the boundary of a categorical perception task, which these tasks were, is preferred over training within a phoneme category. It is true that a listener could potentially ignore the phonological properties of this task and perform only on the basis of discrete auditory cues. However, the rationale, especially in the present study, was that the trained listeners had auditory rather than phonological processing problems, so it was probably best to focus on a speech-based task that delivered a large number of relevant auditory discrimination trials efficiently, than on one that emphasized identification of meaningless tokens. In fact, listeners in our similar studies (<xref rid="R38" ref-type="bibr">Millward et al. 2011</xref>; <xref rid="R23" ref-type="bibr">Halliday et al. 2012</xref>) when asked about their tactics, reported discriminating whole tokens (syllables) rather than meaningless sounds. Regarding the second aspect, of training around rather than outside a categorical boundary, we reasoned that auditory discriminations would be equally difficult in both situations, and that phonetic identification would only be possible around a boundary. Note that each continuum endpoint syllable was clearly identifiable at the start of each training track.</p><p>If auditory training is to be an effective clinical intervention for people with hearing loss, it is important that the training is performed, yet participant compliance often goes unreported. Where reported, compliance rates are often exaggerated, as they are based on participant dropout rather than on those completing the required training. Only 6 of 13 studies in our recent systematic review (<xref rid="R27" ref-type="bibr">Henshaw &#x00026; Ferguson 2013</xref>a) reported compliance figures (<xref rid="R55" ref-type="bibr">Stecker et al. 2006</xref>, 92.5%; Sweetow &#x00026; Henderson Sabes 2006, 73%; <xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>, 81%; <xref rid="R54" ref-type="bibr">Stacey et al. 2010</xref>, 73%; <xref rid="R45" ref-type="bibr">Oba et al. 2011</xref>, 100%; <xref rid="R68" ref-type="bibr">Zhang et al. 2012</xref>, 100%). These figures are comparable with the 80% found in the present study based on completion of required training, or 100% if participant dropout was set as compliance criterion. Of the other studies, only one training regimen was lab-based (<xref rid="R29" ref-type="bibr">Humes et al. 2009</xref>). This suggests that those completing home-based training, where lack of supervision might be expected to result in lower compliance, are as compliant as those undergoing lab-based training. However, high compliance in volunteers who take part in a training study does not necessarily translate to high compliance in a general clinical population. Sweetow &#x00026; Henderson Sabes (2010) reported compliance at 30% in a large-scale clinical trial of over 3000 participants of auditory training using LACE. It is not clear why compliance was so low but they speculate on the importance of clinician-patient interactions and patient motivation. Participants from the present study who took part in two focus groups indicated that hearing loss and the possibility of improving hearing were extrinsic motivators, whereas the desire to complete the training and to beat their previous scores during training were intrinsic motivators (Henshaw et al. 2012b). As with many health conditions, readiness to take action is required to change and improve health behaviors. The principles underpinning the Transtheoretical Health Behaviour Change Model (<xref rid="R16" ref-type="bibr">DiClemente &#x00026; Prochaska 1998</xref>), which define a person&#x02019;s health behavior stage (e.g., contemplation, preparation, action, and maintenance), can also be applied to auditory training. This would form a theoretical underpinning on which further research can establish predictors to identify those who will comply with auditory training.</p><p>In the present study the most robust generalization of learning was to complex cognitive measures. Working memory is highly associated with language comprehension (<xref rid="R49" ref-type="bibr">R&#x000f6;nnberg et al. 2008</xref>). As learning is always greatest on the task that has been trained, and listening ability is also related to cognition (<xref rid="R40" ref-type="bibr">Moore et al. 2010</xref>; <xref rid="R68" ref-type="bibr">Zhang et al. 2012</xref>), these results suggest that it may be beneficial to train cognition directly. We have recently completed a trial of a working memory training program (Cogmed) in a double-blind, randomized, active-controlled trial of hearing aid users (Henshaw &#x00026; Ferguson 2013b). A cognitive-based training study by <xref rid="R51" ref-type="bibr">Smith et al. (2009</xref>) using primarily auditory stimuli (Brain Fitness Program) showed improvements in both attention and working memory in older, though not necessarily hearing-impaired listeners, compared with an active control group (i.e., the control group had an activity to perform, in this case watching educational digital video discs). A study of working memory training has shown improvements in both memory and language (sentence repetition) skills in children with cochlear implants (Kronenberger et al. 2011). This early converging evidence suggests that to improve speech perception performance, the development of cognitive skills may be as important, or even more important than the development of sensory skills. Likewise, the development of listening or perceptual skills generally may be helped more by cognitive than by sensory training. Further research is required to inform the most effective training stimulus (auditory versus cognitive or a combination of both) to improve speech perception abilities for people with hearing loss.</p></sec><sec sec-type="conclusions"><title>CONCLUSIONS</title><p>Significant and robust learning was demonstrated for a phoneme discrimination task in 50- to 74-year-old adults with mild hearing loss. The largest learning effects were found for the most difficult-to-discriminate phonemes. Generalization of learning was shown with moderate effect sizes for complex but not simple measures of divided attention and working memory, and for hearing disability, specifically for complex listening conditions. There were no consistent training-related improvements in speech perception. In the participants who showed transfer of learning, the learning was retained for at least 4 weeks posttraining. Compliance with home-delivered training via laptop computers in this typical, pre-hearing aid population was high, even though only one third considered they were competent PC users. In conclusion, phoneme discrimination training as used in this study provided modest self-perceived benefit for listening abilities and for complex and challenging skills that are relevant for listening in realistic environments.</p><fig id="F4" position="float"><label>Fig. 4.</label><caption><p>Speech intelligibility did not change significantly with training or with repeated testing. Mean change (&#x00394;) in SNR for (A) ASL sentence-in-noise test (B) Digit Triplets test. Data here and in <xref ref-type="fig" rid="F5">Figs. 5</xref> and <xref ref-type="fig" rid="F6">6</xref> all show &#x00394; &#x000b1; 95% confidence interval comparing performance of Immediate Training group (t1-t2) and Delayed Training group (t0-t1) (see Fig. 1).</p></caption><graphic xlink:href="aud-35-e110-g006"/></fig><fig id="F5" position="float"><label>Fig. 5.</label><caption><p>Training improved complex but not simple attention and working memory. (A) Test of Everyday Attention (TEA) dual task decrement (DTD), (B) TEA single task, (C) Digit Span, (D) Visual Letter Monitoring (VLM) 1 letter/s and (E) VLM 1 letter/2s. For other details, see Fig. 4.</p></caption><graphic xlink:href="aud-35-e110-g007"/></fig><fig id="F6" position="float"><label>Fig. 6.</label><caption><p>Self-report of hearing disability and handicap improved with training. (A) Overall Glasgow Hearing Aid Benefit Profile (GHABP) scores, (B) GHABP "having a conversation with several people in a group." For other details, see Fig. 4.</p></caption><graphic xlink:href="aud-35-e110-g008"/></fig><fig id="F7" position="float"><label>Fig. 7.</label><caption><p>Benefits of training were retained in those that showed improvements (indicated by fractions of overall participants) for both the Immediate Training and Delayed training groups for (A) Phoneme probe discrimination, (B) GHABP activity, (C) TEA dual task decrement, (D) Visual Letter Monitoring (VLM) 1/s, and (E) VLM 1/2s. Mean change (&#x00394;) &#x000b1; 95 % confidence interval. t1 = pre-training, t2 = post-training, t3 = 4 weeks post-training.</p></caption><graphic xlink:href="aud-35-e110-g009"/></fig><fig id="F8" position="float"><label>Fig. 8.</label><caption><p>Improved hearing disability and divided attention correlated following training. Filled circles: trained participants who improved on both self-rating (GHABP) of hearing disability and divided attention (TEA dual task decrement, DTD). Unfilled circles: trained participants who did not improve on at least one measure. The regression line is relevant to the filled circles only.</p></caption><graphic xlink:href="aud-35-e110-g010"/></fig></sec><sec><title>ACKNOWLEDGMENTS</title><p>The authors thank Mark Edmondson-Jones for his statistical advice, and Alison Riley and Meg Wadnerker who helped with the data collection. Special thanks to the General Practices who helped the authors recruit the participants (Leen View Surgery, Bulwell; Tolkard Hill Medical Centre, Hucknall; Wollaton Vale Health Centre, Wollaton), and finally to the participants who gave their time to help the authors.</p></sec></body><back><fn-group><fn fn-type="financial-disclosure"><p>This article presents independent research funded by the National Institute for Health Research (NIHR) Biomedical Research Unit Programme. The views expressed are those of the authors and not necessarily those of the National Health Service, the NIHR or the Department of Health.</p></fn><fn fn-type="conflict"><p>The authors declare no other conflict of interest.</p></fn></fn-group><ref-list><title>REFERENCES</title><ref id="R1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>D.</given-names></name></person-group><source>Practical Statistics for Medical Research</source><year>(1991)</year><publisher-loc>London, United Kingdom</publisher-loc><publisher-name>Chapman &#x00026; Hall</publisher-name></element-citation></ref><ref id="R2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amitay</surname><given-names>S.</given-names></name><name><surname>Hawkey</surname><given-names>D. J.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name></person-group><article-title>Auditory frequency discrimination learning is affected by stimulus variability.</article-title><source>Percept Psychophys</source><year>(2005)</year><volume>67</volume><fpage>691</fpage><lpage>698</lpage><pub-id pub-id-type="pmid">16134462</pub-id></element-citation></ref><ref id="R3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amitay</surname><given-names>S.</given-names></name><name><surname>Irwin</surname><given-names>A.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name></person-group><article-title>Discrimination learning induced by training with identical stimuli.</article-title><source>Nat Neurosci</source><year>(2006)</year><volume>9</volume><fpage>1446</fpage><lpage>1448</lpage><pub-id pub-id-type="pmid">17028582</pub-id></element-citation></ref><ref id="R4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bamford</surname><given-names>J.</given-names></name></person-group><article-title>Auditory train. What is it, what is it supposed to do, and does it do it?</article-title><source>Br J Audiol</source><year>(1981)</year><volume>15</volume><fpage>75</fpage><lpage>78</lpage><pub-id pub-id-type="pmid">7225653</pub-id></element-citation></ref><ref id="R5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boothroyd</surname><given-names>A.</given-names></name></person-group><article-title>Adapting to changed hearing: The potential role of formal training.</article-title><source>J Am Acad Audiol</source><year>(2010)</year><volume>21</volume><fpage>601</fpage><lpage>611</lpage><pub-id pub-id-type="pmid">21241648</pub-id></element-citation></ref><ref id="R6"><element-citation publication-type="other"><collab>BSA</collab><article-title>Recommended procedure for pure tone air and bone conduction threshold audiometry with and without the use of masking and determination of uncomfortable loudness levels.</article-title><year>(2004)</year><comment>Retrieved from <ext-link ext-link-type="uri" xlink:href="http://www.thebsa.org.uk/docs/RecPro/PTA.pdf">http://www.thebsa.org.uk/docs/RecPro/PTA.pdf</ext-link> [serial online]</comment></element-citation></ref><ref id="R7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burk</surname><given-names>M. H.</given-names></name><name><surname>Humes</surname><given-names>L. E.</given-names></name></person-group><article-title>Effects of long-term training on aided speech-recognition performance in noise in older adults.</article-title><source>J Speech Lang Hear Res</source><year>(2008)</year><volume>51</volume><fpage>759</fpage><lpage>771</lpage><pub-id pub-id-type="pmid">18506049</pub-id></element-citation></ref><ref id="R8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burk</surname><given-names>M. H.</given-names></name><name><surname>Humes</surname><given-names>L. E.</given-names></name><name><surname>Amos</surname><given-names>N. E.</given-names></name><etal/></person-group><article-title>Effect of training on word-recognition performance in noise for young normal-hearing and older hearing-impaired listeners.</article-title><source>Ear Hear</source><year>(2006)</year><volume>27</volume><fpage>263</fpage><lpage>278</lpage><pub-id pub-id-type="pmid">16672795</pub-id></element-citation></ref><ref id="R9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>R. C.</given-names></name><name><surname>Shum</surname><given-names>D.</given-names></name><name><surname>Toulopoulou</surname><given-names>T.</given-names></name><etal/></person-group><article-title>Assessment of executive functions: Review of instruments and identification of critical issues.</article-title><source>Arch Clin Neuropsychol</source><year>(2008)</year><volume>23</volume><fpage>201</fpage><lpage>216</lpage><pub-id pub-id-type="pmid">18096360</pub-id></element-citation></ref><ref id="R10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J.</given-names></name></person-group><source>Statistical Power Analysis for the Behavioral Sciences</source><year>(1988)</year><edition>2nd ed.</edition><publisher-loc>Hillsdale, NJ</publisher-loc><publisher-name>Lawrence Earlbaum Associates</publisher-name></element-citation></ref><ref id="R11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curry</surname><given-names>S. J.</given-names></name><name><surname>Wagner</surname><given-names>E. H.</given-names></name><name><surname>Grothaus</surname><given-names>L. C.</given-names></name></person-group><article-title>Evaluation of intrinsic and extrinsic motivation interventions with a self-help smoking cessation program.</article-title><source>J Consult Clin Psychol</source><year>(1991)</year><volume>59</volume><fpage>318</fpage><lpage>324</lpage><pub-id pub-id-type="pmid">2030194</pub-id></element-citation></ref><ref id="R12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>A.</given-names></name><name><surname>Smith</surname><given-names>P.</given-names></name><name><surname>Ferguson</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Acceptability, benefit and costs of early screening for hearing disability: A study of potential screening tests and models.</article-title><source>Health Technol Assess</source><year>(2007)</year><volume>11</volume><fpage>1</fpage><lpage>294</lpage></element-citation></ref><ref id="R13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delhommeau</surname><given-names>K.</given-names></name><name><surname>Micheyl</surname><given-names>C.</given-names></name><name><surname>Jouvent</surname><given-names>R.</given-names></name><etal/></person-group><article-title>Transfer of learning across durations and ears in auditory frequency discrimination.</article-title><source>Percept Psychophys</source><year>(2002)</year><volume>64</volume><fpage>426</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">12049283</pub-id></element-citation></ref><ref id="R14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demany</surname><given-names>L.</given-names></name><name><surname>Semal</surname><given-names>C.</given-names></name></person-group><article-title>Learning to perceive pitch differences.</article-title><source>J Acoust Soc Am</source><year>(2002)</year><volume>108</volume><fpage>2964</fpage><lpage>2968</lpage></element-citation></ref><ref id="R15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiClemente</surname><given-names>C. C.</given-names></name><name><surname>Bellino</surname><given-names>L. E.</given-names></name><name><surname>Neavins</surname><given-names>T. M.</given-names></name></person-group><article-title>Motivation for change and alcoholism treatment.</article-title><source>Alcohol Res Health</source><year>(1999)</year><volume>23</volume><fpage>86</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">10890801</pub-id></element-citation></ref><ref id="R16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>DiClemente</surname><given-names>C.</given-names></name><name><surname>Prochaska</surname><given-names>J.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>W.</surname><given-names>Miller</given-names></name><name><surname>N.</surname><given-names>Heather</given-names></name></person-group><article-title>Towards a comprehensive, transtheoretical model of change.</article-title><source>Treating Addictive Behaviours</source><year>(1998)</year><publisher-loc>New York, NY</publisher-loc><publisher-name>Plenum Press</publisher-name></element-citation></ref><ref id="R17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Q.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group><article-title>Moderate auditory training can improve speech performance of adult cochlear implant patients.</article-title><source>Acoust Res Lett Online</source><year>(2005)</year><volume>6</volume><fpage>106</fpage><lpage>111</lpage></element-citation></ref><ref id="R18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names><suffix>III</suffix></name></person-group><article-title>Maximizing cochlear implant patients&#x02019; performance with advanced speech training procedures.</article-title><source>Hear Res</source><year>(2008)</year><volume>242</volume><fpage>198</fpage><lpage>208</lpage><pub-id pub-id-type="pmid">18295992</pub-id></element-citation></ref><ref id="R19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Galvin</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group><article-title>Effects of auditory training on adult cochlear implant patients: A preliminary report.</article-title><source>Cochl Impl Int</source><year>(2004)</year><volume>5</volume><issue>Suppl 1</issue><fpage>84</fpage><lpage>90</lpage></element-citation></ref><ref id="R20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S.</given-names></name></person-group><article-title>Glasgow Hearing Aid Benefit Profile: Derivation and validation of client-centred outcome measures for hearing aid services.</article-title><source>J Am Acad Audiol</source><year>(1999)</year><volume>10</volume><fpage>80</fpage><lpage>103</lpage></element-citation></ref><ref id="R21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S.</given-names></name><name><surname>Naylor</surname><given-names>G.</given-names></name><name><surname>Elberling</surname><given-names>C.</given-names></name></person-group><article-title>Benefits from hearing aids in relation to the interaction between the user and the environment.</article-title><source>Int J Audiol</source><year>(2003)</year><volume>42</volume><issue>Suppl 1</issue><fpage>S77</fpage><lpage>S85</lpage><pub-id pub-id-type="pmid">12918613</pub-id></element-citation></ref><ref id="R22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S.</given-names></name><name><surname>Noble</surname><given-names>W.</given-names></name></person-group><article-title>The Speech, Spatial and Qualities of Hearing Scale (SSQ).</article-title><source>Int J Audiol</source><year>(2004)</year><volume>43</volume><fpage>85</fpage><lpage>99</lpage><pub-id pub-id-type="pmid">15035561</pub-id></element-citation></ref><ref id="R23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halliday</surname><given-names>L. F.</given-names></name><name><surname>Taylor</surname><given-names>J. L.</given-names></name><name><surname>Millward</surname><given-names>K. E.</given-names></name><etal/></person-group><article-title>Lack of generalization of auditory learning in typically developing children.</article-title><source>J Speech Lang Hear Res</source><year>(2012)</year><volume>55</volume><fpage>168</fpage><lpage>181</lpage><pub-id pub-id-type="pmid">22199194</pub-id></element-citation></ref><ref id="R24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkey</surname><given-names>D. J.</given-names></name><name><surname>Amitay</surname><given-names>S.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name></person-group><article-title>Early and rapid perceptual learning.</article-title><source>Nat Neurosci</source><year>(2004)</year><volume>7</volume><fpage>1055</fpage><lpage>1056</lpage><pub-id pub-id-type="pmid">15361880</pub-id></element-citation></ref><ref id="R25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson Sabes</surname><given-names>J.</given-names></name><name><surname>Sweetow</surname><given-names>R. W.</given-names></name></person-group><article-title>Variables predicting outcomes on listening and communication enhancement (LACE) training.</article-title><source>Int J Audiol</source><year>(2007)</year><volume>46</volume><fpage>374</fpage><lpage>383</lpage><pub-id pub-id-type="pmid">17680469</pub-id></element-citation></ref><ref id="R26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henshaw</surname><given-names>H.</given-names></name><name><surname>Clark</surname><given-names>D.</given-names></name><name><surname>Kang</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Computer skill and internet use in adults aged 50&#x02013;74 years: Influence of hearing difficulties.</article-title><source>J Internet Med Res</source><year>2012a</year><volume>14</volume><fpage>e113</fpage></element-citation></ref><ref id="R70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henshaw</surname><given-names>H.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name></person-group><article-title>Efficacy of individual computer-based auditory training for people with hearing loss: A systematic review of the evidence.</article-title><source>PLoS One</source><year>(2013a)</year><volume>8</volume><fpage>e62836</fpage><pub-id pub-id-type="pmid">23675431</pub-id></element-citation></ref><ref id="R27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henshaw</surname><given-names>H.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name></person-group><article-title>Working memory training for adult hearing aid users: study protocol for a double-blind randomized active controlled trial.</article-title><source>Trials</source><year>(2013b)</year><volume>47</volume><fpage>417</fpage><pub-id pub-id-type="pmid">24304745</pub-id></element-citation></ref><ref id="R28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henshaw</surname><given-names>H.</given-names></name><name><surname>McCormack</surname><given-names>A.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name></person-group><article-title>Auditory training: Exploring participant motivations, engagement and compliance.</article-title><source>Int J Audiol</source><year>2012b</year><volume>51</volume><fpage>263</fpage><lpage>264</lpage></element-citation></ref><ref id="R29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humes</surname><given-names>L. E.</given-names></name><name><surname>Burk</surname><given-names>M. H.</given-names></name><name><surname>Strauser</surname><given-names>L. E.</given-names></name><etal/></person-group><article-title>Development and efficacy of a frequent-word auditory training protocol for older adults with impaired hearing.</article-title><source>Ear Hear</source><year>(2009)</year><volume>30</volume><fpage>613</fpage><lpage>627</lpage><pub-id pub-id-type="pmid">19633564</pub-id></element-citation></ref><ref id="R30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ingvalson</surname><given-names>E. M.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name><name><surname>Fiebig</surname><given-names>P.</given-names></name><etal/></person-group><article-title>The effects of short-term computerized speech-in-noise training on postlingually deafened adult cochlear implant recipients.</article-title><source>J Speech Lang Hear Res</source><year>(2013)</year><volume>56</volume><fpage>81</fpage><lpage>88</lpage><pub-id pub-id-type="pmid">22744139</pub-id></element-citation></ref><ref id="R31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiessling</surname><given-names>J.</given-names></name><name><surname>Pichora-Fuller</surname><given-names>M. K.</given-names></name><name><surname>Gatehouse</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Candidature for and delivery of audiological services: Special needs of older people.</article-title><source>Int J Audiol</source><year>(2003)</year><volume>42</volume><issue>Suppl 2</issue><fpage>2S92</fpage><lpage>2101</lpage><pub-id pub-id-type="pmid">12918635</pub-id></element-citation></ref><ref id="R32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kronenberger</surname><given-names>W. G.</given-names></name><name><surname>Pisoni</surname><given-names>D. B.</given-names></name><name><surname>Henning</surname><given-names>S. C.</given-names></name><etal/></person-group><article-title>Working memory training for children with cochlear implants: A pilot study.</article-title><source>J Speech Lang Hear Res</source><year>(2011)</year><volume>54</volume><fpage>1182</fpage><lpage>1196</lpage><pub-id pub-id-type="pmid">21173394</pub-id></element-citation></ref><ref id="R33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levi</surname><given-names>D. M.</given-names></name></person-group><article-title>Prentice award lecture 2011: Removing the brakes on plasticity in the amblyopic brain.</article-title><source>Optom Vis Sci</source><year>(2012)</year><volume>89</volume><fpage>827</fpage><lpage>838</lpage><pub-id pub-id-type="pmid">22581119</pub-id></element-citation></ref><ref id="R34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacLeod</surname><given-names>A.</given-names></name><name><surname>Summerfield</surname><given-names>Q.</given-names></name></person-group><article-title>A procedure for measuring auditory and audio-visual speech-reception thresholds for sentences in noise: Rationale, evaluation, and recommendations for use.</article-title><source>Br J Audiol</source><year>(1990)</year><volume>24</volume><fpage>29</fpage><lpage>43</lpage><pub-id pub-id-type="pmid">2317599</pub-id></element-citation></ref><ref id="R35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahncke</surname><given-names>H. W.</given-names></name><name><surname>Connor</surname><given-names>B. B.</given-names></name><name><surname>Appelman</surname><given-names>J.</given-names></name><etal/></person-group><article-title>Memory enhancement in healthy older adults using a brain plasticity-based training program: A randomized, controlled study.</article-title><source>Proc Natl Acad Sci U S A</source><year>(2006)</year><volume>103</volume><fpage>12523</fpage><lpage>12528</lpage><pub-id pub-id-type="pmid">16888038</pub-id></element-citation></ref><ref id="R36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McArthur</surname><given-names>G.</given-names></name></person-group><article-title>Test-retest effects in treatment studies of reading disability: The devil is in the detail.</article-title><source>Dyslexia</source><year>(2007)</year><volume>13</volume><fpage>240</fpage><lpage>252</lpage><pub-id pub-id-type="pmid">17948880</pub-id></element-citation></ref><ref id="R37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>J. D.</given-names></name><name><surname>Watson</surname><given-names>C. S.</given-names></name><name><surname>Kistler</surname><given-names>D. J.</given-names></name><etal/></person-group><article-title>Preliminary evaluation of the speech perception assessment and training system (SPATS) with hearing-aid and cochlear-implant users.</article-title><source>Proc Meet Acoust</source><year>(2008)</year><volume>2</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">19305636</pub-id></element-citation></ref><ref id="R38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millward</surname><given-names>K. E.</given-names></name><name><surname>Hall</surname><given-names>R. L.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name><etal/></person-group><article-title>Training speech-in-noise perception in mainstream school children.</article-title><source>Int J Pediatr Otorhinolaryngol</source><year>(2011)</year><volume>75</volume><fpage>1408</fpage><lpage>1417</lpage><pub-id pub-id-type="pmid">21889805</pub-id></element-citation></ref><ref id="R39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molloy</surname><given-names>K.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name><name><surname>Sohoglu</surname><given-names>E.</given-names></name><etal/></person-group><article-title>Less is more: Latent learning is maximized by shorter training sessions in auditory perceptual learning.</article-title><source>PLoS One</source><year>(2012)</year><volume>7</volume><fpage>e36929</fpage><pub-id pub-id-type="pmid">22606309</pub-id></element-citation></ref><ref id="R40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>D. R.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name><name><surname>Edmondson-Jones</surname><given-names>A. M.</given-names></name><etal/></person-group><article-title>Nature of auditory processing disorder in children.</article-title><source>Pediatrics</source><year>(2010)</year><volume>126</volume><fpage>e382</fpage><lpage>e390</lpage><pub-id pub-id-type="pmid">20660546</pub-id></element-citation></ref><ref id="R41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>D. R.</given-names></name><name><surname>Halliday</surname><given-names>L. F.</given-names></name><name><surname>Amitay</surname><given-names>S.</given-names></name></person-group><article-title>Use of auditory learning to manage listening problems in children.</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><year>(2009)</year><volume>364</volume><fpage>409</fpage><lpage>420</lpage><pub-id pub-id-type="pmid">18986969</pub-id></element-citation></ref><ref id="R42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>D. R.</given-names></name><name><surname>Rosenberg</surname><given-names>J. F.</given-names></name><name><surname>Coleman</surname><given-names>J. S.</given-names></name></person-group><article-title>Discrimination training of phonemic contrasts enhances phonological processing in mainstream school children.</article-title><source>Brain Lang</source><year>(2005)</year><volume>94</volume><fpage>72</fpage><lpage>85</lpage><pub-id pub-id-type="pmid">15896385</pub-id></element-citation></ref><ref id="R43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>M.</given-names></name><name><surname>McLennan</surname><given-names>D.</given-names></name><name><surname>Wilkinson</surname><given-names>K.</given-names></name><etal/></person-group><article-title>The English indices of multiple deprivation 2007.</article-title><year>(2008)</year><publisher-loc>London, United Kingdom:</publisher-loc><publisher-name>Communities and Local Government</publisher-name><comment><ext-link ext-link-type="uri" xlink:href="http://www.communities.gov.uk/documents/communities/pdf/733520.pdf">http://www.communities.gov.uk/documents/communities/pdf/733520.pdf</ext-link>. [serial online]</comment></element-citation></ref><ref id="R44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nouchi</surname><given-names>R.</given-names></name><name><surname>Taki</surname><given-names>Y.</given-names></name><name><surname>Takeuchi</surname><given-names>H.</given-names></name><etal/></person-group><article-title>Brain training game boosts executive functions, working memory and processing speed in the young adults: A randomized controlled trial.</article-title><source>PLoS One</source><year>(2013)</year><volume>8</volume><fpage>e55518</fpage><pub-id pub-id-type="pmid">23405164</pub-id></element-citation></ref><ref id="R45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oba</surname><given-names>S. I.</given-names></name><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names><suffix>III</suffix></name></person-group><article-title>Digit training in noise can improve cochlear implant users&#x02019; speech understanding in noise.</article-title><source>Ear Hear</source><year>(2011)</year><volume>32</volume><fpage>573</fpage><lpage>581</lpage><pub-id pub-id-type="pmid">21389857</pub-id></element-citation></ref><ref id="R46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>A. M.</given-names></name><name><surname>Hampshire</surname><given-names>A.</given-names></name><name><surname>Grahn</surname><given-names>J. A.</given-names></name><etal/></person-group><article-title>Putting brain training to the test.</article-title><source>Nature</source><year>(2010)</year><volume>465</volume><fpage>775</fpage><lpage>778</lpage><pub-id pub-id-type="pmid">20407435</pub-id></element-citation></ref><ref id="R47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Recanzone</surname><given-names>G. H.</given-names></name><name><surname>Schreiner</surname><given-names>C. E.</given-names></name><name><surname>Merzenich</surname><given-names>M. M.</given-names></name></person-group><article-title>Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys.</article-title><source>J Neurosci</source><year>(1993)</year><volume>13</volume><fpage>87</fpage><lpage>103</lpage><pub-id pub-id-type="pmid">8423485</pub-id></element-citation></ref><ref id="R48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>I. H.</given-names></name><name><surname>Ward</surname><given-names>T.</given-names></name><name><surname>Ridgeway</surname><given-names>V.</given-names></name><etal/></person-group><source>The Test of Everyday Attention</source><year>(1994)</year><publisher-loc>Bury St. Edmunds, United Kingdom</publisher-loc><publisher-name>Thames Valley Test Company</publisher-name></element-citation></ref><ref id="R49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name><name><surname>Rudner</surname><given-names>M.</given-names></name><name><surname>Foo</surname><given-names>C.</given-names></name><etal/></person-group><article-title>Cognition counts: A working memory system for ease of language understanding (ELU).</article-title><source>Int J Audiol</source><year>(2008)</year><volume>47</volume><issue>Suppl 2</issue><fpage>S99</fpage><lpage>105</lpage><pub-id pub-id-type="pmid">19012117</pub-id></element-citation></ref><ref id="R50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulz</surname><given-names>K. F.</given-names></name><name><surname>Altman</surname><given-names>D. G.</given-names></name><name><surname>Moher</surname><given-names>D.</given-names></name></person-group><collab>CONSORT Group</collab><article-title>CONSORT 2010 statement: Updated guidelines for reporting parallel group randomised trials.</article-title><source>BMJ</source><year>(2010)</year><volume>340</volume><fpage>c332</fpage><pub-id pub-id-type="pmid">20332509</pub-id></element-citation></ref><ref id="R51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>G. E.</given-names></name><name><surname>Housen</surname><given-names>P.</given-names></name><name><surname>Yaffe</surname><given-names>K.</given-names></name><etal/></person-group><article-title>A cognitive training program based on principles of brain plasticity: Results from the Improvement in Memory with Plasticity-based Adaptive Cognitive Training (IMPACT) study.</article-title><source>J Am Geriatr Soc</source><year>(2009)</year><volume>57</volume><fpage>594</fpage><lpage>603</lpage><pub-id pub-id-type="pmid">19220558</pub-id></element-citation></ref><ref id="R52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smits</surname><given-names>C.</given-names></name><name><surname>Houtgast</surname><given-names>T.</given-names></name></person-group><article-title>Results from the Dutch speech-in-noise screening test by telephone.</article-title><source>Ear Hear</source><year>(2005)</year><volume>26</volume><fpage>89</fpage><lpage>95</lpage><pub-id pub-id-type="pmid">15692307</pub-id></element-citation></ref><ref id="R53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smits</surname><given-names>C.</given-names></name><name><surname>Kapteyn</surname><given-names>T. S.</given-names></name><name><surname>Houtgast</surname><given-names>T.</given-names></name></person-group><article-title>Development and validation of an automatic speech-in-noise screening test by telephone.</article-title><source>Int J Audiol</source><year>(2004)</year><volume>43</volume><fpage>15</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">14974624</pub-id></element-citation></ref><ref id="R54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stacey</surname><given-names>P. C.</given-names></name><name><surname>Raine</surname><given-names>C. H.</given-names></name><name><surname>O&#x02019;Donoghue</surname><given-names>G. M.</given-names></name><etal/></person-group><article-title>Effectiveness of computer-based auditory training for adult users of cochlear implants.</article-title><source>Int J Audiol</source><year>(2010)</year><volume>49</volume><fpage>347</fpage><lpage>356</lpage><pub-id pub-id-type="pmid">20380610</pub-id></element-citation></ref><ref id="R55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stecker</surname><given-names>G. C.</given-names></name><name><surname>Bowman</surname><given-names>G. A.</given-names></name><name><surname>Yund</surname><given-names>E. W.</given-names></name><etal/></person-group><article-title>Perceptual training improves syllable identification in new and experienced hearing aid users.</article-title><source>J Rehabil Res Dev</source><year>(2006)</year><volume>43</volume><fpage>537</fpage><lpage>552</lpage><pub-id pub-id-type="pmid">17123192</pub-id></element-citation></ref><ref id="R56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sweetow</surname><given-names>R.</given-names></name><name><surname>Palmer</surname><given-names>C. V.</given-names></name></person-group><article-title>Efficacy of individual auditory training in adults: A systematic review of the evidence.</article-title><source>J Am Acad Audiol</source><year>(2005)</year><volume>16</volume><fpage>494</fpage><lpage>504</lpage><pub-id pub-id-type="pmid">16295236</pub-id></element-citation></ref><ref id="R57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sweetow</surname><given-names>R. W.</given-names></name><name><surname>Henderson Sabes</surname><given-names>J.</given-names></name></person-group><article-title>The need for and development of an adaptive Listening and Communication Enhancement (LACE) Program.</article-title><source>J Am Acad Audiol</source><year>(2006)</year><volume>17</volume><fpage>538</fpage><lpage>558</lpage><pub-id pub-id-type="pmid">16999250</pub-id></element-citation></ref><ref id="R58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sweetow</surname><given-names>R. W.</given-names></name><name><surname>Henderson Sabes</surname><given-names>J.</given-names></name></person-group><article-title>Auditory training and challenges associated with participation and compliance.</article-title><source>J Am Acad Audiol</source><year>(2010)</year><volume>21</volume><fpage>586</fpage><lpage>593</lpage><pub-id pub-id-type="pmid">21241646</pub-id></element-citation></ref><ref id="R59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tallal</surname><given-names>P.</given-names></name><name><surname>Miller</surname><given-names>S. L.</given-names></name><name><surname>Bedi</surname><given-names>G.</given-names></name><etal/></person-group><article-title>Language comprehension in language-learning impaired children improved with acoustically modified speech.</article-title><source>Science</source><year>(1996)</year><volume>271</volume><fpage>81</fpage><lpage>84</lpage><pub-id pub-id-type="pmid">8539604</pub-id></element-citation></ref><ref id="R60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tyler</surname><given-names>R. S.</given-names></name><name><surname>Witt</surname><given-names>S. A.</given-names></name><name><surname>Dunn</surname><given-names>C. C.</given-names></name><etal/></person-group><article-title>Initial development of a spatially separated speech-in-noise and localization training program.</article-title><source>J Am Acad Audiol</source><year>(2010)</year><volume>21</volume><fpage>390</fpage><lpage>403</lpage><pub-id pub-id-type="pmid">20701836</pub-id></element-citation></ref><ref id="R61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wagener</surname><given-names>K.</given-names></name></person-group><article-title>D-1&#x02013;9: Report on an optimized inventory of speech-based auditory screening &#x00026; impairment tests for six languages.</article-title><year>(2009)</year><publisher-name>FP6-004171 HEARCOM Hearing in the Communication Society</publisher-name><comment>Available at <ext-link ext-link-type="uri" xlink:href="http://hearcom.eu/about/DisseminationandExploitation/deliverables/HearCom_D01-9_v1.pdf">http://hearcom.eu/about/DisseminationandExploitation/deliverables/HearCom_D01-9_v1.pdf</ext-link></comment></element-citation></ref><ref id="R62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wechsler</surname><given-names>D.</given-names></name></person-group><source>Wechsler Adult Intelligence Scale-Third Edition</source><year>(1997)</year><publisher-loc>San Antonio, TX</publisher-loc><publisher-name>The Psychological Corporation</publisher-name></element-citation></ref><ref id="R63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wechsler</surname><given-names>D.</given-names></name></person-group><source>Wechsler Abbreviated Scale of Intelligence</source><year>(1999)</year><publisher-loc>New York, NY</publisher-loc><publisher-name>The Psychological Corporation: Harcourt Brace &#x00026; Company</publisher-name></element-citation></ref><ref id="R64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>D. L.</given-names></name><name><surname>Yund</surname><given-names>E. W.</given-names></name></person-group><article-title>Perceptual training of phoneme identification for hearing loss.</article-title><source>Sem Hear</source><year>(2007)</year><volume>28</volume><fpage>110</fpage><lpage>119</lpage></element-citation></ref><ref id="R65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>B. A.</given-names></name><name><surname>Buonomano</surname><given-names>D. V.</given-names></name><name><surname>Mahncke</surname><given-names>H. W.</given-names></name><etal/></person-group><article-title>Learning and generalization of auditory temporal-interval discrimination in humans.</article-title><source>J Neurosci</source><year>(1997)</year><volume>17</volume><fpage>3956</fpage><lpage>3963</lpage><pub-id pub-id-type="pmid">9133413</pub-id></element-citation></ref><ref id="R66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>B. A.</given-names></name><name><surname>Sabin</surname><given-names>A. T.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>Enhancing perceptual learning by combining practice with periods of additional sensory stimulation.</article-title><source>J Neurosci</source><year>(2010)</year><volume>30</volume><fpage>12868</fpage><lpage>12877</lpage><pub-id pub-id-type="pmid">20861390</pub-id></element-citation></ref><ref id="R67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>B. A.</given-names></name><name><surname>Wilson</surname><given-names>R. M.</given-names></name><name><surname>Sabin</surname><given-names>A. T.</given-names></name></person-group><article-title>Generalization lags behind learning on an auditory perceptual task.</article-title><source>J Neurosci</source><year>(2010)</year><volume>30</volume><fpage>11635</fpage><lpage>11639</lpage><pub-id pub-id-type="pmid">20810884</pub-id></element-citation></ref><ref id="R68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T.</given-names></name><name><surname>Dorman</surname><given-names>M. F.</given-names></name><name><surname>Fu</surname><given-names>Q. J.</given-names></name><etal/></person-group><article-title>Auditory training in patients with unilateral cochlear implant and contralateral acoustic stimulation.</article-title><source>Ear Hear</source><year>(2012)</year><volume>33</volume><fpage>e70</fpage><lpage>e79</lpage><pub-id pub-id-type="pmid">22622705</pub-id></element-citation></ref><ref id="R69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y. X.</given-names></name><name><surname>Barry</surname><given-names>J. G.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name><etal/></person-group><article-title>A new test of attention in listening (TAIL) predicts auditory performance.</article-title><source>PLoS One</source><year>(2012)</year><volume>7</volume><fpage>e53502</fpage><pub-id pub-id-type="pmid">23300934</pub-id></element-citation></ref></ref-list></back></article>