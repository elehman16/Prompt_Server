<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Int J Behav Nutr Phys Act</journal-id><journal-title-group><journal-title>The International Journal of Behavioral Nutrition and Physical Activity</journal-title></journal-title-group><issn pub-type="epub">1479-5868</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19948049</article-id><article-id pub-id-type="pmc">2793250</article-id><article-id pub-id-type="publisher-id">1479-5868-6-79</article-id><article-id pub-id-type="doi">10.1186/1479-5868-6-79</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Using process evaluation for program improvement in dose, fidelity and reach: the ACT trial experience</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Wilson</surname><given-names>Dawn K</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>profdwilson@hotmail.com</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Griffin</surname><given-names>Sarah</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>sgriffi@clemson.edu</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Saunders</surname><given-names>Ruth P</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>rsaunders@mailbox.sc.edu</email></contrib><contrib contrib-type="author" id="A4"><name><surname>Kitzman-Ulrich</surname><given-names>Heather</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>kitzman@mailbox.sc.edu</email></contrib><contrib contrib-type="author" id="A5"><name><surname>Meyers</surname><given-names>Duncan C</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>meyersd@mailbox.sc.edu</email></contrib><contrib contrib-type="author" id="A6"><name><surname>Mansard</surname><given-names>Leslie</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>leslie_3413@yahoo.com</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Psychology, University of South Carolina, Columbia, SC, 29208, USA</aff><aff id="I2"><label>2</label>Department of Public Health Sciences, College of Heath, Education, and Human Development, Clemson University, Clemson, SC, 29634, USA</aff><aff id="I3"><label>3</label>Department of Health Promotion, Education, and Behavior, Arnold School of Public Health, University of South Carolina, Columbia, SC, 29208, USA</aff><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>30</day><month>11</month><year>2009</year></pub-date><volume>6</volume><fpage>79</fpage><lpage>79</lpage><history><date date-type="received"><day>10</day><month>7</month><year>2009</year></date><date date-type="accepted"><day>30</day><month>11</month><year>2009</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2009 Wilson et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2009</copyright-year><copyright-holder>Wilson et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.ijbnpa.org/content/6/1/79"/><abstract><sec><title>Background</title><p>The purpose of this study was to demonstrate how formative program process evaluation was used to improve dose and fidelity of implementation, as well as reach of the intervention into the target population, in the "Active by Choice Today" (ACT) randomized school-based trial from years 1 to 3 of implementation.</p></sec><sec><title>Methods</title><p>The intervention integrated constructs from Self-Determination Theory and Social Cognitive Theory to enhance intrinsic motivation and behavioral skills for increasing long-term physical activity (PA) behavior in underserved adolescents (low income, minorities). ACT formative process data were examined at the end of each year to provide timely, corrective feedback to keep the intervention "on track".</p></sec><sec><title>Results</title><p>Between years 1 and 2 and years 2 and 3, three significant changes were made to attempt to increase dose and fidelity rates in the program delivery and participant attendance (reach). These changes included expanding the staff training, reformatting the intervention manual, and developing a tracking system for contacting parents of students who were not attending the after-school programs regularly. Process outcomes suggest that these efforts resulted in notable improvements in attendance, dose, and fidelity of intervention implementation from years 1 to 2 and 2 to 3 of the ACT trial.</p></sec><sec><title>Conclusion</title><p>Process evaluation methods, particularly implementation monitoring, are useful tools to ensure fidelity in intervention trials and for identifying key best practices for intervention delivery.</p></sec></abstract></article-meta></front><body><sec><title>Introduction</title><p>Process evaluation can be used to explain why interventions succeed and fail, and whether there are characteristics or mechanisms involved in the program's implementation that potentially mediate or moderate outcomes. In large-scale trials the importance of monitoring program implementation has been highlighted [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B10">10</xref>] and there is strong evidence that level of implementation impacts study outcomes [<xref ref-type="bibr" rid="B4">4</xref>]. Implementation monitoring can be done in both a formative and a summative manner. Formative evaluations can be defined as utilizing data to provide on-going monitoring and quality assessment to maximize the performance of a program [<xref ref-type="bibr" rid="B11">11</xref>-<xref ref-type="bibr" rid="B14">14</xref>]. Summative evaluations analyze data at the conclusion of an initiative to provide a conclusive rating of the extent to which intended outcomes were achieved and the program was implemented as intended [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B14">14</xref>]. Another summative purpose of process evaluation is to include level of implementation data in the outcome analysis [<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B16">16</xref>].</p><p>Evaluations of implementation are especially important given that few studies have achieved full implementation in real-world settings[<xref ref-type="bibr" rid="B16">16</xref>]. This is also true of health promotion efforts, as researchers have noted the great variability in program implementation and policy adoption in community and school settings [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B17">17</xref>]. Thus, one purpose of implementation monitoring is to ensure that the originally designed intervention is, in fact, being implemented, as well as being implemented in a manner that is consistent with the program theory and plan. In effect, if a complex intervention carried out in a field setting is not carefully monitored and adjusted to stay "on track" with the original plan, many different interventions may be implemented. Thus, midcourse changes are designed to increase fidelity, dose, and reach to enable researchers to evaluate the intervention as originally planned. Despite the importance of such evaluations, outcome analyses are frequently conducted without an assessment of program implementation [<xref ref-type="bibr" rid="B18">18</xref>]. This is often referred to as the "black box" approach to evaluation, which refers to examining the outcomes of a program without examining its internal operation. Lack of this knowledge can lead to "a Type III error," which refers to the conclusion that a seemingly ineffective program was, in actuality, not implemented as intended [<xref ref-type="bibr" rid="B19">19</xref>,<xref ref-type="bibr" rid="B20">20</xref>].</p><p>Process evaluation data used for formative purposes during a developed intervention, as described in this study, should be distinguished from process evaluation used for formative evaluation during the developmental phases of an intervention [<xref ref-type="bibr" rid="B21">21</xref>-<xref ref-type="bibr" rid="B23">23</xref>]. In an example of the latter, Wilson and colleagues [<xref ref-type="bibr" rid="B24">24</xref>] conducted a formative evaluation of a motivational PA intervention (Active by Choice Today; ACT). The conceptual framework for the ACT intervention targeted the social environment, cognitive mediators, and motivational orientation related to PA in underserved adolescents. The 8-week program sought to increase moderate-to-vigorous PA (MVPA) for participant youth, and formative evaluation was collected through daily forms and observational data completed by an independent objective observer. ACT process evaluation focused on identifying factors in the social environment and curriculum that worked well and/or were in need of improvement. Most effort was spent ensuring that the theoretical underpinnings of the program were maximized and promoting efficiency by modifying logistical flaws. The process evaluation was used to inform necessary changes to the staff training. Specifically, process data indicated that it would be more beneficial to encourage staff to praise students in subtle ways or in a setting where other students would not be aware of it (due to reduction in positive student-to-student reactions when publicly praised for their behavior by staff). The investigators also learned that training should focus on instructional methods which foster a balance between discipline and nurturing as well as ways to subtly dismantle cliques.</p><p>A growing literature has included process evaluation as a key element in evaluating success of implementation in large-scale PA trials. The Pathways initiative - a large-scale, multi-site, 3-year study testing a school-based intervention, used process evaluation methods in evaluating implementation of an intervention to lower percent body fat in American Indian children [<xref ref-type="bibr" rid="B25">25</xref>]. Pathways applied a multilevel strategy involving individual behavior change and environmental modifications to support changes in individual behavior. The environmental component included a food service intervention to enhance food staff skills in preparing and serving lower-fat meals. For this component, implementation was measured by various behavioral guidelines (e.g., use of low-fat vendor entrees, offer choice of fruits and vegetables). In the first year, none of the 12 goals were achieved; in the second year 6 of the 13 goals were met (a new goal had been added); in the third year 9 of the 13 goals were met. These improvements were due to performance feedback provided by the evaluators at the end of each semester, an example of effective use of formative process data.</p><p>Other large trials have reported summative process evaluations which have implications for using process evaluation data for formative purposes. For example, in one investigation of the SPARK program (Sport, Play, and Active Recreation for Kids), a multi-component elementary school program which sought to promote PA in elementary children, process evaluation data was obtained to determine success of implementation[<xref ref-type="bibr" rid="B26">26</xref>]. The SPARK curriculum focused on physical education (PE) and self-management (SM), and children participated in either an intervention implemented by PE specialists, an intervention implemented by classroom teachers, or a control (usual PE classes). Through direct observation of weekly classroom lessons it was determined that teachers and PE specialists conducted 63% and 67% of the components of the SM curriculum, respectively. The small variance in intervention delivery coupled with the relatively low implementation percentages suggests the possibility of consistent contextual implementation barriers that perhaps could have been addressed with timely, formative process evaluation data.</p><p>In "Switch-Play," Salmon and colleagues [<xref ref-type="bibr" rid="B27">27</xref>] sought to reduce the time spent by primary school children in sedentary behaviors and to increase their skills in, enjoyment of, and participation in PA outside of school. The process evaluation indicated an average attendance of 88% among children in the intervention conditions. Classroom activities were completed 92% of the time; however, outside-of-class PA activities and self-monitoring sheets were completed 57% and 62% of the time, respectively. These data indicate opportunities for improving fidelity to essential program elements, especially for outside of class PA.</p><p>The purpose of the present study was to demonstrate how program process evaluation was used in a formative manner [<xref ref-type="bibr" rid="B11">11</xref>] to improve fidelity and dose (completeness) of implementation as well as reach into the target population in the ACT randomized school-based trial from year to year of implementation. The ACT trial [<xref ref-type="bibr" rid="B28">28</xref>], is a group-randomized cohort design with three intervention and three comparison schools per year over the course of four years (N = 24 schools, n = 60 6<sup>th </sup>graders per school). The formative data from each year were used to provide corrective feedback to keep the intervention "on track", and was part of a comprehensive approach to process evaluation for monitoring and assessing program implementation in ACT [<xref ref-type="bibr" rid="B28">28</xref>].</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Participants</title><p>A total of 24 middle schools (range of 41-71 students per school; N = 1,422 total students) in South Carolina were recruited to participate in one of the two after-school programs (ACT intervention or a general health program that served as a comparison program) over the 4 years (6 schools per year) of the trial implementation. To be eligible, adolescents were required to 1) currently be enrolled in the 6<sup>th </sup>grade, 2) have parental consent to participate, 3) agree to study participation and random assignment, and 4) be available for a 6-month follow-up. Adolescents were excluded from participation if they 1) had a medical condition that would interfere with the prescribed PA intervention plan, 2) were developmentally delayed such that the intervention materials would not be cognitively appropriate or, 3) were currently in treatment for a psychiatric disorder.</p></sec><sec><title>Study Design</title><p>The ACT trial is a group-randomized cohort design with three intervention and three comparison schools per cohort (year). The schools were paired prior to recruitment and randomization to condition to avoid possible bias or confounding by socio-demographic differences. The criteria on which the schools were paired included: 1) school size, 2) proportion of minority versus non-minority ethnicity, 3) proportion of students enrolled in free and reduced lunch program and 4) urban or rural community setting. Baseline psychosocial, PA, and anthropometric measures were obtained prior to randomizing schools in each pair. The measurement team and intervention team maintained separate entities to blind the measurement staff to group conditions. Data was collected by trained measurement staff for each pair of schools on the same days over a period of two weeks in a lagged timeline (pair 1, pair 2, pair 3, respectively). This paper reports on years 1, 2, and 3 of the trial.</p></sec><sec><title>Recruitment</title><p>Two phases of recruitment were implemented yearly during the ACT trial. The first phase involved attending parent orientations at school events to provide program information and obtain informed consent. Following the orientation a second phase of recruitment took place during the school day. Pep rallies and homeroom visits were two methods of recruitment implemented during the second phase to increase enrollment and excitement about the programs (PA and general health education). Randomization of schools to programs (PA intervention vs. general health education) occurred after recruitment and baseline assessments were completed. The recruitment target was 60 students from each school.</p></sec><sec><title>ACT Intervention</title><p>The intervention integrated constructs from Self-Determination Theory (SDT) [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>] and Social Cognitive Theory (SCT) [<xref ref-type="bibr" rid="B31">31</xref>] to enhance intrinsic motivation and behavioral skills for increasing long-term PA behavior specifically in underserved adolescents. A formative evaluation of the theoretical elements was developed during year 1 of the ACT trial [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B28">28</xref>]. In the present study elements from SCT and SDT were combined to develop an intervention that promoted behavioral skills for PA outside the program and a social environmental approach during the after-school program for enhancing autonomy (choice), fun, belongingness (engagement), and competence (challenges emphasizing non-competitive play) for PA [<xref ref-type="bibr" rid="B28">28</xref>]. An interview methodology known as strategic self-presentation was used to integrate SDT and SCT by linking motivational elements from the program to applying behavioral skills for being physical active outside of program time.</p><p>Investigators and staff defined the "essential elements" for the ACT intervention guided by constructs from the ACT theoretical frameworks (SDT and SCT) [<xref ref-type="bibr" rid="B28">28</xref>]. The essential elements informed the development of the program (e.g., ACT program content, methods, and activities), guided staff training, and defined dose (completeness) and fidelity for ACT intervention implementation. The program components and essential elements were also phrased into a list of concise terms that was used in training and to convey the philosophy and approach of the program in a "user-friendly" manner. Table <xref ref-type="table" rid="T1">1</xref> presents the theoretically-based elements of the ACT intervention and the ACT essential elements, including the "user-friendly" terms. Collectively, the essential elements of the intervention were designed to increase perceived competence, intrinsic motivation, commitment, and positive self-concept.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>ACT Theories, Theoretical Constructs, and Essential Elements.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Theory</th><th align="left">Theoretical construct and definition</th><th align="left">ACT Essential Element</th><th align="left">Key Word</th></tr></thead><tbody><tr><td align="left">SDT</td><td align="left">Autonomy supportive environment-contributes to feelings of agency or being "in control" ("internal locus of causation")</td><td align="left">Participants have choices</td><td align="left">Input and Choice</td></tr><tr><td/><td/><td align="left">Participants provide meaningful input, have influence on what happens in program</td><td/></tr><tr><td/><td/><td align="left">Participants know what is expected of them</td><td align="left">Successful and confident (in program)</td></tr><tr><td align="left">SDT</td><td align="left">Competence supportive environment-contributes to being able to effectively interact with ones environment and get wanted effects and outcomes</td><td align="left">Participants feel capable and able to participate successfully</td><td/></tr><tr><td/><td/><td align="left">Participants are engaged and involved in program</td><td align="left">Engaged and Interact</td></tr><tr><td align="left">SDT</td><td align="left">Relatedness supportive environment-contributes to feelings of connectedness and being accepted by significant others</td><td align="left">Participants feel that they belong and are part of the group</td><td align="left">Belonging</td></tr><tr><td/><td/><td align="left">Participants feel like they are a valued member of group</td><td/></tr><tr><td/><td/><td align="left">Participants get along with each other, show respect for each other (positive interactions)</td><td align="left">Respect</td></tr><tr><td align="left">SDT</td><td align="left">Intrinsic motivation for physical activity</td><td align="left">Participants enjoy being in the program and being physically active</td><td align="left">Fun &#x00026; Enjoyment</td></tr><tr><td/><td/><td align="left">Participants are physically active during the PA component of the program</td><td align="left">Being physically active</td></tr><tr><td align="left">SCT</td><td align="left">Self efficacy (person factor)-confidence in ones ability to successfully engage in a behavior</td><td align="left">Participants feel confident that they can be physically active in the program, and at home</td><td align="left">Successful onfident (at home)</td></tr><tr><td align="left">SCT</td><td align="left">Behavioral skills (behavioral factor)-skills or capability to self-regulate behavior (self-monitoring, group goal setting, support seeking)</td><td align="left">Participants have specific behavioral skills that enable them to be physically active at home</td><td align="left">Life skills</td></tr><tr><td align="left">SCT</td><td align="left">Social support (environmental factor)-instrumental and/or emotional support from peers and/or family members to engage in a specific activity</td><td align="left">Participants have the social support needed to be physically active at home</td><td align="left">Support</td></tr><tr><td align="left">SDT &#x00026; SCT</td><td align="left">Self concept/motivation- Participants have a self-concept that includes being physically active</td><td align="left">Students participate in strategic self presentation</td><td align="left">Self-motivated</td></tr></tbody></table><table-wrap-foot><p>Note: SDT = Self-Determination Theory; SCT = Social Cognitive Theory; ACT = Active by Choice Today</p></table-wrap-foot></table-wrap><p>The ACT intervention was implemented on Mondays, Tuesdays, and Thursdays for two hours after school. The ACT intervention was supervised by a team leader who had expertise in implementing physical activities in youth. The team leaders provided the structure for the ACT intervention components including the PA component. Four additional trained staff provided oversight and assisted with facilitating the program components. The program had three main components: snack/homework (30 minutes), a PA component that included activities which the students selected each week of MVPA (60 minutes), and a SCT and motivational component (group time/behavioral skills) during which intervention staff taught participants behavioral skills and motivational strategies to increase their PA at home and with friends (30 minutes).</p><p>The General Health Education Program (comparison program) focused on nutrition, stress management, drug prevention, and school drop-out prevention. The program was held on the same days and times as the ACT intervention program. The health education modules were taught in an interactive format and students typically rotated from one station to then next every twenty minutes [<xref ref-type="bibr" rid="B32">32</xref>].</p></sec><sec><title>ACT Intervention Training</title><p>ACT intervention staff and volunteers were trained prior to the beginning of intervention each school year and received one booster training session midway through the intervention period. Training content included: an overview of the ACT trial purpose, an introduction of the behavioral theories and models guiding the ACT intervention, a detailed review of the ACT intervention manual, staff expectations regarding implementing the intervention and record keeping, team building, interacting with students, first aid, and administrative responsibilities and procedures. Training sessions were didactic and interactive. The interactive components provided opportunities for the staff to practice intervention strategies and for training leaders to identify and correct any problem areas for the staff during the training.</p></sec><sec><title>ACT Process Evaluation Methods</title><p>ACT process evaluation methods were guided by the essential elements framework that defined dose and fidelity or "complete and acceptable delivery" of the ACT intervention [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B33">33</xref>,<xref ref-type="bibr" rid="B34">34</xref>]. The essential elements described in Table <xref ref-type="table" rid="T1">1</xref> guided the development of items for the process evaluation observation form; that is, the key concepts reflected in Table <xref ref-type="table" rid="T1">1</xref> were reflected throughout the components of the ACT intervention <italic>as implemented during the after-school program</italic>. The evaluation questions, presented below, guided the selection of methods and tools: 1) Fidelity (for PA and behavioral skills components)- To what extent was the social environment autonomy supportive?, 2) Dose delivered (completeness for all components)-To what extent were all planned components of the program provided to program participants? and 3) Reach-What percentage of the possible target group attends each week of the program?</p><p>Process evaluation data were collected by a trained, independent process evaluator using systematic observation of after-school program activities. Through observation and use of a quantitative checklist and ratings scales, the process evaluator assessed the extent to which the ACT after-school social environment achieved the essential elements upon which the program was designed. To assess dose and fidelity, the process evaluator observed the two-hour program for each day of the program for two weeks (3 program days for two weeks) at three points in time, early (weeks 1 and 2), midpoint (weeks 8 and 9) and near the end (weeks 15 and 16) of the 17-week program. It was possible to observe each program in the same phase of implementation because program implementation was staggered by 2 weeks across the three intervention sites.</p><p>An overview of the fidelity and dose process tools is provided in Tables <xref ref-type="table" rid="T2">2</xref> and <xref ref-type="table" rid="T3">3</xref>, respectively. As shown in Table <xref ref-type="table" rid="T2">2</xref>, observational data capturing fidelity was scored on a 4 point scale with 1 representing lowest fidelity and 4 representing highest level of fidelity. Fidelity measures for the PA and behavioral skills component of the program included measures for clarity of rules and expectations, choice, optimal challenge, relatedness and belonging. Mean scores were used to summarize the results. An overall mean was calculated to reflect overall fidelity for each school, based on six weeks of program observation, as noted above.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Intervention Process Evaluation Form for Assessing Fidelity for the PA and Behavioral Skills/Group Time components</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center">Program Component</th><th align="left">Essential element categor <italic>y and Sample item</italic></th><th align="left"># of Items</th><th align="left">Format</th></tr></thead><tbody><tr><td align="center">Physical Activity</td><td align="left">1) Clarity of Rules/Expectations <italic>Explain rules and daily activities to students</italic></td><td align="left">1) 3</td><td align="left">Likert Scale: 1-4</td></tr><tr><td/><td align="left">2) Choices<break/><italic>Students get to vote on physical activity games</italic></td><td align="left">2) 3</td><td align="left"><italic>(1 = none, 2 = some, 3 = most, 4 = all)</italic></td></tr><tr><td/><td align="left">3) Optimal Challenges<break/><italic>Leaders encourage participation, fairness and de-emphasizes competition</italic></td><td align="left">3) 8</td><td/></tr><tr><td/><td align="left">4) Relatedness/Belonging<break/><italic>Leaders create a positive, interactive environment</italic></td><td align="left">4) 6</td><td/></tr><tr><td/><td align="left">5) Physical Activity<break/><italic>Students are participating in moderate to vigorous cooperative PA activities</italic></td><td align="left">5) 5</td><td/></tr><tr><td align="center">Behavioral Skills/SSP/Group Time</td><td align="left">1) Clarity of Rules/Expectations<break/><italic>Explains rules to students</italic></td><td align="left">1) 3</td><td align="left">Likert Scale: 1-4</td></tr><tr><td/><td align="left">2) Optimal Challenges<break/><italic>Leaders encourage participation and individual making progress (based on goals)</italic></td><td align="left">2) 7</td><td align="left"><italic>(1 = none, 2 = some, 3 = most, 4 = all)</italic></td></tr><tr><td/><td align="left">3) Relatedness/Belonging<break/><italic>Leaders create a positive, interactive environment</italic></td><td align="left">3) 7</td><td/></tr></tbody></table><table-wrap-foot><p>Note: SSP = Strategic Self-Presentation</p></table-wrap-foot></table-wrap><p>Many implementation fidelity ratings reported in the literature pertain to implementation or a curriculum or set of program activities and a rating ranging from "poor to excellent" has typically been optimal [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B13">13</xref>]. In the ACT trial, however, a different approach to conceptualizing and measuring fidelity was used given the goal of the intervention was to create a positive social environment in the program that was characterized by adult staff behavior. This approach was based on SDT [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>] and because adult behaviors shape the program environment for the child, we selected a rating ranging from "all to none" to assess appropriate staff behavior.</p><p>As shown in Table <xref ref-type="table" rid="T3">3</xref>, the dose assessment used yes/no response options; frequencies and percentages of "yes" responses were used to summarize the results. An overall percentage score was calculated to reflect overall dose delivered for each school. In addition, daily attendance was recorded by the team leader at each school during program days. These records were faxed weekly to the project director.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Description of Intervention Process Evaluation Form for Assessing Dose (or completeness of delivery) for the PA and Behavioral Skills/Group Time components</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Program Component</th><th align="left">Essential elements</th><th align="center"># of Items</th><th align="left">Format</th></tr></thead><tbody><tr><td align="left">Dose for Snack/Welcome</td><td align="left">Greeted arriving students<break/>Snack served<break/>Ground rules displayed<break/>Staff arrive on time<break/>Staff perform assigned duties<break/>Adult leader gave overview of week (Monday only)<break/>Adult leader gave daily overview</td><td align="center">7</td><td align="left">Yes/No</td></tr><tr><td/><td/><td/><td/></tr><tr><td align="left">Dose of Physical Activity</td><td align="left">Overview and introduction to entire activity session<break/>PA choices listed everyday<break/>Warm-up at beginning of PA session<break/>Activity introduced<break/>Cool-down</td><td align="center">5</td><td align="left">Yes/No</td></tr><tr><td/><td/><td/><td/></tr><tr><td align="left">Dose of Behavioral Skills/SSP/Group Time</td><td align="left">Overview of session or activity<break/>Topic/Skill explained<break/>Demonstration of skill<break/>Student involvement (brainstorm, role play, etc)<break/>Summary/closure</td><td align="center">5</td><td align="left">Yes/No</td></tr></tbody></table></table-wrap><p>After the intervention was completed each year, the process evaluation data were examined to determine areas of strengths and weaknesses and to make adjustments to keep the program "on track" for the next year (cohort). Based on process evaluation data in year 1, changes were made in the subsequent program years to ensure complete and acceptable program delivery and to maximize reach into the target population.</p></sec></sec><sec><title>Results</title><sec><title>Demographics</title><p>Demographic data for participants in years 1, 2, and 3 are provided in Table <xref ref-type="table" rid="T4">4</xref>. Students ranged from 10 to 14 years of age with an average age of 11.39 years. Just over half (55%) of the participants were female, 73% were African American and 76% qualified for the free or reduced lunch program through the schools.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p>Student Demographics by Year and Intervention vs. Control Schools</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Demographic</th><th align="center" colspan="3">Control Schools</th><th align="center" colspan="3">Intervention Schools</th><th align="center">All Schools</th></tr></thead><tbody><tr><td align="left"><bold>Year</bold></td><td align="center"><bold>1</bold></td><td align="center"><bold>2</bold></td><td align="center"><bold>3</bold></td><td align="center"><bold>1</bold></td><td align="center"><bold>2</bold></td><td align="center"><bold>3</bold></td><td align="center"><bold>All</bold></td></tr><tr><td colspan="8"><hr/></td></tr><tr><td align="left">Age</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td align="left">&#x02003;Mean</td><td align="center">11.41</td><td align="center">11.44</td><td align="center">11.31</td><td align="center">11.41</td><td align="center">11.36</td><td align="center">11.33</td><td align="center">11.37</td></tr><tr><td align="left">&#x02003;Range across schools</td><td align="center">10-13</td><td align="center">10-14</td><td align="center">10-13</td><td align="center">11-13</td><td align="center">10-13</td><td align="center">11-13</td><td align="center">10-14</td></tr><tr><td align="left">Gender</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td align="left">&#x02003;% Female</td><td align="center">55.13</td><td align="center">55.83</td><td align="center">53.85</td><td align="center">51.85</td><td align="center">57.49</td><td align="center">61.45</td><td align="center">55.93</td></tr><tr><td align="left">&#x02003;Range across schools</td><td align="center">52.5-58.5</td><td align="center">48.3-60.8</td><td align="center">52.4-55.4</td><td align="center">50-53.7</td><td align="center">55.4-60.0</td><td align="center">59.3-65.0</td><td align="center">48.3-65.0</td></tr><tr><td align="left">Race</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td align="left">&#x02003;% African American</td><td align="center">74.36</td><td align="center">71.17</td><td align="center">71.43</td><td align="center">69.20</td><td align="center">80.00</td><td align="center">75.98</td><td align="center">73.69</td></tr><tr><td align="left">&#x02003;Range across schools</td><td align="center">63.6-86.4</td><td align="center">56.7-84.3</td><td align="center">46.0-90.8</td><td align="center">50.0-90.7</td><td align="center">73.8-88.1</td><td align="center">66.7-88.1</td><td align="center">46.0-90.8</td></tr><tr><td align="left">Free or Reduced Lunch</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td align="left">&#x02003;% F/R</td><td align="center">70.10</td><td align="center">75.50</td><td align="center">69.30</td><td align="center">85.8</td><td align="center">81.30</td><td align="center">79.00</td><td align="center">76.83</td></tr><tr><td align="left">&#x02003;Range across schools</td><td align="center">62.3-81.4</td><td align="center">73.1-80.4</td><td align="center">64.9-76.1</td><td align="center">64.8-83.9</td><td align="center">69.2-98.2</td><td align="center">58.1-90.5</td><td align="center">58.1-98.2</td></tr></tbody></table></table-wrap></sec><sec><title>Recruitment and Attendance</title><p>All but one school met the recruitment minimum goal of 60 participants. As shown in Table <xref ref-type="table" rid="T5">5</xref>, intervention school attendance in year 1 shows the average attendance per school ranged from 40% to 51% (schools are denoted by number from the order in which they were worked with during years 1-3 of the trial). Intervention schools had slightly higher attendance than comparison schools (e.g. general health program). Overall attendance rates slightly improved in years 2 and 3 for intervention schools, however attendance remained fairly constant for comparison schools.</p><table-wrap id="T5" position="float"><label>Table 5</label><caption><p>Average Attendance Summary by Year for Intervention and Control Schools</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center">School</th><th align="center" colspan="3">PA Intervention<break/>% attendance</th><th align="center" colspan="3">Control<break/>% attendance</th><th align="center" colspan="2">Total %</th></tr><tr><th/><th/><th/><th/><th/><th/><th/><th align="center">PA</th><th align="center">C</th></tr></thead><tbody><tr><td align="center">Year 1</td><td align="center">40</td><td align="center">48</td><td align="center">51</td><td align="center">46</td><td align="center">49</td><td align="center">47</td><td align="center">46</td><td align="center">47</td></tr><tr><td align="center">Year 2</td><td align="center">59</td><td align="center">78</td><td align="center">55</td><td align="center">42</td><td align="center">39</td><td align="center">44</td><td align="center">64</td><td align="center">42</td></tr><tr><td align="center">Year 3</td><td align="center">67</td><td align="center">55</td><td align="center">48</td><td align="center">55</td><td align="center">41</td><td align="center">49</td><td align="center">57</td><td align="center">48</td></tr></tbody></table></table-wrap></sec><sec><title>Tracking System Changes</title><p>In response to attendance challenges in year 1, a tracking system was developed to more easily contact parents whose children had poor attendance at ACT. Detailed protocols were developed for ACT and general health intervention participants. The protocols included detailed phone scripts and follow-up actions for various scenarios (e.g. wrong phone number, no answering machine, leaving a phone message). The information was then included in a tracking database that included codes for the various scenarios. Staff attempted to collect updated contact information if it was not readily available from the school or provided by the participant.</p></sec><sec><title>Intervention Dose and Fidelity</title><p>The goal of implementation monitoring in ACT was to reach implementation criteria/goals and to ensure complete and acceptable delivery of ACT by criteria that were determined prior to program implementation. Dose delivered (completeness of program delivery) and fidelity were captured through 49 observations in year 1, 47 observations in year 2, and 48 observations in year 3. As shown in Table <xref ref-type="table" rid="T6">6</xref>, in year 1 the completeness rate ranged from 60% to 75% for snack, 32% to 80% for PA, and 48% to 75% for behavioral skills components. The goal was 75% or higher overall, which two schools did not attain. Two of the three schools were rated low in "snacks". The snack is critical to "setting the stage" for the day as it "welcomes" the participants and lets the participants know what will happen each day. Therefore it was important for ensuring that the core content was implemented each day. The areas most commonly omitted during the afterschool interventions involved posting ground rules and providing overviews. For PA, the most commonly omitted elements were explanations of activities, demonstration of skills, and summaries. These are most related to the intervention element of "clarity of rules and expectations". Several strategies to improve dose, described below, were implemented after year one. This seemed to result in improvements for years two and three, as reflected in Table <xref ref-type="table" rid="T6">6</xref>. The remaining areas of weakness were mainly in the snack/welcome component at the beginning of each program day (problems: greeting students in all three schools, posting ground rules in two schools, providing an overview of the week in 1 school for year 2, and providing the summary or closure element in the group time/behavioral skills components.</p><table-wrap id="T6" position="float"><label>Table 6</label><caption><p>Percentage of Dose Delivered for ACT Intervention Components Cohorts 1, 2 and 3 (Goal 75% or higher)</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3">Cohort 1 Schools</th><th align="center" colspan="3">Cohort 2 Schools</th><th align="center" colspan="3">Cohort 3 Schools</th></tr></thead><tbody><tr><td align="left">School number</td><td align="left">1</td><td align="left">2</td><td align="left">3</td><td align="left">4</td><td align="left">5</td><td align="left">6</td><td align="left">7</td><td align="left">8</td><td align="left">9</td></tr><tr><td align="left">Snack (7 elements)</td><td align="left">60</td><td align="left">75</td><td align="left">65</td><td align="left">87</td><td align="left">91</td><td align="left">77</td><td align="left">91</td><td align="left">94</td><td align="left">93</td></tr><tr><td align="left">Physical Activity (4 elements)</td><td align="left">80</td><td align="left">73</td><td align="left">32</td><td align="left">100</td><td align="left">97</td><td align="left">97</td><td align="left">98</td><td align="left">100</td><td align="left">99</td></tr><tr><td align="left">Beh.<break/>Skills (4 elements)</td><td align="left">70</td><td align="left">75</td><td align="left">48</td><td align="left">92</td><td align="left">90</td><td align="left">85</td><td align="left">100</td><td align="left">100</td><td align="left">100</td></tr><tr><td colspan="10"><hr/></td></tr><tr><td align="left">Average</td><td align="left">70</td><td align="left">74</td><td align="left">48</td><td align="left">93</td><td align="left">93</td><td align="left">86</td><td align="left">96</td><td align="left">98</td><td align="left">97</td></tr></tbody></table><table-wrap-foot><p>Note: Schools are denoted by number from 1-9 representing the order in which we worked with the schools during years 1-3 of the trial.</p></table-wrap-foot></table-wrap></sec><sec><title>Staff Manual Changes</title><p>There were both curricula as well as visual and organizational changes made to the manuals. The curricula changes included not repeating any weeks during the program. In addition, some activities were taken out that weren't feasible. For example, a camera activity was taken out because it was not feasible to give each child in each school a camera to complete the activity. Visual and organizational changes were also made to the manual. Each daily sheet was changed to include a "to do" list. A "what's the point?" box was added near the top to reinforce top priorities for each daily activity, and which ACT essential element was being covered that day. Fun and interesting visuals were also added to make the daily sheets more appealing to ACT staff; who were primarily school teachers and staff. Finally, important points conveying the main emphasis of ACT (i.e. fun, belongingness) were bolded and functional definitions were added where appropriate.</p><p>As shown in Table <xref ref-type="table" rid="T7">7</xref>, fidelity data from year 1 indicated some problems. Elements that needed improvement included "clarity of rules and expectations" for PA session and group time/behavioral skills, as well as "optimal challenges" for group time/behavioral skills. Fidelity improved from years 1 to 2, especially choices in the PA component, and clarity of rules and expectations and optimal challenges in group time/behavior skills component. Areas that remained high (e.g., were implemented to a high degree) from years 1 to 2 were optimal challenges, relatedness and belonging in the PA component, and relatedness and belonging in group time/behavioral skills component. Areas that continued to need improvement for all schools are clarity of rules and expectations for both PA and group time/behavior skills components. Areas of weakness from years 1 and 2, clarity of rules and expectations for both PA and group time/behavior skills components and PA during the PA component, were improved in year 3.</p><table-wrap id="T7" position="float"><label>Table 7</label><caption><p>Summary of Fidelity Scores for ACT Intervention Components-Cohorts 1, 2 &#x00026; 3 (Goal 3 or higher; Scale 1-4)</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="center" colspan="3">Cohort 1 Schools</th><th align="center" colspan="3">Cohort 2 Schools</th><th align="center" colspan="3">Cohort 3 Schools</th></tr></thead><tbody><tr><td align="left">School number</td><td align="left">1</td><td align="left">2</td><td align="left">3</td><td align="left">4</td><td align="left">5</td><td align="left">6</td><td align="left">7</td><td align="left">8</td><td align="left">9</td></tr><tr><td align="left">Physical Activity (10 items)</td><td align="left">3.0</td><td align="left">3.2</td><td align="left">2.7</td><td align="left">3.5</td><td align="left">3.3</td><td align="left">3.0</td><td align="left">3.7</td><td align="left">3.7</td><td align="left">3.7</td></tr><tr><td align="left">Beh<break/>Skills (6 items)</td><td align="left">2.5</td><td align="left">2.9</td><td align="left">2.6</td><td align="left">3.4</td><td align="left">3.2</td><td align="left">3.2</td><td align="left">3.7</td><td align="left">3.6</td><td align="left">3.9</td></tr><tr><td colspan="10"><hr/></td></tr><tr><td align="left">Average</td><td align="left">2.7</td><td align="left">3.0</td><td align="left">2.6</td><td align="left">3.4</td><td align="left">3.1</td><td align="left">3.2</td><td align="left">3.7</td><td align="left">3.7</td><td align="left">3.8</td></tr></tbody></table><table-wrap-foot><p>Note: Schools are denoted by number from 1-9 representing the order in which we worked with the schools during years 1-3 of the trial.</p></table-wrap-foot></table-wrap></sec><sec><title>Staff Training Changes</title><p>Significant changes were made in staff training to attempt to improve program dose and fidelity. A core-training with all the schools team leaders was developed and implemented prior to any of the programs start dates. In this training, team leaders spent 20 hours being exposed to all the essential elements of ACT. They participated in hands-on activities that helped them become more familiar with the basic elements of the program. After the core training, team leaders then helped facilitate their school's staff training. The team leaders took on a more active and leadership role in these 12-hour school trainings. Mid-year, a booster training session was held and feedback was given to each team staff member by the ACT project director. Constructive feedback was given based on internal evaluations that had been conducted by the project director. Finally, the external evaluator's criteria sheet was shared with staff members so that they would become familiar with exactly how the essential elements of the program were translated into specific staff tasks and responsibilities.</p></sec></sec><sec><title>Discussion</title><p>Overall, this study suggests that the formative evaluation contributed to improving the intervention dose, fidelity, and program attendance. The intervention itself was not changed; rather, the changes made enabled ACT staff to do a better job of delivering the planned intervention. Many of the changes were related to staff training and monitoring methodology. Specifically, changes in the staff training, the intervention manual, and tracking of students' participation were associated with reaching the goals for dose, fidelity, and reach when comparing years 1 through 3 of implementation. These findings have important implications for future research and suggest that formative process evaluation procedures can inform and enhance program implementation in on-going trials.</p><p>Using process evaluation data in a formative manner is frequently recommended; however, there are relatively few reports describing formative compared to summative uses of process evaluation. A commonly cited challenge, particularly in large trials, is the time frame required for data collection, management, synthesis, and reporting [<xref ref-type="bibr" rid="B14">14</xref>]. This includes the need to develop project infrastructure and procedures that enable project staff to get and use the information in a timely manner. Pre-implementation development of project "essential elements" that define dose and fidelity and a comprehensive process evaluation plan sets the stage and expectations for developing project infrastructure and process evaluation procedures to ensure program implementation and quality [<xref ref-type="bibr" rid="B20">20</xref>].</p><p>In a review conducted by Durlak and DuPre [<xref ref-type="bibr" rid="B4">4</xref>], it was demonstrated that inadequate implementation of a program can adversely affect program outcomes. This is particularly a concern for multi-component programs, given that an improperly implemented component will likely influence the implementation of another. Process data can help ensure that a program stays true to its underlying theory and plan. Theory not only informs proper and desired implementation, it conversely ties implementation to theory and maximizes the possibility of detecting desired outcomes. There is now evidence that links better PA outcomes to fidelity, and methods suggested in this paper may serve as a "best process practice" [<xref ref-type="bibr" rid="B34">34</xref>] that help practitioners identify aspects of PA interventions, [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B28">28</xref>] that may mediate or moderate positive outcomes.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>DKW (1<sup>st </sup>author) is the Principal Investigator on the study and participated in the work of the whole content of this manuscript including conception, design, data acquisition, interpretation of data, drafting the manuscript, critical revision, and supervision. SG (2<sup>nd </sup>author) is a Research Associate, Assistant Professor, who was involved in the conception and design, data acquisition, interpretation of data, drafting the manuscript, critical revision, and supervision. RS (3<sup>rd </sup>author) is a Co-Investigator on the study and participated in the conception and design, data acquisition, analysis and interpretation of data, drafting the manuscript, critical revision, and supervision. HKU (4th author) is a Co-Investigator on the study and participated in data acquisition, drafting the manuscript, critical revision, and supervision. DM (5<sup>th </sup>author) is a graduate student on the study who participated in data acquisition, and drafting the manuscript. LM (6<sup>th </sup>author) is a Research Associate who participated in the acquisition of data, data analysis and interpretation, critical revision of the manuscript, and supervision.</p></sec></body><back><sec><title>Acknowledgements</title><p>This article was supported by a grant (R01 HD 045693) funded by the National Institutes of Child Health and Human Development to Dawn K. Wilson, Ph.D.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Dusenbury</surname><given-names>L</given-names></name><name><surname>Brannigan</surname><given-names>R</given-names></name><name><surname>Falco</surname><given-names>M</given-names></name><name><surname>Hansen</surname><given-names>WB</given-names></name><article-title>A review of research of fidelity of implementation: Implications for drug abuse prevention in school settings</article-title><source>Health Educ Res</source><year>2003</year><volume>18</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1093/her/18.2.237</pub-id><pub-id pub-id-type="pmid">12729182</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>McGraw</surname><given-names>SA</given-names></name><name><surname>Sellers</surname><given-names>DE</given-names></name><name><surname>Stone</surname><given-names>EJ</given-names></name><name><surname>Bebchuk</surname><given-names>J</given-names></name><name><surname>Edmundson</surname><given-names>E</given-names></name><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Buchman</surname><given-names>K</given-names></name><name><surname>Luepker</surname><given-names>R</given-names></name><article-title>Using process data to explain outcomes: An illustration from the Child and Adolescent Trial for Cardiovascular Health (CATCH)</article-title><source>Eval Rev</source><year>1996</year><volume>20</volume><fpage>291</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1177/0193841X9602000304</pub-id><pub-id pub-id-type="pmid">10182206</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>McGraw</surname><given-names>SA</given-names></name><name><surname>Sellers</surname><given-names>DE</given-names></name><name><surname>Stone</surname><given-names>EJ</given-names></name><name><surname>Resnicow</surname><given-names>K</given-names></name><name><surname>Kuester</surname><given-names>S</given-names></name><name><surname>Fridinger</surname><given-names>F</given-names></name><name><surname>Wechsler</surname><given-names>H</given-names></name><article-title>Monitoring implementation of school programs and policies to promote healthy eating and physical activity among youth</article-title><source>Prev Med</source><year>2000</year><volume>31</volume><fpage>S86</fpage><lpage>S97</lpage><pub-id pub-id-type="doi">10.1006/pmed.2000.0648</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Durlak</surname><given-names>J</given-names></name><name><surname>DuPre</surname><given-names>E</given-names></name><article-title>Implementation matters: A review of research on the influence of implementation on program outcomes and the factors affecting implementation</article-title><source>Am J Commun Psychol</source><year>2008</year><volume>41</volume><fpage>327</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s10464-008-9165-0</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="other"><name><surname>Griffin</surname><given-names>S</given-names></name><name><surname>Wilcox</surname><given-names>S</given-names></name><name><surname>Ory</surname><given-names>M</given-names></name><name><surname>Lattimore</surname><given-names>D</given-names></name><name><surname>Leviton</surname><given-names>L</given-names></name><name><surname>Castro</surname><given-names>C</given-names></name><name><surname>Carpenter</surname><given-names>R</given-names></name><name><surname>Rheaume</surname><given-names>C</given-names></name><article-title>Results from Active for Life process evaluation: Program delivery and fidelity</article-title><source>Health Educ Res</source><year>2009</year><comment> in press </comment><pub-id pub-id-type="pmid">19325031</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Holiday</surname><given-names>J</given-names></name><name><surname>Audrey</surname><given-names>S</given-names></name><name><surname>Moore</surname><given-names>L</given-names></name><name><surname>Parry-Langdon</surname><given-names>N</given-names></name><name><surname>Campbell</surname><given-names>R</given-names></name><article-title>High fidelity? How should we consider variations in the delivery of school-based health promotion interventions?</article-title><source>Health Educ J</source><year>2009</year><volume>68</volume><fpage>44</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1177/0017896908100448</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Schneider</surname><given-names>M</given-names></name><name><surname>Hall</surname><given-names>W</given-names></name><name><surname>Hernandez</surname><given-names>A</given-names></name><name><surname>Hindes</surname><given-names>K</given-names></name><name><surname>Montez</surname><given-names>G</given-names></name><name><surname>Pham</surname><given-names>T</given-names></name><name><surname>Rosen</surname><given-names>L</given-names></name><name><surname>Thompson</surname><given-names>D</given-names></name><name><surname>Volpe</surname><given-names>S</given-names></name><name><surname>Zeveloff</surname><given-names>A</given-names></name><name><surname>Steckler</surname><given-names>A</given-names></name><article-title>Rationale, design and methods for process evaluation in the HEALTH study</article-title><source>Int J Ob</source><year>2009</year><volume>33</volume><fpage>S60</fpage><lpage>S67</lpage><pub-id pub-id-type="doi">10.1038/ijo.2009.118</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Karwalajtys</surname><given-names>T</given-names></name><name><surname>McDonough</surname><given-names>B</given-names></name><name><surname>Hall</surname><given-names>H</given-names></name><name><surname>Guirguis-Younger</surname><given-names>M</given-names></name><name><surname>Chambers</surname><given-names>L</given-names></name><name><surname>Kaczorowski</surname><given-names>J</given-names></name><name><surname>Lohfeld</surname><given-names>L</given-names></name><name><surname>Hutchison</surname><given-names>B</given-names></name><article-title>Development of the volunteer peer educator role in a community cardiovascular health awareness program (CHAP): A process evaluation in two communities</article-title><source>J Commun Health</source><year>2009</year><volume>34</volume><fpage>336</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1007/s10900-009-9149-5</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Audrey</surname><given-names>S</given-names></name><name><surname>Holliday</surname><given-names>J</given-names></name><name><surname>Parry-Langdon</surname><given-names>N</given-names></name><name><surname>Campbell</surname><given-names>DT</given-names></name><article-title>Meeting the challenges of implementing process evaluation within randomized controlled trials: the example of ASSIST (A stop smoking in schools trial)</article-title><source>Health Educ Res</source><year>2006</year><volume>21</volume><fpage>366</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1093/her/cyl029</pub-id><pub-id pub-id-type="pmid">16740670</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Young</surname><given-names>D</given-names></name><name><surname>Steckler</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>S</given-names></name><name><surname>Pratt</surname><given-names>C</given-names></name><name><surname>Felton</surname><given-names>G</given-names></name><name><surname>Moe</surname><given-names>S</given-names></name><name><surname>Pickrel</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Grieser</surname><given-names>M</given-names></name><name><surname>Lytle</surname><given-names>LA</given-names></name><name><surname>Lee</surname><given-names>JS</given-names></name><name><surname>Raburn</surname><given-names>B</given-names></name><article-title>Process evaluation results from a school-and community-linked intervention: the Trial of Activity for Adolescent Girls (TAAG)</article-title><source>Health Educ Res</source><year>2008</year><volume>23</volume><fpage>97</fpage><lpage>111</lpage></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Devaney</surname><given-names>B</given-names></name><name><surname>Rossi</surname><given-names>P</given-names></name><article-title>Thinking through evaluation design options</article-title><source>Children Youth Services Review</source><year>1997</year><volume>19</volume><fpage>587</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1016/S0190-7409(97)00047-9</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><name><surname>Helitzer</surname><given-names>D</given-names></name><name><surname>Yoon</surname><given-names>S</given-names></name><person-group person-group-type="editor">Steckler A, Linnan L</person-group><article-title>Process evaluation of the adolescent social action program in New Mexico</article-title><source>Process evaluation for public health interventions and research</source><year>2002</year><publisher-name>San Francisco: Jossey-Bass</publisher-name><fpage>83</fpage><lpage>109</lpage></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Helitzer</surname><given-names>D</given-names></name><name><surname>Yoon</surname><given-names>S</given-names></name><name><surname>Wallerstein</surname><given-names>N</given-names></name><name><surname>Garcia-Velarde</surname><given-names>L</given-names></name><article-title>The role of process evaluation in the training of facilitators for an adolescent health education program</article-title><source>J School Health</source><year>2000</year><volume>70</volume><fpage>141</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1111/j.1746-1561.2000.tb06460.x</pub-id><pub-id pub-id-type="pmid">10790837</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Viadro</surname><given-names>C</given-names></name><name><surname>Earp</surname><given-names>J</given-names></name><name><surname>Altpeter</surname><given-names>M</given-names></name><article-title>Designing a process evaluation for a comprehensive breast cancer screening intervention: Challenges and opportunities</article-title><source>Eval Program Plann</source><year>1997</year><volume>20</volume><fpage>237</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1016/S0149-7189(97)00001-3</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Baranowski</surname><given-names>T</given-names></name><name><surname>Stables</surname><given-names>G</given-names></name><article-title>Process evaluation of the 5-a-day projects</article-title><source>Health Educ Res Behav</source><year>2000</year><volume>27</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1177/109019810002700202</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><name><surname>Shadish</surname><given-names>WR</given-names></name><name><surname>Cook</surname><given-names>TD</given-names></name><name><surname>Campbell</surname><given-names>DT</given-names></name><article-title>Experimental and generalized causal inference</article-title><source>Experimental and quasi-experimental designs for generalized causal inference</source><year>2002</year><publisher-name>Boston, M.A.: Houghton Mifflin Company</publisher-name><fpage>1</fpage><lpage>32</lpage></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Lillehoj</surname><given-names>C</given-names></name><name><surname>Griffin</surname><given-names>K</given-names></name><name><surname>Spoth</surname><given-names>R</given-names></name><article-title>Program provider and observer ratings of school-based preventive intervention implementation: Agreement and relation to youth outcomes</article-title><source>Health Educ Behav</source><year>2004</year><volume>31</volume><fpage>242</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1177/1090198103260514</pub-id><pub-id pub-id-type="pmid">15090124</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>Saunders</surname><given-names>R</given-names></name><name><surname>Ward</surname><given-names>D</given-names></name><name><surname>Felton</surname><given-names>G</given-names></name><name><surname>Dowda</surname><given-names>M</given-names></name><name><surname>Pate</surname><given-names>R</given-names></name><article-title>Examining the link between program implementation and behavior outcomes in the Lifestyle Education for Activity Program (LEAP)</article-title><source>Eval Program Plann</source><year>2006</year><volume>29</volume><fpage>352</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1016/j.evalprogplan.2006.08.006</pub-id><pub-id pub-id-type="pmid">17950863</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="book"><name><surname>Steckler</surname><given-names>A</given-names></name><name><surname>Linnan</surname><given-names>L</given-names></name><person-group person-group-type="editor">Steckler A, Linnan L</person-group><article-title>Process evaluation for public health interventions and research: An overview</article-title><source>Process evaluation for public health interventions and research</source><year>2002</year><publisher-name>San Francisco, C.A.: Jossey-Bass</publisher-name><fpage>1</fpage><lpage>21</lpage></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Brownson</surname><given-names>R</given-names></name><name><surname>Fielding</surname><given-names>J</given-names></name><name><surname>Maylahn</surname><given-names>C</given-names></name><article-title>Evidence based public health: A fundamental concept for public health practice</article-title><source>Ann Rev Publ Health</source><year>2009</year><volume>30</volume><fpage>175</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1146/annurev.publhealth.031308.100134</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Cunningham</surname><given-names>L</given-names></name><name><surname>Michielutte</surname><given-names>R</given-names></name><name><surname>Dignan</surname><given-names>M</given-names></name><name><surname>Sharpe</surname><given-names>P</given-names></name><name><surname>Boxley</surname><given-names>J</given-names></name><article-title>The value of process evaluation in a community-based cancer control program</article-title><source>Eval and Program Plann</source><year>2000</year><volume>23</volume><fpage>13</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/S0149-7189(99)00033-6</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Gettelsohn</surname><given-names>J</given-names></name><name><surname>Steckler</surname><given-names>A</given-names></name><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Pratt</surname><given-names>C</given-names></name><name><surname>Grieser</surname><given-names>M</given-names></name><name><surname>Pickrel</surname><given-names>J</given-names></name><name><surname>Stone</surname><given-names>E</given-names></name><name><surname>Conway</surname><given-names>T</given-names></name><name><surname>Coombs</surname><given-names>D</given-names></name><name><surname>Staten</surname><given-names>L</given-names></name><article-title>Formative research in school and community-based health programs and studies: "State of the art" and the TAAG approach</article-title><source>Health Educ Behav</source><year>2006</year><volume>33</volume><fpage>25</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1177/1090198105282412</pub-id><pub-id pub-id-type="pmid">16397157</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Young</surname><given-names>D</given-names></name><name><surname>Saunders</surname><given-names>R</given-names></name><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Steckler</surname><given-names>A</given-names></name><name><surname>Gettelsohn</surname><given-names>J</given-names></name><name><surname>Saksvig</surname><given-names>R</given-names></name><name><surname>Lythle</surname><given-names>L</given-names></name><name><surname>McKenzie</surname><given-names>T</given-names></name><article-title>Data to action: Using formative research to develop intervention programs to increase physical activity in adolescent girls</article-title><source>Health Educ Behav</source><year>2006</year><volume>33</volume><fpage>97</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1177/1090198105282444</pub-id><pub-id pub-id-type="pmid">16397162</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Wilson</surname><given-names>DK</given-names></name><name><surname>Griffin</surname><given-names>S</given-names></name><name><surname>Saunders</surname><given-names>RP</given-names></name><name><surname>Evans</surname><given-names>A</given-names></name><name><surname>Mixon</surname><given-names>G</given-names></name><name><surname>Wright</surname><given-names>M</given-names></name><name><surname>Beasley</surname><given-names>A</given-names></name><name><surname>Umstattd</surname><given-names>MR</given-names></name><name><surname>Lattimore</surname><given-names>D</given-names></name><name><surname>Watts</surname><given-names>A</given-names></name><name><surname>Freelove</surname><given-names>J</given-names></name><article-title>Formative evaluation of a motivational intervention for increasing physical activity in underserved youth</article-title><source>Eval Program Plann</source><year>2006</year><volume>29</volume><fpage>260</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/j.evalprogplan.2005.12.008</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Steckler</surname><given-names>A</given-names></name><name><surname>Ethelbah</surname><given-names>B</given-names></name><name><surname>Martin</surname><given-names>C</given-names></name><name><surname>Stewart</surname><given-names>D</given-names></name><name><surname>Pardilla</surname><given-names>M</given-names></name><name><surname>Gittelsohn</surname><given-names>J</given-names></name><name><surname>Stone</surname><given-names>E</given-names></name><name><surname>Fenn</surname><given-names>D</given-names></name><name><surname>Smyth</surname><given-names>M</given-names></name><name><surname>Vu</surname><given-names>M</given-names></name><article-title>Pathways process evaluation results: A school-based prevention trial to promote healthful diet and physical activity in American Indian third, fourth, and fifth grade students</article-title><source>Prev Med</source><year>2003</year><volume>37</volume><fpage>S80</fpage><lpage>S90</lpage><pub-id pub-id-type="doi">10.1016/j.ypmed.2003.08.002</pub-id><pub-id pub-id-type="pmid">14636812</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>Marcoux</surname><given-names>M</given-names></name><name><surname>Sallis</surname><given-names>JF</given-names></name><name><surname>McKenzie</surname><given-names>T</given-names></name><name><surname>Marshall</surname><given-names>S</given-names></name><name><surname>Armstrong</surname><given-names>C</given-names></name><name><surname>Goggin</surname><given-names>K</given-names></name><article-title>Process evaluation of a physical activity self-management program for children: SPARK</article-title><source>Psychol Health</source><year>1999</year><volume>14</volume><fpage>659</fpage><lpage>677</lpage><pub-id pub-id-type="doi">10.1080/08870449908410756</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Salmon</surname><given-names>J</given-names></name><name><surname>Ball</surname><given-names>K</given-names></name><name><surname>Crawford</surname><given-names>D</given-names></name><name><surname>Booth</surname><given-names>M</given-names></name><name><surname>Telford</surname><given-names>A</given-names></name><name><surname>Hume</surname><given-names>C</given-names></name><name><surname>Jolley</surname><given-names>D</given-names></name><name><surname>Worsley</surname><given-names>A</given-names></name><article-title>Reducing sedentary behaviors and increasing physical activity among 10-year old children: An overview and process evaluation of the "Switch-Play" intervention</article-title><source>Health Promot Int</source><year>2005</year><volume>20</volume><fpage>7</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1093/heapro/dah502</pub-id><pub-id pub-id-type="pmid">15668218</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="other"><name><surname>Wilson</surname><given-names>DK</given-names></name><name><surname>Kitzman-Ulrich</surname><given-names>H</given-names></name><name><surname>Williams</surname><given-names>JE</given-names></name><name><surname>Saunders</surname><given-names>R</given-names></name><name><surname>Griffin</surname><given-names>S</given-names></name><name><surname>Pate</surname><given-names>R</given-names></name><name><surname>Van Horn</surname><given-names>ML</given-names></name><name><surname>Evans</surname><given-names>A</given-names></name><name><surname>Hutto</surname><given-names>B</given-names></name><name><surname>Addy</surname><given-names>CL</given-names></name><name><surname>Mixon</surname><given-names>G</given-names></name><name><surname>Sission</surname><given-names>S</given-names></name><article-title>An overview of the "Active by Choice Today" (ACT) trial for increasing physical activity Contemp Clin Trials</article-title><year>2008</year><volume>29</volume><fpage>21</fpage><lpage>31</lpage><pub-id pub-id-type="pmid">17716952</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Ryan</surname><given-names>R</given-names></name><name><surname>Deci</surname><given-names>E</given-names></name><article-title>Self-determination theory and the facilitation of intrinsic motivation, social development, and well being</article-title><source>Am Psychol</source><year>2000</year><volume>55</volume><fpage>68</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.55.1.68</pub-id><pub-id pub-id-type="pmid">11392867</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><name><surname>Deci</surname><given-names>E</given-names></name><name><surname>Koestner</surname><given-names>R</given-names></name><name><surname>Ryan</surname><given-names>R</given-names></name><article-title>A meta-analytic review of experiments examining the effects of extrinsic rewards on intrinsic motivation</article-title><source>Psychology Bulletin</source><year>1999</year><volume>125</volume><fpage>41</fpage></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="book"><name><surname>Bandura</surname><given-names>A</given-names></name><source>Social foundation for thought and action</source><year>1986</year><publisher-name>Englewood Cliffs: Prentice-Hall</publisher-name></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Wilson</surname><given-names>DK</given-names></name><name><surname>Evans</surname><given-names>AE</given-names></name><name><surname>Williams</surname><given-names>JE</given-names></name><name><surname>Mixon</surname><given-names>G</given-names></name><name><surname>Sirard</surname><given-names>J</given-names></name><name><surname>Pate</surname><given-names>R</given-names></name><article-title>A preliminary test of a student-centered intervention on increasing physical activity in underserved adolescents</article-title><source>Annals of Behavioral Medicine</source><year>2005</year><volume>30</volume><fpage>119</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1207/s15324796abm3002_4</pub-id><pub-id pub-id-type="pmid">16173908</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="book"><name><surname>Bartholomew</surname><given-names>LK</given-names></name><name><surname>Parcel</surname><given-names>GS</given-names></name><name><surname>Kok</surname><given-names>G</given-names></name><name><surname>Gottieb</surname><given-names>NH</given-names></name><source>Planning Health Promotion Programs: An Intervention Mapping Approach</source><year>2006</year><publisher-name>San Francisco, CA: Jossey-Bass</publisher-name></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><name><surname>Saunders</surname><given-names>RP</given-names></name><name><surname>Evans</surname><given-names>MH</given-names></name><name><surname>Joshi</surname><given-names>P</given-names></name><article-title>Developing a process-evaluation plan for assessing health promotion program implementation: a how-to-guide</article-title><source>Health Promot Practice</source><year>2005</year><volume>6</volume><fpage>134</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1177/1524839904273387</pub-id></mixed-citation></ref></ref-list></back></article>