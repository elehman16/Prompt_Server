<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29551984</article-id><article-id pub-id-type="pmc">5840261</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2018.00254</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>EEG-Based Analysis of the Emotional Effect of Music Therapy on Palliative Care Cancer Patients</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ramirez</surname><given-names>Rafael</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/218839/overview"/></contrib><contrib contrib-type="author"><name><surname>Planas</surname><given-names>Josep</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/21028/overview"/></contrib><contrib contrib-type="author"><name><surname>Escude</surname><given-names>Nuria</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Mercade</surname><given-names>Jordi</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/531455/overview"/></contrib><contrib contrib-type="author"><name><surname>Farriols</surname><given-names>Cristina</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Music and Machine Learning Lab, Department of Information and Communication Technologies, Pompeu Fabra University</institution>, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff><aff id="aff2"><sup>2</sup><institution>Palliative Care Unit, Oncology Service, Parc de Salut Mar, Instituto Mar de Investigaciones M&#x000e9;dicas</institution>, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff><aff id="aff3"><sup>3</sup><institution>Catalan Institute of Music Therapy, University of Barcelona</institution>, <addr-line>Barcelona</addr-line>, <country>Spain</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: <italic>Michele Biasutti, Universit&#x000e0; degli Studi di Padova, Italy</italic></p></fn><fn fn-type="edited-by"><p>Reviewed by: <italic>Dianna Theadora Kenny, University of Sydney, Australia; Jane Ginsborg, Royal Northern College of Music, United Kingdom</italic></p></fn><corresp id="fn001">*Correspondence: <italic>Rafael Ramirez, <email xlink:type="simple">rafael.ramirez@upf.edu</email></italic></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Performance Science, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>02</day><month>3</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>9</volume><elocation-id>254</elocation-id><history><date date-type="received"><day>01</day><month>11</month><year>2017</year></date><date date-type="accepted"><day>15</day><month>2</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Ramirez, Planas, Escude, Mercade and Farriols.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Ramirez, Planas, Escude, Mercade and Farriols</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Music is known to have the power to induce strong emotions. The present study assessed, based on Electroencephalography (EEG) data, the emotional response of terminally ill cancer patients to a music therapy intervention in a randomized controlled trial. A sample of 40 participants from the palliative care unit in the Hospital del Mar in Barcelona was randomly assigned to two groups of 20. The first group [experimental group (EG)] participated in a session of music therapy (MT), and the second group [control group (CG)] was provided with company. Based on our previous work on EEG-based emotion detection, instantaneous emotional indicators in the form of a coordinate in the arousal-valence plane were extracted from the participants&#x02019; EEG data. The emotional indicators were analyzed in order to quantify (1) the overall emotional effect of MT on the patients compared to controls, and (2) the relative effect of the different MT techniques applied during each session. During each MT session, five conditions were considered: <italic>I</italic> (initial patient&#x02019;s state before MT starts), <italic>C1</italic> (passive listening), <italic>C2</italic> (active listening), <italic>R</italic> (relaxation), and <italic>F</italic> (final patient&#x02019;s state). EEG data analysis showed a significant increase in valence (<italic>p</italic> = 0.0004) and arousal (<italic>p</italic> = 0.003) between <italic>I</italic> and <italic>F</italic> in the EG. No significant changes were found in the CG. This results can be interpreted as a positive emotional effect of MT in advanced cancer patients. In addition, according to pre- and post-intervention questionnaire responses, participants in the EG also showed a significant decrease in tiredness, anxiety and breathing difficulties, as well as an increase in levels of well-being. No equivalent changes were observed in the CG.</p></abstract><kwd-group><kwd>palliative care</kwd><kwd>music therapy</kwd><kwd>EEG</kwd><kwd>emotion regulation</kwd><kwd>cancer</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">Horizon 2020<named-content content-type="fundref-id">10.13039/501100007601</named-content></funding-source><award-id rid="cn001">688269</award-id></award-group><award-group><funding-source id="cn002">Ministerio de Ciencia y Tecnolog&#x000ed;a<named-content content-type="fundref-id">10.13039/501100006280</named-content></funding-source><award-id rid="cn002">TIN2013-48152-C2-2-R</award-id></award-group></funding-group><counts><fig-count count="5"/><table-count count="2"/><equation-count count="2"/><ref-count count="49"/><page-count count="7"/><word-count count="0"/></counts></article-meta></front><body><sec><title>Introduction</title><p>Music known to have the power to induce strong emotions and effectively impact the mood of individuals (<xref rid="B41" ref-type="bibr">Sloboda, 1992</xref>; <xref rid="B24" ref-type="bibr">Juslin and V&#x000e4;stfj&#x000e4;ll, 2008</xref>; <xref rid="B25" ref-type="bibr">Koelsch, 2010a</xref>). Research involving functional neuroimaging has shown that emotions evoked by music can modulate activity in virtually all limbic and paralimbic brain structures (<xref rid="B26" ref-type="bibr">Koelsch, 2010b</xref>, <xref rid="B27" ref-type="bibr">2014</xref>). Thus, music is sometimes used as an adjunct therapy in a variety of clinical conditions (<xref rid="B17" ref-type="bibr">Degli Stefani and Biasutti, 2016</xref>; <xref rid="B3" ref-type="bibr">Biasutti and Mangiacotti, 2018</xref>). Music therapy (MT) is based on the therapeutic aspects of music. According to the American Music Therapy Association &#x0201c;Music Therapy is an established health profession in which music is used within a therapeutic relationship to address physical, emotional, cognitive, and social needs of individuals&#x0201d; (<xref rid="B1" ref-type="bibr">American Music Therapy Association, 2017</xref>). MT techniques may be classified as either <italic>active</italic> (where patients participate actively in the process of music creation) or <italic>receptive</italic> (where patients simply listen to live or prerecorded music). Techniques normally include relaxation/imaginative interventions (receptive), therapeutic use of songs (active or receptive), and various types of improvisation (active). Verbal interaction with the patients can complement MT interventions in some cases but is not strictly necessary (<xref rid="B48" ref-type="bibr">Warth et al., 2014</xref>). In general, interventions are personalized according to the needs of the patient (e.g., according to physical state and psychosocial needs).</p><p>Helping patients in palliative care and their families to cope effectively with the pain, worries, and emotional impact inherent in the diagnosis of cancer is a recurrent challenge for doctors and nurses in palliative units. In this context, MT may be considered as a candidate for helping to cope and provide emotional and physical comfort to patients and their families. Active MT (e.g., interactive live music performances) delivered by trained music therapists using singing voice and music instruments can engage patients in ways that receptive MT (e.g., prerecorded music) cannot (<xref rid="B42" ref-type="bibr">Standley, 1986</xref>; <xref rid="B43" ref-type="bibr">Standley and Hanser, 1995</xref>). Studies have found that live music is more effective than prerecorded music with adult cancer patients, i.e., patients over 17 years old (<xref rid="B32" ref-type="bibr">MacGill, 1983</xref>). Live MT allows for personalized interactions which may be particularly important for patients who relate best to music which is relevant to their special current situation (<xref rid="B44" ref-type="bibr">Stecher et al., 1972</xref>). In clinical palliative care, where the patient&#x02019;s medical condition is not likely to be improved, the objective of MT is often to improve the patient&#x02019;s quality of life, e.g., the improvement of pain, stress, and help to regulate negative emotions, e.g., depression, anxiety, anger (<xref rid="B36" ref-type="bibr">Planas et al., 2015</xref>), as well as to enhance communication (<xref rid="B48" ref-type="bibr">Warth et al., 2014</xref>). MT has been associated with a reduction of anxiety (<xref rid="B34" ref-type="bibr">Nguyen, 2003</xref>; <xref rid="B23" ref-type="bibr">Horne-Thompson and Grocke, 2008</xref>) and pain (<xref rid="B29" ref-type="bibr">Krout, 2001</xref>; <xref rid="B30" ref-type="bibr">Lee, 2005</xref>; <xref rid="B12" ref-type="bibr">Curtis, 2011</xref>; <xref rid="B20" ref-type="bibr">Gutgsell et al., 2013</xref>), in addition to enhancing communication (<xref rid="B6" ref-type="bibr">Brown, 2006</xref>) and spiritual well-being (<xref rid="B49" ref-type="bibr">Wlodarczyk, 2007</xref>). <xref rid="B22" ref-type="bibr">Hilliard (2003)</xref> reported a significant improvement of quality of life in terminally ill patients using MT compared to standard medical care only. <xref rid="B33" ref-type="bibr">Nakayama et al. (2009)</xref> reported a decrease in salivary cortisol levels after nine participants received a receptive MT session. Furthermore, MT has been found not only useful for end-of-life patients, but also for family and caregivers (<xref rid="B35" ref-type="bibr">O&#x02019;Callaghan, 2009</xref>). However, current reviews consistently state that there is a lack of rigorous studies providing quantitative grounds for recommending or not the use of MT in the context of palliative care (<xref rid="B28" ref-type="bibr">Korczak et al., 2013</xref>; <xref rid="B5" ref-type="bibr">Bradt and Dileo, 2014</xref>). The 2010 Cochrane review on MT clinical interventions in palliative care reported that only five trials had implemented (quasi-) randomized controlled designs (<xref rid="B5" ref-type="bibr">Bradt and Dileo, 2014</xref>).</p><p>Recently, the neural correlates of music-evoked emotion have been investigated by the neuroscientific community using both functional neuroimaging and Electroencephalography (EEG) techniques. In particular EEG brain activity information has been used to detect emotional states in humans (<xref rid="B10" ref-type="bibr">Choppin, 2000</xref>; <xref rid="B45" ref-type="bibr">Takahashi, 2004</xref>; <xref rid="B4" ref-type="bibr">Bos, 2007</xref>; <xref rid="B31" ref-type="bibr">Lin et al., 2010</xref>; <xref rid="B38" ref-type="bibr">Ramirez and Vamvakousis, 2012</xref>). Patterns of EEG activity have been found to distinguish emotions induced by stimuli with different valence and arousal levels. Asymmetry patterns in frontal EEG activity have been found to distinguish between positive and negative valence, and patterns of overall frontal EEG activity have been found to identify high and low arousal levels (<xref rid="B40" ref-type="bibr">Schmidt and Trainor, 2001</xref>; <xref rid="B38" ref-type="bibr">Ramirez and Vamvakousis, 2012</xref>). <xref rid="B37" ref-type="bibr">Ramirez et al. (2015)</xref> describe an approach to computing in real-time continuous arousal and valence values from EEG activity: based on the EEG signal of a person, the arousal level was determined by computing the ratio of the beta (12&#x02013;28 Hz) and alpha (8&#x02013;12 Hz) brainwaves in the prefrontal cortex, while valence values were computed by comparing the alpha power activation levels of the left and right cortical hemispheres.</p><p>The aim of the present study is to contribute to the understanding of the emotional effect (estimated by EEG information) of MT in the context of palliative care. More precisely, the study aims to evaluate the effectiveness of a particular MT intervention (a 30-min session including active and receptive MT techniques) for improving the emotional state (e.g., stress, anxiety, anger, and depression) of palliative care patients by analyzing their EEG activity. The patients&#x02019; emotional states were estimated before, during, and after MT sessions in order to evaluate the general emotional effect of the MT session, and to assess the emotional effect of particular (active and receptive) MT techniques. With this aim we randomized and assigned participants (<italic>N</italic> = 40) to two groups: the first experimental group (EG) participated in a MT session, while the second (control) group was provided with company. We compared the EEG-based estimated emotional states effect of MT on participants in the EG with the effects of company on participants in the control group (CG). To the best of our knowledge, the present study is the first clinical randomized controlled trial worldwide to examine the emotional effects of MT in palliative care using brain activity information.</p></sec><sec sec-type="materials|methods" id="s1"><title>Materials and Methods</title><sec><title>Participants</title><p>The research reported in this paper is the result of a collaboration between the Palliative Care Unit (PCU), Oncology Service, Parc de Salut Mar in Barcelona, and the Universitat Pompeu Fabra, Barcelona, Spain. Recruitment, interventions, and data collection are carried out at the PCU. Data processing and analysis was carried out at the Universitat Pompeu Fabra. All patients were assessed for eligibility according to predefined inclusion and exclusion criteria shown in <bold>Table <xref ref-type="table" rid="T1">1</xref></bold>. Forty adults (13 female and 27 male, mean = 69 years old, <italic>SD</italic> = 15) with normal hearing, participated in the study. Twenty of them were randomly selected to participate in a MT intervention consisting of both active and receptive techniques. The other twenty participants were provided with company by the music therapists but no music was involved in their sessions. Patients were randomly assigned to the MT group or to the company group by using the method of randomly permuted blocks. Participants granted their written consent and the study procedures were positively evaluated by the Clinical Research Ethical Committee of the Parc de Salut Mar (CEIC-Parc de Salut Mar), Barcelona, Spain, under reference number: 2015/6078/I. All participants were patients admitted to the PCU.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Patients&#x02019; inclusion and exclusion criteria.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Inclusion criteria</th><th valign="top" align="left" rowspan="1" colspan="1">Exclusion criteria</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Admitted to palliative care</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Agony phase (no responsiveness)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Advanced cancer</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Cognitive impairment</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Understanding of Spanish or Catalan language</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Deafness</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">&#x02022; Restlessness and agitation</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></sec><sec><title>Materials</title><sec><title>Music Material</title><p>Prior to the MT session, participants in the EG were interviewed about their music preferences in order to identify particular pieces to be included in their MT session. Music included both instrumental and vocal pieces in a variety of music genres (both classical and popular music), e.g., Canon de Pachelbel, La Bella Lola, Rien de rien, Hey Jude, Color Esperanza.</p></sec><sec><title>Data Acquisition and Processing</title><p>The Emotiv EPOC EEG system (<xref rid="B18" ref-type="bibr">Emotiv Systems Inc., 2014</xref>) was used for acquiring the patients&#x02019; EEG data. It consists of 16 wet saline electrodes, providing 14 EEG channels, and a wireless amplifier. The electrodes&#x02019; positions were located at AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4 according to the international 10&#x02013;20 system (see <bold>Figure <xref ref-type="fig" rid="F1">1</xref></bold>). Reference electrodes were placed at P3 and P4 (just above the subject&#x02019;s ears). Data were digitized using the built-in 16-bit ADC with 128 Hz sampling frequency per channel and sent to the computer via Bluetooth. The obtained EEG data were filtered using Butterworth 8&#x02013;12 Hz and 12&#x02013;28 Hz filters. The electrode contact impedance to the scalp was visually monitored using the Emotiv Control Panel software.</p><fig id="F1" position="float"><label>FIGURE 1</label><caption><p>Electrode positions in the Emotiv EPOC according to the international 10&#x02013;20 system.</p></caption><graphic xlink:href="fpsyg-09-00254-g001"/></fig><p>The Emotiv EPOC EEG device is a low-cost EEG device, which has been mainly marketed as a gaming device. It captures a lower quality signal compared to the quality of the signal captured by more expensive equipments. However, recent reports evaluating the reliability of some low-cost EEG devices, such as the Emotiv Epoc EEG device, for research purposes suggests that they can be reliable for measuring EEG signals (<xref rid="B16" ref-type="bibr">Debener et al., 2012</xref>; <xref rid="B47" ref-type="bibr">Thie et al., 2012</xref>; <xref rid="B2" ref-type="bibr">Badcock et al., 2013</xref>). A usability review of the Emotiv EPOC EEG device as well as of other low-cost systems can be found in <xref rid="B2" ref-type="bibr">Badcock et al. (2013)</xref>. For recording and processing the data, the OpenViBE platform (<xref rid="B39" ref-type="bibr">Renard et al., 2010</xref>) was used.</p></sec></sec><sec><title>Methods</title><p>Patients eligible for inclusion in the study were contacted at the Palliative Care Unit (PCU), Oncology Service, Parc de Salut Mar, and informed about the procedures and objectives of the study. Patients received no information about which of the two interventions was the actual experimental condition. If patients agreed to participate, they were asked to sign the informed consent form. Participants were treated individually. Participants in the EG received a MT session of approximately 30 min. The sessions were conducted by three professional music therapists with extensive experience in palliative care. Each MT session consisted of a receptive song, an active song and a relaxation/imaginative receptive intervention. EEG data was recorded before the MT session, during the session, and at the end of the session. Participants in the CG were accompanied by the same music therapists for approximately 30 min in which they conversed feely about music and their music preferences. All participants were receiving similar levels of medication at the moment of the study. <bold>Figure <xref ref-type="fig" rid="F2">2</xref></bold> shows a flow diagram of the study design.</p><fig id="F2" position="float"><label>FIGURE 2</label><caption><p>Flow diagram of the study design.</p></caption><graphic xlink:href="fpsyg-09-00254-g002"/></fig><p>In addition to EEG data, participants self-assessed several qualitative variables before and after the sessions by completing the Edmonton Symptom Assessment System (ESAS) pre and post. ESAS (<xref rid="B7" ref-type="bibr">Bruera et al., 1991</xref>; <xref rid="B8" ref-type="bibr">Bruera and Macdonald, 1993</xref>; <xref rid="B9" ref-type="bibr">Chang et al., 2000</xref>) is designed to help in the assessment of nine common symptoms in patients with cancer. The nine symptoms considered in ESAS are: pain, tiredness, nausea, depression, anxiety, drowsiness, appetite, wellbeing, and shortness of breath. The degree of severity of each symptom is rated in 0&#x02013;10 numerical scale. For each group (i.e., EG and CG) and each rated symptom, data were analyzed by applying a <italic>t</italic>-test of the differences of pre- and post- values.</p><sec><title>EEG Analysis</title><p>The patients&#x02019; EEG data was transformed into a coordinate in Thayer&#x02019;s arousal-valence emotion plane (<xref rid="B46" ref-type="bibr">Thayer, 1989</xref>), depicted in <bold>Figure <xref ref-type="fig" rid="F3">3</xref></bold>. The EEG data processing was inspired by <xref rid="B38" ref-type="bibr">Ramirez and Vamvakousis (2012)</xref> where it is shown that the computed arousal and valence values indeed contain meaningful information about the user&#x02019;s emotional state. Artifact detection/elimination was performed by visual inspection of the signal. EEG data was normalized to avoid inter-participant variability. Using the EEG signal of a participant, his/her arousal level was computed as the ratio of the beta (12&#x02013;28 Hz) and alpha (8&#x02013;12 Hz) brainwaves (see Equation 1). EEG data was recorded in 4 locations on the prefrontal cortex: AF3, AF4, F3, and F4 (see <bold>Figure <xref ref-type="fig" rid="F1">1</xref></bold>). Beta (&#x003b2;) waves have been associated with alert or excited states of mind, while alpha (&#x003b1;) waves are associated with relaxed or brain inactivation states of mind. Thus, the &#x003b2;/&#x003b1; ratio may be considered as an indicator of the arousal state of a person. More precisely, the instantaneous arousal level of a participant was computed as specified by Equation 1 below:</p><disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mrow><mml:mo mathvariant="normal">(</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">3</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">4</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">3</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">4</mml:mn><mml:mo mathvariant="normal">)</mml:mo><mml:mo mathvariant="normal">/</mml:mo><mml:mrow><mml:mo mathvariant="normal">(</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">3</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">4</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">3</mml:mn><mml:mo mathvariant="normal">+</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">4</mml:mn><mml:mo mathvariant="normal">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><fig id="F3" position="float"><label>FIGURE 3</label><caption><p>Thayer&#x02019;s arousal-valence emotional plane.</p></caption><graphic xlink:href="fpsyg-09-00254-g003"/></fig><p>A number of EEG studies (<xref rid="B21" ref-type="bibr">Henriques and Davidson, 1991</xref>; <xref rid="B13" ref-type="bibr">Davidson, 1992</xref>, <xref rid="B14" ref-type="bibr">1995</xref>, <xref rid="B15" ref-type="bibr">1998</xref>) have shown that the right hemisphere is more involved in negative emotion while the left frontal area more associated with positive affect and memories. Thus, for computing valence states, in this study we computed the activation levels of the two cortical hemispheres and compared them. Positions F3 and F4 are the most commonly used positions for looking at this valence related activity, as they are located in the prefrontal lobe, which plays a central role in emotion regulation. Valence values were obtained by computing the difference of alpha power &#x003b1; in channels F4 and F3. More precisely, valence level was computed as specified by Equation 2, as following:</p><disp-formula id="E2"><mml:math id="M2"><mml:mrow><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">4</mml:mn><mml:mo mathvariant="normal">&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi mathvariant="normal">F</mml:mi><mml:mn mathvariant="normal">3</mml:mn></mml:mrow></mml:math></disp-formula></sec></sec></sec><sec><title>Results</title><p>Among the symptoms assessed with ESAS, tiredness (<italic>p</italic> = 0.002), anxiety (<italic>p</italic> = 0.002), breathing difficulty (<italic>p</italic> = 0.042), and wellbeing (<italic>p</italic> = 0.036) showed statistical significant differences (i.e., improvement) between pre and post values in the EG. No statistically significant differences were found in the pre and post values of the qualitative indicators in the CG.</p><p>Using the EEG data obtained during both the MT sessions and the company sessions, average valence and arousal values were computed at the beginning and at the end of the sessions (<bold>Table <xref ref-type="table" rid="T2">2</xref></bold>). Average valence values in <bold>Table <xref ref-type="table" rid="T2">2</xref></bold> correspond to the average degree of relative alpha activity in the left frontal lobe, thus larger values are associated with more positive emotional states. Average arousal values on the other hand correspond to either more beta activity or less alpha activity (or both) in the frontal lobe, and thus larger values represent higher arousal states. For the EG, the computed average arousal values (standard deviation) were -0.3 (0.25) and -0.19 (0.18) for the beginning and end of session, respectively, while the computed average valence values (standard deviation) were -0.23 (0.16) and 0.08 (0.17) for the beginning and end of the session, respectively. For the CG, the computed average arousal values were -0.35 (0.25) and -0.24 (0.24) for the beginning and end of the session, respectively, while the computed average valence values were -0.16 (0.38) and -0.11 (0.33) for the beginning and end of session, respectively.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Average and standard deviation of arousal and valence values at the beginning and at the end of the session.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Group</th><th valign="top" align="center" rowspan="1" colspan="1">Indicators</th><th valign="top" align="center" colspan="2" rowspan="1">Beginning</th><th valign="top" align="center" colspan="2" rowspan="1">End</th></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" colspan="2" rowspan="1"><hr/></td><td valign="top" align="left" colspan="2" rowspan="1"><hr/></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1">Average</th><th valign="top" align="center" rowspan="1" colspan="1"><italic>SD</italic></th><th valign="top" align="center" rowspan="1" colspan="1">Average</th><th valign="top" align="center" rowspan="1" colspan="1"><italic>SD</italic></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">EG</td><td valign="top" align="center" rowspan="1" colspan="1">Arousal</td><td valign="top" align="center" rowspan="1" colspan="1">-0.30</td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">-0.19</td><td valign="top" align="center" rowspan="1" colspan="1">0.18</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">Valence</td><td valign="top" align="center" rowspan="1" colspan="1">-0.23</td><td valign="top" align="center" rowspan="1" colspan="1">0.16</td><td valign="top" align="center" rowspan="1" colspan="1">-0.08</td><td valign="top" align="center" rowspan="1" colspan="1">0.17</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">CG</td><td valign="top" align="center" rowspan="1" colspan="1">Arousal</td><td valign="top" align="center" rowspan="1" colspan="1">-0.35</td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">-0.24</td><td valign="top" align="center" rowspan="1" colspan="1">0.24</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">Valence</td><td valign="top" align="center" rowspan="1" colspan="1">-0.16</td><td valign="top" align="center" rowspan="1" colspan="1">0.38</td><td valign="top" align="center" rowspan="1" colspan="1">-0.11</td><td valign="top" align="center" rowspan="1" colspan="1">0.33</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"/></tr></tbody></table></table-wrap><p>In the EG, both the difference between arousal values (<italic>p</italic> = 0.003) and the difference between valence values (<italic>p</italic> = 0.0004) at the beginning and the end of the MT sessions were statistically significant. No significant differences were found in the CG.</p><p><bold>Figure <xref ref-type="fig" rid="F4">4</xref></bold> shows the correlation within a session between time and the computed average arousal (orange line) and valence (blue line) values, for the EG. Periods in time correspond to each of the session sections: beginning, receptive song, active song, receptive imaginative intervention, and end of session. For arousal the obtained correlation was <italic>r</italic> = 0.63 (<italic>p</italic> = 0.25) while for valence it was <italic>r</italic> = 0.89 (<italic>p</italic> = 0.04).</p><fig id="F4" position="float"><label>FIGURE 4</label><caption><p>Experimental group averaged arousal (Orange) and valence (blue) levels along time. 1 = beginning, 2 = receptive song, 3 = active song, 4 = receptive imaginative intervention, and 5 = end of session.</p></caption><graphic xlink:href="fpsyg-09-00254-g004"/></fig><p><bold>Figure <xref ref-type="fig" rid="F5">5</xref></bold> shows the plot in the arousal/valence plane for the averaged estimated emotional state of participants in the EG during the music therapy session: initial state (1), receptive song (2), active song (3), receptive imaginative intervention (4), and final state (5).</p><fig id="F5" position="float"><label>FIGURE 5</label><caption><p>Plot in the arousal/valence plane for the averaged estimated emotional state of participants in the EG during one session: initial state (1), receptive song (2), active song (3), receptive imaginative intervention (4), and final state (5).</p></caption><graphic xlink:href="fpsyg-09-00254-g005"/></fig><p>In order to investigate if there was a correlation between the participants&#x02019; initial and final emotional state, we trained a (regression) support vector machine (SVM) (<xref rid="B11" ref-type="bibr">Cristianini and Shawe-Taylor, 2000</xref>) with linear kernel to learn a model to predict the final emotional state of participants given their initial state. Pearson correlation coefficients of the predicted end-of-session values with respect to the real end-of-session values were computed using 10-fold cross validation. For the EG we obtained <italic>r</italic> = 0.53 for arousal and <italic>r</italic> = 0.77 for valence, while for the CG the obtained correlations were <italic>r</italic> = -0.15 for arousal and <italic>r</italic> = 0.13 for valence.</p></sec><sec><title>Discussion</title><p>Analysis of the qualitative self-reported data showed that 12 out of the 20 participants in the EG reported feeling less weak after the MT session compared with the beginning of the session (while none of the other participants in the group reported increased weakness), confirming the reported statistically significant difference (<italic>p</italic> = 0.002) between pre and post weakness self-reported values. On the other hand, six out of the 20 participants in the CG reported feeling weaker after the company session (while only two reported feeling less weak). Similarly, 11 out of the 20 participants in the EG reported feeling less anxious, and 12 in a better mood after the MT session compared to their self-reported values at the beginning of the session. This is in line with the statistically significant decrease in anxiety (<italic>p</italic> = 0.002) and increase in mood (<italic>p</italic> = 0.036).</p><p>Electroencephalography data obtained showed that overall valence level in the participants in the EG was significantly higher at the end of the MT session compared to the starting level (<italic>p</italic> = 0.0004). This was not the case in the CG where no significant difference in valence levels was found. This result should be interpreted as a decrease of relative alpha activity in the left frontal lobe in the EG participants, which may be interpreted as an improvement of mood or a lessening of depressive mood (<xref rid="B21" ref-type="bibr">Henriques and Davidson, 1991</xref>; <xref rid="B19" ref-type="bibr">Gotlib et al., 1999</xref>; <xref rid="B37" ref-type="bibr">Ramirez et al., 2015</xref>). This reinforces the significant improvement in self-assessment mood reported by the participants in the EG. Similarly, arousal values at the beginning and at the end of the MT session showed a smaller but nevertheless significant difference (<italic>p</italic> = 0.003) in the EG, while no difference in arousal values was found in the CG. The lower <italic>p</italic>-value for arousal may be due to the fact that while most of the patients with terminal cancer are naturally in a low arousal state (e.g., low-mood or depressed), there may be some patients who feel anxious, i.e., are already in a high arousal state. EEG data also showed a significant improvement in valence in participants in the EG reflecting a positive change in their initial emotional state. It is worth noting that while there was a continuous improvement in the participants&#x02019; valence throughout the whole MT session, the first MT intervention (i.e., the receptive song) alone produced a significant improvement in valence (<italic>p</italic> = 0.0019) when compared to the EG participants&#x02019; initial state.</p><p>Regarding the relative effects of the different MT techniques applied during the session (i.e., passive listening, active listening, and relaxation), relaxation produced significantly lower arousal levels than active listening in participants in the EG (<italic>p</italic> = 0.025). This result was expected given that <italic>R</italic> is a relaxation technique used for managing both psychological and physiological agitated states. Surprisingly, no similar significant differences were found between relaxation and passive listening. No relative significant differences in valence were found between passive listening, active listening and relaxation.</p><p>In the EG no significant correlation between arousal values and time was found. This may be because of differences between the participants&#x02019; states of arousal, as previously mentioned, to the different MT techniques used in the sessions, or the differences between participants&#x02019; sensitivity to music. Interestingly, the correlation between computed valence levels and time within the MT session was found significant (<italic>p</italic> = 0.038), which represents a gradual and constant improvement in the EG participants&#x02019; valence emotional state. It has to be noted that time and type of MT intervention are confounded, thus this result has to be investigated further in order to establish if it is due to the natural progression of the MT session or to the particular sequence of interventions.</p><p>Considering the observed improvements in valence levels in one MT session and the limited duration of each session (i.e., approximately 30 min), it seems possible that further improvement in valence levels may have been obtained if sessions had been longer and/or if treatment had consisted of more sessions. Unfortunately, due to the very short life-span (2 weeks on average) of the participants in the study it was impossible to program more than one MT session per participant. In the past, only a few studies in the literature have investigated the long-term effect of MT. In the current study, no follow-up of the participants in order to examine the long-term effect of MT was possible. We plan to investigate this issue further, perhaps considering a different group of patients.</p><p>The question of personalization in MT is an important one but nevertheless it has been little investigated. In this context, we asked ourselves if the emotional state of the participants at the end of the session was related to their emotional state at the beginning of the session. In order to investigate this issue, machine learning techniques were applied to obtain a computational model to predict the participants&#x02019; emotional state at the end of the session given their initial emotional state. The accuracy of the obtained models (<italic>r</italic> = 0.53 for arousal and <italic>r</italic> = 0.77 for valence in the EG, and <italic>r</italic> = -0.15 for arousal and <italic>r</italic> = 0.13 for valence in the CG), indicate that there is a moderate/strong relationship between the initial and final arousal/valence states of participants in the EG, while there is no such relationship in the CG. Interestingly, in the context of this study, we showed that it is possible to predict with some degree of accuracy the final emotional state of a person after the MT session based on his/her initial emotional state. This is, using the EEG data of the participants in the study it is possible to extract patterns which allow us to predict the emotional outcome (in particular valence) of new participants after the MT intervention described in this paper. This could open the possibility for personalized MT interventions based on the patient&#x02019;s state at the beginning of the session. We plan to investigate this further, specifically by adding extra information about the patients (e.g., physiological variables) for training the predictive models.</p><p>The results obtained in this study seem to indicate that MT techniques (both active and receptive) can be useful tools for modulating the emotional state of end-of-life patients. Helping such patients to modulate their emotions may improve their quality of life by helping them to cope with the emotional effects inherent in their condition. Although the present study is limited in scope due to the use of only one MT session per participant, it provides an evidence-based rationale for MT in palliative care based on methods involving brain activity (EEG) data. Furthermore, the results obtained open the possibility for personalized MT interventions based on patients&#x02019; emotional state before MT is applied.</p></sec><sec><title>Author Contributions</title><p>RR supervised data gathering, processed, and analyzed EEG data, and wrote the paper. JP and CF recruited participants and supervised the study at Parc de Salut Mar and contributed to the writing of the paper. NE and JM participated in both the music therapy and company sessions as well as gathered EEG data.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This work was partly sponsored by Fundaci&#x000f3;n Memora, the Spanish TIN project TIMUL (TIN2013-48152-C2-2-R), and the European Union Horizon 2020 research and innovation program under grant agreement No. 688269 (TELMI project).</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><collab>American Music Therapy Association</collab> (<year>2017</year>). Available at. <ext-link ext-link-type="uri" xlink:href="http://www.musictherapy.org">http://www.musictherapy.org</ext-link></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badcock</surname><given-names>N. A.</given-names></name><name><surname>Mousikou</surname><given-names>P.</given-names></name><name><surname>Mahajan</surname><given-names>Y.</given-names></name><name><surname>de Lissa</surname><given-names>P.</given-names></name><name><surname>Johnson</surname><given-names>T.</given-names></name><name><surname>McArthur</surname><given-names>G.</given-names></name></person-group> (<year>2013</year>). <article-title>Validation of the emotiv EPOC<sup>&#x000ae;</sup> EEG gaming system for measuring research quality auditory ERPs.</article-title>
<source><italic>PeerJ.</italic></source>
<volume>1</volume>:<issue>e38</issue>
<pub-id pub-id-type="doi">10.7717/peerj.38</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biasutti</surname><given-names>M.</given-names></name><name><surname>Mangiacotti</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Assessing a cognitive music training for older participants: a randomised controlled trial.</article-title>
<source><italic>Int. J. Geriatr. Psychiatry</italic></source>
<volume>33</volume>
<fpage>271</fpage>&#x02013;<lpage>278</lpage>. <pub-id pub-id-type="doi">10.1002/gps.4721</pub-id>
<pub-id pub-id-type="pmid">28401595</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bos</surname><given-names>D. O.</given-names></name></person-group> (<year>2007</year>). <article-title>EEG-based emotion recognition: the influence of visual and auditory stimuli.</article-title>
<source><italic>Emotion</italic></source>
<volume>57</volume>
<fpage>1798</fpage>&#x02013;<lpage>1806</lpage>.</mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradt</surname><given-names>J.</given-names></name><name><surname>Dileo</surname><given-names>C.</given-names></name></person-group> (<year>2014</year>). <article-title>Music therapy for end-of-life care.</article-title>
<source><italic>Cochrane Database Syst. Rev</italic></source>
<volume>1</volume>:<issue>CD007169</issue>. <pub-id pub-id-type="doi">10.1002/14651858.CD007169.pub3</pub-id>
<pub-id pub-id-type="pmid">24638935</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <source><italic>Comparison of the Effects of Music and Conversation on Hospice Patient&#x02019;s Predisposition to Communicate and Communication Behaviors.</italic></source>
<comment>Master&#x02019;s thesis</comment>, <publisher-loc>Florida State University, Tallahassee, FL</publisher-loc>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruera</surname><given-names>E.</given-names></name><name><surname>Kuehn</surname><given-names>N.</given-names></name><name><surname>Miller</surname><given-names>M. J.</given-names></name><name><surname>Selmser</surname><given-names>P.</given-names></name><name><surname>Macmillan</surname><given-names>K.</given-names></name></person-group> (<year>1991</year>). <article-title>The edmonton symptom assessment system (ESAS): a simple method of the assessment of palliative care patients.</article-title>
<source><italic>J. Palliat. Care</italic></source>
<volume>7</volume>
<fpage>6</fpage>&#x02013;<lpage>9</lpage>.<pub-id pub-id-type="pmid">1714502</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bruera</surname><given-names>E.</given-names></name><name><surname>Macdonald</surname><given-names>S.</given-names></name></person-group> (<year>1993</year>). <article-title>&#x0201c;Audit methods: the edmonton symptom assessment,&#x0201d; in</article-title>
<source><italic>Clinical Audit in Palliative Care</italic></source>, <role>ed.</role>
<person-group person-group-type="editor"><name><surname>Higginson</surname><given-names>I.</given-names></name></person-group> (<publisher-loc>Oxford</publisher-loc>: <publisher-name>Radcliffe Medical Press</publisher-name>), <fpage>61</fpage>&#x02013;<lpage>77</lpage>.</mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>V. T.</given-names></name><name><surname>Hwang</surname><given-names>S. S.</given-names></name><name><surname>Feuerrman</surname><given-names>M.</given-names></name></person-group> (<year>2000</year>). <article-title>Validation of the edmonton symptom assessment scale.</article-title>
<source><italic>Cancer</italic></source>
<volume>88</volume>
<fpage>2164</fpage>&#x02013;<lpage>2171</lpage>. <pub-id pub-id-type="doi">10.1002/(SICI)1097-0142(20000501)88:9&#x0003c;2164::AID-CNCR24&#x0003e;3.0.CO;2-5</pub-id><pub-id pub-id-type="pmid">10813730</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Choppin</surname><given-names>A.</given-names></name></person-group> (<year>2000</year>). <source><italic>EEG-Based Human Interface for Disabled Individuals: Emotion Expression With Neural Networks.</italic></source>
<comment>Master&#x02019;s thesis</comment>, <publisher-loc>Tokyo Institute of Technology, Yokohama</publisher-loc>.</mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N.</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name></person-group> (<year>2000</year>). <source><italic>An Introduction to Support Vector Machines and other Kernel-Based Learning Methods.</italic></source>
<publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>
<pub-id pub-id-type="doi">10.1017/CBO9780511801389</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname><given-names>S. L.</given-names></name></person-group> (<year>2011</year>). <article-title>Music therapy and the symphony: a university-community collaborative project in palliative care.</article-title>
<source><italic>Music Med.</italic></source>
<volume>3</volume>
<fpage>20</fpage>&#x02013;<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1177/1943862110389618</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1992</year>). <article-title>Emotion and affective style: hemispheric substrates.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>3</volume>
<fpage>39</fpage>&#x02013;<lpage>43</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1992.tb00254.x</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1995</year>). <article-title>&#x0201c;Cerebral asymmetry, emotion and affective style,&#x0201d; in</article-title>
<source><italic>Brain Asymmetry</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Davidson</surname><given-names>R. J.</given-names></name><name><surname>Hugdahl</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>361</fpage>&#x02013;<lpage>387</lpage>.</mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Affective style and affective disorders: perspectives from affective neuroscience.</article-title>
<source><italic>Cogn. Emot.</italic></source>
<volume>12</volume>
<fpage>307</fpage>&#x02013;<lpage>330</lpage>. <pub-id pub-id-type="doi">10.1080/026999398379628</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debener</surname><given-names>S.</given-names></name><name><surname>Minow</surname><given-names>F.</given-names></name><name><surname>Emkes</surname><given-names>R.</given-names></name><name><surname>Gandras</surname><given-names>G.</given-names></name><name><surname>de Vos</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>How about taking a low-cost, small, and wireless EEG for a walk?</article-title>
<source><italic>Psychophysiology</italic></source>
<volume>49</volume>
<fpage>1617</fpage>&#x02013;<lpage>1621</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01471.x</pub-id>
<pub-id pub-id-type="pmid">23013047</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Degli Stefani</surname><given-names>M.</given-names></name><name><surname>Biasutti</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <article-title>Effects of music therapy on drug therapy of adult psychiatric outpatients: a pilot randomized controlled study.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>7</volume>:<issue>1518</issue>. <pub-id pub-id-type="doi">10.3389/fpsyg.2016.01518</pub-id>
<pub-id pub-id-type="pmid">27774073</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><collab>Emotiv Systems Inc.</collab> (<year>2014</year>). <source><italic>Researchers.</italic></source> Available at: <ext-link ext-link-type="uri" xlink:href="http://www.emotiv.com/">http://www.emotiv.com/</ext-link></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gotlib</surname><given-names>I. H.</given-names></name><name><surname>Ranganath</surname><given-names>C.</given-names></name><name><surname>Rosenfeld</surname><given-names>J. P.</given-names></name></person-group> (<year>1999</year>). <article-title>EEG alpha asymmetry, depression, and cognitive functioning.</article-title>
<source><italic>Cogn. Emot.</italic></source>
<volume>12</volume>
<fpage>449</fpage>&#x02013;<lpage>478</lpage>. <pub-id pub-id-type="doi">10.1080/026999398379673</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gutgsell</surname><given-names>K. J.</given-names></name><name><surname>Schluchter</surname><given-names>M.</given-names></name><name><surname>Margevicius</surname><given-names>S.</given-names></name><name><surname>DeGolia</surname><given-names>P. A.</given-names></name><name><surname>McLaughlin</surname><given-names>B.</given-names></name><name><surname>Harris</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Music therapy reduces pain in palliative care patients: a randomized controlled trial.</article-title>
<source><italic>J. Pain Symptom Manage</italic></source>
<volume>45</volume>
<fpage>822</fpage>&#x02013;<lpage>831</lpage>. <pub-id pub-id-type="doi">10.1016/j.jpainsymman.2012.05.008</pub-id>
<pub-id pub-id-type="pmid">23017609</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henriques</surname><given-names>J. B.</given-names></name><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1991</year>). <article-title>Left frontal hypoactivation in depression.</article-title>
<source><italic>J. Abnorm. Psychol.</italic></source>
<volume>100</volume>
<fpage>535</fpage>&#x02013;<lpage>545</lpage>. <pub-id pub-id-type="doi">10.1037/0021-843X.100.4.535</pub-id><pub-id pub-id-type="pmid">1757667</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hilliard</surname><given-names>R. E.</given-names></name></person-group> (<year>2003</year>). <article-title>The effects of music therapy on the quality and length of life of people diagnosed with terminal cancer.</article-title>
<source><italic>J. Music Ther.</italic></source>
<volume>40</volume>
<fpage>113</fpage>&#x02013;<lpage>137</lpage>. <pub-id pub-id-type="doi">10.1093/jmt/40.2.113</pub-id>
<pub-id pub-id-type="pmid">14505443</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horne-Thompson</surname><given-names>A.</given-names></name><name><surname>Grocke</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>The effect of music therapy on anxiety in patients who are terminally ill.</article-title>
<source><italic>J. Palliat. Med.</italic></source>
<volume>11</volume>
<fpage>582</fpage>&#x02013;<lpage>590</lpage>. <pub-id pub-id-type="doi">10.1089/jpm.2007.0193</pub-id>
<pub-id pub-id-type="pmid">18454611</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juslin</surname><given-names>P. N.</given-names></name><name><surname>V&#x000e4;stfj&#x000e4;ll</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>Emotional responses to music: the need to consider underlying mechanisms.</article-title>
<source><italic>Behav. Brain Sci.</italic></source>
<volume>31</volume>
<fpage>559</fpage>&#x02013;<lpage>575</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X08005293</pub-id>
<pub-id pub-id-type="pmid">18826699</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S.</given-names></name></person-group> (<year>2010a</year>). <article-title>&#x0201c;Functional neuroimaging,&#x0201d; in</article-title>
<source><italic>Music and Emotion</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Juslin</surname><given-names>P.</given-names></name><name><surname>Sloboda</surname><given-names>J. A.</given-names></name></person-group> (<publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>), <fpage>975</fpage>.</mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S.</given-names></name></person-group> (<year>2010b</year>). <article-title>Towards a neural basis of music-evoked emotions.</article-title>
<source><italic>Trends Cogn. Sci.</italic></source>
<volume>14</volume>
<fpage>131</fpage>&#x02013;<lpage>137</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2010.01.002</pub-id>
<pub-id pub-id-type="pmid">20153242</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>Brain correlates of music-evoked emotions.</article-title>
<source><italic>Nat. Rev. Neurosci.</italic></source>
<volume>15</volume>
<fpage>170</fpage>&#x02013;<lpage>180</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3666</pub-id>
<pub-id pub-id-type="pmid">24552785</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korczak</surname><given-names>D.</given-names></name><name><surname>Wastian</surname><given-names>M.</given-names></name><name><surname>Schneider</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Music therapy in palliative setting.</article-title>
<source><italic>GMS Health Technol. Assess.</italic></source>
<volume>9</volume>:<issue>Doc07</issue>. <pub-id pub-id-type="doi">10.3205/hta000113</pub-id>
<pub-id pub-id-type="pmid">23904890</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krout</surname><given-names>R. E.</given-names></name></person-group> (<year>2001</year>). <article-title>The effects of single-session music therapy interventions on the observed and self-reported levels of pain control, physical comfort, and relaxation of hospice patients.</article-title>
<source><italic>Am. J. Hosp. Palliat. Care</italic></source>
<volume>18</volume>
<fpage>383</fpage>&#x02013;<lpage>390</lpage>. <pub-id pub-id-type="doi">10.1177/104990910101800607</pub-id>
<pub-id pub-id-type="pmid">11712719</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H.</given-names></name></person-group> (<year>2005</year>). <source><italic>The Effect of Live Music Via the ISO-Priniciple on Pain Management in Palliative Care as Measured by Self-Report using a Graphic Rating Scale (GRS) and Pulse Rate.</italic></source>
<comment>Master&#x02019;s thesis</comment>, <publisher-loc>Florida State University, Tallahassee, FL</publisher-loc>.</mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>Y.-P.</given-names></name><name><surname>Wang</surname><given-names>C.-H.</given-names></name><name><surname>Jung</surname><given-names>T.-P.</given-names></name><name><surname>Wu</surname><given-names>T.-L.</given-names></name><name><surname>Jeng</surname><given-names>S.-K.</given-names></name><name><surname>Duann</surname><given-names>J.-R.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>EEG-based emotion recognition in music listening.</article-title>
<source><italic>IEEE Trans. Biomed. Eng.</italic></source>
<volume>57</volume>
<fpage>1798</fpage>&#x02013;<lpage>1806</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2010.2048568</pub-id>
<pub-id pub-id-type="pmid">20442037</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacGill</surname><given-names>B. L.</given-names></name></person-group> (<year>1983</year>). <article-title>The effects of live music versus tape recorded music on hospitalized cancer patients.</article-title>
<source><italic>Music Ther.</italic></source>
<volume>3</volume>
<fpage>17</fpage>&#x02013;<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1093/mt/3.1.17</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakayama</surname><given-names>H.</given-names></name><name><surname>Kikuta</surname><given-names>F.</given-names></name><name><surname>Takeda</surname><given-names>H.</given-names></name></person-group> (<year>2009</year>). <article-title>A pilot study on effectiveness of music therapy in hospice in Japan.</article-title>
<source><italic>J. Music Ther.</italic></source>
<volume>46</volume>
<fpage>160</fpage>&#x02013;<lpage>172</lpage>. <pub-id pub-id-type="doi">10.1093/jmt/46.2.160</pub-id>
<pub-id pub-id-type="pmid">19463033</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <source><italic>The Effect Of Music Therapy on End-of-Life Patients&#x02019; Quality of Life, Emotional State, and Family Satisfaction as Measured by Self-Report.</italic></source>
<comment>Master&#x02019;s thesis</comment>, <publisher-loc>Florida State University, Tallahassee, FL</publisher-loc>.</mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O&#x02019;Callaghan</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <article-title>Objectivist and constructivist music therapy research in oncology and palliative care: an overview and reflection.</article-title>
<source><italic>Music Med.</italic></source>
<volume>1</volume>
<fpage>41</fpage>&#x02013;<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1177/1943862109337135</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Planas</surname><given-names>J.</given-names></name><name><surname>Escud&#x000e9;</surname><given-names>N.</given-names></name><name><surname>Farriols</surname><given-names>C.</given-names></name><name><surname>Villar</surname><given-names>H.</given-names></name><name><surname>Mercad&#x000e9;</surname><given-names>J.</given-names></name><name><surname>Ruiz</surname><given-names>A. I.</given-names></name></person-group> (<year>2015</year>). <article-title>Effectiveness of music therapy in advanced cancer patients admitted to a palliative care unit: a non-randomized controlled.</article-title>
<source><italic>Clin. Trial Music Med.</italic></source>
<volume>7</volume>
<fpage>23</fpage>&#x02013;<lpage>31</lpage>.</mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Palencia-Lefler</surname><given-names>M.</given-names></name><name><surname>Giraldo</surname><given-names>S.</given-names></name><name><surname>Vamvakousis</surname><given-names>Z.</given-names></name></person-group> (<year>2015</year>). <article-title>Musical neurofeedback for treating depression in elderly people.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>9</volume>:<issue>354</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2015.00354</pub-id>
<pub-id pub-id-type="pmid">26483628</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Vamvakousis</surname><given-names>Z.</given-names></name></person-group> (<year>2012</year>). <article-title>&#x0201c;Detecting emotion from EEG signals using the emotive Epoc device,&#x0201d; in</article-title>
<source><italic>Proceedings of the 2012 International Conference on Brain Informatics, LNCS 7670</italic></source>, <publisher-loc>Macau</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>175</fpage>&#x02013;<lpage>184</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-642-35139-6_17</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renard</surname><given-names>Y.</given-names></name><name><surname>Lotte</surname><given-names>F.</given-names></name><name><surname>Gibert</surname><given-names>G.</given-names></name><name><surname>Congedo</surname><given-names>M.</given-names></name><name><surname>Maby</surname><given-names>E.</given-names></name><name><surname>Delannoy</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>An open-source software platform to design, test, and use brain-computer interfaces in real and virtual environments.</article-title>
<source><italic>Presence</italic></source>
<volume>19</volume>
<fpage>35</fpage>&#x02013;<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1162/pres.19.1.35</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>L. A.</given-names></name><name><surname>Trainor</surname><given-names>L. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Frontal brain electrical activity (EEG) distinguishes valence and intensity of musical emotions.</article-title>
<source><italic>Cogn. Emot.</italic></source>
<volume>15</volume>
<fpage>487</fpage>&#x02013;<lpage>500</lpage>. <pub-id pub-id-type="doi">10.1080/02699930126048</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sloboda</surname><given-names>J. A.</given-names></name></person-group> (<year>1992</year>). <article-title>&#x0201c;Empirical studies of emotional response to music,&#x0201d; in</article-title>
<source><italic>Cognitive Bases of Musical Communication</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Riess-Jones</surname><given-names>M.</given-names></name><name><surname>Holleran</surname><given-names>S.</given-names></name></person-group> (<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>), <fpage>33</fpage>&#x02013;<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1037/10104-003</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Standley</surname><given-names>J. M.</given-names></name></person-group> (<year>1986</year>). <article-title>Music research in medical/dental treatment: meta-analysis and clinical implications.</article-title>
<source><italic>J. Music Ther.</italic></source>
<volume>23</volume>
<fpage>56</fpage>&#x02013;<lpage>122</lpage>. <pub-id pub-id-type="doi">10.1093/jmt/23.2.56</pub-id><pub-id pub-id-type="pmid">10301218</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Standley</surname><given-names>J. M.</given-names></name><name><surname>Hanser</surname><given-names>S. B.</given-names></name></person-group> (<year>1995</year>). <article-title>Music therapy research and applications in pediatric oncology treatment.</article-title>
<source><italic>J. Pediatr. Oncol. Nurs.</italic></source>
<volume>12</volume>
<fpage>3</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1177/104345429501200103</pub-id>
<pub-id pub-id-type="pmid">7893459</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stecher</surname><given-names>M. B.</given-names></name><name><surname>McElheny</surname><given-names>H.</given-names></name><name><surname>Greenwood</surname><given-names>M.</given-names></name></person-group> (<year>1972</year>). <source><italic>Music and Movement Improvisations (Threshold Early Learning Library)</italic></source>, <volume>Vol. 4</volume>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Macmillan Publishing Co, Inc.</publisher-name></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>&#x0201c;Remarks on emotion recognition from bio-potential signals,&#x0201d; in</article-title>
<source><italic>2nd International Conference on Autonomous Robots and Agents</italic></source>, <publisher-loc>Palmerston North</publisher-loc>, <fpage>186</fpage>&#x02013;<lpage>191</lpage>.</mixed-citation></ref><ref id="B46"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thayer</surname><given-names>R. E.</given-names></name></person-group> (<year>1989</year>). <source><italic>The Biopsychology of Mood and Arousal.</italic></source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>, <fpage>1989</fpage>.</mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thie</surname><given-names>J.</given-names></name><name><surname>Klistorner</surname><given-names>A.</given-names></name><name><surname>Graham</surname><given-names>S. L.</given-names></name></person-group> (<year>2012</year>). <article-title>Biomedical signal acquisition with streaming wireless communication for recording evoked potentials.</article-title>
<source><italic>Doc. Ophthalmol.</italic></source>
<volume>125</volume>
<fpage>149</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1007/s10633-012-9345-y</pub-id>
<pub-id pub-id-type="pmid">22843193</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warth</surname><given-names>M.</given-names></name><name><surname>Koenig</surname><given-names>J.</given-names></name><name><surname>Ke&#x000df;ler</surname><given-names>J.</given-names></name><name><surname>Wormit</surname><given-names>A. F.</given-names></name><name><surname>Hillecke</surname><given-names>T. K.</given-names></name><name><surname>Bardenheuer</surname><given-names>H. J.</given-names></name></person-group> (<year>2014</year>). <article-title>Musiktherapie in der palliativmedizinischen versorgung: gegenw&#x000e4;rtiger stand und aktuelle entwicklungen.</article-title>
<source><italic>Musikther. Umsch.</italic></source>
<volume>35</volume>
<fpage>331</fpage>&#x02013;<lpage>343</lpage>. <pub-id pub-id-type="doi">10.13109/muum.2014.35.4.261</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wlodarczyk</surname><given-names>N.</given-names></name></person-group> (<year>2007</year>). <article-title>The effect of music therapy on the spirituality of persons in an in-patient hospice unit as measured by self-report.</article-title>
<source><italic>J. Music Ther.</italic></source>
<volume>44</volume>
<fpage>113</fpage>&#x02013;<lpage>122</lpage>. <pub-id pub-id-type="pmid">17488173</pub-id></mixed-citation></ref></ref-list></back></article>