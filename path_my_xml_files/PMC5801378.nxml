<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Prev Sci</journal-id><journal-id journal-id-type="iso-abbrev">Prev Sci</journal-id><journal-title-group><journal-title>Prevention Science</journal-title></journal-title-group><issn pub-type="ppub">1389-4986</issn><issn pub-type="epub">1573-6695</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28631234</article-id><article-id pub-id-type="pmc">5801378</article-id><article-id pub-id-type="publisher-id">802</article-id><article-id pub-id-type="doi">10.1007/s11121-017-0802-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Quality Matters: Implementation Moderates Student Outcomes in the PATHS Curriculum</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8148-9500</contrib-id><name><surname>Humphrey</surname><given-names>Neil</given-names></name><address><email>neil.humphrey@manchester.ac.uk</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Barlow</surname><given-names>Alexandra</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Lendrum</surname><given-names>Ann</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000000121662407</institution-id><institution-id institution-id-type="GRID">grid.5379.8</institution-id><institution>Manchester Institute of Education, </institution><institution>The University of Manchester, </institution></institution-wrap>Oxford Road, Manchester, M13 9PL UK </aff></contrib-group><pub-date pub-type="epub"><day>19</day><month>6</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>19</day><month>6</month><year>2017</year></pub-date><pub-date pub-type="ppub"><year>2018</year></pub-date><volume>19</volume><issue>2</issue><fpage>197</fpage><lpage>208</lpage><permissions><copyright-statement>&#x000a9; The Author(s) 2017</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Analyses of the relationship between levels of implementation and outcomes of school-based social and emotional learning (SEL) interventions are relatively infrequent and are typically narrowly focused. Thus, our objective was to assess the relationship between variability in a range of implementation dimensions and intervention outcomes in the Promoting Alternative Thinking Strategies (PATHS) curriculum. Implementation of PATHS was examined in 69 classrooms across 23 schools in the first year of a major randomized controlled trial. Implementation data were generated via classroom-level structured observations. In addition to factual data on dosage and reach, exploratory factor analysis of observer ratings revealed two distinct implementation dimensions, namely, &#x0201c;quality and participant responsiveness&#x0201d; and &#x0201c;procedural fidelity.&#x0201d; Student social-emotional skills, pro-social behavior, internalizing symptoms, and externalizing problems were captured through child self-report and teacher informant-report surveys (<italic>N</italic>&#x000a0;=&#x000a0;1721). Hierarchical linear modeling of study data revealed that higher implementation quality and participant responsiveness was associated with significantly lower ratings of students&#x02019; externalizing problems at 12-month follow-up. Conversely, and contrary to expectations, higher dosage was associated with significantly lower pro-social behavior and social-emotional skills at 12-month follow-up. No significant associations were found between variability in either procedural fidelity or reach and any intervention outcomes. The implications of these findings are discussed, and study limitations are noted.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Social and emotional learning</kwd><kwd>Intervention</kwd><kwd>Implementation</kwd><kwd>Paths</kwd><kwd>Outcomes</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001921</institution-id><institution>Public Health Research Programme</institution></institution-wrap></funding-source><award-id>10/3006/01</award-id><principal-award-recipient><name><surname>Humphrey</surname><given-names>Neil</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Society for Prevention Research 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Universal, school-based social and emotional learning (SEL) interventions foster the social-emotional skills (e.g., self-management, social awareness, relationship skills) of children and young people through explicit instruction in the context of learning environments that are safe, caring, well-managed, and participatory (Weissberg et al. <xref ref-type="bibr" rid="CR54">2015</xref>). Three recent meta-analyses have rigorously demonstrated that SEL interventions can lead to meaningful improvements in a range of student outcomes, including their social-emotional skills, mental health, and academic attainment (Durlak et al. <xref ref-type="bibr" rid="CR19">2011</xref>; Sklad et al. <xref ref-type="bibr" rid="CR50">2012</xref>; Wigelsworth et al. <xref ref-type="bibr" rid="CR55">2016</xref>). However, the implementation of SEL interventions is variable, and this variability is hypothesized to be a key moderator of intervention outcomes (Durlak <xref ref-type="bibr" rid="CR17">2016</xref>). Our primary objective in this study, therefore, was to assess the relationship between levels of implementation and intervention outcomes in the Promoting Alternative Thinking Strategies (PATHS) curriculum. In doing so, we also sought to offer a distinct contribution to knowledge vis-&#x000e0;-vis the distinction between fidelity and quality in implementation and prevention science.</p></sec><sec id="Sec2"><title>Implementation of School-Based Interventions</title><p id="Par3">The implementation of school-based interventions is typically conceptualized in terms of constructs such as <italic>fidelity</italic> (what is delivered and how closely does this adhere to intervention guidance materials?), <italic>dosage</italic> (how much of the intervention is delivered?), <italic>quality</italic> (how well is the intervention delivered?), <italic>reach</italic> (was the intervention delivered to all intended recipients?), and <italic>participant responsiveness</italic> (did recipients engage with the intervention?) (Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>). A current source of contention is whether fidelity and quality are distinct. To some, fidelity is a superordinate construct, used to describe the overall pattern of activity, with other implementation dimensions viewed as subordinate indicators (Carroll et al. <xref ref-type="bibr" rid="CR7">2007</xref>). This carries an implicit assumption that for intervention outcomes to be replicated, the exact delivery regime under which an intervention was validated must also be replicated. This is the &#x0201c;zero-sum-game&#x0201d; view of implementation: higher fidelity results in better outcomes, and any deviation from the intended intervention model must therefore be detrimental (e.g., Elliott and Mihalic <xref ref-type="bibr" rid="CR20">2004</xref>). Fidelity thus becomes synonymous with quality, to the extent that the terms are used interchangeably (Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>).</p><p id="Par4">To others, <italic>implementation</italic> is the superordinate construct, with fidelity included as a subordinate indicator alongside the aforementioned other dimensions (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>; Durlak and DuPre <xref ref-type="bibr" rid="CR18">2008</xref>) and typically understood and operationalized in procedural terms (e.g., how closely the structure and sequence of activities outlined in the intervention guidance are followed). Implementation quality is viewed as distinct from fidelity, referring to how effectively the intervention has been delivered for the achievement of intended outcomes (O&#x02019;Donnell <xref ref-type="bibr" rid="CR44">2008</xref>; Odom et al. <xref ref-type="bibr" rid="CR45">2010</xref>), including facets such as implementer competence and skills, enthusiasm and engagement, and preparedness for implementation (Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>). This view is adopted in the current study and is reflected in our approach to assessment (see &#x0201c;<xref rid="Sec5" ref-type="sec">Method</xref>&#x0201d; section). We see it as more consistent with emergent theorization of implementation that acknowledges the important distinction between <italic>what</italic> is implemented and <italic>how well</italic> (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>).</p><p id="Par5">Whatever model one subscribes to, there is broad agreement that measurement of implementation is still in its relative infancy: &#x0201c;Even if the concept of implementation is not new, the idea of developing ways of measuring it certainly is&#x0201d; (Ogden and Fixsen <xref ref-type="bibr" rid="CR46">2014</xref>, p.8). Thus, the field has yet to emerge at a clear consensus regarding the optimal frequency and timing of measurement within a period of implementation (Durlak <xref ref-type="bibr" rid="CR16">2015</xref>; Humphrey <xref ref-type="bibr" rid="CR36">2016b</xref>). However, one area where there is general agreement is modality, with independent structured observations considered to be greatly preferable to teacher self-report methods, the latter being subject to substantial positive bias (Hansen et al. <xref ref-type="bibr" rid="CR31">2014</xref>).</p><p id="Par6">Although it is generally accepted that &#x0201c;implementation matters&#x0201d; (Durlak and DuPre <xref ref-type="bibr" rid="CR18">2008</xref>), the evidence base pertaining to SEL and school-based interventions more generally is currently limited in a number of respects. First, despite a significant rise in the proportion of studies reporting on implementation in the last two decades (currently up to 69% of SEL studies, Wigelsworth et al. <xref ref-type="bibr" rid="CR55">2016</xref>; but still less than half of school-based intervention studies more generally, Bruhn et al. <xref ref-type="bibr" rid="CR5">2015</xref>), most offer only descriptive data, which are used to provide evidence that a given intervention was actually delivered and thus strengthen the internal validity of trial outcome analyses. By contrast, analyses in which researchers model levels of implementation dimensions as moderators of intervention effects are relatively infrequent, despite their obvious significance in terms of both internal and external validity in program evaluation. For example, a recent systematic review found that only 10% of intervention studies reported implementation-outcome relationships (Schoenwald and Garland <xref ref-type="bibr" rid="CR48">2014</xref>).</p><p id="Par7">Second, research published to date has been characterized by a narrow focus on particular aspects of implementation at the expense of others. Thus, while 63% of studies included in Durlak and DuPre&#x02019;s (<xref ref-type="bibr" rid="CR18">2008</xref>) seminal review assessed fidelity, only 10% assessed quality. This narrow approach reflects the zero-sum-game model noted earlier and greatly increases the risk of a Type III error (the inaccurate attribution of cause) (Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>). Less frequently studied implementation dimensions such as quality may be equally or even more important than fidelity and dosage in driving intervention outcomes (Durlak <xref ref-type="bibr" rid="CR16">2015</xref>). A teachers&#x02019; preparedness, ability to actively engage and enthuse students, and clarity of delivery is crucial for effective learning; without this, the internalization of lesson content and subsequent skill development that underpins intervention outcomes is unlikely to occur (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>; Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>).</p><p id="Par8">Third, the conceptualization and assessment of different aspects of implementation currently lags behind other aspects of intervention research. As noted above, terms such as fidelity and quality have been used interchangeably in some studies (e.g., Social and Character Development Research Consortium <xref ref-type="bibr" rid="CR53">2010</xref>). Furthermore, the means by which they are measured generally lacks the level of rigor afforded to the assessment of intervention outcomes (Ogden and Fixsen <xref ref-type="bibr" rid="CR46">2014</xref>). A recent systematic review found that only around one third of papers provided <italic>any</italic> data on the psychometric properties of instruments used to generate implementation data (Schoenwald and Garland <xref ref-type="bibr" rid="CR48">2014</xref>). Studies reporting factor analytic work to establish the distinctiveness of implementation dimensions as the foundation for implementation-outcomes analyses are extremely rare (Cross et al. <xref ref-type="bibr" rid="CR10">2015</xref>; Pettigrew et al. <xref ref-type="bibr" rid="CR47">2015</xref>). To a certain degree, this is understandable, given that each intervention typically generates its own implementation measures (which may be used infrequently), and also that interventions often evolve over time (meaning that implementation measures would also need to be revised frequently). One possible solution is the development and application of standardized implementation measures, though existing attempts have met with mixed success to date (Humphrey et al. <xref ref-type="bibr" rid="CR36">2016b</xref>).</p></sec><sec id="Sec3"><title>The PATHS Curriculum</title><p id="Par9">PATHS is a universal SEL intervention that aims to help all children to manage their behavior, understand their emotions, and work well with others. It is designed to be delivered by class teachers and includes a series of lessons on topics such as identifying and labeling feelings, generalization activities and techniques that support the application of new skills during the school day, and parent materials that aim to extend learning to the home environment. Further information about PATHS can be found at <ext-link ext-link-type="uri" xlink:href="http://www.pathseducation.co.uk/">www.pathseducation.co.uk/</ext-link>. The PATHS materials used in the current study were subjected to a process of cultural adaptation by Barnardo&#x02019;s (the children&#x02019;s charity who own the UK license to distribute PATHS) in order to &#x02018;Anglicize&#x02019; them. These primarily surface level changes (e.g., modified vocabulary, photographs and names, changes to cultural references) did not substantively change the structure or delivery model of PATHS.</p><p id="Par10">Several randomized trials have found small-to-moderate but practically meaningful effects of PATHS on a range of outcomes, including children&#x02019;s social and emotional skills (Domitrovich et al. <xref ref-type="bibr" rid="CR13">2007</xref>), their mental health (Crean and Johnson <xref ref-type="bibr" rid="CR9">2013</xref>), and academic attainment (Schonfeld et al. <xref ref-type="bibr" rid="CR49">2015</xref>). However, reflecting the trends noted above, some existing studies of PATHS only provide descriptive implementation data (e.g., Domitrovich et al. <xref ref-type="bibr" rid="CR13">2007</xref>). Those PATHS studies where implementation-outcomes analyses have been conducted have, in many ways, led the SEL field in terms of our understanding of implementation. However, findings across such studies have been somewhat inconsistent. Some have found little or no connection between levels of PATHS implementation and outcomes (e.g., Berry et al. <xref ref-type="bibr" rid="CR3">2016</xref>; Social and Character Development Research Consortium <xref ref-type="bibr" rid="CR53">2010</xref>), while others have found significant associations (e.g., Faria et al. <xref ref-type="bibr" rid="CR22">2013</xref>; Schonfeld et al. <xref ref-type="bibr" rid="CR49">2015</xref>). These studies all maintained a relatively narrow focus, measuring only one or two implementation dimensions, and none assessed reach or participant responsiveness. Finally, with a few exceptions (Conduct Problems Prevention Research Group <xref ref-type="bibr" rid="CR8">1999</xref>; Kam et al. <xref ref-type="bibr" rid="CR37">2003</xref>; Social and Character Development Research Consortium <xref ref-type="bibr" rid="CR53">2010</xref>), existing studies of PATHS implementation have relied exclusively on teachers&#x02019; self-reports to generate implementation data. While convenient, this method is, as noted above, limited by the substantial positive bias shown by teachers in their self-ratings and its generally weak relation with more rigorous independent observer ratings (Hansen et al. <xref ref-type="bibr" rid="CR31">2014</xref>).</p></sec><sec id="Sec4"><title>The Current Study</title><p id="Par11">In 2012, the authors were commissioned to conduct a 2-year cluster-randomized trial of the PATHS curriculum in primary schools in Greater Manchester, England (ISRCTN85087674). Having already published reports on the outcomes of this trial (which were somewhat varied, with evidence of intervention effects on social-emotional skills, mixed findings in relation to mental health, and null results in relation to academic progress&#x02014;see Humphrey et al. <xref ref-type="bibr" rid="CR34">2015</xref>, <xref ref-type="bibr" rid="CR35">2016a</xref>), we turn our attention here to assessing the role of variability in PATHS implementation as a moderator of students&#x02019; social and emotional skills and mental health outcomes in the first year of the study. In doing so, we sought to advance the current literature in terms of adopting a more wide-ranging approach to the assessment of implementation, increased objectivity and rigor afforded by the use of independent observational data, and the application of a theoretical framework for implementation that posits quality and fidelity as distinct dimensions, enabling us to concurrently assess the relative importance of <italic>what</italic> is delivered and <italic>how well</italic> in determining intervention outcomes (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>). These contributions are a direct response to calls for research of this kind in implementation science (e.g., Durlak <xref ref-type="bibr" rid="CR15">2010</xref>; Hansen <xref ref-type="bibr" rid="CR29">2014</xref>).</p></sec><sec id="Sec5"><title>Method</title><sec id="Sec6"><title>Design</title><p id="Par12">A longitudinal, natural variation design was utilized. A multi-method approach was taken, with structured observations and surveys as the primary vehicles for data generation in relation to implementation and intervention outcomes respectively. Outcomes were assessed at baseline (summer term 2012) and 12-month follow-up (summer term 2013), with structured observations of implementation taking place in between (specifically, autumn term 2012 and winter term 2013). See Fig. <xref rid="Fig1" ref-type="fig">1</xref> for flow of participants in the study.<fig id="Fig1"><label>Fig. 1</label><caption><p>Flow of participants in the study</p></caption><graphic xlink:href="11121_2017_802_Fig1_HTML" id="MO1"/></fig>
</p></sec><sec id="Sec7"><title>Participants</title><sec id="FPar1"><title>Schools and Teachers</title><p id="Par13">Data were drawn from 23 primary schools implementing PATHS across the Greater Manchester region in the northwest of England. Participating schools were representative of norms in England in respect of size, attendance, attainment, ethnicity, and the proportion of children identified as having special educational needs but had moderately higher proportions of children eligible for free school meals (FSM) and speaking English as an additional language (EAL) than national averages (Department for Education <xref ref-type="bibr" rid="CR11">2012</xref>).</p><p id="Par14">Implementation data from 69 Year 3 and 4 teachers/classrooms in the first year of the aforementioned trial were collected. Classes contained an average of 25 students. Teachers of these students averaged 8&#x000a0;years of experience in the classroom, were predominantly female (82.5%), educated to postgraduate level (61.5%), and reported having 2&#x02013;5&#x000a0;years of experience implementing other SEL programs prior to becoming involved in the current study (40.7%).</p></sec><sec id="FPar2"><title>Students</title><p id="Par15">Outcome data were generated for <italic>N</italic>&#x000a0;=&#x000a0;1721 (839 male, 882 female) students, whose average age was 7&#x000a0;years, 7&#x000a0;months (range 6&#x000a0;years, 7&#x000a0;months to 8&#x000a0;years, 10&#x000a0;months) at baseline. Their demographic characteristics were consistent with national norms, albeit with the same exceptions noted above regarding the school characteristics (Department for Education <xref ref-type="bibr" rid="CR11">2012</xref>). The proportion of children scoring in the borderline/abnormal ranges for mental health difficulties broadly mirrored national norms for children aged 5&#x02013;10 (<ext-link ext-link-type="uri" xlink:href="http://www.sdqinfo.com">www.sdqinfo.com</ext-link>).</p></sec><sec id="FPar3"><title>Ethics</title><p id="Par16">Participation in the study required consent from schools&#x02019; head teachers. Child assent and parental opt-out consent were also sought. Ethical approval from the University of Manchester Research Ethics Committee was sought and received (Ref 11470). In total, 88 parents (5.1% of the sample utilized in the current study) exercised their right to opt their children out of the research, and no children declined assent or exercised their right to withdraw.</p></sec></sec></sec><sec id="Sec8"><title>Measures</title><sec id="FPar4"><title>Implementation</title><p id="Par17">PATHS lessons were observed by three research assistants, who were each qualified and experienced teachers trained to Masters level in psychology or education. A structured observation schedule was developed by the authors for the study, drawing on the aforementioned theoretical framework for implementation (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>), existing rubrics utilized in previous studies of PATHS (e.g., Kam et al. <xref ref-type="bibr" rid="CR37">2003</xref>), advice from the program developer and colleagues at Pennsylvania State University, and the extant literature on assessment of implementation (e.g., Domitrovich et al. <xref ref-type="bibr" rid="CR14">2010</xref>). Two factual indicators&#x02014;one each for dosage and reach&#x02014;were generated and supplemented by ten observer-rated indicators designed to assess fidelity, quality, and participant responsiveness (see Table <xref rid="Tab1" ref-type="table">1</xref>). The data generated was demonstrative of a general trend in which PATHS was delivered between once and twice a week, with most children in a given class present, teachers adhering to most procedural elements outlined in lesson materials, delivering them well, and with children responding appropriately.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Descriptive statistics and exploratory factor analysis of PATHS implementation indicators</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th/><th/><th/><th colspan="2">Factor</th></tr><tr><th/><th>Scoring</th><th>Mean (SD)</th><th>Initial designation</th><th>Quality and responsiveness</th><th>Procedural fidelity</th></tr></thead><tbody><tr><td>Projected dosage (% lessons complete by end of the school year) based on progress against the implementation schedule?</td><td>0&#x02013;100</td><td>65.18 (17.43)</td><td>Dosage</td><td>&#x02013;</td><td>&#x02013;</td></tr><tr><td>Proportion of the class present during the lesson?</td><td>0&#x02013;100</td><td>91.86 (1.10)</td><td>Reach</td><td>&#x02013;</td><td>&#x02013;</td></tr><tr><td>To what extent does the teacher cover the general and specific objectives of the lesson?</td><td>0&#x02013;10</td><td>8.74 (1.46)</td><td>Fidelity</td><td>0.57</td><td>0.48</td></tr><tr><td>To what extent does the teacher follow the structure and sequence of activities outlined in the lesson guidance?</td><td>0&#x02013;10</td><td>8.04 (2.33)</td><td>Fidelity</td><td>0.09</td><td>0.96</td></tr><tr><td>How closely does the teacher adhere to the guidance when teaching the core activities of the lesson?</td><td>0&#x02013;10</td><td>7.37 (2.22)</td><td>Fidelity</td><td>0.08</td><td>0.87</td></tr><tr><td>How well prepared is the teacher for the lesson?</td><td>0&#x02013;10</td><td>8.68 (1.29)</td><td>Quality</td><td>0.74</td><td>0.30</td></tr><tr><td>Rate the teacher&#x02019;s interest and enthusiasm in his/her delivery of the lesson.</td><td>0&#x02013;10</td><td>8.99 (1.11)</td><td>Quality</td><td>0.72</td><td>0.18</td></tr><tr><td>How clearly does the teacher explain key concepts and activities in the lesson?</td><td>0&#x02013;10</td><td>8.41 (1.28)</td><td>Quality</td><td>0.81</td><td>0.21</td></tr><tr><td>How well does the teacher respond to pupil queries/ meet the needs of all of the class if it is required?</td><td>0&#x02013;10</td><td>8.47 (1.35)</td><td>Quality</td><td>0.82</td><td>0.04</td></tr><tr><td>Rate the extent to which children in the class actively participate in the lesson activities.</td><td>0&#x02013;10</td><td>7.46 (1.45)</td><td>Responsiveness</td><td>0.77</td><td>&#x02212;0.01</td></tr><tr><td>Rate the level of sustained interest and attentiveness among children in the class during the lesson.</td><td>0&#x02013;10</td><td>6.82 (1.85)</td><td>Responsiveness</td><td>0.84</td><td>&#x02212;0.01</td></tr><tr><td>Rate the extent to which the learning objectives have been met.</td><td>0&#x02013;10</td><td>7.56 (1.51)</td><td>Responsiveness</td><td>0.87</td><td>0.21</td></tr></tbody></table></table-wrap>
</p><p id="Par18">The schedule and an accompanying explanatory rubric<xref ref-type="fn" rid="Fn1">1</xref> were explained in detail to the research assistants ahead of piloting and refinement using video footage of PATHS lessons being implemented in English schools in a previous trial (Berry et al. <xref ref-type="bibr" rid="CR3">2016</xref>). In this initial formative stage, which lasted several days, the emphasis was on developing a shared understanding of the various implementation indicators and their application in the context of a PATHS lesson. Additional video footage of PATHS lessons was then used in order to generate interrater reliability data for each indicator. Given the multiple raters and the ordinal response format of the coding schedule, the intraclass correlation coefficient (ICC) was used. ICC values can range between &#x02212;1 and 1, with higher scores being indicative of limited variation between raters. The overall ICC was determined to be 0.91, considered to be &#x0201c;excellent&#x0201d; (Hallgren <xref ref-type="bibr" rid="CR28">2012</xref>).</p><p id="Par20">During the live trial observations, each teacher was observed implementing a single PATHS lesson at a mutually agreeable date and time. The third author moderated a randomly selected 10% of these observations in order to guard against drift over time. In order to streamline analyses and thus reduce the likelihood of &#x0201c;model overfitting&#x0201d; (Myung <xref ref-type="bibr" rid="CR42">2000</xref>), avoid collinearity, and establish clear differentiation between implementation constructs, the observer-rated implementation data were subjected to exploratory factor analysis (EFA) in SPSS using the Principal Axis Factoring extraction method (common factor analysis) with Varimax rotation (oblique rotation method).<xref ref-type="fn" rid="Fn2">2</xref> The EFA identified two distinct factors, accounting for 69.4% of the explained common variance in the data, corresponding to <italic>procedural fidelity</italic> (&#x003b1;&#x000a0;=&#x000a0;0.93) and <italic>quality and responsiveness</italic> (&#x003b1;&#x000a0;=&#x000a0;0.93), respectively (see Table <xref rid="Tab1" ref-type="table">1</xref>). Bivariate correlation analyses demonstrated that the two identified factors were clearly distinct from one another (<italic>r</italic>&#x000a0;=&#x000a0;.02, <italic>p</italic>&#x000a0;=&#x000a0;.85) and from the dosage and reach indicators (quality-dosage, <italic>r</italic>&#x000a0;=&#x000a0;&#x02212;.02, <italic>p</italic>&#x000a0;=&#x000a0;.79; fidelity-dosage, <italic>r</italic>&#x000a0;=&#x000a0;&#x02212;.04, <italic>p</italic>&#x000a0;=&#x000a0;0.64; quality-reach, <italic>r</italic>&#x000a0;=&#x000a0;.08, <italic>p</italic>&#x000a0;=&#x000a0;.38; fidelity-reach, <italic>r</italic>&#x000a0;=&#x000a0;.16, <italic>p</italic>&#x000a0;=&#x000a0;.07), which in turn shared a weak, albeit statistically significant association with each other (<italic>r</italic>&#x000a0;=&#x000a0;.20, <italic>p</italic>&#x000a0;=&#x000a0;.02).</p><p id="Par22">To preserve the loading values of each item on a given factor, factor scores were generated using the least squares regression approach (DiStefano et al. <xref ref-type="bibr" rid="CR12">2009</xref>). These factor scores, which are standardized to a mean of zero, were subsequently used as explanatory variables for procedural fidelity and quality and responsiveness in the main analysis. To facilitate interpretation within and across models, dosage and reach data were also standardized (e.g., converted to z-scores) (Low et al. <xref ref-type="bibr" rid="CR40">2016</xref>).</p></sec><sec id="FPar5"><title>Child Self-Report Version of the SSIS</title><p id="Par23">The 46-item Social Skills Improvement System (SSIS) provides a broadband index of children&#x02019;s social-emotional skills (Gresham &#x00026; Elliot, <xref ref-type="bibr" rid="CR27">2008</xref>). The respondent reads a statement (e.g., &#x0201c;I make friends easily&#x0201d;) and indicates their level of agreement on a four-point scale (never, sometimes, often, always). The instrument is psychometrically sound, with good reliability (internal &#x003b1; up to 0.95; test-retest <italic>r</italic> up to 0.92) and strong validity (factorial: established through confirmatory factor analysis, CFA; convergent: correlates with a range of similar instruments; discriminative: discriminates between clinical and non-clinical samples) (Humphrey et al. <xref ref-type="bibr" rid="CR33">2011</xref>). Internal consistency of the SSIS total social skills scale used in the current study was &#x003b1;&#x000a0;=&#x000a0;0.92.</p><p id="Par24">Teacher informant-report version of the Social and Emotional Competence Change Index (SECCI). The five-item SECCI was derived from the PATHS program evaluation tools (EPISCenter <xref ref-type="bibr" rid="CR21">2014</xref>). Respondents indicate the degree of change they have observed in a child (e.g., &#x0201c;The student&#x02019;s ability to stop and calm down e.g., when angry, excited or upset&#x0201d;) over a specified period of time using a five-point scale (much worse, a little worse, no change, a little improved, much improved). Internal consistency of this instrument in the current study was &#x003b1;&#x000a0;=&#x000a0;0.92.</p></sec><sec id="FPar6"><title>Teacher Informant-Report Version of the SDQ</title><p id="Par25">The 25-item Strengths and Difficulties Questionnaire (SDQ) provides a measure of children&#x02019;s internalizing symptoms, externalizing problems, and pro-social behavior.<xref ref-type="fn" rid="Fn3">3</xref> Respondents read a statement (e.g., &#x0201c;[This child] often lies or cheats&#x0201d;) and indicate their level of agreement on a three-point scale (not true, somewhat true, certainly true). The SDQ has robust psychometric properties, with evidence of both reliability (internal &#x003b1; up to 0.87; test-retest <italic>r</italic> up to 0.8) and validity (factorial: established through CFA; convergent: correlates with a range of similar instruments; predictive: strongly predictive of independently diagnosed psychiatric disorders) (Goodman et al. <xref ref-type="bibr" rid="CR24">2010</xref>; Goodman <xref ref-type="bibr" rid="CR23">2001</xref>). Internal consistency in the current study was &#x003b1;&#x000a0;=&#x000a0;0.87 for internalizing symptoms, &#x003b1;&#x000a0;=&#x000a0;0.90 for externalizing problems, and &#x003b1;&#x000a0;=&#x000a0;0.86 for pro-social behavior.</p></sec></sec><sec id="Sec9"><title>Statistical Analysis</title><p id="Par27">Outcome data were standardized (e.g., converted to z-scores) prior to analysis. In addition to mean-centring the data, this procedure also facilitates interpretation and produces standardized regression coefficients that are comparable to an effect size that accounts for other variables in the model, thereby increasing precision and rigor (Bierman et al. <xref ref-type="bibr" rid="CR4">2014</xref>). In view of the hierarchical and clustered nature of the dataset, we used hierarchical linear modeling in MLWin 2.32. Each model was fitted with two levels (classroom, child), with score at follow-up as the response variable. At the class level, procedural fidelity, quality and responsiveness, dosage, and reach were entered as explanatory variables. Given that there are no universally agreed thresholds of implementation ratings for PATHS (or indeed any school-based intervention; any that have been imposed in studies to date are arguably arbitrary; Berry et al. <xref ref-type="bibr" rid="CR3">2016</xref>), we used the observational data to classify each class/teacher as either &#x0201c;low,&#x0201d; &#x0201c;moderate,&#x0201d; or &#x0201c;high&#x0201d; for each aspect of implementation using a distributional cut-point method (low, &#x0003c;&#x02212;1 SD; moderate, &#x02212;1 to +1 SD; and high, &#x0003e;+1 SD; in subsequent dummy coding, low implementation was the designated reference group). Importantly, these designations were statistical rather than qualitative (that is, they are based on relative position in the distribution as opposed to being based on arbitrarily imposed thresholds of what &#x0201c;good&#x0201d; implementation might look like; Durlak and DuPre <xref ref-type="bibr" rid="CR18">2008</xref>). An exception to this was <italic>reach</italic>: this was coded as high (100%), moderate (90&#x02013;99%), or low (89% or less) according to the proportion of students present during the PATHS lesson being observed. Descriptive statistics pertaining to these implementation subgroups are available in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Descriptive statistics (<italic>n</italic>, means, and SDs) for implementation subgroups</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Low</th><th>Moderate</th><th>High</th></tr></thead><tbody><tr><td>Dosage</td><td>11/40.0% (6.76)</td><td>48/66.46% (9.92)</td><td>7/96.26 (12.88)</td></tr><tr><td>Reach</td><td>11/72.72% (1.49)</td><td>26/90.39% (0.14)</td><td>29/100.0% (0.0)</td></tr><tr><td>Quality and responsiveness</td><td>11/6.29 (0.46)</td><td>44/8.21 (0.77)</td><td>11/9.57 (0.18)</td></tr><tr><td>Procedural fidelity</td><td>6/2.00 (2.07)</td><td>53/8.02 (1.03)</td><td>7/10.0 (0.0)</td></tr></tbody></table></table-wrap>
</p><p id="Par28">Given their established associations with social-emotional skills and mental health outcomes (e.g., Green et al. <xref ref-type="bibr" rid="CR26">2005</xref>), gender and FSM eligibility were entered as covariates alongside baseline outcome scores at the child level. Guidance on power and sample size for hierarchical linear modeling suggested that the level-two (classroom) sample should be the principal focus given that the primary aim of our analysis was to test the effects of variables at this level (Snijders <xref ref-type="bibr" rid="CR51">2005</xref>); here, the level-two sample was deemed sufficiently large to support the explanatory variables noted above (Green <xref ref-type="bibr" rid="CR25">1991</xref>; Snijders and Bosker <xref ref-type="bibr" rid="CR52">2012</xref>).</p><p id="Par29">Implementation data was missing at the classroom level in 6% of cases, where teachers left the school during the observation window. At the child level, outcome data was missing at either baseline or follow-up for between 13% (SECCI) and 30% (SSIS) of the sample due to student absence or them having left a given school. Missing value analysis showed the data was not missing completely at random (MCAR) but was instead conditional on other variables (e.g., pupil outcome data was more likely to be missing at follow-up). Therefore, the data was considered missing at random (MAR) (Heijtan and Basu <xref ref-type="bibr" rid="CR32">1996</xref>). Accordingly, multiple imputation procedures were carried out in REALCOM-Impute, using the MAR assumption (Carpenter et al. <xref ref-type="bibr" rid="CR6">2011</xref>). This enabled us to include both partially and completely observed cases of all 69 teachers/classes and 1721 students in the analysis, thereby reducing the bias associated with attrition. Gender and the constant were entered as auxiliary variables. REALCOM-Impute default settings of 1000 iterations and a burn-in of 100, refresh of 10, were used, following guidance for multi-level imputation with mixed response types (Carpenter et al. <xref ref-type="bibr" rid="CR6">2011</xref>).</p></sec><sec id="Sec10"><title>Results</title><p id="Par30">Descriptive statistics are presented in Tables <xref rid="Tab1" ref-type="table">1</xref> (overall implementation data and factor loadings), <xref rid="Tab2" ref-type="table">2</xref> (implementation data by subgroup), and <xref rid="Tab3" ref-type="table">3</xref> (outcome data). Inferential statistics are presented in Table <xref rid="Tab4" ref-type="table">4</xref>. In the interests of brevity, only the multiply imputed analyses are shown. Complete case analyses were also performed, but there were no substantive differences in findings. In all cases, inclusion of the explanatory implementation variables significantly improved model fit when compared to &#x0201c;unconditional&#x0201d; models (chi-squared tests of the change in &#x02212;2*Log-likelihood values were all significant at <italic>p</italic>&#x000a0;&#x0003c;&#x000a0;.001). The ICC for the models presented in Table <xref rid="Tab3" ref-type="table">3</xref> ranged from 0.02 (SSIS) to 0.35 (SECCI).<table-wrap id="Tab3"><label>Table 3</label><caption><p>Descriptive statistics (means and SDs) for teacher (SECCI) and child ratings of social and emotional skills (SSIS) and teacher ratings of pro-social behavior, internalizing symptoms, and externalizing problems (SDQ)</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th/><th/><th>Scoring</th><th>Baseline</th><th>Follow-up</th></tr></thead><tbody><tr><td colspan="3">SECCI</td><td>&#x02212;2 to +2</td><td>&#x02013;</td><td>0.68 (0.63)</td></tr><tr><td colspan="3">SDQ</td><td/><td/><td/></tr><tr><td/><td colspan="2">Internalizing symptoms</td><td>0&#x02013;20</td><td>2.57 (3.06)</td><td>2.51 (2.97)</td></tr><tr><td/><td colspan="2">Externalizing problems</td><td>0&#x02013;20</td><td>4.09 (4.42)</td><td>3.72 (4.03)</td></tr><tr><td/><td colspan="2">Pro-social behavior</td><td>0&#x02013;10</td><td>7.80 (2.43)</td><td>7.69 (2.34)</td></tr><tr><td colspan="3">SSIS</td><td>0&#x02013;138</td><td>106.58 (19.59)</td><td>104.33 (19.75)</td></tr></tbody></table><table-wrap-foot><p>
<italic>SECCI</italic> Social and Emotional Competence Change Index, <italic>SDQ</italic> Strengths and Difficulties Questionnaire, <italic>SSIS</italic> Social Skills Improvement System</p></table-wrap-foot></table-wrap>
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Hierarchical linear models of the associations between levels of implementation and intervention outcomes in the PATHS curriculum</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th colspan="3">SECCI</th><th colspan="3">SDQ internalizing</th><th colspan="3">SDQ externalizing</th><th colspan="3">SDQ pro-social</th><th colspan="3">SSIS total</th></tr><tr><th/><th>
<italic>&#x003b2;</italic>
<sub>0</sub>
<sub><italic>ij</italic></sub> = 0.18 (0.37)</th><th/><th/><th>
<italic>&#x003b2;</italic>
<sub>0</sub>
<sub><italic>ij</italic></sub> = 0.20 (0.30)</th><th/><th/><th>
<italic>&#x003b2;</italic>
<sub>0</sub>
<sub><italic>ij</italic></sub> = 0.09 (0.19)</th><th/><th/><th>
<italic>&#x003b2;</italic>
<sub>0</sub>
<sub><italic>ij</italic></sub> = 0.12 (0.29)</th><th/><th/><th>
<italic>&#x003b2;</italic>
<sub>0</sub>
<sub><italic>ij</italic></sub> = 0.18 (0.17)</th><th/><th/></tr><tr><th/><th>Co-efficient &#x003b2;</th><th>SE</th><th>
<italic>p</italic>
</th><th>Co-efficient &#x003b2;</th><th>SE</th><th>
<italic>p</italic>
</th><th>Co-efficient &#x003b2;</th><th>SE</th><th>
<italic>p</italic>
</th><th>Co-efficient &#x003b2;</th><th>SE</th><th>
<italic>p</italic>
</th><th>Co-efficient &#x003b2;</th><th>SE</th><th>
<italic>p</italic>
</th></tr></thead><tbody><tr><td>Class</td><td>0.35</td><td>0.07</td><td>&#x0003c;.01</td><td>0.20</td><td>0.04</td><td>&#x0003c;.01</td><td>0.07</td><td>0.02</td><td>&#x0003c;.01</td><td>0.18</td><td>0.04</td><td>&#x0003c;.01</td><td>0.02</td><td>0.01</td><td>.02</td></tr><tr><td>&#x02003;Dosage (compared to low)</td><td>&#x02212;0.06 (if mod)<break/>&#x02212;0.32 (if high)</td><td>0.27<break/>0.35</td><td>.41<break/>.18</td><td>&#x02212;0.01 (if mod)<break/>0.10 (if high)</td><td>0.19<break/>0.26</td><td>.48<break/>.35</td><td>&#x02212;0.05 (if mod)<break/>0.02 (if high)</td><td>0.13<break/>0.17</td><td>.35<break/>.45</td><td>0.02 (if mod)<break/>&#x02212;0.52 (if high)</td><td>0.18<break/>0.26</td><td>.46<break/>.02</td><td>&#x02212;0.25 (if mod)<break/>&#x02212;0.28 (if high)</td><td>0.11<break/>0.14</td><td>.01<break/>.03</td></tr><tr><td>&#x02003;Reach (compared to low)</td><td>0.11 (if mod)<break/>0.04 (if high)</td><td>0.25<break/>0.26</td><td>.33<break/>.44</td><td>&#x02212;0.14 (if mod)<break/>&#x02212;0.22 (if high)</td><td>0.20<break/>0.19</td><td>.24<break/>.13</td><td>0.08 (if mod)<break/>0.12 (if high)</td><td>0.13<break/>0.13</td><td>.27<break/>.18</td><td>&#x02212;0.20 (if mod)<break/>&#x02212;0.23 (if high)</td><td>0.18<break/>0.18</td><td>.14<break/>.10</td><td>&#x02212;0.02 (if mod)<break/>0.02 (if high)</td><td>0.10<break/>0.10</td><td>.42<break/>.42</td></tr><tr><td>&#x02003;Quality and responsiveness (compared to low)</td><td>&#x02212;0.05 (if mod)<break/>0.22 (if high)</td><td>0.24<break/>0.32</td><td>.42<break/>.25</td><td>&#x02212;0.09 (if mod)<break/>&#x02212;0.14 (if high)</td><td>0.18<break/>0.23</td><td>.31<break/>.27</td><td>&#x02212;0.14 (if mod)<break/>&#x02212;0.26 (if high)</td><td>0.12<break/>0.15</td><td>.11<break/>.04</td><td>0.09 (if mod)<break/>0.14 (if high)</td><td>0.17<break/>0.23</td><td>.30<break/>.27</td><td>0.06 (if mod)<break/>&#x02212;0.13 (if high)</td><td>0.10<break/>0.12</td><td>.28<break/>.14</td></tr><tr><td>&#x02003;Procedural fidelity (compared to low)</td><td>0.25 (if mod)<break/>0.14 (if high)</td><td>0.31<break/>0.37</td><td>.21<break/>.35</td><td>&#x02212;0.04 (if mod)<break/>0.34 (if high)</td><td>0.23<break/>0.28</td><td>.43<break/>.12</td><td>0.07 (if mod)<break/>0.18 (if high)</td><td>0.14<break/>0.19</td><td>.31<break/>.17</td><td>&#x02212;0.13 (if mod)<break/>&#x02212;0.19 (if high)</td><td>0.22<break/>0.27</td><td>.28<break/>.24</td><td>&#x02212;0.11 (if mod)<break/>0.11 (if high)</td><td>0.12<break/>0.15</td><td>.18<break/>.23</td></tr><tr><td>Pupil</td><td>0.61</td><td>0.02</td><td>&#x0003c;.01</td><td>0.65</td><td>0.02</td><td>&#x0003c;.01</td><td>0.42</td><td>0.02</td><td>&#x0003c;.01</td><td>0.56</td><td>0.02</td><td>&#x0003c;01</td><td>0.74</td><td>0.03</td><td>&#x0003c;.01</td></tr><tr><td>&#x02003;Gender (if female)</td><td>&#x02212;0.01</td><td>0.04</td><td>.38</td><td>0.03</td><td>0.04</td><td>.23</td><td>&#x02212;0.16</td><td>0.04</td><td>&#x0003c;.01</td><td>0.36</td><td>0.04</td><td>&#x0003c;.001</td><td>0.27</td><td>0.05</td><td>&#x0003c;.01</td></tr><tr><td>&#x02003;FSM (if eligible)</td><td>&#x02212;0.04</td><td>0.05</td><td>.16</td><td>0.10</td><td>0.05</td><td>.02</td><td>0.12</td><td>0.04</td><td>.01</td><td>&#x02212;0.17</td><td>0.05</td><td>.01</td><td>&#x02212;0.13</td><td>0.06</td><td>.01</td></tr><tr><td>&#x02003;Baseline score</td><td>&#x02013;</td><td>&#x02013;</td><td>&#x02013;</td><td>0.38</td><td>0.02</td><td>&#x0003c;.01</td><td>0.70</td><td>0.02</td><td>&#x0003c;.01</td><td>0.40</td><td>0.02</td><td>&#x0003c;.01</td><td>0.44</td><td>0.03</td><td>&#x0003c;.01</td></tr></tbody></table><table-wrap-foot><p>
<italic>SECCI</italic> Social and Emotional Competence Change Index, <italic>SDQ</italic> Strengths and Difficulties Questionnaire, <italic>SSIS</italic> Social Skills Improvement System</p></table-wrap-foot></table-wrap>
</p><sec id="FPar7"><title>Quality and Responsiveness</title><p id="Par31">Compared to low levels, high levels of implementation quality and participant responsiveness were associated with significantly lower ratings of students&#x02019; externalizing problems at 12-month follow-up (&#x003b2;&#x000a0;=&#x000a0;&#x02212;0.26, <italic>p</italic>&#x000a0;=&#x000a0;.04). This effect was mirrored in a marginal, non-significant trend relating to moderate implementation quality and participant responsiveness for the same outcome variable (&#x003b2;&#x000a0;=&#x000a0;&#x02212;0.14, <italic>p</italic>&#x000a0;=&#x000a0;.11). Levels of implementation quality and responsiveness were not significantly associated with any other intervention outcome (all <italic>p</italic>&#x000a0;&#x0003e;&#x000a0;.05).</p></sec><sec id="FPar8"><title>Procedural Fidelity</title><p id="Par32">Levels of procedural fidelity were not significantly associated with any intervention outcome (all <italic>p</italic>&#x000a0;&#x0003e;&#x000a0;.05).</p></sec><sec id="FPar9"><title>Dosage</title><p id="Par33">Contrary to expectations, high levels of dosage (compared to low) were associated with significantly lower ratings of students&#x02019; pro-social behavior at 12-month follow-up (&#x003b2;&#x000a0;=&#x000a0;&#x02212;0.52, <italic>p</italic>&#x000a0;=&#x000a0;.02). Similarly, both moderate (&#x003b2;&#x000a0;=&#x000a0;&#x02212;0.25, <italic>p</italic>&#x000a0;=&#x000a0;.01) and high (&#x003b2;&#x000a0;=&#x000a0;&#x02212;0.28, <italic>p</italic>&#x000a0;=&#x000a0;.03), compared to low levels of dosage, were associated with significantly lower ratings of students&#x02019; social-emotional skills. Levels of dosage were not significantly associated with any other intervention outcome (all <italic>p</italic>&#x000a0;&#x0003e;&#x000a0;.05).</p></sec><sec id="FPar10"><title>Reach</title><p id="Par34">Levels of reach were not significantly associated with any intervention outcome (all <italic>p</italic>&#x000a0;&#x0003e;&#x000a0;.05).</p></sec></sec><sec id="Sec11"><title>Discussion</title><p id="Par35">The principal aim of the current study was to assess the relationship between implementation and intervention outcomes in the PATHS curriculum. In doing so, we sought to offer distinct contributions to the field by adopting a more wide-ranging approach to the assessment of implementation than has previously been evident, through the increased objectivity and rigor afforded by the use of independent observational data, and via the application of a theoretical framework for implementation that posits quality and fidelity as distinct dimensions, enabling us to concurrently assess the relative importance of <italic>what</italic> is delivered and <italic>how well</italic> in determining intervention outcomes (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>). Our analysis of observational implementation data revealed distinct dimensions of implementation <italic>quality and responsiveness</italic> and <italic>procedural fidelity</italic>. Implementation-outcomes analyses demonstrated that high (and, marginally, moderate) levels of implementation quality and responsiveness were associated with significantly lower ratings of students&#x02019; externalizing problems. Contrary to expectations, high (and, for students&#x02019; social-emotional skills, moderate) levels of dosage were associated with significantly lower ratings of students&#x02019; pro-social behavior and social-emotional skills. No associations were found between variability in either procedural fidelity or reach and intervention outcomes.</p><p id="Par36">The factor analytic model of our observational data offers clear empirical support for the integrated model of implementation that posits fidelity and quality as distinct dimensions (Berkel et al. <xref ref-type="bibr" rid="CR2">2011</xref>). The fact that the observational indicators relating to quality and those relating to participant responsiveness loaded strongly together in our EFA<xref ref-type="fn" rid="Fn4">4</xref> is also consistent with the integrated model, in which the former is seen as a foundation for the latter. It is here where parallels with the literature on therapeutic alliances may be drawn; in this body of work, the relational and interactional bond between therapist and client is articulated in terms the competence and skills of the former and the engagement and active participation of the latter. Interestingly, the quality of this alliance has been shown to be a reliable predictor of positive intervention outcomes regardless of the therapeutic model used (Ardito and Rabellino <xref ref-type="bibr" rid="CR1">2011</xref>). Thus, as in the current study, <italic>quality matters</italic>.</p><p id="Par38">Our implementation-outcomes analyses challenge the predominance of fidelity and dosage in the study of school-based interventions. Elsewhere, we have argued against the &#x0201c;zero sum game&#x0201d; view of implementation (e.g., fidelity is all that matters, and therefore attention to matters beyond fidelity is not worthwhile; Elliott and Mihalic <xref ref-type="bibr" rid="CR20">2004</xref>) on conceptual and theoretical bases (Lendrum et al. <xref ref-type="bibr" rid="CR38">2016</xref>). Here, we extend our position by demonstrating empirically that variability in procedural fidelity appears to be unrelated to intervention outcomes in the PATHS curriculum. Our findings align with those of Berry et al. (<xref ref-type="bibr" rid="CR3">2016</xref>) and the Social and Character Development Research Consortium (<xref ref-type="bibr" rid="CR53">2010</xref>). These authors also found no association between fidelity and outcomes in their recent PATHS trials. However, it is important to note that their analyses did not take account of the critical distinction between fidelity and quality made in the current study.</p><p id="Par39">Our findings contrast with those of Faria et al. (<xref ref-type="bibr" rid="CR22">2013</xref>) and Schonfeld et al. (<xref ref-type="bibr" rid="CR49">2015</xref>), both of whom found a significant, <italic>positive</italic> association between PATHS dosage and outcomes. The dosage levels reported in the current study (see Table <xref rid="Tab1" ref-type="table">1</xref>) are comparable with those of Faria et al. (<xref ref-type="bibr" rid="CR22">2013</xref>),<xref ref-type="fn" rid="Fn5">5</xref> so the apparent <italic>negative</italic> effect seen here is presumably not because of a failure to achieve a &#x0201c;minimum effective dose&#x0201d; (Liu <xref ref-type="bibr" rid="CR39">2010</xref>). Instead, we speculate that methodological and other differences between our studies may account for the apparent incongruence. For example, Schonfeld et al. (<xref ref-type="bibr" rid="CR49">2015</xref>) used different methods to assess implementation (teacher self-report), covered a longer period of implementation (up to 4&#x000a0;years), and assessed different outcomes (academic attainment) than the current study.</p><p id="Par41">Such differences aside, the question still remains as to why higher levels of dosage were found to be associated with significantly worse intervention outcomes. One possible reason is that this high dosage was at the expense of quality. Put another way, some teachers may have engaged in a &#x0201c;race to the finish line,&#x0201d; implementing PATHS <italic>quickly</italic> rather than implementing it <italic>well</italic>. An alternative explanation is that the teachers who implemented PATHS more frequently did so because they had a lower functioning class. In support of this hypothesis, exploration of the study data indicated that children in the moderate and high dosage classrooms demonstrated marginally higher internalizing symptoms, externalizing problems, and lower pro-social behavior at baseline. Finally, it may simply be the case that more frequent delivery of PATHS lessons meant that other efficacious activities (including, potentially, targeted interventions) were displaced.</p><p id="Par42">Conversely, we found that higher implementation quality and participant responsiveness was associated with lower ratings of students&#x02019; externalizing problems at 12-month follow-up. These analyses support Durlak&#x02019;s (<xref ref-type="bibr" rid="CR16">2015</xref>) claim that &#x0201c;in some circumstances, quality of delivery&#x02026; may be more strongly related than other implementation components to some program benefits&#x0201d; (p.1126) and add to a small but growing evidence base on the importance of this dimension of implementation as a moderator of intervention outcomes. In particular, our findings support those of Pettigrew et al. (<xref ref-type="bibr" rid="CR47">2015</xref>), whose implementation-outcomes analyses of the <italic>keepin&#x02019; it REAL</italic> program revealed that implementation quality and participant responsiveness were more reliable predictors of intervention outcomes than fidelity. This emergent pattern of findings suggests that a broadening of focus to incorporate quality and responsiveness is perhaps warranted in implementation support processes (e.g., initial training, on-going technical support and assistance). This may, however, prove to be challenging for manualized interventions that perhaps lend themselves to a more procedural emphasis.</p><p id="Par43">The current study is not without limitations. Chief among these was the fact that we were only able to observe each teacher/classroom once, thereby providing only a &#x0201c;snapshot&#x0201d; of implementation. The general recommendation is to capture implementation over multiple occasions to improve reliability and such that temporal patterns can be identified and taken into account in analyses (Humphrey et al. <xref ref-type="bibr" rid="CR36">2016b</xref>). As a counterpoint, however, we note the fact that some major observational studies of temporal patterns in implementation have actually evidenced high levels of stability in key dimensions (e.g., Hansen et al. <xref ref-type="bibr" rid="CR30">2013</xref>). Of particular relevance is Domitrovich et al.&#x02019;s (<xref ref-type="bibr" rid="CR14">2010</xref>) study of PATHS, which found no significant changes in fidelity, dosage, or participant responsiveness when growth models were applied to implementation data collected monthly over the course of a school year. Similar temporal stability (in implementation quality) was found in the FAST Track trial of PATHS (CPPRG <xref ref-type="bibr" rid="CR8">1999</xref>). Moreover, multiple observations in the current study were simply not possible due to resource and data burden considerations. We do note though that, as observations were scheduled with teachers, they might have differentially prepared for these lessons. This is, however, almost impossible to avoid, given the ethical and practical considerations inherent in observational studies of implementation in schools.</p><p id="Par44">A second limitation is that, despite adopting a more wide-ranging approach to the assessment of implementation than had previously been evident, the current study was not completely comprehensive. It is difficult, if not impossible, to study all implementation components simultaneously (Durlak <xref ref-type="bibr" rid="CR17">2016</xref>). Specifically, we were not able to include data on program differentiation or adaptations in the analyses reported here. In terms of the former, establishing the distinctiveness of a given intervention from existing classroom practice is crucial in terms of determining its &#x0201c;achieved relative strength&#x0201d; (Nelson et al. <xref ref-type="bibr" rid="CR43">2012</xref>). In relation to the latter, assessment needs to take into account the reasons for adaptation (e.g., logistical, philosophical), their timing (e.g., pro-active, reactive), and valence (e.g., positive, negative, neutral) (Moore et al. <xref ref-type="bibr" rid="CR41">2013</xref>). These two dimensions have proven particularly elusive in the broader field (Humphrey et al. <xref ref-type="bibr" rid="CR36">2016b</xref>). However, recent work by Hansen et al. (<xref ref-type="bibr" rid="CR30">2013</xref>) suggests that reliable and valid assessment is possible, albeit time consuming and costly.</p><p id="Par45">Finally, we should also note alternative explanations for the lack of positive associations between procedural fidelity, dosage, and the outcomes modeled herein. It is possible, for example, that once minimum effective levels of these dimensions of implementation are reached, little or no &#x0201c;added value&#x0201d; is gained from higher levels. While somewhat plausible, this explanation does not align well with findings of other studies (e.g., the aforementioned study by Schonfeld et al. (<xref ref-type="bibr" rid="CR49">2015</xref>) found that the probability of achieving academic proficiency status in reading increased 1.37 times for each additional lesson taught), and is also discordant with the developers&#x02019; recommendations, particularly in relation to dosage. Another explanation is that there was not enough variability in our dataset, particularly for procedural fidelity, to detect its effects. However, scrutiny of the descriptive data for the implementation indicators (Table <xref rid="Tab1" ref-type="table">1</xref>) does not support this interpretation, as the two procedural fidelity indicators actually yielded <italic>higher</italic> standard deviations (indicative of greater variability) than the quality and responsiveness indicators.</p></sec><sec id="Sec12"><title>Conclusion</title><p id="Par46">The current study adds to the growing body of literature exploring the relationship between implementation and intervention outcomes in school-based SEL. We provide distinct contributions in terms of the adoption of a more wide-ranging approach to the assessment of implementation than has previously been evident, increased objectivity and rigor afforded by the use of independent observational methods, and the application of a theoretical framework for implementation that posits quality and fidelity as distinct dimensions. Our analyses provide support for the integrated model of implementation and suggest that quality and responsiveness are at least as critical as fidelity and dosage, if not more so, in determining the achievement of expected outcomes. Put another way, the current study reinforces Durlak&#x02019;s (<xref ref-type="bibr" rid="CR15">2010</xref>) clarion call for the advancement of implementation science, in which he noted &#x0201c;the importance of doing well in whatever you do&#x0201d; (p.348).</p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par19">The rubric was designed to orient observers to behaviors indicative of the implementation indicator in question. For example, when rating students&#x02019; engagement in core activities, the explanatory notes guided observers to assess the extent to which children in the class actively participated in lesson activities (e.g., joining in role plays and answering questions).</p></fn><fn id="Fn2"><label>2</label><p id="Par21">In order to meet minimal sample size requirements (e.g., <italic>N</italic>&#x000a0;=&#x000a0;10 per item), the EFA was conducted using data from the 127 observations conducted across the 2&#x000a0;years of the trial.</p></fn><fn id="Fn3"><label>3</label><p id="Par26">Historically, the SDQ has been scored according to a five-factor structure (emotional symptoms, conduct problems, inattention/hyperactivity, peer problems, and pro-social behavior). However, research has indicated that a three-factor structure (internalizing symptoms, externalizing problems, pro-social behavior) offers improved data fit (Goodman, Lamping &#x00026; Ploubidis, 2010).</p></fn><fn id="Fn4"><label>4</label><p id="Par37">We note that one item initially designated as belonging to the fidelity dimension also loaded onto this factor; however, there was evidence that of ambiguity, with this item cross-loading onto both factors (loadings of 0.57 and 0.48 respectively).</p></fn><fn id="Fn5"><label>5</label><p id="Par40">Schonfeld et al. (<xref ref-type="bibr" rid="CR49">2015</xref>) did not provide descriptive statistics for their implementation data and a direct comparison of overall dosage levels is therefore not possible.</p></fn></fn-group><notes notes-type="COI-statement"><title>Compliance with Ethical Standards</title><sec id="FPar11"><title>Funding</title><p id="Par47">National Institute for Health Research (Grant ref 10/3006/01).</p></sec><sec id="FPar12"><title>Conflicts of Interest</title><p id="Par48">The authors declare that they have no conflict of interest.</p></sec><sec id="FPar13"><title>Ethical Approval</title><p id="Par49">University of Manchester ethics committee (Ref 11470).</p></sec><sec id="FPar14"><title>Informed Consent</title><p id="Par50">Participation in the study required consent from schools&#x02019; head teachers. Child assent and parental opt-out consent were also sought.</p></sec></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ardito</surname><given-names>RB</given-names></name><name><surname>Rabellino</surname><given-names>D</given-names></name></person-group><article-title>Therapeutic alliance and outcome of psychotherapy: Historical excursus, measurements, and prospects for research</article-title><source>Frontiers in Psychology</source><year>2011</year><volume>2</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00270</pub-id><pub-id pub-id-type="pmid">21713130</pub-id></element-citation></ref><ref id="CR2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berkel</surname><given-names>C</given-names></name><name><surname>Mauricio</surname><given-names>AM</given-names></name><name><surname>Schoenfelder</surname><given-names>E</given-names></name><name><surname>Sandler</surname><given-names>IN</given-names></name></person-group><article-title>Putting the pieces together: An integrated model of program implementation</article-title><source>Prevention Science</source><year>2011</year><volume>12</volume><fpage>23</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1007/s11121-010-0186-1</pub-id><pub-id pub-id-type="pmid">20890725</pub-id></element-citation></ref><ref id="CR3"><mixed-citation publication-type="other">Berry, V., Axford, N., Blower, S., Taylor, R. S., Edwards, R. T., Tobin, K., &#x02026; Bywater, T. (2016). The effectiveness and micro-costing analysis of a universal, school-based, social&#x02013;emotional learning programme in the UK: A cluster-randomised controlled trial. <italic>School Mental Health</italic>, 238&#x02013;256. doi:10.1007/s12310-015-9160-1</mixed-citation></ref><ref id="CR4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierman</surname><given-names>KL</given-names></name><name><surname>Nix</surname><given-names>RL</given-names></name><name><surname>Heinrichs</surname><given-names>BS</given-names></name><name><surname>Domitrovich</surname><given-names>CE</given-names></name><name><surname>Gest</surname><given-names>SD</given-names></name><name><surname>Welsh</surname><given-names>JA</given-names></name><name><surname>Gill</surname><given-names>S</given-names></name></person-group><article-title>Effects of head start REDI on children&#x02019;s outcomes 1 year later in different kindergarten contexts</article-title><source>Child Development</source><year>2014</year><volume>85</volume><fpage>140</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1111/cdev.12117</pub-id><pub-id pub-id-type="pmid">23647355</pub-id></element-citation></ref><ref id="CR5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruhn</surname><given-names>AL</given-names></name><name><surname>Hirsch</surname><given-names>SE</given-names></name><name><surname>Lloyd</surname><given-names>JW</given-names></name></person-group><article-title>Treatment integrity in school-wide programs: A review of the literature (1993&#x02013;2012)</article-title><source>The Journal of Primary Prevention</source><year>2015</year><volume>36</volume><fpage>335</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1007/s10935-015-0400-9</pub-id><pub-id pub-id-type="pmid">26319798</pub-id></element-citation></ref><ref id="CR6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>JJR</given-names></name><name><surname>Goldstein</surname><given-names>H</given-names></name><name><surname>Kenward</surname><given-names>MGM</given-names></name></person-group><article-title>REALCOM-IMPUTE software for multilevel multiple imputation with mixed response types</article-title><source>Journal of Statistical Software</source><year>2011</year><volume>45</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.18637/jss.v045.i05</pub-id></element-citation></ref><ref id="CR7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>C</given-names></name><name><surname>Patterson</surname><given-names>M</given-names></name><name><surname>Wood</surname><given-names>S</given-names></name><name><surname>Booth</surname><given-names>A</given-names></name><name><surname>Rick</surname><given-names>J</given-names></name><name><surname>Balain</surname><given-names>S</given-names></name></person-group><article-title>A conceptual framework for implementation fidelity</article-title><source>Implementation Science</source><year>2007</year><volume>2</volume><fpage>40</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1186/1748-5908-2-40</pub-id><pub-id pub-id-type="pmid">18053122</pub-id></element-citation></ref><ref id="CR8"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>Conduct Problems Prevention Research Group</collab></person-group><article-title>Initial impact of the Fast track prevention trial for conduct problems: II. Classroom effects</article-title><source>Journal of Consulting and Clinical Psychology</source><year>1999</year><volume>67</volume><fpage>648</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1037/0022-006X.67.5.648</pub-id><pub-id pub-id-type="pmid">10535231</pub-id></element-citation></ref><ref id="CR9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crean</surname><given-names>HF</given-names></name><name><surname>Johnson</surname><given-names>DB</given-names></name></person-group><article-title>Promoting alternative thinking strategies (PATHS) and elementary school aged children&#x02019;s aggression: Results from a cluster randomized trial</article-title><source>American Journal of Community Psychology</source><year>2013</year><volume>52</volume><fpage>56</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1007/s10464-013-9576-4</pub-id><pub-id pub-id-type="pmid">23625456</pub-id></element-citation></ref><ref id="CR10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cross</surname><given-names>W</given-names></name><name><surname>West</surname><given-names>J</given-names></name><name><surname>Wyman</surname><given-names>PA</given-names></name><etal/></person-group><article-title>Observational measures of implementer fidelity for a school-based preventive intervention: Development, reliability and validity</article-title><source>Prevention Science</source><year>2015</year><volume>16</volume><fpage>122</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1007/s11121-014-0488-9</pub-id><pub-id pub-id-type="pmid">24736951</pub-id></element-citation></ref><ref id="CR11"><mixed-citation publication-type="other">Department for Education. (2012). <italic>Schools, pupils and their characteristics</italic>. London: Department for Education.</mixed-citation></ref><ref id="CR12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiStefano</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Mindrila</surname><given-names>D</given-names></name></person-group><article-title>Understanding and using factor scores: Considerations for the applied researcher</article-title><source>Practical Assessment, Research and Evaluation</source><year>2009</year><volume>14</volume><fpage>1</fpage><lpage>11</lpage></element-citation></ref><ref id="CR13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domitrovich</surname><given-names>CE</given-names></name><name><surname>Cortes</surname><given-names>RC</given-names></name><name><surname>Greenberg</surname><given-names>MT</given-names></name></person-group><article-title>Improving young children&#x02019;s social and emotional competence: A randomized trial of the preschool &#x0201c;PATHS&#x0201d; curriculum</article-title><source>The Journal of Primary Prevention</source><year>2007</year><volume>28</volume><fpage>67</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1007/s10935-007-0081-0</pub-id><pub-id pub-id-type="pmid">17265130</pub-id></element-citation></ref><ref id="CR14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domitrovich</surname><given-names>CE</given-names></name><name><surname>Gest</surname><given-names>SD</given-names></name><name><surname>Jones</surname><given-names>D</given-names></name><name><surname>Gill</surname><given-names>S</given-names></name><name><surname>Sanford Derousie</surname><given-names>RM</given-names></name></person-group><article-title>Implementation quality: Lessons learned in the context of the head start REDI trial</article-title><source>Early Childhood Research Quarterly</source><year>2010</year><volume>25</volume><fpage>284</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1016/j.ecresq.2010.04.001</pub-id><pub-id pub-id-type="pmid">22844183</pub-id></element-citation></ref><ref id="CR15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durlak</surname><given-names>J</given-names></name></person-group><article-title>The importance of doing well in whatever you do: A commentary on the special edition, &#x0201c;implementation research in early childhood education&#x0201d;</article-title><source>Early Childhood Research Quarterly</source><year>2010</year><volume>25</volume><fpage>348</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1016/j.ecresq.2010.03.003</pub-id></element-citation></ref><ref id="CR16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durlak</surname><given-names>JA</given-names></name></person-group><article-title>Studying program implementation is not easy but it is essential</article-title><source>Prevention Science</source><year>2015</year><volume>16</volume><fpage>1123</fpage><lpage>1127</lpage><pub-id pub-id-type="doi">10.1007/s11121-015-0606-3</pub-id><pub-id pub-id-type="pmid">26399607</pub-id></element-citation></ref><ref id="CR17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durlak</surname><given-names>JA</given-names></name></person-group><article-title>Programme implementation in social and emotional learning: Basic issues and research findings</article-title><source>Cambridge Journal of Education</source><year>2016</year><volume>46</volume><fpage>333</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1080/0305764X.2016.1142504</pub-id></element-citation></ref><ref id="CR18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durlak</surname><given-names>JA</given-names></name><name><surname>DuPre</surname><given-names>EP</given-names></name></person-group><article-title>Implementation matters: A review of research on the influence of implementation on program outcomes and the factors affecting implementation</article-title><source>American Journal of Community Psychology</source><year>2008</year><volume>41</volume><fpage>327</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1007/s10464-008-9165-0</pub-id><pub-id pub-id-type="pmid">18322790</pub-id></element-citation></ref><ref id="CR19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durlak</surname><given-names>J a</given-names></name><name><surname>Weissberg</surname><given-names>RP</given-names></name><name><surname>Dymnicki</surname><given-names>AB</given-names></name><name><surname>Taylor</surname><given-names>RD</given-names></name><name><surname>Schellinger</surname><given-names>KB</given-names></name></person-group><article-title>The impact of enhancing students&#x02019; social and emotional learning: A meta-analysis of school-based universal interventions</article-title><source>Child Development</source><year>2011</year><volume>82</volume><fpage>405</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8624.2010.01564.x</pub-id><pub-id pub-id-type="pmid">21291449</pub-id></element-citation></ref><ref id="CR20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>D</given-names></name><name><surname>Mihalic</surname><given-names>S</given-names></name></person-group><article-title>Issues in disseminating and replicating effective prevention programs</article-title><source>Prevention Science</source><year>2004</year><volume>5</volume><fpage>47</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1023/B:PREV.0000013981.28071.52</pub-id><pub-id pub-id-type="pmid">15058912</pub-id></element-citation></ref><ref id="CR21"><mixed-citation publication-type="other">EPISCenter. (2014). <italic>Promoting alternative thinking strategies</italic>. Retrieved August 14, 2014, from <ext-link ext-link-type="uri" xlink:href="http://www.episcenter.psu.edu/ebp/altthinking">http://www.episcenter.psu.edu/ebp/altthinking</ext-link></mixed-citation></ref><ref id="CR22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Faria</surname><given-names>AM</given-names></name><name><surname>Kendziora</surname><given-names>K</given-names></name><name><surname>Brown</surname><given-names>L</given-names></name><name><surname>O&#x02019;Brien</surname><given-names>B</given-names></name><name><surname>Osher</surname><given-names>D</given-names></name></person-group><source>PATHS implementation and outcome study in the Cleveland metropolitan School District: Final report</source><year>2013</year><publisher-loc>Washington</publisher-loc><publisher-name>American Institutes for Research</publisher-name></element-citation></ref><ref id="CR23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>R</given-names></name></person-group><article-title>Psychometric properties of the strengths and difficulties questionnaire</article-title><source>Journal of the American Academy of Child and Adolescent Psychiatry</source><year>2001</year><volume>40</volume><fpage>1337</fpage><lpage>1345</lpage><pub-id pub-id-type="doi">10.1097/00004583-200111000-00015</pub-id><pub-id pub-id-type="pmid">11699809</pub-id></element-citation></ref><ref id="CR24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>A</given-names></name><name><surname>Lamping</surname><given-names>DL</given-names></name><name><surname>Ploubidis</surname><given-names>GB</given-names></name></person-group><article-title>When to use broader internalising and externalising subscales instead of the hypothesised five subscales on the strengths and difficulties questionnaire (SDQ): Data from British parents, teachers and children</article-title><source>Journal of Abnormal Child Psychology</source><year>2010</year><volume>38</volume><fpage>1179</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1007/s10802-010-9434-x</pub-id><pub-id pub-id-type="pmid">20623175</pub-id></element-citation></ref><ref id="CR25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname><given-names>SB</given-names></name></person-group><article-title>How many subjects does it take to do a regression analysis</article-title><source>Multivariate Behavioral Research</source><year>1991</year><volume>26</volume><fpage>499</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1207/s15327906mbr2603_7</pub-id><pub-id pub-id-type="pmid">26776715</pub-id></element-citation></ref><ref id="CR26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>H</given-names></name><name><surname>McGinnity</surname><given-names>A</given-names></name><name><surname>Meltzer</surname><given-names>H</given-names></name><name><surname>Ford</surname><given-names>T</given-names></name><name><surname>Goodman</surname><given-names>R</given-names></name></person-group><source>Mental health of children and young people in Great Britain</source><year>2005</year><publisher-loc>Newport</publisher-loc><publisher-name>Office for National Statistics</publisher-name></element-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Gresham, F. M., &#x00026; Elliot, S. N. (2008). Social skills improvement system: Rating scales manual. Minneapolis, MN: Pearson</mixed-citation></ref><ref id="CR28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallgren</surname><given-names>KA</given-names></name></person-group><article-title>Computing inter-rater reliability for observational data: An overview and tutorial</article-title><source>Tutorials in Quantitative Methods for Psychology</source><year>2012</year><volume>8</volume><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.20982/tqmp.08.1.p023</pub-id><pub-id pub-id-type="pmid">22833776</pub-id></element-citation></ref><ref id="CR29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>W</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Sloboda</surname><given-names>Z</given-names></name><name><surname>Petras</surname><given-names>H</given-names></name></person-group><article-title>Measuring fidelity</article-title><source>Defining prevention science</source><year>2014</year><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name><fpage>335</fpage><lpage>359</lpage></element-citation></ref><ref id="CR30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>WB</given-names></name><name><surname>Pankrantz</surname><given-names>MM</given-names></name><name><surname>Dusenbury</surname><given-names>L</given-names></name><name><surname>Giles</surname><given-names>SM</given-names></name><name><surname>Bishop</surname><given-names>D</given-names></name><name><surname>Albritton</surname><given-names>J</given-names></name><etal/></person-group><article-title>Styles of adaptation: The impact of frequency and valence of adaptation on preventing substance abuse</article-title><source>Health Education</source><year>2013</year><volume>113</volume><fpage>345</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1108/09654281311329268</pub-id></element-citation></ref><ref id="CR31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>WB</given-names></name><name><surname>Pankratz</surname><given-names>MM</given-names></name><name><surname>Bishop</surname><given-names>DC</given-names></name></person-group><article-title>Differences in observers&#x02019; and teachers&#x02019; fidelity assessments</article-title><source>Journal of Primary Prevention</source><year>2014</year><volume>35</volume><fpage>297</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1007/s10935-014-0351-6</pub-id><pub-id pub-id-type="pmid">24903491</pub-id></element-citation></ref><ref id="CR32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heijtan</surname><given-names>DF</given-names></name><name><surname>Basu</surname><given-names>S</given-names></name></person-group><article-title>Distinguishing &#x0201c;missing at random&#x0201d; and &#x0201c;missing completely at random&#x0201d;</article-title><source>The American Statistician</source><year>1996</year><volume>50</volume><fpage>207</fpage><lpage>213</lpage></element-citation></ref><ref id="CR33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphrey</surname><given-names>N</given-names></name><name><surname>Kalambouka</surname><given-names>A</given-names></name><name><surname>Wigelsworth</surname><given-names>M</given-names></name><name><surname>Lendrum</surname><given-names>A</given-names></name><name><surname>Deighton</surname><given-names>J</given-names></name><name><surname>Wolpert</surname><given-names>M</given-names></name></person-group><article-title>Measures of social and emotional skills for children and young people: A systematic review</article-title><source>Educational and Psychological Measurement</source><year>2011</year><volume>71</volume><fpage>617</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1177/0013164410382896</pub-id></element-citation></ref><ref id="CR34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Humphrey</surname><given-names>N</given-names></name><name><surname>Barlow</surname><given-names>A</given-names></name><name><surname>Wigelsworth</surname><given-names>M</given-names></name><name><surname>Lendrum</surname><given-names>A</given-names></name><name><surname>Pert</surname><given-names>K</given-names></name><name><surname>Joyce</surname><given-names>C</given-names></name><etal/></person-group><source>Promoting alternative thinking strategies (PATHS): Evaluation report</source><year>2015</year><publisher-loc>London</publisher-loc><publisher-name>Education Endowment Foundation</publisher-name></element-citation></ref><ref id="CR35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humphrey</surname><given-names>N</given-names></name><name><surname>Barlow</surname><given-names>A</given-names></name><name><surname>Wigelsworth</surname><given-names>M</given-names></name><name><surname>Lendrum</surname><given-names>A</given-names></name><name><surname>Pert</surname><given-names>K</given-names></name><name><surname>Joyce</surname><given-names>C</given-names></name><etal/></person-group><article-title>A cluster randomized controlled trial of the promoting alternative thinking strategies (PATHS) curriculum</article-title><source>Journal of School Psychology</source><year>2016</year><volume>58</volume><fpage>73</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.jsp.2016.07.002</pub-id><pub-id pub-id-type="pmid">27586071</pub-id></element-citation></ref><ref id="CR36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Humphrey</surname><given-names>N</given-names></name><name><surname>Lendrum</surname><given-names>A</given-names></name><name><surname>Ashworth</surname><given-names>E</given-names></name><name><surname>Frearson</surname><given-names>K</given-names></name><name><surname>Buck</surname><given-names>R</given-names></name><name><surname>Kerr</surname><given-names>K</given-names></name></person-group><source>Implementation and process evaluation (IPE) for interventions in educational settings: A synthesis of the literature</source><year>2016</year><publisher-loc>London</publisher-loc><publisher-name>Education Endowment Foundation</publisher-name></element-citation></ref><ref id="CR37"><mixed-citation publication-type="other">Kam, C.M., Greenberg, M. T., &#x00026; Walls, C. T. (2003). Examining the role of implementation quality in school-based prevention using the PATHS curriculum. <italic>Prevention Science</italic>, 4, 55&#x02013;63&#x02013;63. doi:10.1023/A:1021786811186</mixed-citation></ref><ref id="CR38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lendrum</surname><given-names>A</given-names></name><name><surname>Humphrey</surname><given-names>N</given-names></name><name><surname>Greenberg</surname><given-names>MT</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Shute</surname><given-names>R</given-names></name><name><surname>Slee</surname><given-names>P</given-names></name></person-group><article-title>Implementing for success in school-based mental health promotion: The role of quality in resolving the tension between fidelity and adaptation</article-title><source>Mental health and wellbeing through schools: The way forward</source><year>2016</year><publisher-loc>London</publisher-loc><publisher-name>Taylor and Francis</publisher-name><fpage>53</fpage><lpage>63</lpage></element-citation></ref><ref id="CR39"><mixed-citation publication-type="other">Liu, J. (2010). Minimum effective dose. In <italic>Encyclopedia of Biopharmaceutical Statistics</italic> (pp. 799&#x02013;800). London: Informa.</mixed-citation></ref><ref id="CR40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname><given-names>S</given-names></name><name><surname>Smolkowski</surname><given-names>K</given-names></name><name><surname>Cook</surname><given-names>C</given-names></name></person-group><article-title>What constitutes high-quality implementation of SEL programs? A latent class analysis of second step implementation</article-title><source>Prevention Science</source><year>2016</year><volume>17</volume><fpage>981</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1007/s11121-016-0670-3</pub-id><pub-id pub-id-type="pmid">27457205</pub-id></element-citation></ref><ref id="CR41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>JE</given-names></name><name><surname>Bumbarger</surname><given-names>BK</given-names></name><name><surname>Cooper</surname><given-names>BR</given-names></name></person-group><article-title>Examining adaptations of evidence-based programs in natural contexts</article-title><source>The Journal of Primary Prevention</source><year>2013</year><volume>34</volume><fpage>147</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1007/s10935-013-0303-6</pub-id><pub-id pub-id-type="pmid">23605294</pub-id></element-citation></ref><ref id="CR42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myung</surname><given-names>IJ</given-names></name></person-group><article-title>The importance of complexity in model selection</article-title><source>Journal of Mathematical Psychology</source><year>2000</year><volume>44</volume><fpage>190</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1006/jmps.1999.1283</pub-id><pub-id pub-id-type="pmid">10733864</pub-id></element-citation></ref><ref id="CR43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>MC</given-names></name><name><surname>Cordray</surname><given-names>DS</given-names></name><name><surname>Hulleman</surname><given-names>CS</given-names></name><name><surname>Darrow</surname><given-names>CL</given-names></name><name><surname>Sommer</surname><given-names>EC</given-names></name></person-group><article-title>A procedure for assessing intervention fidelity in experiments testing educational and behavioral interventions</article-title><source>Journal of Behavioral Health Services and Research</source><year>2012</year><volume>39</volume><fpage>374</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1007/s11414-012-9295-x</pub-id><pub-id pub-id-type="pmid">22935907</pub-id></element-citation></ref><ref id="CR44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O&#x02019;Donnell</surname><given-names>CL</given-names></name></person-group><article-title>Defining, conceptualising, and measuring fidelity of implementation and its relationship to outcomes in K-12 curriculum intervention research</article-title><source>Review of Educational Research</source><year>2008</year><volume>78</volume><fpage>33</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.3102/0034654307313793</pub-id></element-citation></ref><ref id="CR45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Odom</surname><given-names>SL</given-names></name><name><surname>Fleming</surname><given-names>K</given-names></name><name><surname>Diamond</surname><given-names>K</given-names></name><name><surname>Lieber</surname><given-names>J</given-names></name><name><surname>Hanson</surname><given-names>M</given-names></name><name><surname>Butera</surname><given-names>G</given-names></name><etal/></person-group><article-title>Examining different forms of implementation in early childhood curriculum research</article-title><source>Early Childhood Research Quarterly</source><year>2010</year><volume>25</volume><fpage>314</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1016/j.ecresq.2010.03.001</pub-id><pub-id pub-id-type="pmid">21874091</pub-id></element-citation></ref><ref id="CR46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogden</surname><given-names>T</given-names></name><name><surname>Fixsen</surname><given-names>DL</given-names></name></person-group><article-title>Implementation science: A brief overview and a look ahead</article-title><source>Zeitschrift f&#x000fc;r Psychologie</source><year>2014</year><volume>222</volume><fpage>4</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1027/2151-2604/a000160</pub-id></element-citation></ref><ref id="CR47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettigrew</surname><given-names>J</given-names></name><name><surname>Graham</surname><given-names>JW</given-names></name><name><surname>Miller-Day</surname><given-names>M</given-names></name><name><surname>Hecht</surname><given-names>ML</given-names></name><name><surname>Krieger</surname><given-names>JL</given-names></name><name><surname>Shin</surname><given-names>YJ</given-names></name></person-group><article-title>Adherence and delivery: Implementation quality and program outcomes for the seventh-grade keepin&#x02019; it REAL program</article-title><source>Prevention Science&#x000a0;: The Official Journal of the Society for Prevention Research</source><year>2015</year><volume>16</volume><fpage>90</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1007/s11121-014-0459-1</pub-id><pub-id pub-id-type="pmid">24442403</pub-id></element-citation></ref><ref id="CR48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoenwald</surname><given-names>SK</given-names></name><name><surname>Garland</surname><given-names>AF</given-names></name></person-group><article-title>A review of treatment adherence measurement methods</article-title><source>Psychological Assessment</source><year>2014</year><volume>25</volume><fpage>146</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1037/a0029715</pub-id></element-citation></ref><ref id="CR49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schonfeld</surname><given-names>DJ</given-names></name><name><surname>Adams</surname><given-names>RE</given-names></name><name><surname>Fredstrom</surname><given-names>BK</given-names></name><name><surname>Weissberg</surname><given-names>RP</given-names></name><name><surname>Gilman</surname><given-names>R</given-names></name><name><surname>Voyce</surname><given-names>C</given-names></name><etal/></person-group><article-title>Cluster-randomized trial demonstrating impact on academic achievement of elementary social-emotional learning</article-title><source>School Psychology Quarterly</source><year>2015</year><volume>30</volume><fpage>406</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1037/spq0000099</pub-id><pub-id pub-id-type="pmid">25485463</pub-id></element-citation></ref><ref id="CR50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sklad</surname><given-names>M</given-names></name><name><surname>Diekstra</surname><given-names>R</given-names></name><name><surname>De Ritter</surname><given-names>M</given-names></name><name><surname>Ben</surname><given-names>J</given-names></name><name><surname>Gravesteijn</surname><given-names>C</given-names></name></person-group><article-title>Effectiveness of school-based universal social, emotional, and behavioral programs: Do they enhance students&#x02019; development in the area of skills, behavior and adjustment?</article-title><source>Psychology in the Schools</source><year>2012</year><volume>49</volume><fpage>892</fpage><lpage>909</lpage><pub-id pub-id-type="doi">10.1002/pits.21641</pub-id></element-citation></ref><ref id="CR51"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Snijders</surname><given-names>TAB</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Everitt</surname><given-names>BS</given-names></name><name><surname>Howell</surname><given-names>DC</given-names></name></person-group><article-title>Power and sample size in multilevel modeling</article-title><source>Encyclopedia of statistics in behavioral science</source><year>2005</year><publisher-loc>Chichester</publisher-loc><publisher-name>Wiley</publisher-name><fpage>1570</fpage><lpage>1573</lpage></element-citation></ref><ref id="CR52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Snijders</surname><given-names>TAB</given-names></name><name><surname>Bosker</surname><given-names>RJ</given-names></name></person-group><source>Multilevel analysis</source><year>2012</year><publisher-loc>London</publisher-loc><publisher-name>SAGE Publications</publisher-name></element-citation></ref><ref id="CR53"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Social and Character Development Research Consortium</collab></person-group><source>Efficacy of school-wide programs to promote social and character development and reduce problem behavior in elementary school children</source><year>2010</year><publisher-loc>Washington</publisher-loc><publisher-name>Institute of Educational Science</publisher-name></element-citation></ref><ref id="CR54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weissberg</surname><given-names>RP</given-names></name><name><surname>Durlak</surname><given-names>JA</given-names></name><name><surname>Domitrovich</surname><given-names>CE</given-names></name><name><surname>Gullotta</surname><given-names>TP</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Durlak</surname><given-names>JA</given-names></name><name><surname>Domitrovich</surname><given-names>CE</given-names></name><name><surname>Weissberg</surname><given-names>RP</given-names></name><name><surname>Gullotta</surname><given-names>TP</given-names></name></person-group><article-title>Social and emotional learning: Past, present and future</article-title><source>Handbook of social and emotional learning</source><year>2015</year><publisher-loc>New York</publisher-loc><publisher-name>Guilford Press</publisher-name><fpage>3</fpage><lpage>19</lpage></element-citation></ref><ref id="CR55"><mixed-citation publication-type="other">Wigelsworth, M., Lendrum, A., Oldfield, J., Scott, A., Ten-Bokkel, I., Tate, K., &#x00026; Emery, C. (2016). The influence of trial stage, developer involvement and international transferability on the outcomes of universal social and emotional learning outcomes: A meta-analysis. <italic>Cambridge Journal of Education, 46</italic>, 347&#x02013;376. doi:10.1080/0305764X.2016.1195791.</mixed-citation></ref></ref-list></back></article>