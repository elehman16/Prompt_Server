<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26379570</article-id><article-id pub-id-type="pmc">4547016</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2015.01191</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Emotion word processing: does mood make a difference?</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sereno</surname><given-names>Sara C.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/36162/overview"/></contrib><contrib contrib-type="author"><name><surname>Scott</surname><given-names>Graham G.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/38913/overview"/></contrib><contrib contrib-type="author"><name><surname>Yao</surname><given-names>Bo</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/80389/overview"/></contrib><contrib contrib-type="author"><name><surname>Thaden</surname><given-names>Elske J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/201860/overview"/></contrib><contrib contrib-type="author"><name><surname>O'Donnell</surname><given-names>Patrick J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/61740/overview"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>School of Psychology, University of Glasgow</institution><country>Glasgow, UK</country></aff><aff id="aff2"><sup>2</sup><institution>Institute of Neuroscience and Psychology, University of Glasgow</institution><country>Glasgow, UK</country></aff><aff id="aff3"><sup>3</sup><institution>Applied Psychology Research Group, School of Media, Culture and Society, University of the West of Scotland</institution><country>Paisley, UK</country></aff><aff id="aff4"><sup>4</sup><institution>School of Psychological Sciences, University of Manchester</institution><country>Manchester, UK</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Cornelia Herbert, University Hospital of T&#x000fc;bingen, Germany</p></fn><fn fn-type="edited-by"><p>Reviewed by: Francesca M. M. Citron, Lancaster University, UK; Kevin B. Paterson, University of Leicester, UK</p></fn><corresp id="fn001">*Correspondence: Sara C. Sereno, Institute of Neurscience and Psychology, School of Psychology, University of Glasgow, 58 Hillhead Street, Glasgow G12 8QB, UK <email xlink:type="simple">sara.sereno@glasgow.ac.uk</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Language Sciences, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>24</day><month>8</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>6</volume><elocation-id>1191</elocation-id><history><date date-type="received"><day>13</day><month>12</month><year>2014</year></date><date date-type="accepted"><day>28</day><month>7</month><year>2015</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2015 Sereno, Scott, Yao, Thaden and O'Donnell.</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Sereno, Scott, Yao, Thaden and O'Donnell</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Visual emotion word processing has been in the focus of recent psycholinguistic research. In general, emotion words provoke differential responses in comparison to neutral words. However, words are typically processed within a context rather than in isolation. For instance, how does one's inner emotional state influence the comprehension of emotion words? To address this question, the current study examined lexical decision responses to emotionally positive, negative, and neutral words as a function of induced mood as well as their word frequency. Mood was manipulated by exposing participants to different types of music. Participants were randomly assigned to one of three conditions&#x02014;no music, positive music, and negative music. Participants' moods were assessed during the experiment to confirm the mood induction manipulation. Reaction time results confirmed prior demonstrations of an interaction between a word's emotionality and its frequency. Results also showed a significant interaction between participant mood and word emotionality. However, the pattern of results was not consistent with mood-congruency effects. Although positive and negative mood facilitated responses overall in comparison to the control group, neither positive nor negative mood appeared to additionally facilitate responses to mood-congruent words. Instead, the pattern of findings seemed to be the consequence of attentional effects arising from induced mood. Positive mood broadens attention to a global level, eliminating the category distinction of positive-negative valence but leaving the high-low arousal dimension intact. In contrast, negative mood narrows attention to a local level, enhancing within-category distinctions, in particular, for negative words, resulting in less effective facilitation.</p></abstract><kwd-group><kwd>emotion</kwd><kwd>mood induction</kwd><kwd>valence</kwd><kwd>arousal</kwd><kwd>word frequency</kwd><kwd>visual word recognition</kwd><kwd>lexical decision</kwd></kwd-group><counts><fig-count count="4"/><table-count count="7"/><equation-count count="0"/><ref-count count="72"/><page-count count="13"/><word-count count="9525"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>For several decades, research into visual word recognition has sought to identify and delineate the factors affecting the access of word meaning. One focus of more recent research has been on the processing of written emotional words. In general, such research has established that emotion words provoke differential responses in comparison to neutral words. Words, however, are typically recognized not in isolation, but within a context. A context can be the prior sentence or paragraph that makes a word more or less predictable. Alternatively, a context can be the inner emotional state of the comprehender. The current study investigates the effect of induced mood on the recognition of emotional and neutral words. We begin by reviewing recent advances in emotion word recognition. We then consider studies that have investigated how mood affects word recognition. Our study attempts to address some of the perceived limitations of the research that has been conducted to date.</p><p>Emotion words are typically characterized within a two-dimensional framework of valence, a measure of value or worth, and arousal, a measure of internal activation (e.g., Osgood et al., <xref rid="B48" ref-type="bibr">1957</xref>; Russell, <xref rid="B51" ref-type="bibr">1980</xref>). Because extreme valence is correlated with higher arousal (e.g., Bradley and Lang, <xref rid="B7" ref-type="bibr">1999</xref>), positive and negative words, when compared with neutral words, also tend to have higher associated levels of arousal. In terms of their semantics, emotion words, broadly construed, can either express an emotional state (e.g., <italic>happy, panic</italic>) or elicit one (e.g., <italic>puppy, shark</italic>).</p><p>Investigations of emotion word processing have often examined different categories of emotion words, controlled for different lexical variables, and used diverse experimental paradgims, making direct comparisons and generalizations difficult (Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>). Until more recently, most studies did not compare positive, negative, and neutral words within an experiment, but instead examine only two of these three categories or sometimes words comprising specific emotional categories (e.g., happiness, sadness). Nonetheless, a processing advantage for positive over neutral words is generally demonstrated (e.g., Kanske and Kotz, <xref rid="B31" ref-type="bibr">2007</xref>; Kuchinke et al., <xref rid="B39" ref-type="bibr">2007</xref>; Kousta et al., <xref rid="B38" ref-type="bibr">2009</xref>; Schacht and Sommer, <xref rid="B52" ref-type="bibr">2009</xref>; Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B55" ref-type="bibr">2014</xref>; Sheikh and Titone, <xref rid="B60" ref-type="bibr">2013</xref>; Knickerbocker et al., <xref rid="B37" ref-type="bibr">2015</xref>). Some studies have shown an advantage for negative over neutral words (e.g., Tabert et al., <xref rid="B63" ref-type="bibr">2001</xref>; Windmann et al., <xref rid="B70" ref-type="bibr">2002</xref>; Nakic et al., <xref rid="B45" ref-type="bibr">2006</xref>; Kanske and Kotz, <xref rid="B31" ref-type="bibr">2007</xref>; Kousta et al., <xref rid="B38" ref-type="bibr">2009</xref>; Schacht and Sommer, <xref rid="B52" ref-type="bibr">2009</xref>; Knickerbocker et al., <xref rid="B37" ref-type="bibr">2015</xref>). Others have shown an advantage for positive over negative words (e.g., Kiehl et al., <xref rid="B33" ref-type="bibr">1999</xref>; Wentura et al., <xref rid="B68" ref-type="bibr">2000</xref>; Dahl, <xref rid="B11" ref-type="bibr">2001</xref>; Atchley et al., <xref rid="B1" ref-type="bibr">2003</xref>; Estes and Adelman, <xref rid="B18" ref-type="bibr">2008</xref>; Citron et al., <xref rid="B8" ref-type="bibr">2014</xref>; Kuperman et al., <xref rid="B41" ref-type="bibr">2014</xref>).</p><p>Research of ours and of others has investigated the interaction of emotion with word frequency (Kuchinke et al., <xref rid="B39" ref-type="bibr">2007</xref>; Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B55" ref-type="bibr">2014</xref>; M&#x000e9;ndez-B&#x000e9;rtolo et al., <xref rid="B43" ref-type="bibr">2011</xref>; Sheikh and Titone, <xref rid="B60" ref-type="bibr">2013</xref>). A word frequency effect represents the behavioral advantage in recognizing commonly used high frequency (HF) words over low frequency (LF) words that occur less often (e.g., Hand et al., <xref rid="B23" ref-type="bibr">2010</xref>, <xref rid="B24" ref-type="bibr">2012</xref>). A word frequency effect is considered to be a reliable indicator of lexical access (e.g., Sereno and Rayner, <xref rid="B59" ref-type="bibr">2003</xref>). Consequently, an interaction between word emotionality and frequency would imply that a word's emotional quality can influence the early, lexical stages of word recognition. Scott et al. (<xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B55" ref-type="bibr">2014</xref>) have found such an interaction in lexical decision reaction times (RTs), in brain electrophysiology measures, and in eye fixation durations during fluent reading. The pattern of behavioral effects is as follows: for LF words, positive and negative word responses are faster than neutral word responses; for HF words, positive word responses alone are faster than negative or neutral word responses (which do not differ from each other). The differential pattern of responses to negative words across frequency may be able to account for the different patterns of emotion word effects in the literature in that different studies may have used different ratios of higher and lower frequency negative words within their stimulus sets. Nevertheless, converging evidence from recent brain electrophysiological studies has confirmed an early, lexical (i.e., before ~250 ms) locus of emotion in word recognition tasks (Herbert et al., <xref rid="B26" ref-type="bibr">2006</xref>, <xref rid="B25" ref-type="bibr">2008</xref>; Kissler et al., <xref rid="B35" ref-type="bibr">2007</xref>, <xref rid="B36" ref-type="bibr">2009</xref>; Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>; Bayer et al., <xref rid="B3" ref-type="bibr">2012</xref>; Kissler and Herbert, <xref rid="B34" ref-type="bibr">2013</xref>; Keuper et al., <xref rid="B32" ref-type="bibr">2014</xref>; Zhang et al., <xref rid="B72" ref-type="bibr">2014</xref>).</p><p>Another factor that influences the recognition of emotion words is the mood state of the reader. According to Bower's (<xref rid="B6" ref-type="bibr">1981</xref>) notion of mood congruency, there is a link between mood state and cognitive processes such as attention and memory, whereby processing is facilitated when the affective tone of received information matches the valence of the mood. A mood can be reliably induced in individuals via several different laboratory procedures (Martin, <xref rid="B42" ref-type="bibr">1990</xref>), including the self-statement or Velten (<xref rid="B67" ref-type="bibr">1968</xref>) technique, music listening (V&#x000e4;stfj&#x000e4;ll, <xref rid="B66" ref-type="bibr">2002</xref>), film watching, and hypnotic suggestion. For word recognition experiments, inducing mood via the non-verbal method of listening to instrumental music is generally preferred.</p><p>A number of studies have investigated mood effects on the recognition of emotion words (e.g., Small, <xref rid="B61" ref-type="bibr">1985</xref>; Halberstadt et al., <xref rid="B22" ref-type="bibr">1995</xref>; Niedenthal et al., <xref rid="B46" ref-type="bibr">1997</xref>; Olafson and Ferraro, <xref rid="B47" ref-type="bibr">2001</xref>; Ferraro et al., <xref rid="B19" ref-type="bibr">2003</xref>). In these studies, a mood is first induced in participants by having them listen to either &#x0201c;happy&#x0201d; or &#x0201c;sad&#x0201d; music, and this is followed by a word recognition task (sometimes the music is also played in the background during the task). In general, these studies find that mood-congruent words are facilitated relative to mood-incongruent words. However, there are certain methodological concerns which may weaken the generalizability of the findings. We focus on the three studies that used lexical decision as the response time measure (Niedenthal et al., <xref rid="B46" ref-type="bibr">1997</xref>; Olafson and Ferraro, <xref rid="B47" ref-type="bibr">2001</xref>; Ferraro et al., <xref rid="B19" ref-type="bibr">2003</xref>). In Halberstadt et al. (<xref rid="B22" ref-type="bibr">1995</xref>), participants wrote down auditorily presented words that were purposely selected as homophones having both emotional and non-emotional realizations (e.g., <italic>won, one</italic>). In Small (<xref rid="B61" ref-type="bibr">1985</xref>), words were presented tachistoscopically for increasing durations until they were identified.</p><p>Our concerns with the lexical decision studies were as follows. First, relatively few stimuli were used and lexical specifications of the stimuli were not always controlled or presented. Niedenthal et al.'s (<xref rid="B46" ref-type="bibr">1997</xref>) Experiments 1 and 2 used either six or eight words, respectively, within each of their four conditions (&#x0201c;happy words,&#x0201d; &#x0201c;sad words,&#x0201d; &#x0201c;love words,&#x0201d; and &#x0201c;anger words&#x0201d;) and equal numbers of neutral words (24 or 32, respectively). Olafson and Ferraro (<xref rid="B47" ref-type="bibr">2001</xref>) used 25 &#x0201c;happy words&#x0201d; and 25 &#x0201c;sad words&#x0201d; (which included homophones from Halberstadt et al., <xref rid="B22" ref-type="bibr">1995</xref>); no neutral words were included. Ferraro et al. (<xref rid="B19" ref-type="bibr">2003</xref>) replicated Olafson and Ferraro (<xref rid="B47" ref-type="bibr">2001</xref>) with identical stimuli, extending the original experiment by testing older adults (N.B., the stimuli are not listed in either study). In fact, neither of these studies presented any lexical characteristics of their stimuli (e.g., frequency, length, valence, arousal). In Niedenthal et al. (<xref rid="B46" ref-type="bibr">1997</xref>), the stimuli were not explicitly controlled for arousal&#x02014;happy words had numerically higher arousal values than the sad words (accd. to the norms of Bradley and Lang, <xref rid="B7" ref-type="bibr">1999</xref>). In terms of mood induction, Niedenthal et al.'s (<xref rid="B46" ref-type="bibr">1997</xref>) Experiment 2 was the only study to include a control group of participants that were not exposed to any mood-inducing music. The selection of music chosen to induce the different moods is another concern. Across all studies, many of the happy and sad music pieces used are relatively well-known (e.g., Mozart's &#x0201c;Eine Kleine Nacht Musik,&#x0201d; and Barber's &#x0201c;Adagio for Strings&#x0201d;). As such, individuals' own affective associations may or may not be consistent with the desired mood that was to be induced. In addition, the tempo of the sad music is much slower than that of the happy music, which should correspondingly affect RTs (e.g., K&#x000e4;mpfe et al., <xref rid="B30" ref-type="bibr">2010</xref>; Bottiroli et al., <xref rid="B5" ref-type="bibr">2014</xref>). In all three studies, only the discrete emotions of happy and sad were examined [although it may be that Olafson and Ferraro's (<xref rid="B47" ref-type="bibr">2001</xref>) happy and sad words could be classified more generally as positive and negative words]. It is possible that implementing the broader positive and negative categories, derived from the dimensions of valence and arousal, may also demonstrate facilitation within a mood-induction framework (e.g., Eerola and Vuoskoski, <xref rid="B16" ref-type="bibr">2011</xref>).</p><p>The current study attempted to address these concerns. As in our prior research (Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B55" ref-type="bibr">2014</xref>), we implemented an Emotion (Positive, Negative, Netural) &#x000d7; Frequency (LF, HF) design. We used a total of 240 words, with 40 words in each of the 6 conditions. Words were matched across conditions on an item-by-item basis for word frequency and length. We also used several sets of published norms to obtain values on all our stimuli for valence and arousal, as well as imageability and age of acquisition (AoA). We induced positive and negative mood and also had a control condition in which no mood was induced. Positive and negative music clips were selected from a variety of sources that we anticipated would make them less recognizable (e.g., from movie soundtracks), with the deliberate selection of positive and negative clips having similar tempos. Music clips were normed ahead of time to ensure that they were equally intense in valence and arousal. Finally, we sought to broaden the scope of both the induced mood and emotional stimuli from discrete to categorical emotions (i.e., from &#x0201c;happy&#x0201d; and &#x0201c;sad&#x0201d; to &#x0201c;positive&#x0201d; and &#x0201c;negative&#x0201d;).</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec><title>Participants</title><p>A total of 144 members of the University of Glasgow community participated in this study. All were native English speaking, had not been diagnosed with dyslexia, had normal or corrected-to-normal vision, had normal hearing, and were na&#x000ef;ve as to the purpose of the experiment. An additional nine participants took part in the study, but their data were excluded due to a high amount of data loss from word errors, non-word errors, and/or very slow responses. Participants were compensated for their time with either experimental credits or &#x000a3;5. All participants gave written informed consent and the experimental procedure was approved by the College of Science and Engineering Ethics Committee at the University of Glasgow.</p><p>Participants were opportunistically assigned to one of the three mood groups&#x02014;Control, Positive, and Negative. All groups comprised 48 participants. The average age and number of females within each group were as follows: 22 years and 35 females for the Control group; 23 years and 31 females for the Positive group; and 24 years and 39 females for the Negative group.</p></sec><sec><title>Design and materials</title><p>A 3 (Mood: Control, Positive, Negative) &#x000d7; 3 (Emotion: Positive, Negative, Neutral) &#x000d7; 2 (Frequency: LF, HF) mixed design was used. Mood was the between-participants factor and was implemented via a mood-induction procedure for Positive and Negative groups (no mood induction was used for the Control group). Emotion and Frequency were within-participant factors and the different levels of these factors were achieved via stimulus selection based on existing norms and databases.</p><sec><title>Mood induction stimuli</title><p>In accordance with previous studies, pieces of music were used to induce positive or negative mood (e.g., Eerola et al., <xref rid="B15" ref-type="bibr">2009</xref>; Eerola and Vuoskoski, <xref rid="B16" ref-type="bibr">2011</xref>). In order to select the appropriate music, a norming study was run on a set of 28 participants (mean age 20 years; 19 females), none of whom (later) took part in the main experiment. In view of constraints of the main experiment, it was necessary to have a large selection of musical pieces to contribute to the mood induction procedures. The participants were run in small groups in sessions lasting ~1.5 h. They were presented with 52 music clips, each lasting around 1 min. Participants were asked to rate each clip in terms of its valence and arousal, both on 9-point scales. Valence ranged from 1 (low, negative) to 9 (high, positive) and arousal ranged from 1 (low) to 9 (high). For each clip, participants were also asked to indicate whether they recognized it.</p><p>Based on the average valence and arousal ratings, individual pieces were then chosen for inclusion in the main experiment for mood induction. Positive music selections had valence ratings greater than 6 and negative music selections had valence ratings less than 4. Both positive and negative music selections had comparable arousal ratings of around 6. Since the main experiment included a large number of trials, we wanted to ensure that participants' moods were maintained throughout the experiment. Thus, we opted for three separate musical mood-induction exposures, each lasting around 5 min. Each 5-min set of music comprised five different pieces, with a total of 15 pieces for each mood induced. For these pieces (15 positive, 15 negative), participants' recognition rate was 19%. Thus, on average, participants reported recognizing just under three of the 15 pieces for each mood set. A complete list of the selected music is presented in Appendix A. The valence and arousal ratings (with SDs) from the final sets of positive and negative music are presented in Table <xref ref-type="table" rid="T1">1</xref>.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Means (with SDs) of music specifications for Positive and Negative mood conditions</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Music</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Set</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Duration</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Valence</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Arousal</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Positive</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1</bold></td><td valign="top" align="center" rowspan="1" colspan="1">319</td><td valign="top" align="center" rowspan="1" colspan="1">7.6 (1.1)</td><td valign="top" align="center" rowspan="1" colspan="1">6.0 (1.6)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>2</bold></td><td valign="top" align="center" rowspan="1" colspan="1">314</td><td valign="top" align="center" rowspan="1" colspan="1">7.4 (1.2)</td><td valign="top" align="center" rowspan="1" colspan="1">6.0 (1.5)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>3</bold></td><td valign="top" align="center" rowspan="1" colspan="1">299</td><td valign="top" align="center" rowspan="1" colspan="1">7.5 (1.1)</td><td valign="top" align="center" rowspan="1" colspan="1">5.8 (1.7)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Negative</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1</bold></td><td valign="top" align="center" rowspan="1" colspan="1">317</td><td valign="top" align="center" rowspan="1" colspan="1">2.7 (1.3)</td><td valign="top" align="center" rowspan="1" colspan="1">6.0 (2.0)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>2</bold></td><td valign="top" align="center" rowspan="1" colspan="1">306</td><td valign="top" align="center" rowspan="1" colspan="1">2.6 (1.2)</td><td valign="top" align="center" rowspan="1" colspan="1">6.1 (1.7)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>3</bold></td><td valign="top" align="center" rowspan="1" colspan="1">298</td><td valign="top" align="center" rowspan="1" colspan="1">2.7 (1.4)</td><td valign="top" align="center" rowspan="1" colspan="1">5.9 (1.9)</td></tr></tbody></table><table-wrap-foot><p><italic>Units of measurement are as follows: Duration in seconds; Valence on a scale from 1 (low, negative) to 9 (high, positive); Arousal on a scale from 1 (low) to 9 (high)</italic>.</p></table-wrap-foot></table-wrap></sec><sec><title>Lexical decision stimuli</title><p>The 3 (Emotion: Positive, Negative, Neutral) &#x000d7; 2 (Frequency: LF, HF) design gave rise to 6 conditions. With 40 words in each of the 6 conditions, the lexical decision experiment comprised a total of 240 words, ranging from 3 to 9 characters in length. Non-words comprised 240 pronounceable, orthographically legal pseudowords that were matched to word stimuli in terms of string length (e.g., <italic>wid, felp, chire, narvey, bruddle, durledge, slamperic</italic>). Words were matched across the 6 conditions on an item-by-item basis for word frequency (occurrences per million) and word length (number of letters). The complete list of 240 words is presented in Appendix B. The specifications of the words in terms of length, frequency, valence, and arousal are presented in Table <xref ref-type="table" rid="T2">2</xref>. Other word characteristics that were not directly controlled for, but were matched as best as possible across conditions, are also presented in Table <xref ref-type="table" rid="T2">2</xref>. These include number of syllables, imageability (i.e., whether a word represents something that is easy or difficult to imagine or picture), age of acquisition (AoA; i.e., the age at which a word was initially learned), and grammatical class.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Means (with SDs) of target specifications across experimental conditions</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Variable</bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>LF</bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>HF</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Length</bold></td><td valign="top" align="center" rowspan="1" colspan="1">5.8 (1.5)</td><td valign="top" align="center" rowspan="1" colspan="1">5.7 (1.4)</td><td valign="top" align="center" rowspan="1" colspan="1">5.6 (1.3)</td><td valign="top" align="center" rowspan="1" colspan="1">5.8 (1.5)</td><td valign="top" align="center" rowspan="1" colspan="1">5.7 (1.6)</td><td valign="top" align="center" rowspan="1" colspan="1">5.8 (1.2)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Frequency</bold></td><td valign="top" align="center" rowspan="1" colspan="1">9.0 (4.5)</td><td valign="top" align="center" rowspan="1" colspan="1">9.4 (5.0)</td><td valign="top" align="center" rowspan="1" colspan="1">9.3 (4.8)</td><td valign="top" align="center" rowspan="1" colspan="1">65.8 (51)</td><td valign="top" align="center" rowspan="1" colspan="1">63.3 (54)</td><td valign="top" align="center" rowspan="1" colspan="1">62.6 (47)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Valence</bold></td><td valign="top" align="center" rowspan="1" colspan="1">7.6 (0.5)</td><td valign="top" align="center" rowspan="1" colspan="1">2.4 (0.4)</td><td valign="top" align="center" rowspan="1" colspan="1">5.1 (0.6)</td><td valign="top" align="center" rowspan="1" colspan="1">7.8 (0.5)</td><td valign="top" align="center" rowspan="1" colspan="1">2.4 (0.6)</td><td valign="top" align="center" rowspan="1" colspan="1">5.3 (0.4)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Arousal</bold></td><td valign="top" align="center" rowspan="1" colspan="1">5.9 (0.8)</td><td valign="top" align="center" rowspan="1" colspan="1">6.1 (0.7)</td><td valign="top" align="center" rowspan="1" colspan="1">4.1 (0.7)</td><td valign="top" align="center" rowspan="1" colspan="1">6.1 (0.7)</td><td valign="top" align="center" rowspan="1" colspan="1">6.3 (0.8)</td><td valign="top" align="center" rowspan="1" colspan="1">4.0 (0.5)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Syllables</bold></td><td valign="top" align="center" rowspan="1" colspan="1">1.9 (0.8)</td><td valign="top" align="center" rowspan="1" colspan="1">1.8 (0.6)</td><td valign="top" align="center" rowspan="1" colspan="1">1.7 (0.6)</td><td valign="top" align="center" rowspan="1" colspan="1">1.8 (0.7)</td><td valign="top" align="center" rowspan="1" colspan="1">1.8 (0.7)</td><td valign="top" align="center" rowspan="1" colspan="1">1.9 (0.6)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Imageability</bold></td><td valign="top" align="center" rowspan="1" colspan="1">4.9 (1.1)</td><td valign="top" align="center" rowspan="1" colspan="1">4.7 (1.0)</td><td valign="top" align="center" rowspan="1" colspan="1">5.0 (1.2)</td><td valign="top" align="center" rowspan="1" colspan="1">5.0 (0.9)</td><td valign="top" align="center" rowspan="1" colspan="1">4.7 (0.8)</td><td valign="top" align="center" rowspan="1" colspan="1">4.9 (1.2)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>AoA</bold></td><td valign="top" align="center" rowspan="1" colspan="1">3.9 (1.2)</td><td valign="top" align="center" rowspan="1" colspan="1">3.9 (0.9)</td><td valign="top" align="center" rowspan="1" colspan="1">3.5 (0.9)</td><td valign="top" align="center" rowspan="1" colspan="1">3.3 (0.8)</td><td valign="top" align="center" rowspan="1" colspan="1">3.7 (0.9)</td><td valign="top" align="center" rowspan="1" colspan="1">3.3 (0.9)</td></tr><tr><td valign="top" align="left" colspan="7" rowspan="1"><bold>PoS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;Adjective</bold></td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">0.28</td><td valign="top" align="center" rowspan="1" colspan="1">0.23</td><td valign="top" align="center" rowspan="1" colspan="1">0.35</td><td valign="top" align="center" rowspan="1" colspan="1">0.25</td><td valign="top" align="center" rowspan="1" colspan="1">0.13</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;Noun</bold></td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.63</td><td valign="top" align="center" rowspan="1" colspan="1">0.73</td><td valign="top" align="center" rowspan="1" colspan="1">0.78</td><td valign="top" align="center" rowspan="1" colspan="1">0.70</td><td valign="top" align="center" rowspan="1" colspan="1">0.93</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;Verb</bold></td><td valign="top" align="center" rowspan="1" colspan="1">0.33</td><td valign="top" align="center" rowspan="1" colspan="1">0.43</td><td valign="top" align="center" rowspan="1" colspan="1">0.20</td><td valign="top" align="center" rowspan="1" colspan="1">0.18</td><td valign="top" align="center" rowspan="1" colspan="1">0.43</td><td valign="top" align="center" rowspan="1" colspan="1">0.20</td></tr></tbody></table><table-wrap-foot><p><italic>LF, low frequency; HF, high frequency; AoA, age of acquisition; PoS, part of speech. Units of measurement are as follows: Length in number of letters; Frequency in occurrences per million; Arousal on a scale from 1 (low) to 9 (high); Valence on a scale from 1 (low, negative) to 9 (high, positive); Syllables in number of syllables; Imageability on a scale from 1 (low) to 7 (high); AoA on a scale from 1 (early) to 7 (late). For PoS, the grammatical class of each word was determined (some words were classified as belonging to more than one class), and the average frequencies of Adjective, Noun, and Verb usage across conditions are listed</italic>.</p></table-wrap-foot></table-wrap><p>The different types of emotion words were determined by their valence values from the Affective Norms for English Words (ANEW), a database of 1000 words (Bradley and Lang, <xref rid="B7" ref-type="bibr">1999</xref>). Each word has associated ratings for valence, from 1 (low, having a negative meaning) to 9 (high, having a positive meaning), and for arousal, from 1 (low) to 9 (high). As extreme valence values correlate with higher levels of arousal (Bradley and Lang, <xref rid="B7" ref-type="bibr">1999</xref>), Positive and Negative words also tended to have higher arousal ratings. Mean valence and arousal values (with SDs) across all word conditions are presented in Table <xref ref-type="table" rid="T2">2</xref>.</p><p>Word frequencies were obtained from the British National Corpus (BNC; <ext-link ext-link-type="uri" xlink:href="http://www.natcorp.ox.ac.uk">http://www.natcorp.ox.ac.uk</ext-link>), a corpus of 90 million written-word tokens, using the on-line resource provided by Davies (<xref rid="B13" ref-type="bibr">2004</xref>; <ext-link ext-link-type="uri" xlink:href="http://corpus.byu.edu/bnc">http://corpus.byu.edu/bnc</ext-link>). Word frequencies (with SDs) across all conditions are presented in Table <xref ref-type="table" rid="T2">2</xref>.</p><p>While the chief variables affecting the speed of recognizing a word are its length, frequency, and contextual predictability, several other lexical variables are also known to influence processing of words (e.g., Sereno et al., <xref rid="B58" ref-type="bibr">2009</xref>; Yao et al., <xref rid="B71" ref-type="bibr">2013</xref>). For example, high imageable or early AoA words are facilitated relative to low imageable or late AoA words (e.g., Juhasz and Rayner, <xref rid="B29" ref-type="bibr">2003</xref>; Balota et al., <xref rid="B2" ref-type="bibr">2004</xref>; Sereno and O'Donnell, <xref rid="B57" ref-type="bibr">2009</xref>). In addition, the grammatical class of a word also affects its processing (e.g., Sereno, <xref rid="B56" ref-type="bibr">1999</xref>; Palazova et al., <xref rid="B49" ref-type="bibr">2011</xref>). Means (with SDs) of these variables across all conditions are presented in Table <xref ref-type="table" rid="T2">2</xref>. Imageability ratings were obtained from five sources: the Bristol Norms (Stadthagen-Gonzalez and Davis, <xref rid="B62" ref-type="bibr">2006</xref>), the MRC Psycholinguistic Database (Wilson, <xref rid="B69" ref-type="bibr">1988</xref>), and norms of Bird et al. (<xref rid="B4" ref-type="bibr">2001</xref>), Clark and Paivio (<xref rid="B9" ref-type="bibr">2004</xref>), and Cortese and Fugett (<xref rid="B10" ref-type="bibr">2004</xref>). AoA ratings were obtained from the first four sources listed for imageability as well as the norms of Morrison et al. (<xref rid="B44" ref-type="bibr">1997</xref>).</p></sec></sec><sec><title>Apparatus</title><p>Stimuli were presented via E-Prime 2.0 software (Psychology Software Tools, Pittsburgh, PA) on a Dell OptiPlex GX520 desktop computer and a 17&#x02033; LCD flat-screen monitor (1024 &#x000d7; 768 resolution; 75 Hz). Letter strings appeared in Courier New, 24-point bold font (black characters on a white background). At a viewing distance of ~84 cm, 2.3 characters of text subtended 1&#x000b0; of visual angle. Responses were made via the computer keyboard and were recorded with millisecond accuracy. Music was played through headphones and was adjusted to a comfortable volume.</p></sec><sec><title>Procedure</title><p>Participants were tested individually. They were given written information about the experiment and a consent form. Participants were assigned (in order of their arrival) to one of the three mood groups. Participants were given mood assessment sheets to rate the current state of their mood via the dimensions of valence and arousal (described below). Participants in all groups rated their mood at the beginning of the experiment. They were then given instructions for the lexical decision task. They were told that half of the stimuli were words and half were non-words and that they should respond as quickly and as accurately as possible. They were instructed to make word responses using their right forefinger on the &#x0201c;L&#x0201d; key (labeled &#x0201c;W&#x0201d;) and non-word responses with their left forefinger on the &#x0201c;S&#x0201d; key (labeled &#x0201c;NW&#x0201d;). They were then presented with a short practice block of items (<italic>N</italic> = 12) to become accustomed to the task.</p><p>Each trial consisted of the following events. A blank screen was initially presented for 1000 ms. A fixation cross (+) then appeared in the center of the screen for 200 ms, replaced by another blank screen for 500 ms. A letter string was then presented centrally until the participant responded. Experimental trials (240 words, 240 non-words) were presented in a different random order for each participant.</p><p>The lexical decision experiment was presented in three equal blocks of trials. Participants in the Control mood condition performed the experiment with short break periods preceding each block. The procedure for participants in the Positive and Negative mood conditions was as follows. For each of the three blocks, they first listened to a set of mood-appropriate music (~5 min), rated their mood, then proceeded with a block of lexical decision trials. Positive and Negative mood condition participants were not asked whether they recognized any of the music (a total of 15 clips over the course of the experiment). We thought this would disrupt the flow of the experiment. Moreover, as these participants were selected from the same participant pool as those who had provided ratings for the pieces (none were the same), we assumed that recognition rates would be similarly minimal. The experiment lasted ~30 min for the Control mood participants and 45 min for Positive and Negative mood participants.</p><p>The mood rating sheets provided the following information to participants. Valence was described as a measure of value or worth and used a 9-point scale from 1 (very negative) to 5 (neutral) to 9 (very positive). Scale endpoints of &#x0201c;very positive&#x0201d; and &#x0201c;very negative&#x0201d; would indicate that they felt very good and very bad, respectively. Arousal was described as a measure of excitement vs. calmness and used a 9-point scale from 1 (very low arousal) to 5 (intermediate arousal) to 9 (very high arousal). The scale endpoint of &#x0201c;very high arousal&#x0201d; would indicate that they felt stimulated, excited, frenzied, jittery, or wide-awake, and that of &#x0201c;very low arousal&#x0201d; would indicate feeling relaxed, calm, sluggish, dull, or sleepy.</p></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Mood induction manipulation check</title><p>At the outset of the experiment (prior to any mood induction procedure), all participants provided valence and arousal ratings of their current mood. Mean ratings (with SDs) across the participant groups are presented in Table <xref ref-type="table" rid="T3">3</xref>. A 1-factor analysis of variance (ANOVA) was carried out on the valence and arousal rating data comparing the three mood groups. No differences in ratings between mood groups were found either for valence [<italic>F</italic><sub>1(2, 141)</sub> = 1.09, <italic>p</italic> &#x0003e; 0.30] or for arousal [<italic>F</italic><sub>1</sub> &#x0003c; 1].</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p><bold>Means (with SDs) of valence and arousal ratings across mood groups during the experiment</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Measure</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Control Mood</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive Mood</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative Mood</bold></th></tr></thead><tbody><tr><td valign="top" align="left" colspan="4" style="background-color:#bbbdc0" rowspan="1"><bold>BEFORE EXPERIMENT</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Valence</bold></td><td valign="top" align="center" rowspan="1" colspan="1">6.0 (1.4)</td><td valign="top" align="center" rowspan="1" colspan="1">6.2 (1.4)</td><td valign="top" align="center" rowspan="1" colspan="1">6.4 (1.4)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Arousal</bold></td><td valign="top" align="center" rowspan="1" colspan="1">4.6 (1.8)</td><td valign="top" align="center" rowspan="1" colspan="1">4.9 (1.7)</td><td valign="top" align="center" rowspan="1" colspan="1">5.0 (1.7)</td></tr><tr><td valign="top" align="left" colspan="4" style="background-color:#bbbdc0" rowspan="1"><bold>AFTER MUSIC</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Valence</bold></td><td valign="top" align="center" rowspan="1" colspan="1">N/A</td><td valign="top" align="center" rowspan="1" colspan="1">6.6 (1.2)</td><td valign="top" align="center" rowspan="1" colspan="1">5.0 (1.3)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Arousal</bold></td><td valign="top" align="center" rowspan="1" colspan="1">N/A</td><td valign="top" align="center" rowspan="1" colspan="1">5.4 (1.4)</td><td valign="top" align="center" rowspan="1" colspan="1">5.8 (1.6)</td></tr></tbody></table><table-wrap-foot><p><italic>Units of measurement are as follows: Valence on a scale from 1 (low, negative) to 9 (high, positive); Arousal on a scale from 1 (low) to 9 (high)</italic>.</p></table-wrap-foot></table-wrap><p>For the Positive and Negative mood groups, participants listened to positive and negative music, respectively, before each of the three blocks of lexical decision trials. Participants in these mood groups provided additional ratings of their mood on each of these occasions. Mean valence and arousal ratings (with SDs) for Positive and Negative mood groups are presented in Table <xref ref-type="table" rid="T3">3</xref>. Paired-sample <italic>t</italic>-tests were carried out separately for Positive and Negative mood groups, comparing their pre-experiment to post-music valence and arousal mood ratings. The Positive mood group showed a significant increase in valence (+0.4) [<italic>t</italic><sub>(47)</sub>= 2.46, <italic>p</italic> &#x0003c; 0.05], and a marginal increase in arousal (+0.5) [<italic>t</italic><sub>(47)</sub> = 1.97, <italic>p</italic> = 0.055]. The Negative mood group showed a significant decrease in valence (&#x02212;1.4) [<italic>t</italic><sub>(47)</sub> = &#x02212;7.44, <italic>p</italic> &#x0003c; 0.001], as well as a significant increase in arousal (+0.8) [<italic>t</italic><sub>(47)</sub> = 3.36, <italic>p</italic> &#x0003c; 0.01].</p></sec><sec><title>Lexical decision data</title><p>For correct word responses (97.77% of the data), items having RTs less than 250 ms or greater than 1500 ms were first excluded. In addition, for each participant in each condition, items with RTs beyond two standard deviations of the mean were then excluded. These trimming procedures resulted in an average data loss of 5.78% per participant (~2 items per condition). Overall, participants on average provided RT data on 37 of the 40 possible items per condition.</p><p>The mean RT data across experimental conditions are presented in Table <xref ref-type="table" rid="T4">4</xref>. The RT means (with standard error bars) are presented in Figure <xref ref-type="fig" rid="F1">1</xref>. A three-way mixed design ANOVA was performed on the RT data both by participants (<italic>F</italic><sub>1</sub>) and by items (<italic>F</italic><sub>2</sub>). Mood (Control, Positive, Negative) was the between-participant factor; within-participant factors were the word variables of Emotion (Positive, Negative, Neutral) and Frequency (LF, HF). A summary of all RT main effects and interactions is presented in Table <xref ref-type="table" rid="T5">5</xref>. The mean percent error (%Error) data are also presented and similarly analyzed (see Tables <xref ref-type="table" rid="T4">4</xref>, <xref ref-type="table" rid="T5">5</xref>, and Figure <xref ref-type="fig" rid="F2">2</xref>). However, as errors only comprised 2.23% of the total data, our focus is on the RT data.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p><bold>RT and %Error means (with SDs) as a function of Mood (Control, Positive, Negative), Emotion (Positive, Negative, Neutral), and Frequency (LF, HF)</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Mood</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Frequency</bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>RT</bold></th><th rowspan="1" colspan="1"/><th valign="top" align="center" colspan="3" rowspan="1"><bold>%Error</bold></th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Neutral</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Control</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>LF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">573 (74)</td><td valign="top" align="center" rowspan="1" colspan="1">580 (75)</td><td valign="top" align="center" rowspan="1" colspan="1">585 (70)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">2.19 (2.5)</td><td valign="top" align="center" rowspan="1" colspan="1">2.92 (3.4)</td><td valign="top" align="center" rowspan="1" colspan="1">4.32 (3.6)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>HF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">541 (76)</td><td valign="top" align="center" rowspan="1" colspan="1">561 (75)</td><td valign="top" align="center" rowspan="1" colspan="1">561 (76)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.99 (2.0)</td><td valign="top" align="center" rowspan="1" colspan="1">1.20 (1.9)</td><td valign="top" align="center" rowspan="1" colspan="1">1.46 (1.8)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Positive</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>LF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">568 (65)</td><td valign="top" align="center" rowspan="1" colspan="1">562 (62)</td><td valign="top" align="center" rowspan="1" colspan="1">585 (64)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">1.98 (2.5)</td><td valign="top" align="center" rowspan="1" colspan="1">2.76 (3.1)</td><td valign="top" align="center" rowspan="1" colspan="1">4.17 (3.9)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>HF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">535 (66)</td><td valign="top" align="center" rowspan="1" colspan="1">544 (57)</td><td valign="top" align="center" rowspan="1" colspan="1">548 (64)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.83 (1.6)</td><td valign="top" align="center" rowspan="1" colspan="1">1.20 (2.0)</td><td valign="top" align="center" rowspan="1" colspan="1">1.09 (1.6)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Negative</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>LF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">552 (57)</td><td valign="top" align="center" rowspan="1" colspan="1">563 (61)</td><td valign="top" align="center" rowspan="1" colspan="1">585 (70)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">2.55 (3.1)</td><td valign="top" align="center" rowspan="1" colspan="1">2.45 (2.6)</td><td valign="top" align="center" rowspan="1" colspan="1">5.57 (5.0)</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>HF</bold></td><td valign="top" align="center" rowspan="1" colspan="1">522 (56)</td><td valign="top" align="center" rowspan="1" colspan="1">543 (63)</td><td valign="top" align="center" rowspan="1" colspan="1">542 (58)</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">1.09 (2.0)</td><td valign="top" align="center" rowspan="1" colspan="1">1.83 (2.5)</td><td valign="top" align="center" rowspan="1" colspan="1">1.51 (2.0)</td></tr></tbody></table><table-wrap-foot><p><italic>RT in ms; LF, low frequency; HF, high frequency</italic>.</p></table-wrap-foot></table-wrap><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Mean RT (ms), with SE bars, on words as a function of Mood (Control, Positive, Negative), Emotion (Positive, Negative, Neutral), and Frequency (LF, HF)</bold>. LF, low frequency; HF, high frequency.</p></caption><graphic xlink:href="fpsyg-06-01191-g0001"/></fig><table-wrap id="T5" position="float"><label>Table 5</label><caption><p><bold>Main effects and interactions by participants (<italic>F</italic><sub>1</sub>) and by items (<italic>F</italic><sub>2</sub>) for RT and %Error measures</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Source</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>df</italic></bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>RT</bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>%Error</bold></th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>F</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>MSE</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>p</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>F</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>MSE</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>p</italic></bold></th></tr></thead><tbody><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>MOOD</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2141</td><td valign="top" align="center" rowspan="1" colspan="1">1.13</td><td valign="top" align="center" rowspan="1" colspan="1">24,993</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003e;0.30</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2117</td><td valign="top" align="center" rowspan="1" colspan="1">17.70</td><td valign="top" align="center" rowspan="1" colspan="1">1292</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">1.42</td><td valign="top" align="center" rowspan="1" colspan="1">11</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003e;0.20</td></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>EMOTION</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2282</td><td valign="top" align="center" rowspan="1" colspan="1">102.78</td><td valign="top" align="center" rowspan="1" colspan="1">360</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">29.68</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2234</td><td valign="top" align="center" rowspan="1" colspan="1">69.81</td><td valign="top" align="center" rowspan="1" colspan="1">491</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">16.33</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>FREQUENCY</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">1141</td><td valign="top" align="center" rowspan="1" colspan="1">374.89</td><td valign="top" align="center" rowspan="1" colspan="1">539</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">118.83</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">1117</td><td valign="top" align="center" rowspan="1" colspan="1">249.33</td><td valign="top" align="center" rowspan="1" colspan="1">720</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">69.69</td><td valign="top" align="center" rowspan="1" colspan="1">10</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>EMOTION</bold> &#x000d7; <bold>FREQUENCY</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2282</td><td valign="top" align="center" rowspan="1" colspan="1">26.84</td><td valign="top" align="center" rowspan="1" colspan="1">334</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">21.73</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2234</td><td valign="top" align="center" rowspan="1" colspan="1">20.46</td><td valign="top" align="center" rowspan="1" colspan="1">415</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">9.04</td><td valign="top" align="center" rowspan="1" colspan="1">9</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>MOOD</bold> &#x000d7; <bold>EMOTION</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">4282</td><td valign="top" align="center" rowspan="1" colspan="1">4.88</td><td valign="top" align="center" rowspan="1" colspan="1">360</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.001</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">4234</td><td valign="top" align="center" rowspan="1" colspan="1">2.97</td><td valign="top" align="center" rowspan="1" colspan="1">491</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 0.05</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>MOOD</bold> &#x000d7; <bold>FREQUENCY</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2141</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">2117</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" colspan="8" style="background-color:#bbbdc0" rowspan="1"><bold>MOOD</bold> &#x000d7; <bold>EMOTION</bold> &#x000d7; <bold>FREQUENCY</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>1</sub></td><td valign="top" align="center" rowspan="1" colspan="1">4282</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">2.00</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">=0.095</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic><sub>2</sub></td><td valign="top" align="center" rowspan="1" colspan="1">4234</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c; 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr></tbody></table><table-wrap-foot><p><italic>MSE, mean squared error</italic>.</p></table-wrap-foot></table-wrap><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Mean %Error, with SE bars, on words as a function of Mood (Control, Positive, Negative), Emotion (Positive, Negative, Neutral), and Frequency (LF, HF)</bold>. LF, low frequency; HF, high frequency.</p></caption><graphic xlink:href="fpsyg-06-01191-g0002"/></fig><sec><title>RTs</title><sec><title>Main effects</title><p>The between group factor of Mood was not significant by participants, but was significant by items (see Table <xref ref-type="table" rid="T5">5</xref>). This disparity resulted from the much higher level of variance among participants than items (evidenced in the <italic>MSE</italic>s). Unlike participants, items were matched across groups. Bonferroni pairwise comparisons in the items analysis showed that participants in the Control mood condition (571 ms) were slower than those in both the Positive (557 ms) and Negative (552 ms) mood conditions [<italic>p</italic><sub>2</sub>s &#x0003c; 0.001], which did not differ from each other [<italic>p</italic><sub>2</sub>s &#x0003e; 0.30].</p><p>The main effect of Emotion was significant (see Table <xref ref-type="table" rid="T5">5</xref>). Bonferroni pairwise comparisons by participants and items demonstrated reliable differences between all word types, with Positive words (548 ms) responded to faster than both Negative (559 ms) and Neutral (571 ms) words, which also significantly differed from each other [all <italic>p</italic>s &#x0003c; 0.001].</p><p>The main effect of Frequency was also significant (see Table <xref ref-type="table" rid="T5">5</xref>). Responses to HF words (544 ms) were faster than those to LF words (575 ms).</p></sec><sec><title>Interactions</title><p>Two of the interactions were significant: Emotion &#x000d7; Frequency and Mood &#x000d7; Emotion (see Table <xref ref-type="table" rid="T5">5</xref>). The associated RT means (with standard error bars) for these interactions are presented in Figures <xref ref-type="fig" rid="F2">2</xref>, <xref ref-type="fig" rid="F3">3</xref>, respectively. Neither the Mood &#x000d7; Frequency nor the Mood &#x000d7; Emotion &#x000d7; Frequency interactions were significant (see Table <xref ref-type="table" rid="T5">5</xref>).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Mean RT (ms), with SE bars, on words as a function of Emotion (Positive, Negative, Neutral) and Frequency (LF, HF)</bold>. LF, low frequency; HF, high frequency.</p></caption><graphic xlink:href="fpsyg-06-01191-g0003"/></fig><p>For the Emotion &#x000d7; Frequency interaction (see Figure <xref ref-type="fig" rid="F3">3</xref>), participant and item Bonferroni pairwise comparisons examined frequency effects for each type of emotion word and emotion word differences within each level of frequency. Word frequency effects were significant for all types of emotion words [all <italic>p</italic>s &#x0003c; 0.001]. RTs to HF Positive, Negative, and Neutral words (533, 550, and 550 ms, respectively) were faster than those to their LF counterparts (564, 568, and 592 ms, respectively). For LF words, RTs to Positive (564 ms) and Negative (568 ms) words were faster than those to Neutral words (592 ms) [<italic>p</italic>s &#x0003c; 0.001]. The LF Positive-Negative contrast was marginal by participants [<italic>p</italic><sub>1</sub> = 0.099], and not significant by items [<italic>p</italic><sub>2</sub> &#x0003e; 0.25]. For HF words, a different pattern emerged. RTs to HF Positive words (533 ms) were significantly faster than those to both HF Negative (550 ms) and Neutral (550 ms) words [all <italic>p</italic>s &#x0003c; 0.001], which did not differ from each other [all <italic>p</italic>s = 1].</p><p>For the Mood &#x000d7; Emotion interaction (see Figure <xref ref-type="fig" rid="F4">4</xref>), participant and item Bonferroni pairwise comparisons examined mood effects for each type of emotion word as well as emotion word differences within each level of mood. By participants, Control, Positive, and Negative mood groups did not differ significantly in their responses to Positive words (557, 551, and 536 ms, respectively), Negative words (571, 553, and 553 ms, respectively), nor Neutral words (583, 566, and 563 ms, respectively) [all <italic>p</italic><sub>1</sub>s &#x0003e; 0.35]. The lack of significance (given apparent differences) is due to the high variability in RTs across participants. Item variability, in contrast, is much less as items are matched across groups (cf. the main effect of Mood). By items, significant differences did emerge. The Control mood group was significantly slower than the Positive and Negative mood groups in response to Negative words (571 ms vs. 553 and 553 ms, respectively) [<italic>p</italic><sub>2</sub>s &#x0003c; 0.001] and to Neutral words (583 ms vs. 566 and 563 ms, respectively) [<italic>p</italic><sub>2</sub>s &#x0003c; 0.01]. Positive and Negative mood groups did not differ in response to either Negative or Neutral words [<italic>p</italic><sub>2</sub>s = 1]. In partial contrast, both the Control and Positive mood groups were significantly slower than the Negative mood group in response to Positive words (557 and 551 ms vs. 536 ms, respectively) [<italic>p</italic><sub>2</sub>s &#x0003c; 0.001]. The difference between Control and Positive mood groups to Positive words was not significant [<italic>p</italic><sub>2</sub> &#x0003e; 0.15].</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Mean RT (ms), with SE bars, on words as a function of Mood (Control, Positive, Negative) and Emotion (Positive, Negative, Neutral)</bold>.</p></caption><graphic xlink:href="fpsyg-06-01191-g0004"/></fig><p>Participant and item Bonferroni pairwise comparisons also examined emotion word differences within each level of mood. Within the Control mood group, Positive words (557 ms) were responded to faster than Negative words (571 ms), and both types of words were responded to faster than Neutral words (583 ms) [all <italic>p</italic>s &#x0003c; 0.001]. A similar pattern emerged for the Negative mood group: Positive words (537 ms) were responded to faster than Negative words (553 ms), and both types of words were responded to faster than Neutral words (563 ms) [all <italic>p</italic>s &#x0003c; 0.01]. Within the Positive mood group, however, there was no difference between Positive (551 ms) and Negative (553 ms) words [all <italic>p</italic>s = 1], although both types of emotion words were responded to faster than Neutral words (566 ms) [all <italic>p</italic>s &#x0003c; 0.001].</p></sec></sec><sec><title>%Error</title><sec><title>Main effects</title><p>The between group effect of Mood was not significant (see Table <xref ref-type="table" rid="T5">5</xref>). Similar to the RT findings, the within-participant effects of Emotion and Frequency were both significant (see Table <xref ref-type="table" rid="T5">5</xref>). For Emotion, Bonferroni pairwise comparisons by participants and items demonstrated that more errors were reliably made with Neutral (3.02%) compared to both Positive (1.61%) and Negative (2.06%) words [all <italic>p</italic>s &#x0003c; 0.001]. Errors to Positive and Negative words differed significantly by participants [<italic>p</italic><sub>1</sub> &#x0003c; 0.05], but marginally by items [<italic>p</italic><sub>2</sub> = 0.071]. For Frequency, participants made fewer errors on HF (1.24%) than on LF (3.21%) words.</p></sec><sec><title>Interactions</title><p>The only interaction that was significant was Emotion &#x000d7; Frequency (see Table <xref ref-type="table" rid="T5">5</xref>). Participant and item Bonferroni pairwise comparisons examined frequency effects for each type of emotion word and emotion word differences within each level of frequency. Word frequency effects were significant for all types of emotion words [all <italic>p</italic>s &#x0003c; 0.001]. The percentage of errors on HF Positive, Negative, and Neutral words (0.97, 1.41, and 1.35%, respectively) was less than that on their LF counterparts (2.24, 2.71, and 4.69%, respectively). For LF words, significantly fewer errors were made on both Positive (2.24%) and Negative (2.71%) words in comparison to Neutral words (4.69%) [all <italic>p</italic>s &#x0003c; 0.001]. There was no difference between errors on Positive and Negative words [all <italic>p</italic>s &#x0003e; 0.20]. For HF words, none of the comparisons reached significance. The %Error on Positive words (0.97%) was marginally less than that on Negative words (1.41%) [<italic>p</italic><sub>1</sub> = 0.062, <italic>p</italic><sub>2</sub> = 0.086], and no different than that on Neutral words (1.35%) [all <italic>p</italic>s &#x0003e; 0.10]. Negative and Neutral words did not differ in %Error [all <italic>p</italic>s = 1].</p></sec></sec></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>The current study investigated effects of mood on emotion word recognition. While past studies have demonstrated mood-congruency effects (e.g., Niedenthal et al., <xref rid="B46" ref-type="bibr">1997</xref>; Olafson and Ferraro, <xref rid="B47" ref-type="bibr">2001</xref>; Ferraro et al., <xref rid="B19" ref-type="bibr">2003</xref>), they may be limited by the methodologies that were employed. For example, tight experimental control over lexical variables associated with the stimuli was not always implemented, baseline conditions (i.e., neutral words, no mood induction) were not always used, happy and sad mood-inducing music differed in tempo and arousal, and effects were restricted to discrete emotions (i.e., happy, sad). We attempted to address these concerns. In our study, our between-group factor of mood was induced via positive and negative music equated for intensity of valence and arousal. A no-mood control group was also included. In line with recent emotion word studies, we used an Emotion (Positive, Negative Neutral) &#x000d7; Frequency (LF, HF) stimulus design. Word stimuli (<italic>N</italic> = 240) varied systematically in valence and arousal and were explicitly controlled for word frequency and length. In contrast to the prior mood-induction studies, we also attempted to match stimuli as closely as possible for imageability, AoA, and grammatical class, although strict equivalences of these variables were not always achieved (see Table <xref ref-type="table" rid="T2">2</xref>) which could limit the generalizability of our findings.</p><p>We found main effects of Mood (significant only by items due to inter-participant variability), Emotion, and Frequency. Positive and Negative mood groups were faster overall in their responses than the Control (no music) group. This was most likely due to participants' relatively higher levels of arousal produced by the mood-inducing music (see Table <xref ref-type="table" rid="T3">3</xref>) as well as a possible consequence of the music's tempo (e.g., Husain et al., <xref rid="B28" ref-type="bibr">2002</xref>; K&#x000e4;mpfe et al., <xref rid="B30" ref-type="bibr">2010</xref>; Bottiroli et al., <xref rid="B5" ref-type="bibr">2014</xref>). The Emotion-Frequency results are similar to what we have found in the past (Scott et al., <xref rid="B53" ref-type="bibr">2009</xref>, <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B55" ref-type="bibr">2014</xref>). For Emotion, Positive words were responded to faster than Negative words, and both had faster responses than Neutral words. For Frequency, HF words were responded to faster than LF words. The Emotion &#x000d7; Frequency interaction arose from the pattern associated with Negative words&#x02014;responses to LF Negative words were as fast as Positive words (both faster than Neutral words), whereas responses to HF Negative words were as slow as Neutral words (both slower than Positive words). The relative slowing of responses to negative (vs. positive) stimuli has often been explained by differential effects at different stages of stimulus processing. Two-stage models of emotion word processing&#x02014;Taylor's (<xref rid="B64" ref-type="bibr">1991</xref>) mobilization-minimization hypothesis and Pratto and John's (<xref rid="B50" ref-type="bibr">1991</xref>) automatic vigilance hypothesis&#x02014;propose that all emotionally valenced words enjoy an initial facilitation relative to neutral words because of their high arousal, but that negative words are subsequently inhibited due to their low valence and, hence, inherent threat. This would predict a consistent advantage in processing for positive over neutral words, and an advantage for negative over neutral words under some circumstances. Scott et al. (<xref rid="B53" ref-type="bibr">2009</xref>) suggested that salience in the form of word frequency may be one such moderating factor. Various models of this process have been reviewed by Kuperman (<xref rid="B40" ref-type="bibr">2015</xref>) who distinguished between the &#x0201c;motivated attention&#x0201d; account, explaining equal speeding of positive and negative words, and the &#x0201c;automatic vigilance&#x0201d; account, which argues for fast attention capture in negative words but slower disengagement, producing a relative advantage for positive over negative words.</p><p>The main aim of our study, however, was to investigate the effect of mood on the processing of emotion words. We had expected to find mood-congruency effects within the more general categories of &#x0201c;positive&#x0201d; and &#x0201c;negative.&#x0201d; Although we found a significant Mood &#x000d7; Emotion interaction, it did not appear to be the result of mood-congruency effects (see Figure <xref ref-type="fig" rid="F4">4</xref>). Instead, we found that Neutral and Negative mood conditions behaved similarly, mirroring the main effect of Emotion (with fastest responses to Positive words, followed by Negative, then Neutral words). In the Positive mood condition, the relative advantage for Positive words disappeared&#x02014; responses to Positive and Negative words did not differ, but both were faster than responses to Neutral words. From these findings, we are left with two patterns of data to explain. First, for the Positive mood group, mood congruency would predict that responses to Positive words should be even faster than that found in a baseline (Control mood) condition. In fact, there was no difference between responses to Positive and Negative words. It is not clear whether this represents a relative slowing down of responses to Positive words or a relative speeding up of responses to Negative words. Second, for the Negative mood group, mood congruency would again predict that responses to Negative words should be speeded in comparison to the Control mood condition. On this view, responses to Negative words should be as fast or faster than those to Positive words. However, our results showed that the Negative mood group behaved no differently than the Control group, with the exception that the overall response time was speeded.</p><p>It has been proposed that internal affective cues can direct our attention, with positive mood focusing attention on the metaphorical forest and negative on the trees (e.g., Easterbrook, <xref rid="B14" ref-type="bibr">1959</xref>; Gasper and Clore, <xref rid="B21" ref-type="bibr">2002</xref>; Fredrickson and Branigan, <xref rid="B20" ref-type="bibr">2005</xref>; Huntsinger, <xref rid="B27" ref-type="bibr">2013</xref>). This is traditionally attributed to a broadening or narrowing of attention to the global or local level, respectively. Within this context, it becomes possible to account for the pattern of our findings. For the Positive mood group, a broadening of attention could diminish the impact of any negative content of words in the second stage of a two-stage processing mechanism, removing the need to inhibit the processing of negative stimuli and eliminating the difference in response time between positive and negative emotional stimuli. A positive mood might act as a buffer against potential threat inherent in negative stimuli (e.g., Das et al., <xref rid="B12" ref-type="bibr">2012</xref>). Under such circumstances, the initial processing advantage (or &#x0201c;mobilization&#x0201d;) enjoyed by negative words would not only be maintained, but would be preserved because the subsequent inhibition (or &#x0201c;minimization&#x0201d;) stage would not be prompted. In this way, positive mood could eliminate the category distinction of positive-negative valence but leave the high-low arousal dimension intact. For the Negative mood group, a narrowing of attention could enhance distinctions between words within each of the categories of Positive, Negative, and Neutral. Traditionally, emotions have been classified into six subtypes&#x02014;&#x0201c;happiness,&#x0201d; &#x0201c;surprise,&#x0201d; &#x0201c;sadness,&#x0201d; &#x0201c;anger,&#x0201d; &#x0201c;fear,&#x0201d; and &#x0201c;disgust&#x0201d; (e.g., Ekman and Friesen, <xref rid="B17" ref-type="bibr">1971</xref>). As such, negative emotions comprise a broader range of subtypes. Moreover, Unkelbach et al. (<xref rid="B65" ref-type="bibr">2008</xref>) have suggested that positive information is more densely clustered in semantic space than negative information, and this leads to processing benefits such as speeded access. As a consequence, a negative mood may only serve to enhance the intrinsic diversity of &#x0201c;negative&#x0201d; as a category and, thus, it may lose its potency as a facilitative agent, in particular, for negative words.</p><p>In sum, our study sought to investigate the effect of mood on emotion word recognition, notably by employing strict experimental controls over both the mood-inducing music as well as the word stimuli. Past studies have found mood-congruency effects, but only for the discrete emotions of &#x0201c;happy&#x0201d; and &#x0201c;sad.&#x0201d; We tried to extend these findings to the more general categories of &#x0201c;positive&#x0201d; and &#x0201c;negative.&#x0201d; Our findings did replicate prior studies in terms of the pattern of Emotion &#x000d7; Frequency effects. However, our Mood &#x000d7; Emotion interaction was not driven mood-congruency effects. Instead, it seemed that mood-induced attentional effects differentially modulated responses to emotion words when situated within the context of categories defined only by their valence and arousal.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We would like to thank A. M. Murray for her assistance with some of the data collection.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atchley</surname><given-names>R. A.</given-names></name><name><surname>Ilardi</surname><given-names>S. S.</given-names></name><name><surname>Enloe</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Hemispheric asymmetry in the processing of emotional content in word meanings: the effect of current and past depression</article-title>. <source>Brain Lang.</source>
<volume>84</volume>, <fpage>105</fpage>&#x02013;<lpage>119</lpage>. <pub-id pub-id-type="doi">10.1016/S0093-934X(02)00523-0</pub-id><pub-id pub-id-type="pmid">12537954</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balota</surname><given-names>D. A.</given-names></name><name><surname>Cortese</surname><given-names>M. J.</given-names></name><name><surname>Sergent-Marshall</surname><given-names>S. D.</given-names></name><name><surname>Spieler</surname><given-names>D. H.</given-names></name><name><surname>Yap</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <article-title>Visual word recognition of single-syllable words</article-title>. <source>J. Exp. Psychol. Gen.</source>
<volume>133</volume>, <fpage>283</fpage>&#x02013;<lpage>316</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.133.2.283</pub-id><pub-id pub-id-type="pmid">15149254</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bayer</surname><given-names>M.</given-names></name><name><surname>Sommer</surname><given-names>W.</given-names></name><name><surname>Schacht</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>P1 and beyond: functional separation of multiple emotion effects in word recognition</article-title>. <source>Psychophysiology</source>
<volume>49</volume>, <fpage>959</fpage>&#x02013;<lpage>969</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01381.x</pub-id><pub-id pub-id-type="pmid">22594767</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bird</surname><given-names>H.</given-names></name><name><surname>Franklin</surname><given-names>S.</given-names></name><name><surname>Howard</surname><given-names>D.</given-names></name></person-group> (<year>2001</year>). <article-title>Age of acquisition and imageability ratings for a large set of words, including verbs and function words</article-title>. <source>Behav. Res. Methods Instrum. Comput.</source>
<volume>33</volume>, <fpage>73</fpage>&#x02013;<lpage>79</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195349</pub-id><pub-id pub-id-type="pmid">11296722</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bottiroli</surname><given-names>S.</given-names></name><name><surname>Rosi</surname><given-names>A.</given-names></name><name><surname>Russo</surname><given-names>R.</given-names></name><name><surname>Vecchi</surname><given-names>T.</given-names></name><name><surname>Cavallini</surname><given-names>E.</given-names></name></person-group> (<year>2014</year>). <article-title>The cognitive effects of listening to background music on older adults: processing speed improves with upbeat music, while memory seems to benefit from both upbeat and downbeat music</article-title>. <source>Front. Aging Neurosci.</source>
<volume>6</volume>:<issue>284</issue>. <pub-id pub-id-type="doi">10.3389/fnagi.2014.00284</pub-id><pub-id pub-id-type="pmid">25360112</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bower</surname><given-names>G. H.</given-names></name></person-group> (<year>1981</year>). <article-title>Mood and memory</article-title>. <source>Am. Psychol.</source>
<volume>36</volume>, <fpage>129</fpage>&#x02013;<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1037/0003-066X.36.2.129</pub-id><pub-id pub-id-type="pmid">7224324</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>M. M.</given-names></name><name><surname>Lang</surname><given-names>P. J.</given-names></name></person-group> (<year>1999</year>). <source>Affective Norms for English Words (ANEW): Stimuli, Instruction Manual and Affective Ratings.</source> Technical Report C-1, The Center for Research in Psychophysiology, University of Florida.</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Citron</surname><given-names>F. M. M.</given-names></name><name><surname>Gray</surname><given-names>M. A.</given-names></name><name><surname>Critchley</surname><given-names>H. D.</given-names></name><name><surname>Weekes</surname><given-names>B. S.</given-names></name><name><surname>Ferstl</surname><given-names>E. C.</given-names></name></person-group> (<year>2014</year>). <article-title>Emotional valence and arousal affect reading in an interactive way: neuroimaging evidence for an approach-withdrawal framework</article-title>. <source>Neuropsychologia</source>
<volume>56</volume>, <fpage>79</fpage>&#x02013;<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.01.002</pub-id><pub-id pub-id-type="pmid">24440410</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>J. M.</given-names></name><name><surname>Paivio</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Extensions of the Paivio, Yuille, and Madigan (1968) norms</article-title>. <source>Behav. Res. Methods Instrum. Comput.</source>
<volume>36</volume>, <fpage>371</fpage>&#x02013;<lpage>383</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195584</pub-id><pub-id pub-id-type="pmid">15641426</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortese</surname><given-names>M. J.</given-names></name><name><surname>Fugett</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Imageability ratings for 3,000 monosyllabic words</article-title>. <source>Behav. Res. Methods Instrum. Comput.</source>
<volume>36</volume>, <fpage>384</fpage>&#x02013;<lpage>387</lpage>. <pub-id pub-id-type="doi">10.3758/BF03195585</pub-id><pub-id pub-id-type="pmid">15641427</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahl</surname><given-names>M.</given-names></name></person-group> (<year>2001</year>). <article-title>Asymmetries in the processing of emotionally valenced words</article-title>. <source>Scand. J. Psychol.</source>
<volume>42</volume>, <fpage>97</fpage>&#x02013;<lpage>104</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9450.00218</pub-id><pub-id pub-id-type="pmid">11321641</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Das</surname><given-names>E.</given-names></name><name><surname>Vonkeman</surname><given-names>C.</given-names></name><name><surname>Hartmann</surname><given-names>T.</given-names></name></person-group> (<year>2012</year>). <article-title>Mood as a resource in dealing with health recommendations: how mood affects information processing and acceptance of quit-smoking messages</article-title>. <source>Psychol. Health</source>
<volume>27</volume>, <fpage>116</fpage>&#x02013;<lpage>127</lpage>. <pub-id pub-id-type="doi">10.1080/08870446.2011.569888</pub-id><pub-id pub-id-type="pmid">21678163</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>M.</given-names></name></person-group> (<year>2004</year>). <source>BYU-BNC: The British National Corpus</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://corpus.byu.edu/bnc">http://corpus.byu.edu/bnc</ext-link></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Easterbrook</surname><given-names>J. A.</given-names></name></person-group> (<year>1959</year>). <article-title>The effect of emotion on cue utilization and the organization of behavior</article-title>. <source>Psychol. Rev.</source>
<volume>66</volume>, <fpage>183</fpage>&#x02013;<lpage>201</lpage>. <pub-id pub-id-type="doi">10.1037/h0047707</pub-id><pub-id pub-id-type="pmid">13658305</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eerola</surname><given-names>T.</given-names></name><name><surname>Lartillot</surname><given-names>O.</given-names></name><name><surname>Toiviainen</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Prediction of multidimensional emotional ratings in music from audio using multivariate regression models</article-title> in <source>Proceedings of the 10th International Society for Music Information Retrieval Conference (ISMIR)</source> (<publisher-loc>Kobe</publisher-loc>), <fpage>621</fpage>&#x02013;<lpage>626</lpage>.</mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eerola</surname><given-names>T.</given-names></name><name><surname>Vuoskoski</surname><given-names>J. K.</given-names></name></person-group> (<year>2011</year>). <article-title>A comparison of the discrete and dimensional models of emotion in music</article-title>. <source>Psychol. Music</source>
<volume>39</volume>, <fpage>18</fpage>&#x02013;<lpage>49</lpage>. <pub-id pub-id-type="doi">10.1177/0305735610362821</pub-id><pub-id pub-id-type="pmid">25813790</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P.</given-names></name><name><surname>Friesen</surname><given-names>W. V.</given-names></name></person-group> (<year>1971</year>). <article-title>Constants across cultures in the face and emotion</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>17</volume>, <fpage>124</fpage>&#x02013;<lpage>129</lpage>. <pub-id pub-id-type="doi">10.1037/h0030377</pub-id><pub-id pub-id-type="pmid">5542557</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estes</surname><given-names>Z.</given-names></name><name><surname>Adelman</surname><given-names>J. S.</given-names></name></person-group> (<year>2008</year>). <article-title>Automatic vigilance for negative words in lexical decision and naming: comment on Larsen, Mercer, and Balota (2006)</article-title>. <source>Emotion</source>
<volume>8</volume>, <fpage>441</fpage>&#x02013;<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1037/1528-3542.8.4.441</pub-id><pub-id pub-id-type="pmid">18729575</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferraro</surname><given-names>F. R.</given-names></name><name><surname>King</surname><given-names>B.</given-names></name><name><surname>Ronning</surname><given-names>B.</given-names></name><name><surname>Pekarski</surname><given-names>K.</given-names></name><name><surname>Risan</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>Effects of induced emotional state on lexical processing in younger and older adults</article-title>. <source>J. Psychol.</source>
<volume>137</volume>, <fpage>262</fpage>&#x02013;<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1080/00223980309600613</pub-id><pub-id pub-id-type="pmid">12795548</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fredrickson</surname><given-names>B. L.</given-names></name><name><surname>Branigan</surname><given-names>C.</given-names></name></person-group> (<year>2005</year>). <article-title>Positive emotions broaden the scope of attention and thought-action repertoires</article-title>. <source>Cogn. Emot.</source>
<volume>19</volume>, <fpage>313</fpage>&#x02013;<lpage>332</lpage>. <pub-id pub-id-type="doi">10.1080/02699930441000238</pub-id><pub-id pub-id-type="pmid">21852891</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gasper</surname><given-names>K.</given-names></name><name><surname>Clore</surname><given-names>G. L.</given-names></name></person-group> (<year>2002</year>). <article-title>Attending to the big picture: mood and global versus local processing of visual information</article-title>. <source>Psychol. Sci.</source>
<volume>13</volume>, <fpage>34</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9280.00406</pub-id><pub-id pub-id-type="pmid">11892776</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halberstadt</surname><given-names>J. B.</given-names></name><name><surname>Niedenthal</surname><given-names>P. M.</given-names></name><name><surname>Kushner</surname><given-names>J.</given-names></name></person-group> (<year>1995</year>). <article-title>Resolution of lexical ambiguity by emotional state</article-title>. <source>Psychol. Sci.</source>
<volume>6</volume>, <fpage>278</fpage>&#x02013;<lpage>282</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1995.tb00511.x</pub-id><pub-id pub-id-type="pmid">12825642</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hand</surname><given-names>C. J.</given-names></name><name><surname>Miellet</surname><given-names>S.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2010</year>). <article-title>The frequency-predictability interaction in reading: it depends where you're coming from</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
<volume>36</volume>, <fpage>1294</fpage>&#x02013;<lpage>1313</lpage>. <pub-id pub-id-type="doi">10.1037/a0020363</pub-id><pub-id pub-id-type="pmid">20854004</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hand</surname><given-names>C. J.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2012</year>). <article-title>Word-initial letters influence fixation durations during fluent reading</article-title>. <source>Front. Psychol. Lang. Sci.</source>
<volume>3</volume>:<issue>85</issue>. <pub-id pub-id-type="doi">10.3389/fpsyg.2012.00085</pub-id><pub-id pub-id-type="pmid">22485100</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herbert</surname><given-names>C.</given-names></name><name><surname>Junghofer</surname><given-names>M.</given-names></name><name><surname>Kissler</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>Event related potentials to emotional adjectives during reading</article-title>. <source>Psychophysiology</source>
<volume>45</volume>, <fpage>487</fpage>&#x02013;<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2007.00638.x</pub-id><pub-id pub-id-type="pmid">18221445</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herbert</surname><given-names>C.</given-names></name><name><surname>Kissler</surname><given-names>J.</given-names></name><name><surname>Jungh&#x000f6;fer</surname><given-names>M.</given-names></name><name><surname>Peyk</surname><given-names>P.</given-names></name><name><surname>Rockstroh</surname><given-names>B.</given-names></name></person-group> (<year>2006</year>). <article-title>Processing of emotional adjectives: evidence from startle EMG and ERPs</article-title>. <source>Psychophysiology</source>
<volume>43</volume>, <fpage>197</fpage>&#x02013;<lpage>206</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2006.00385.x</pub-id><pub-id pub-id-type="pmid">16712590</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huntsinger</surname><given-names>J. R.</given-names></name></person-group> (<year>2013</year>). <article-title>Does emotion directly tune the scope of attention?</article-title>
<source>Curr. Dir. Psychol. Sci.</source>
<volume>22</volume>, <fpage>265</fpage>&#x02013;<lpage>270</lpage>. <pub-id pub-id-type="doi">10.1177/0963721413480364</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Husain</surname><given-names>G.</given-names></name><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name></person-group> (<year>2002</year>). <article-title>Effects of musical tempo and mode on arousal, mood, and spatial abilities</article-title>. <source>Music Percept. Interdiscip. J.</source>
<volume>20</volume>, <fpage>151</fpage>&#x02013;<lpage>171</lpage>. <pub-id pub-id-type="doi">10.1525/mp.2002.20.2.151</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juhasz</surname><given-names>B. J.</given-names></name><name><surname>Rayner</surname><given-names>K.</given-names></name></person-group> (<year>2003</year>). <article-title>Investigating the effects of a set of intercorrelated variables on eye fixation durations in reading</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>29</volume>, <fpage>1312</fpage>&#x02013;<lpage>1318</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.29.6.1312</pub-id><pub-id pub-id-type="pmid">14622063</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000e4;mpfe</surname><given-names>J.</given-names></name><name><surname>Sedlmeier</surname><given-names>P.</given-names></name><name><surname>Renkewitz</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>The impact of background music on adult listeners: a meta-analysis</article-title>. <source>Psychol. Music</source>
<volume>39</volume>, <fpage>424</fpage>&#x02013;<lpage>448</lpage>. <pub-id pub-id-type="doi">10.1177/0305735610376261</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanske</surname><given-names>P.</given-names></name><name><surname>Kotz</surname><given-names>S. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Concreteness in emotional words: ERP evidence from a hemifield study</article-title>. <source>Brain Res.</source>
<volume>1148</volume>, <fpage>138</fpage>&#x02013;<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1016/j.brainres.2007.02.044</pub-id><pub-id pub-id-type="pmid">17391654</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keuper</surname><given-names>K.</given-names></name><name><surname>Zwanzger</surname><given-names>P.</given-names></name><name><surname>Nordt</surname><given-names>M.</given-names></name><name><surname>Eden</surname><given-names>A.</given-names></name><name><surname>Laeger</surname><given-names>I.</given-names></name><name><surname>Zwitserlood</surname><given-names>P.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>How &#x02018;love&#x02019; and &#x02018;hate&#x02019; differ from &#x02018;sleep&#x02019;: using combined electro/magnetoencephalographic data to reveal the sources of early cortical responses to emotional words</article-title>. <source>Hum. Brain Mapp.</source>
<volume>35</volume>, <fpage>875</fpage>&#x02013;<lpage>888</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22220</pub-id><pub-id pub-id-type="pmid">23281129</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiehl</surname><given-names>K. A.</given-names></name><name><surname>Hare</surname><given-names>R. D.</given-names></name><name><surname>McDonald</surname><given-names>J. J.</given-names></name><name><surname>Brink</surname><given-names>J.</given-names></name></person-group> (<year>1999</year>). <article-title>Semantic and affective processing in psychopaths: an event-related potential (ERP) study</article-title>. <source>Psychophysiology</source>
<volume>36</volume>, <fpage>765</fpage>&#x02013;<lpage>774</lpage>. <pub-id pub-id-type="doi">10.1111/1469-8986.3660765</pub-id><pub-id pub-id-type="pmid">10554590</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kissler</surname><given-names>J.</given-names></name><name><surname>Herbert</surname><given-names>C.</given-names></name></person-group> (<year>2013</year>). <article-title>Emotion, etmnooi, or emitoon? Faster lexical access to emotional than to neutral words during reading</article-title>. <source>Biol. Psychol.</source>
<volume>92</volume>, <fpage>464</fpage>&#x02013;<lpage>479</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2012.09.004</pub-id><pub-id pub-id-type="pmid">23059636</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kissler</surname><given-names>J.</given-names></name><name><surname>Herbert</surname><given-names>C.</given-names></name><name><surname>Peyk</surname><given-names>P.</given-names></name><name><surname>Junghofer</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Buzzwords: early cortical responses to emotional words during reading</article-title>. <source>Psychol. Sci.</source>
<volume>18</volume>, <fpage>475</fpage>&#x02013;<lpage>480</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01924.x</pub-id><pub-id pub-id-type="pmid">17576257</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kissler</surname><given-names>J.</given-names></name><name><surname>Herbert</surname><given-names>C.</given-names></name><name><surname>Winkler</surname><given-names>I.</given-names></name><name><surname>Junghofer</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Emotion and attention in visual word processing: an ERP study</article-title>. <source>Biol. Psychol.</source>
<volume>80</volume>, <fpage>75</fpage>&#x02013;<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2008.03.004</pub-id><pub-id pub-id-type="pmid">18439739</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knickerbocker</surname><given-names>H.</given-names></name><name><surname>Johnson</surname><given-names>R. L.</given-names></name><name><surname>Altarriba</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Emotion effects during reading: Influence of an emotion target word on eye movements and processing</article-title>. <source>Cogn. Emot.</source>
<volume>29</volume>, <fpage>784</fpage>&#x02013;<lpage>806</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2014.938023</pub-id><pub-id pub-id-type="pmid">25034443</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kousta</surname><given-names>S.-T.</given-names></name><name><surname>Vinson</surname><given-names>D. P.</given-names></name><name><surname>Vigliocco</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Emotion words, regardless of polarity, have a processing advantage over neutral words</article-title>. <source>Cognition</source>
<volume>112</volume>, <fpage>473</fpage>&#x02013;<lpage>481</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2009.06.007</pub-id><pub-id pub-id-type="pmid">19591976</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchinke</surname><given-names>L.</given-names></name><name><surname>V&#x000f5;</surname><given-names>M. L.-H.</given-names></name><name><surname>Hofmann</surname><given-names>M.</given-names></name><name><surname>Jacobs</surname><given-names>A. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Pupillary responses during lexical decisions vary with word frequency but not emotional valence</article-title>. <source>Int. J. Psychophysiol.</source>
<volume>65</volume>, <fpage>132</fpage>&#x02013;<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2007.04.004</pub-id><pub-id pub-id-type="pmid">17532075</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuperman</surname><given-names>V.</given-names></name></person-group> (<year>2015</year>). <article-title>Virtual experiments in megastudies: a case study of language and emotion</article-title>. <source>Q. J. Exp. Psychol</source>. <volume>68</volume>, <fpage>1693</fpage>&#x02013;<lpage>1710</lpage>. <pub-id pub-id-type="doi">10.1080/17470218.2014.989865</pub-id><pub-id pub-id-type="pmid">25406972</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuperman</surname><given-names>V.</given-names></name><name><surname>Estes</surname><given-names>Z.</given-names></name><name><surname>Brysbaert</surname><given-names>M.</given-names></name><name><surname>Warriner</surname><given-names>A. B.</given-names></name></person-group> (<year>2014</year>). <article-title>Emotion and language: valence and arousal affect word recognition</article-title>. <source>J. Exp. Psychol. Gen.</source>
<volume>143</volume>, <fpage>1065</fpage>&#x02013;<lpage>1081</lpage>. <pub-id pub-id-type="doi">10.1037/a0035669</pub-id><pub-id pub-id-type="pmid">24490848</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>M.</given-names></name></person-group> (<year>1990</year>). <article-title>On the induction of mood</article-title>. <source>Clin. Psychol. Rev.</source>
<volume>10</volume>, <fpage>669</fpage>&#x02013;<lpage>697</lpage>. <pub-id pub-id-type="doi">10.1016/0272-7358(90)90075-L</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>M&#x000e9;ndez-B&#x000e9;rtolo</surname><given-names>C.</given-names></name><name><surname>Pozo</surname><given-names>M. A.</given-names></name><name><surname>Hinojosa</surname><given-names>J. A.</given-names></name></person-group> (<year>2011</year>). <article-title>Word frequency modulates the processing of emotional words: convergent behavioral and electrophysiological data</article-title>. <source>Neurosci. Lett.</source>
<volume>494</volume>, <fpage>250</fpage>&#x02013;<lpage>254</lpage>. <pub-id pub-id-type="doi">10.1016/j.neulet.2011.03.026</pub-id><pub-id pub-id-type="pmid">21406214</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>C. M.</given-names></name><name><surname>Chappell</surname><given-names>T. D.</given-names></name><name><surname>Ellis</surname><given-names>A. W.</given-names></name></person-group> (<year>1997</year>). <article-title>Age of acquisition norms for a large set of object names and their relation to adult estimates and other variables</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>50A</volume>, <fpage>528</fpage>&#x02013;<lpage>559</lpage>. <pub-id pub-id-type="doi">10.1080/027249897392017</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakic</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>B. W.</given-names></name><name><surname>Busis</surname><given-names>S.</given-names></name><name><surname>Vythilingam</surname><given-names>M.</given-names></name><name><surname>Blair</surname><given-names>R. J. R.</given-names></name></person-group> (<year>2006</year>). <article-title>The impact of affect and frequency on lexical decision: the role of the amygdala and inferior frontal cortex</article-title>. <source>Neuroimage</source>
<volume>31</volume>, <fpage>1752</fpage>&#x02013;<lpage>1761</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.02.022</pub-id><pub-id pub-id-type="pmid">16647271</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niedenthal</surname><given-names>P. M.</given-names></name><name><surname>Halberstadt</surname><given-names>J. B.</given-names></name><name><surname>Setterlund</surname><given-names>M. B.</given-names></name></person-group> (<year>1997</year>). <article-title>Being happy and seeing &#x0201c;happy&#x0201d;: emotional state mediates visual word recognition</article-title>. <source>Cogn. Emot.</source>
<volume>11</volume>, <fpage>403</fpage>&#x02013;<lpage>432</lpage>. <pub-id pub-id-type="doi">10.1080/026999397379863</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olafson</surname><given-names>K. M.</given-names></name><name><surname>Ferraro</surname><given-names>F. R.</given-names></name></person-group> (<year>2001</year>). <article-title>Effects of emotional state on lexical decision performance</article-title>. <source>Brain Cogn.</source>
<volume>45</volume>, <fpage>15</fpage>&#x02013;<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1006/brcg.2000.1248</pub-id><pub-id pub-id-type="pmid">11161359</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Osgood</surname><given-names>C. E.</given-names></name><name><surname>Suci</surname><given-names>G. J.</given-names></name><name><surname>Tannenbaum</surname><given-names>P. H.</given-names></name></person-group> (<year>1957</year>). <source>The Measurement of Meaning</source>. <publisher-loc>Urbana, IL</publisher-loc>: <publisher-name>University of IllinoisPress</publisher-name>.</mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palazova</surname><given-names>M.</given-names></name><name><surname>Mantwill</surname><given-names>K.</given-names></name><name><surname>Sommer</surname><given-names>W.</given-names></name><name><surname>Schacht</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Are effects of emotion in single words non-lexical? Evidence from event-related brain potentials</article-title>. <source>Neuropsychologia</source>
<volume>49</volume>, <fpage>2766</fpage>&#x02013;<lpage>2775</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.06.005</pub-id><pub-id pub-id-type="pmid">21684295</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pratto</surname><given-names>F.</given-names></name><name><surname>John</surname><given-names>O. P.</given-names></name></person-group> (<year>1991</year>). <article-title>Automatic vigilance: the attention-grabbing power of negative social information</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>61</volume>, <fpage>380</fpage>&#x02013;<lpage>391</lpage>. <pub-id pub-id-type="doi">10.1037/0022-3514.61.3.380</pub-id><pub-id pub-id-type="pmid">1941510</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>J. A.</given-names></name></person-group> (<year>1980</year>). <article-title>A circumplex model of affect</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>39</volume>, <fpage>1161</fpage>&#x02013;<lpage>1178</lpage>. <pub-id pub-id-type="doi">10.1037/h0077714</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacht</surname><given-names>A.</given-names></name><name><surname>Sommer</surname><given-names>W.</given-names></name></person-group> (<year>2009</year>). <article-title>Time course and task dependence of emotion effects in word processing</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>9</volume>, <fpage>28</fpage>&#x02013;<lpage>43</lpage>. <pub-id pub-id-type="doi">10.3758/CABN.9.1.28</pub-id><pub-id pub-id-type="pmid">19246325</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>G. G.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Leuthold</surname><given-names>H.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2009</year>). <article-title>Early emotion word processing: evidence from event-related potentials</article-title>. <source>Biol. Psychol.</source>
<volume>80</volume>, <fpage>95</fpage>&#x02013;<lpage>104</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2008.03.010</pub-id><pub-id pub-id-type="pmid">18440691</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>G. G.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2012</year>). <article-title>Emotion words affect eye fixations during reading</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source>
<volume>38</volume>, <fpage>783</fpage>&#x02013;<lpage>792</lpage>. <pub-id pub-id-type="doi">10.1037/a0027209</pub-id><pub-id pub-id-type="pmid">22329788</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>G. G.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2014</year>). <article-title>Emotion words and categories: evidence from lexical decision</article-title>. <source>Cogn. Process.</source>
<volume>15</volume>, <fpage>209</fpage>&#x02013;<lpage>215</lpage>. <pub-id pub-id-type="doi">10.1007/s10339-013-0589-6</pub-id><pub-id pub-id-type="pmid">24258708</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>J. A.</given-names></name></person-group> (<year>1999</year>). <article-title>Hemispheric differences in grammatical class</article-title>. <source>Brain Lang.</source>
<volume>70</volume>, <fpage>13</fpage>&#x02013;<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1006/brln.1999.2137</pub-id><pub-id pub-id-type="pmid">10534370</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>S. C.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Participant and word gender in age of acquisition effects: the role of gender socialization</article-title>. <source>Sex Roles</source>
<volume>61</volume>, <fpage>510</fpage>&#x02013;<lpage>518</lpage>. <pub-id pub-id-type="doi">10.1007/s11199-009-9649-x</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>S. C.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>M. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Size matters: bigger is faster</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>62</volume>, <fpage>1115</fpage>&#x02013;<lpage>1122</lpage>. <pub-id pub-id-type="doi">10.1080/17470210802618900</pub-id><pub-id pub-id-type="pmid">19142830</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>S. C.</given-names></name><name><surname>Rayner</surname><given-names>K.</given-names></name></person-group> (<year>2003</year>). <article-title>Measuring word recognition in reading: eye movements and event-related potentials</article-title>. <source>Trends Cogn. Sci.</source>
<volume>7</volume>, <fpage>489</fpage>&#x02013;<lpage>493</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2003.09.010</pub-id><pub-id pub-id-type="pmid">14585445</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheikh</surname><given-names>N. A.</given-names></name><name><surname>Titone</surname><given-names>D. A.</given-names></name></person-group> (<year>2013</year>). <article-title>Sensorimotor and linguistic information attenuate emotional word processing benefits: an eye-movement study</article-title>. <source>Emotion</source>
<volume>13</volume>, <fpage>1107</fpage>&#x02013;<lpage>1121</lpage>. <pub-id pub-id-type="doi">10.1037/a0032417</pub-id><pub-id pub-id-type="pmid">23647453</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Small</surname><given-names>S. A.</given-names></name></person-group> (<year>1985</year>). <article-title>The effect of mood on word recognition</article-title>. <source>Bull. Psychon. Soc.</source>
<volume>23</volume>, <fpage>453</fpage>&#x02013;<lpage>455</lpage>. <pub-id pub-id-type="doi">10.3758/BF03329850</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stadthagen-Gonzalez</surname><given-names>H.</given-names></name><name><surname>Davis</surname><given-names>C. J.</given-names></name></person-group> (<year>2006</year>). <article-title>The Bristol norms for age of acquisition, imageability, and familiarity</article-title>. <source>Behav. Res. Methods</source>
<volume>38</volume>, <fpage>598</fpage>&#x02013;<lpage>605</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193891</pub-id><pub-id pub-id-type="pmid">17393830</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tabert</surname><given-names>M. H.</given-names></name><name><surname>Borod</surname><given-names>J. C.</given-names></name><name><surname>Tang</surname><given-names>C. Y.</given-names></name><name><surname>Lange</surname><given-names>G.</given-names></name><name><surname>Wei</surname><given-names>T. C.</given-names></name><name><surname>Johnson</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2001</year>). <article-title>Differential amygdala activation during emotional decision and recognition memory tasks using unpleasant words: an fMRI study</article-title>. <source>Neuropsychologia</source>
<volume>39</volume>, <fpage>556</fpage>&#x02013;<lpage>573</lpage>. <pub-id pub-id-type="doi">10.1016/S0028-3932(00)00157-3</pub-id><pub-id pub-id-type="pmid">11257281</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>S. E.</given-names></name></person-group> (<year>1991</year>). <article-title>Asymmetrical effects of positive and negative events: the mobilization-minimization hypothesis</article-title>. <source>Psychol. Bull.</source>
<volume>110</volume>, <fpage>67</fpage>&#x02013;<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.110.1.67</pub-id><pub-id pub-id-type="pmid">1891519</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unkelbach</surname><given-names>C.</given-names></name><name><surname>Fiedler</surname><given-names>K.</given-names></name><name><surname>Bayer</surname><given-names>M.</given-names></name><name><surname>Stegm&#x000fc;ller</surname><given-names>M.</given-names></name><name><surname>Danner</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <article-title>Why positive information is processed faster: the density hypothesis</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>95</volume>, <fpage>36</fpage>&#x02013;<lpage>49</lpage>. <pub-id pub-id-type="doi">10.1037/0022-3514.95.1.36</pub-id><pub-id pub-id-type="pmid">18605850</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>V&#x000e4;stfj&#x000e4;ll</surname><given-names>D.</given-names></name></person-group> (<year>2002</year>). <article-title>Emotion induction through music: a review of the musical mood induction procedure</article-title>. <source>Musicae Scientiae</source>
<volume>5</volume>, <fpage>173</fpage>&#x02013;<lpage>211</lpage>. <pub-id pub-id-type="doi">10.1177/10298649020050S107</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Velten</surname><given-names>E.</given-names></name></person-group> (<year>1968</year>). <article-title>A laboratory task for induction of mood states</article-title>. <source>Behav. Res. Ther.</source>
<volume>6</volume>, <fpage>473</fpage>&#x02013;<lpage>482</lpage>. <pub-id pub-id-type="doi">10.1016/0005-7967(68)90028-4</pub-id><pub-id pub-id-type="pmid">5714990</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wentura</surname><given-names>D.</given-names></name><name><surname>Rothermund</surname><given-names>K.</given-names></name><name><surname>Bak</surname><given-names>P.</given-names></name></person-group> (<year>2000</year>). <article-title>Automatic vigilance: the attention-grabbing power of approach- and avoidance-related social information</article-title>. <source>J. Pers. Soc. Psychol.</source>
<volume>78</volume>, <fpage>1024</fpage>&#x02013;<lpage>1037</lpage>. <pub-id pub-id-type="doi">10.1037/0022-3514.78.6.1024</pub-id><pub-id pub-id-type="pmid">10870906</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>M.</given-names></name></person-group> (<year>1988</year>). <article-title>MRC psycholinguistic database: machine-usable dictionary, Version 2</article-title>. <source>Behav. Res. Methods Instrum. Comput.</source>
<volume>20</volume>, <fpage>6</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.3758/BF03202594</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Windmann</surname><given-names>S.</given-names></name><name><surname>Daum</surname><given-names>I.</given-names></name><name><surname>G&#x000fc;nt&#x000fc;rk&#x000fc;n</surname><given-names>O.</given-names></name></person-group> (<year>2002</year>). <article-title>Dissociating prelexical and postlexical processing of affective information in the two hemispheres: effects of the stimulus presentation format</article-title>. <source>Brain Lang.</source>
<volume>80</volume>, <fpage>269</fpage>&#x02013;<lpage>286</lpage>. <pub-id pub-id-type="doi">10.1006/brln.2001.2586</pub-id><pub-id pub-id-type="pmid">11896641</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>B.</given-names></name><name><surname>Vasiljevic</surname><given-names>M.</given-names></name><name><surname>Weick</surname><given-names>M.</given-names></name><name><surname>Sereno</surname><given-names>M. E.</given-names></name><name><surname>O'Donnell</surname><given-names>P. J.</given-names></name><name><surname>Sereno</surname><given-names>S. C.</given-names></name></person-group> (<year>2013</year>). <article-title>Semantic size of abstract concepts: it gets emotional when you can't see it</article-title>. <source>PLoS ONE</source>
<volume>8</volume>:<fpage>e75000</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0075000</pub-id><pub-id pub-id-type="pmid">24086421</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>He</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>T.</given-names></name><name><surname>Luo</surname><given-names>W.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Gu</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Three stages of emotional word processing: an ERP study with rapid serial visual presentation</article-title>. <source>Soc. Cogn. Affect. Neurosci.</source>
<volume>9</volume>, <fpage>1897</fpage>&#x02013;<lpage>1903</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nst188</pub-id><pub-id pub-id-type="pmid">24526185</pub-id></mixed-citation></ref></ref-list><app-group><app id="A1"><title>Appendix</title><table-wrap id="d35e4855" position="anchor"><label>Appendix A</label><caption><p><bold>Music Stimuli</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Music</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Set</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Album name (Track No.) or &#x0201c;Song Title&#x0201d; (Artist)</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Duration (sec)</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Positive</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Mozart Essential: Divertimento in D Major, K. 136 (8)</td><td valign="top" align="center" rowspan="1" colspan="1">63</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Vivaldi: Concerto in G Major for 2 Mandolins (1)</td><td valign="top" align="center" rowspan="1" colspan="1">72<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Made in Dagenham (3)</td><td valign="top" align="center" rowspan="1" colspan="1">70<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Pride and Prejudice (14)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">69</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Music Box Dancer&#x0201d; (Frank Mills)</td><td valign="top" align="center" rowspan="1" colspan="1">45</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>2</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Oliver Twist (8)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">47</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Chocolat (4)</td><td valign="top" align="center" rowspan="1" colspan="1">65</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Finding Neverland (23)</td><td valign="top" align="center" rowspan="1" colspan="1">66</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Golden Compass (14)</td><td valign="top" align="center" rowspan="1" colspan="1">73<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Steel Drum Sounds of the Caribbean (4)</td><td valign="top" align="center" rowspan="1" colspan="1">63<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>3</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Dances with Wolves (10)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">47</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">The Untouchables (6)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">68</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Haydn: Flute Concerto in D Major (1)</td><td valign="top" align="center" rowspan="1" colspan="1">70<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Happy Music&#x0201d; (James Last)</td><td valign="top" align="center" rowspan="1" colspan="1">60</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">The Holidays (5)</td><td valign="top" align="center" rowspan="1" colspan="1">54</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Negative</bold></td><td valign="top" align="center" rowspan="1" colspan="1"><bold>1</bold></td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Evil Theme&#x0201d; (Danny Elfman)</td><td valign="top" align="center" rowspan="1" colspan="1">58<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">The Miraculous Mandarin (1)</td><td valign="top" align="center" rowspan="1" colspan="1">74</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Minority Report (3)</td><td valign="top" align="center" rowspan="1" colspan="1">61</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Hannibal&#x02013;Original (1)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">57</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Penderecki&#x02013;Orchestral Works (2)</td><td valign="top" align="center" rowspan="1" colspan="1">67<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>2</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Rite of Spring (17)</td><td valign="top" align="center" rowspan="1" colspan="1">76<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Lord of the Rings III (28)</td><td valign="top" align="center" rowspan="1" colspan="1">72<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">War of the Worlds (11)</td><td valign="top" align="center" rowspan="1" colspan="1">62<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Iannis Xenakis&#x02013;Music for Strings (2)</td><td valign="top" align="center" rowspan="1" colspan="1">43</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Batman Returns (5)<xref ref-type="table-fn" rid="TN1"><sup>a</sup></xref></td><td valign="top" align="center" rowspan="1" colspan="1">53</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1"><bold>3</bold></td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Yeti&#x0201d; (Unknown)</td><td valign="top" align="center" rowspan="1" colspan="1">53</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Xenakis: Phlegra/Jalons/Karen/N (2)</td><td valign="top" align="center" rowspan="1" colspan="1">62<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Harry Potter and the Chamber of Secrets (18)</td><td valign="top" align="center" rowspan="1" colspan="1">53<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Minority Report (5)</td><td valign="top" align="center" rowspan="1" colspan="1">76<xref ref-type="table-fn" rid="TN2"><sup>b</sup></xref></td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Penderecki&#x02013;Orchestral Works (8)</td><td valign="top" align="center" rowspan="1" colspan="1">54</td></tr></tbody></table><table-wrap-foot><fn id="TN1"><label>a</label><p><italic>Adapted from Eerola and Vuoskoski (<xref rid="B16" ref-type="bibr">2011</xref>)</italic>.</p></fn><fn id="TN2"><label>b</label><p><italic>Looped</italic>.</p></fn></table-wrap-foot></table-wrap><table-wrap id="d35e5182" position="anchor"><label>Appendix B</label><caption><p><bold>Word Stimuli</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="center" colspan="3" rowspan="1"><bold>LF</bold></th><th valign="top" align="center" colspan="3" rowspan="1"><bold>HF</bold></th></tr><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Neutral</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Positive</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Negative</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Neutral</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">toys</td><td valign="top" align="left" rowspan="1" colspan="1">rage</td><td valign="top" align="left" rowspan="1" colspan="1">chin</td><td valign="top" align="left" rowspan="1" colspan="1">car</td><td valign="top" align="left" rowspan="1" colspan="1">war</td><td valign="top" align="left" rowspan="1" colspan="1">door</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">glory</td><td valign="top" align="left" rowspan="1" colspan="1">cruel</td><td valign="top" align="left" rowspan="1" colspan="1">stiff</td><td valign="top" align="left" rowspan="1" colspan="1">strong</td><td valign="top" align="left" rowspan="1" colspan="1">death</td><td valign="top" align="left" rowspan="1" colspan="1">paper</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">grin</td><td valign="top" align="left" rowspan="1" colspan="1">agony</td><td valign="top" align="left" rowspan="1" colspan="1">lamp</td><td valign="top" align="left" rowspan="1" colspan="1">music</td><td valign="top" align="left" rowspan="1" colspan="1">died</td><td valign="top" align="left" rowspan="1" colspan="1">month</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">intimate</td><td valign="top" align="left" rowspan="1" colspan="1">hostile</td><td valign="top" align="left" rowspan="1" colspan="1">garment</td><td valign="top" align="left" rowspan="1" colspan="1">success</td><td valign="top" align="left" rowspan="1" colspan="1">pressure</td><td valign="top" align="left" rowspan="1" colspan="1">context</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">angel</td><td valign="top" align="left" rowspan="1" colspan="1">burn</td><td valign="top" align="left" rowspan="1" colspan="1">obey</td><td valign="top" align="left" rowspan="1" colspan="1">heart</td><td valign="top" align="left" rowspan="1" colspan="1">fear</td><td valign="top" align="left" rowspan="1" colspan="1">unit</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">charm</td><td valign="top" align="left" rowspan="1" colspan="1">regret</td><td valign="top" align="left" rowspan="1" colspan="1">avenue</td><td valign="top" align="left" rowspan="1" colspan="1">happy</td><td valign="top" align="left" rowspan="1" colspan="1">killed</td><td valign="top" align="left" rowspan="1" colspan="1">window</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">comedy</td><td valign="top" align="left" rowspan="1" colspan="1">scared</td><td valign="top" align="left" rowspan="1" colspan="1">nursery</td><td valign="top" align="left" rowspan="1" colspan="1">leader</td><td valign="top" align="left" rowspan="1" colspan="1">failure</td><td valign="top" align="left" rowspan="1" colspan="1">method</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">fame</td><td valign="top" align="left" rowspan="1" colspan="1">ugly</td><td valign="top" align="left" rowspan="1" colspan="1">spray</td><td valign="top" align="left" rowspan="1" colspan="1">cash</td><td valign="top" align="left" rowspan="1" colspan="1">pain</td><td valign="top" align="left" rowspan="1" colspan="1">plant</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">liberty</td><td valign="top" align="left" rowspan="1" colspan="1">crushed</td><td valign="top" align="left" rowspan="1" colspan="1">custom</td><td valign="top" align="left" rowspan="1" colspan="1">holiday</td><td valign="top" align="left" rowspan="1" colspan="1">broken</td><td valign="top" align="left" rowspan="1" colspan="1">teacher</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">loyal</td><td valign="top" align="left" rowspan="1" colspan="1">devil</td><td valign="top" align="left" rowspan="1" colspan="1">elbow</td><td valign="top" align="left" rowspan="1" colspan="1">truth</td><td valign="top" align="left" rowspan="1" colspan="1">crime</td><td valign="top" align="left" rowspan="1" colspan="1">chair</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">sunshine</td><td valign="top" align="left" rowspan="1" colspan="1">jealousy</td><td valign="top" align="left" rowspan="1" colspan="1">whistle</td><td valign="top" align="left" rowspan="1" colspan="1">powerful</td><td valign="top" align="left" rowspan="1" colspan="1">accident</td><td valign="top" align="left" rowspan="1" colspan="1">machine</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">bride</td><td valign="top" align="left" rowspan="1" colspan="1">slave</td><td valign="top" align="left" rowspan="1" colspan="1">invest</td><td valign="top" align="left" rowspan="1" colspan="1">travel</td><td valign="top" align="left" rowspan="1" colspan="1">fight</td><td valign="top" align="left" rowspan="1" colspan="1">museum</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">circus</td><td valign="top" align="left" rowspan="1" colspan="1">misery</td><td valign="top" align="left" rowspan="1" colspan="1">hammer</td><td valign="top" align="left" rowspan="1" colspan="1">pretty</td><td valign="top" align="left" rowspan="1" colspan="1">prison</td><td valign="top" align="left" rowspan="1" colspan="1">corner</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">admired</td><td valign="top" align="left" rowspan="1" colspan="1">poison</td><td valign="top" align="left" rowspan="1" colspan="1">fabric</td><td valign="top" align="left" rowspan="1" colspan="1">freedom</td><td valign="top" align="left" rowspan="1" colspan="1">murder</td><td valign="top" align="left" rowspan="1" colspan="1">square</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">trophy</td><td valign="top" align="left" rowspan="1" colspan="1">torture</td><td valign="top" align="left" rowspan="1" colspan="1">sphere</td><td valign="top" align="left" rowspan="1" colspan="1">victory</td><td valign="top" align="left" rowspan="1" colspan="1">crisis</td><td valign="top" align="left" rowspan="1" colspan="1">manner</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">nude</td><td valign="top" align="left" rowspan="1" colspan="1">jail</td><td valign="top" align="left" rowspan="1" colspan="1">lawn</td><td valign="top" align="left" rowspan="1" colspan="1">gold</td><td valign="top" align="left" rowspan="1" colspan="1">debt</td><td valign="top" align="left" rowspan="1" colspan="1">iron</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">dancer</td><td valign="top" align="left" rowspan="1" colspan="1">terror</td><td valign="top" align="left" rowspan="1" colspan="1">salad</td><td valign="top" align="left" rowspan="1" colspan="1">dinner</td><td valign="top" align="left" rowspan="1" colspan="1">afraid</td><td valign="top" align="left" rowspan="1" colspan="1">detail</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">graduate</td><td valign="top" align="left" rowspan="1" colspan="1">ambulance</td><td valign="top" align="left" rowspan="1" colspan="1">nonsense</td><td valign="top" align="left" rowspan="1" colspan="1">excellent</td><td valign="top" align="left" rowspan="1" colspan="1">violence</td><td valign="top" align="left" rowspan="1" colspan="1">contents</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">thrill</td><td valign="top" align="left" rowspan="1" colspan="1">demon</td><td valign="top" align="left" rowspan="1" colspan="1">clumsy</td><td valign="top" align="left" rowspan="1" colspan="1">bright</td><td valign="top" align="left" rowspan="1" colspan="1">injury</td><td valign="top" align="left" rowspan="1" colspan="1">engine</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">treasure</td><td valign="top" align="left" rowspan="1" colspan="1">selfish</td><td valign="top" align="left" rowspan="1" colspan="1">umbrella</td><td valign="top" align="left" rowspan="1" colspan="1">pleasure</td><td valign="top" align="left" rowspan="1" colspan="1">rejected</td><td valign="top" align="left" rowspan="1" colspan="1">passage</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">hug</td><td valign="top" align="left" rowspan="1" colspan="1">rat</td><td valign="top" align="left" rowspan="1" colspan="1">shy</td><td valign="top" align="left" rowspan="1" colspan="1">fun</td><td valign="top" align="left" rowspan="1" colspan="1">fat</td><td valign="top" align="left" rowspan="1" colspan="1">odd</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ecstasy</td><td valign="top" align="left" rowspan="1" colspan="1">brutal</td><td valign="top" align="left" rowspan="1" colspan="1">coarse</td><td valign="top" align="left" rowspan="1" colspan="1">beauty</td><td valign="top" align="left" rowspan="1" colspan="1">cancer</td><td valign="top" align="left" rowspan="1" colspan="1">author</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">greet</td><td valign="top" align="left" rowspan="1" colspan="1">dread</td><td valign="top" align="left" rowspan="1" colspan="1">muddy</td><td valign="top" align="left" rowspan="1" colspan="1">beach</td><td valign="top" align="left" rowspan="1" colspan="1">guilty</td><td valign="top" align="left" rowspan="1" colspan="1">phase</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">puppy</td><td valign="top" align="left" rowspan="1" colspan="1">toxic</td><td valign="top" align="left" rowspan="1" colspan="1">basket</td><td valign="top" align="left" rowspan="1" colspan="1">treat</td><td valign="top" align="left" rowspan="1" colspan="1">victim</td><td valign="top" align="left" rowspan="1" colspan="1">metal</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">cheer</td><td valign="top" align="left" rowspan="1" colspan="1">snake</td><td valign="top" align="left" rowspan="1" colspan="1">noisy</td><td valign="top" align="left" rowspan="1" colspan="1">magic</td><td valign="top" align="left" rowspan="1" colspan="1">angry</td><td valign="top" align="left" rowspan="1" colspan="1">yellow</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">awe</td><td valign="top" align="left" rowspan="1" colspan="1">rude</td><td valign="top" align="left" rowspan="1" colspan="1">lazy</td><td valign="top" align="left" rowspan="1" colspan="1">song</td><td valign="top" align="left" rowspan="1" colspan="1">hurt</td><td valign="top" align="left" rowspan="1" colspan="1">item</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">merry</td><td valign="top" align="left" rowspan="1" colspan="1">vomit</td><td valign="top" align="left" rowspan="1" colspan="1">rust</td><td valign="top" align="left" rowspan="1" colspan="1">proud</td><td valign="top" align="left" rowspan="1" colspan="1">bomb</td><td valign="top" align="left" rowspan="1" colspan="1">paint</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">joyful</td><td valign="top" align="left" rowspan="1" colspan="1">insult</td><td valign="top" align="left" rowspan="1" colspan="1">insect</td><td valign="top" align="left" rowspan="1" colspan="1">wedding</td><td valign="top" align="left" rowspan="1" colspan="1">damaged</td><td valign="top" align="left" rowspan="1" colspan="1">circle</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">diamonds</td><td valign="top" align="left" rowspan="1" colspan="1">deceive</td><td valign="top" align="left" rowspan="1" colspan="1">glacier</td><td valign="top" align="left" rowspan="1" colspan="1">exciting</td><td valign="top" align="left" rowspan="1" colspan="1">disaster</td><td valign="top" align="left" rowspan="1" colspan="1">medicine</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">heal</td><td valign="top" align="left" rowspan="1" colspan="1">slap</td><td valign="top" align="left" rowspan="1" colspan="1">bland</td><td valign="top" align="left" rowspan="1" colspan="1">gift</td><td valign="top" align="left" rowspan="1" colspan="1">gun</td><td valign="top" align="left" rowspan="1" colspan="1">bowl</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">tasty</td><td valign="top" align="left" rowspan="1" colspan="1">annoy</td><td valign="top" align="left" rowspan="1" colspan="1">vest</td><td valign="top" align="left" rowspan="1" colspan="1">kiss</td><td valign="top" align="left" rowspan="1" colspan="1">evil</td><td valign="top" align="left" rowspan="1" colspan="1">clock</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">jewels</td><td valign="top" align="left" rowspan="1" colspan="1">drown</td><td valign="top" align="left" rowspan="1" colspan="1">stove</td><td valign="top" align="left" rowspan="1" colspan="1">heaven</td><td valign="top" align="left" rowspan="1" colspan="1">crash</td><td valign="top" align="left" rowspan="1" colspan="1">shadow</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">miracle</td><td valign="top" align="left" rowspan="1" colspan="1">filthy</td><td valign="top" align="left" rowspan="1" colspan="1">golfer</td><td valign="top" align="left" rowspan="1" colspan="1">passion</td><td valign="top" align="left" rowspan="1" colspan="1">assault</td><td valign="top" align="left" rowspan="1" colspan="1">poetry</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">blossom</td><td valign="top" align="left" rowspan="1" colspan="1">spider</td><td valign="top" align="left" rowspan="1" colspan="1">violin</td><td valign="top" align="left" rowspan="1" colspan="1">humour</td><td valign="top" align="left" rowspan="1" colspan="1">destroy</td><td valign="top" align="left" rowspan="1" colspan="1">stomach</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">paradise</td><td valign="top" align="left" rowspan="1" colspan="1">suffocate</td><td valign="top" align="left" rowspan="1" colspan="1">reserved</td><td valign="top" align="left" rowspan="1" colspan="1">laughter</td><td valign="top" align="left" rowspan="1" colspan="1">infection</td><td valign="top" align="left" rowspan="1" colspan="1">corridor</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">lust</td><td valign="top" align="left" rowspan="1" colspan="1">riot</td><td valign="top" align="left" rowspan="1" colspan="1">nun</td><td valign="top" align="left" rowspan="1" colspan="1">joke</td><td valign="top" align="left" rowspan="1" colspan="1">hate</td><td valign="top" align="left" rowspan="1" colspan="1">tool</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">vacation</td><td valign="top" align="left" rowspan="1" colspan="1">despise</td><td valign="top" align="left" rowspan="1" colspan="1">mischief</td><td valign="top" align="left" rowspan="1" colspan="1">romantic</td><td valign="top" align="left" rowspan="1" colspan="1">confused</td><td valign="top" align="left" rowspan="1" colspan="1">curious</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">aroused</td><td valign="top" align="left" rowspan="1" colspan="1">trauma</td><td valign="top" align="left" rowspan="1" colspan="1">rattle</td><td valign="top" align="left" rowspan="1" colspan="1">reward</td><td valign="top" align="left" rowspan="1" colspan="1">horror</td><td valign="top" align="left" rowspan="1" colspan="1">journal</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">radiant</td><td valign="top" align="left" rowspan="1" colspan="1">anguish</td><td valign="top" align="left" rowspan="1" colspan="1">errand</td><td valign="top" align="left" rowspan="1" colspan="1">delight</td><td valign="top" align="left" rowspan="1" colspan="1">tragedy</td><td valign="top" align="left" rowspan="1" colspan="1">gender</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">witty</td><td valign="top" align="left" rowspan="1" colspan="1">scorn</td><td valign="top" align="left" rowspan="1" colspan="1">slush</td><td valign="top" align="left" rowspan="1" colspan="1">brave</td><td valign="top" align="left" rowspan="1" colspan="1">panic</td><td valign="top" align="left" rowspan="1" colspan="1">butter</td></tr></tbody></table><table-wrap-foot><p><italic>LF, low frequency; HF, high frequency</italic>.</p></table-wrap-foot></table-wrap></app></app-group></back></article>