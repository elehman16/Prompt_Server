<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychology</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">22787452</article-id><article-id pub-id-type="pmc">3392841</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2012.00224</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Training Visual Imagery: Improvements of Metacognition, but not Imagery Strength</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rademaker</surname><given-names>Rosanne L.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="author-notes" rid="fn001">*</xref></contrib><contrib contrib-type="author"><name><surname>Pearson</surname><given-names>Joel</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Cognitive Neuroscience Department, Maastricht University</institution><country>Maastricht, Netherlands</country></aff><aff id="aff2"><sup>2</sup><institution>Psychology Department, Vanderbilt University</institution><country>Nashville, TN, USA</country></aff><aff id="aff3"><sup>3</sup><institution>Vanderbilt Vision Research Center, Vanderbilt University</institution><country>Nashville, TN, USA</country></aff><aff id="aff4"><sup>4</sup><institution>School of Psychology, The University of New South Wales</institution><country>Sydney, NSW, Australia</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Stephen Michael Kosslyn, Stanford University, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: Stephen Michael Kosslyn, Stanford University, USA; Gregoire Borst, Universit&#x000e9; Paris Descartes, France</p></fn><corresp id="fn001">*Correspondence: Rosanne L. Rademaker, Cognitive Neuroscience Department, Maastricht University, Universiteitssingel 40, 6229 ER Maastricht, Netherlands. e-mail: <email xlink:type="simple">rosanne.rademaker@maastrichtuniversity.nl</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Frontiers in Perception Science, a specialty of Frontiers in Psychology.</p></fn></author-notes><pub-date pub-type="epub"><day>10</day><month>7</month><year>2012</year></pub-date><pub-date pub-type="collection"><year>2012</year></pub-date><volume>3</volume><elocation-id>224</elocation-id><history><date date-type="received"><day>27</day><month>4</month><year>2012</year></date><date date-type="accepted"><day>16</day><month>6</month><year>2012</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2012 Rademaker and Pearson.</copyright-statement><copyright-year>2012</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><license-p>This is an open-access article distributed under the terms of the <uri xlink:type="simple" xlink:href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution License</uri>, which permits use, distribution and reproduction in other forums, provided the original authors and source are credited and subject to any copyright notices concerning any third-party graphics etc.</license-p></license></permissions><abstract><p>Visual imagery has been closely linked to brain mechanisms involved in perception. Can visual imagery, like visual perception, improve by means of training? Previous research has demonstrated that people can reliably evaluate the vividness of single episodes of imagination &#x02013; might the metacognition of imagery also improve over the course of training? We had participants imagine colored Gabor patterns for an hour a day, over the course of five consecutive days, and again 2&#x02009;weeks after training. Participants rated the subjective vividness and effort of their mental imagery on each trial. The influence of imagery on subsequent binocular rivalry dominance was taken as our measure of imagery strength. We found no overall effect of training on imagery strength. Training did, however, improve participant&#x02019;s metacognition of imagery. Trial-by-trial ratings of vividness gained predictive power on subsequent rivalry dominance as a function of training. These data suggest that, while imagery strength might be immune to training in the current context, people&#x02019;s metacognitive understanding of mental imagery can improve with practice.</p></abstract><kwd-group><kwd>visual imagery</kwd><kwd>training</kwd><kwd>learning</kwd><kwd>metacognition</kwd><kwd>introspection</kwd><kwd>binocular rivalry</kwd><kwd>consciousness</kwd></kwd-group><counts><fig-count count="6"/><table-count count="0"/><equation-count count="3"/><ref-count count="80"/><page-count count="11"/><word-count count="9714"/></counts></article-meta></front><body><sec><title>Introduction</title><p>Mental imagery can be described as the retrieval of perceptual information from memory, and the subsequent examination of this information in the &#x0201c;minds eye.&#x0201d; Research has provided a growing body of behavioral and neuroimaging evidence that there is considerable overlap between the &#x0201c;minds eye&#x0201d; and actual perception (Chen et al., <xref ref-type="bibr" rid="B9">1998</xref>; Kreiman et al., <xref ref-type="bibr" rid="B44">2000</xref>; O&#x02019;Craven and Kanwisher, <xref ref-type="bibr" rid="B54">2000</xref>; Zatorre and Halpern, <xref ref-type="bibr" rid="B79">2005</xref>). For example, behavioral studies have demonstrated that imagery content can selectively influence perception (Perky, <xref ref-type="bibr" rid="B59">1910</xref>; McDermott and Roediger, <xref ref-type="bibr" rid="B50">1994</xref>; Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>). Imagery has been shown to affect visual detection thresholds (Ishai and Sagi, <xref ref-type="bibr" rid="B34">1997</xref>), performance on a visual acuity task (Craver-Lemley and Reeves, <xref ref-type="bibr" rid="B11">1992</xref>), and to induce negative aftereffects (Gilden et al., <xref ref-type="bibr" rid="B27">1995</xref>) in much the same way as a sensory stimulus. Recent neuroimaging studies show that there is considerable spatial overlap between activated areas of the brain during both visual perception and visual imagery, for example information about a pattern held in mind during working memory or imagery can be present in visual sensory cortex (Kosslyn et al., <xref ref-type="bibr" rid="B43">1995</xref>; Slotnick et al., <xref ref-type="bibr" rid="B71">2005</xref>; Harrison and Tong, <xref ref-type="bibr" rid="B30">2009</xref>; Serences et al., <xref ref-type="bibr" rid="B68">2009</xref>; Stokes et al., <xref ref-type="bibr" rid="B73">2009</xref>). Like perception, visual imagery is impaired when visual cortical activity is disturbed by means of transcranial magnetic stimulation (Kosslyn et al., <xref ref-type="bibr" rid="B42">1999</xref>).</p><p>If visual imagery can indeed be defined as the recreation of a perceptual representation in the absence of retinal input (Ishai and Sagi, <xref ref-type="bibr" rid="B33">1995</xref>), one may wonder exactly how similar imagery is to perception. Specifically, prolonged visual practice can improve perceptual skill (Fahle and Poggio, <xref ref-type="bibr" rid="B20">2002</xref>; Fine and Jacobs, <xref ref-type="bibr" rid="B22">2002</xref>; Sasaki et al., <xref ref-type="bibr" rid="B63">2010</xref>); can imagery also improve with daily practice? There is some evidence to suggest that perceptual learning can occur from training without physical stimulation. Repetitively imagining the crucial part of a visual bisection stimulus (visual spatial judgment) or imagining a low-contrast Gabor pattern (contrast judgment) can improve performance on subsequent perceptual tasks (Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>). Similarly, imagining motor-acts facilitates performance on corresponding tasks by training relevant parts of motor cortex, and by strengthening associations between processes and actions (Driskell et al., <xref ref-type="bibr" rid="B17">1994</xref>; Weiss et al., <xref ref-type="bibr" rid="B77">1994</xref>; Feltz and Landers, <xref ref-type="bibr" rid="B21">2007</xref>). To date, research has mainly focused on the effects imagery training has on subsequent perceptual tasks. Here, we look directly at the influence of imagery training on the strength of imagery itself.</p><p>One of the hallmarks of mental imagery is the considerable difference in reported imagery strength and vividness observed across individuals (Galton, <xref ref-type="bibr" rid="B25">1883</xref>; McKellar, <xref ref-type="bibr" rid="B51">1965</xref>; Marks, <xref ref-type="bibr" rid="B49">1973</xref>; Amedi et al., <xref ref-type="bibr" rid="B4">2005</xref>; Cui et al., <xref ref-type="bibr" rid="B12">2007</xref>). Some individuals claim veridical, vivid imagery, while others doubt its entire existence (McKellar, <xref ref-type="bibr" rid="B51">1965</xref>). The factors causing such differences in imagery strength remain largely unknown. One hypothesis is that individuals who actively practice, or whose everyday activities involve strong use of imagery, might have strengthened their imagery through training and practice (Sacks, <xref ref-type="bibr" rid="B62">2010</xref>). We sought to examine such a proposal in the lab by engaging individuals in an imagery task daily, over a period of 5&#x02009;days. Can repeated instances of forming visual imagery lead to improved imagery strength?</p><p>To address this question researchers must be able to reliably measure imagery strength from 1&#x02009;day to the next. Previous work demonstrated that sustained imagery has a pronounced and visually specific impact on subsequent perception (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>, <xref ref-type="bibr" rid="B57">2011</xref>). These studies utilized a visual phenomenon called binocular rivalry; when two different patterns are presented one to each eye, only one of the patterns is consciously perceived. Subtle experimental manipulations, such as attention (Meng and Tong, <xref ref-type="bibr" rid="B52">2004</xref>; Mitchell et al., <xref ref-type="bibr" rid="B53">2004</xref>; Chong and Blake, <xref ref-type="bibr" rid="B10">2006</xref>; Kamphuisen et al., <xref ref-type="bibr" rid="B35">2007</xref>), sensory memory (Pearson and Brascamp, <xref ref-type="bibr" rid="B55">2008</xref>), or imagery (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>), can bring about a slight imbalance in the neural states, creating a bias that helps one pattern win the race for dominance at the expense of the other.</p><p>We have previously demonstrated that imagery can alter future competitive visual interactions in favor of the imagined stimulus on a large percentage of trials (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>, <xref ref-type="bibr" rid="B57">2011</xref>), while catch-trial presentations of mock rivalry stimuli do not reveal such bias, ruling out the possibility of demand characteristics (Pylyshyn, <xref ref-type="bibr" rid="B60">2003</xref>). Indeed, scores on offline imagery questionnaires predict imagery strength measured using rivalry (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>) and rivalry has been utilized to examine the role of imagery during visual working memory (Keogh and Pearson, <xref ref-type="bibr" rid="B37">2011</xref>). Thus, there is compelling evidence that rivalry bias (or &#x0201c;perceptual bias&#x0201d;) is a useful way to measure imagery strength in general (e.g., encompassing perceptual elements and sensations of vividness). In the current study, imagery strength is the underlying construct of interest, and the extent to which imagery biases perception is taken as a reliable measure of imagery strength. The subjective experiences associated with imagery strength are probed by having participants report the &#x0201c;vividness&#x0201d; of their mental images.</p><p>Can people evaluate the phenomenal qualities of internally generated experiences, such as whether a mental image is vivid or detailed? Recently, an attempt was made to answer the question of knowing ones own thoughts (exemplifying the problem of &#x0201c;metacognition;&#x0201d; Flavell, <xref ref-type="bibr" rid="B23">1979</xref>) in relation to mental imagery (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). This study provided compelling new evidence that people have accurate metacognitive knowledge at fine-grained scale, regarding specific instances of imagery: On individual trials, higher ratings of imagery vividness predicted a greater likelihood that the imagined pattern would appear dominant during subsequent rivalry (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). Interestingly, repeated attempts to form a particular visual image can lead to different degrees of success with each try, causing imagery strength to fluctuate from one moment to the next. Despite this variance in imagery strength, people demonstrate good metacognitive understanding of their imagery, and can readily evaluate how vivid their mental images are on a particular occasion.</p><p>At a general level, there has been a growing interest in metacognitive judgments of memory and sensory decision-making (Kiani and Shadlen, <xref ref-type="bibr" rid="B39">2009</xref>; Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>; Rounis et al., <xref ref-type="bibr" rid="B61">2010</xref>; Song et al., <xref ref-type="bibr" rid="B72">2011</xref>). Frontal brain regions are important for introspective or metacognitive ability (Kepecs et al., <xref ref-type="bibr" rid="B38">2008</xref>; Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>), which suggests that the neural substrates of metacognitive ability are distinct from those supporting primary perception. Although the ability to introspect varies substantially across individuals, within a single individual metacognitive ability seems to be stable and task independent, suggesting a common cognitive process (Song et al., <xref ref-type="bibr" rid="B72">2011</xref>).</p><p>Little is known regarding the stability and independence of metacognition of mental imagery. If metacognition for perceptual tasks originates from a common cognitive process, might a similar process allow people to have metacognition of mental imagery? Despite the highly subjective and volitional nature of imagery, people are reasonably good at imagery metacognition (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). Is this ability stable, or might metacognition of imagery improve with repeated practice? Here, we also investigated the degree of imagery metacognition as a function of daily training.</p><p>To assess metacognition we use a method derived from signal detection theory (Swets, <xref ref-type="bibr" rid="B74">1986</xref>; Macmillan and Creelman, <xref ref-type="bibr" rid="B48">1991</xref>; Galvin et al., <xref ref-type="bibr" rid="B26">2003</xref>; Kornbrot, <xref ref-type="bibr" rid="B40">2006</xref>) that has been successfully employed in a variety of recent metacognition studies (Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>; Song et al., <xref ref-type="bibr" rid="B72">2011</xref>). Using this method, we looked at the likelihood that imagery biased subsequent rivalry, given a certain level of imagery vividness. Signal detection allows us to estimate a single quantitative &#x0201c;sensitivity&#x0201d; measure of metacognitive ability, derived from these objective (amount of perceptual bias) and subjective (ratings of vividness) variables. This measure of sensitivity is criterion free, which means that it is not prone to changes in criterion (rating-magnitude), and it is not affected by irregular use of the rating scale (which generally results in unequal numbers of observations across the various conditions).</p><p>By way of preview, here we report that imagery strength &#x02013; measured as the extent to which imagery biases perception during binocular rivalry &#x02013; did not increase over the 5-day training period. Interestingly, participant&#x02019;s metacognition of imagery did significantly improve over the training period. This dissociation between imagery strength and metacognitive ability suggests a degree of independence between the two processes.</p></sec><sec sec-type="materials|methods"><title>Materials and Methods</title><sec><title>Participants</title><p>Nine observers (six female) participated in the experiment. All had normal or corrected-to-normal visual acuity and normal stereovision, and all provided written informed consent. Observers received payment for their participation ($10 per hour, plus a $5 per hour bonus upon completion) with the exception of a participating author (RR) and participant BW. The study was carried out with the approval of the Institutional Review Board at Vanderbilt University.</p></sec><sec><title>Materials</title><p>Observers viewed the stimuli on a luminance-calibrated CRT monitor with 1152&#x02009;&#x000d7;&#x02009;870 resolution and a 75-Hz refresh rate in an otherwise darkened room. Visual stimuli were generated with Matlab 7.5.0 (R2007b) and the Psychophysics toolbox (Brainard, <xref ref-type="bibr" rid="B7">1997</xref>; Pelli, <xref ref-type="bibr" rid="B58">1997</xref>) under Mac OSX. Observers sat at a viewing distance of 56&#x02009;cm, and used a chinrest to maintain a stable head position. A mirror stereoscope was used to present a different pattern to each eye, and binocular convergence of the two images was aided by a white bull&#x02019;s eye fixation dot (0.95&#x000b0;) at the center of each monocular half-image. Participants were instructed to maintain steady fixation throughout all experimental trials.</p><p>Rivalry stimuli consisted of a green and a red grating (spatial frequency&#x02009;=&#x02009;1.23&#x02009;c/&#x000b0;) surrounding a central fixation point, presented against a black background with a mean luminance of 0.09&#x02009;cd/m<sup>2</sup>. CIE color values of the stimuli were as follows &#x02013; green: <italic>x&#x02009;</italic>=&#x02009;0.293, <italic>y&#x02009;</italic>=&#x02009;0.572; red: <italic>x&#x02009;</italic>=&#x02009;0.602, <italic>y&#x02009;</italic>=&#x02009;0.353. Gratings were presented at 75% contrast and had a Gaussian-shaped luminance profile (mean luminance&#x02009;=&#x02009;6.95&#x02009;cd/m<sup>2</sup>) that faded to black at the stimulus edge (Gaussian &#x003c3;&#x02009;=&#x02009;4.29&#x000b0;). Five observers were trained with a green grating of orientation 112.5&#x000b0; and a red grating of orientation 22.5&#x000b0;, while on generalization blocks they were presented with 67.5&#x000b0; green, and 157.5&#x000b0; red gratings. The opposite was true for the remaining four observers, meaning that we counterbalanced which grating-pairs were used for training and generalization between participants. On catch trials, a mock rivalry stimulus was presented consisting of a physical blend of the green and red rivalry patterns. This stimulus was presented to both eyes simultaneously in order to avoid interocular competition. Presentation of the mock-stimulus allowed us to test for decisional bias and demand characteristics (Landsberger, <xref ref-type="bibr" rid="B45">1958</xref>).</p><p>The dominant eye plays a key role in determining which of two monocular images is likely to be perceived at the onset of binocular rivalry. Therefore, individual fine-tuning of stimulus contrast was done before the start of the experiment, and before each daily session, to control for differences in ocular dominance between observers. We used the same procedure as in previous research (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>, <xref ref-type="bibr" rid="B57">2011</xref>; Keogh and Pearson, <xref ref-type="bibr" rid="B37">2011</xref>), matching the relative strength of the rivalry gratings to the point at which perceptual competition is most balanced, and thus most susceptible to disruption.</p></sec><sec><title>Procedure</title><p>To investigate whether visual imagery can be improved by means of training, and to see how this relates to metacognition of imagery over time, we had observers perform a visual imagery task on five consecutive days, for about an hour a day. A sixth follow-up session was conducted 2&#x02013;3&#x02009;weeks after training. Participants came into the lab at or around the same time on each day of training, and were dark-adapted for a couple of minutes before the start of each experimental session.</p><p>During the experiment, participants were briefly presented with a randomly chosen (equal number of both) central cue (&#x0201c;G&#x0201d; for green, or &#x0201c;R&#x0201d; for red) at the beginning of each imagery-trial (Figure <xref ref-type="fig" rid="F1">1</xref>A). Subsequently, participants would engage in visual imagery of the cued pattern for an 8-s period. After completing this imagery period, the word &#x0201c;vividness?&#x0201d; cued participants to first report the quality of their imagery by means of left-handed button presses (1&#x02009;=&#x02009;<italic>almost no imagery</italic>, 2&#x02009;=&#x02009;<italic>some weak imagery</italic>, 3&#x02009;=&#x02009;<italic>moderate imagery</italic>, 4&#x02009;=&#x02009;<italic>strong imagery almost like perception</italic>), after which they were cued by the word &#x0201c;effort?&#x0201d; to report the amount of vigor with which they had tried to imagine the pattern (1&#x02009;=&#x02009;<italic>almost no effort</italic>, 2&#x02009;=&#x02009;<italic>some effort</italic>, 3&#x02009;=&#x02009;<italic>moderate effort</italic>, 4&#x02009;=&#x02009;<italic>tried very hard to form a mental image</italic>). Observers were instructed to use the full range of the rating scale to the best of their abilities.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Sample trial sequence and example ROC II curve. (A)</bold> Participants were presented with a random cue (&#x0201c;G&#x0201d; or &#x0201c;R&#x0201d;) after which they formed a mental image of the green or red grating over an 8-s period. Participants were then cued to report the vividness of the imagined item, and the effort exerted while imagining the item, on an absolute scale from 1 to 4. After a brief flash of the rivalry display, participants reported which grating had appeared perceptually dominant, or whether their percept was an equal mix of the two. On 10% of the trials &#x02013; instead of the rivalry display &#x02013; a mock-stimulus was presented to both eyes simultaneously, consisting of a physical combination of both the green and red grating. <bold>(B)</bold> To determine how well subjective ratings predict perceptual bias, type II ROC sensitivity was calculated by taking the area under the ROC curve (<italic>A</italic><sub>roc</sub>). This area is the sum of the area of the half-square triangle (dark-gray shaded region) and the area between the diagonal and the ROC function (light-gray shaded region).</p></caption><graphic xlink:href="fpsyg-03-00224-g001"/></fig><p>As soon as a participant had responded to both questions, a rivalry display (90% of trials) or a mock display (10% of trials) was presented for 750&#x02009;ms. On rivalry trials, the green grating was presented to the left eye, and the red grating to the right eye. On mock trials, the plaid-stimulus was presented to both eyes simultaneously. Participants reported which image had appeared most dominant, by pressing one of three buttons (1&#x02009;=&#x02009;<italic>green</italic>, 2&#x02009;=&#x02009;<italic>mixed</italic>, 3&#x02009;=&#x02009;<italic>red</italic>). For this response, the right hand was used in order to minimize potential response conflict between the two hands. A &#x0201c;mixed&#x0201d; response could be made on all trials (rivalry and mock trials). On rivalry trials, the observer could give a mixed response in case he or she was unable to distinguish which grating had appeared more dominant due to binocular combination or piecemeal rivalry. This type of mixed percept was reported on 6.49% of rivalry trials (SEM&#x02009;=&#x02009;2.49%).</p><p>A single training session consisted of two blocks of 70 trials each. Within each block, seven catch trials were randomly interleaved between the rivalry trials. We tested potential generalization of learning to non-trained orientations on day 1 and 5 of training, and during follow-up. On these days, observers performed twice the amount of trials, with training and generalization blocks presented separately and in a randomized order.</p></sec><sec><title>Analyses</title><p>To assess the strength of visual imagery, we looked at the perceptual facilitation (or bias) of imagery on rivalry. This was calculated as the percentage of trials in which the imagined grating matched subsequent perception during rivalry (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>), excluding trials on which a mixed percept was reported. A perceptual bias greater than 50% (chance) on the rivalry trials but not on the catch trials suggests facilitation due to imagery content. Due to experimenter error, a small number of runs (7 out of 108) were missing from the data. Where necessary, we used tri-linear interpolation to infer the mean percentage of bias. For the day-by-day analysis (Figure <xref ref-type="fig" rid="F2">2</xref>) only one data point was interpolated (percentage perceptual bias for participant CB on day 4); the session-by-session analysis of the same data required interpolation of all seven missing runs.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Imagery biased perception during rivalry in favor of the previously imagined grating, but this perceptual bias did not significantly change over the course of a 5-day training</bold>. The blue line represents the mean training data, and the blue shaded regions represent &#x000b1;1 SEM. The parts of the plot depicted in red represent data from blocks where we tested training generalization to other orientations.</p></caption><graphic xlink:href="fpsyg-03-00224-g002"/></fig><p>Data obtained from subjective ratings of vividness (and effort) were analyzed by constructing type II receiver operating characteristic (ROC) curves for each participant on each day of training. This method of assessing metacognitive ability is derived from signal detection methods (Swets, <xref ref-type="bibr" rid="B74">1986</xref>; Macmillan and Creelman, <xref ref-type="bibr" rid="B48">1991</xref>; Galvin et al., <xref ref-type="bibr" rid="B26">2003</xref>; Kornbrot, <xref ref-type="bibr" rid="B40">2006</xref>) and has been successfully employed in a variety of recent inquiries about metacognition (Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>; Song et al., <xref ref-type="bibr" rid="B72">2011</xref>). Essentially, the only difference between type I and type II tasks lies in the event that is being discriminated: Type I decisions are about the occurrence of events independent of the observer (so, distinguishing between signal and noise), whereas type II decisions are about whether a decision was correct or incorrect (so, making a metacognitive judgment).</p><p>Since it is not possible to be &#x0201c;correct&#x0201d; or &#x0201c;incorrect&#x0201d; about an internally generated image, we adapted the definition of the type II decision to include judgments about the vividness of single episodes of mental imagery and its effect on the perceptual outcome during brief instances of subsequent binocular rivalry. Applying the signal detection logic, we categorized trials where participants reported high vividness and where imagery subsequently biased perception as &#x0201c;hits.&#x0201d; Trials where participants reported high vividness but perception was not subsequently biased were categorized as &#x0201c;false alarms.&#x0201d; Here, the ROC II characterizes the probability of a participant being perceptually biased during rivalry, given a certain level of self-reported vividness.</p><p>To construct the ROC II curves, we calculated <italic>p</italic>(rating&#x02009;=&#x02009;<italic>i</italic>&#x02009;|&#x02009;perceptual bias) and <italic>p</italic>(rating&#x02009;=&#x02009;<italic>i</italic>&#x02009;|&#x02009;no perceptual bias) for all <italic>i</italic>, and transformed these into cumulative probabilities before plotting them against each other (anchored at [0,0] and [1,1]). Distribution-free methods were employed to characterize type II ROC sensitivity by calculating the area under the ROC curve (<italic>A</italic><sub>roc</sub>), and type II ROC bias (<italic>B</italic><sub>roc</sub>). These parameters are derived from simple geometry and do not make assumptions about the shape of the distribution (Kornbrot, <xref ref-type="bibr" rid="B40">2006</xref>). The area under the ROC curve (<italic>A</italic><sub>roc</sub>) quantifies the extent to which metacognitive judgments are predictive of perceptual bias during rivalry (Figure <xref ref-type="fig" rid="F1">1</xref>B); a diagonally flat ROC function indicates little predictive value of the metacognitive judgment on the subsequent perceptual outcome during rivalry. The area under the ROC curve is the sum of the area of the half-square triangle (dark-gray shaded region in Figure <xref ref-type="fig" rid="F1">1</xref>B) and the area between the diagonal and the ROC function (light-gray shaded region in Figure <xref ref-type="fig" rid="F1">1</xref>B):</p><disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>roc</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">.</mml:mo><mml:mn>25</mml:mn><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mfenced separators="" open="[" close="]"><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo class="MathClass-bin">-</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">.</mml:mo><mml:mn>5</mml:mn></mml:math></disp-formula><p>The bias of the ROC II curve (<italic>B</italic><sub>roc</sub>) was defined as the ratio <italic>K</italic><sub>B</sub><italic>/K</italic><sub>A</sub>, where <italic>K</italic><sub>B</sub> is the area between the ROC curve and the major diagonal (dashed line in Figure <xref ref-type="fig" rid="F1">1</xref>B) to the right of the minor diagonal (dotted line in Figure <xref ref-type="fig" rid="F1">1</xref>B), and <italic>K</italic><sub>A</sub> is the area between the ROC curve and the major diagonal to the left of the minor diagonal. A neutral bias would give <italic>B</italic><sub>roc</sub> equal to zero, while a negative or positive <italic>B</italic><sub>roc</sub> indicates a bias toward lower or higher ratings respectively.</p><disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mstyle class="text"><mml:mtext>roc</mml:mtext></mml:mstyle></mml:mrow></mml:msub><mml:mo class="MathClass-rel">=</mml:mo><mml:mo class="qopname">ln</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">.</mml:mo><mml:mn>25</mml:mn><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mfenced separators="" open="[" close="]"><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo class="MathClass-bin">-</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo class="MathClass-punc">.</mml:mo><mml:mn>25</mml:mn><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mfenced separators="" open="[" close="]"><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo class="MathClass-bin">-</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo class="MathClass-bin">-</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula><p>Previous research has shown that subjective ratings of vividness &#x02013; but not effort &#x02013; are predictive of how much perceptual bias someone experiences (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). To confirm this, we also applied the ROC II methods described above to participant&#x02019;s ratings of exerted effort. This effort-based ROC thus characterizes the probability of a participant being perceptually biased given a certain level of self-reported effort. Finally, to determine whether the ROC II model did a good job accounting for our metacognitive data, we fit a linear regression model:</p><disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mi>z</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mfenced><mml:mo class="MathClass-rel">=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo class="MathClass-bin">+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>z</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced><mml:mo class="MathClass-bin">+</mml:mo><mml:mi>&#x003b5;</mml:mi></mml:math></disp-formula><p>Where <italic>z</italic> is the inverse of the cumulative normal distribution function. The ROC II model provided a good fit to the self-reported vividness (mean <italic>R</italic><sup>2</sup>&#x02009;=&#x02009;0.976&#x02009;&#x000b1;&#x02009;0.004) and effort data (mean <italic>R</italic><sup>2</sup>&#x02009;=&#x02009;0.981&#x02009;&#x000b1;&#x02009;0.007).</p></sec></sec><sec><title>Results</title><sec><title>Imagery training</title><p>Sustained mental imagery can bias the perception of an ambiguous display, resulting in a reliable measure of imagery strength on a trial-to-trial basis (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>, <xref ref-type="bibr" rid="B57">2011</xref>). When people rate their imagery as more vivid, the likelihood that imagery influences perception is larger (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). Thus, if training mental imagery would result in more vivid images, one would expect to see an increase of perceptual bias over time. Figure <xref ref-type="fig" rid="F2">2</xref> shows the mean imagery strength (or &#x0201c;perceptual bias&#x0201d;) as a function of days of training and again 2&#x02009;weeks later. A within-subjects ANOVA revealed that training did not increase the amount of perceptual bias over time [<italic>F</italic><sub>(5,40)</sub>&#x02009;&#x0003c;&#x02009;1].</p><p>Mental imagery did bias perception in favor of the imagined grating [<italic>F</italic><sub>(5,40)</sub>&#x02009;=&#x02009;8.861; <italic>p</italic>&#x02009;=&#x02009;0.018] which is consistent with previous work demonstrating the effect of mental imagery on rivalry (Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>, <xref ref-type="bibr" rid="B57">2011</xref>). Unsurprisingly &#x02013; considering the lack of a training effect &#x02013; gratings of both trained and untrained (generalization) orientations yielded similar perceptual biases: a within-subjects ANOVA for training days 1, 5, and follow-up revealed no main effect of orientation [<italic>F</italic><sub>(1,8)</sub>&#x02009;&#x0003c;&#x02009;1]. Analyzing the data by session did not unveil any hidden differences in perceptual bias over time [<italic>F</italic><sub>(11,88)</sub>&#x02009;=&#x02009;1.106; <italic>p</italic>&#x02009;=&#x02009;0.366], which excludes the possibility that most learning took place between the first couple of sessions.</p><p>Additional evidence that mental imagery was not improved by training comes from participant&#x02019;s introspective judgments of imagery vividness. Mean self-reported vividness of mental imagery was statistically the same on all days of training [<italic>F</italic><sub>(5,40)</sub>&#x02009;=&#x02009;1.224; <italic>p</italic>&#x02009;=&#x02009;0.316]. Self-reports of exerted effort did not change over the course of training either [<italic>F</italic><sub>(5,40)</sub>&#x02009;&#x0003c;&#x02009;1]. In summary, neither the perceptual measure of imagery strength (&#x0201c;perceptual bias&#x0201d;) nor ratings of vividness showed any significant change over the 5-days of training. Thus, it appears that training in this study was unable to increase imagery strength over time.</p></sec><sec><title>Catch trials</title><p>Catch trials were presented in a randomly interleaved fashion on 10% of all experimental trials, to determine whether observers showed response bias in favor of the imagined grating. On these trials, a mock rivalry display was presented consisting of a balanced physical combination of the green and red gratings shown to both eyes simultaneously. If the effects observed during rivalry were due to decisional bias or demand characteristics, we expect to find the same degree of response bias on catch trials. We analyzed bias by coding veridical &#x0201c;mixed&#x0201d; responses to the catch trials as 50%, while responses that matched the cued pattern were coded as 100%, and responses opposite to the cued grating were coded as 0%. The percentage of catch trials during which participant&#x02019;s responses were biased in favor of the cued grating are shown in Figure <xref ref-type="fig" rid="F3">3</xref> (for all days of training). On average, this bias was 50.79%. This indicates that demand characteristics and decisional bias have a negligible influence on participant&#x02019;s reports of rivalry dominance, as previously documented (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Mean percentage of catch trials on which participant&#x02019;s response to the fake-rivalry display was biased in favor of the imagined grating</bold>. A score of 50% indicates a lack of bias. Gray shaded areas show each individual participant, the colored bars represent the 5&#x02009;days of training plus follow-up 2&#x02013;3&#x02009;weeks later.</p></caption><graphic xlink:href="fpsyg-03-00224-g003"/></fig></sec><sec><title>Metacognitive judgments</title><p>To assess whether people&#x02019;s metacognitive insights about imagery strength improve over the course of training, we constructed ROC II curves for each individual observer, on each day of training (Figure <xref ref-type="fig" rid="F4">4</xref>; Materials and Methods). The extent to which metacognitive judgments of vividness predict perceptual bias was quantified as the area under each ROC II curve. Data presented in Figure <xref ref-type="fig" rid="F4">4</xref> demonstrate that on earlier days of training (darker green lines) the area under the curve is smaller than on later days of training (lighter green lines). The upward bowing profile of the curves observable in over half of our participants demonstrates that vividness judgments indeed predict perceptual bias.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Participant&#x02019;s metacognition of imagery over the course of training</bold>. ROC II curves based on the vividness ratings reported by our participants (collapsed over Gabor orientations). Each plot represents an individual participant; the colored lines represent the ROC curves for the different days of training.</p></caption><graphic xlink:href="fpsyg-03-00224-g004"/></fig><p>There is a clear trend toward more metacognitive ability over time for both the trained [<italic>F</italic><sub>(5,40)</sub>&#x02009;=&#x02009;1.742; <italic>p</italic>&#x02009;=&#x02009;0.147] and untrained (generalization) orientation [<italic>F</italic><sub>(2,16)</sub>&#x02009;=&#x02009;7.416; <italic>p</italic>&#x02009;=&#x02009;0.005]. Trained and untrained orientations do not statistically differ [<italic>F</italic><sub>(1,8)</sub>&#x02009;&#x0003c;&#x02009;1]. This lack of orientation specificity may not be surprising considering that metacognition for perception is something presumably supported by higher-level frontal areas of the brain (Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>), where responses are invariant to fine-grained orientation information. Hence, we simplified our analysis by collapsing the data from all orientations before constructing the ROC II curves as displayed in Figure <xref ref-type="fig" rid="F4">4</xref>. Estimates of the type II ROC sensitivity <italic>A</italic><sub>roc</sub> are therefore slightly more reliable on day 1, day 5, and during follow-up, since they are constructed based on more data.</p><p>The information from Figure <xref ref-type="fig" rid="F4">4</xref> is summarized in Figure <xref ref-type="fig" rid="F5">5</xref>, showing the main effect of training: vividness judgments predict perceptual bias increasingly better over time [<italic>F</italic><sub>(5,40)</sub>&#x02009;=&#x02009;3.075; <italic>p</italic>&#x02009;=&#x02009;0.019]. This trend is linear when only looking at training days 1&#x02013;5 [<italic>F</italic><sub>(1,8)</sub>&#x02009;=&#x02009;5.846; <italic>p</italic>&#x02009;=&#x02009;0.042] but becomes quadratic when follow-up is included [<italic>F</italic><sub>(1,8)</sub>&#x02009;=&#x02009;8.778; <italic>p</italic>&#x02009;=&#x02009;0.018], indicating a drop of the proportion <italic>A</italic><sub>roc</sub> at follow-up. Nevertheless, planned comparisons (uncorrected <italic>t</italic>-tests) show that &#x02013; with the exception of day 1 &#x02013; the predictive value of self-reported vividness on the perceptual outcome is larger than would be expected by chance (one-tailed one-sample <italic>t</italic>-test day 1: <italic>p</italic>&#x02009;=&#x02009;0.243; all others: <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.029), and this ability is still present 2&#x02013;3&#x02009;weeks after training (<italic>p</italic>&#x02009;=&#x02009;0.021).</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Imagery metacognition improves over the course of training</bold>. The extent to which self-reported vividness predicts perceptual bias (quantified as the area under the ROC II curve after collapsing all grating orientations, as also shown in Figure <xref ref-type="fig" rid="F4">4</xref>) plotted against day of training. Shaded areas represent &#x000b1;1 SEM.</p></caption><graphic xlink:href="fpsyg-03-00224-g005"/></fig><p>In previous work we demonstrated that people can reliably evaluate the vividness of their mental imagery from one trial to the next (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). Participants in that previous study were tested only once. Thus, one might expect to find evidence for metacognition of imagery strength on day 1 of training in the current experiment. However, the difference in analyses used to determine metacognition in our previous and current work (within-subjects analysis of variance, and area under ROC II curve respectively), make it hard to directly compare the findings. A within-subjects analysis of variance performed on the current data shows that on day 1 of training, participants marginally (but not significantly) showed a main effect of vividness on perceptual bias [<italic>F</italic><sub>(3,15)</sub>&#x02009;=&#x02009;2.83; <italic>p</italic>&#x02009;=&#x02009;0.074]. However, a lack of observed power (0.558) indicates that at this sample size there is only a small (44%) chance of finding a significant effect (at &#x003b1;&#x02009;=&#x02009;0.05) when assuming that people have metacognitive insights into their own imagery strength at the population level. An <italic>a priori</italic> power analysis indicates that, assuming a medium effect size, 21 subjects would be required to obtain a power of 0.95.</p><p>Vividness ratings are predictive of the efficacy that mental imagery has at biasing the perception of rivaling stimuli. By contrast, self-reported effort for imagery was not hypothesized to predict perceptual bias. Attempts to exert greater effort do not necessarily result in highly effective imagery, as demonstrated by previous work (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). To ensure that our findings were specific to introspective vividness &#x02013; and not effort &#x02013; we constructed ROC II curves (as in Figure <xref ref-type="fig" rid="F4">4</xref>; Materials and Methods) based on the effort ratings reported by our participants. The pooled (across participants) curves per day are shown in Figure <xref ref-type="fig" rid="F6">6</xref>A; the diagonally flat function indicates a weak link between self-reported effort ratings and perceptual bias during rivalry. Figure <xref ref-type="fig" rid="F6">6</xref>B demonstrates that, as expected, effort did not predict perceptual bias [<italic>F</italic><sub>(1,8)</sub>&#x02009;&#x0003c;&#x02009;1]. The area under the ROC II curve (<italic>A</italic><sub>roc</sub>), which quantifies the degree to which self-reported effort predicts perceptual bias during rivalry, did not differ from chance on any of the training days (two-tailed one-sample <italic>t</italic>-tests all <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.081). Neither did we observe a change over time for the trained [<italic>F</italic><sub>(5,40)</sub>&#x02009;&#x0003c;&#x02009;1], untrained (generalized) [<italic>F</italic><sub>(2,16)</sub>&#x02009;=&#x02009;2.711; <italic>p</italic>&#x02009;=&#x02009;0.097], or collapsed [<italic>F</italic><sub>(5,40)</sub>&#x02009;&#x0003c;&#x02009;1] grating orientations.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Participant&#x02019;s self-reported effort with which the gratings were imagined does not predict perceptual bias</bold>. <bold>(A)</bold> ROC II curves based on the effort ratings pooled across participants. Green colored lines represent the different days of training. The diagonally flat functions indicate a weak link between self-reported effort ratings and perceptual bias during rivalry. <bold>(B)</bold> The extent to which self-reported effort predicts perceptual bias (quantified as the area under the ROC II curve) plotted against each day of training. Self-reported effort does not predict perceptual bias, and this does not change over time. Data was collapsed over Gabor orientations, since outcomes did not differ between the two sets of orientations [<italic>F</italic><sub>(1,8)</sub>&#x02009;&#x0003c;&#x02009;1]. Shaded areas represent &#x000b1;1 SEM.</p></caption><graphic xlink:href="fpsyg-03-00224-g006"/></fig><p>Vividness appears to predict perceptual bias more strongly over the course of training, whereas effort does not predict perceptual bias at all. Can this finding be explained by the way participants used the rating scales? Participant&#x02019;s average reported vividness (2.57&#x02009;&#x000b1;&#x02009;0.21) and effort (2.86&#x02009;&#x000b1;&#x02009;0.14) did not significantly differ (<italic>p</italic>&#x02009;=&#x02009;0.261). In other words, subjective vividness &#x02013; but not effort &#x02013; is predictive of how well something was imagined independent of rating-magnitude. Signal detection theory considers metacognitive ability (sensitivity) and rating-magnitude (bias) as two independent properties (Galvin et al., <xref ref-type="bibr" rid="B26">2003</xref>). In accordance with this notion, we find that individuals with higher self-reported vividness were not better at evaluating their imagery strength and vice versa. Specifically, participant&#x02019;s ability to make accurate metacognitive judgments of their mental imagery (<italic>A</italic><sub>roc</sub> vividness) and participant&#x02019;s mean vividness ratings were not correlated (<italic>r</italic>&#x02009;=&#x02009;0.063; <italic>p</italic>&#x02009;=&#x02009;0.873).</p><p>The type II bias of the ROC curve (<italic>B</italic><sub>roc</sub>) provides us with a distribution-free estimate of the criterion used by participants to provide their subjective ratings. A neutral bias would give <italic>B</italic><sub>roc</sub> equal to zero, while a negative or positive <italic>B</italic><sub>roc</sub> indicates a bias toward lower or higher ratings respectively. This estimate corresponded very well with the actual rating-magnitude collected during the experiment: self-reported vividness ratings and estimated vividness bias (<italic>B</italic><sub>roc</sub> vividness) were highly correlated (<italic>r</italic>&#x02009;=&#x02009;0.913; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), as were self-reported effort and estimated effort bias (<italic>r</italic>&#x02009;=&#x02009;0.889; <italic>p</italic>&#x02009;=&#x02009;0.001). The close resemblance between these two variables &#x02013; both measures of participant&#x02019;s criterion &#x02013; helps validate the distribution-free approach used to determine ROC estimates in the current paradigm.</p><p>Strikingly, Figure <xref ref-type="fig" rid="F4">4</xref> shows large differences between individuals: the degree to which metacognitive vividness judgments predict perceptual bias varies quite a bit from one person to the next (<italic>A</italic><sub>roc&#x02009;</sub>=&#x02009;0.48&#x02013;0.71). This type of variability is not uncommon, and previous studies have reported similarly large individual differences in metacognitive ability for perceptual tasks (Song et al., <xref ref-type="bibr" rid="B72">2011</xref>). Besides large differences related to metacognition, also the overall amount of perceptual bias experienced by our participants varied widely (46&#x02013;76%). Nonetheless, participant&#x02019;s overall metacognitive ability and the percent perceptual bias they experienced throughout the experiment, were uncorrelated (<italic>r</italic>&#x02009;=&#x02009;&#x02212;0.027; <italic>p</italic>&#x02009;=&#x02009;0.945). This suggests that participant&#x02019;s metacognitive ability in this task is independent of imagery strength, as measured by binocular rivalry.</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>The research presented here suggests that mental imagery strength does not improve over the course of our 5-day training regime. Over the 5-days, no changes were observed relating to imagery strength as measured by rivalry, nor were there any changes in the average introspective judgments of imagery vividness. We further demonstrated that self-reported vividness of mental imagery predicts the perceptual consequences of single epochs of imagery. More importantly, this prediction becomes stronger with practice, implying increased metacognition of imagery over the course of training. Self-reported effort of mental imagery on the other hand, did not predict perceptual outcomes.</p><p>There have been reports of visual imagery increasing performance on subsequent perceptual tasks (Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>). Yet we were unable to find an increase in facilitation of rivalry dominance after 5&#x02009;days of training. The question is of course, why? The emphasis of the research presented here was on improving imagery strength over time. This is a notably different emphasis from studies that have investigated how imagery training changes perceptual skills (Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>). One obvious explanation for the lack of an imagery training effect in this study is that imagery strength simply cannot improve with practice. This idea is corroborated by the fact that neither imagery bias, nor subjective ratings of imagery strength showed a significant increase as a function of training. Introspective ratings of imagery strength are reflected in the perceptual outcomes during rivalry, and the close relationship between the two implies they measure the same underlying construct (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). Thus, several aspects of the data support the hypothesis that it is not possible &#x02013; or very difficult &#x02013; to improve imagery strength by means of training.</p><p>The idea that training cannot easily change imagery strength might be explained by the manner in which imagery strength is linked to brain anatomy. The Tartaglia study (Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>) had participants repetitively imagine the crucial part of a bisection stimulus (spatial judgment) or a low-contrast Gabor pattern (contrast judgment). They found improved perceptual performance on a subsequent perceptual bisection task and a Gabor detection task after imagery training, and this improvement generalized to untrained orientations. This lack of orientation specificity implies that learning through imagery did not involve plastic changes in early visual cortex, but probably involved higher-level extra-striate areas. Higher-level changes may boost perceptual performance through imagery training, yet, changes at this cortical level may not be sufficient to improve imagery strength itself.</p><p>Historically, mental imagery has been considered a fainter form of perception (Hume, <xref ref-type="bibr" rid="B32">1739</xref>). Evidence to support this notion comes from functional magnetic resonance imaging (fMRI) studies demonstrating that the magnitude of brain activity is lower during imagery than during bottom-up perception (Goebel et al., <xref ref-type="bibr" rid="B28">1998</xref>; O&#x02019;Craven and Kanwisher, <xref ref-type="bibr" rid="B54">2000</xref>). Likewise, single neuron recordings in the medial temporal lobe of humans found fewer neurons that were recruited during imagery than during perception, and that the firing rate of these cells was lower during imagery compared to perception (Kreiman et al., <xref ref-type="bibr" rid="B44">2000</xref>). In the case of perceptual bias during rivalry, imagery is presumed to influence or boost the memory trace that exists between one rivalry presentation and the next, and the location and orientation specificity of this memory trace implies that it is composed of primarily low-level characteristics (Ishai and Sagi, <xref ref-type="bibr" rid="B33">1995</xref>; Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>; Slotnick, <xref ref-type="bibr" rid="B70">2008</xref>). Mechanisms such as a gain in sensitivity for the imagined pattern, or the strengthening of sensory traces, would be needed to modify population activity in lower visual areas mediating alternations of conscious perception during rivalry. Imagery may simply lack sufficient impact to induce permanent plastic changes at these lowest sensory levels. Future research directions aiming to improve imagery strength could investigate the necessity of bottom-up information for learning. Specifically, it would be interesting to see if there is a transfer from improving visual perception by means of prolonged training with actual sensory stimuli, to improvements of imagery strength.</p><p>One could hypothesize that imagery strength is liable to improvement, but we simply failed to find any in this study due to the configuration of our task. Research into the process of improving perceptual skill &#x02013; or perceptual learning &#x02013; provides useful context in support of this hypothesis. One influential view known as the reverse hierarchy theory (Ahissar and Hochstein, <xref ref-type="bibr" rid="B3">2004</xref>), states that learning is gated by top-down, task-related factors: Learning begins at high-level areas of the brain, after which it trickles down the hierarchy, fine-tuning the read out from lower level areas. This theory invokes a number of detailed predictions, namely, early (fast) learning should be related to high-level changes, whereas asymptotic (slow) learning should involve plasticity in low-level sensory areas &#x02013; if required by the task. There is considerable evidence supporting this view (Ahissar and Hochstein, <xref ref-type="bibr" rid="B1">1993</xref>, <xref ref-type="bibr" rid="B2">1997</xref>; Dosher and Lu, <xref ref-type="bibr" rid="B15">1998</xref>; Dupuis-Roy and Gosselin, <xref ref-type="bibr" rid="B19">2007</xref>).</p><p>In light of the reverse hierarchy framework, our training regime is suspect to a critical vulnerability. Namely: training duration. Five days may have been insufficient time to reach the asymptotic learning phase. The Tartaglia study previously mentioned (Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>) trained participant&#x02019;s imagery for 10&#x02009;days, twice as long as in our study, and found an improvement on perceptual tasks. Assuming that specific cellular plastic processes at the hierarchical level of ocular dominance columns can only occur during asymptotic learning, longer training might be necessary when aiming to influence rivalry perception.</p><p>Recent research has demonstrated that perceptual learning can also occur without a specific task and outside of awareness, as long as the information of interest is paired with feedback or a reward signal (Seitz and Watanabe, <xref ref-type="bibr" rid="B66">2003</xref>, <xref ref-type="bibr" rid="B64">2005</xref>; Seitz et al., <xref ref-type="bibr" rid="B65">2009</xref>) or with online-feedback via decoded fMRI signals (Shibata et al., <xref ref-type="bibr" rid="B69">2011</xref>). Our experimental design lacked a direct reward signal. Perhaps if successful epochs of imagery were paired with a reward signal, this could facilitate learning. In practice the implementation of a reward may prove difficult to realize. Often, measures of imagery strength are dependent on subjective reports, and offering rewards based on only self-reports could induce strong response and observer biases. Nevertheless, it is possible that our training was insufficient to obtain an effect, and providing feedback, rewards, or some manner of getting participants to intentionally try and increase their imagery strength, could have been a more effective way to train mental imagery.</p><p>During memory consolidation, initially fragile memory traces become stabilized due to practice-induced plasticity in task relevant brain areas (Karni, <xref ref-type="bibr" rid="B36">1996</xref>; Dudai, <xref ref-type="bibr" rid="B18">2004</xref>). Can the ineffectiveness of imagery training be due to somehow disrupted memory consolidation? Classically, consolidation has been defined as a time limited process directly following learning (Dudai, <xref ref-type="bibr" rid="B18">2004</xref>). However, recent studies indicate that interference is rather time independent, and can occur at long intervals after training (Goedert and Willingham, <xref ref-type="bibr" rid="B29">2002</xref>; Caithness et al., <xref ref-type="bibr" rid="B8">2004</xref>; Zhang et al., <xref ref-type="bibr" rid="B80">2008</xref>). Interference can be considered strongly stimulus dependent, resulting from similarity between the learned and interfering stimulus, and the corresponding neuronal populations recruited by these stimuli (Seitz et al., <xref ref-type="bibr" rid="B67">2005</xref>; Been et al., <xref ref-type="bibr" rid="B6">2011</xref>). Specifically, for Gabor patterns most interference occurs when interfering stimuli differ from the learned orientation by 30&#x000b0;, while no interference is observed from orthogonal orientations (Been et al., <xref ref-type="bibr" rid="B6">2011</xref>). Considering the orthogonal training orientations of our experiment, disruption of consolidation seems an unlikely explanation for the ineffectiveness of imagery training.</p><p>Can people become better at knowing their own thoughts? We were able to improve subject&#x02019;s ability to judge the vividness of their imagery. This improvement was still present during a follow-up test, implying a long lasting effect of training on metacognitive evaluation of mental imagery. Furthermore, training of metacognition was not orientation specific: metacognition was improved for both trained and untrained sets of orientations. It is likely that the improvement of metacognition reported here originates from higher-level brain areas. This is in concordance with the suspected high-level neural locus of metacognitive ability for perception (Kepecs et al., <xref ref-type="bibr" rid="B38">2008</xref>; Kiani and Shadlen, <xref ref-type="bibr" rid="B39">2009</xref>; Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>) as well as the idea that networks in high-level cortical regions orchestrate strategic choices during early learning, allocating attention and motivation in response to specific task demands (Willingham, <xref ref-type="bibr" rid="B78">1999</xref>; Hochstein and Ahissar, <xref ref-type="bibr" rid="B31">2002</xref>; Doyon et al., <xref ref-type="bibr" rid="B16">2003</xref>).</p><p>Our study demonstrated improvements of the metacognition of imagery, whereas no changes in imagery strength itself were observed. This dissociation suggests distinct brain mechanisms underlying metacognition and visual imagery respectively. Similar distinctions have been made regarding metacognition of perception: Neuroanatomical substrates of introspective ability are distinct from those supporting primary perception (Fleming et al., <xref ref-type="bibr" rid="B24">2010</xref>), and there is a marked dissociation between metacognitive ability and performance on visual perceptual tasks (Lau and Passingham, <xref ref-type="bibr" rid="B47">2006</xref>; Lau, <xref ref-type="bibr" rid="B46">2008</xref>; Rounis et al., <xref ref-type="bibr" rid="B61">2010</xref>; Song et al., <xref ref-type="bibr" rid="B72">2011</xref>). Thus, metacognitive ability can be viewed as a stable and task independent cognitive process that can be improved with practice, independent of performance on other tasks. Changes in high-level neuronal populations are likely candidates for this learning.</p><p>The ability to introspect on private thoughts is key to human subjective experience. Yet, people&#x02019;s ability to evaluate internally generated experiences &#x02013; such as imagery &#x02013; is not as self-evident as it may appear. Although a large number of studies now demonstrate that something as private as a mental image can be successfully studied from a third-person perspective (Ishai and Sagi, <xref ref-type="bibr" rid="B33">1995</xref>, <xref ref-type="bibr" rid="B34">1997</xref>; Kosslyn et al., <xref ref-type="bibr" rid="B41">2001</xref>; Pearson et al., <xref ref-type="bibr" rid="B56">2008</xref>; Tartaglia et al., <xref ref-type="bibr" rid="B75">2009</xref>), research has only recently begun to tackle issues related to the first-person perspective (Pearson et al., <xref ref-type="bibr" rid="B57">2011</xref>). The core problem from the first-person perspective of the imaginer is that self-generated instances of imagery, unlike perception, cannot be directly compared with a perceptual template. Nevertheless, people seem quite capable of knowing if a mental image is accurate, vivid, or detailed. And practice further improves this first-person introspective ability. Why might such metacognitive knowledge be important?</p><p>Introspective or &#x0201c;metacognitive&#x0201d; sensitivity is important to guide actions and to make decisions (Vickers, <xref ref-type="bibr" rid="B76">1979</xref>; Daw et al., <xref ref-type="bibr" rid="B13">2005</xref>; Dayan and Daw, <xref ref-type="bibr" rid="B14">2008</xref>) and being able to adequately estimate ones confidence can help drive adaptive behavior (Kepecs et al., <xref ref-type="bibr" rid="B38">2008</xref>). In its simplest form, low confidence that a recent decision was correct may prompt reexamination of the evidence, or seeking a second-opinion. In the event of internally generated experiences such as mental imagery, low confidence that an image was veridical and life-like may lead someone to reconsider such an experience. A better metacognitive understanding may help the imaginer bridge the gap between first and third-person perspective. For example, people can resolve potential ambiguities about perception by comparing their own perceptual experience with the subjective experience of another person (Bahrami et al., <xref ref-type="bibr" rid="B5">2010</xref>). Similarly, when the imaginer has a better understanding of the authenticity of his or her mental image, it will be easier to communicate its content to another person. In sum, increasing the efficiency with which people introspect the quality of their mental images can prove a novel and important finding.</p><p>In conclusion, we discussed a variety of reasons why training did not lead to an improvement of imagery strength in the current study. Such an improvement may simply be very difficult to document, or our task may not have been optimally suited to detect improvements of imagery strength. Nevertheless, we demonstrated that people&#x02019;s ability to introspect their own imagery strength does improve with training, which suggests distinct mechanisms underlying imagery and metacognition. Being able to improve metacognition by means of practice can have important implications for real-life situations. It would be interesting to know if training metacognition could help people improve certain cognitive functions, such as decision-making or planning actions. If so, this may prove especially helpful for specific patient populations. Finally, future investigations of prolonged training of imagery can prove advantageous in outlining the overlap between mechanisms of perception and imagery. Imagery as defined here is a highly voluntary process that allows introspection in the absence of direct perceptual input. As such, imagery can provide a unique gateway to understanding how perceptual and introspective processes are represented in the brain.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><p>We thank Frank Tong for discussions and helpful input with design and execution of this work. We also thank Jan Brascamp, Elias Cohen, Janneke Jehee, Jan Schepers, and Jascha Swisher for helpful comments and discussions regarding this research. This work was funded by grants from the National Health and Medical Research Council of Australia CJ Martin Fellowship 457146 and project grant APP1024800 to Joel Pearson.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>M.</given-names></name><name><surname>Hochstein</surname><given-names>S.</given-names></name></person-group> (<year>1993</year>). <article-title>Attentional control of early perceptual learning</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>90</volume>, <fpage>5718</fpage>&#x02013;<lpage>5722</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.12.5718</pub-id><pub-id pub-id-type="pmid">8516322</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>M.</given-names></name><name><surname>Hochstein</surname><given-names>S.</given-names></name></person-group> (<year>1997</year>). <article-title>Task difficulty and the specificity of perceptual learning</article-title>. <source>Nature</source>
<volume>387</volume>, <fpage>401</fpage>&#x02013;<lpage>406</lpage><pub-id pub-id-type="doi">10.1038/387401a0</pub-id><pub-id pub-id-type="pmid">9163425</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>M.</given-names></name><name><surname>Hochstein</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). <article-title>The reverse hierarchy theory of visual perceptual learning</article-title>. <source>Trends Cogn. Sci. (Regul. Ed.)</source>
<volume>8</volume>, <fpage>457</fpage>&#x02013;<lpage>464</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.08.011</pub-id><pub-id pub-id-type="pmid">15450510</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amedi</surname><given-names>A.</given-names></name><name><surname>Malach</surname><given-names>R.</given-names></name><name><surname>Pascual-Leone</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Negative BOLD differentiates visual imagery and perception</article-title>. <source>Neuron</source>
<volume>48</volume>, <fpage>859</fpage>&#x02013;<lpage>872</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.10.032</pub-id><pub-id pub-id-type="pmid">16337922</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bahrami</surname><given-names>B.</given-names></name><name><surname>Olsen</surname><given-names>K.</given-names></name><name><surname>Latham</surname><given-names>P. E.</given-names></name><name><surname>Roepstorff</surname><given-names>A.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name><name><surname>Frith</surname><given-names>C. D.</given-names></name></person-group> (<year>2010</year>). <article-title>Optimally interacting minds</article-title>. <source>Science</source>
<volume>329</volume>, <fpage>1081</fpage>&#x02013;<lpage>1085</lpage><pub-id pub-id-type="doi">10.1126/science.1185718</pub-id><pub-id pub-id-type="pmid">20798320</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Been</surname><given-names>M.</given-names></name><name><surname>Jans</surname><given-names>B.</given-names></name><name><surname>De Weerd</surname><given-names>P.</given-names></name></person-group> (<year>2011</year>). <article-title>Time-limited consolidation and task interference: no direct link</article-title>. <source>J. Neurosci.</source>
<volume>31</volume>, <fpage>14944</fpage>&#x02013;<lpage>14951</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1046-11.2011</pub-id><pub-id pub-id-type="pmid">22016527</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>D. H.</given-names></name></person-group> (<year>1997</year>). <article-title>The psychophysics toolbox</article-title>. <source>Spat. Vis.</source>
<volume>10</volume>, <fpage>433</fpage>&#x02013;<lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caithness</surname><given-names>G.</given-names></name><name><surname>Osu</surname><given-names>R.</given-names></name><name><surname>Bays</surname><given-names>P.</given-names></name><name><surname>Chase</surname><given-names>H.</given-names></name><name><surname>Klassen</surname><given-names>J.</given-names></name><name><surname>Kawato</surname><given-names>M.</given-names></name><name><surname>Wolpert</surname><given-names>D. M.</given-names></name><name><surname>Flanagan</surname><given-names>J. R.</given-names></name></person-group> (<year>2004</year>). <article-title>Failure to consolidate the consolidation theory of learning for sensorimotor adaptation tasks</article-title>. <source>J. Neurosci.</source>
<volume>24</volume>, <fpage>8662</fpage>&#x02013;<lpage>8671</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2214-04.2004</pub-id><pub-id pub-id-type="pmid">15470131</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>W.</given-names></name><name><surname>Kato</surname><given-names>T.</given-names></name><name><surname>Zhu</surname><given-names>X. H.</given-names></name><name><surname>Ogawa</surname><given-names>S.</given-names></name><name><surname>Tank</surname><given-names>D. W.</given-names></name><name><surname>Ugurbil</surname><given-names>K.</given-names></name></person-group> (<year>1998</year>). <article-title>Human primary visual cortex and lateral geniculate nucleus activation during visual imagery</article-title>. <source>Neuroreport</source>
<volume>9</volume>, <fpage>3669</fpage>&#x02013;<lpage>3674</lpage><pub-id pub-id-type="doi">10.1097/00001756-199811160-00019</pub-id><pub-id pub-id-type="pmid">9858377</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname><given-names>S.</given-names></name><name><surname>Blake</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Exogenous attention and endogenous attention influence initial dominance in binocular rivalry</article-title>. <source>Vision Res.</source>
<volume>46</volume>, <fpage>1794</fpage>&#x02013;<lpage>1803</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2005.10.031</pub-id><pub-id pub-id-type="pmid">16368126</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craver-Lemley</surname><given-names>C.</given-names></name><name><surname>Reeves</surname><given-names>A.</given-names></name></person-group> (<year>1992</year>). <article-title>How visual imagery interferes with vision</article-title>. <source>Psychol. Rev.</source>
<volume>99</volume>, <fpage>633</fpage>&#x02013;<lpage>649</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.99.4.633</pub-id><pub-id pub-id-type="pmid">1454902</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>X.</given-names></name><name><surname>Jeter</surname><given-names>C. B.</given-names></name><name><surname>Yang</surname><given-names>D.</given-names></name><name><surname>Montague</surname><given-names>P. R.</given-names></name><name><surname>Eagleman</surname><given-names>D. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Vividness of mental imagery: individual variability can be measured objectively</article-title>. <source>Vision Res.</source>
<volume>47</volume>, <fpage>474</fpage>&#x02013;<lpage>478</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2006.11.013</pub-id><pub-id pub-id-type="pmid">17239915</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>N. D.</given-names></name><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat. Neurosci.</source>
<volume>8</volume>, <fpage>1704</fpage>&#x02013;<lpage>1711</lpage><pub-id pub-id-type="doi">10.1038/nn1560</pub-id><pub-id pub-id-type="pmid">16286932</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Daw</surname><given-names>N. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Decision theory, reinforcement learning, and the brain</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>8</volume>, <fpage>429</fpage>&#x02013;<lpage>453</lpage><pub-id pub-id-type="doi">10.3758/CABN.8.4.429</pub-id><pub-id pub-id-type="pmid">19033240</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosher</surname><given-names>B. A.</given-names></name><name><surname>Lu</surname><given-names>Z. L.</given-names></name></person-group> (<year>1998</year>). <article-title>Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>95</volume>, <fpage>13988</fpage>&#x02013;<lpage>13993</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.23.13988</pub-id><pub-id pub-id-type="pmid">9811913</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyon</surname><given-names>J.</given-names></name><name><surname>Penhune</surname><given-names>V.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>2003</year>). <article-title>Distinct contribution of the cortico-striatal and cortico-cerebellar systems to motor skill learning</article-title>. <source>Neuropsychologia</source>
<volume>41</volume>, <fpage>252</fpage>&#x02013;<lpage>262</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(02)00158-6</pub-id><pub-id pub-id-type="pmid">12457751</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driskell</surname><given-names>J.</given-names></name><name><surname>Copper</surname><given-names>C.</given-names></name><name><surname>Moran</surname><given-names>A.</given-names></name></person-group> (<year>1994</year>). <article-title>Does mental practice enhance performance?</article-title>
<source>J. of Appl. Psychol.</source>
<volume>79</volume>, <fpage>481</fpage>&#x02013;<lpage>491</lpage><pub-id pub-id-type="doi">10.1037/0021-9010.79.4.481</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudai</surname><given-names>Y.</given-names></name></person-group> (<year>2004</year>). <article-title>The neurobiology of consolidations, or, how stable is the engram?</article-title>
<source>Annu. Rev. Psychol.</source>
<volume>55</volume>, <fpage>51</fpage>&#x02013;<lpage>86</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.55.090902.142050</pub-id><pub-id pub-id-type="pmid">14744210</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupuis-Roy</surname><given-names>N.</given-names></name><name><surname>Gosselin</surname><given-names>F.</given-names></name></person-group> (<year>2007</year>). <article-title>Perceptual learning without signal</article-title>. <source>Vision Res.</source>
<volume>47</volume>, <fpage>349</fpage>&#x02013;<lpage>356</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2006.10.016</pub-id><pub-id pub-id-type="pmid">17178142</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fahle</surname><given-names>M.</given-names></name><name><surname>Poggio</surname><given-names>T.</given-names></name></person-group> (<year>2002</year>). <source>Perceptual Learning</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Feltz</surname><given-names>D. L.</given-names></name><name><surname>Landers</surname><given-names>D. M.</given-names></name></person-group> (<year>2007</year>). <source>The Effects of Mental Practice on Motor Skill Learning and Performance: A Meta-analysis</source>. <publisher-loc>Champaign, IL</publisher-loc>: <publisher-name>Human Kinetics</publisher-name></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fine</surname><given-names>I.</given-names></name><name><surname>Jacobs</surname><given-names>R. A.</given-names></name></person-group> (<year>2002</year>). <article-title>Comparing perceptual learning tasks: a review</article-title>. <source>J. Vis.</source>
<volume>2</volume>, <fpage>190</fpage>&#x02013;<lpage>203</lpage><pub-id pub-id-type="doi">10.1167/2.10.66</pub-id><pub-id pub-id-type="pmid">12678592</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>J. H.</given-names></name></person-group> (<year>1979</year>). <article-title>Metacognition and cognitive monitoring: a new area of cognitive-developmental inquiry</article-title>. <source>Am. Psychol.</source>
<volume>34</volume>, <fpage>906</fpage>&#x02013;<lpage>911</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.34.10.906</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>S. M.</given-names></name><name><surname>Weil</surname><given-names>R. S.</given-names></name><name><surname>Nagy</surname><given-names>Z.</given-names></name><name><surname>Dolan</surname><given-names>R. J.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>). <article-title>Relating introspective accuracy to individual differences in brain structure</article-title>. <source>Science</source>
<volume>329</volume>, <fpage>1541</fpage>&#x02013;<lpage>1543</lpage><pub-id pub-id-type="doi">10.1126/science.1191883</pub-id><pub-id pub-id-type="pmid">20847276</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Galton</surname><given-names>F.</given-names></name></person-group> (<year>1883</year>). <source>Inquiries into Human Faculty and its Development</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Macmillan</publisher-name></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galvin</surname><given-names>S. J.</given-names></name><name><surname>Podd</surname><given-names>J. V.</given-names></name><name><surname>Drga</surname><given-names>V.</given-names></name><name><surname>Whitmore</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>Type 2 tasks in the theory of signal detectability: discrimination between correct and incorrect decisions</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>10</volume>, <fpage>843</fpage>&#x02013;<lpage>876</lpage><pub-id pub-id-type="doi">10.3758/BF03196546</pub-id><pub-id pub-id-type="pmid">15000533</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilden</surname><given-names>D.</given-names></name><name><surname>Blake</surname><given-names>R.</given-names></name><name><surname>Hurst</surname><given-names>G.</given-names></name></person-group> (<year>1995</year>). <article-title>Neural adaptation of imaginary visual motion</article-title>. <source>Cogn. Psychol.</source>
<volume>28</volume>, <fpage>1</fpage>&#x02013;<lpage>16</lpage><pub-id pub-id-type="doi">10.1006/cogp.1995.1002</pub-id><pub-id pub-id-type="pmid">7895467</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goebel</surname><given-names>R.</given-names></name><name><surname>Khorram-Sefat</surname><given-names>D.</given-names></name><name><surname>Muckli</surname><given-names>L.</given-names></name><name><surname>Hacker</surname><given-names>H.</given-names></name><name><surname>Singer</surname><given-names>W.</given-names></name></person-group> (<year>1998</year>). <article-title>The constructive nature of vision: direct evidence from functional magnetic resonance imaging studies of apparent motion and motion imagery</article-title>. <source>Eur. J. Neurosci.</source>
<volume>10</volume>, <fpage>1563</fpage>&#x02013;<lpage>1573</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.1998.00181.x</pub-id><pub-id pub-id-type="pmid">9751129</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goedert</surname><given-names>K. M.</given-names></name><name><surname>Willingham</surname><given-names>D. B.</given-names></name></person-group> (<year>2002</year>). <article-title>Patterns of interference in sequence learning and prism adaptation inconsistent with the consolidation hypothesis</article-title>. <source>Learn. Mem.</source>
<volume>9</volume>, <fpage>279</fpage>&#x02013;<lpage>292</lpage><pub-id pub-id-type="doi">10.1101/lm.50102</pub-id><pub-id pub-id-type="pmid">12359837</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>S.</given-names></name><name><surname>Tong</surname><given-names>F.</given-names></name></person-group> (<year>2009</year>). <article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title>. <source>Nature</source>
<volume>458</volume>, <fpage>632</fpage>&#x02013;<lpage>635</lpage><pub-id pub-id-type="doi">10.1038/nature07832</pub-id><pub-id pub-id-type="pmid">19225460</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochstein</surname><given-names>S.</given-names></name><name><surname>Ahissar</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>View from the top: hierarchies and reverse hierarchies in the visual system</article-title>. <source>Neuron</source>
<volume>36</volume>, <fpage>791</fpage>&#x02013;<lpage>804</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01091-7</pub-id><pub-id pub-id-type="pmid">12467584</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hume</surname><given-names>D.</given-names></name></person-group> (<year>1739</year>). <source>A Treatise on Human Nature</source>, Vol. <volume>1</volume>
<publisher-loc>London</publisher-loc>: <publisher-name>John Noon</publisher-name></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishai</surname><given-names>A.</given-names></name><name><surname>Sagi</surname><given-names>D.</given-names></name></person-group> (<year>1995</year>). <article-title>Common mechanisms of visual imagery and perception</article-title>. <source>Science</source>
<volume>268</volume>, <fpage>1772</fpage>&#x02013;<lpage>1774</lpage><pub-id pub-id-type="doi">10.1126/science.7792605</pub-id><pub-id pub-id-type="pmid">7792605</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishai</surname><given-names>A.</given-names></name><name><surname>Sagi</surname><given-names>D.</given-names></name></person-group> (<year>1997</year>). <article-title>Visual imagery: effects of short-and long-term memory</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>9</volume>, <fpage>734</fpage>&#x02013;<lpage>742</lpage><pub-id pub-id-type="doi">10.1162/jocn.1997.9.4.476</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamphuisen</surname><given-names>A.</given-names></name><name><surname>Van Wezel</surname><given-names>R.</given-names></name><name><surname>Van Ee</surname><given-names>R.</given-names></name></person-group> (<year>2007</year>). <article-title>Inter-ocular transfer of stimulus cueing in dominance selection at the onset of binocular rivalry</article-title>. <source>Vision Res.</source>
<volume>47</volume>, <fpage>1142</fpage>&#x02013;<lpage>1144</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2007.01.016</pub-id><pub-id pub-id-type="pmid">17360017</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karni</surname><given-names>A.</given-names></name></person-group> (<year>1996</year>). <article-title>The acquisition of perceptual and motor skills: a memory system in the adult human cortex</article-title>. <source>Brain Res. Cogn. Brain Res.</source>
<volume>5</volume>, <fpage>39</fpage>&#x02013;<lpage>48</lpage><pub-id pub-id-type="doi">10.1016/S0926-6410(96)00039-0</pub-id><pub-id pub-id-type="pmid">9049069</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keogh</surname><given-names>R.</given-names></name><name><surname>Pearson</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Mental imagery and visual working memory</article-title>. <source>PLoS ONE</source>
<volume>6</volume>, <fpage>e29221</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0029221</pub-id><pub-id pub-id-type="pmid">22195024</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A.</given-names></name><name><surname>Uchida</surname><given-names>N.</given-names></name><name><surname>Zariwala</surname><given-names>H. A.</given-names></name><name><surname>Mainen</surname><given-names>Z. F.</given-names></name></person-group> (<year>2008</year>). <article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title>. <source>Nature</source>
<volume>455</volume>, <fpage>227</fpage>&#x02013;<lpage>231</lpage><pub-id pub-id-type="doi">10.1038/nature07200</pub-id><pub-id pub-id-type="pmid">18690210</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R.</given-names></name><name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2009</year>). <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source>
<volume>324</volume>, <fpage>759</fpage>&#x02013;<lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id><pub-id pub-id-type="pmid">19423820</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornbrot</surname><given-names>D. E.</given-names></name></person-group> (<year>2006</year>). <article-title>Signal detection theory, the approach of choice: model-based and distribution-free measures and evaluation</article-title>. <source>Percept. Psychophys.</source>
<volume>68</volume>, <fpage>393</fpage>&#x02013;<lpage>414</lpage><pub-id pub-id-type="doi">10.3758/BF03193685</pub-id><pub-id pub-id-type="pmid">16900832</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosslyn</surname><given-names>S. M.</given-names></name><name><surname>Ganis</surname><given-names>G.</given-names></name><name><surname>Thompson</surname><given-names>W. L.</given-names></name></person-group> (<year>2001</year>). <article-title>Neural foundations of imagery</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>2</volume>, <fpage>635</fpage>&#x02013;<lpage>642</lpage><pub-id pub-id-type="doi">10.1038/35085102</pub-id><pub-id pub-id-type="pmid">11533731</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosslyn</surname><given-names>S. M.</given-names></name><name><surname>Pascual-Leone</surname><given-names>A.</given-names></name><name><surname>Felician</surname><given-names>O.</given-names></name><name><surname>Camposano</surname><given-names>S.</given-names></name><name><surname>Keenan</surname><given-names>J. P.</given-names></name><name><surname>Thompson</surname><given-names>W. L.</given-names></name><name><surname>Ganis</surname><given-names>G.</given-names></name><name><surname>Sukel</surname><given-names>K. E.</given-names></name><name><surname>Alpert</surname><given-names>N. M.</given-names></name></person-group> (<year>1999</year>). <article-title>The role of area 17 in visual imagery: convergent evidence from PET and rTMS</article-title>. <source>Science</source>
<volume>284</volume>, <fpage>167</fpage>&#x02013;<lpage>170</lpage><pub-id pub-id-type="doi">10.1126/science.284.5411.167</pub-id><pub-id pub-id-type="pmid">10102821</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kosslyn</surname><given-names>S. M.</given-names></name><name><surname>Thompson</surname><given-names>W. L.</given-names></name><name><surname>Kim</surname><given-names>I. J.</given-names></name><name><surname>Alpert</surname><given-names>N. M.</given-names></name></person-group> (<year>1995</year>). <article-title>Topographical representations of mental images in primary visual cortex</article-title>. <source>Nature</source>
<volume>378</volume>, <fpage>496</fpage>&#x02013;<lpage>498</lpage><pub-id pub-id-type="doi">10.1038/378496a0</pub-id><pub-id pub-id-type="pmid">7477406</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G.</given-names></name><name><surname>Koch</surname><given-names>C.</given-names></name><name><surname>Fried</surname><given-names>I.</given-names></name></person-group> (<year>2000</year>). <article-title>Imagery neurons in the human brain</article-title>. <source>Nature</source>
<volume>408</volume>, <fpage>357</fpage>&#x02013;<lpage>361</lpage><pub-id pub-id-type="doi">10.1038/35042575</pub-id><pub-id pub-id-type="pmid">11099042</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Landsberger</surname><given-names>H. A.</given-names></name></person-group> (<year>1958</year>). <source>Hawthorne Revisited</source>. <publisher-loc>Ithaca, NY</publisher-loc>: <publisher-name>Cornell University</publisher-name></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>H. C.</given-names></name></person-group> (<year>2008</year>). <article-title>A higher order Bayesian decision theory of consciousness</article-title>. <source>Prog. Brain Res.</source>
<volume>168</volume>, <fpage>35</fpage>&#x02013;<lpage>48</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(07)68004-2</pub-id><pub-id pub-id-type="pmid">18166384</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>H. C.</given-names></name><name><surname>Passingham</surname><given-names>R. E.</given-names></name></person-group> (<year>2006</year>). <article-title>Relative blindsight in normal observers and the neural correlate of visual consciousness</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>103</volume>, <fpage>18763</fpage>&#x02013;<lpage>18768</lpage><pub-id pub-id-type="doi">10.1073/pnas.0607716103</pub-id><pub-id pub-id-type="pmid">17124173</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>N. A.</given-names></name><name><surname>Creelman</surname><given-names>C. D.</given-names></name></person-group> (<year>1991</year>). <source>Detection Theory: A User&#x02019;s Guide</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marks</surname><given-names>D. F.</given-names></name></person-group> (<year>1973</year>). <article-title>Visual imagery differences in the recall of pictures</article-title>. <source>Br. J. Psychol.</source>
<volume>64</volume>, <fpage>17</fpage>&#x02013;<lpage>24</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8295.1973.tb01322.x</pub-id><pub-id pub-id-type="pmid">4742442</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>K. B.</given-names></name><name><surname>Roediger</surname><given-names>H. L.</given-names></name></person-group> (<year>1994</year>). <article-title>Effects of imagery on perceptual implicit memory tests</article-title>. <source>J. Exp. Psychol. Learn Mem. Cogn.</source>
<volume>20</volume>, <fpage>1379</fpage>&#x02013;<lpage>1390</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.20.6.1379</pub-id><pub-id pub-id-type="pmid">7983469</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McKellar</surname><given-names>P.</given-names></name></person-group> (<year>1965</year>). <source>The Investigation of Mental Images</source>. <publisher-loc>Harmondsworth</publisher-loc>: <publisher-name>Penguin Books</publisher-name></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>M.</given-names></name><name><surname>Tong</surname><given-names>F.</given-names></name></person-group> (<year>2004</year>). <article-title>Can attention selectively bias bistable perception? Differences between binocular rivalry and ambiguous figures</article-title>. <source>J. Vis.</source>
<volume>4</volume>, <fpage>539</fpage>&#x02013;<lpage>551</lpage><pub-id pub-id-type="doi">10.1167/4.7.2</pub-id><pub-id pub-id-type="pmid">15330700</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>J.</given-names></name><name><surname>Stoner</surname><given-names>G.</given-names></name><name><surname>Reynolds</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>Object-based attention determines dominance in binocular rivalry</article-title>. <source>Nature</source>
<volume>429</volume>, <fpage>410</fpage>&#x02013;<lpage>413</lpage><pub-id pub-id-type="doi">10.1038/nature02584</pub-id><pub-id pub-id-type="pmid">15164062</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O&#x02019;Craven</surname><given-names>K.</given-names></name><name><surname>Kanwisher</surname><given-names>N.</given-names></name></person-group> (<year>2000</year>). <article-title>Mental imagery of faces and places activates corresponding stimulus-specific brain regions</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>12</volume>, <fpage>1013</fpage>&#x02013;<lpage>1023</lpage><pub-id pub-id-type="doi">10.1162/08989290051137549</pub-id><pub-id pub-id-type="pmid">11177421</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>J.</given-names></name><name><surname>Brascamp</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>Sensory memory for ambiguous vision</article-title>. <source>Trends Cogn. Sci. (Regul. Ed.)</source>
<volume>12</volume>, <fpage>334</fpage>&#x02013;<lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.05.006</pub-id><pub-id pub-id-type="pmid">18684661</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>J.</given-names></name><name><surname>Clifford</surname><given-names>C.</given-names></name><name><surname>Tong</surname><given-names>F.</given-names></name></person-group> (<year>2008</year>). <article-title>The functional impact of mental imagery on conscious perception</article-title>. <source>Curr. Biol.</source>
<volume>18</volume>, <fpage>982</fpage>&#x02013;<lpage>986</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.10.019</pub-id><pub-id pub-id-type="pmid">18583132</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>J.</given-names></name><name><surname>Rademaker</surname><given-names>R. L.</given-names></name><name><surname>Tong</surname><given-names>F.</given-names></name></person-group> (<year>2011</year>). <article-title>Evaluating the mind&#x02019;s eye: the metacognition of visual imagery</article-title>. <source>Psychol. Sci.</source>
<volume>22</volume>, <fpage>1535</fpage>&#x02013;<lpage>1542</lpage><pub-id pub-id-type="doi">10.1177/0956797611417134</pub-id><pub-id pub-id-type="pmid">22058106</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>D. G.</given-names></name></person-group> (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spat. Vis.</source>
<volume>10</volume>, <fpage>437</fpage>&#x02013;<lpage>442</lpage><pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id><pub-id pub-id-type="pmid">9176953</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perky</surname><given-names>C.</given-names></name></person-group> (<year>1910</year>). <article-title>An experimental study of imagination?</article-title>. <source>Am. J. Psychol.</source>
<volume>21</volume>, <fpage>422</fpage>&#x02013;<lpage>452</lpage><pub-id pub-id-type="doi">10.2307/1413350</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pylyshyn</surname><given-names>Z.</given-names></name></person-group> (<year>2003</year>). <article-title>Return of the mental image: are there really pictures in the brain?</article-title>
<source>Trends Cogn. Sci. (Regul. Ed.)</source>
<volume>7</volume>, <fpage>113</fpage>&#x02013;<lpage>118</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(03)00004-4</pub-id><pub-id pub-id-type="pmid">12639692</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rounis</surname><given-names>E.</given-names></name><name><surname>Maniscalco</surname><given-names>B.</given-names></name><name><surname>Rothwell</surname><given-names>J. C.</given-names></name><name><surname>Passingham</surname><given-names>R. E.</given-names></name><name><surname>Lau</surname><given-names>H.</given-names></name></person-group> (<year>2010</year>). <article-title>Theta-burst transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive visual awareness</article-title>. <source>Cogn. Neurosci.</source>
<volume>1</volume>, <fpage>165</fpage>&#x02013;<lpage>175</lpage><pub-id pub-id-type="doi">10.1080/17588921003632529</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sacks</surname><given-names>O.</given-names></name></person-group> (<year>2010</year>). <source>The Mind&#x02019;s Eye</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Alfred A. Knopf</publisher-name></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sasaki</surname><given-names>Y.</given-names></name><name><surname>Nanez</surname><given-names>J. E.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Advances in visual perceptual learning and plasticity</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>11</volume>, <fpage>53</fpage>&#x02013;<lpage>60</lpage><pub-id pub-id-type="doi">10.1038/nrn2737</pub-id><pub-id pub-id-type="pmid">19953104</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>A.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>A unified model for perceptual learning</article-title>. <source>Trends Cogn. Sci. (Regul. Ed.)</source>
<volume>9</volume>, <fpage>329</fpage>&#x02013;<lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.05.010</pub-id><pub-id pub-id-type="pmid">15955722</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>A. R.</given-names></name><name><surname>Kim</surname><given-names>D.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name></person-group> (<year>2009</year>). <article-title>Rewards evoke learning of unconsciously processed visual stimuli in adult humans</article-title>. <source>Neuron</source>
<volume>61</volume>, <fpage>700</fpage>&#x02013;<lpage>707</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.016</pub-id><pub-id pub-id-type="pmid">19285467</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>A. R.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name></person-group> (<year>2003</year>). <article-title>Psychophysics: is subliminal learning really passive?</article-title>
<source>Nature</source>
<volume>422</volume>, <fpage>36</fpage><pub-id pub-id-type="pmid">12621425</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>A. R.</given-names></name><name><surname>Yamagishi</surname><given-names>N.</given-names></name><name><surname>Werner</surname><given-names>B.</given-names></name><name><surname>Goda</surname><given-names>N.</given-names></name><name><surname>Kawato</surname><given-names>M.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>Task-specific disruption of perceptual learning</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>102</volume>, <fpage>14895</fpage>&#x02013;<lpage>14900</lpage><pub-id pub-id-type="doi">10.1073/pnas.0505765102</pub-id><pub-id pub-id-type="pmid">16203984</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serences</surname><given-names>J. T.</given-names></name><name><surname>Ester</surname><given-names>E. F.</given-names></name><name><surname>Vogel</surname><given-names>E. K.</given-names></name><name><surname>Awh</surname><given-names>E.</given-names></name></person-group> (<year>2009</year>). <article-title>Stimulus-specific delay activity in human primary visual cortex</article-title>. <source>Psychol. Sci.</source>
<volume>20</volume>, <fpage>207</fpage>&#x02013;<lpage>214</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id><pub-id pub-id-type="pmid">19170936</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shibata</surname><given-names>K.</given-names></name><name><surname>Watanabe</surname><given-names>T.</given-names></name><name><surname>Sasaki</surname><given-names>Y.</given-names></name><name><surname>Kawato</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>Perceptual learning incepted by decoded fMRI neurofeedback without stimulus presentation</article-title>. <source>Science</source>
<volume>334</volume>, <fpage>1413</fpage>&#x02013;<lpage>1415</lpage><pub-id pub-id-type="doi">10.1126/science.1212003</pub-id><pub-id pub-id-type="pmid">22158821</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slotnick</surname><given-names>S. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Imagery: mental pictures disrupt perceptual rivalry</article-title>. <source>Curr. Biol.</source>
<volume>18</volume>, <fpage>R603</fpage>&#x02013;<lpage>R605</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.06.002</pub-id><pub-id pub-id-type="pmid">18644335</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slotnick</surname><given-names>S. D.</given-names></name><name><surname>Thompson</surname><given-names>W. L.</given-names></name><name><surname>Kosslyn</surname><given-names>S. M.</given-names></name></person-group> (<year>2005</year>). <article-title>Visual mental imagery induces retinotopically organized activation of early visual areas</article-title>. <source>Cereb. Cortex</source>
<volume>15</volume>, <fpage>1570</fpage>&#x02013;<lpage>1583</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhi035</pub-id><pub-id pub-id-type="pmid">15689519</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>C.</given-names></name><name><surname>Kanai</surname><given-names>R.</given-names></name><name><surname>Fleming</surname><given-names>S. M.</given-names></name><name><surname>Weil</surname><given-names>R. S.</given-names></name><name><surname>Schwarzkopf</surname><given-names>D. S.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name></person-group> (<year>2011</year>). <article-title>Relating inter-individual differences in metacognitive performance on different perceptual tasks</article-title>. <source>Conscious. Cogn.</source>
<volume>20</volume>, <fpage>1787</fpage>&#x02013;<lpage>1792</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2010.12.011</pub-id><pub-id pub-id-type="pmid">21256051</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>M.</given-names></name><name><surname>Thompson</surname><given-names>R.</given-names></name><name><surname>Cusack</surname><given-names>R.</given-names></name><name><surname>Duncan</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>Top-down activation of shape-specific population codes in visual cortex during mental imagery</article-title>. <source>J. Neurosci.</source>
<volume>29</volume>, <fpage>1565</fpage>&#x02013;<lpage>1572</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4657-08.2009</pub-id><pub-id pub-id-type="pmid">19193903</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swets</surname><given-names>J. A.</given-names></name></person-group> (<year>1986</year>). <article-title>Form of empirical ROCs in discrimination and diagnostic tasks: implications for theory and measurement of performance</article-title>. <source>Psychol. Bull.</source>
<volume>99</volume>, <fpage>181</fpage>&#x02013;<lpage>198</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.99.1.100</pub-id><pub-id pub-id-type="pmid">3515382</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tartaglia</surname><given-names>E. M.</given-names></name><name><surname>Bamert</surname><given-names>L.</given-names></name><name><surname>Mast</surname><given-names>F. W.</given-names></name><name><surname>Herzog</surname><given-names>M. H.</given-names></name></person-group> (<year>2009</year>). <article-title>Human perceptual learning by mental imagery</article-title>. <source>Curr. Biol.</source>
<volume>19</volume>, <fpage>2081</fpage>&#x02013;<lpage>2085</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.10.060</pub-id><pub-id pub-id-type="pmid">19962313</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name></person-group> (<year>1979</year>). <source>Decision Processes in Visual Perception</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>T.</given-names></name><name><surname>Hansen</surname><given-names>E.</given-names></name><name><surname>Rost</surname><given-names>R.</given-names></name><name><surname>Beyer</surname><given-names>L.</given-names></name><name><surname>Merten</surname><given-names>F.</given-names></name><name><surname>Nichelmann</surname><given-names>C.</given-names></name><name><surname>Zippel</surname><given-names>C.</given-names></name></person-group> (<year>1994</year>). <article-title>Mental practice of motor skills used in poststroke rehabilitation has own effects on central nervous activation</article-title>. <source>Int. J. Neurosci.</source>
<volume>78</volume>, <fpage>157</fpage>&#x02013;<lpage>166</lpage><pub-id pub-id-type="doi">10.3109/00207459408986054</pub-id><pub-id pub-id-type="pmid">7883452</pub-id></mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willingham</surname><given-names>D. B.</given-names></name></person-group> (<year>1999</year>). <article-title>Implicit motor sequence learning is not purely perceptual</article-title>. <source>Mem. Cognit.</source>
<volume>27</volume>, <fpage>561</fpage>&#x02013;<lpage>572</lpage><pub-id pub-id-type="doi">10.3758/BF03211549</pub-id><pub-id pub-id-type="pmid">10355244</pub-id></mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zatorre</surname><given-names>R. J.</given-names></name><name><surname>Halpern</surname><given-names>A. R.</given-names></name></person-group> (<year>2005</year>). <article-title>Mental concerts: musical imagery and auditory cortex</article-title>. <source>Neuron</source>
<volume>47</volume>, <fpage>9</fpage>&#x02013;<lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.06.013</pub-id><pub-id pub-id-type="pmid">15996544</pub-id></mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J.-Y.</given-names></name><name><surname>Kuai</surname><given-names>S.-G.</given-names></name><name><surname>Xiao</surname><given-names>L.-Q.</given-names></name><name><surname>Klein</surname><given-names>S. A.</given-names></name><name><surname>Levi</surname><given-names>D. M.</given-names></name><name><surname>Yu</surname><given-names>C.</given-names></name></person-group> (<year>2008</year>). <article-title>Stimulus coding rules for perceptual learning</article-title>. <source>PLoS Biol.</source>
<volume>6</volume>, <fpage>e197</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0060197</pub-id><pub-id pub-id-type="pmid">18707195</pub-id></mixed-citation></ref></ref-list></back></article>