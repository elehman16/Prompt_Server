<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">JMIR Mhealth Uhealth</journal-id><journal-id journal-id-type="iso-abbrev">JMIR Mhealth Uhealth</journal-id><journal-id journal-id-type="publisher-id">JMU</journal-id><journal-title-group><journal-title>JMIR mHealth and uHealth</journal-title></journal-title-group><issn pub-type="epub">2291-5222</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28912113</article-id><article-id pub-id-type="pmc">5620455</article-id><article-id pub-id-type="publisher-id">v5i9e139</article-id><article-id pub-id-type="doi">10.2196/mhealth.7943</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group><subj-group subj-group-type="article-type"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Mobile Augmented Reality as a Feature for Self-Oriented, Blended Learning in Medicine: Randomized Controlled Trial</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Eysenbach</surname><given-names>Gunther</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Oliveira</surname><given-names>Allisson</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Grainger</surname><given-names>Rebecca</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Lang</surname><given-names>Michael</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author" equal-contrib="yes"><name><surname>Noll</surname><given-names>Christoph</given-names></name><xref ref-type="aff" rid="aff1">1</xref><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5194-9078</contrib-id></contrib><contrib id="contrib2" contrib-type="author" equal-contrib="yes"><name><surname>von Jan</surname><given-names>Ute</given-names></name><degrees>Dr rer biol hum</degrees><xref ref-type="aff" rid="aff1">1</xref><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9225-593X</contrib-id></contrib><contrib id="contrib3" contrib-type="author" equal-contrib="yes"><name><surname>Raap</surname><given-names>Ulrike</given-names></name><degrees>Dr med</degrees><xref ref-type="aff" rid="aff2">2</xref><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9573-4714</contrib-id></contrib><contrib id="contrib4" contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Albrecht</surname><given-names>Urs-Vito</given-names></name><degrees>Dr med, MPH</degrees><xref ref-type="aff" rid="aff1">1</xref><address><institution>PL Reichertz Institute for Medical Informatics</institution><institution>Hannover Medical School</institution><addr-line>Carl-Neuberg-Str. 1</addr-line><addr-line>Hannover, 30625</addr-line><country>Germany</country><phone>49 511 532 ext 3508</phone><fax>49 511 532 2517</fax><email>albrecht.urs-vito@mh-hannover.de</email></address><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8989-6696</contrib-id></contrib></contrib-group><aff id="aff1">
<sup>1</sup>
<institution>PL Reichertz Institute for Medical Informatics</institution>
<institution>Hannover Medical School</institution>
<addr-line>Hannover</addr-line>
<country>Germany</country></aff><aff id="aff2">
<sup>2</sup>
<institution>Universit&#x000e4;tsklinik f&#x000fc;r Dermatologie und Allergologie</institution>
<institution>Klinikum Oldenburg A&#x000f6;R</institution>
<addr-line>Oldenburg</addr-line>
<country>Germany</country></aff><author-notes><corresp>Corresponding Author: Urs-Vito Albrecht
<email>albrecht.urs-vito@mh-hannover.de</email></corresp></author-notes><pub-date pub-type="collection"><month>9</month><year>2017</year></pub-date><pub-date pub-type="epub"><day>14</day><month>9</month><year>2017</year></pub-date><volume>5</volume><issue>9</issue><elocation-id>e139</elocation-id><history><date date-type="received"><day>29</day><month>4</month><year>2017</year></date><date date-type="rev-request"><day>27</day><month>7</month><year>2017</year></date><date date-type="rev-recd"><day>6</day><month>8</month><year>2017</year></date><date date-type="accepted"><day>9</day><month>8</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9;Christoph Noll, Ute von Jan, Ulrike Raap, Urs-Vito Albrecht. Originally published in JMIR Mhealth and Uhealth (http://mhealth.jmir.org), 14.09.2017.</copyright-statement><copyright-year>2017</copyright-year><license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/"><license-p><!--CREATIVE COMMONS-->This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR mhealth and uhealth, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link ext-link-type="uri" xlink:href="http://mhealth.jmir.org/,">http://mhealth.jmir.org/,</ext-link> as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:type="simple" xlink:href="http://mhealth.jmir.org/2017/9/e139/"/><abstract><sec sec-type="background"><title>Background</title><p>Advantages of mobile Augmented Reality (mAR) application-based learning versus textbook-based learning were already shown in a previous study. However, it was unclear whether the augmented reality (AR) component was responsible for the success of the self-developed app or whether this was attributable to the novelty of using mobile technology for learning.</p></sec><sec sec-type="objective"><title>Objective</title><p>The study&#x02019;s aim was to test the hypothesis whether there is no difference in learning success between learners who employed the mobile AR component and those who learned without it to determine possible effects of mAR. Also, we were interested in potential emotional effects of using this technology.</p></sec><sec sec-type="methods"><title>Methods</title><p>Forty-four medical students (male: 25, female: 19, mean age: 22.25 years, standard deviation [SD]: 3.33 years) participated in this study. Baseline emotional status was evaluated using the Profile of Mood States (POMS) questionnaire. Dermatological knowledge was ascertained using a single choice (SC) test (10 questions). The students were randomly assigned to learn 45 min with either a mobile learning method with mAR (group A) or without AR (group B). Afterwards, both groups were again asked to complete the previous questionnaires. AttrakDiff 2 questionnaires were used to evaluate the perceived usability as well as pragmatic and hedonic qualities. For capturing longer term effects, after 14 days, all participants were again asked to complete the SC questionnaire. All evaluations were anonymous, and descriptive statistics were calculated. For hypothesis testing, an unpaired signed-rank test was applied.</p></sec><sec sec-type="results"><title>Results</title><p>For the SC tests, there were only minor differences, with both groups gaining knowledge (average improvement group A: 3.59 [SD 1.48]; group B: 3.86 [SD 1.51]). Differences between both groups were statistically insignificant (exact Mann Whitney U, U=173.5; <italic>P</italic>=.10; r=.247). However, in the follow-up SC test after 14 days, group A had retained more knowledge&#x000a0;(average decrease of the number of correct answers group A: 0.33 [SD 1.62]; group B: 1.14 [SD 1.30]). For both groups, descriptively, there were only small variations regarding emotional involvement, and learning experiences also differed little, with both groups rating the app similar for its stimulating effect.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>We were unable to show significant effects for mAR on the immediate learning success of the mobile learning setting. However, the similar level of stimulation being noted for both groups is inconsistent with the previous assumption of the success of mAR-based approach being solely attributable to the excitement of using mobile technology, independent of mAR; the mAR group showed some indications for a better long-term retention of knowledge. Further studies are needed to examine this aspect.</p></sec><sec sec-type="Trial Registration"><title>Trial Registration</title><p>German Clinical Trials Register (DRKS): 00012980; http://www.drks.de/drks_web/navigate.do? navigationId=trial.HTML&#x00026;TRIAL_ID=DRKS00012980&#x000a0;(Archived by WebCite at&#x000a0;http://www.webcitation.org/ 6tCWoM2Jb).</p></sec></abstract><kwd-group><kwd>problem-based learning</kwd><kwd>cellular phone</kwd><kwd>education</kwd><kwd>medical</kwd><kwd>mHealth</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>According to authors such as Johnson et al [<xref rid="ref1" ref-type="bibr">1</xref>] and Kroeker [<xref rid="ref2" ref-type="bibr">2</xref>], augmented reality (AR) will become one of the major user interfaces of the 21st century. AR allows real and virtual objects to coexist and interact in the same space and time [<xref rid="ref3" ref-type="bibr">3</xref>]. Using AR, virtual information can be interwoven with reality, which leads to an augmentation of the physical environment. Thanks to the ready and still growing availability of smartphones and tablets and their ever-increasing processing power, AR can now be used in a mobile manner (ie, mobile Augmented Reality [mAR]) as well. Whereas previously, AR was mainly of relevance for entertainment, marketing, or video games, it is now also entering the challenging field of teaching and training. One significant benefit of mAR for learning is the ease of modeling objects and presenting them to learners in real-world settings, so that they can get a clear idea about what they are to learn [<xref rid="ref4" ref-type="bibr">4</xref>], and there are various studies evaluating the effects this technology has on the learning process for various user groups and settings [<xref rid="ref4" ref-type="bibr">4</xref>-<xref rid="ref7" ref-type="bibr">7</xref>].</p><p>In preparatory work done at Hannover Medical School, there was already an initial investigation into the possible uses of mAR for teaching and learning in a medical education setting [<xref rid="ref6" ref-type="bibr">6</xref>]. For this purpose, a <italic>mobile Augmented Reality blended learning environment</italic> (mARble) app was built, which was then evaluated in comparison with conventional learning material (textbook), specifically with respect to its learning efficiency [<xref rid="ref6" ref-type="bibr">6</xref>]. Despite the low number of cases (n=10) for that pilot study, it was possible to show positive activation for those participants who had been learning with the mAR app, and when checking the participants&#x02019; knowledge gain, the mAR group performed significantly better than those who had learned with the conventional textbook material [<xref rid="ref6" ref-type="bibr">6</xref>].</p><p>However, it remained unclear whether this activation had to be attributed to using a different medium and its exciting novelty. Initially, it was unclear to what extent mAR had actually contributed to the learning success, a problem also mentioned by Radu [<xref rid="ref4" ref-type="bibr">4</xref>] when contemplating the effects of different media&#x02014;with entirely different means of presentation&#x02014;on learning. With this study, we wanted to address this issue.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>The Learning Environment mARble</title><p>The iPhone operating system (iOS, Apple Inc)-based app mARble-Derma (mARble-dermatology) was developed at the Peter L. Reichertz Institute for Medical Informatics of Hannover Medical School, in collaboration with Ulrike Raap, formerly of the Clinic for Dermatology and Allergy at Hannover Medical School, and her team at the clinic. It provides users with learning content organized in the form of digital flashcards. Using paper-based markers that can be placed on the skin of users, the app employs AR to recall content linked to the markers, overlay it on images of the environment if desired, and to thus add an entirely new level of information [<xref rid="ref6" ref-type="bibr">6</xref>]. The app&#x02019;s code and its content are kept separately. Via an extensible markup language-based file format, content can easily be edited or added without changing the code [<xref rid="ref6" ref-type="bibr">6</xref>,<xref rid="ref8" ref-type="bibr">8</xref>].</p></sec><sec><title>Learning Material</title><p>The subject of dermatology was chosen for the study, as dermatology is a specialty where visual information is of high relevance when it comes to diagnosing various skin conditions, making it ideal for AR-based scenarios. The lecturer for dermatology selected altogether five relevant topics (malignant melanoma, basal cell carcinoma, psoriasis vulgaris, bullous pemphigoid, and atopic dermatitis) from the learning catalog. The learning material for the selected topics was adapted from relevant literature [<xref rid="ref9" ref-type="bibr">9</xref>], as well as the course material normally provided to students by the department. In close collaboration with the lecturer, it was then integrated into the app. All images originated in the department and were professionally produced for teaching purposes.</p></sec><sec><title>Fine-Tuning the Content: Selecting the AR Markers and Their Corresponding Content</title><p>For selecting a suitable subset out of the available markers and flashcards, a randomized single-blinded questionnaire was employed. For each of the available markers, this questionnaire contained images that had been acquired by overlaying the respective finding onto the skin of a test subject using the app. These images were then rated by 16 doctors (9 junior doctors and 7 dermatologists) working at the clinic for Dermatology and Allergy of Hannover Medical School. For each image, the doctors were asked to give a free text answer stating their diagnosis. A subsequent analysis of interrater reliability [<xref rid="ref10" ref-type="bibr">10</xref>] led to the aforementioned selection from originally 10 markers and 6 subject areas. With one exception, only markers that were correctly recognized and had shown an interrater reliability of at least 60% were included. The marker and the subject area for &#x0201c;atopic dermatitis&#x0201d; (item 2) were included despite poor reliability (46% [6/13]); whereas location is an important aspect when diagnosing this condition, it could not adequately be deduced from the presented image. It is to be expected that with a more carefully chosen view better depicting the location, the association of the presented image with the correct diagnosis would have been more reliable, as the term &#x0201c;eczema,&#x0201d; which also covers &#x0201c;atopic dermatitis,&#x0201d; was often used to describe the depicted finding. Altogether, eight markers from five subject areas were finally included (<xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="430" span="1"/><col width="60" span="1"/><col width="80" span="1"/><col width="50" span="1"/><col width="60" span="1"/><col width="80" span="1"/><col width="50" span="1"/><col width="60" span="1"/><col width="130" span="1"/><thead><tr valign="top"><td rowspan="2" colspan="1">Item</td><td rowspan="2" colspan="1">N</td><td rowspan="2" colspan="1">Correct answers</td><td colspan="2" rowspan="1">Specialist</td><td rowspan="2" colspan="1">Incorrect answers</td><td colspan="2" rowspan="1">Specialist</td><td rowspan="2" colspan="1">Correct answers, % (n/N)</td></tr><tr valign="top"><td rowspan="1" colspan="1">yes</td><td rowspan="1" colspan="1">no</td><td rowspan="1" colspan="1">yes</td><td rowspan="1" colspan="1">no</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Item 1 melanoma metastases</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">64 (9/14)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 2 atopic dermatitis</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">46 (6/13)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 3 psoriasis vulgaris, single spot</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">88 (14/16)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 4 basal cell carcinoma, pigmented</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">19 (3/16)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 5 nodular melanoma</td><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">67 (10/15)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 6 basal cell carcinoma</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">16</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">100 (16/16)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 7 superficial spreading melanoma</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">64 (9/14)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 8 bullous pemphigoid</td><td rowspan="1" colspan="1">15</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">93 (14/15)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 9 urticaria</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">50 (5/10)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Item 10 psoriasis vulgaris, multiple spots</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">62 (8/13)</td></tr></tbody></table></table-wrap><fig id="figure1" position="float"><label>Figure 1</label><caption><p>Schedule and tests that were performed. Throughout the text, individual steps or tests are referenced with the labels shown in this figure (T1a/b, T2a/b/c, and T3).</p></caption><graphic xlink:href="mhealth_v5i9e139_fig1"/></fig></sec><sec><title>Objective</title><p>The hypothesis to be tested in the study was that there is no significant difference in the score of correct answers (learning success) between learners who have access to mAR and those who do not. In addition, it was of interest whether there were indicators hinting at better long-term retention of acquired knowledge for those who had learned with mAR. We were also interested in whether the emotional involvement seen in the prestudy could be reproduced.</p></sec><sec><title>Study</title><p>The study was conducted with approval by the institutional review board of Hannover Medical School, study number 1823-2013, amended 2014. For this study, it was decided to use the design of a two-arm, prospective randomized trial. There were two study groups, both of which were equipped with smart devices (iOS-based smartphones and tablets, specifically iPads, iPad Mini tablets, iPhones 4, or iPhones 5) with preinstalled copies of the mobile learning environment. For both groups, the software was identical, with the exception of the mAR functionality, which was only provided to one group (<xref ref-type="fig" rid="figure1">Figure 1</xref>).</p><sec><title>Sample Size Calculation</title><p>Experiences from our previous study [<xref rid="ref6" ref-type="bibr">6</xref>] had shown that recruiting students for extracurricular activities such as participation in a study is extremely difficult. We therefore decided to take a conservative approach in our calculations, leading to a reasonable (and realistically obtainable) number of participants while still keeping the power at an acceptable level. On the basis of our previous results [<xref rid="ref6" ref-type="bibr">6</xref>], the sample size required for Mann Whitney <italic>U</italic> testing (unpaired rank sum, two-sided, effect size <italic>d</italic>=0.73, Laplace distribution, minimum power of .8) was calculated with G*Power 3.1 (Heinrich-Heine-Universit&#x000e4;t D&#x000fc;sseldorf) [<xref rid="ref11" ref-type="bibr">11</xref>,<xref rid="ref12" ref-type="bibr">12</xref>], leading to 21 individuals per group (altogether 42 participants). However, we chose to recruit 2 additional candidates to be able to compensate for spontaneous dropouts, at least for the initial part of the study.</p><table-wrap id="table2" position="float"><label>Table 2</label><caption><p>Descriptive statistics of the participants (N=44).</p></caption><table frame="hsides" rules="groups" width="100" cellpadding="5" cellspacing="0" border="1"><col width="150" span="1"/><col width="150" span="1"/><col width="80" span="1"/><col width="245" span="1"/><col width="170" span="1"/><col width="200" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Group</td><td rowspan="1" colspan="1">Gender</td><td rowspan="1" colspan="1">n</td><td rowspan="1" colspan="1">Age in years, mean (SD<sup>a</sup>)</td><td rowspan="1" colspan="1">iPhone owners</td><td rowspan="1" colspan="1">Other smartphone or tablet</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">A</td><td rowspan="1" colspan="1">Female</td><td rowspan="1" colspan="1">9</td><td rowspan="2" colspan="1">21.45 (2.39)</td><td rowspan="2" colspan="1">9</td><td rowspan="2" colspan="1">14</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Male</td><td rowspan="1" colspan="1">13</td></tr><tr valign="top"><td rowspan="1" colspan="1">B</td><td rowspan="1" colspan="1">Female</td><td rowspan="1" colspan="1">16</td><td rowspan="2" colspan="1">23.05 (3.97)</td><td rowspan="2" colspan="1">16</td><td rowspan="2" colspan="1">8</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Male</td><td rowspan="1" colspan="1">6</td></tr></tbody></table><table-wrap-foot><fn id="table2fn1"><p><sup>a</sup>SD: standard deviation.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Study Population</title><p>A total of 44 third-year medical students (25 females, 19 males, mean age=22.25 years [SD 3.33]) were included in the study. None of them had previously finished the dermatology module (<xref ref-type="table" rid="table2">Table 2</xref>).</p></sec><sec><title>Implementation</title><p>After all the participants had given their consent to being included in the study, they were given a brief introduction into the study&#x02019;s topic and its schedule. Following this initial introduction, the participants were allocated to the two study groups by letting them choose a random envelope containing information about their assignment to one of the two groups, their individual study ID, and the questionnaires used in the study. These envelopes had been prepared by the study team beforehand. These were sealed, with no labeling or other discernible markings on the outside that could have provided a hint as to their specific content, and they were also mixed before being presented to the participants. Before the students opened their chosen envelopes, it was not possible for either the students or the study team to determine which group assignment was given by the envelopes&#x02019; contents.</p><p>To assess the initial emotional status of the students, the participants were asked to fill out a German version of the &#x0201c;Profile of Mood States&#x0201d; (POMS) questionnaire [<xref rid="ref13" ref-type="bibr">13</xref>,<xref rid="ref14" ref-type="bibr">14</xref>]. As shown in <xref ref-type="fig" rid="figure1">Figure 1</xref>, they were given 5 min for answering this questionnaire (T1a). To obtain a baseline about their knowledge regarding the subject areas, they were also asked to answer a single choice (SC) test consisting of 10 questions (T2a), for which they were given 15 min.</p><p>Whereas the setting was otherwise identical, group A learned with mAR and group B without the mAR component. Both groups were led into two different rooms where they were again given a brief introduction, this time into the basic operation of the app mARble (<xref ref-type="fig" rid="figure2">Figure 2</xref>). The students were then equipped with mobile devices (one per individual) on which the app had been preinstalled. They also received headphones for individual use. The participants were then allowed to study using the app for a time span of 45 min (<xref ref-type="fig" rid="figure1">Figure 1</xref>). Group B simply used the flashcard-based material containing textual information as well as corresponding images (<xref ref-type="fig" rid="figure2">Figure 2</xref>). Members of group A were given the opportunity to use the additional markers (<xref ref-type="fig" rid="figure2">Figure 2</xref>), for example, to place them on their own bodies, to view the corresponding findings overlaid on their skin, and to quickly access the same textual as well as image data as group B. All participants learned at their own pace. For both groups, members of the study team were present to quietly observe the learning process and to be able to react to potential technical problems.</p><p>The control group B was provided with the (content-wise) same app as group A, but the members of this group were not given any markers that they could have used to trigger the mAR-based functionalities of the app. They were only told about how they could access the provided content (flashcards) using the app&#x02019;s navigation menu (<xref ref-type="fig" rid="figure2">Figure 2</xref>). During the learning phase, the participants of group B were allowed to learn at their own pace, without any interaction with other members of their group, and to take notes on paper if they wished to do so. Following the learning phase, the participants were asked to complete a questionnaire (AttrakDiff 2, T3) covering user experience-related aspects of what they had just experienced [<xref rid="ref15" ref-type="bibr">15</xref>]. They were also asked to once again fill out the POMS questionnaire (T1b) about their emotional status. For filling out both questionnaires, they were given 10 min. Finally, to determine how much they had learned, they were once again asked to answer the SC test consisting of 10 questions, with the questions being presented in a random order (T2b).</p><p>Similar to group B, group A was briefed about using the app, the included flashcards, as well as attachments. Additionally, they were familiarized with using the paper-based markers serving as triggers for the mAR-based functions of the app. The participants were asked to use all of the provided eight markers for the five subject areas by placing them on their own skin and to also utilize the markers for &#x0201c;help&#x0201d; and &#x0201c;contact.&#x0201d; For two subject areas, multiple markers were available. There were three markers for &#x0201c;malignant melanoma&#x0201d; and two markers for &#x0201c;psoriasis vulgaris.&#x0201d; Similar to group B, for the study phase of 45 min duration, group A was asked to study individually, without any interaction with other members of their group, and taking paper-based notes was also allowed. After finishing the learning phase, again, similar to group B, they were also asked to complete the user experience (AttrakDiff 2, T3) and POMS questionnaires (T1b), as well as the 10-question SC test (T2b) about the five subject areas they had learned.</p><p>After reminding the participants about the Web-based follow-up survey (T2c), planned for 14 days after the day the study had taken place, everyone was thanked and the study group B were informed that they would get an opportunity to experience the full functionality of mARble, including mAR, at a later date if they so desired.</p><p>For the follow-up survey (T2c), the participants were invited via an email that contained an individual link, leading them to a Web-based version with the same questionnaire as before, consisting of 10 questions presented in a random order.</p><fig id="figure2" position="float"><label>Figure 2</label><caption><p>Upper row: Using mobile Augmented Reality (mAR), a malignant melanoma is simulated on the cheek of a student. Lower row: Screenshots taken within the mobile Augmented Reality blended learning environment (mARble) app. Left to right: Overlaid image, question side of a flashcard, answer side with links to additional image material, and a presentation of said image material. For the control group B, the app was provided without the mAR component, and they were solely able to access the flashcard-based information.</p></caption><graphic xlink:href="mhealth_v5i9e139_fig2"/></fig></sec></sec><sec><title>Evaluation Tools</title><sec><title>Emotional Involvement (T1a+T1b): POMS Questionnaire, German Version</title><p>Similar to the previous study by Albrecht et al [<xref rid="ref6" ref-type="bibr">6</xref>,<xref rid="ref8" ref-type="bibr">8</xref>], before and immediately after the learning phase, the emotional status of the students was evaluated based on the POMS questionnaire [<xref rid="ref13" ref-type="bibr">13</xref>]. It was applied in its German, slightly modified version, as described by Biel et al [<xref rid="ref14" ref-type="bibr">14</xref>]. This questionnaire contains 35 adjectives that can be divided into groups associated with four different emotional states, that is, fatigue&#x02013;inertia (14 items), vigor&#x02013;activity (7 items), tension&#x02013;anxiety (7 items), and depression&#x02013;dejection (7 items). Ratings are assigned based on a 7-point rating scale representing the experienced intensity (ranging from &#x0201c;not at all&#x0201d; to &#x0201c;very strongly&#x0201d;).</p></sec><sec><title>Learning Success: Single Choice Tests (T2a, T2b, and T2c)</title><p>The learning outcome was evaluated by means of the aforementioned paper-based SC tests (single choice answers) consisting of 10 questions. There were 88 test forms, with questions and answers being presented in a random order. For the follow-up survey, a Web-based questionnaire was used, which participants were able to access using their participant ID as well as a password they had received at the beginning of the study. As the participant IDs had been randomly assigned to the students&#x02014;the IDs and corresponding passwords were noted on a slip of paper in the envelope the students had chosen themselves at the beginning&#x02014;it was not possible to identify individual students.</p><p>The questions employed for testing closely followed the methodology also used in official exams for medical students as they are compiled by the German Institute for Medical and Pharmaceutical Examination Questions (Institut f&#x000fc;r medizinische und pharmazeutische Pr&#x000fc;fungsfragen). The questions&#x02019; language and content were adapted to reflect the material provided in the lecture notes available for the dermatology and allergy class at Hannover Medical School, and they were checked for correctness and solvability by the module&#x02019;s lecturer. The content provided by the app was also checked with respect to whether it was adequate for solving the test questions and whether it was presented in a manner that made it possible to go through all of this content within the given time frame of 45 min.</p><p>On the basis of the tests conducted before and after the learning phase, the learning efficiency (T2a, T2b, and T2c) for both groups was evaluated descriptively using the calculated mean values and corresponding SD. For hypothesis testing, a nonparametrical signed-rank test for unpaired samples was conducted (exact Mann Whitney <italic>U</italic> test) with Statistical Package for the Social Sciences (SPSS) version 24 (IBM Corp). All questionnaires were included in this evaluation, and each of them had been fully completed. For the follow-up survey, only those questionnaires were included in the evaluation that had been completed in the time span between the start of the follow-up period (after 14 days) up to 8 days later. Missing questionnaires were replaced by the mean values calculated for the respective group.</p></sec><sec><title>Learning Experience (T3): AttrakDiff 2</title><p>Isleifsd&#x000f3;ttir et al [<xref rid="ref16" ref-type="bibr">16</xref>] describe &#x0201c;user experience&#x0201d; as an important factor to consider when designing software. In their previous, preliminary evaluation of mARble, Albrecht et al [<xref rid="ref6" ref-type="bibr">6</xref>] employed the AttrakDiff 2 questionnaire as described by Hassenzahl et al [<xref rid="ref15" ref-type="bibr">15</xref>,<xref rid="ref17" ref-type="bibr">17</xref>,<xref rid="ref18" ref-type="bibr">18</xref>] to evaluate this aspect of the app. It uses altogether 28 questions, covering four different aspects (pragmatic quality, PQ; hedonic quality (HQ)-stimulation, HQ-S; hedonic quality-identification, HQ-I; and attractiveness, ATT), with 7 questions per group. For each item, semantic differentials are used, with opposite adjectives (eg, &#x0201c;good&#x02013;bad&#x0201d; and &#x0201c;confusing&#x02013;clear&#x0201d;) being placed at the poles of a 7-point Likert scale. In the work presented here, using a similar setting, the AttrakDiff 2 questionnaire was again used to evaluate the app&#x02019;s ATT, as well as its hedonic and pragmatic qualities.</p><p>For each of the 28 attributes included in the questionnaire, mean values as well as corresponding SDs were calculated for the ratings given by the participants. For each dimension, average ratings were calculated and plotted for clarity. The values for PQ (on the x-axis) were plotted against those obtained for HQ (aggregated from the values obtained for hedonic stimulation and hedonic identification, placed on the y-axis). By including the corresponding confidence intervals into the plot, rectangles are shown that allow asserting to what extent the user experiences between both groups differ or overlap.</p></sec><sec><title>Analyzing User Behavior Based on Log Files Recorded on the Devices</title><p>To provide insights into how the participants had learned, the usage of markers as well as the included flashcards were tracked via the logging functionality integrated into the app. The recorded data included the date and time at which a marker or flashcard had been used, the type of the event (marker in focus, flashcard being invoked), the title of the marker or flashcard being used, as well as the duration of the event in seconds. As there were multiple flashcards per subject, for the flashcards, a numeric identifier was recorded as well. It was also noted whether the answer or question side of the flashcard had been displayed.</p><p>For all participants, the log files recorded during the learning phase were transferred to a central database. How long the provided flashcard content had been utilized (median values and interquartile range [IQR]) was then calculated for each group, in aggregated form as well as per flashcard (stratified for questions and answers) and per participant. For group A, median values and IQRs for the markers were calculated as well.</p></sec></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Item Analysis: Single Choice Tests (T2a, T2b, and T2c)</title><p>The three SC tests were subjected to an item analysis to determine their difficulty and selectivity. For both groups, for each of the questions in a test, a difficulty index <italic>p</italic> was calculated with the following formula:</p><disp-formula><italic>p=N</italic><sub>C</sub><italic>/ N</italic></disp-formula><p>(<italic>N</italic><sub>C</sub>=number of participants with a correct answer, <italic>N</italic>=number of participants in the group). A selectivity index <italic>r</italic> as point-biserial correlation (r_p.bis) was calculated for each test as well.</p><p>For the pretest T2a, <italic>p</italic> was .7682 for group A and .7782 for group B. Thus, initially, the overall difficulty for both groups was almost identical, despite differences on a per-question level, which, however, is to be expected to be able to discriminate between high and low performing participants [<xref rid="ref19" ref-type="bibr">19</xref>]. Overall, over the course of the study, <italic>p</italic> rose for both groups, denoting decreasing difficulty. Directly after the initial learning phase, <italic>p</italic> was .8400 for group A and .8555 for group B. At the time of the final follow-up test, there were again only minor negligible differences between both groups with <italic>p</italic>=.8667 (group A) and <italic>p</italic>=.8650 (group B).</p></sec><sec><title>Learning Success: Single Choice Test (T2a, T2b, and T2c)</title><p>Immediately after the learning phase (post 1, T2b), as well as after 2 weeks (post 2, T2c), both groups showed improvements compared with their initial level of knowledge (baseline, T2a). Although there were only minor differences between both groups immediately following the learning phase, with the average number of correctly answered questions rising by 3.59 (SD 1.48) for group A and 3.86 (SD 1.51) for group B (difference 2.7% between both groups), the differences between the two groups were statistically insignificant (exact Mann Whitney <italic>U</italic>, <italic>U</italic>=173.5, <italic>P</italic>=.10, <italic>r</italic>=.247).</p><p>Descriptively, at the time of the final test after 2 weeks (<xref ref-type="table" rid="table3">Table 3</xref> and <xref ref-type="fig" rid="figure3">Figure 3</xref>), both groups did not do as well as before. However, those who had learned with mAR (group A) made an average of 8.1% fewer errors compared with those who had learned without the benefits of mAR (group B).</p><table-wrap id="table3" position="float"><label>Table 3</label><caption><p>Results (number of correctly answered questions) and changes for the single choice tests administered during the study.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="300" span="1"/><col width="115" span="1"/><col width="225" span="1"/><col width="110" span="1"/><col width="225" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Phase</td><td colspan="2" rowspan="1">Group A (mARble<sup>a</sup>)</td><td colspan="2" rowspan="1">Group B (mble<sup>b</sup>)</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Mean (SD<sup>c</sup>)</td><td rowspan="1" colspan="1">Change to the previous phase</td><td rowspan="1" colspan="1">Mean (SD)</td><td rowspan="1" colspan="1">Change to the previous phase</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Pre (T2a)</td><td rowspan="1" colspan="1">3.41 (1.33)</td><td rowspan="1" colspan="1">-</td><td rowspan="1" colspan="1">3.91 (1.90)</td><td rowspan="1" colspan="1">-</td></tr><tr valign="top"><td rowspan="1" colspan="1">Post 1 (T2b)</td><td rowspan="1" colspan="1">7.00 (1.48)</td><td rowspan="1" colspan="1">+3.59</td><td rowspan="1" colspan="1">7.77 (1.51)</td><td rowspan="1" colspan="1">+ 3.86</td></tr><tr valign="top"><td rowspan="1" colspan="1">Post 2 (T2c)</td><td rowspan="1" colspan="1">6.67 (1.62)</td><td rowspan="1" colspan="1">&#x02212;0.33</td><td rowspan="1" colspan="1">6.63 (1.30)</td><td rowspan="1" colspan="1">&#x02212;1.14</td></tr><tr valign="top"><td rowspan="1" colspan="1">Total <break/>(T2a to T2c)</td><td rowspan="1" colspan="1">-</td><td rowspan="1" colspan="1">+3.26</td><td rowspan="1" colspan="1">-</td><td rowspan="1" colspan="1">+2.72</td></tr></tbody></table><table-wrap-foot><fn id="table3fn1"><p><sup>a</sup>mARble: mobile Augmented Reality blended learning environment.</p></fn><fn id="table3fn2"><p><sup>b</sup>mble: mobile blended learning environment.</p></fn><fn id="table3fn3"><p><sup>c</sup>SD: standard deviation.</p></fn></table-wrap-foot></table-wrap><fig id="figure3" position="float"><label>Figure 3</label><caption><p>Results of the single choice tests for both groups. For the third test, missing values are denoted by m.</p></caption><graphic xlink:href="mhealth_v5i9e139_fig3"/></fig></sec><sec><title>Evaluating App Usage Based on Log Files Recorded on the Devices</title><p>For both groups, utilization periods for the question as well as answer cards differed (<xref ref-type="table" rid="table4">Tables 4</xref> and <xref ref-type="table" rid="table5">5</xref>). With a total time of 42,977 s of using the flashcards (usage times for questions and answers summarized), group A used considerably less time than group B (59.816 s, see <xref ref-type="table" rid="table4">Table 4</xref>). For group A, the median usage time per flashcard was 45 s for questions and 370 s for answer cards. Altogether, each member of group A had used question cards for a median of 311 s (IQR 236 s) and answer cards for a median of 1587.5 s (IQR 503 s). For group B, the median use amounted to 71 s for each question and 245 s per answer card. Again, looking at median values, each member of group B had used the question cards for 534 s (IQR 265 s), and answers were viewed for 2094 s (IQR 874 s), both time spans again being longer than those of group A (<xref ref-type="table" rid="table5">Table 5</xref>). The lower utilization times recorded for group A can be explained by the additional effort required by interacting with the markers (in-focus time for the markers, sum for all participants: 3603 s, median time per participant 156 s, IQR 85 s; see <xref ref-type="table" rid="table4">Tables 4</xref> and <xref ref-type="table" rid="table5">5</xref>). Also, considerable time was spent on selecting the desired markers, placing them on the skin, focusing on them with the device&#x02019;s camera etc (12,820 s, see <xref ref-type="table" rid="table4">Table 4</xref> and <xref ref-type="fig" rid="figure4">Figure 4</xref>).</p><table-wrap id="table4" position="float"><label>Table 4</label><caption><p>Combined utilization times in seconds, including in-focus time spans for the markers, interaction time span, and presentation times for both question and answer parts of the flashcards, stratified by group (group A with mobile Augmented Reality [mAR], group B without mAR functionality, both n=22).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="465" span="1"/><col width="265" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">&#x000a0;Utilization of specific parts of the application</td><td rowspan="1" colspan="1">Group A time, s (%)</td><td rowspan="1" colspan="1">Group B time, s (%)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">In-focus time span for the markers, n (%)</td><td rowspan="1" colspan="1">3603 (6.07)</td><td rowspan="1" colspan="1">-</td></tr><tr valign="top"><td rowspan="1" colspan="1">Other interactions with the markers, n (%)</td><td rowspan="1" colspan="1">12,820<sup>a</sup> (21.58)</td><td rowspan="1" colspan="1">-</td></tr><tr valign="top"><td rowspan="1" colspan="1">Presentation time: Questions, n (%)</td><td rowspan="1" colspan="1">8177 (13.77)</td><td rowspan="1" colspan="1">11,992 (20.05)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Presentation time: Answers, n (%)</td><td rowspan="1" colspan="1">34,800 (58.59)</td><td rowspan="1" colspan="1">47,824 (79.95)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Total learning time, N</td><td rowspan="1" colspan="1">59,400 (100.00)</td><td rowspan="1" colspan="1">59,816 (100.00)</td></tr></tbody></table><table-wrap-foot><fn id="table4fn1"><p><sup>a</sup>This value was calculated rather than measured.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table5" position="float"><label>Table 5</label><caption><p>Utilization times in seconds (median values and interquartile ranges) for the markers (in-focus time span), marker interaction, and flashcards (questions and answers) stratified by group (group A with mobile Augmented Reality [mAR], group B without mAR functionality, both n=22).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="465" span="1"/><col width="125" span="1"/><col width="140" span="1"/><col width="125" span="1"/><col width="125" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">&#x000a0;Utilization of specific parts of the application</td><td colspan="2" rowspan="1">Group A time (s)</td><td colspan="2" rowspan="1">Group B time (s)</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Median</td><td rowspan="1" colspan="1">IQR<sup>a</sup></td><td rowspan="1" colspan="1">Median</td><td rowspan="1" colspan="1">IQR</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Markers: In-focus time per participant</td><td rowspan="1" colspan="1">156.0</td><td rowspan="1" colspan="1">85.0</td><td rowspan="1" colspan="1">-</td><td rowspan="1" colspan="1">-</td></tr><tr valign="top"><td rowspan="1" colspan="1">Presentation time per question/participant</td><td rowspan="1" colspan="1">45.0</td><td rowspan="1" colspan="1">71.0</td><td rowspan="1" colspan="1">71.0</td><td rowspan="1" colspan="1">84.5</td></tr><tr valign="top"><td rowspan="1" colspan="1">Total presentation time per participant (questions only)</td><td rowspan="1" colspan="1">311.0</td><td rowspan="1" colspan="1">236.0</td><td rowspan="1" colspan="1">534.0</td><td rowspan="1" colspan="1">265.0</td></tr><tr valign="top"><td rowspan="1" colspan="1">Presentation time per answer/participant</td><td rowspan="1" colspan="1">245.0</td><td rowspan="1" colspan="1">276.0</td><td rowspan="1" colspan="1">370.0</td><td rowspan="1" colspan="1">311.0</td></tr><tr valign="top"><td rowspan="1" colspan="1">Total presentation time per participant (answers only)</td><td rowspan="1" colspan="1">1587.5</td><td rowspan="1" colspan="1">503.0</td><td rowspan="1" colspan="1">2094.0</td><td rowspan="1" colspan="1">874.0</td></tr></tbody></table><table-wrap-foot><fn id="table5fn1"><p><sup>a</sup>IQR: interquartile range.</p></fn></table-wrap-foot></table-wrap><fig id="figure4" position="float"><label>Figure 4</label><caption><p>Graphical representation of the distribution of time spent on interacting with the markers as well as the flashcards, stratified for group A (mobile Augmented Reality blended learning environment [mARble]) and group B (mobile blended learning environment [mble]).</p></caption><graphic xlink:href="mhealth_v5i9e139_fig4"/></fig></sec><sec><title>Emotional Involvement (T1a+T1b): POMS Questionnaire, German Version</title><p>For the two groups, the results of the POMS tests applied before and after the learning phase with the aim of determining whether there were any changes in the participant&#x02019;s emotional status did not show significant differences with respect to the evaluated qualities (see <xref ref-type="table" rid="table6">Table 6</xref> and <xref ref-type="fig" rid="figure5">Figure 5</xref>). Descriptively, differences were seen for the two dimensions of &#x0201c;irritability&#x0201d; and &#x0201c;numbness,&#x0201d; whereas for both groups, &#x0201c;fatigue&#x0201d; did not change as much. For &#x0201c;vigor,&#x0201d; the decrease was almost equal for both groups (decrease for group A: 1.54, for group B: 1.5). For group B, &#x0201c;numbness&#x0201d; decreased by 2.11, from 7.36 (SD 8.54) to 5.25 (SD 7.56). This decrease was larger than for group A, where &#x0201c;numbness&#x0201d; had only been reduced by 0.87, with an initial value of 4.55 (SD 4.78), which changed to 3.68 (SD 4.52) after the learning phase. For &#x0201c;irritability,&#x0201d; there was a slight increase for group A and a slight decrease for group B.</p><table-wrap id="table6" position="float"><label>Table 6</label><caption><p>Aggregated values for numbness, vigor, fatigue, and irritability for groups A and B (both n=22).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="75" span="1"/><col width="100" span="1"/><col width="220" span="1"/><col width="215" span="1"/><col width="215" span="1"/><col width="160" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Group</td><td rowspan="1" colspan="1">Phase</td><td colspan="4" rowspan="1">Dimensions</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Numbness, mean (SD<sup>a</sup>)</td><td rowspan="1" colspan="1">Vigor, mean (SD)</td><td rowspan="1" colspan="1">Fatigue, mean (SD)</td><td rowspan="1" colspan="1">Irritability, mean (SD)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">A</td><td rowspan="1" colspan="1">Pre</td><td rowspan="1" colspan="1">4.55 (4.78)</td><td rowspan="1" colspan="1">24.55 (5.47)</td><td rowspan="1" colspan="1">11.36 (5.11)</td><td rowspan="1" colspan="1">3.55 (4.70)</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Post</td><td rowspan="1" colspan="1">3.68 (4.52)</td><td rowspan="1" colspan="1">23.01 (5.02)</td><td rowspan="1" colspan="1">11.77 (6.79)</td><td rowspan="1" colspan="1">4.00 (4.35)</td></tr><tr valign="top"><td rowspan="1" colspan="1">B</td><td rowspan="1" colspan="1">Pre</td><td rowspan="1" colspan="1">7.36 (8.54)</td><td rowspan="1" colspan="1">21.36 (6.69)</td><td rowspan="1" colspan="1">15.64 (8.64)</td><td rowspan="1" colspan="1">3.14 (3.51)</td></tr><tr valign="top"><td rowspan="1" colspan="1"><break/></td><td rowspan="1" colspan="1">Post</td><td rowspan="1" colspan="1">5.25 (7.56)</td><td rowspan="1" colspan="1">19.86 (6.39)</td><td rowspan="1" colspan="1">15.15 (9.47)</td><td rowspan="1" colspan="1">2.45 (3.19)</td></tr></tbody></table><table-wrap-foot><fn id="table6fn1"><p><sup>a</sup>SD: standard deviation.</p></fn></table-wrap-foot></table-wrap><fig id="figure5" position="float"><label>Figure 5</label><caption><p>Aggregated values for irritability, fatigue, vigor, and numbness.</p></caption><graphic xlink:href="mhealth_v5i9e139_fig5"/></fig><fig id="figure6" position="float"><label>Figure 6</label><caption><p>Left: Portfolio with average values of the dimensions pragmatic quality (PQ) and hedonic quality (HQ) and the respective confidence rectangles of A (mobile Augmented Reality blended learning environment [mARble]) and B (mobile blended learning environment [mble]), modified following Hassenzahl et al. Right: Corresponding values.</p></caption><graphic xlink:href="mhealth_v5i9e139_fig6"/></fig><fig id="figure7" position="float"><label>Figure 7</label><caption><p>Average values calculated for the four qualities (both groups).</p></caption><graphic xlink:href="mhealth_v5i9e139_fig7"/></fig></sec><sec><title>Learning Experience (T3): AttrakDiff 2</title><p>The learning experience was rated positively by all participants, independent of whether they had learned with or without the mAR component, with only marginal differences (descriptive) between both groups (<xref ref-type="fig" rid="figure6">Figures 6</xref> and <xref ref-type="fig" rid="figure7">7</xref>,<xref ref-type="table" rid="table7">Table 7</xref>). Nevertheless, as the confidence rectangles for both groups overlap (<xref ref-type="fig" rid="figure6">Figure 6</xref>; [<xref rid="ref15" ref-type="bibr">15</xref>]), this is statistically insignificant [<xref rid="ref18" ref-type="bibr">18</xref>]. However, AR-based learning was rated better with respect to HQ, and there was also an emphasis on &#x0201c;self-orientation,&#x0201d; which can be attributed to the greater degree of self-centeredness (HQ-I) calculated for this group. In contrast, for group B, ratings emphasized the PQ of the learning experience, mirroring its perceived task-orientation. Differences between the average values calculated for PQ and HQ (aggregated from HQ-I and HQ-S) are negligible. Both groups gave similar ratings for stimulation (HQ-S), with the app without mAR being rated slightly more attractive (group A: 1.143, group B: 1.564).</p><table-wrap id="table7" position="float"><label>Table 7</label><caption><p>Aggregated values calculated for the four qualities covered by AttrakDiff 2: pragmatic quality (PQ), identification (HQ-I), stimulation (HQ-S), and attractiveness (ATT) for groups A and B (both n=22).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="240" span="1"/><col width="210" span="1"/><col width="210" span="1"/><col width="210" span="1"/><col width="125" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Group</td><td rowspan="1" colspan="1">PQ<sup>a</sup><break/>mean (SD<sup>b</sup>)</td><td rowspan="1" colspan="1">HQ-I<sup>c</sup><break/>mean (SD)</td><td rowspan="1" colspan="1">HQ-S<sup>d</sup><break/>mean (SD)</td><td rowspan="1" colspan="1">ATT<sup>e</sup><break/>mean (SD)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">A</td><td rowspan="1" colspan="1">0.890 (0.76)</td><td rowspan="1" colspan="1">1.435 (0.51)</td><td rowspan="1" colspan="1">0.564 (0.57)</td><td rowspan="1" colspan="1">1.143 (0.60)</td></tr><tr valign="top"><td rowspan="1" colspan="1">B</td><td rowspan="1" colspan="1">1.286 (0.77)</td><td rowspan="1" colspan="1">0.870 (0.78)</td><td rowspan="1" colspan="1">0.617 (0.66)</td><td rowspan="1" colspan="1">1.564 (0.65)</td></tr></tbody></table><table-wrap-foot><fn id="table7fn1"><p><sup>a</sup>PQ: pragmatic quality.</p></fn><fn id="table7fn2"><p><sup>b</sup>SD: standard deviation.</p></fn><fn id="table7fn3"><p><sup>c</sup>HQ-I: hedonic quality-identification.</p></fn><fn id="table7fn4"><p><sup>d</sup>HQ-S: hedonic quality-stimulation.</p></fn><fn id="table7fn5"><p><sup>e</sup>ATT: attractiveness.</p></fn></table-wrap-foot></table-wrap></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Ascertaining the Effects of mAR</title><p>The basic suitability of the mAR-based concept for teaching purposes had already been evaluated in a previous study, where a comparison between conventional learning (using textbooks) and app-based learning was presented, which also included mAR [<xref rid="ref6" ref-type="bibr">6</xref>]. At that time, a clear advantage of the app-based approach versus textbook-based learning was shown. However, it was unclear whether the positive effects that had been noted could in fact be attributed to the AR component. There was also a suspicion that the learning medium itself, that is, the excitement of using a mobile phone or tablet personal computer (PC), might already have influenced the results [<xref rid="ref6" ref-type="bibr">6</xref>]. On the contrary, in this study, with the learning scenarios and presentation of the learning content being identical (multimedia-supported flashcards presented on mobile phones and tablet PCs) with the exception of the mAR component, it was possible to examine the influence of the mAR component on both learning success and learning experience.</p></sec><sec><title>Principal Findings</title><p>Surprisingly, the test scores showed an almost identical increase in the average number of correct answers for both groups (pre to post 1, average improvement for group A: 3.59 [SD 1.48], group B: 3.86 [SD 1.51]; exact Mann Whitney <italic>U</italic>, <italic>U</italic>=173.5; <italic>P</italic>=.10; <italic>r</italic>=.247). Therefore, simply attributing the learning success to the mAR component seems implausible. In comparison with our previous study, whether the greater increase in knowledge is simply because of the use of mobile technologies in general rather than the influence of the mAR component (with its seemingly small contribution shown here), warrants further scrutiny and needs to be considered in future work. However, indications&#x02014;albeit small&#x02014;of possible long-term effects may be of interest; at the time of the follow-up test 14 days later, the average number of correct answers only decreased by 0.33 (SD 1.62) for group A but by 1.14 (SD 1.30) for group B, which had not had access to the mAR component of the app while learning. Unfortunately, the dropout rate at T2c (<xref ref-type="fig" rid="figure1">Figure 1</xref>) was too high to permit a more confident assertion, but it may be reasonably assumed that the mAR component contributes to committing what is learned to long-term memory, and this is indeed an interesting subject to be examined in later studies. On a side note, we do not believe that repeat testing&#x02014;that is, using the same tests for T2a, T2b, and T2c (<xref ref-type="fig" rid="figure1">Figure 1</xref>)&#x02014;had a significant influence on the results. During the course of the study, none of the students were provided with either their test scores or the correct answers to the presented questions, which would have given them the opportunity to improve their results. They were only able to base their answers on the provided study material, and if any of the participants had cheated or memorized the answers based on the previously administered tests, we would have expected a more significant increase of their knowledge.</p><p>Particularly noteworthy was that group A, learning with mAR support, spent obviously much less time on using the flashcard-based content (identical for both groups) than their counterparts in group B (group A: 1587.5 s [IQR 503 s], group B: 2094 s [IQR 874 s]). Group A spent a significant amount of the allocated time on interacting with the markers, which amounted to a total of 3603 s for all participants (median marker usage per participant: 156.0s, IQR 85.0, also see <xref ref-type="table" rid="table5">Table 5</xref>). Whereas for the missing 12,820 s, there was no hard evidence proving additional marker usage in the log files (see <xref ref-type="table" rid="table4">Table 4</xref>), there were observations by the principal investigator who was present during the learning phase that there had indeed been significant mAR related interaction which&#x02014;for technical reasons&#x02014;had not been recorded by the app. This included time spent on searching for the desired markers, placing the markers on the skin, trying to focus on the markers, etc, which can certainly be rated as marker-related use of the app. It is up for speculation whether there is an effect of AR and interaction on the learning success that might have effects on better committing knowledge to long-term memory. Future study designs need to consider this aspect carefully. However, some indications for a potentially positive impact of interactive components on the learning process and commitment of knowledge to long-term memory can be found in literature.</p><p>In comparison to other technology-supported learning techniques, there are several mentions of potentially positive as well as negative effects of AR on the learning process [<xref rid="ref4" ref-type="bibr">4</xref>]. In the past, there were fears that with AR demanding a higher level of focus from learners than, for example, simple multimedia supported learning modules&#x02014;and possibly requiring more attention for technical aspects&#x02014;AR might in fact distract students from the presented content [<xref rid="ref20" ref-type="bibr">20</xref>]. However, we do not believe this to be true, as nowadays, when implemented in a mobile manner, on devices users are familiar with, many of the complexities previously attributed to AR are much less of an issue. This was also corroborated by observations we made during the study, where none of the participants of the mARble group indicated problems with handling the application. In fact, there were early mentions of AR and its playful aspects possibly decreasing cognitive load [<xref rid="ref21" ref-type="bibr">21</xref>], encouraging students to be creative, to explore the provided content, and to make exciting discoveries on their own, thereby also improving learner's motivation.</p><p>The directed attention required when using AR is often also described as beneficial. AR's ability to direct its users&#x02019; attention to the relevant content, effectively highlighting important content [<xref rid="ref4" ref-type="bibr">4</xref>,<xref rid="ref22" ref-type="bibr">22</xref>], as well as the ability to physically enact a learning experience or at least interact with the content, may lead to enhanced memory encoding and better retention of what is being learned [<xref rid="ref4" ref-type="bibr">4</xref>]. There are also indications that this physical interaction may activate kinesthetic schemas [<xref rid="ref23" ref-type="bibr">23</xref>], which may also have a positive influence on the learning outcome and help with transferring acquired knowledge from working memory (with relatively low-capacity) to (high-capacity) long-term memory [<xref rid="ref24" ref-type="bibr">24</xref>].</p><p>The learning experience for both groups was evaluated based on the method described by Hassenzahl et al [<xref rid="ref15" ref-type="bibr">15</xref>,<xref rid="ref17" ref-type="bibr">17</xref>,<xref rid="ref18" ref-type="bibr">18</xref>]. Descriptively, mAR was rated more self-oriented, which was because of higher average values in the hedonic domain and smaller average values for pragmatic qualities in comparison with mobile blended learning environment (mble). Nevertheless, as the confidence rectangles for both groups overlap (see <xref ref-type="fig" rid="figure6">Figure 6</xref>), this is statistically insignificant [<xref rid="ref17" ref-type="bibr">17</xref>]. In detail, both systems were rated as similarly stimulating (see <xref ref-type="fig" rid="figure7">Figure 7</xref>), which is consistent with ratings for mARble in the previously conducted study [<xref rid="ref6" ref-type="bibr">6</xref>]. Thus, the stimulating effect is probably rather attributable to the app and the devices it runs on rather than to the mAR component. With respect to a possible self-oriented perception of the AR-based learning experience, the intense (and time-consuming) engagement with the mAR component may be an explanation. However, this hypothesis needs to be further corroborated by additional studies.</p><p>In contrast, there were no significant differences between both groups in the emotional realm, as evaluated by the POMS questionnaire. For &#x0201c;numbness,&#x0201d; &#x0201c;vigor,&#x0201d; &#x0201c;fatigue,&#x0201d; and &#x0201c;irritability,&#x0201d; there were only marginal differences in the ratings of both groups (see <xref ref-type="table" rid="table6">Table 6</xref> and <xref ref-type="fig" rid="figure5">Figure 5</xref>).</p></sec><sec><title>Limitations</title><p>As indicated, the study design was adapted according to the general difficulty of recruiting students. The highly streamlined and demanding curriculum medical students have to deal with does not give them much room for participating in activities that they perceive as further reducing their spare time. With this kept in mind, we were forced to make a compromise to the study design by calculating the sample size with a power of 0.8. For the future, for disciplines where visual content plays an important role in medical education, we will therefore aim at integrating our approach into the curriculum, thus also giving us access to a larger number of (potential) study participants.</p><p>There is room for debate about whether the random allocation of female and male participants to the two groups, which lead to a rather heterogeneous sample for both, had any influence on the results of the SC tests.</p><p>With respect to the markers, based on the chosen technical approach, it was impossible to record usage times other than those that were caused by the markers being in the camera&#x02019;s focus, defined as the time span from recognition of a marker to a flashcard being displayed. Other efforts required for making use of the markers, leading up to them being in focus (selection of the desired markers, placing them on the skin, and trying to focus the camera) were not logged. In follow-up studies, a way for recording the time to fulfill these tasks needs to be found. Finally, assessing emotional involvement solely based on the POMS questionnaire is less than ideal, and care should be taken to identify an instrument better suited to evaluating the self-oriented character of the mAR-based approach.</p></sec><sec><title>Conclusions</title><p>Using mobile technologies for learning purposes integrated into a multimedia-based concept, for example, with a flashcard-based approach similar to the one presented here, can be an effective approach that is at least equivalent to conventional ways of learning, if not better [<xref rid="ref6" ref-type="bibr">6</xref>]. In this study, isolated indications for the actual impact of mAR on learning success could not be found. The effect described in the previous study may be attributable to the impact of other mobile design aspects rather than the mAR component. Larger-scale evaluations seem advisable for providing final evidence. However, whereas both groups of students obtained similar results regarding learning success, compared with their counterparts, the mARble group spent a significant part of their allocated learning time on AR-related interactions instead of on the flashcards providing textual information, pointing to the potential benefits of mAR on knowledge retention. The (descriptive) indications we found for mAR&#x02019;s potentially positive influence on committing knowledge to long-term memory also point in this direction. Finally, the presented work also found indications pointing to the self-oriented character of mAR-based learning but unfortunately with a lack of significance. Whether&#x02014;and if so, how&#x02014;this contributes to the learning process also needs to be investigated in future studies.</p></sec></sec></body><back><ack><p>The authors would like to thank Bernhard H&#x000e4;ussermann and Felix Str&#x000fc;bing for technical support during the development of mARble, Anke Mittelst&#x000e4;dt and Enno Rubner for assistance with the photography, and all students for their participation in this trial. No external funding was obtained to conduct the study. The manuscript was checked against the Consolidated Standards of Reporting Trials of Electronic and Mobile HEalth Applications and onLine TeleHealth checklist [<xref rid="ref25" ref-type="bibr">25</xref>].</p></ack><fn-group><fn fn-type="COI-statement"><p>Conflicts of Interest: None declared.</p></fn></fn-group><glossary><title>Abbreviations</title><def-list><def-item><term id="abb1">AR</term><def><p>augmented reality</p></def></def-item><def-item><term id="abb2">ATT</term><def><p>attractiveness</p></def></def-item><def-item><term id="abb3">HQ</term><def><p>hedonic quality</p></def></def-item><def-item><term id="abb4">HQ-I</term><def><p>hedonic quality-identification</p></def></def-item><def-item><term id="abb5">HQ-S</term><def><p>hedonic quality-stimulation</p></def></def-item><def-item><term id="abb6">iOS</term><def><p>iPhone operating system</p></def></def-item><def-item><term id="abb7">IQR</term><def><p>interquartile range</p></def></def-item><def-item><term id="abb8">mAR</term><def><p>mobile Augmented Reality</p></def></def-item><def-item><term id="abb9">mARble</term><def><p>mobile Augmented Reality blended learning environment</p></def></def-item><def-item><term id="abb10">mble</term><def><p>mobile blended learning environment</p></def></def-item><def-item><term id="abb11">PC</term><def><p>personal computer</p></def></def-item><def-item><term id="abb12">POMS</term><def><p>Profile of Mood States Questionnaire</p></def></def-item><def-item><term id="abb13">PQ</term><def><p>pragmatic quality</p></def></def-item><def-item><term id="abb14">SC</term><def><p>single choice</p></def></def-item><def-item><term id="abb15">SD</term><def><p>standard deviation</p></def></def-item></def-list></glossary><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>L</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Levine</surname><given-names>A</given-names></name><name><surname>Haywood</surname><given-names>K</given-names></name></person-group><source>The 2010 Horizon Report: Australia-New Zealand Edition</source><year>2010</year><publisher-loc>Austin, Texas</publisher-loc><publisher-name>The New Media Consortium</publisher-name></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kroeker</surname><given-names>KL</given-names></name></person-group><article-title>Mainstreaming augmented reality</article-title><source>Commun ACM</source><year>2010</year><month>7</month><day>01</day><volume>53</volume><issue>7</issue><fpage>19</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1145/1785414.1785422</pub-id></element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azuma</surname><given-names>RT</given-names></name></person-group><article-title>A survey of augmented reality</article-title><source>Presence-Teleop VIRT</source><year>1997</year><month>8</month><volume>6</volume><issue>4</issue><fpage>355</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1162/pres.1997.6.4.355</pub-id></element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Radu</surname><given-names>I</given-names></name></person-group><article-title>Why should my students use AR? A comparative review of the educational impacts of augmented-reality</article-title><year>2012</year><conf-name>2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</conf-name><conf-date>2012</conf-date><conf-loc>Atlanta, Georgia, USA</conf-loc><fpage>313</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1109/ISMAR.2012.6402590</pub-id></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Figueiredo</surname><given-names>M</given-names></name><name><surname>Gomes</surname><given-names>J</given-names></name><name><surname>Gomes</surname><given-names>C</given-names></name><name><surname>Lopes</surname><given-names>J</given-names></name></person-group><article-title>Augmented reality tools and learning practice in mobile-learning</article-title><source>International Conference on Universal Access in Human-Computer Interaction. Universal Access to Information and Knowledge. Proceedings, Part II</source><year>2014</year><conf-name>8th International Conference, UAHCI 2014</conf-name><conf-date>June 22-27, 2014</conf-date><conf-loc>Heraklion, Crete, Greece</conf-loc><publisher-loc>Heidelberg, New York, Dordrecht, London</publisher-loc><publisher-name>Springer Cham</publisher-name><fpage>301</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-07440-5_28</pub-id></element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albrecht</surname><given-names>U-V</given-names></name><name><surname>Folta-Schoofs</surname><given-names>K</given-names></name><name><surname>Behrends</surname><given-names>M</given-names></name><name><surname>von Jan</surname><given-names>U</given-names></name></person-group><article-title>Effects of mobile augmented reality learning compared to textbook learning on medical students: randomized controlled pilot study</article-title><source>J Med Internet Res</source><year>2013</year><volume>15</volume><issue>8</issue><fpage>e182</fpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/2013/8/e182/"/></comment><pub-id pub-id-type="doi">10.2196/jmir.2497</pub-id><pub-id pub-id-type="medline">23963306</pub-id><!--<pub-id pub-id-type="pii">v15i8e182</pub-id>--><!--<pub-id pub-id-type="pmcid">PMC3758026</pub-id>--><pub-id pub-id-type="pmid">23963306</pub-id></element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrer-Torregrosa</surname><given-names>J</given-names></name><name><surname>Jim&#x000e9;nez-Rodr&#x000ed;guez</surname><given-names>M&#x000c1;</given-names></name><name><surname>Torralba-Estelles</surname><given-names>J</given-names></name><name><surname>Garz&#x000f3;n-Farin&#x000f3;s</surname><given-names>F</given-names></name><name><surname>P&#x000e9;rez-Bermejo</surname><given-names>M</given-names></name><name><surname>Fern&#x000e1;ndez-Ehrling</surname><given-names>N</given-names></name></person-group><article-title>Distance learning ects and flipped classroom in the anatomy learning: comparative study of the use of augmented reality, video and notes</article-title><source>BMC Med Educ</source><year>2016</year><month>9</month><day>01</day><volume>16</volume><issue>1</issue><fpage>230</fpage><comment><ext-link ext-link-type="uri" xlink:href="https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-016-0757-3"/></comment><pub-id pub-id-type="doi">10.1186/s12909-016-0757-3</pub-id><pub-id pub-id-type="medline">27581521</pub-id><!--<pub-id pub-id-type="pii">10.1186/s12909-016-0757-3</pub-id>--><!--<pub-id pub-id-type="pmcid">PMC5007708</pub-id>--><pub-id pub-id-type="pmid">27581521</pub-id></element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Albrecht</surname><given-names>U-V</given-names></name><name><surname>Behrends</surname><given-names>M</given-names></name><name><surname>Matthies</surname><given-names>HK</given-names></name><name><surname>von Jan</surname><given-names>U</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Sampson</surname><given-names>DG</given-names></name><name><surname>Isaias</surname><given-names>P</given-names></name><name><surname>Ifenthaler</surname><given-names>D</given-names></name><name><surname>Spector</surname><given-names>JM</given-names></name></person-group><article-title>Medical students experience the mobile augmented reality blended learning environment (mARble&#x000ae;): an attractive concept for the net generation?</article-title><source>Ubiquitous and Mobile Learning in the Digital Age</source><year>2013</year><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name><fpage>109</fpage><lpage>113</lpage></element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Moll</surname><given-names>I</given-names></name><name><surname>Jung</surname><given-names>EG</given-names></name><name><surname>Augustin</surname><given-names>M</given-names></name></person-group><source>Duale Reihe Dermatologie</source><year>2010</year><publisher-loc>Stuttgart</publisher-loc><publisher-name>Thieme</publisher-name></element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wirtz</surname><given-names>M</given-names></name><name><surname>Caspar</surname><given-names>F</given-names></name></person-group><source>Beurteiler&#x000fc;bereinstimmung und Beurteilerreliabilit&#x000e4;t: Methoden zur Bestimmung und Verbesserung der Zuverl&#x000e4;ssigkeit von Einsch&#x000e4;tzungen mittels Kategoriensystemen und Ratingskalen</source><year>2002</year><publisher-loc>G&#x000f6;ttingen</publisher-loc><publisher-name>Hogrefe</publisher-name></element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Lang</surname><given-names>AG</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name></person-group><article-title>G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title><source>Behav Res Methods</source><year>2007</year><month>5</month><volume>39</volume><issue>2</issue><fpage>175</fpage><lpage>91</lpage><pub-id pub-id-type="medline">17695343</pub-id><pub-id pub-id-type="pmid">17695343</pub-id></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name><name><surname>Lang</surname><given-names>AG</given-names></name></person-group><article-title>Statistical power analyses using G*Power 3.1: tests for correlation and regression analyses</article-title><source>Behav Res Methods</source><year>2009</year><month>11</month><volume>41</volume><issue>4</issue><fpage>1149</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.3758/BRM.41.4.1149</pub-id><pub-id pub-id-type="medline">19897823</pub-id><!--<pub-id pub-id-type="pii">41/4/1149</pub-id>--><pub-id pub-id-type="pmid">19897823</pub-id></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McNair</surname><given-names>DM</given-names></name><name><surname>Lorr</surname><given-names>M</given-names></name><name><surname>Droppleman</surname><given-names>LF</given-names></name></person-group><source>EITS Manual for the Profile of Mood States</source><year>1971</year><publisher-loc>San Diego, CA</publisher-loc><publisher-name>Educational and Industrial Testing Service</publisher-name></element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Biehl</surname><given-names>B</given-names></name><name><surname>Dangel</surname><given-names>S</given-names></name><name><surname>Reiser</surname><given-names>A</given-names></name></person-group><article-title>POMS: Profile of Mood States - deutsche Fassung</article-title><source>Internationale Skalen f&#x000fc;r Psychiatrie</source><year>1981</year><publisher-loc>Weinheim</publisher-loc><publisher-name>Collegium Internationale Psychiatriae Scalarum (CIPS)</publisher-name></element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hassenzahl</surname><given-names>M</given-names></name><name><surname>Burmester</surname><given-names>M</given-names></name><name><surname>Koller</surname><given-names>F</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Szwillus</surname><given-names>G</given-names></name><name><surname>Ziegler</surname><given-names>J</given-names></name></person-group><article-title>AttrakDiff: Ein Fragebogen zur Messung wahrgenommener hedonischer und pragmatischer Qualit&#x000e4;t</article-title><source>Mensch &#x00026; Computer 2003</source><year>2003</year><publisher-loc>Wiesbaden</publisher-loc><publisher-name>Vieweg+Teubner Verlag</publisher-name><fpage>187</fpage><lpage>196</lpage></element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Isleifsd&#x000f3;ttir</surname><given-names>J</given-names></name><name><surname>L&#x000e1;rusd&#x000f3;ttir</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Law</surname><given-names>ELC</given-names></name><name><surname>Bevan</surname><given-names>N</given-names></name><name><surname>Christou</surname><given-names>G</given-names></name><name><surname>Springett</surname><given-names>M</given-names></name><name><surname>L&#x000e1;rusd&#x000f3;ttir</surname><given-names>M</given-names></name></person-group><article-title>Measuring the user experience of task oriented software</article-title><source>Proceedings of the International Workshop on Meaningful Measures: Valid Useful User Experience Measurement (VUUM)</source><year>2008</year><publisher-loc>Toulouse, France</publisher-loc><publisher-name>Institute of Research in Informatics of Toulouse (IRIT)</publisher-name><fpage>97</fpage><lpage>102</lpage></element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassenzahl</surname><given-names>M</given-names></name></person-group><article-title>The interplay of beauty, goodness, and usability in interactive products</article-title><source>Hum Comput Interact</source><year>2004</year><month>12</month><day>1</day><volume>19</volume><issue>4</issue><fpage>319</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1207/s15327051hci1904_2</pub-id></element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hassenzahl</surname><given-names>M</given-names></name><name><surname>Burmester</surname><given-names>M</given-names></name><name><surname>Koller</surname><given-names>F</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Brau</surname><given-names>H</given-names></name><name><surname>Diefenbach</surname><given-names>S</given-names></name><name><surname>Hassenzahl</surname><given-names>M</given-names></name><name><surname>Koller</surname><given-names>F</given-names></name><name><surname>Peissner</surname><given-names>M</given-names></name><name><surname>R&#x000f6;se</surname><given-names>K</given-names></name></person-group><article-title>Der User Experience (UX) auf der Spur: Zum Einsatz von www.attrakdiff.de</article-title><source>Usability Professionals 2008</source><year>2008</year><publisher-loc>Stuttgart</publisher-loc><publisher-name>Fraunhofer IRB Verlag</publisher-name><fpage>78</fpage><lpage>82</lpage></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kuni</surname><given-names>H</given-names></name><name><surname>Becker</surname><given-names>P</given-names></name></person-group><source>Multiple Choice als Numerus clausus: (4) Pr&#x000fc;fung nicht bestanden: die Kandidaten oder die Fragen? [German]</source><date-in-citation>2017-04-28</date-in-citation><publisher-loc>Marburg</publisher-loc><publisher-name>Universit&#x000e4;t Marburg</publisher-name><comment><ext-link ext-link-type="uri" xlink:href="http://staff-www.uni-marburg.de/~kunih/all-doc/mcalsnc4.pdf">http://staff-www.uni-marburg.de/~kunih/all-doc/mcalsnc4.pdf</ext-link><ext-link ext-link-type="webcite" xlink:href="6q3jyyuaK"/></comment></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y-C</given-names></name></person-group><article-title>Peer learning in an AR-based learning environment</article-title><year>2008</year><conf-name>16th International Conference on Computers in Education</conf-name><conf-date>2008</conf-date><conf-loc>Taipei, Taiwan</conf-loc><fpage>291</fpage><lpage>295</lpage></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>H</given-names></name><name><surname>D&#x000fc;nser</surname><given-names>A</given-names></name></person-group><article-title>Summary of usability evaluations of an educational augmented reality application</article-title><year>2007</year><conf-name>ICVR'07 Proceedings of the 2nd international conference on Virtual reality</conf-name><conf-date>July 22 - 27, 2007</conf-date><conf-loc>Beijing, China</conf-loc><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>660</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1007/978-3-540-73335-5_71</pub-id></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nischelwitzer</surname><given-names>A</given-names></name><name><surname>Lenz</surname><given-names>FJ</given-names></name><name><surname>Searle</surname><given-names>G</given-names></name><name><surname>Holzinger</surname><given-names>A</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Stephanidis</surname><given-names>C</given-names></name></person-group><article-title>Some aspects of the development of low-cost augmented reality learning environments as examples for future interfaces in technology enhanced learning</article-title><source>Universal Access in Human-Computer Interaction Applications and Services</source><year>2007</year><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>728</fpage><lpage>737</lpage></element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Abrahamson</surname><given-names>D</given-names></name><name><surname>Trninic</surname><given-names>D</given-names></name></person-group><article-title>Toward an embodied-interaction design framework for mathematical concepts</article-title><source>Proceedings of the 10th International Conference on Interaction Design and Children</source><year>2011</year><conf-name>IDC '11</conf-name><conf-date>June 20 - 23, 2011</conf-date><conf-loc>Ann Arbor, Michigan</conf-loc><publisher-loc>New York, NY, USA</publisher-loc><publisher-name>ACM</publisher-name><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1145/1999030.1999031</pub-id></element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirazi</surname><given-names>A</given-names></name><name><surname>Behzadan</surname><given-names>AH</given-names></name></person-group><article-title>Design and assessment of a mobile augmented reality-based information delivery tool for construction and civil engineering curriculum</article-title><source>J Prof Issues Eng Educ Pract</source><year>2015</year><month>7</month><volume>141</volume><issue>3</issue><pub-id pub-id-type="doi">10.1061/(ASCE)EI.1943-5541.0000229</pub-id></element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eysenbach</surname><given-names>G</given-names></name><collab>CONSORT-EHEALTH GROUP</collab></person-group><article-title>CONSORT-EHEALTH: improving and standardizing evaluation reports of Web-based and mobile health interventions</article-title><source>J Med Internet Res</source><year>2011</year><volume>13</volume><issue>4</issue><fpage>e126</fpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/2011/4/e126/"/></comment><pub-id pub-id-type="doi">10.2196/jmir.1923</pub-id><pub-id pub-id-type="medline">22209829</pub-id><!--<pub-id pub-id-type="pii">v13i4e126</pub-id>--><!--<pub-id pub-id-type="pmcid">PMC3278112</pub-id>--><pub-id pub-id-type="pmid">22209829</pub-id></element-citation></ref></ref-list><app-group><app id="app1"><title>Multimedia Appendix 1</title><p>Completed CONSORT checklist.</p><fig id="d35e2638" position="anchor"><media xlink:href="mhealth_v5i9e139_app1.pdf"/></fig></app></app-group></back></article>