<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26173007</article-id><article-id pub-id-type="pmc">4501786</article-id><article-id pub-id-type="publisher-id">PONE-D-15-02789</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0132578</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Sample Size Calculation: Inaccurate <italic>A Priori</italic> Assumptions for Nuisance Parameters Can Greatly Affect the Power of a Randomized Controlled Trial</article-title><alt-title alt-title-type="running-head">Nuisance Parameter and Sample Size Calculation</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tavernier</surname><given-names>Elsa</given-names></name><xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref><xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref><xref ref-type="aff" rid="aff003">
<sup>3</sup>
</xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Giraudeau</surname><given-names>Bruno</given-names></name><xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref><xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref><xref ref-type="aff" rid="aff003">
<sup>3</sup>
</xref><xref ref-type="aff" rid="aff004">
<sup>4</sup>
</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>INSERM, U1153, Paris, France</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>CHRU, Tours, France</addr-line>
</aff><aff id="aff003">
<label>3</label>
<addr-line>INSERM CIC 1415, Tours, France</addr-line>
</aff><aff id="aff004">
<label>4</label>
<addr-line>Universit&#x000e9; Fran&#x000e7;ois-Rabelais de Tours, Tours, France</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Moerbeek</surname><given-names>Mirjam</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Utrecht University, NETHERLANDS</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con" id="contrib001"><p>Conceived and designed the experiments: ET BG. Performed the experiments: ET BG. Analyzed the data: ET BG. Wrote the paper: ET BG.</p></fn><corresp id="cor001">* E-mail: <email>elsa.tavernier@univ-tours.fr</email></corresp></author-notes><pub-date pub-type="collection"><year>2015</year></pub-date><pub-date pub-type="epub"><day>14</day><month>7</month><year>2015</year></pub-date><volume>10</volume><issue>7</issue><elocation-id>e0132578</elocation-id><history><date date-type="received"><day>20</day><month>1</month><year>2015</year></date><date date-type="accepted"><day>17</day><month>6</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; 2015 Tavernier, Giraudeau</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Tavernier, Giraudeau</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:type="simple" xlink:href="pone.0132578.pdf"/><abstract><p>We aimed to examine the extent to which inaccurate assumptions for nuisance parameters used to calculate sample size can affect the power of a randomized controlled trial (RCT). In a simulation study, we separately considered an RCT with continuous, dichotomous or time-to-event outcomes, with associated nuisance parameters of standard deviation, success rate in the control group and survival rate in the control group at some time point, respectively. For each type of outcome, we calculated a required sample size <italic>N</italic> for a hypothesized treatment effect, an assumed nuisance parameter and a nominal power of 80%. We then assumed a nuisance parameter associated with a relative error at the design stage. For each type of outcome, we randomly drew 10,000 relative errors of the associated nuisance parameter (from empirical distributions derived from a previously published review). Then, retro-fitting the sample size formula, we derived, for the pre-calculated sample size <italic>N</italic>, the real power of the RCT, taking into account the relative error for the nuisance parameter. In total, 23%, 0% and 18% of RCTs with continuous, binary and time-to-event outcomes, respectively, were underpowered (i.e., the real power was &#x0003c; 60%, as compared with the 80% nominal power); 41%, 16% and 6%, respectively, were overpowered (i.e., with real power &#x0003e; 90%). Even with proper calculation of sample size, a substantial number of trials are underpowered or overpowered because of imprecise knowledge of nuisance parameters. Such findings raise questions about how sample size for RCTs should be determined.</p></abstract><funding-group><funding-statement>The authors have no support or funding to report.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="1"/><page-count count="8"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The data underlying the findings described in the manuscript are freely available in the supporting information.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The data underlying the findings described in the manuscript are freely available in the supporting information.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>When calculating the sample size for a randomized controlled trial (RCT) comparing two low-fat diets, Gardner <italic>et al</italic> [<xref rid="pone.0132578.ref001" ref-type="bibr">1</xref>] estimated 60 patients in each group, which corresponded to 80% power with two-sided type I error 5%, a hypothesized between-group difference in level of low-density lipoprotein cholesterol after 4 weeks of 0.26 mmol/L and an assumed standard deviation of 0.52 mmol/L. However, the observed standard deviation was 0.78 mmol/L. If we consider the real between-group difference equaling the hypothesized value, an estimated sample size of 60 patients in each group would ensure only 45% power for such a trial. To insure 80% power, the required sample size should have been 142 patients in each group.</p><p>This situation is not rare. Vickers [<xref rid="pone.0132578.ref002" ref-type="bibr">2</xref>], and more recently, Charles <italic>et al</italic> [<xref rid="pone.0132578.ref003" ref-type="bibr">3</xref>], found large discrepancies between values for <italic>a priori</italic>-assumed parameters used for sample size calculation and <italic>a posteriori</italic>-estimated ones from observed data. Vickers focused on the common underestimation of the nuisance parameter standard deviation with a continuous outcome and showed that the observed standard deviation was greater than the <italic>a priori</italic>-assumed standard deviation in 80% of RCTs. The same issues could arise when the outcome is binary, for which the success rate in the control group is <italic>a priori</italic>-specified.</p><p>Establishing a correct sample size is of utmost importance [<xref rid="pone.0132578.ref004" ref-type="bibr">4</xref>, <xref rid="pone.0132578.ref005" ref-type="bibr">5</xref>] and the CONSORT Statement states that sample size calculations must be reported and justified in published articles [<xref rid="pone.0132578.ref006" ref-type="bibr">6</xref>]. If an RCT is too small, even with important differences among treatments, the trial results could be inconclusive (i.e., with no significantly statistical results). Moreover, even if the trial is conclusive, a too-small study would not be convincing enough to affect medical practice [<xref rid="pone.0132578.ref007" ref-type="bibr">7</xref>]. As well, patients included in too-small trials would not have the assurance that they were helping improve clinical practice, which raises ethical concerns [<xref rid="pone.0132578.ref008" ref-type="bibr">8</xref>]. Conversely, an RCT should be no larger than necessary. Indeed, an oversized trial would expose more patients than necessary to potential harm [<xref rid="pone.0132578.ref009" ref-type="bibr">9</xref>]. Such a trial would also lead to declaring a non-clinically relevant treatment effect as statistically significant [<xref rid="pone.0132578.ref009" ref-type="bibr">9</xref>]. Finally, it could consume more resources than necessary.</p><p>The aim of the present study was to assess how uncertainty in establishing nuisance parameters for continuous, dichotomous and time-to-event outcomes for RCTs affects the sample size calculations for trials and therefore real power.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and Methods</title><sec id="sec003"><title>Sample size calculation</title><p>In a superiority two-parallel-group RCT, the number of subjects is derived from four parameters: the hypothesized treatment effect on primary outcome measure, an assumption related to the control group, and the two <italic>a priori</italic>-specified statistical errors (considering that the type II statistical error is generally appraised with its complement, which corresponds to power). General equations for sample size calculations are in the <xref ref-type="supplementary-material" rid="pone.0132578.s001">S1 Appendix</xref>.</p></sec><sec id="sec004"><title>Nuisance parameter</title><p>In real life, calculating a sample size is difficult because it depends on some parameter associated with the control group that has to be <italic>a priori</italic>-specified. Such a parameter is sometimes called a nuisance parameter [<xref rid="pone.0132578.ref010" ref-type="bibr">10</xref>]. We considered three types of data for a primary outcome: continuous, binary and time-to-event data. As shown in <xref ref-type="table" rid="pone.0132578.t001">Table 1</xref>, each type of data is associated with a different way of hypothesizing a treatment effect but also implies assuming a nuisance parameter related to the control group. When the primary outcome is continuous, the treatment effect is often hypothesized as a mean difference. However, we also need to specify the standard deviation of the outcome (should be common to both the control and experimental groups). When the primary outcome is binary, we often hypothesize a success-rate difference, but we also have to assume the success rate expected in the control group. Finally, for a time-to-event outcome, the treatment effect is usually hypothesized as a hazard ratio or a survival-rate difference, but the expected survival rate in the control group at some time point must be <italic>a priori</italic>-specified for calculating the total number of patients to be included. These nuisance parameters are not the object of the study, but they need to be <italic>a priori</italic>-specified to plan the study. <italic>A priori</italic>-specified values are usually derived from previously published data. The quality of the assumption for a nuisance parameter made at this step relies heavily on the precision of the parameters derived from previous studies as well as similarities of these previous studies to the one being planned in terms of population. An incorrect assumption for a nuisance parameter could affect the power of the planned study (thus leading to an underpowered or overpowered study), and the aim of the present work was to assess the extent of such an impact.</p><table-wrap id="pone.0132578.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0132578.t001</object-id><label>Table 1</label><caption><title>Parameter of interest and nuisance parameter for the different types of data.</title></caption><alternatives><graphic id="pone.0132578.t001g" xlink:href="pone.0132578.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">
<bold>Type of data</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold>Hypothesized treatment effect</bold>
</th><th align="left" rowspan="1" colspan="1">
<bold>Nuisance parameter</bold>
</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Continuous</td><td align="left" rowspan="1" colspan="1">Mean difference</td><td align="left" rowspan="1" colspan="1">Standard deviation <break/>in the control group</td></tr><tr><td align="left" rowspan="1" colspan="1">Binary</td><td align="left" rowspan="1" colspan="1">Success rate difference</td><td align="left" rowspan="1" colspan="1">Success rate <break/>in the control group</td></tr><tr><td align="left" rowspan="1" colspan="1">Time-to-event</td><td align="left" rowspan="1" colspan="1">Hazard ratio</td><td align="left" rowspan="1" colspan="1">Survival rate in the control group <break/>at some time point</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec005"><title>Simulation study</title><p>To assess the impact of errors made in <italic>a priori</italic>-specifying a nuisance parameter on power in RCTs, we performed a simulation study. For each of the three types of outcomes, we considered a two-parallel-group RCT for which we hypothesized a treatment effect. We also assumed a nuisance parameter in the control group. With the chosen values, we calculated the appropriate sample size N considering 80% power, with two-sided type I error 5%. Then we considered that the true nuisance parameter differed from the <italic>a priori</italic>-assumed nuisance parameter. For each simulation, we used a probability density function (cf infra) to determine the error made in the nuisance parameter by comparing the assumed and the deduced true nuisance parameter. Considering the previously calculated sample size of N, we then retro-fitted the sample size formula to derive the real power of the trial with the true nuisance parameter to detect the treatment effect that had been hypothesized. Such a procedure was re-run 10,000 times to allow for estimating the proportion of underpowered or overpowered RCTs. The same simulation study was repeated considering a nominal power of 90%. Full details of the algorithms used are in the <xref ref-type="supplementary-material" rid="pone.0132578.s002">S2 Appendix</xref>.</p></sec><sec id="sec006"><title>Relative errors on nuisance parameters</title><p>To simulate the errors made in the <italic>a priori</italic>-specified nuisance parameter, we used data from a survey of 215 RTCs published in 2004 and 2006 in 6 general journals with high impact factor. In this survey, Charles <italic>et al</italic> [<xref rid="pone.0132578.ref003" ref-type="bibr">3</xref>] compared the assumptions in nuisance parameters made for the sample size calculation and the results. Data extracted included <italic>a priori</italic>-specified nuisance parameters and corresponding observed values reported in results sections. The <italic>a priori</italic>-specified assumptions and observed values could be compared for 147 articles reporting enough information (namely, in the sample size calculation section). For the three types of data, we estimated the relative difference between the observed parameter and its <italic>a priori</italic>-specified value (i.e., the difference between the observed minus the <italic>a priori</italic>-specified value divided by the <italic>a priori</italic>-specified value). We performed this calculation for 21 standard deviations, 78 success rates and 48 survival rates. Moreover, for success rates and survival rates, we applied an angular transformation to stretch out the values near 0 or 1 before calculating relative differences. Histograms of these relative differences are in <xref ref-type="fig" rid="pone.0132578.g001">Fig 1</xref>. A distribution was fitted for each of the three types of data. For continuous outcomes, the mean relative difference between the observed standard deviation of the outcome and its <italic>a priori</italic>-specified value was 0, with standard deviation 0.4. For binary outcomes, the mean relative difference between the observed success rate in the control group and its <italic>a priori</italic>-specified value was 0.05, with standard deviation 0.3. Finally, for time-to-event outcomes, the mean relative difference between the observed survival rate in the control group and its <italic>a priori</italic>-specified value was -0.1, with standard deviation 0.2.</p><fig id="pone.0132578.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0132578.g001</object-id><label>Fig 1</label><caption><title>Distribution curves fitted on the relative errors observed for nuisance parameters.</title><p>A gamma distribution was fitted for continuous outcomes. Angular transformations were applied before calculating relative errors for dichotomous and time-to-event outcomes, then normal distribution curves were fitted. Dataset of 147 published trials. (a) Relative error between the observed standard deviation compared to the postulated standard deviation for continuous data on for studies. (b) Relative error between the observed rate in the control group compared to the postulated rate in the control group for dichotomous data for 78 studies. (c) Relative error between the observed rate in the control group compared to the postulated rate in the control group for time to event data for 48 studies</p></caption><graphic xlink:href="pone.0132578.g001"/></fig></sec></sec><sec sec-type="results" id="sec007"><title>Results</title><p>
<xref ref-type="fig" rid="pone.0132578.g002">Fig 2</xref> displays real power proportions for the three types of data. For trials with continuous outcomes, 23% had a real power &#x0003c; 60%. Therefore, for one quarter of such RCTs, the planned sample size should be increased by at least 60% (cf <xref ref-type="supplementary-material" rid="pone.0132578.s003">S3 Appendix</xref>). However, 41% of such trials had a real power &#x0003e; 90%, so in these trials, the planned sample size was 25% greater than would be necessary. For trials with dichotomous outcomes, no RCT had a power &#x0003c; 60%, but 16% had a real power &#x0003e; 90% and would thus include at least 25% more patients than necessary. Finally, for trials with time-to-event outcomes, 18% had a real power &#x0003c; 60%, so the sample size should be increased by at least 60% to reach the nominal power of 80%. Only a few of these RCTs (6%) had a real power &#x0003e; 90%, so the planned number of recruited patients was overestimated by about 25%.</p><fig id="pone.0132578.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0132578.g002</object-id><label>Fig 2</label><caption><title>Real power distributions for 80% intended power and considering a normal distribution for the relative error for the true nuisance parameter.</title></caption><graphic xlink:href="pone.0132578.g002"/></fig><p>The discrepancies between real power and nominal 80% power were greater for continuous than dichotomous or time-to-event outcomes, which agrees with the distribution of relative errors having more widespread distribution for continuous than other outcomes. We presume that this finding is due to the greater complexity in specifying a standard deviation than a success rate or survival rate: the latter parameters are indeed more concrete and understandable than the former parameter. Finally, we found a certain proportion of underpowered trials with time-to-event outcomes, which is explained by the non-centered distribution of the relative error associated with the <italic>a priori</italic>-specified rate of events in the control group.</p><p>When the nominal power is 90%, 12.7% of trials with continuous outcomes and 5.3% of those with time-to-event outcomes had a real power of &#x0003c; 60%. The proportion of overpowered trials (&#x0003e; 90% power) was 54% for those with continuous outcomes, 42.8% for those with dichotomous outcomes and 31.6% for those with time-to-event outcomes.</p></sec><sec sec-type="conclusions" id="sec008"><title>Discussion</title><p>The present simulation study illustrates how realistic errors in assumptions for nuisance parameters translates into decreased or increased real power of an RCT. Within the parameters of the simulation, a large proportion of RCTs (i.e., 23% and 18% of RCTs with continuous and time-to-event outcomes, respectively) had a real power &#x0003c; 60%, that is, far less than the nominal 80% value. In contrast, overpowered RCTs were also common: 41%, 16% and 6% of RCTs with continuous, binary and time-to-event outcomes, respectively, had real power &#x0003e; 90%. When considering a higher nominal power (90%), the proportion of trials with power &#x0003c; 60% decreased to 12.7% for those with continuous outcomes and 5.3% for those with time-to-event outcomes. Our study has one limitation in that the distribution of the relative errors for the nuisance parameters were derived from a limited set of articles. Nevertheless, these distributions are realistic because they are derived from real RCTs.</p><p>Several explanations may explain the discrepancies between <italic>a priori</italic>-specified assumptions and observed values for nuisance parameters. The discrepancies may be due to lack of precision in estimating these nuisance parameters in previously published studies, caused by the nuisance parameters being sample estimates but assumed to be known in the sample size calculation. Moreover, trialists may also base their assumptions on monocenter pilot studies. In doing so, one may face another limitation: heterogeneity is less likely between patients from a common center than patients from different centers. Especially for continuous outcomes, standard deviations derived from monocenter pilot studies are expected to underestimate standard deviations derived from multicentric studies [<xref rid="pone.0132578.ref002" ref-type="bibr">2</xref>].</p><p>A targeted power of 90% instead of 80% allows for decreasing the proportion of trials with real power &#x0003c; 60%. As well, a study with a targeted 90% power will much more likely ensure at least the acceptable level of 80% than a study with a targeted 80% power. This consideration is related to the errors made on the nuisance parameter. Indeed, trials with 90% power are more likely to recruit for at least 80% power than those planned for 80% power [<xref rid="pone.0132578.ref011" ref-type="bibr">11</xref>]. Therefore the choice of 90% power is preferable when performing a sample size calculation. Moreover, some methods exist to deal with uncertainty associated with nuisance parameters. Thus, when planning the trial, the sensitivity of the sample size calculation to the imprecision of the population variance estimate [<xref rid="pone.0132578.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0132578.ref013" ref-type="bibr">13</xref>], or to the population success rate estimate for the control groups [<xref rid="pone.0132578.ref014" ref-type="bibr">14</xref>] should be investigated. Although such methods are rarely used (Clark et al. observed they were used in only 3% of a series of 446 protocols [<xref rid="pone.0132578.ref015" ref-type="bibr">15</xref>]), we could surely take advantage of using them more frequently. Otherwise, during the trial, sample re-estimations [<xref rid="pone.0132578.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0132578.ref017" ref-type="bibr">17</xref>], also referred to as internal pilot studies [<xref rid="pone.0132578.ref018" ref-type="bibr">18</xref>], are a kind of adaptive design. The idea is to consider part of the main trial as a pilot phase. The design is used for recomputing the nuisance parameter and recalculating the required sample size during the trial. The final analyses then incorporate all data, ignoring that part of the data came from a pilot phase. In this scenario, the first few patients entered in the trial should be more representative of the population of the trial than patients from a previous pilot study. However, such an approach has some limitations. First, it supposes an outcome rapidly assessed after randomization, thus allowing a sample size re-estimation before recruitment has ended. Second, there is a high risk of great imprecision with re-estimating nuisance parameters, which could be highly damaging. Finally, the approach supposes that the trialists have enough resources to increase the sample size, which is not always the case, namely for publicly funded RCTs.</p><p>Our results also illustrate that the emphasis on sample size calculation is inconsistent with the major difficulties that inevitably come with it, which explains why the usual guidance has been criticized. Bacchetti holds such calculations as responsible for the &#x0201c;threshold myth&#x0201d; [<xref rid="pone.0132578.ref019" ref-type="bibr">19</xref>]. In other words, current conventions assume a meaningful demarcation at which sample sizes are considered fair and adequate and that any smaller sample size would imply a wasted trial: this illusion causes substantial harm to the research process and he encourages alternative approaches based on cost and feasibility [<xref rid="pone.0132578.ref020" ref-type="bibr">20</xref>, <xref rid="pone.0132578.ref021" ref-type="bibr">21</xref>]. As well, Norman <italic>et al</italic> [<xref rid="pone.0132578.ref022" ref-type="bibr">22</xref>] supports the use of &#x0201c;off-the-peg&#x0201d; sample sizes when sufficient information is not available for a &#x0201c;made-to-measure&#x0201d; calculation. In general, authors agree with Bacchetti on the need to determine a sample size by more than literal statistical calculations.</p><p>Besides sample size issues, a unique trial often cannot provide definite evidence for the existence or absence of a treatment effect. Misinterpretations are indeed likely with the use of p values to dichotomise significant or non-significant results, which indicates the need for both small and large studies to focus on confidence intervals rather than p values [<xref rid="pone.0132578.ref023" ref-type="bibr">23</xref>]. Moreover systematic reviews and meta-analyses combining evidence from several RCTs are considered a higher level of evidence. Altough results from a single, small, underpowered trial may be unreliable, some authors nevertheless consider such trials legitimate [<xref rid="pone.0132578.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0132578.ref024" ref-type="bibr">24</xref>]. These trials are indeed expected to contribute to a body of knowledge, and a forthcoming meta-analysis can give a definite answer [<xref rid="pone.0132578.ref025" ref-type="bibr">25</xref>]. Indeed, with little data available, starting small seems meaningful and relevant [<xref rid="pone.0132578.ref021" ref-type="bibr">21</xref>]. Moreover, results from meta-analyses are more informative in that they allow for appraising the variability in between-RCT treatment effects and are a good opportunity to explore such variability.</p><p>These issues confirm and reinforce the fundamental idea that results from one trial should not be interpreted alone. In the end, the present work illustrates once again [<xref rid="pone.0132578.ref003" ref-type="bibr">3</xref>] the discrepancy between the important emphasis put on the sample size calculations and the reality of the great imprecision when implementing them.</p></sec><sec sec-type="supplementary-material" id="sec009"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0132578.s001"><label>S1 Appendix</label><caption><title>Sample size calculations.</title><p>(PDF)</p></caption><media xlink:href="pone.0132578.s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0132578.s002"><label>S2 Appendix</label><caption><title>Simulation study.</title><p>(PDF)</p></caption><media xlink:href="pone.0132578.s002.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0132578.s003"><label>S3 Appendix</label><caption><title>How an over- or underpowered trial translates to under- or overrecruitment.</title><p>(PDF)</p></caption><media xlink:href="pone.0132578.s003.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0132578.s004"><label>S1 Text</label><caption><title>Powers for continuous outcomes over 10,000 simulations.</title><p>(TXT)</p></caption><media xlink:href="pone.0132578.s004.txt"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0132578.s005"><label>S2 Text</label><caption><title>Powers for binary outcomes over 10,000 simulations.</title><p>(TXT)</p></caption><media xlink:href="pone.0132578.s005.txt"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0132578.s006"><label>S3 Text</label><caption><title>Powers for time-to-event outcomes over 10,000 simulations.</title><p>(TXT)</p></caption><media xlink:href="pone.0132578.s006.txt"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>The authors are grateful to Professor Philippe Ravaud and Pierre Charles for granting permission to use their data, and Agn&#x000e8;s Caille for her helpful comments to improve this paper.</p></ack><ref-list><title>References</title><ref id="pone.0132578.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Gardner</surname><given-names>CD</given-names></name>, <name><surname>Coulston</surname><given-names>A</given-names></name>, <name><surname>Chatterjee</surname><given-names>L</given-names></name>, <name><surname>Rigby</surname><given-names>A</given-names></name>, <name><surname>Spiller</surname><given-names>G</given-names></name>, <name><surname>Farquhar</surname><given-names>JW</given-names></name>. <article-title>The effect of a plant-based diet on plasma lipids in hypercholesterolemic adults: a randomized trial</article-title>. <source>Annals of Internal Medicine</source>. <year>2005</year>
<month>5</month>;<volume>142</volume>(<issue>9</issue>):<fpage>725</fpage>&#x02013;<lpage>733</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7326/0003-4819-142-9-200505030-00007">10.7326/0003-4819-142-9-200505030-00007</ext-link></comment>
<pub-id pub-id-type="pmid">15867404</pub-id></mixed-citation></ref><ref id="pone.0132578.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Vickers</surname><given-names>AJ</given-names></name>. <article-title>Underpowering in randomized trials reporting a sample size calculation</article-title>. <source>Journal of Clinical Epidemiology</source>. <year>2003</year>
<month>8</month>;<volume>56</volume>(<issue>8</issue>):<fpage>717</fpage>&#x02013;<lpage>720</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0895-4356(03)00141-0">10.1016/S0895-4356(03)00141-0</ext-link></comment>
<pub-id pub-id-type="pmid">12954462</pub-id></mixed-citation></ref><ref id="pone.0132578.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Charles</surname><given-names>P</given-names></name>, <name><surname>Giraudeau</surname><given-names>B</given-names></name>, <name><surname>Dechartres</surname><given-names>A</given-names></name>, <name><surname>Baron</surname><given-names>G</given-names></name>, <name><surname>Ravaud</surname><given-names>P</given-names></name>. <article-title>Reporting of sample size calculation in randomised controlled trials: review</article-title>. <source>BMJ (Clinical research ed)</source>. <year>2009</year>;<volume>338</volume>:<fpage>b1732</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1136/bmj.b1732">10.1136/bmj.b1732</ext-link></comment>
</mixed-citation></ref><ref id="pone.0132578.ref004"><label>4</label><mixed-citation publication-type="book">
<name><surname>Machin</surname><given-names>D</given-names></name>, <name><surname>Campbell</surname><given-names>MJ</given-names></name>, <name><surname>Tan</surname><given-names>SB</given-names></name>, <name><surname>Tan</surname><given-names>SH</given-names></name>. <source>Sample Size Tables for Clinical Studies</source>. <edition>3rd ed</edition>
<publisher-loc>Chichester, West Sussex, UK; Hoboken, NJ</publisher-loc>: <publisher-name>Wiley-Blackwell</publisher-name>; <year>2008</year>.</mixed-citation></ref><ref id="pone.0132578.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Schulz</surname><given-names>KF</given-names></name>, <name><surname>Grimes</surname><given-names>DA</given-names></name>. <article-title>Sample size calculations in randomised trials: mandatory and mystical</article-title>. <source>Lancet</source>. <year>2005</year>
<month>4</month>;<volume>365</volume>(<issue>9467</issue>):<fpage>1348</fpage>&#x02013;<lpage>1353</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(05)61034-3">10.1016/S0140-6736(05)61034-3</ext-link></comment>
<pub-id pub-id-type="pmid">15823387</pub-id></mixed-citation></ref><ref id="pone.0132578.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Moher</surname><given-names>D</given-names></name>, <name><surname>Hopewell</surname><given-names>S</given-names></name>, <name><surname>Schulz</surname><given-names>KF</given-names></name>, <name><surname>Montori</surname><given-names>V</given-names></name>, <name><surname>G&#x000f8;tzsche</surname><given-names>PC</given-names></name>, <name><surname>Devereaux</surname><given-names>PJ</given-names></name>, <etal>et al</etal>
<article-title>CONSORT 2010 Explanation and Elaboration: updated guidelines for reporting parallel group randomised trials</article-title>. <source>BMJ</source>. <year>2010</year>
<month>3</month>;<volume>340</volume>:<fpage>c869</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1136/bmj.c869">10.1136/bmj.c869</ext-link></comment>
<pub-id pub-id-type="pmid">20332511</pub-id></mixed-citation></ref><ref id="pone.0132578.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Bacchetti</surname><given-names>P</given-names></name>, <name><surname>Wolf</surname><given-names>LE</given-names></name>, <name><surname>Segal</surname><given-names>MR</given-names></name>, <name><surname>McCulloch</surname><given-names>CE</given-names></name>. <article-title>Ethics and sample size</article-title>. <source>American Journal of Epidemiology</source>. <year>2005</year>
<month>1</month>;<volume>161</volume>(<issue>2</issue>):<fpage>105</fpage>&#x02013;<lpage>110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/aje/kwi014">10.1093/aje/kwi014</ext-link></comment>
<pub-id pub-id-type="pmid">15632258</pub-id></mixed-citation></ref><ref id="pone.0132578.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Halpern</surname><given-names>SD</given-names></name>, <name><surname>Karlawish</surname><given-names>JHT</given-names></name>, <name><surname>Berlin</surname><given-names>JA</given-names></name>. <article-title>The continuing unethical conduct of underpowered clinical trials</article-title>. <source>JAMA</source>. <year>2002</year>
<month>7</month>;<volume>288</volume>(<issue>3</issue>):<fpage>358</fpage>&#x02013;<lpage>362</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1001/jama.288.3.358">10.1001/jama.288.3.358</ext-link></comment>
<pub-id pub-id-type="pmid">12117401</pub-id></mixed-citation></ref><ref id="pone.0132578.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Wittes</surname><given-names>J</given-names></name>. <article-title>Sample size calculations for randomized controlled trials</article-title>. <source>Epidemiologic Reviews</source>. <year>2002</year>;<volume>24</volume>(<issue>1</issue>):<fpage>39</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/epirev/24.1.39">10.1093/epirev/24.1.39</ext-link></comment>
<pub-id pub-id-type="pmid">12119854</pub-id></mixed-citation></ref><ref id="pone.0132578.ref010"><label>10</label><mixed-citation publication-type="book">
<name><surname>Gad</surname><given-names>SC</given-names></name>. <source>Clinical Trials Handbook</source>. <publisher-name>John Wiley &#x00026; Sons</publisher-name>; <year>2009</year>.</mixed-citation></ref><ref id="pone.0132578.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Sully</surname><given-names>BGO</given-names></name>, <name><surname>Julious</surname><given-names>SA</given-names></name>, <name><surname>Nicholl</surname><given-names>J</given-names></name>. <article-title>A reinvestigation of recruitment to randomised, controlled, multicenter trials: a review of trials funded by two UK funding agencies</article-title>. <source>Trials</source>. <year>2013</year>;<volume>14</volume>:<fpage>166</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1745-6215-14-166">10.1186/1745-6215-14-166</ext-link></comment>
<pub-id pub-id-type="pmid">23758961</pub-id></mixed-citation></ref><ref id="pone.0132578.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Julious</surname><given-names>SA</given-names></name>. <article-title>Designing clinical trials with uncertain estimates of variability</article-title>. <source>Pharmaceutical Statistics</source>. <year>2004</year>
<month>10</month>;<volume>3</volume>(<issue>4</issue>):<fpage>261</fpage>&#x02013;<lpage>268</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/pst.139">10.1002/pst.139</ext-link></comment>
</mixed-citation></ref><ref id="pone.0132578.ref013"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Julious</surname><given-names>SA1 OR</given-names></name>. <article-title>Sample size calculations for clinical studies allowing for uncertainty about the variance</article-title>. <source>Pharm Stat</source>. <year>2006</year>;p. <fpage>29</fpage>&#x02013;<lpage>37</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/pst.197">10.1002/pst.197</ext-link></comment>
<pub-id pub-id-type="pmid">17080926</pub-id></mixed-citation></ref><ref id="pone.0132578.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Julious</surname><given-names>SA</given-names></name>, <name><surname>Owen</surname><given-names>RJ</given-names></name>. <article-title>A comparison of methods for sample size estimation for non-inferiority studies with binary outcomes</article-title>. <source>Statistical Methods in Medical Research</source>. <year>2011</year>
<month>12</month>;<volume>20</volume>(<issue>6</issue>):<fpage>595</fpage>&#x02013;<lpage>612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0962280210378945">10.1177/0962280210378945</ext-link></comment>
<pub-id pub-id-type="pmid">20889572</pub-id></mixed-citation></ref><ref id="pone.0132578.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Clark</surname><given-names>T</given-names></name>, <name><surname>Berger</surname><given-names>U</given-names></name>, <name><surname>Mansmann</surname><given-names>U</given-names></name>. <article-title>Sample size determinations in original research protocols for randomised clinical trials submitted to UK research ethics committees: review</article-title>. <source>BMJ (Clinical research ed)</source>. <year>2013</year>;<volume>346</volume>:<fpage>f1135</fpage>.</mixed-citation></ref><ref id="pone.0132578.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Proschan</surname><given-names>MA</given-names></name>. <article-title>Two-stage sample size re-estimation based on a nuisance parameter: a review</article-title>. <source>Journal of Biopharmaceutical Statistics</source>. <year>2005</year>;<volume>15</volume>(<issue>4</issue>):<fpage>559</fpage>&#x02013;<lpage>574</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1081/BIP-200062852">10.1081/BIP-200062852</ext-link></comment>
<pub-id pub-id-type="pmid">16022163</pub-id></mixed-citation></ref><ref id="pone.0132578.ref017"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Gould</surname><given-names>AL</given-names></name>. <article-title>Sample size re-estimation: recent developments and practical considerations</article-title>. <source>Statistics in Medicine</source>. <year>2001</year>
<month>9</month>;<volume>20</volume>(<issue>17</issue>&#x02013;<issue>18</issue>):<fpage>2625</fpage>&#x02013;<lpage>2643</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/sim.733">10.1002/sim.733</ext-link></comment>
<pub-id pub-id-type="pmid">11523073</pub-id></mixed-citation></ref><ref id="pone.0132578.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Wittes</surname><given-names>J</given-names></name>, <name><surname>Brittain</surname><given-names>E</given-names></name>. <article-title>The role of internal pilot studies in increasing the efficiency of clinical trials</article-title>. <source>Statistics in Medicine</source>. <year>1990</year>
<month>2</month>;<volume>9</volume>(<issue>1</issue>&#x02013;<issue>2</issue>):<fpage>65</fpage>&#x02013;<lpage>71</lpage>; <comment>discussion 71&#x02013;72. doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/sim.4780090113">10.1002/sim.4780090113</ext-link></comment>
<pub-id pub-id-type="pmid">2345839</pub-id></mixed-citation></ref><ref id="pone.0132578.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Bacchetti</surname><given-names>P</given-names></name>. <article-title>Current sample size conventions: flaws, harms, and alternatives</article-title>. <source>BMC medicine</source>. <year>2010</year>;<volume>8</volume>:<fpage>17</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1741-7015-8-17">10.1186/1741-7015-8-17</ext-link></comment>
<pub-id pub-id-type="pmid">20307281</pub-id></mixed-citation></ref><ref id="pone.0132578.ref020"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Bacchetti</surname><given-names>P</given-names></name>, <name><surname>McCulloch</surname><given-names>CE</given-names></name>, <name><surname>Segal</surname><given-names>MR</given-names></name>. <article-title>Simple, defensible sample sizes based on cost efficiency</article-title>. <source>Biometrics</source>. <year>2008</year>
<month>6</month>;<volume>64</volume>(<issue>2</issue>):<fpage>577</fpage>&#x02013;<lpage>585</lpage>; <comment>discussion 586&#x02013;594. doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1541-0420.2008.01004_1.x">10.1111/j.1541-0420.2008.01004_1.x</ext-link></comment>
<pub-id pub-id-type="pmid">18482055</pub-id></mixed-citation></ref><ref id="pone.0132578.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Bacchetti</surname><given-names>P</given-names></name>, <name><surname>Deeks</surname><given-names>SG</given-names></name>, <name><surname>McCune</surname><given-names>JM</given-names></name>. <article-title>Breaking free of sample size dogma to perform innovative translational research</article-title>. <source>Science Translational Medicine</source>. <year>2011</year>
<month>6</month>;<volume>3</volume>(<issue>87</issue>):<fpage>87ps24</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/scitranslmed.3001628">10.1126/scitranslmed.3001628</ext-link></comment>
<pub-id pub-id-type="pmid">21677197</pub-id></mixed-citation></ref><ref id="pone.0132578.ref022"><label>22</label><mixed-citation publication-type="journal">
<name><surname>Norman</surname><given-names>G</given-names></name>, <name><surname>Monteiro</surname><given-names>S</given-names></name>, <name><surname>Salama</surname><given-names>S</given-names></name>. <article-title>Sample size calculations: should the emperor&#x02019;s clothes be off the peg or made to measure?</article-title>
<source>BMJ (Clinical research ed)</source>. <year>2012</year>;<volume>345</volume>:<fpage>e5278</fpage>.</mixed-citation></ref><ref id="pone.0132578.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Gardner</surname><given-names>MJ</given-names></name>, <name><surname>Altman</surname><given-names>DG</given-names></name>. <article-title>Confidence intervals rather than P values: estimation rather than hypothesis testing</article-title>. <source>British Medical Journal (Clinical Research Ed)</source>. <year>1986</year>
<month>3</month>;<volume>292</volume>(<issue>6522</issue>):<fpage>746</fpage>&#x02013;<lpage>750</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1136/bmj.292.6522.746">10.1136/bmj.292.6522.746</ext-link></comment>
<pub-id pub-id-type="pmid">3082422</pub-id></mixed-citation></ref><ref id="pone.0132578.ref024"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Edwards</surname><given-names>SJ</given-names></name>, <name><surname>Lilford</surname><given-names>RJ</given-names></name>, <name><surname>Braunholtz</surname><given-names>D</given-names></name>, <name><surname>Jackson</surname><given-names>J</given-names></name>. <article-title>Why &#x0201c;underpowered&#x0201d; trials are not necessarily unethical</article-title>. <source>Lancet</source>. <year>1997</year>
<month>9</month>;<volume>350</volume>(<issue>9080</issue>):<fpage>804</fpage>&#x02013;<lpage>807</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(97)02290-3">10.1016/S0140-6736(97)02290-3</ext-link></comment>
<pub-id pub-id-type="pmid">9298015</pub-id></mixed-citation></ref><ref id="pone.0132578.ref025"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Guyatt</surname><given-names>GH</given-names></name>, <name><surname>Mills</surname><given-names>EJ</given-names></name>, <name><surname>Elbourne</surname><given-names>D</given-names></name>. <article-title>In the era of systematic reviews, does the size of an individual trial still matter</article-title>. <source>PLoS medicine</source>. <year>2008</year>
<month>1</month>;<volume>5</volume>(<issue>1</issue>):<fpage>e4</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.0050004">10.1371/journal.pmed.0050004</ext-link></comment>
<pub-id pub-id-type="pmid">18177203</pub-id></mixed-citation></ref></ref-list></back></article>