<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Comput Intell Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Comput Intell Neurosci</journal-id><journal-id journal-id-type="publisher-id">CIN</journal-id><journal-title-group><journal-title>Computational Intelligence and Neuroscience</journal-title></journal-title-group><issn pub-type="ppub">1687-5265</issn><issn pub-type="epub">1687-5273</issn><publisher><publisher-name>Hindawi Publishing Corporation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28074090</article-id><article-id pub-id-type="pmc">5203925</article-id><article-id pub-id-type="doi">10.1155/2016/3891253</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Application of Machine Learning in Postural Control Kinematics for the Diagnosis of Alzheimer's Disease</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6566-3927</contrib-id><name><surname>Costa</surname><given-names>Lu&#x000ed;s</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0894-6207</contrib-id><name><surname>Gago</surname><given-names>Miguel F.</given-names></name><xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref><xref ref-type="aff" rid="I3">
<sup>3</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Yelshyna</surname><given-names>Darya</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5355-3117</contrib-id><name><surname>Ferreira</surname><given-names>Jaime</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6570-6501</contrib-id><name><surname>David Silva</surname><given-names>H&#x000e9;lder</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-8184-8801</contrib-id><name><surname>Rocha</surname><given-names>Lu&#x000ed;s</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8755-5126</contrib-id><name><surname>Sousa</surname><given-names>Nuno</given-names></name><xref ref-type="aff" rid="I3">
<sup>3</sup>
</xref><xref ref-type="aff" rid="I4">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Bicho</surname><given-names>Estela</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="I1"><sup>1</sup>Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal</aff><aff id="I2"><sup>2</sup>Neurology Department, Hospital da Senhora da Oliveira, Guimar&#x000e3;es, Portugal</aff><aff id="I3"><sup>3</sup>Life and Health Sciences Research Institute (ICVS), School of Health Sciences, University of Minho, Braga, Portugal</aff><aff id="I4"><sup>4</sup>ICVS-3B's-PT Government Associate Laboratory, Braga, Portugal</aff><author-notes><corresp id="cor1">*Miguel F. Gago: <email>miguelfgago@yahoo.com</email></corresp><fn fn-type="other"><p>Academic Editor: Silvia Conforto</p></fn></author-notes><pub-date pub-type="ppub"><year>2016</year></pub-date><pub-date pub-type="epub"><day>18</day><month>12</month><year>2016</year></pub-date><volume>2016</volume><elocation-id>3891253</elocation-id><history><date date-type="received"><day>21</day><month>7</month><year>2016</year></date><date date-type="accepted"><day>9</day><month>10</month><year>2016</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2016 Lu&#x000ed;s Costa et al.</copyright-statement><copyright-year>2016</copyright-year><license xlink:href="https://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>The use of wearable devices to study gait and postural control is a growing field on neurodegenerative disorders such as Alzheimer's disease (AD). In this paper, we investigate if machine-learning classifiers offer the discriminative power for the diagnosis of AD based on postural control kinematics. We compared Support Vector Machines (SVMs), Multiple Layer Perceptrons (MLPs), Radial Basis Function Neural Networks (RBNs), and Deep Belief Networks (DBNs) on 72 participants (36 AD patients and 36 healthy subjects) exposed to seven increasingly difficult postural tasks. The decisional space was composed of 18 kinematic variables (adjusted for age, education, height, and weight), with or without neuropsychological evaluation (Montreal cognitive assessment (MoCA) score), top ranked in an error incremental analysis. Classification results were based on threefold cross validation of 50 independent and randomized runs sets: training (50%), test (40%), and validation (10%). Having a decisional space relying solely on postural kinematics, accuracy of AD diagnosis ranged from 71.7 to 86.1%. Adding the MoCA variable, the accuracy ranged between 91 and 96.6%. MLP classifier achieved top performance in both decisional spaces. Having comprehended the interdynamic interaction between postural stability and cognitive performance, our results endorse machine-learning models as a useful tool for computer-aided diagnosis of AD based on postural control kinematics.</p></abstract><funding-group><award-group><funding-source>FP7 ITN Marie Curie Neural Engineering Transformative Technologies (NETT) project</funding-source></award-group></funding-group></article-meta></front><body><sec id="sec1"><title>1. Introduction</title><p>Around 30% of the people aged more than 65, living in the community, and more than 50% of those living in residential care facilities or nursing homes fall every year. Moreover, about half of those who fall do so repeatedly [<xref rid="B1" ref-type="bibr">1</xref>]. With the increase in the elderly population, the number of falls in this group has been rising constituting an important public health problem [<xref rid="B2" ref-type="bibr">2</xref>]. Postural instability, characterized by excessive and uncontrolled sway, degrades with ageing and is a risk factor for the occurrence of falls, especially in neurodegenerative diseases, such as Alzheimer's disease (AD) [<xref rid="B3" ref-type="bibr">3</xref>]. AD is a neurodegenerative cortical disorder that besides memory deficits also displays disturbances of posture and gait, which triggers more serious falls compared to nondemented elderly people. In that regard, diagnostic tools that allow an early and noninvasive detection of AD pathology are highly required.</p><p>To this end, many researchers have devoted their efforts to find appropriate data/features and have applied different machine-learning methods for computer-aided diagnosis of AD. Most of the works reported in the literature make use of Support Vector Machines (SVMs) and Artificial Neural Networks (ANNs), such as Multiple Layer Perceptrons (MLPs), Radial Basis Function Networks (RBNs), and Deep Belief Networks (DBNs). We provide a brief review next in this context.</p><p>SVMs are a particular type of supervised machine-learning method that classifies data points by maximizing the margin between classes in a high-dimensional space [<xref rid="B4" ref-type="bibr">4</xref>]. They are the most widely used classifiers and have shown promising results on problems of pattern recognition in neurology and psychiatry diseases [<xref rid="B5" ref-type="bibr">5</xref>], including detection of AD based on electrical brain activity Electroencephalography (EEG) [<xref rid="B6" ref-type="bibr">6</xref>], neuroimaging data from Magnetic Resonance Imaging (MRI), and Positron Emission Tomography (PET) brain images [<xref rid="B8" ref-type="bibr">7</xref>&#x02013;<xref rid="B11" ref-type="bibr">10</xref>]. Several works have applied MLPs in the diagnosis of AD, combining different variables such as demographic, neurological, and psychiatric evaluation, neuropsychological tests, and even more complex clinical diagnostic tools (e.g., neuropathology, EEG, and MRI/PET brain imaging), where hundreds of variables of recorded data are potentially clinically relevant on one single patient [<xref rid="B8" ref-type="bibr">7</xref>, <xref rid="B7" ref-type="bibr">11</xref>, <xref rid="B13" ref-type="bibr">12</xref>]. RBNs have successfully been applied to the discrimination of plasma signalling proteins for the prediction of this disease [<xref rid="B14" ref-type="bibr">13</xref>] and classification of MRI features of AD [<xref rid="B8" ref-type="bibr">7</xref>]. DBNs are a recent machine-learning model that is exhibiting performance records on classification accuracy also on medical fields such as AD, based on MRI/PET neuroimaging data [<xref rid="B15" ref-type="bibr">14</xref>, <xref rid="B16" ref-type="bibr">15</xref>].</p><p>The survey of the above literature shows that the majority of the studies have relied on neuroimaging data from MRI and/or PET images, which though widely available, are relatively expensive. In contrast, inertial measurement units (IMUs), with integrated accelerometers and gyroscopes, are inexpensive and small fully portable devices, opening a new field of research on AD. In fact, IMUs have been used to portrait different postural kinematic profiles in AD, including a higher risk of falling [<xref rid="B17" ref-type="bibr">16</xref>]. These devices are independent of inclination in space, having proved to be equivalent to force platforms in the evaluation of the center of mass (COM) kinematics. However, although hundreds of kinematic parameters have been used to represent postural body sway [<xref rid="B18" ref-type="bibr">17</xref>], which parameters provide the most relevant information about normal postural control and which kinematic parameters better identify neurodegenerative diseases such as AD are still yet undetermined. We advocate that a complementary tool that makes use of kinematic postural data for the diagnosis of AD would be extremely helpful and valuable for clinicians.</p><p>To the best of our knowledge, the use of machine-learning classifiers for the diagnosis of AD based on kinematic postural sway data has not yet been investigated. With this in mind, our study has two main goals. First, to validate the feasibility of the application of machine-learning models in the diagnosis of AD based on postural kinematic data, collected on different and increasingly difficult postural balance tasks. Second, to compare different classifier models&#x02014;SVM, MLP, RBN, and DBN&#x02014;with respect to their discriminative performance.</p><p>The remainder of the paper is structured as follows. In <xref ref-type="sec" rid="sec2">Section 2</xref> we explain the materials and methodology used for collecting the data, feature reduction, and implementation of the three dataset models, subsequently used for training, testing, and comparing the different classifiers models. <xref ref-type="sec" rid="sec3"> Section 3</xref> gives a brief description on how we implemented the classifiers' models. <xref ref-type="sec" rid="sec4"> Section 4</xref> presents results of performance for the different classifiers in the different dataset models. In <xref ref-type="sec" rid="sec5">Section 5</xref> a detailed discussion is made such that, in <xref ref-type="sec" rid="sec6">Section 6</xref>, some conclusions can be drawn about the potential use of the tested classifiers in future automatic diagnostic tools for AD based on kinematic postural sway data.</p></sec><sec id="sec2"><title>2. Materials and Methodology for Data Collection</title><sec id="sec2.1"><title>2.1. Study Population</title><p>The study population was recruited from our hospital outpatient neurology department. Patients with probable AD, according to Diagnostic and Statistical Manual of Mental Disorders- IV (DSM-IV) and National Institute of Neurological and Communicative Disorders and Stroke/Alzheimer's Disease and Related Disorders Association (NINCDS/ADRDA) criteria [<xref rid="B19" ref-type="bibr">18</xref>], on a stage of 1 on the Clinical Dementia Rating Scale, were consecutively recruited for the study. The control group included age-matched caregivers of patients that had no history of falls or of neurological or psychiatric disease. Patients or controls were excluded if there was a history of orthopedic, musculoskeletal, vestibular disorder, or alcohol abuse. Demographic, anthropometric, and MoCA data, normalized to the Portuguese population [<xref rid="B20" ref-type="bibr">19</xref>], were collected in both groups. Local hospital ethics committee approved the protocol of the study, submitted by ICVS/UM and Center Algoritmi/UM. Written consent was obtained from all subjects or their guardians.</p><p>We included 36 AD patients (24 females/12 males, with a mean age of 76 &#x000b1; 7 years) and 36 healthy controls (15 females/21 males, with a mean age of 70 &#x000b1; 8 years) (AD versus C, <italic>p</italic> = 0.003). Concerning demographic and anthropometric data, the two groups displayed the following: education (AD: 1 &#x000b1; 0.58; control: 2 &#x000b1; 1.19; <italic>p</italic> = 0.008); MoCA (AD: 11 &#x000b1; 5.10; control: 25 &#x000b1; 3.87; <italic>p</italic> &#x0003c; 0.001); weight (kg) (AD: 65.60 &#x000b1; 10.28; control: 75.24 &#x000b1; 12.11; <italic>p</italic> = 0.001); height (m) (AD: 1.54 &#x000b1; 0.08; control: 1.63 &#x000b1; 0.106; <italic>p</italic> &#x0003c; 0.001); body mass index (kg/m<sup>2</sup>) (AD: 27.58 &#x000b1; 4.12; control: 28.24 &#x000b1; 3.79; <italic>p</italic> = 0.44). These significant differences between the two groups justified the adjustment of the kinematic variables to age, education, height, and weight (please see below).</p></sec><sec id="sec2.2"><title>2.2. Kinematic Acquisition and Assessment System</title><p>Five kinetic sensing modules harboring 8051 microprocessor embedded in CC2530<italic> Texas Instrument</italic> SoC (System on Chip) [<xref rid="B21" ref-type="bibr">20</xref>] and an inertial measurement unit MPU6000 (triaxial accelerometer and gyroscope), operating with a sample rate frequency of 113&#x02009;Hz on SD card, were attached to five body segments: trunk (on the COM, located at 55% of a person's height [<xref rid="B22" ref-type="bibr">21</xref>]), both legs (middle of ankle-knee), and both thighs (middle of knee-iliac crest) by Velcro bands. One of the normal human mechanisms of maintaining balance is to vary the height of the COM. Therefore, final kinematic information derived from the IMU on the COM was constantly adjusted to the angle and length of the IMU located on the thigh and shank. A more detailed description of our methodology and mathematical formulas for kinematic acquisition procedure can be consulted at [<xref rid="B17" ref-type="bibr">16</xref>].</p></sec><sec id="sec2.3"><title>2.3. Clinical Postural Tasks</title><p>Subjects were instructed to perform seven different postural tasks with increasing stability stress: normal stance: standing with the medial aspects of the feet touching each other with eyes open (EO) and eyes closed (EC), and standing with the medial aspects of the feet touching each other with EO and EC on a ramp with 15 degrees' inclination in a backwards position (EOBP, ECBP) and frontwards position (EOFP, ECFP) [<xref rid="B23" ref-type="bibr">22</xref>]. A representation of a patient, wearing the safety trunk belt, with the IMU placed on the center of mass while performing the tasks mentioned, can be seen in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Tasks with kinematic capture were performed for 30 seconds [<xref rid="B24" ref-type="bibr">23</xref>], with subjects standing quiet, their arms hanging at their sides, and their head in a normal forward-looking position to a visual eye target height approximately 2 meters away. Balance is a complex process of coordination of multiple body systems&#x02014;including the vestibular, auditory, visual, motor, and higher level premotor systems&#x02014;that generates appropriate synergic postural muscle movements of the head, eye, trunk, and limbs to maintain posture [<xref rid="B25" ref-type="bibr">24</xref>]. This is achieved by sustaining, achieving, or restoring the body COM relative to the base of support or, more generally, within the limits of stability with minimal sway [<xref rid="B26" ref-type="bibr">25</xref>]. Visual suppression makes the human body more dependent on vestibular and proprioceptive systems, consequently increasing sway [<xref rid="B27" ref-type="bibr">26</xref>]. On an inclined or tilting support surface, postural control is mainly achieved with the help of visual, vestibular, and proprioceptive afferents. The investigation of postural stability under dynamic conditions, either continuous or predictable perturbations of the supporting platform, has been used to study anticipatory adjustments and sensory feedback [<xref rid="B25" ref-type="bibr">24</xref>]. This was the rationale in our study to use different and increasing difficulty postural stability tasks, changing kinematic variables, in order to obtain more information for machine-learning analysis and discrimination between patients and healthy subjects.</p></sec><sec id="sec2.4"><title>2.4. Kinematic Collected Variables</title><p>We focused on demographic and biometric data (age, weight, height, and body mass index) and kinematic parameters (extracted from the IMU placed at the COM) that emerged from a systematic review as predictors of falls among older people and AD patients [<xref rid="B27" ref-type="bibr">26</xref>&#x02013;<xref rid="B31" ref-type="bibr">30</xref>]. Kinematic parameters are as follows: total displacement on the transverse plane (cm); maximal displacement (cm) with respect to the origin; mean distance (cm) with respect to origin on transverse plane; dispersion radius (average distances relative to average point); maximal and mean linear velocity (cm/s); positioning (cm) on <italic>x</italic>-axis (maximal, mean, and range) and <italic>y</italic>-axis (maximal, mean, and range); roll angle (degrees) (maximal, minimum, and mean); and pitch angle (degrees) (maximal, minimum and mean). These 18 kinematic measurements, captured on each task, were further averaged summarizing the patient's behavior throughout the seven different postural tasks. The overlap between the different kinematic postural features between the two groups and the different tasks can be seen in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></sec><sec id="sec2.5"><title>2.5. Feature Extraction and Statistical Significance</title><p>There is still little information about the value of each singular kinematic variable, and even less information exists on how these variables interact among themselves during postural balance. During data collection on the different postural tasks, there is substantial overlap of kinematic information, even if we only consider one particular variable, like displacement on the <italic>x</italic> and <italic>y</italic>-axis (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Therefore, the objective of the feature extraction process is to assess which of the kinematic variables are statistically significant features that contribute to an accurate classification of AD patients.</p><p>As in [<xref rid="B32" ref-type="bibr">31</xref>], all kinematic variables were adjusted for age, education, height, and weight (as these were found to be significant factors, with a significance value of 0.05, using the Mann&#x02013;Whitney<italic> U</italic> test and Chi-Square test):<disp-formula id="EEq1"><label>(1)</label><mml:math id="M1"><mml:mtable style="T2"><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:msub><mml:malignmark/><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>ua</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mtext>age</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>sAge</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>mAge</mml:mtext></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="4.19899pt"/></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/><mml:mspace width="11.436553955078125pt"/><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mtext>wght</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>sWght</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>mWght</mml:mtext></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="4.19899pt"/></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/><mml:mspace width="11.436553955078125pt"/><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mtext>hght</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>sHght</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>mHght</mml:mtext></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mspace width="11.436553955078125pt"/><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mtext>Edu</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="2.46999pt"/><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>sEdu</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mtext>mEdu</mml:mtext></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="2.46999pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>K</italic>
<sub>a</sub> is the adjusted kinematic feature; <italic>K</italic>
<sub>ua</sub> is the unadjusted kinematic feature; <italic>K</italic>
<sub>sAge</sub>,&#x02009;&#x02009;<italic>K</italic>
<sub>sWght</sub>,&#x02009;&#x02009;<italic>K</italic>
<sub>sHght</sub>, and <italic>K</italic>
<sub>sEdu</sub> are the subject's age, weight, height, and years of education, respectively; <italic>K</italic>
<sub>mAge</sub>, <italic>K</italic>
<sub>mWght</sub>, <italic>K</italic>
<sub>mHght</sub> and <italic>K</italic>
<sub>mEdu</sub> are the corresponding means for all subjects. The gradients <italic>G</italic>
<sub>age</sub>, <italic>G</italic>
<sub>wght</sub>, <italic>G</italic>
<sub>hght</sub>, and <italic>G</italic>
<sub>Edu</sub> are the slopes of a region specific regression line against subject age, weight, height, and education of all participants. This process of adjustment guarantees that the regression is not influenced by the classification of each variable in particular.</p><p>Data is then preprocessed by a min&#x02013;max normalization method (see, e.g., [<xref rid="B33" ref-type="bibr">32</xref>]):<disp-formula id="EEq2"><label>(2)</label><mml:math id="M2"><mml:mtable style="T2"><mml:mtr><mml:mtd><mml:maligngroup/><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02032;</mml:mi></mml:mrow></mml:msup><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mi>&#x02217;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mtext>new</mml:mtext><mml:mo>_</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mtext>new</mml:mtext><mml:mo>_</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/><mml:mspace width="11.436553955078125pt"/><mml:mo>+</mml:mo><mml:mtext>new</mml:mtext><mml:mo>_</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="2.59pt"/><mml:mi>g</mml:mi><mml:mspace height="4.53pt" depth="2.59pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>&#x02061;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>and that, in our case, transformed data into a range of values between &#x02212;1 and 1. Thus, new_max&#x02061;(<italic>g</italic>) and new_min&#x02061;(<italic>g</italic>)&#x02061; were set to 1 and &#x02212;1, respectively, and max&#x02061;(<italic>g</italic>) and min&#x02061;(<italic>g</italic>)&#x02061; are the maximum and minimum values of the attribute, respectively. Afterwards, a nonparametric statistical analysis (Mann&#x02013;Whitney<italic> U</italic> test) is implemented to determine the rank and significance, of each variable, in the classification outcome of the two groups, following one branch considering solely the 18 kinematic variables, and the second branch including the MoCA score as to form a 19-variable vector for each subject.</p></sec><sec id="sec2.6"><title>2.6. Variable Selection Using Error Incremental Analysis</title><p>As per [<xref rid="B11" ref-type="bibr">10</xref>], the ranking of the statistically significant variables provides an insight on the discriminative power of each variable for each classifier. Selecting the optimal number of top-ranked variables can be considered a dimensionality reduction problem which is performed using error incremental analysis: starting from the top-ranked variable and incrementally adding the next best ranked variable until all significant variables are included. The methodology followed in this study is presented in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></sec></sec><sec id="sec3"><title>3. Machine-Learning Classifiers</title><p>The selection of the best classifier for diagnosis is an open problem. In addition, the advantage of using multiple classification models over a single model has been suggested [<xref rid="B33" ref-type="bibr">32</xref>]. Hence, we compare four different classifier models: SVM, MLP, RBN, and DBN. With the purpose of facilitating and streamlining the work, we developed a custom-made software application on MATLAB&#x000ae; (version R2014a), which implements an automatic grid-search (i.e., automatically and systematically tests different configurations and performance of the different machine-learning models).</p><p>All the experiments were based on a threefold cross validation, meaning that the subjects were divided into three sets: training (50%), test (40%), and validation (10%) [<xref rid="B34" ref-type="bibr">33</xref>]. To limit the potential data partitioning error induced by random data assignment and cross validation, the same experiment was repeated 50 times and the average performance was recorded. We opted for an output layer composed of two neurons, one representing AD patients and the other healthy/control subjects, as this model would better replicate clinical practice.</p><sec id="sec3.1"><title>3.1. Support Vector Machines (SVMs)</title><p>The learning mechanism of a SVM considers distinct classes of examples as being divided by geometrical surfaces, separating hyperplanes, whose optimal behavior is determined by an extension of the method of Lagrange multipliers. The support vector classifier chooses the classifier that separates the classes with maximal margin [<xref rid="B35" ref-type="bibr">34</xref>]. Our implementation of SVM follows the MATLAB Documentation and [<xref rid="B36" ref-type="bibr">35</xref>].</p><p>We provide a brief description, but for more detailed information refer to the respective references.</p><p>Let us assume that the dataset is of the form<disp-formula id="EEq3"><label>(3)</label><mml:math id="M3"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.53pt" depth="2.484pt"/></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <bold>x</bold>
<sub><italic>k</italic></sub> &#x02208; <italic>&#x0211d;</italic>
<sup><italic>m</italic></sup> is the <italic>k</italic>th input vector of dimension <italic>m</italic> and <italic>o</italic>
<sub><italic>k</italic></sub> is the corresponding binary category, <italic>o</italic>
<sub><italic>k</italic></sub> &#x02208; {&#x02212;1,1}.</p><p>The equation that defines the hyperplane is<disp-formula id="EEq4"><label>(4)</label><mml:math id="M4"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="2.484pt"/><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <bold>v</bold> &#x02208; <italic>&#x0211d;</italic>
<sup><italic>m</italic></sup> is the vector normal to the hyperplane, &#x02329;&#x000b7;&#x0232a; represents the inner product, and<italic> b</italic>, a real number, is the bias.</p><p>In order to define the best separating hyperplane one needs to find <bold>v</bold> and <italic>b</italic> that minimize &#x02016;<bold>v</bold>&#x02016; subject to<disp-formula id="EEq5"><label>(5)</label><mml:math id="M5"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="8.07999pt" depth="2.98001pt"/><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="2.484pt"/><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace height="8.07999pt" depth="2.98001pt"/></mml:mrow></mml:mfenced><mml:mo>&#x02265;</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>In order to simplify the math, the problem is usually given as the equivalent of minimizing &#x02329;<italic>v</italic>, <bold>v</bold>&#x0232a;/2.</p><p>Once the optimal <bold>v</bold> and <italic>b</italic> are found, one can classify a given vector, <bold>z</bold>, as follows:<disp-formula id="EEq6"><label>(6)</label><mml:math id="M6"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.59pt" depth="1.16998pt"/><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">z</mml:mi><mml:mspace height="4.59pt" depth="1.16998pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>y</italic>
<sub><italic>z</italic></sub> is the binary category in which <bold>z</bold> is inserted. This is considered to be the primal form of the classification problem.</p><p>In order to attain the dual form of the classification problem, one needs to take the Lagrange multipliers, <italic>&#x003b1;</italic>
<sub><italic>k</italic></sub>, multiplied by each constraint and subtract from the objective function:<disp-formula id="EEq7"><label>(7)</label><mml:math id="M7"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfrac><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="1.16998pt"/><mml:mi mathvariant="bold">v</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mspace height="4.29pt" depth="1.16998pt"/></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="8.07999pt" depth="2.98001pt"/><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="8.07999pt" depth="2.98001pt"/><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="2.484pt"/><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace height="8.07999pt" depth="2.98001pt"/></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mspace height="8.07999pt" depth="2.98001pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>N</italic> is the size of the training data.</p><p>The first-order optimal conditions of the primal problem are obtained by taking partial derivatives of <italic>L</italic>
<sub><italic>p</italic></sub> with respect to the primal variables and then setting them to zero:<disp-formula id="EEq8"><label>(8)</label><mml:math id="M8"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn><mml:mo>&#x027f6;</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>The dual form of the classification problem is obtained as follows:<disp-formula id="EEq9"><label>(9)</label><mml:math id="M9"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>&#x02009;</mml:mi><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>subject to constraints<disp-formula id="EEq10"><label>(10)</label><mml:math id="M10"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="10pt"/><mml:mn mathvariant="normal">0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>c</italic> is considered a constraint value that keeps the allowable values of the Lagrange multipliers, <italic>&#x003b1;</italic>
<sub><italic>k</italic></sub>, in a bounded region.</p><p>Some classification problems cannot be solved with the linear methods explained above because they do not have a simple hyperplane as a separating criterion. For those problems, one needs to use a nonlinear transformation, and that is achievable through the use of kernels [<xref rid="B35" ref-type="bibr">34</xref>].</p><p>Assuming <italic>F</italic> is a high-dimensional feature space and <italic>&#x003c6;</italic> is a function that maps <bold>x</bold>
<sub><italic>k</italic></sub> to <italic>F</italic>, the kernel has the following form:<disp-formula id="EEq11"><label>(11)</label><mml:math id="M11"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="9.52998pt" depth="4.43001pt"/><mml:mi>&#x003c6;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>&#x003c6;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mspace height="9.52998pt" depth="4.43001pt"/></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>In our implementation we used the Gaussian kernel function defined as follows:<disp-formula id="EEq12"><label>(12)</label><mml:math id="M12"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mspace height="9.52998pt" depth="4.43001pt"/><mml:mi>&#x003c6;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mi>&#x003c6;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mspace height="9.52998pt" depth="4.43001pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mrow><mml:mfenced open="&#x02329;" close="&#x0232a;" separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>&#x003c3;</italic> is a positive number.</p><p>Applying the kernel to the dual form of the classification problem, one obtains<disp-formula id="EEq13"><label>(13)</label><mml:math id="M13"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>&#x02009;</mml:mi><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mi>K</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold">,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.29pt" depth="4.19899pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>subject to constraints<disp-formula id="EEq14"><label>(14)</label><mml:math id="M14"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="10pt"/><mml:mn mathvariant="normal">0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></sec><sec id="sec3.2"><title>3.2. Multiple Layer Perceptrons (MLPs)</title><p>We have previously detailed our MLP model [<xref rid="B37" ref-type="bibr">36</xref>], where computation of the output of neuron <italic>y</italic>
<sub><italic>j</italic></sub> was based on the following:<disp-formula id="EEq15"><label>(15)</label><mml:math id="M15"><mml:mtable style="T17"><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:malignmark/><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="16.99994pt" depth="11.644pt"/><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>n</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>n</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mspace height="16.99994pt" depth="11.644pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>y</italic>
<sub><italic>i</italic></sub>
<sup>(<italic>l</italic> &#x02212; 1)</sup>(<italic>n</italic>) is the output of neuron <italic>i</italic> in the previous layer <italic>l</italic> &#x02212; 1 at iteration <italic>n</italic> and <italic>w</italic>
<sub><italic>ji</italic></sub>
<sup>(<italic>l</italic>)</sup> is the synaptic weight from neuron <italic>i</italic> in layer <italic>l</italic> &#x02212; 1 to neuron <italic>j</italic> in layer <italic>l</italic>. The synaptic weight <italic>w</italic>
<sub><italic>j</italic>0</sub>
<sup>(<italic>l</italic>)</sup> equals the bias, <italic>b</italic>
<sub><italic>j</italic></sub>, applied to neuron <italic>j</italic> [<xref rid="B35" ref-type="bibr">34</xref>]. We used a sigmoidal logistic activation function, <italic>g</italic>(<italic>v</italic>
<sub><italic>j</italic></sub>), to represent the nonlinear behavior between the inputs and outputs, where <italic>v</italic>
<sub><italic>j</italic></sub> is the net internal activity level of neuron <italic>j</italic> (i.e., the weighted sum of all synaptic inputs plus bias).</p><p>We used MLP backpropagation (MLP-BP) and MLP Scaled Conjugate Gradient (MLP-SCG) training algorithms [<xref rid="B36" ref-type="bibr">35</xref>]. Our custom-made software application automatically created, trained, and tested different configurations of MLPs, according to number of hidden layers and number of neurons in each hidden layer and best performance. The application begins testing the ANN with the minimum number of neurons chosen for the first hidden layer (1st hidden layer), incrementing until it reaches the maximum number of neurons (100). When this happens, a second hidden layer (2nd hidden layer) is included, first with one neuron, and a first hidden layer is set to its initial setup incrementing once again till best performance is rendered. This autonomous process is cyclically repeated with a hypothetical maximum number of neurons of 100 on 1st hidden layer and 100 on 2nd hidden layer. On each training cycle, the performance of each neural network is evaluated and stored. The autonomous creation of networks, MLP-BP or MLP-SCG, was tried with different error functions (<italic>Mean Absolute Error</italic> (MAE),<italic> Mean Squared Error</italic> (MSE),<italic> Sum Absolute Error</italic> (SAE), and<italic> Sum-Squared Error</italic> (SSE)), until best performance was reached. In the training process, the best performance is measured by two parameters that control the terminus of the training: the number of error checks and the error gradient. The latter is associated with the training performance: the lower its value, the better the training performance; and the first is incremented each time the error value in the validation set rises. These parameters were defined through an initial test with a limited number of neurons in each layer where the performance was evaluated with different gradient and error check values.</p></sec><sec id="sec3.3"><title>3.3. Radial Basis Function Neural Networks (RBNs)</title><p>RBNs are a subtype of an artificial neural network that uses radial basis functions as activation functions [<xref rid="B38" ref-type="bibr">37</xref>]. They consist of three layers: an input layer, a hidden radial basis neuron layer, and a linear neuron output layer. The output units implement a weighted sum of hidden-unit outputs. In RBNs, the transformation from the input space to the hidden-unit space is nonlinear whereas the transformation from the hidden-unit space to the output space is linear. When an input vector <bold>x</bold> is presented to such a network, each neuron's output in the hidden layer is defined by<disp-formula id="EEq17"><label>(16)</label><mml:math id="M16"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>&#x003c6;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="0.0pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mspace height="4.29pt" depth="0.0pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfenced open="&#x02016;" close="&#x02016;" separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn mathvariant="normal">2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <bold>c</bold>
<sub><italic>i</italic></sub> = [<italic>c</italic>
<sub><italic>i</italic>1</sub>, <italic>c</italic>
<sub><italic>i</italic>2</sub>,&#x02026;,<italic>c</italic>
<sub><italic>im</italic></sub>]&#x02009;&#x02009;<sup><italic>T</italic></sup> &#x02208; <italic>&#x0211d;</italic>
<sup><italic>m</italic></sup> is the center vector of neuron <italic>i</italic> and <italic>&#x003c3;</italic>
<sub><italic>i</italic></sub> is the width of the <italic>i</italic>th node. The response of each neuron in the output layer is computed according to<disp-formula id="EEq18"><label>(17)</label><mml:math id="M17"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>&#x003c6;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.29pt" depth="0.0pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mspace height="4.29pt" depth="0.0pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="10pt"/><mml:mtext>with&#x02009;&#x02009;</mml:mtext><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1,2</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>w</italic>
<sub><italic>ij</italic></sub> represents the synaptic weight between neuron <italic>i</italic> in the hidden layer and neuron <italic>j</italic> in the output layer and <italic>b</italic>
<sub><italic>j</italic></sub> represents the bias applied to the output neuron <italic>j</italic>. For more details, refer to the relevant MATLAB Documentation.</p><p>In the training process, in each iteration, two parameters were changed: the Sum-Squared Error goal and the spread value (or neuron radius) until a designated maximum value is achieved (the error goal from 1<italic>e</italic> &#x02212; 8 to 1 and the spread value from 0.01 to 10).</p></sec><sec id="sec3.4"><title>3.4. Deep Belief Networks (DBNs)</title><p>A DBN is a generative graphical model with many layers of hidden causal variables along with a greedy layer-wise unsupervised learning algorithm. These networks are built in two separate stages. In the first stage, the DBN is formed by a number of layers of Restricted Boltzmann Machines (RBMs), which are trained in a greedy layer-wise fashion. In order to use the DBN for classification, the second stage uses the synaptic weights obtained in the RBM stage to train the whole model, in a supervised way, as a feed-forward-backpropagation neural network. For the implementation of DBNs, we used a MATLAB Toolbox developed by Palm [<xref rid="B39" ref-type="bibr">38</xref>].</p><p>RBMs have binary-valued hidden and visible units. If one defines the visible input layer as <bold>x</bold>, the hidden layer as <bold>h</bold>, and weights between them as <bold>W</bold>, the model that defines the probability distribution according to [<xref rid="B40" ref-type="bibr">39</xref>] is<disp-formula id="EEq19"><label>(18)</label><mml:math id="M18"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.01999pt" depth="1.16998pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mspace height="7.01999pt" depth="1.16998pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>Z</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>Z</italic>(<bold>x</bold>, <bold>h</bold>) is a partition function given by summing over all possible pairs of visible and hidden vectors:<disp-formula id="EEq20"><label>(19)</label><mml:math id="M19"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>Z</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.01999pt" depth="1.16998pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mspace height="7.01999pt" depth="1.16998pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>
<italic>E</italic>(<bold>x</bold>, <bold>h</bold>) is the energy function, analogous to the one used on a Hopfield network [<xref rid="B41" ref-type="bibr">40</xref>], defined as<disp-formula id="EEq21"><label>(20)</label><mml:math id="M20"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.01999pt" depth="1.16998pt"/><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">h</mml:mi><mml:mspace height="7.01999pt" depth="1.16998pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mtext>visible</mml:mtext></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mtext>hidden</mml:mtext></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>x</italic>
<sub><italic>i</italic></sub> and <italic>h</italic>
<sub><italic>j</italic></sub> are the binary states of visible unit <italic>i</italic> and hidden unit <italic>j</italic> and <italic>b</italic>
<sub><italic>i</italic></sub>
<sup>(1)</sup> and <italic>b</italic>
<sub><italic>j</italic></sub>
<sup>(2)</sup> are the bias values of the visible and hidden layer units, respectively.</p><p>Taking into account (<xref ref-type="disp-formula" rid="EEq19">18</xref>) and given that there are no direct connections between hidden units in a RBM, the probability of a single neuron state in the hidden layer, <italic>h</italic>
<sub><italic>j</italic></sub>, to be set to one, given the visible vector <bold>x</bold>, can be defined as<disp-formula id="EEq22"><label>(21)</label><mml:math id="M21"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.08pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mrow><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo></mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mspace height="7.08pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>In the same way, one can infer the probability of a single neuron, <italic>x</italic>
<sub><italic>i</italic></sub>, in the visible layer, binary state being set to one given the hidden vector <bold>h</bold>:<disp-formula id="EEq23"><label>(22)</label><mml:math id="M22"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.08pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mrow><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo></mml:mrow><mml:mi mathvariant="bold">h</mml:mi><mml:mspace height="7.08pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>In the training process the goal is to maximize the log probability of the training data or minimize the negative log probability of the training data.</p><p>Palm's algorithm [<xref rid="B39" ref-type="bibr">38</xref>], instead of initializing the model at some arbitrary state and iterating it <italic>n</italic> times, initializes it with contrastive divergence algorithm introduced in [<xref rid="B40" ref-type="bibr">39</xref>]. For computational efficiency reasons, this training algorithm uses stochastic gradient descent instead of a batch update rule. The Restricted Boltzmann Machines (RBM) learning algorithm, as defined in [<xref rid="B39" ref-type="bibr">38</xref>], can be seen as follows (see [<xref rid="B40" ref-type="bibr">39</xref>]):<list list-type="simple"><list-item><p>for all training samples as <italic>t</italic> do</p></list-item><list-item><p>
<italic>x</italic>
<sup>(0)</sup> &#x02190; <italic>t</italic>
</p></list-item><list-item><p>
<italic>h</italic>
<sup>(0)</sup> &#x02190; sigm&#x02061;(<italic>x</italic>
<sup>(0)</sup>
<italic>W</italic> + <italic>c</italic>) &#x0003e; rand()</p></list-item><list-item><p>
<italic>x</italic>
<sup>(1)</sup> &#x02190; sigm&#x02061;(<italic>h</italic>
<sup>(0)</sup>
<italic>W</italic> + <italic>B</italic>) &#x0003e; rand()</p></list-item><list-item><p>
<italic>h</italic>
<sup>(1)</sup> &#x02190; sigm&#x02061;(<italic>x</italic>
<sup>(1)</sup>
<italic>W</italic> + <italic>c</italic>) &#x0003e; rand()</p></list-item><list-item><p>
<italic>W</italic> &#x02190; <italic>W</italic> + <italic>&#x003b1;</italic>&#x02009;sigm&#x02061;(<italic>x</italic>
<sup>(0)</sup>
<italic>h</italic>
<sup>(0)</sup> &#x02212; <italic>x</italic>
<sup>(1)</sup>
<italic>h</italic>
<sup>(1)</sup>)</p></list-item><list-item><p>
<italic>b</italic> &#x02190; <italic>b</italic> + <italic>&#x003b1;</italic>(<italic>x</italic>
<sup>(0)</sup> &#x02212; <italic>x</italic>
<sup>(1)</sup>)</p></list-item><list-item><p>
<italic>c</italic> &#x02190; <italic>c</italic> + <italic>&#x003b1;</italic>(<italic>h</italic>
<sup>(0)</sup> &#x02212; <italic>h</italic>
<sup>(1)</sup>)</p></list-item><list-item><p>end for</p></list-item></list>where <italic>&#x003b1;</italic> is a learning rate and rand() produces random uniform numbers between 0 and 1.</p><p>Our algorithm, which uses the implementation above, trains several DBNs consecutively, varying the number of hidden neurons of the RBM and of the feed-forward neural network to a maximum of 100 hidden neurons in each of the two layers. Each RBM is trained in a layer-wise greedy manner with a learning rate of 1 for the duration of 100 epochs. After this training, the synaptic weights are subsequently used to initialize and train a backpropagation feed-forward neural network with optimal tangency activation function (<xref ref-type="disp-formula" rid="EEq11">11</xref>) for the hidden layers and sigmoid logistic activation function (<xref ref-type="disp-formula" rid="EEq12">12</xref>) for the output layer:<disp-formula id="EEq24"><label>(23)</label><mml:math id="M23"><mml:mtable style="T17"><mml:mtr><mml:mtd><mml:maligngroup/><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="2.484pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="EEq25"><label>(24)</label><mml:math id="EEq25EAAANABDCA"><mml:mtable><mml:mtr><mml:mtd><mml:maligngroup/><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.42pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.42pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>v</italic>
<sub><italic>i</italic></sub>, in (<xref ref-type="disp-formula" rid="EEq24">23</xref>), is the weighted sum of all synaptic inputs of neuron <italic>i</italic> plus its bias and <italic>v</italic>
<sub><italic>j</italic></sub> is the weighted sum of all synaptic inputs of the output neuron <italic>j</italic> plus its bias. In each training cycle the performance of each network is evaluated and stored.</p></sec><sec id="sec3.5"><title>3.5. Quantitative Measurements for Performance Evaluation</title><p>To evaluate the performance of the different classifiers we calculated accuracy, sensitivity, and specificity. A true positive (TP) was considered when the classifier output agreed with the clinical diagnosis of AD. A true negative (TN) was considered when the classifier output correctly excluded AD. Meanwhile, a false positive (FP) indicated that the classifier output incorrectly classified a healthy person with AD. The last case was a false negative (FN) when the classifier output missed AD and incorrectly classified an AD patient as a healthy person. Classification accuracy is calculated as follows:<disp-formula id="EEq26"><label>(25)</label><mml:math id="M24"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mtext>Accuracy</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>TN</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TCT</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where TCT( = TP + TN + FP + FN) is the total number of classification tests.</p><p>Sensitivity (true positive rate) and specificity (true negative rate) are calculated as follows:<disp-formula id="EEq27"><label>(26)</label><mml:math id="M25"><mml:mtable style="T17"><mml:mtr><mml:mtd><mml:maligngroup/><mml:mtext>Sensitivity</mml:mtext><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:mtext>Specificity</mml:mtext><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TN</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></sec></sec><sec id="sec4"><title>4. Results</title><p>In this work, classifiers' performance is evaluated using the quantitative measures presented in <xref ref-type="sec" rid="sec3.5">Section 3.5</xref>.</p><sec id="sec4.1"><title>4.1. Rank of Variables</title><p>Based on the methodology described in <xref ref-type="sec" rid="sec2.6">Section 2.6</xref>, variables found with significance level below 0.05 are ranked as shown in <xref ref-type="table" rid="tab1">Table 1</xref>. In this step only the training data was used to assert the statistical significance of each feature. A box-plot is presented in <xref ref-type="fig" rid="fig4">Figure 4</xref> in order to show that even when data was normalized and adjusted for biometric data, with the exception of MoCA score, there is substantial overlap. This highlights the challenge for disease classification based on machine learning. In order to evaluate the rank reliability of the features, which might be dependent on the dataset size, a test was conducted by randomly reducing the dataset to 80% and 50% of its original size. The rank of variables was then conducted in 100 random repetitions and the ranks were summed and averaged to get the rank expectation. The final rank was calculated by sorting the rank expectation of all features from low to high and the top three variables were recorded and shown in <xref ref-type="table" rid="tab2">Table 2</xref>, demonstrating that the rank does not change even when the dataset size is reduced 80% and 50%. This is a good indication that the set of variables found and used in this study is reliable, reproducible, and statistically meaningful even under a smaller subset of the data.</p></sec><sec id="sec4.2"><title>4.2. Error Incremental Analysis Results</title><p>The objective of the incremental error analysis is to determine the number of top-ranked variables one should use in order to produce the best classification results. As in [<xref rid="B11" ref-type="bibr">10</xref>], the classification of AD was performed starting from the top-ranked variable and incrementally adding the next best ranked variable until all significant variables were included. The results are depicted in <xref ref-type="fig" rid="fig5">Figure 5</xref>. In this step the test dataset was used to estimate the accuracy values. As one can observe, all the classifiers benefited from the addition of kinematic variables, having increasingly higher accuracy values until the maximum accuracy values were achieved. These values are displayed in <xref ref-type="table" rid="tab3">Table 3</xref>. Figures <xref ref-type="fig" rid="fig6">6</xref> and <xref ref-type="fig" rid="fig7">7</xref> allow inferring that AD and CN groups are generally separable as they tend to form two distinct clusters.</p></sec><sec id="sec4.3"><title>4.3. General Classification Performance</title><p>Overall, MLP achieved the highest scores with accuracy ranging from 86.1%, without MoCA, to 96.6% when kinematic postural variables were combined with MoCA. When trained with datasets combining the MoCA variable and kinematic variables, all machine-learning models showed a good classification performance, with superiority for MLP (achieving accuracy of 96.6%), followed by DBN (accuracy of 96.5%), RBN (accuracy of 92.5%), and SVM classifiers (accuracy of 91%). MLP also achieved higher sensitivity, which is also beneficial reducing the cost of misdiagnosing an AD patient as a healthy subject [<xref rid="B42" ref-type="bibr">41</xref>, <xref rid="B43" ref-type="bibr">42</xref>]. MLP was also less susceptible to the different training iterations presenting lower standard deviation when compared to the other classifiers. Withdrawing the MoCA variable, the machine-learning classifiers also displayed a reasonably good accuracy, with results above 71%, with MLP achieving an 86.1% of accuracy rating. These results were followed by the DBN classifier with 78% accuracy rating the RBN model with 74% accuracy and lastly the SVM model achieving 71.7% accuracy rating.</p></sec></sec><sec id="sec5"><title>5. Discussion</title><p>Postural control and sensory organization are known to be critical for moving safely and adapting to the environment. The investigation of postural stability under dynamic conditions, either continuous or on predictable perturbations of the supporting platform, has been used to study the complexity of balance process, which coordinates visual, vestibular, proprioceptive, auditory, and motor systems information [<xref rid="B25" ref-type="bibr">24</xref>, <xref rid="B28" ref-type="bibr">27</xref>]. Visual suppression makes the human body more dependent on vestibular and proprioceptive systems, consequently increasing postural sway [27. Moreover, there is growing evidence that executive function and attention have an important role in the control of balance during standing and walking, as other higher cognitive processing shares brain resources with postural control [<xref rid="B45" ref-type="bibr">43</xref>]. Thereby, individuals who have limited cognitive processing due to neurological impairments, such as in AD, when using more of their available cognitive resources on postural control, may inadvertently increase their susceptibility to falls [<xref rid="B46" ref-type="bibr">44</xref>].</p><p>Having the above in context, it is not surprising that hundreds of kinematic parameters can be extracted from the IMU and each parameter can individually or in correlation represent postural body sway. While the discriminatory role of each kinematic postural variable per se is not clear, the rationale in our study was to use different and increasing difficulty balance tasks (manipulating vision and inclination), so as to increase discriminative kinematic information.</p><p>In our study we have shown that there is high intercorrelation between the different proposed kinematic variables, and even when data was normalized and adjusted for biometric characteristics, there is substantial overlap between healthy subjects and AD patients (Figures <xref ref-type="fig" rid="fig2">2</xref> and <xref ref-type="fig" rid="fig4">4</xref>), which highlighted the challenge and added value on using machine-learning classifiers. As the problem being handled in this study is a classification problem, three important questions have arisen, the sample size, the number of variables per patient, and which variables compose the ideal dataset that yields the best accuracy. A small size sample has been proved to limit the performance of machine-learning accuracy [<xref rid="B47" ref-type="bibr">45</xref>, <xref rid="B48" ref-type="bibr">46</xref>]. Also, too many variables relative to the number of patients potentially leads to overfitting, a consequence of the classifier learning with the data instead of learning the trend that underlies the data [<xref rid="B49" ref-type="bibr">47</xref>]. As a rule of thumb, more than 10 &#x0201c;events&#x0201d; are needed for each attribute to result in a classifier with reasonable predictive value [<xref rid="B50" ref-type="bibr">48</xref>]. Ideally, similar numbers of &#x0201c;healthy&#x0201d; and &#x0201c;unhealthy&#x0201d; subjects would be used in a training set, resulting in a training set that is more than 20 times the number of attributes. Since most medical studies typically involve a small number of subjects and there are essentially unlimited numbers of parameters that can be used, the possibility of overfitting has to be acquainted [<xref rid="B51" ref-type="bibr">49</xref>]. On one neuroimaging study, with a relatively small sample, 14 AD patients versus 20 healthy subjects, SVM reached a discriminating power of 88.2% [<xref rid="B52" ref-type="bibr">50</xref>]. In another study a combined approach of a genetic algorithm with ANN on EEG and neuropsychological examination of 43 AD patients versus 5 healthy subjects returned an accuracy of 85% [<xref rid="B53" ref-type="bibr">51</xref>].</p><p>Feature reduction can be a viable solution to tackle this problem. Besides speeding up the process of classification, it also reduces the required sizes of the training sets, therefore avoiding overfitting. Moreover, it is a way to avoid the so-called curse of dimensionality, which is the difficulty for the classifiers to learn effective models in spaces of high-dimensionality (many features) when the number of samples is limited. High dimensionality leads to overparameterization (the complexity is too high to identify all the coefficients of the model) or to poor performance of the classifiers [<xref rid="B54" ref-type="bibr">52</xref>]. Feature reduction can be accomplished by combining linear with nonlinear statistical analyses and/or by reducing the number of attributes. In this regard, it may contribute to simplifying the medical interpretation of the machine-learning process, by directing attention to practical clinically relevant attributes. However, choosing attributes in this retrospective manner introduces a post hoc subjective element into analyses [<xref rid="B55" ref-type="bibr">53</xref>]. Previous works have shown that feature reduction/selection methods have a positive effect on the classifiers' performance [<xref rid="B11" ref-type="bibr">10</xref>, <xref rid="B56" ref-type="bibr">54</xref>&#x02013;<xref rid="B59" ref-type="bibr">57</xref>].</p><p>Using the error incremental analysis method one was able to determine the optimal decisional space in which the classification of AD versus controls is carried out. By testing the variable's ranks with reduced datasets (80% and 50%) one verified that the rank of the top variables did not change, indicating that the combination of features suggested in this study is reliable and statistically relevant. As also indicated in [<xref rid="B11" ref-type="bibr">10</xref>], it can be argued that incremental error analysis does not cover all the possible combinations of features. Assessing all the combinations of variables, besides being exhausting and extremely time-consuming, is unnecessary due to the ranking of variables done in the beginning of the study.</p><p>Several biomarkers, such as demographic, neuropsychological assessment, MRI imaging, and genetic and fluid biomarkers, have been used in the diagnosis of AD [<xref rid="B60" ref-type="bibr">58</xref>]. Even though neuroimaging biomarkers, such as normalized hippocampus volume, have reached high accuracy rates in the diagnosis of AD, they are a structural anatomical evaluation of the brain and not its function. Patients with higher cognitive reserve, due to education and occupational attainment, can compensate their deficits and be more resilient to structural pathological brain changes [<xref rid="B61" ref-type="bibr">59</xref>]. As such, neuropsychological test, a functional cognitive assessment, can outperform MRI imaging, in the diagnosis of AD or even in the differential diagnosis with other dementias [<xref rid="B62" ref-type="bibr">60</xref>]. In our study, in general, all classifiers&#x02014;SVM, MLP, RBN, and DBN&#x02014;have presented very satisfying results: MLP classifier model had the highest performances, being more consistent between the different training iterations. As expected, adding MoCA scores yielded higher accuracy rates, with above 90% accuracy rates for all classifiers. As the diagnosis of AD is supported on cognitive evaluation, including the MoCA evaluation score into the dimensional space has to be considered with caution, as it can result in biased accuracy estimates. Nevertheless, relying solely on kinematic data, we achieved performance rates ranging from 71.7 to 86.1%. Interestingly, our results are in contrast to other studies where the combination of biomarkers, MRI imaging and neuropsychological assessment, had a detrimental effect of classification accuracy rates, probably as a consequence of redundancy between these variables that represent the same dysfunction [<xref rid="B62" ref-type="bibr">60</xref>]. Even though further studies are needed to elucidate the correlation between postural control and cognition, we have shown that the combination of neuropsychological assessment and postural control analysis are complementary in the diagnosis of AD. Our results are consistent with other studies where performances within 88% [<xref rid="B6" ref-type="bibr">6</xref>, <xref rid="B63" ref-type="bibr">61</xref>] and 92% [<xref rid="B13" ref-type="bibr">12</xref>] were achieved using neural networks. DBNs have also displayed very good performances, which are compatible to the performance records of classifying AD based on neuroimaging data [<xref rid="B15" ref-type="bibr">14</xref>, <xref rid="B42" ref-type="bibr">41</xref>, <xref rid="B64" ref-type="bibr">62</xref>]. SVM is considered useful for handling high-dimensional data [<xref rid="B55" ref-type="bibr">53</xref>], as it efficiently deals with a very large number of features due to the exploitation of kernel functions. This is particularly useful in applications where the number of attributes is much larger than the number of training objects [<xref rid="B65" ref-type="bibr">63</xref>]. However, we did not find SVM to be the superior classifier. A drawback of SVM is that the problem complexity is not of the order of the dimension of the samples, but of the order of the samples.</p></sec><sec id="sec6"><title>6. Conclusion</title><p>Our work shows that postural kinematic analysis has the potential to be used as complementary biomarker in the diagnosis of AD. Machine-learning classification systems can be a helpful tool for the diagnosis of AD, based on postural kinematics, age, height, weight, education, and MoCA. We have shown that MLPs, followed by DBN, RBN, and SVM, are useful statistical tools for pattern recognition on clinical data and neuropsychological and kinematic postural evaluation. Specifically, in the datasets relying solely on kinematic postural data (i) MLP achieved a diagnostic accuracy of 86% (sensitivity: 79%; specificity: 93%); (ii) DBN achieved a diagnostic accuracy of 78% (sensitivity: 79%; specificity: 77%); (iii) RBN achieved a diagnostic accuracy of 74% (sensitivity: 71.3%; specificity: 76.7%); and finally (iv) SVM achieved a diagnostic accuracy of 71.7% (sensitivity: 65%; specificity: 78.4%).</p><p>These results are competitive in comparison to results reported in other recent studies that make use of other types of data, such as MRI, PET, EEG, and other biomarkers (see [<xref rid="B11" ref-type="bibr">10</xref>] for a list of performances). These results are also competitive when compared to [<xref rid="B11" ref-type="bibr">10</xref>], which also used a neuropsychological variable (minimental state examination) (MMSE) in combination with MRI, obtaining results of 78.2% and 92.4% accuracy when the SVM is trained with datasets without and with the MMSE variable, respectively. Crossing a statistical model (nonparametric Mann&#x02013;Whitney<italic> U</italic> test) to reduce the number of input variables with machine-learning models has proved to be an advantageous preprocessing tool to a certain extent. This is corroborated by observing that the best results were obtained by the classifiers when trained with reduced datasets.</p><p>Future perspectives of our work are to collect a larger dataset of AD patients and healthy subjects, so as to better comprehend the discriminatory role of each kinematic postural variable per se as well as its interdynamic interaction, in the process of maintaining balance within the limits of stability. Other future step, would be to evolve from a nonstatic to a dynamic paradigm, that is to say, simultaneously studying the constant dynamics of postural control and cognition (e.g., attention) on nonstationary increasingly difficult levels of balance and cognition tasks.</p></sec></body><back><ack><title>Acknowledgments</title><p>The Algoritmi Center was funded by the FP7 ITN Marie Curie Neural Engineering Transformative Technologies (NETT) project.</p></ack><sec sec-type="COI-statement"><title>Competing Interests</title><p>The authors declare that there is no conflict of interests regarding the publication of this paper.</p></sec><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kannus</surname><given-names>P.</given-names></name><name><surname>Siev&#x000e4;nen</surname><given-names>H.</given-names></name><name><surname>Palvanen</surname><given-names>M.</given-names></name><name><surname>J&#x000e4;rvinen</surname><given-names>T.</given-names></name><name><surname>Parkkari</surname><given-names>J.</given-names></name></person-group><article-title>Prevention of falls and consequent injuries in elderly people</article-title><source><italic>The Lancet</italic></source><year>2005</year><volume>366</volume><issue>9500</issue><fpage>1885</fpage><lpage>1893</lpage><pub-id pub-id-type="doi">10.1016/s0140-6736(05)67604-0</pub-id><pub-id pub-id-type="other">2-s2.0-28044463832</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etman</surname><given-names>A.</given-names></name><name><surname>Wijlhuizen</surname><given-names>G. J.</given-names></name><name><surname>van heuvelen</surname><given-names>M. J. G.</given-names></name><name><surname>Chorus</surname><given-names>A.</given-names></name><name><surname>Hopman-Rock</surname><given-names>M.</given-names></name></person-group><article-title>Falls incidence underestimates the risk of fall-related injuries in older age groups: a comparison with the FARE (Falls risk by exposure)</article-title><source><italic>Age and Ageing</italic></source><year>2012</year><volume>41</volume><issue>2</issue><fpage>190</fpage><lpage>195</lpage><pub-id pub-id-type="publisher-id">afr178</pub-id><pub-id pub-id-type="doi">10.1093/ageing/afr178</pub-id><pub-id pub-id-type="other">2-s2.0-84857199910</pub-id><pub-id pub-id-type="pmid">22345295</pub-id></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shumway-Cook</surname><given-names>A.</given-names></name><name><surname>Woollacott</surname><given-names>M.</given-names></name></person-group><article-title>Attentional demands and postural control: the effect of sensory context</article-title><source><italic>Journals of Gerontology&#x02014;Series A Biological Sciences and Medical Sciences</italic></source><year>2000</year><volume>55</volume><issue>1</issue><fpage>M10</fpage><lpage>M16</lpage><pub-id pub-id-type="doi">10.1093/gerona/55.1.m10</pub-id><pub-id pub-id-type="other">2-s2.0-0034049680</pub-id></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orr&#x000f9;</surname><given-names>G.</given-names></name><name><surname>Pettersson-Yeo</surname><given-names>W.</given-names></name><name><surname>Marquand</surname><given-names>A. F.</given-names></name><name><surname>Sartori</surname><given-names>G.</given-names></name><name><surname>Mechelli</surname><given-names>A.</given-names></name></person-group><article-title>Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease: a critical review</article-title><source><italic>Neuroscience and Biobehavioral Reviews</italic></source><year>2012</year><volume>36</volume><issue>4</issue><fpage>1140</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2012.01.004</pub-id><pub-id pub-id-type="other">2-s2.0-84857000430</pub-id><pub-id pub-id-type="pmid">22305994</pub-id></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subasi</surname><given-names>A.</given-names></name><name><surname>Gursoy</surname><given-names>M. I.</given-names></name></person-group><article-title>EEG signal classification using PCA, ICA, LDA and support vector machines</article-title><source><italic>Expert Systems with Applications</italic></source><year>2010</year><volume>37</volume><issue>12</issue><fpage>8659</fpage><lpage>8666</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2010.06.065</pub-id><pub-id pub-id-type="other">2-s2.0-77957830692</pub-id></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehmann</surname><given-names>C.</given-names></name><name><surname>Koenig</surname><given-names>T.</given-names></name><name><surname>Jelic</surname><given-names>V.</given-names></name><etal/></person-group><article-title>Application and comparison of classification algorithms for recognition of Alzheimer's disease in electrical brain activity (EEG)</article-title><source><italic>Journal of Neuroscience Methods</italic></source><year>2007</year><volume>161</volume><issue>2</issue><fpage>342</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.10.023</pub-id><pub-id pub-id-type="other">2-s2.0-33947517339</pub-id><pub-id pub-id-type="other">17156848</pub-id><pub-id pub-id-type="pmid">17156848</pub-id></element-citation></ref><ref id="B8"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguilar</surname><given-names>C.</given-names></name><name><surname>Westman</surname><given-names>E.</given-names></name><name><surname>Muehlboeck</surname><given-names>J.-S.</given-names></name><etal/></person-group><article-title>Different multivariate techniques for automated classification of MRI data in Alzheimer's disease and mild cognitive impairment</article-title><source><italic>Psychiatry Research&#x02014;Neuroimaging</italic></source><year>2013</year><volume>212</volume><issue>2</issue><fpage>89</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/j.pscychresns.2012.11.005</pub-id><pub-id pub-id-type="other">2-s2.0-84876791647</pub-id></element-citation></ref><ref id="B9"><label>8</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Guan</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>W.</given-names></name></person-group><article-title>Independent component analysis-based multimodal classification of Alzheimer's disease versus healthy controls</article-title><conf-name>Proceedings of the 9th International Conference on Natural Computation (ICNC '13)</conf-name><conf-date>July 2013</conf-date><conf-loc>Shenyang, China</conf-loc><fpage>75</fpage><lpage>79</lpage></element-citation></ref><ref id="B10"><label>9</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rodrigues</surname><given-names>F.</given-names></name><name><surname>Silveira</surname><given-names>M.</given-names></name></person-group><article-title>Longitudinal FDG-PET features for the classification of Alzheimers disease</article-title><volume>2014</volume><conf-name>Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society</conf-name><conf-date>August 2014</conf-date><fpage>1941</fpage><lpage>1944</lpage></element-citation></ref><ref id="B11"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Q.</given-names></name><name><surname>Goryawala</surname><given-names>M.</given-names></name><name><surname>Cabrerizo</surname><given-names>M.</given-names></name><etal/></person-group><article-title>An optimal decisional space for the classification of alzheimer's disease and mild cognitive impairment</article-title><source><italic>IEEE Transactions on Biomedical Engineering</italic></source><year>2014</year><volume>61</volume><issue>8</issue><fpage>2245</fpage><lpage>2253</lpage><pub-id pub-id-type="doi">10.1109/TBME.2014.2310709</pub-id><pub-id pub-id-type="other">2-s2.0-84904701349</pub-id><pub-id pub-id-type="other">25051543</pub-id><pub-id pub-id-type="pmid">25051543</pub-id></element-citation></ref><ref id="B7"><label>11</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Escudero</surname><given-names>J.</given-names></name><name><surname>Zajicek</surname><given-names>J. P.</given-names></name><name><surname>Ifeachor</surname><given-names>E.</given-names></name></person-group><article-title>Machine Learning classification of MRI features of Alzheimers disease and mild cognitive impairment subjects to reduce the sample size in clinical trials</article-title><volume>2011</volume><conf-name>Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society</conf-name><conf-date>2011</conf-date><fpage>7957</fpage><lpage>7960</lpage></element-citation></ref><ref id="B13"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pritchard</surname><given-names>W. S.</given-names></name><name><surname>Duke</surname><given-names>D. W.</given-names></name><name><surname>Coburn</surname><given-names>K. L.</given-names></name><etal/></person-group><article-title>EEG-based, neural-net predictive classification of Alzheimer's disease versus control subjects is augmented by non-linear EEG measures</article-title><source><italic>Electroencephalography and Clinical Neurophysiology</italic></source><year>1994</year><volume>91</volume><issue>2</issue><fpage>118</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(94)90033-7</pub-id><pub-id pub-id-type="other">2-s2.0-0028129569</pub-id><pub-id pub-id-type="pmid">7519141</pub-id></element-citation></ref><ref id="B14"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agarwal</surname><given-names>S.</given-names></name><name><surname>Ghanty</surname><given-names>P.</given-names></name><name><surname>Pal</surname><given-names>N. R.</given-names></name></person-group><article-title>Identification of a small set of plasma signalling proteins using neural network for prediction of Alzheimer's disease</article-title><source><italic>Bioinformatics</italic></source><year>2015</year><volume>31</volume><issue>15</issue><fpage>2505</fpage><lpage>2513</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btv173</pub-id><pub-id pub-id-type="other">2-s2.0-84943623488</pub-id><pub-id pub-id-type="pmid">25819077</pub-id></element-citation></ref><ref id="B15"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suk</surname><given-names>H.-I.</given-names></name><name><surname>Lee</surname><given-names>S.-W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group><article-title>Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis</article-title><source><italic>NeuroImage</italic></source><year>2014</year><volume>101</volume><fpage>569</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.077</pub-id><pub-id pub-id-type="other">2-s2.0-84907019192</pub-id><pub-id pub-id-type="other">25042445</pub-id><pub-id pub-id-type="pmid">25042445</pub-id></element-citation></ref><ref id="B16"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Cai</surname><given-names>W.</given-names></name><etal/></person-group><article-title>Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer's Disease</article-title><source><italic>IEEE Transactions on Biomedical Engineering</italic></source><year>2015</year><volume>62</volume><issue>4</issue><fpage>1132</fpage><lpage>1140</lpage><pub-id pub-id-type="doi">10.1109/TBME.2014.2372011</pub-id><pub-id pub-id-type="other">2-s2.0-84925851214</pub-id><pub-id pub-id-type="pmid">25423647</pub-id></element-citation></ref><ref id="B17"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gago</surname><given-names>M. F.</given-names></name><name><surname>Fernandes</surname><given-names>V.</given-names></name><name><surname>Ferreira</surname><given-names>J.</given-names></name><etal/></person-group><article-title>Postural stability analysis with inertial measurement units in Alzheimer's disease</article-title><source><italic>Dementia and Geriatric Cognitive Disorders Extra</italic></source><year>2014</year><volume>4</volume><issue>1</issue><fpage>22</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1159/000357472</pub-id><pub-id pub-id-type="pmid">24575114</pub-id></element-citation></ref><ref id="B18"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lafond</surname><given-names>D.</given-names></name><name><surname>Corriveau</surname><given-names>H.</given-names></name><name><surname>H&#x000e9;bert</surname><given-names>R.</given-names></name><name><surname>Prince</surname><given-names>F.</given-names></name></person-group><article-title>Intrasession reliability of center of pressure measures of postural steadiness in healthy elderly people</article-title><source><italic>Archives of Physical Medicine and Rehabilitation</italic></source><year>2004</year><volume>85</volume><issue>6</issue><fpage>896</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1016/j.apmr.2003.08.089</pub-id><pub-id pub-id-type="other">2-s2.0-3042628237</pub-id><pub-id pub-id-type="other">15179642</pub-id><pub-id pub-id-type="pmid">15179642</pub-id></element-citation></ref><ref id="B19"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKhann</surname><given-names>G. M.</given-names></name><name><surname>Knopman</surname><given-names>D. S.</given-names></name><name><surname>Chertkow</surname><given-names>H.</given-names></name><etal/></person-group><article-title>The diagnosis of dementia due to Alzheimer's disease: recommendations from the National Institute on Aging-Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease</article-title><source><italic>Alzheimer's and Dementia</italic></source><year>2011</year><volume>7</volume><issue>3</issue><fpage>263</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1016/j.jalz.2011.03.005</pub-id><pub-id pub-id-type="other">2-s2.0-79956142378</pub-id></element-citation></ref><ref id="B20"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freitas</surname><given-names>S.</given-names></name><name><surname>Sim&#x000f5;es</surname><given-names>M. R.</given-names></name><name><surname>Alves</surname><given-names>L.</given-names></name><name><surname>Santana</surname><given-names>I.</given-names></name></person-group><article-title>Montreal Cognitive Assessment (MoCA): normative study for the Portuguese population</article-title><source><italic>Journal of Clinical and Experimental Neuropsychology</italic></source><year>2011</year><volume>33</volume><issue>9</issue><fpage>989</fpage><lpage>996</lpage><pub-id pub-id-type="doi">10.1080/13803395.2011.589374</pub-id><pub-id pub-id-type="other">2-s2.0-84855657605</pub-id><pub-id pub-id-type="pmid">22082082</pub-id></element-citation></ref><ref id="B21"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Afonso</surname><given-names>J. A.</given-names></name><name><surname>Silva</surname><given-names>H. D.</given-names></name><name><surname>Macedo</surname><given-names>P.</given-names></name><name><surname>Rocha</surname><given-names>L. A.</given-names></name></person-group><article-title>An enhanced reservation-based MAC protocol for IEEE 802.15.4 networks</article-title><source><italic>Sensors</italic></source><year>2011</year><volume>11</volume><issue>4</issue><fpage>3852</fpage><lpage>3873</lpage><pub-id pub-id-type="doi">10.3390/s110403852</pub-id><pub-id pub-id-type="other">2-s2.0-79953838808</pub-id><pub-id pub-id-type="other">22163826</pub-id><pub-id pub-id-type="pmid">22163826</pub-id></element-citation></ref><ref id="B22"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winter</surname><given-names>D. A.</given-names></name><name><surname>Patla</surname><given-names>A. E.</given-names></name><name><surname>Frank</surname><given-names>J. S.</given-names></name></person-group><article-title>Assessment of balance control in humans</article-title><source><italic>Medical Progress through Technology</italic></source><year>1990</year><volume>16</volume><issue>1-2</issue><fpage>31</fpage><lpage>51</lpage><pub-id pub-id-type="other">2-s2.0-0025431004</pub-id><pub-id pub-id-type="other">2138696</pub-id><pub-id pub-id-type="pmid">2138696</pub-id></element-citation></ref><ref id="B23"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piirtola</surname><given-names>M.</given-names></name><name><surname>Era</surname><given-names>P.</given-names></name></person-group><article-title>Force platform measurements as predictors of falls among older people&#x02014;a review</article-title><source><italic>Gerontology</italic></source><year>2006</year><volume>52</volume><issue>1</issue><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1159/000089820</pub-id><pub-id pub-id-type="other">2-s2.0-31544457615</pub-id><pub-id pub-id-type="pmid">16439819</pub-id></element-citation></ref><ref id="B24"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>M. G.</given-names></name><name><surname>Frank</surname><given-names>J. S.</given-names></name><name><surname>Winter</surname><given-names>D. A.</given-names></name><name><surname>Peysar</surname><given-names>G. W.</given-names></name></person-group><article-title>Sampling duration effects on centre of pressure summary measures</article-title><source><italic>Gait &#x00026; Posture</italic></source><year>2001</year><volume>13</volume><issue>1</issue><fpage>35</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/s0966-6362(00)00093-x</pub-id><pub-id pub-id-type="other">2-s2.0-0035141512</pub-id><pub-id pub-id-type="pmid">11166552</pub-id></element-citation></ref><ref id="B25"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horak</surname><given-names>F. B.</given-names></name><name><surname>Henry</surname><given-names>S. M.</given-names></name><name><surname>Shumway-Cook</surname><given-names>A.</given-names></name></person-group><article-title>Postural perturbations: new insights for treatment of balance disorders</article-title><source><italic>Physical Therapy</italic></source><year>1997</year><volume>77</volume><issue>5</issue><fpage>517</fpage><lpage>533</lpage><pub-id pub-id-type="other">2-s2.0-0030960047</pub-id><pub-id pub-id-type="pmid">9149762</pub-id></element-citation></ref><ref id="B26"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollock</surname><given-names>A. S.</given-names></name><name><surname>Durward</surname><given-names>B. R.</given-names></name><name><surname>Rowe</surname><given-names>P. J.</given-names></name><name><surname>Paul</surname><given-names>J. P.</given-names></name></person-group><article-title>What is balance?</article-title><source><italic>Clinical Rehabilitation</italic></source><year>2000</year><volume>14</volume><issue>4</issue><fpage>402</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1191/0269215500cr342oa</pub-id><pub-id pub-id-type="other">2-s2.0-0033914284</pub-id><pub-id pub-id-type="other">10945424</pub-id><pub-id pub-id-type="pmid">10945424</pub-id></element-citation></ref><ref id="B27"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leandri</surname><given-names>M.</given-names></name><name><surname>Cammisuli</surname><given-names>S.</given-names></name><name><surname>Cammarata</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Balance features in Alzheimer's disease and amnestic mild cognitive impairment</article-title><source><italic>Journal of Alzheimer's Disease</italic></source><year>2009</year><volume>16</volume><issue>1</issue><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.3233/JAD-2009-0928</pub-id><pub-id pub-id-type="other">2-s2.0-58849164331</pub-id><pub-id pub-id-type="other">19158427</pub-id><pub-id pub-id-type="pmid">19158427</pub-id></element-citation></ref><ref id="B28"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nardone</surname><given-names>A.</given-names></name><name><surname>Schieppati</surname><given-names>M.</given-names></name></person-group><article-title>Balance in Parkinson's disease under static and dynamic conditions</article-title><source><italic>Movement Disorders</italic></source><year>2006</year><volume>21</volume><issue>9</issue><fpage>1515</fpage><lpage>1520</lpage><pub-id pub-id-type="doi">10.1002/mds.21015</pub-id><pub-id pub-id-type="other">2-s2.0-33750325317</pub-id><pub-id pub-id-type="other">16817196</pub-id><pub-id pub-id-type="pmid">16817196</pub-id></element-citation></ref><ref id="B29"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merlo</surname><given-names>A.</given-names></name><name><surname>Zemp</surname><given-names>D.</given-names></name><name><surname>Zanda</surname><given-names>E.</given-names></name><etal/></person-group><article-title>Postural stability and history of falls in cognitively able older adults: The Canton Ticino Study</article-title><source><italic>Gait and Posture</italic></source><year>2012</year><volume>36</volume><issue>4</issue><fpage>662</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.gaitpost.2012.06.016</pub-id><pub-id pub-id-type="other">2-s2.0-84867140230</pub-id><pub-id pub-id-type="pmid">22832469</pub-id></element-citation></ref><ref id="B30"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maeda</surname><given-names>Y.</given-names></name><name><surname>Tanaka</surname><given-names>T.</given-names></name><name><surname>Nakajima</surname><given-names>Y.</given-names></name><name><surname>Shimizu</surname><given-names>K.</given-names></name></person-group><article-title>Analysis of postural adjustment responses to perturbation stimulus by surface tilts in the feet-together position</article-title><source><italic>Journal of Medical and Biological Engineering</italic></source><year>2011</year><volume>31</volume><issue>4</issue><fpage>301</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.5405/jmbe.867</pub-id><pub-id pub-id-type="other">2-s2.0-80053257956</pub-id></element-citation></ref><ref id="B31"><label>30</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Winter</surname><given-names>D. A.</given-names></name></person-group><source><italic>Biomechanics and Motor Control of Human Movement</italic></source><year>2009</year><edition>4th</edition><publisher-loc>Hoboken, NJ, USA</publisher-loc><publisher-name>John Wiley &#x00026; Sons</publisher-name></element-citation></ref><ref id="B32"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jack</surname><given-names>C. R.</given-names><suffix>Jr.</suffix></name><name><surname>Twomey</surname><given-names>C. K.</given-names></name><name><surname>Zinsmeister</surname><given-names>A. R.</given-names></name><name><surname>Sharbrough</surname><given-names>F. W.</given-names></name><name><surname>Petersen</surname><given-names>R. C.</given-names></name><name><surname>Cascino</surname><given-names>G. D.</given-names></name></person-group><article-title>Anterior temporal lobes and hippocampal formations: normative volumetric measurements from MR images in young adults</article-title><source><italic>Radiology</italic></source><year>1989</year><volume>172</volume><issue>2</issue><fpage>549</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1148/radiology.172.2.2748838</pub-id><pub-id pub-id-type="other">2-s2.0-0024354747</pub-id><pub-id pub-id-type="pmid">2748838</pub-id></element-citation></ref><ref id="B33"><label>32</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Han</surname><given-names>J.</given-names></name><name><surname>Kamber</surname><given-names>M.</given-names></name><name><surname>Pei</surname><given-names>J.</given-names></name></person-group><source><italic>Data Mining: Concepts and Techniques</italic></source><year>2011</year><edition>3rd</edition><publisher-loc>Burlington, Mass, USA</publisher-loc><publisher-name>Morgan Kaufmann</publisher-name></element-citation></ref><ref id="B34"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowden</surname><given-names>G. J.</given-names></name><name><surname>Maier</surname><given-names>H. R.</given-names></name><name><surname>Dandy</surname><given-names>G. C.</given-names></name></person-group><article-title>Optimal division of data for neural network models in water resources applications</article-title><source><italic>Water Resources Research</italic></source><year>2002</year><volume>38</volume><issue>2</issue><fpage>2-1</fpage><lpage>2-11</lpage></element-citation></ref><ref id="B35"><label>34</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>V. N.</given-names></name></person-group><source><italic>The Nature of Statistical Learning Theory</italic></source><year>1995</year><publisher-loc>New York, NY, USA</publisher-loc><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4757-2440-0</pub-id><pub-id pub-id-type="other">MR1367965</pub-id></element-citation></ref><ref id="B36"><label>35</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N.</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name></person-group><source><italic>An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods</italic></source><year>2000</year><publisher-loc>Cambridge, UK</publisher-loc><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/cbo9780511801389</pub-id></element-citation></ref><ref id="B37"><label>36</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ferreira</surname><given-names>J.</given-names></name><name><surname>Gago</surname><given-names>M. F.</given-names></name><name><surname>Fernandes</surname><given-names>V.</given-names></name><etal/></person-group><article-title>Analysis of postural kinetics data using artificial neural networks in Alzheimer's disease</article-title><conf-name>Proceedings of the 9th IEEE International Symposium on Medical Measurements and Applications (MeMeA '14)</conf-name><conf-date>June 2014</conf-date><conf-loc>Lisbon, Portugal</conf-loc><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1109/memea.2014.6860040</pub-id><pub-id pub-id-type="other">2-s2.0-84906902037</pub-id></element-citation></ref><ref id="B38"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moody</surname><given-names>J.</given-names></name><name><surname>Darken</surname><given-names>C. J.</given-names></name></person-group><article-title>Fast learning in networks of locally-tuned processing units</article-title><source><italic>Neural Computation</italic></source><year>1989</year><volume>1</volume><issue>2</issue><fpage>281</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1162/neco.1989.1.2.281</pub-id></element-citation></ref><ref id="B39"><label>38</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Palm</surname><given-names>R. B.</given-names></name></person-group><source><italic>Prediction as a candidate for learning deep hierarchical models of data [M.S. thesis]</italic></source><year>2012</year><publisher-name>DTU Informatics, Kongens Lyngby, Technical University of Denmark</publisher-name></element-citation></ref><ref id="B40"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>G. E.</given-names></name><name><surname>Osindero</surname><given-names>S.</given-names></name><name><surname>Teh</surname><given-names>Y.-W.</given-names></name></person-group><article-title>A fast learning algorithm for deep belief nets</article-title><source><italic>Neural Computation</italic></source><year>2006</year><volume>18</volume><issue>7</issue><fpage>1527</fpage><lpage>1554</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1527</pub-id><pub-id pub-id-type="other">MR2224485</pub-id><pub-id pub-id-type="other">2-s2.0-33745805403</pub-id><pub-id pub-id-type="other">16764513</pub-id><pub-id pub-id-type="pmid">16764513</pub-id></element-citation></ref><ref id="B41"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>J. J.</given-names></name></person-group><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source><italic>Proceedings of the National Academy of Sciences of the United States of America</italic></source><year>1982</year><volume>79</volume><issue>8</issue><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id><pub-id pub-id-type="other">MR652033</pub-id><pub-id pub-id-type="other">2-s2.0-0020118274</pub-id><pub-id pub-id-type="other">6953413</pub-id><pub-id pub-id-type="pmid">6953413</pub-id></element-citation></ref><ref id="B42"><label>41</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Cai</surname><given-names>W.</given-names></name><name><surname>Pujol</surname><given-names>S.</given-names></name><name><surname>Kikinis</surname><given-names>R.</given-names></name><name><surname>Feng</surname><given-names>D.</given-names></name></person-group><article-title>Early diagnosis of Alzheimer's disease with deep learning</article-title><conf-name>Proceedings of the in IEEE 11th International Symposium on Biomedical Imaging (ISBI '14)</conf-name><conf-date>April-May 2014</conf-date><conf-loc>Beijing, China</conf-loc><fpage>1015</fpage><lpage>1018</lpage><pub-id pub-id-type="doi">10.1109/ISBI.2014.6868045</pub-id></element-citation></ref><ref id="B43"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>L.</given-names></name><name><surname>Yuan</surname><given-names>H.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group><article-title>Multimodal classification of Alzheimer's disease and mild cognitive impairment</article-title><source><italic>NeuroImage</italic></source><year>2011</year><volume>55</volume><issue>3</issue><fpage>856</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.01.008</pub-id><pub-id pub-id-type="other">2-s2.0-79952073234</pub-id><pub-id pub-id-type="other">21236349</pub-id><pub-id pub-id-type="pmid">21236349</pub-id></element-citation></ref><ref id="B45"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woollacott</surname><given-names>M.</given-names></name><name><surname>Shumway-Cook</surname><given-names>A.</given-names></name></person-group><article-title>Attention and the control of posture and gait: a review of an emerging area of research</article-title><source><italic>Gait &#x00026; Posture</italic></source><year>2002</year><volume>16</volume><issue>1</issue><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/s0966-6362(01)00156-4</pub-id><pub-id pub-id-type="other">2-s2.0-0036065843</pub-id><pub-id pub-id-type="pmid">12127181</pub-id></element-citation></ref><ref id="B46"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gago</surname><given-names>M. F.</given-names></name><name><surname>Yelshyna</surname><given-names>D.</given-names></name><name><surname>Bicho</surname><given-names>E.</given-names></name><etal/></person-group><article-title>Compensatory postural adjustments in an oculus virtual reality environment and the risk of falling in Alzheimer's disease</article-title><source><italic>Dementia and Geriatric Cognitive Disorders Extra</italic></source><year>2016</year><volume>6</volume><issue>2</issue><fpage>252</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1159/000447124</pub-id><pub-id pub-id-type="pmid">27489559</pub-id></element-citation></ref><ref id="B47"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukunaga</surname><given-names>K.</given-names></name><name><surname>Hayes</surname><given-names>R. R.</given-names></name></person-group><article-title>Effects of sample size in classifier design</article-title><source><italic>IEEE Transactions on Pattern Analysis and Machine Intelligence</italic></source><year>1989</year><volume>11</volume><issue>8</issue><fpage>873</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1109/34.31448</pub-id><pub-id pub-id-type="other">2-s2.0-0024716579</pub-id></element-citation></ref><ref id="B48"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raudys</surname><given-names>S. J.</given-names></name><name><surname>Jain</surname><given-names>A. K.</given-names></name></person-group><article-title>Small sample size effects in statistical pattern recognition: recommendations for practitioners</article-title><source><italic>IEEE Transactions on Pattern Analysis and Machine Intelligence</italic></source><year>1991</year><volume>13</volume><issue>3</issue><fpage>252</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1109/34.75512</pub-id><pub-id pub-id-type="other">2-s2.0-0026120032</pub-id></element-citation></ref><ref id="B49"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>G. P.</given-names></name></person-group><article-title>Neural networks for classification: a survey</article-title><source><italic>IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews</italic></source><year>2000</year><volume>30</volume><issue>4</issue><fpage>451</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1109/5326.897072</pub-id></element-citation></ref><ref id="B50"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peduzzi</surname><given-names>P.</given-names></name><name><surname>Concato</surname><given-names>J.</given-names></name><name><surname>Kemper</surname><given-names>E.</given-names></name><name><surname>Holford</surname><given-names>T. R.</given-names></name><name><surname>Feinstem</surname><given-names>A. R.</given-names></name></person-group><article-title>A simulation study of the number of events per variable in logistic regression analysis</article-title><source><italic>Journal of Clinical Epidemiology</italic></source><year>1996</year><volume>49</volume><issue>12</issue><fpage>1373</fpage><lpage>1379</lpage><pub-id pub-id-type="doi">10.1016/S0895-4356(96)00236-3</pub-id><pub-id pub-id-type="other">2-s2.0-0030474271</pub-id><pub-id pub-id-type="other">8970487</pub-id><pub-id pub-id-type="pmid">8970487</pub-id></element-citation></ref><ref id="B51"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>K. R.</given-names></name><name><surname>Koprowski</surname><given-names>R.</given-names></name><name><surname>Skufca</surname><given-names>J. D.</given-names></name></person-group><article-title>Machine learning, medical diagnosis, and biomedical engineering research&#x02014;commentary</article-title><source><italic>BioMedical Engineering Online</italic></source><year>2014</year><volume>13</volume><issue>1, article no. 94</issue><pub-id pub-id-type="doi">10.1186/1475-925x-13-94</pub-id><pub-id pub-id-type="other">2-s2.0-84907019464</pub-id></element-citation></ref><ref id="B52"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliveira</surname><given-names>P. P.</given-names></name><name><surname>Nitrini</surname><given-names>R.</given-names></name><name><surname>Busatto</surname><given-names>G.</given-names></name><name><surname>Buchpiguel</surname><given-names>C.</given-names></name><name><surname>Sato</surname><given-names>J. R.</given-names></name><name><surname>Amaro</surname><given-names>E.</given-names></name></person-group><article-title>Use of SVM methods with surface-based cortical and volumetric subcortical measurements to detect Alzheimer's disease</article-title><source><italic>Journal of Alzheimer's Disease</italic></source><year>2010</year><volume>19</volume><issue>4</issue><fpage>1263</fpage><lpage>1272</lpage><pub-id pub-id-type="doi">10.3233/jad-2010-1322</pub-id><pub-id pub-id-type="other">2-s2.0-77950343082</pub-id></element-citation></ref><ref id="B53"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bert&#x000e8;</surname><given-names>F.</given-names></name><name><surname>Lamponi</surname><given-names>G.</given-names></name><name><surname>Calabr&#x000f2;</surname><given-names>R. S.</given-names></name><name><surname>Bramanti</surname><given-names>P.</given-names></name></person-group><article-title>Elman neural network for the early identification of cognitive impairment in Alzheimer's disease</article-title><source><italic>Functional Neurology</italic></source><year>2014</year><volume>29</volume><issue>1</issue><fpage>57</fpage><lpage>65</lpage><pub-id pub-id-type="other">2-s2.0-84904244408</pub-id><pub-id pub-id-type="other">25014050</pub-id><pub-id pub-id-type="pmid">25014050</pub-id></element-citation></ref><ref id="B54"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmerini</surname><given-names>L.</given-names></name><name><surname>Rocchi</surname><given-names>L.</given-names></name><name><surname>Mellone</surname><given-names>S.</given-names></name><name><surname>Valzania</surname><given-names>F.</given-names></name><name><surname>Chiari</surname><given-names>L.</given-names></name></person-group><article-title>Feature selection for accelerometer-based posture analysis in Parkinsons disease</article-title><source><italic>IEEE Transactions on Information Technology in Biomedicine</italic></source><year>2011</year><volume>15</volume><issue>3</issue><fpage>481</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1109/TITB.2011.2107916</pub-id><pub-id pub-id-type="other">2-s2.0-79955670717</pub-id><pub-id pub-id-type="other">21349795</pub-id><pub-id pub-id-type="pmid">21349795</pub-id></element-citation></ref><ref id="B55"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group><article-title>Deep learning in neural networks: an overview</article-title><source><italic>Neural Networks</italic></source><year>2015</year><volume>61</volume><fpage>85</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2014.09.003</pub-id><pub-id pub-id-type="other">2-s2.0-84910651844</pub-id><pub-id pub-id-type="pmid">25462637</pub-id></element-citation></ref><ref id="B56"><label>54</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Torabi</surname><given-names>M.</given-names></name><name><surname>Ardekani</surname><given-names>R. D.</given-names></name><name><surname>Fatemizadeh</surname><given-names>E.</given-names></name></person-group><article-title>Discrimination between Alzheimer's disease and control group in MR-images based on texture analysis using artificial neural network</article-title><conf-name>Proceedings of the 2006 International Conference on Biomedical and Pharmaceutical Engineering (ICBPE'06)</conf-name><conf-date>December 2006</conf-date><fpage>79</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1109/icbpe.2006.348558</pub-id><pub-id pub-id-type="other">2-s2.0-46249097330</pub-id></element-citation></ref><ref id="B57"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howley</surname><given-names>T.</given-names></name><name><surname>Madden</surname><given-names>M. G.</given-names></name><name><surname>O'Connell</surname><given-names>M.-L.</given-names></name><name><surname>Ryder</surname><given-names>A. G.</given-names></name></person-group><article-title>The effect of principal component analysis on machine learning accuracy with high-dimensional spectral data</article-title><source><italic>Knowledge-Based Systems</italic></source><year>2006</year><volume>19</volume><issue>5</issue><fpage>363</fpage><lpage>370</lpage><pub-id pub-id-type="doi">10.1016/j.knosys.2005.11.014</pub-id><pub-id pub-id-type="other">2-s2.0-33746924562</pub-id></element-citation></ref><ref id="B58"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmadlou</surname><given-names>M.</given-names></name><name><surname>Adeli</surname><given-names>H.</given-names></name><name><surname>Adeli</surname><given-names>A.</given-names></name></person-group><article-title>New diagnostic EEG markers of the Alzheimer's disease using visibility graph</article-title><source><italic>Journal of Neural Transmission</italic></source><year>2010</year><volume>117</volume><issue>9</issue><fpage>1099</fpage><lpage>1109</lpage><pub-id pub-id-type="doi">10.1007/s00702-010-0450-3</pub-id><pub-id pub-id-type="other">2-s2.0-77956469969</pub-id><pub-id pub-id-type="other">20714909</pub-id><pub-id pub-id-type="pmid">20714909</pub-id></element-citation></ref><ref id="B59"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>S. I.</given-names></name><name><surname>Iplikci</surname><given-names>S.</given-names></name><name><surname>Warwick</surname><given-names>K.</given-names></name><name><surname>Aziz</surname><given-names>T. Z.</given-names></name></person-group><article-title>Parkinson's disease tremor classification&#x02014;a comparison between Support Vector Machines and neural networks</article-title><source><italic>Expert Systems with Applications</italic></source><year>2012</year><volume>39</volume><issue>12</issue><fpage>10764</fpage><lpage>10771</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2012.02.189</pub-id><pub-id pub-id-type="other">2-s2.0-84861186364</pub-id></element-citation></ref><ref id="B60"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>Y.</given-names></name><name><surname>Su</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Huang</surname><given-names>S.</given-names></name></person-group><article-title>Heterogeneous multimodal biomarkers analysis for Alzheimer&#x02019;s disease via Bayesian network</article-title><source><italic>EURASIP Journal on Bioinformatics and Systems Biology</italic></source><year>2016</year><volume>12</volume><pub-id pub-id-type="doi">10.1186/s13637-016-0046-9</pub-id></element-citation></ref><ref id="B61"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stern</surname><given-names>Y.</given-names></name></person-group><article-title>Cognitive reserve in ageing and Alzheimer's disease</article-title><source><italic>The Lancet Neurology</italic></source><year>2012</year><volume>11</volume><issue>11</issue><fpage>1006</fpage><lpage>1012</lpage><pub-id pub-id-type="doi">10.1016/S1474-4422(12)70191-6</pub-id><pub-id pub-id-type="other">2-s2.0-84867603343</pub-id><pub-id pub-id-type="other">23079557</pub-id><pub-id pub-id-type="pmid">23079557</pub-id></element-citation></ref><ref id="B62"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Redmond</surname><given-names>S. J.</given-names></name><name><surname>Bertoux</surname><given-names>M.</given-names></name><name><surname>Hodges</surname><given-names>J. R.</given-names></name><name><surname>Hornberger</surname><given-names>M.</given-names></name></person-group><article-title>A comparison of magnetic resonance imaging and neuropsychological examination in the diagnostic distinction of Alzheimer's disease and behavioral variant frontotemporal dementia</article-title><source><italic>Frontiers in Aging Neuroscience</italic></source><year>2016</year><volume>8, article 119</volume><pub-id pub-id-type="doi">10.3389/fnagi.2016.00119</pub-id></element-citation></ref><ref id="B63"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderer</surname><given-names>P.</given-names></name><name><surname>Saletu</surname><given-names>B.</given-names></name><name><surname>Kl&#x000f6;ppel</surname><given-names>B.</given-names></name><name><surname>Semlitsch</surname><given-names>H. V.</given-names></name><name><surname>Werner</surname><given-names>H.</given-names></name></person-group><article-title>Discrimination between demented patients and normals based on topographic EEG slow wave activity: comparison between <italic>z</italic> statistics, discriminant analysis and artificial neural network classifiers</article-title><source><italic>Electroencephalography and Clinical Neurophysiology</italic></source><year>1994</year><volume>91</volume><issue>2</issue><fpage>108</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(94)90032-9</pub-id><pub-id pub-id-type="other">2-s2.0-0028146347</pub-id><pub-id pub-id-type="pmid">7519140</pub-id></element-citation></ref><ref id="B64"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Cai</surname><given-names>W.</given-names></name><etal/></person-group><article-title>Multimodal neuroimaging feature learning for multiclass diagnosis of Alzheimer's disease</article-title><source><italic>IEEE Transactions on Biomedical Engineering</italic></source><year>2015</year><volume>62</volume><issue>4</issue><fpage>1132</fpage><lpage>1140</lpage><pub-id pub-id-type="doi">10.1109/tbme.2014.2372011</pub-id><pub-id pub-id-type="other">2-s2.0-84925851214</pub-id><pub-id pub-id-type="pmid">25423647</pub-id></element-citation></ref><ref id="B65"><label>63</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Simon Rogers</surname><given-names>M. G.</given-names></name></person-group><source><italic>A First Course in Machine Learning</italic></source><year>2011</year><publisher-name>Chapman and Hall/CRC</publisher-name></element-citation></ref></ref-list></back><floats-group><fig id="fig1" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Representation of a patient, wearing the safety trunk belt, with the IMU placed on the center of mass (55% height), while performing the tasks: eyes closed with feet together on flat surface (a) and on frontwards platform (b) (other tasks were performed, as further detailed on the Materials and Methodology for Data Collection).</p></caption><graphic xlink:href="CIN2016-3891253.001"/></fig><fig id="fig2" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Representation of the substantial overlap on the different kinematic postural features, on an orthogonal projection, between the two groups and the different tasks, (a) EO, (b) EOFW, (c) EOBW, (d) EC, (e) ECFW, and (f) ECBW, with increasing difficulty of postural stability.</p></caption><graphic xlink:href="CIN2016-3891253.002"/></fig><fig id="fig3" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Methodological flowchart of the classification approach.</p></caption><graphic xlink:href="CIN2016-3891253.003"/></fig><fig id="fig4" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Box-plot representation of raw versus adjusted and normalized data of MoCA, total distance covered, and range of sway on <italic>y</italic>-axis in controls and Alzheimer's disease (AD) groups. There were significant differences between the two groups in raw data (MoCA, <italic>p</italic> &#x0003c; 0.001; distance covered, <italic>p</italic> &#x0003c; 0.001; <italic>y</italic>-axis range, <italic>p</italic> = 0.022) and after data was adjusted for age, education, height, and weight, followed by a normalization process (MoCA, <italic>p</italic> &#x0003c; 0.001; distance covered, <italic>p</italic> = 0.002, <italic>y</italic>-axis range, <italic>p</italic> = 0.05). Despite these statistical differences, especially in unadjusted raw data, it is important to note the significant overlap between the different individuals in the kinematic postural variables, highlighting the challenge of classification based on machine learning.</p></caption><graphic xlink:href="CIN2016-3891253.004"/></fig><fig id="fig5" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Incremental error analysis performance of accuracy with standard deviation indicated as error bar for SVM (a), MLP-BP (b), RBN (c), and DBN (d). The orange curve represents the datasets with the MoCA variable and the blue curve the datasets with only kinematic variables.</p></caption><graphic xlink:href="CIN2016-3891253.005"/></fig><fig id="fig6" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Four specific cases displaying the distribution of the subject population of the testing sets of Support Vector Machines (SVMs), Multiple Layer Perceptrons (MLPs), Radial Basis Function Neural Networks (RBNs), and Deep Belief Networks (DBNs) in the context of the top three features. This is a typical case of classification approach for Alzheimer's disease (AD) versus controls (CN).</p></caption><graphic xlink:href="CIN2016-3891253.006"/></fig><fig id="fig7" orientation="portrait" position="float"><label>Figure 7</label><caption><p>One specific case displaying the distribution of the same subject population of the testing of Support Vector Machines (SVMs), Multiple Layer Perceptrons (MLPs), Radial Basis Function Neural Networks (RBNs), and Deep Belief Networks (DBNs) in the context of the top three features. This is a typical case of classification approach for Alzheimer's disease (AD) versus controls (CN).</p></caption><graphic xlink:href="CIN2016-3891253.007"/></fig><table-wrap id="tab1" orientation="portrait" position="float"><label>Table 1</label><caption><p>Ranking of the 19 variables in the input vector, Alzheimer's disease versus controls groups.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="center" rowspan="1" colspan="1">Rank</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">MoCA</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Distance covered</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>Y</italic> range</td><td align="center" rowspan="1" colspan="1">3</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>X</italic> range</td><td align="center" rowspan="1" colspan="1">4</td></tr><tr><td align="left" rowspan="1" colspan="1">Maximum distance</td><td align="center" rowspan="1" colspan="1">5</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>Y</italic> maximum</td><td align="center" rowspan="1" colspan="1">6</td></tr><tr><td align="left" rowspan="1" colspan="1">Maximum Pitch</td><td align="center" rowspan="1" colspan="1">7</td></tr><tr><td align="left" rowspan="1" colspan="1">Mean distance</td><td align="center" rowspan="1" colspan="1">8</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>Y</italic> mean</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>X</italic> maximum</td><td align="center" rowspan="1" colspan="1">10</td></tr><tr><td align="left" rowspan="1" colspan="1">Radius of dispersion</td><td align="center" rowspan="1" colspan="1">11</td></tr><tr><td align="left" rowspan="1" colspan="1">Mean velocity</td><td align="center" rowspan="1" colspan="1">12</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>X</italic> mean</td><td align="center" rowspan="1" colspan="1">13</td></tr><tr><td align="left" rowspan="1" colspan="1">Maximum Roll</td><td align="center" rowspan="1" colspan="1">14</td></tr><tr><td align="left" rowspan="1" colspan="1">Mean pitch angle</td><td align="center" rowspan="1" colspan="1">15</td></tr><tr><td align="left" rowspan="1" colspan="1">Maximum velocity</td><td align="center" rowspan="1" colspan="1">16</td></tr><tr><td align="left" rowspan="1" colspan="1">Mean roll angle</td><td align="center" rowspan="1" colspan="1">17</td></tr><tr><td align="left" rowspan="1" colspan="1">Minimum Roll</td><td align="center" rowspan="1" colspan="1">18</td></tr><tr><td align="left" rowspan="1" colspan="1">Minimum Pitch</td><td align="center" rowspan="1" colspan="1">19</td></tr></tbody></table></table-wrap><table-wrap id="tab2" orientation="portrait" position="float"><label>Table 2</label><caption><p>Summary of top-ranked variables with varying dataset size.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Dataset size</th><th align="center" rowspan="1" colspan="1">Rank of variables</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">100%</td><td align="center" rowspan="1" colspan="1">MoCA<break/>Distance covered<break/>
<italic>Y</italic> range</td></tr><tr><td align="left" rowspan="1" colspan="1">80%</td><td align="center" rowspan="1" colspan="1">MoCA<break/>Distance covered<break/>
<italic>Y</italic> range</td></tr><tr><td align="left" rowspan="1" colspan="1">50%</td><td align="center" rowspan="1" colspan="1">MoCA<break/>Distance covered<break/>
<italic>Y</italic> range</td></tr></tbody></table></table-wrap><table-wrap id="tab3" orientation="portrait" position="float"><label>Table 3</label><caption><p>Best results obtained with each classifier trained with datasets with and without the MoCA variable. Between parentheses are the minimum and maximum values obtained. All results are in percentage.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">&#x02009;</th><th align="center" rowspan="1" colspan="1">Accuracy</th><th align="center" rowspan="1" colspan="1">Sensitivity</th><th align="center" rowspan="1" colspan="1">Specificity</th><th align="center" rowspan="1" colspan="1">Best decisional space</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SVM with MoCA</td><td align="center" rowspan="1" colspan="1">91 (75&#x02013;96.4)</td><td align="center" rowspan="1" colspan="1">89.3 (64.3&#x02013;100)</td><td align="center" rowspan="1" colspan="1">92.7 (71.4&#x02013;100)</td><td rowspan="2" align="center" colspan="1">Top 10 features</td></tr><tr><td align="left" rowspan="1" colspan="1">SVM without MoCA</td><td align="center" rowspan="1" colspan="1">71,7 (53.6&#x02013;92.9)</td><td align="center" rowspan="1" colspan="1">65 (35.7&#x02013;92.9)</td><td align="center" rowspan="1" colspan="1">78.4 (35.7&#x02013;100)</td></tr><tr><td align="left" rowspan="1" colspan="1">MLP with MoCA</td><td align="center" rowspan="1" colspan="1">96.6 (96.5&#x02013;100)</td><td align="center" rowspan="1" colspan="1">100 (100&#x02013;100)</td><td align="center" rowspan="1" colspan="1">94.9 (94.7&#x02013;100)</td><td rowspan="2" align="center" colspan="1">Top 11 features and top 15 features</td></tr><tr><td align="left" rowspan="1" colspan="1">MLP without MoCA</td><td align="center" rowspan="1" colspan="1">86,1 (79.3&#x02013;86.2)</td><td align="center" rowspan="1" colspan="1">78.5 (77.8&#x02013;78.6)</td><td align="center" rowspan="1" colspan="1">93.1 (81.8&#x02013;93.3)</td></tr><tr><td align="left" rowspan="1" colspan="1">RBN with MoCA</td><td align="center" rowspan="1" colspan="1">92,5 (75&#x02013;100)</td><td align="center" rowspan="1" colspan="1">90.4 (71.4&#x02013;100)</td><td align="center" rowspan="1" colspan="1">94.5 (78.6&#x02013;100)</td><td rowspan="2" align="center" colspan="1">Top 15 features</td></tr><tr><td align="left" rowspan="1" colspan="1">RBN without MoCA</td><td align="center" rowspan="1" colspan="1">74,0 (53.6&#x02013;82.1)</td><td align="center" rowspan="1" colspan="1">71.3 (50&#x02013;100)</td><td align="center" rowspan="1" colspan="1">76.7 (42.9&#x02013;100)</td></tr><tr><td align="left" rowspan="1" colspan="1">DBN with MoCA</td><td align="center" rowspan="1" colspan="1">96,5 (89.3&#x02013;100)</td><td align="center" rowspan="1" colspan="1">95.3 (85.7&#x02013;100)</td><td align="center" rowspan="1" colspan="1">97.7 (85.7&#x02013;100)</td><td rowspan="2" align="center" colspan="1">Top 15 features</td></tr><tr><td align="left" rowspan="1" colspan="1">DBN without MoCA</td><td align="center" rowspan="1" colspan="1">78,0 (57.1&#x02013;92.9)</td><td align="center" rowspan="1" colspan="1">79 (14.3&#x02013;100)</td><td align="center" rowspan="1" colspan="1">77 (21.4&#x02013;100)</td></tr></tbody></table></table-wrap></floats-group></article>