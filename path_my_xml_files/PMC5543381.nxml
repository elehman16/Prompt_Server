<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">AMIA Jt Summits Transl Sci Proc</journal-id><journal-id journal-id-type="iso-abbrev">AMIA Jt Summits Transl Sci Proc</journal-id><journal-title-group><journal-title>AMIA Summits on Translational Science Proceedings</journal-title></journal-title-group><issn pub-type="epub">2153-4063</issn><publisher><publisher-name>American Medical Informatics Association</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28815147</article-id><article-id pub-id-type="pmc">5543381</article-id><article-id pub-id-type="publisher-id">2609765</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Triangulating Methodologies from Software, Medicine and Human Factors Industries to Measure Usability and Clinical Efficacy of Medication Data Visualization in an Electronic Health Record System</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Chang</surname><given-names>Bora</given-names></name><xref ref-type="aff" rid="af1-2609765">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Kanagaraj</surname><given-names>Manoj</given-names></name><xref ref-type="aff" rid="af1-2609765">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Neely</surname><given-names>Ben</given-names></name><xref ref-type="aff" rid="af2-2609765">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Segall</surname><given-names>Noa</given-names></name><degrees>PhD</degrees><xref ref-type="aff" rid="af1-2609765">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Erich</given-names></name><degrees>MD</degrees><degrees>PhD</degrees><xref ref-type="aff" rid="af1-2609765">
<sup>1</sup>
</xref><xref ref-type="aff" rid="af2-2609765">
<sup>2</sup>
</xref></contrib></contrib-group><aff id="af1-2609765"><label>1</label>Duke University School of Medicine, Durham, NC;</aff><aff id="af2-2609765"><label>2</label>Duke University Health System Division of Translational Bioinformatics, Durham, NC</aff><pub-date pub-type="collection"><year>2017</year></pub-date><pub-date pub-type="epub"><day>26</day><month>7</month><year>2017</year></pub-date><volume>2017</volume><fpage>473</fpage><lpage>482</lpage><permissions><copyright-statement>&#x000a9;2017 AMIA - All rights reserved.</copyright-statement><copyright-year>2017</copyright-year><license><license-p>This is an Open Access article: verbatim copying and redistribution of this article are permitted in all media for any purpose</license-p></license></permissions><abstract><p>Within the last decade, use of Electronic Health Record (EHR) systems has become intimately integrated into healthcare practice in the United States. However, large gaps remain in the study of clinical usability and require rigorous and innovative approaches for testing usability principles. In this study, validated tools from the core functions that EHRs serve&#x02014;software, medicine and human factors&#x02014;were combined to holistically understand and objectively measure usability of medication data displays. The first phase of this study included 132 medical trainee participants who were randomized to one of two simulated EHR environments with either a medication list or a medication timeline visualization. Within these environments human-computer interaction metrics, clinical reasoning and situation awareness tests, and usability surveys captured their multi-faceted interactions. Results showed no statistically significant differences in the two displays from software and situation awareness perspectives, though there were higher statistically significant usability scores of the medication timeline (intervention) as compared to the medication list (control). This first phase of a novel design in triangulating methodologies revealed several limitations from which future experiments will be adjusted with hopes of yielding further insight and a generalizable testing platform for evolving EHR interfaces.</p></abstract></article-meta></front><body><sec id="sec1"><title>Background</title><p>In 2009, The Health Information Technology for Economic and Clinical Health (HITECH) Act passed as part of the American Recovery and Reinvestment Act to promote the adoption and meaningful use of health information technology. This law spurred the rapid adoption of electronic health record systems (EHRs) across the United States in a short period of time.<sup><xref rid="r1-2609765" ref-type="bibr">1</xref></sup> The National Center for Health Statistics (NCHS) found that the use of EHRs in hospitals, outpatient departments, and office-based practices had major increases in EHR adoption to levels of 80% usage nation-wide by 2013<sup><xref rid="r2-2609765" ref-type="bibr">2</xref></sup>, <sup><xref rid="r3-2609765" ref-type="bibr">3</xref></sup>3 With considerable incentives for rapid implementation, meeting federal guidelines has been the priority for EHR vendors over provider and patient usability.<sup><xref rid="r4-2609765" ref-type="bibr">4</xref></sup> With such precipitous EHR adoption come significant changes in the clinical workflow and the nature of medical practice. The increased frequency with which clinicians must interface with EHRs to provide patient care underscores the need for their use to be efficient and effective. According to the Healthcare Information and Management Systems Society (HIMSS) Task Force on Usability, the usability of EHRs has a direct relationship with clinical productivity, error rate, user fatigue and user satisfaction, all of which affect patient safety and health outcomes. To evaluate the usability of a tool requires measuring user efficiency, effectiveness, cognitive load and ease of learning.<sup><xref rid="r5-2609765" ref-type="bibr">5</xref></sup> The study of usability related to EHRs is a relatively new field. Thus, relevant medical literature is mostly limited to the past decade and a half. Recent systematic reviews [Harrington (2011), Clarke (2013) and Zahabi (2015)] of the literature on EHR usability and safety cover 91 publications between 2000 to 2015.<sup><xref rid="r6-2609765" ref-type="bibr">6</xref></sup><sup><xref rid="r7-2609765" ref-type="bibr">7</xref></sup>-<sup><xref rid="r8-2609765" ref-type="bibr">8</xref></sup>8 Though studies included a range of methods, including heuristic design assessment, questionnaires, semi-structured and in-depth interviews, observations and task and behavior pattern analyses, Harrington (2011) and Zahabi (2015) explicitly describe the &#x0201c;limitations of the existing body of research identifying EMR design problems, including the application of various methods of usability and safety analysis&#x0201d; in which &#x0201c;the majority of studies of EMR usability issues have employed descriptive or qualitative analysis methods.&#x0201d;<sup><xref rid="r6-2609765" ref-type="bibr">6</xref></sup>,<sup><xref rid="r7-2609765" ref-type="bibr">7</xref></sup>
<sup><xref rid="r8-2609765" ref-type="bibr">8</xref></sup> Additionally, they point out that much of the current literature identifies EHR usability issues using comparisons between paper-based systems and EHRs, but few studies include comparisons among multiple EHR designs.<sup><xref rid="r6-2609765" ref-type="bibr">6</xref></sup>,<sup><xref rid="r7-2609765" ref-type="bibr">7</xref></sup>
<sup><xref rid="r8-2609765" ref-type="bibr">8</xref></sup> There is a paucity in research on EHR usability in quantitative methodologies that capture a complete understanding of active user-application interaction and the downstream, clinical impact of EHR designs.</p><p>Precedents for quantifiably measuring software efficacy with proven validity can be found within the software industry in the form of controlled experiments. Controlled experiments are designed to establish causal relationships with high probability between certain variables. These experiments have been described in scientific literature since the early 20th century and have been well developed in the statistics community.<sup><xref rid="r9-2609765" ref-type="bibr">9</xref></sup> However, it was not until the 1990s, with the growth of the Internet that technology giants like Amazon, Facebook, Google, and Yahoo! built a culture of data-driven user interface design and enhancements.<sup><xref rid="r10-2609765" ref-type="bibr">10</xref></sup> Industry leaders like Google and Microsoft have created a software development infrastructure around controlled experiments, or software A/B testing, at its core and have propelled this method as a standard of development in the industry.<sup><xref rid="r11-2609765" ref-type="bibr">11</xref></sup>, <sup><xref rid="r12-2609765" ref-type="bibr">12</xref></sup></p><p>Based on the need for a robust quantifiable system of measurement coupled with clinical objectives, we sought to develop a framework of integrating methodologies of software A/B testing with simulated clinical decision measurements. Integrated into an infrastructure of a controlled experiment, we have built simulated electronic health record environments with two different designs that present medication history, alongside a clinical questionnaire module that prompts users to interact with the information presented in the simulated EHRs. This questionnaire seeks to measure degrees of clinical understanding and reasoning based on the way information is presented. We have utilized human factors and usability principles as defined in heuristic evaluation methodology to address several layers of reasoning.<sup><xref rid="r13-2609765" ref-type="bibr">13</xref></sup> We hypothesized that interactive software designs developed with a focus on user-experience will aid in efficient visualization of clinical information, affect understanding of patient history, improve clinical management, and ultimately provide patients with optimized medical care. Furthermore, this novel triangulated approach to comprehensively understand and measure user interactions with health informatics technologies provides a rigorous and quantifiable framework that can be agnostically applied to a variety of clinical decision support tools that may be developed in the future.</p></sec><sec id="sec2"><title>Methods</title><sec id="sec2-1"><title>Study Design</title><p>This study was a randomized, controlled trial aimed to quantifiably measure the impact of a medication timeline visualization on usability and clinical reasoning. Simulated electronic medical record environments, built as web applications, hosted the control and intervention variables (<xref ref-type="fig" rid="f1-2609765">Figure&#x000a0;1</xref> &#x00026; 2). Users were randomized to one of the two simulated EHR environments, provided a clinical scenario, then asked to interact with the EHR environment by answering a uniform set of clinical questions based on the medication information in the simulated environment. This clinical questionnaire and simulated EHR environment is referred to as the experimental &#x0201c;module&#x0201d; in this paper. The user interactions with the medication application were tracked by a web analytics platform called Optimizely, which provides robust A/B, multivariate, multi-page testing capabilities to improve user engagement. The objective metrics that Optimizely tracked in this study were: (1) the number of unique, engaged users and (2) the number of clicks inside the simulated EHR environment.<sup><xref rid="r14-2609765" ref-type="bibr">14</xref></sup> After the module was completed, users were asked to complete a multi-part survey, which reflected user opinion of the usability of the medication applications presented in the simulated EHR environments.</p></sec><sec id="sec2-2"><title>Setting and Eligibility</title><p>We obtained approval for this study through the Duke University Health System Institutional Review Board. We were granted a request to waive consent from users since there was no collection of sensitive personal health information from study subjects. Participants included medical trainees who had completed the Duke Health System&#x02019;s EHR training module that is mandatory before engaging in direct patient care. In the first phase of this experiment these medical trainees were in the following programs: Duke Physician Assistant (PA) Program and Duke University School of Medicine. The training levels of students included second year PA students and medical school students in their second year of training and above. The second phase of the study will be completed with GME Duke residents in the future. This paper only discusses the results from the first phase of this experiment.</p></sec><sec id="sec2-3"><title>Control and Intervention</title><p>The simulated EHR environment that acted as the control in this experiment was modeled after the medication list that currently exists in the major EHRs in healthcare. Currently, much of the medication information for patients exists as a list of medication names, start and end dates, instructions for taking the medications and the providers&#x02019; names that prescribed the medications. Our control web page looks similar to this model, portraying a list of a patient&#x02019;s medications and their corresponding details (<xref ref-type="fig" rid="f1-2609765">Figure&#x000a0;1</xref>). The intervention was a simulated EHR environment with a visualization of the same medication information in an interactive, chronological timeline &#x02013; one that the user can zoom in and out to see various timeframes, with a representative &#x0201c;time bar&#x0201d; at the bottom of the screen to give users easy control to define the time period of interest (<xref ref-type="fig" rid="f2-2609765">Figure&#x000a0;2</xref>). This was modeled similarly to the Belden, Plaisant, <italic>et&#x000a0;al.</italic> (2015) &#x0201c;Inspired EHR&#x0201d;, medication list.<sup><xref rid="r15-2609765" ref-type="bibr">15</xref></sup> In addition to visualizing this information with a historical and chronological lens, the intervention included filters that simplified the information. The intervention medication application included a filter for conditions that allowed users to filter the list by the condition for which a medication was prescribed. Another sorting feature was filtering by drug type. Lastly, an important visual component was the color of the timeline bars which indicated two concepts: (1) the gradation of color communicated a relative change in dose of medication, with darker shades signaling increases in dose and lighter shades signaling decreases in dose, (2) the purple and orange colors denoted pharmacy &#x0201c;fill status&#x0201d; of the medication, indicating that the medication was purchased at the pharmacy by the patient; purple indicated a filled prescription and orange indicated a non-filled prescription. For both simulated EHR settings, users could obtain detailed information by double-clicking on the medication row in the control or the medication timeline bar in the intervention. This function would open a pop-up window with more detailed information about the prescription such as the name of the provider, dosing details, directions for medication intake, number of refills and pharmacy fill status (<xref ref-type="fig" rid="f3-2609765">Figure&#x000a0;3</xref>).</p></sec><sec id="sec2-4"><title>Software A/B Testing and Objective Metrics</title><p>Prior to the experiment we determined several &#x0201c;Overall Evaluation Criteria&#x0201d; (OEC) as referred to in the software industry, or metrics of defined &#x0201c;success&#x0201d; that we wished to track in the study.<sup><xref rid="r16-2609765" ref-type="bibr">16</xref></sup> We captured these objective metrics by A/B testing software, Optimizely, while users interacted with the module. The metrics we selected were: (1) the total number of engaged, unique users, defined by the Optimizely platform as users who clicked on an element of the website and tracked by a cookie unique to their devices, and (2) the total number of clicks within the medication information application.</p></sec><sec id="sec2-5"><title>Clinical Questionnaire</title><p>The clinical questionnaire was developed to elucidate the clinical reasoning and decision-making process in the simulated EHR environment. When developing the questions and answers, we followed the principles of situational awareness assessment. Endsley, <italic>et&#x000a0;al.</italic> (2003) define three levels of situation awareness: (1) perception of the elements in the environment, (2) comprehension of the current situation, and (3) projection of future status<sup><xref rid="r17-2609765" ref-type="bibr">17</xref></sup> (Table&#x000a0;<xref ref-type="table" rid="t1-2609765">Table&#x000a0;1</xref>). The first tier, perception, entails perceiving status, attributes, and dynamics of relevant elements in the environment. In our simulation, users perceived various data elements such as medication names, start and end dates for prescriptions, colors of fill status, etc. The second tier, comprehension, involves understanding what the data and cues perceived mean in relation to relevant goals and objectives. In our simulation, users were asked to synthesize disjointed data elements to answer questions related to ultimate treatment goals. Lastly, the projection tier demands the prediction of what those data elements from the first two layers will do in the short-term future. A person can only achieve this third level of situation awareness by having a solid understanding of the situation and the dynamics of the system within which she or he is working. In our simulation, users were asked to project what treatment option would be best given their understanding of the patient&#x02019;s medication history. These three layers of situation awareness integrate perception of knowledge and the ability to prioritize and synthesize information. These are critical for efficient decision-making and effective action.</p><p>The clinical scenario was based on a fictitious patient whose situation mirrors a typical American patient in the fourth quartile of life with several chronic conditions that require numerous medications for treatment. Answers to clinical questions were based on standard of care guidelines for the pertinent clinical management of diabetes mellitus type 2, hypertension and unipolar depression.<sup><xref rid="r18-2609765" ref-type="bibr">18</xref></sup><sup><xref rid="r19-2609765" ref-type="bibr">19</xref></sup>-<sup><xref rid="r20-2609765" ref-type="bibr">20</xref></sup> The questionnaire was an embedded Qualtrics survey, a survey software platform, within the simulated EHR web environment. Qualtrics captured all questionnaire data in addition to the total time spent on the survey. The scoring of the clinical questionnaire are as follows: a total score (a measure of correctly answered questions), a tier 1 score (subset of the overall score including only perception questions), a tier 2 score (subset of the overall score including comprehension questions), a tier 3 score (subset of the overall score including projection questions), and a total time-to-complete questionnaire metric.</p></sec><sec id="sec2-9"><title>Usability Questionnaire</title><p>The usability survey was based on several validated tools in the human factors field. The survey addressed three major components: (1) ease of use (2) cognitive workload (3) user satisfaction and perception of impact. For measuring ease of use, we tailored the System Usability Survey (SUS), which has been used to evaluate a wide variety of products and services, including hardware, software, mobile devices, websites and applications. The SUS has become an industry standard, with references in over 1300 articles and publications. The benefits of using SUS are its ease of administration to participants (short length), its ability to deliver reliable results even with small sample sizes, and its proven validity<sup><xref rid="r21-2609765" ref-type="bibr">21</xref></sup>, <sup><xref rid="r22-2609765" ref-type="bibr">22</xref></sup> (<xref ref-type="fig" rid="f5-2609765">Figure&#x000a0;5</xref>). One minor change in the survey was the substitution of &#x02018;system&#x02019; with &#x02018;application&#x02019; for the sake of language consistency used throughout the study. To assess cognitive workload, we used the NASA Task Load Index (NASA-TLX). It includes six subscales that represent somewhat independent clusters of variables: Mental, Physical, and Temporal Demands, Frustration, Effort, and Performance. Since its initial development over 20 years ago, the NASA-TLX has been cited by over 5000 articles and has been used in numerous industries<sup><xref rid="r23-2609765" ref-type="bibr">23</xref></sup>, <sup><xref rid="r24-2609765" ref-type="bibr">24</xref></sup> (<xref ref-type="fig" rid="f6-2609765">Figure&#x000a0;6</xref>). To assess users&#x02019; satisfaction and perception of impact of the application, we asked three questions on their perception of the application&#x02019;s effect on their cognition, clinical management and projected patient outcomes from those decisions and actions (<xref ref-type="fig" rid="f7-2609765">Figure&#x000a0;7</xref>). Finally, there was a free text space provided for any comments, suggestions, or questions. All answer choices were on a Likert scale of one to five ranging from strongly disagree to strongly agree for ease of use (SUS) and user satisfaction, and ranging from very low to very high for cognitive workload (NASA-TLX). The published scoring rubrics for SUS and NASA-TLX were used to score these data.<sup><xref rid="r21-2609765" ref-type="bibr">21</xref></sup><sup><xref rid="r22-2609765" ref-type="bibr">22</xref></sup><sup><xref rid="r23-2609765" ref-type="bibr">23</xref></sup>-<sup><xref rid="r24-2609765" ref-type="bibr">24</xref></sup> A modification of the NASA-TLX involved weighting each question equally, and scoring answers from one to five based on whether the question was &#x0201c;positive&#x0201d; or &#x0201c;negative.&#x0201d;<sup><xref rid="r23-2609765" ref-type="bibr">23</xref></sup>, <sup><xref rid="r25-2609765" ref-type="bibr">25</xref></sup></p><sec id="sec3"><title>Analysis</title><p>In this randomized experiment, 132 participants who completed the module were randomized to a standard and an innovative EHR environment. Testing the superiority of the two arms was accomplished with a two-sided t-test for the average of two independent samples. The significance level (alpha) was set at 0.05. Each data collection instrument captured different, yet important data, from which various metrics were derived. All of these metrics were considered equal and no primary analysis was defined <italic>a priori</italic>.</p></sec><sec id="sec4"><title>Results</title><sec id="sec4-1"><title>Demographics</title><p>Of the 132 participants in Phase 1 who completed the entirety of the module, 72% (95 participants) were second to fifth year medical students and 28% (37 participants) were second-year physician assistant students. There are fluctuations in the total number of participants in the various portions of the study module. This limitation is discussed in the following section. All participants received EHR training through modules set by the Duke University Health System as part of patient safety certification before engaging in clinical duties. All participants had at least 10 months of EHR experience at the time this study was conducted.</p><p>The results of the control and intervention arms from all three areas of methodology (software, clinical and situation awareness, and human factors) are included in Table&#x000a0;<xref ref-type="table" rid="t2-2609765">Table&#x000a0;2</xref>. There is a difference in total number of recorded engaged users as measured by Optimizely and the total number of recorded participants for the clinical questionnaire and usability surveys. This difference is attributed to the attrition of users who engaged with the module but did not complete the entirety of the module. These results show several noteworthy items: 1) The intervention showed more than double the click rate per user than the control; 2) there was an insignificant difference between both arms in clinical questionnaire scores or timing, however, there was 3) a significant difference showing better usability for the intervention than the control as measured by SUS and user satisfaction surveys (p-value 0.02 and 0.00014 respectively).</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec id="sec6-1"><title>Software Analytics and Usability</title><p>The fields of software analytics and human-computer interaction generally correlate a high number of clicks with increased user workload. In this experiment, Optimizely data demonstrated more than double the number of clicks in absolute total and per user number of clicks in the intervention compared to the control. From the conventional perspective, this could be interpreted as the intervention visualization being more &#x0201c;burdensome&#x0201d; on users. However, the features of the medication timeline, which are interactive by nature, include an array of additional functionality, which require users to interact with the information (zoom, drag and drop, filter, set scope of timeframe). This is in contrast with the medication list, which has a single function of scrolling vertically up and down to see a full list of medications. Other than the granular window feature (<xref ref-type="fig" rid="f3-2609765">Figure&#x000a0;3</xref>), the two arms of the study had drastically different presentations of medication data. In combining this insight with the usability survey results, which indicate a higher statistically significant score for the medication timeline in its ease of use and user satisfaction, it is clear that despite the larger number of clicks for the intervention, its reported usability was greater. The NASA-TLX scores show a higher average score for the intervention as well though this is not statistically significant. In sampling user comments and suggestions, there was a greater number of comments overall for the control medication list (30 comments) as compared to those received for the intervention medication timeline (17 comments). Though limited by subjective assessment, several of the comments for the medication list involved suggestions that were being executed in the medication timeline such as filters for conditions, current medication list, color-coded fill and unfilled prescription data. Contrarily, many comments in the intervention were positive reactions to the new interface with adjustments for optimized ergonomic design that would be helpful in the future.</p></sec><sec id="sec6-2"><title>Clinical Reasoning and Total Duration</title><p>The primary hypothesis was that the medication timeline would be more effective in aiding users to answer the questions in all three tiers of situation awareness with higher accuracy. Interestingly, there is no statistically significant difference in the clinical questionnaire scores between control and intervention. This holds true for the total average score as well as the scores by situation awareness tier. Users generally scored well on the clinical questionnaire with average scores of 80-85%. This indicated that on all levels, despite the type of program used to obtain medication data, medical trainees are able to find the information, interpret it and project clinical reasoning based on the information to a high degree of accuracy. We wanted to explore whether the medication list or timeline formats varied with respect to total time spent on the clinical module. We hypothesized that participants would require more time to complete the clinical module using the control interface than when using the intervention. Again, time to complete the module was similar across interfaces. These findings indicate that, when given a generous time limit (30 minutes), all questions can be answered accurately in both the intervention and control formats. There may be a &#x0201c;ceiling&#x0201d; effect where users, when given ample time, are able to overcome the difficulty of interacting with the control interface and correctly respond to clinical questions.</p><sec id="sec7"><title>Limitations</title><p><bold><italic>Completion Rates</italic></bold> - While the web application distribution of the clinical study allowed us to capture an overall completion rate of approximately 132 participants as defined by those who completed the last step of the study, the major limitation of such a distribution was the inconsistency in completion rates of the entire module, where there was a greater attrition rate as the module progressed.</p><p><bold><italic>Optimizely Set-up</italic></bold> - When comparing the number of clicks between the control and intervention arms, due to the inherent difference in the nature of how the information is presented, there is a stark contrast in the way users interact with the medication list versus the medication timeline. Because of this difference, the objective metric of total number of clicks was not a fair metric of comparison between the two arms of the study.</p><p><bold><italic>Clinical Reasoning and Time Pressure</italic></bold> - There is a limit to the difficulty of a question that can be asked in the clinical questionnaire before it verges on relying on medical expertise. The purpose of the clinical questionnaire and three tiers of reasoning was to ask clinical questions typical of those a primary care physician asks when attempting to understand a patient&#x02019;s history via the EHR. However, as demonstrated in this experiment, the ample time given to users allowed them to accurately answer many of these questions in both arms of the study and did not create the common &#x0201c;time pressure&#x0201d; experienced by physicians in a real clinical setting.</p><p><bold><italic>Adjustment to New Models of Visualization</italic></bold> - There is yet a question of how much exposure to or practice with a new application is needed before a user is well adjusted. As with any new skill, with learning a new application, there is a learning curve: users first recognize the features of the application, learn to effectively use them, and then practice to use them efficiently. As one user in the medication timeline arm of the study noted: &#x0201c;I got more used to it while using it just in the 20 or so minutes.&#x0201d; This is a significant variable that distinguishes the intervention from the control. The control medication list is familiar to users who have been trained in a &#x0201c;typical&#x0201d; EHR with a similar medication data presentation. There is not an interactive visualization in a typical EHR system that includes the types of functionalities (zoom, filtering, setting timeline parameters) presented in our intervention. Hence, the learning curve of first exposure may have been a key limitation in accurately measuring user interaction with the intervention compared to the control.</p></sec><sec id="sec8"><title>Future directions</title><p>In order to address the limitations outlined in the previous section, we will adjust the design of the second phase of this experiment. The second cohort will include medical trainees in the Duke Graduate Medical Education (GME) Internal Medicine and Psychiatry Residencies.</p><p><bold><italic>Unique User Tracking and Research Subject Anonymity</italic></bold> - The inconsistent completion rates were one limitation of the web distribution of the study module. There was no mechanism to track unique user data from one portion of the study (ie. the clinical questionnaire) to the data of the usability. Hence, data analysis in Phase 1 was limited to the aggregate averages with varying total number of participants per section. In Phase 2 of this study, in order to link and track unique users who complete the entire module from beginning to end, while still maintaining anonymity by keeping the contact information collected for award purposes, we will use the methodology of &#x0201c;piping text&#x0201d; to carry over unique response IDs through the survey collection system (Qualtrics). This will allow us to tie clinical reasoning data to usability data in a 1:1 ratio for rigorous integrity in the data analysis of these surveys. In addition, the feature to &#x0201c;prevent ballot box stuffing,&#x0201d; or to allow one survey attempt per user will be enabled via Qualtrics.</p><p><bold><italic>Optimizely Set-up for Fair Comparison</italic></bold> - Because of the explicit differences in the interaction required for the medication list versus the timeline, in order to have a fair comparison of the control and intervention for the metric of the number of clicks, we devised a &#x0201c;goal&#x0201d; measurement on a feature that is consistent between the two arms. The granular window that pops-up when users double-click on the medication list item or bar contains identical information. The act of &#x0201c;mining&#x0201d; for more granular data is parallel in the control and intervention. Hence, we will add a click tracker to the &#x0201c;close&#x0201d; button on the window of both arms via Optimizely. This will be a proxy to how many times users were clicking to access more detailed data in the control versus the intervention.</p><p><bold><italic>Clinical Reasoning and Simulated Clinical Time Pressure</italic></bold> - The results of the clinical questionnaire showed a high percentage of accuracy on the clinical questionnaire in both arms with no significant difference between their average scores. The average amount of time spent on the module was approximately 13 minutes for both arms, with a range of 1 minute to 30 minutes. A majority of the users spent between 10-15 minutes on the clinical module portion, which demonstrates the approximate amount of time necessary to thoroughly go through the clinical vignette, interact with the medication information and answer the clinical questions. Based on this time average from phase 1 of the study, in the proceeding phase we will create a time pressure that gives users a cut-off time limit of 8 minutes which will simulate the typical time pressure felt by clinicians in situations of patient care. We believe this type of pressure will allow us to spread the user accuracy curve and hypothesize that we will see a significant difference in accuracy between the control and intervention arms when under such pressure to quickly analyze and mine information.</p><p><bold><italic>Learning Curve of a New Visualization</italic></bold> - In order to address the learning curve of a first time exposure, we are setting up a &#x0201c;playground&#x0201d; in which users will be able view their respective, randomized video tutorial of how to navigate the simulated EHR and medication information, then link to their respective practice simulated environment to allow users to gain familiarity with the type of visualization and its features before beginning the clinical module. This playground will be limited to 2 minutes on each arm of the study.</p><p>As we move to the second phase of this study, with the improvements listed above, we note that this is the first report of a platform for objectively measuring EHR user interfaces and experience using a triangulated approach for measuring objective and subjective data. Our pilot experiment suggests that, with further refinements, this is a viable and scalable tool with which to move EHRs and their associated workflows to more user-friendly and efficient experiences.</p></sec></sec></sec></sec></sec></body><back><ref-list><title>References</title><ref id="r1-2609765"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandl</surname><given-names>K. D.</given-names></name><name><surname>Khorasani</surname><given-names>R.</given-names></name><name><surname>Kohane</surname><given-names>I. S.</given-names></name></person-group><article-title>Meaningful use of electronic health records</article-title><source>Health Affairs</source><year>2012</year><volume>31</volume><issue>6</issue><fpage>1365</fpage></element-citation></ref><ref id="r2-2609765"><label>2</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jamoom</surname><given-names>E</given-names></name><name><surname>Hing</surname><given-names>E.</given-names></name></person-group><article-title>Progress with electronic health record adoption among emergency and outpatient departments: United States, 2006&#x02013;2011.</article-title><source>NCHS data brief, no 187</source><year>2015</year><publisher-loc>Hyattsville, MD</publisher-loc><publisher-name>National Center for Health Statistics</publisher-name><fpage>2015</fpage></element-citation></ref><ref id="r3-2609765"><label>3</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hsiao</surname><given-names>C-J</given-names></name><name><surname>Hing</surname><given-names>E.</given-names></name></person-group><article-title>Use and characteristics of electronic health record systems among office-based physician practices: United States, 2001&#x02013;2013.</article-title><source>NCHS data brief, no 143</source><year>2014</year><publisher-loc>Hyattsville, MD</publisher-loc><publisher-name>National Center for Health Statistics 2014</publisher-name></element-citation></ref><ref id="r4-2609765"><label>4</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Wachter</surname><given-names>R.</given-names></name></person-group><article-title>The Digital Doctor: Hope, Hype, and Harm at the Dawn of Medicine&#x02019;s Computer Age.</article-title><year>2015</year><comment>McGraw Hill Professional; 2015</comment></element-citation></ref><ref id="r5-2609765"><label>5</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Belden</surname><given-names>J</given-names></name><name><surname>Grayson</surname><given-names>R</given-names></name><name><surname>Barnes</surname><given-names>J.</given-names></name></person-group><source>Defining and Testing EMR Usability: Principles and Proposed Methods of EMR Usability Evaluation and Rating.</source><year>2009</year><comment><ext-link ext-link-type="uri" xlink:href="https://www.himss.org/sites/himssorg/files/HIMSSorg/Content/files/HIMSS_DefiningandTestingEMRUsability.pdf">https://www.himss.org/sites/himssorg/files/HIMSSorg/Content/files/HIMSS_DefiningandTestingEMRUsability.pdf</ext-link>. June 2009.</comment></element-citation></ref><ref id="r6-2609765"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrington</surname><given-names>L</given-names></name><name><surname>Kennerly</surname><given-names>D</given-names></name><name><surname>Johnson</surname><given-names>C.</given-names></name></person-group><article-title>Safety issues related to the electronic medical record (EMR): synthesis of the literature from the last decade, 2000&#x02013;2009.</article-title><source>J Healthc Manag</source><year>2009</year><volume>56</volume><issue>1</issue><fpage>31</fpage><lpage>43</lpage><comment>2011</comment></element-citation></ref><ref id="r7-2609765"><label>7</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>M</given-names></name><name><surname>Steege</surname><given-names>L</given-names></name><name><surname>Moore</surname><given-names>J</given-names></name><name><surname>Belden</surname><given-names>J</given-names></name><name><surname>Koopman</surname><given-names>R</given-names></name><name><surname>Kim</surname><given-names>M.</given-names></name></person-group><source>Addressing Human Computer Interaction Issues of Electronic Health Record in Clinical Encounters. Design, User Experience, and Usability: User Experience Design for Everyday Life Applications and Services</source><year>2014</year><conf-loc>Third International Conference, DUXU 2014, Held as Part of HCI International 2014, Heraklion, Crete, Greece, June 22-27, 2014,</conf-loc><comment>Proceedings. Springer</comment></element-citation></ref><ref id="r8-2609765"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahabi</surname><given-names>M</given-names></name><name><surname>Kaber</surname><given-names>D</given-names></name><name><surname>Swangnetr</surname><given-names>M.</given-names></name></person-group><article-title>Usability and Safety in Electronic Medical Records Interface Design: A Review of Recent Literature and Guideline Formulation.</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><year>2015</year><volume>57</volume><issue>5</issue><fpage>805</fpage><lpage>834</lpage></element-citation></ref><ref id="r9-2609765"><label>9</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Box</surname><given-names>G</given-names></name><name><surname>Hunter</surname><given-names>J</given-names></name><name><surname>William</surname><given-names>G.</given-names></name></person-group><source>Statistics for Experimenters: Design, Innovation, and Discovery.</source><year>2005</year><publisher-name>John Wiley &#x00026; Sons, Inc.</publisher-name></element-citation></ref><ref id="r10-2609765"><label>10</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kohavi</surname><given-names>R.</given-names></name></person-group><article-title>Online controlled experiments.</article-title><source>Proceedings of the Sixth ACM Conference on Recommender Systems - RecSys &#x02018;12.</source><year>2012</year></element-citation></ref><ref id="r11-2609765"><label>11</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>D</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name><name><surname> O'brien,</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name></person-group><article-title>Overlapping experiment infrastructure.</article-title><source>Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD &#x02018;10.</source><year>2010</year></element-citation></ref><ref id="r12-2609765"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohavi</surname><given-names>R</given-names></name><name><surname>Longbotham</surname><given-names>R</given-names></name><name><surname>Sommerfield</surname><given-names>D</given-names></name><name><surname>Henne</surname><given-names>R.</given-names></name></person-group><article-title>Controlled experiments on the web: Survey and practical guide</article-title><source>Data Mining and Knowledge Discovery Data Min Knowl Disc</source><year>2008</year><volume>18</volume><issue>1</issue><fpage>140</fpage><lpage>181</lpage></element-citation></ref><ref id="r13-2609765"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumas</surname><given-names>J</given-names></name><name><surname>Salzman</surname><given-names>M.</given-names></name></person-group><article-title>Usability Assessment Methods</article-title><source>Reviews of Human Factors and Ergonomics</source><year>2006</year><volume>2</volume><issue>1</issue><fpage>109</fpage><lpage>140</lpage></element-citation></ref><ref id="r14-2609765"><label>14</label><element-citation publication-type="webpage"><collab>Optimizely: Optimizely: Let&#x02019;s optimize digital experiences for your customers</collab><year>2016</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="https://www.optimizely.com/">https://www.optimizely.com/</ext-link></comment></element-citation></ref><ref id="r15-2609765"><label>15</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Belden</surname><given-names>J</given-names></name><name><surname>Plaisant</surname><given-names>C</given-names></name><name><surname>Johnson</surname><given-names>T.</given-names></name></person-group><source>Inspired EHRs: Designing for Clinicians. (2014)</source><year>2014</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://inspiredehrs.org/">http://inspiredehrs.org/</ext-link></comment></element-citation></ref><ref id="r16-2609765"><label>16</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>R. K.</given-names></name></person-group><source>Design of experiments using the Taguchi approach: 16 steps to product and process improvement.</source><year>2001</year><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="r17-2609765"><label>17</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Endsley</surname><given-names>MR</given-names></name><name><surname>Bolte</surname><given-names>B</given-names></name><name><surname>Jones</surname><given-names>DG</given-names></name></person-group><source>Designing for situation awareness: An approach to user-centered design.</source><year>2003</year><publisher-loc>Boca Raton, FL</publisher-loc><publisher-name>CRC Press</publisher-name><comment>2003</comment></element-citation></ref><ref id="r18-2609765"><label>18</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>McCulloch</surname><given-names>D</given-names></name><name><surname>Nathan</surname><given-names>D</given-names></name><name><surname>Mulder</surname><given-names>J</given-names></name></person-group><source>Initial management of blood glucose in adults with type 2 diabetes mellitus.</source><year>2015</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://www.uptodate.com/contents/initial-management-of-blood-glucose-in-">http://www.uptodate.com/contents/initial-management-of-blood-glucose-in-</ext-link> adults-with-type-2-diabetes-mellitus.</comment></element-citation></ref><ref id="r19-2609765"><label>19</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Mann</surname><given-names>J.</given-names></name></person-group><article-title>Choice of drug therapy in primary (essential) hypertension</article-title><year>2015</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://www.uptodate.com/contents/choice-of-drug-therapy-in-primary-essential-hypertension">http://www.uptodate.com/contents/choice-of-drug-therapy-in-primary-essential-hypertension</ext-link></comment></element-citation></ref><ref id="r20-2609765"><label>20</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>G</given-names></name><name><surname>Ciechanowski</surname><given-names>P.</given-names></name></person-group><source>Unipolar major depression in adults: Choosing initial treatment</source><year>2015</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://www.uptodate.com/contents/unipolar-major-depression-in-adults-choosing-initial-treatment">http://www.uptodate.com/contents/unipolar-major-depression-in-adults-choosing-initial-treatment</ext-link>.</comment></element-citation></ref><ref id="r21-2609765"><label>21</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Brooke</surname><given-names>J.</given-names></name></person-group><source>SUS - A quick and dirty usability scale</source><year>1986</year><comment>Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://www.usabilitynet.org/trump/documents/Suschapt.doc">http://www.usabilitynet.org/trump/documents/Suschapt.doc</ext-link></comment></element-citation></ref><ref id="r22-2609765"><label>22</label><element-citation publication-type="webpage"><year>2016</year><comment>System Usability Scale (SUS). (2016). Retrieved May 16, 2016, from <ext-link ext-link-type="uri" xlink:href="http://www.usability.gov/how-to-and-">http://www.usability.gov/how-to-and-</ext-link> tools/methods/system-usability-scale.html.</comment></element-citation></ref><ref id="r23-2609765"><label>23</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>S</given-names></name><name><surname>Staveland</surname><given-names>L.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Hancock</surname><given-names>P. A.</given-names></name><name><surname>Meshkati</surname><given-names>N.</given-names></name></person-group><article-title>Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research</article-title><source>Human Mental Workload.</source><year>1988</year><edition>(Eds.)</edition><publisher-loc>Amsterdam</publisher-loc><publisher-name>North Holland Press</publisher-name></element-citation></ref><ref id="r24-2609765"><label>24</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>S. G.</given-names></name></person-group><article-title>NASA-task load index (NASA-TLX); 20 years later.</article-title><source>PsycEXTRA Dataset</source><year>2006</year></element-citation></ref><ref id="r25-2609765"><label>25</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Geddie</surname><given-names>JC</given-names></name><name><surname>Boer</surname><given-names>LC</given-names></name><name><surname>Edwards</surname><given-names>RJ</given-names></name><etal/></person-group><article-title>NATO Guidelines on Human Engineering Testing and Evaluation</article-title><source>Neuilly- sur-Seine Cedex: NATO;</source><year>2001</year></element-citation></ref></ref-list></back><floats-group><fig id="f1-2609765" position="float"><label>Figure&#x000a0;1.</label><caption><p>Simulated EHR with Control Medication List</p></caption><graphic xlink:href="2609765f1"/></fig><fig id="f2-2609765" position="float"><label>Figure&#x000a0;2.</label><caption><p>Simulated EHR with Intervention Medication Timeline</p></caption><graphic xlink:href="2609765f2"/></fig><fig id="f3-2609765" position="float"><label>Figure&#x000a0;3.</label><caption><p>Granular Prescription Data Window</p></caption><graphic xlink:href="2609765f3"/></fig><fig id="f5-2609765" position="float"><label>Figure&#x000a0;5.</label><caption><p>System Usability Scale (SUS)</p></caption><graphic xlink:href="2609765f5"/></fig><fig id="f6-2609765" position="float"><label>Figure&#x000a0;6.</label><caption><p>NASA - Task Load Index (NASA-TLX)</p></caption><graphic xlink:href="2609765f6"/></fig><fig id="f7-2609765" position="float"><label>Figure&#x000a0;7.</label><caption><p>User Satisfaction Questions</p></caption><graphic xlink:href="2609765f7"/></fig><table-wrap id="t1-2609765" position="float"><label>Table&#x000a0;1.</label><caption><p>Clinical Questionnaire Based on Situation Awareness</p></caption><table frame="box" rules="none"><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Clinical Vignette</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Meet Mr. Smith. He is a 62 year old gentleman living in Durham, NC with his family. He has been seeing Dr. Bradley as his primary care provider for over 20 years. After a long, prolific career, Dr. Bradley, who is one of your partners in the practice, is retiring. You are now adopting Mr. Smith as a new patient.</td><td valign="top" align="left" rowspan="1" colspan="1">His past medical history includes:</td><td valign="top" align="left" rowspan="1" colspan="1"><list list-type="bullet"><list-item><p>&#x02022; Obesity</p></list-item><list-item><p>&#x02022; Hypertension</p></list-item><list-item><p>&#x02022; Type 2 Diabetes</p></list-item><list-item><p>&#x02022; Gout</p></list-item><list-item><p>&#x02022; Depression</p></list-item><list-item><p>&#x02022; Community-Acquired Pneumonia</p></list-item></list></td><td valign="top" align="left" rowspan="1" colspan="1">He has come in today for three reasons. He would like to:</td><td valign="top" align="left" rowspan="1" colspan="1"><list list-type="order"><list-item><p>Discuss his most recent HbA1c of 8.4% despite taking his diabetes medications</p></list-item><list-item><p>Discuss his last elevated blood pressure readings despite changes in his medications</p></list-item><list-item><p>Discuss his depressed mood and decreased interest in activities recently</p></list-item></list></td><td valign="top" align="left" rowspan="1" colspan="1">Your objectives:</td><td valign="top" align="left" rowspan="1" colspan="1"><list list-type="order"><list-item><p>Concerning his diabetes, you can trust that he has been on a diabetic diet with regular exercise. You would like to assess his past and current regimen of medications for his Type 2 Diabetes and <underline>see if an additional</underline>
<underline>agent is necessary to prescribe today</underline>.</p></list-item><list-item><p>For his hypertension, despite taking his new hypertensive medication diligently for the last year, his hypertension has not changed. Trends of blood pressure readings in the last year and a half have shown &#x0003e; 145/95 (JNC 8 recommends treatment for &#x0003e; 140/90). He has been trialed on several different types of medications. <underline>You would</underline>
<underline>like to assess what additional changes in his regimen may be required</underline> today.</p></list-item><list-item><p>For his depression, after assessing any changes that may have caused an increase in depressive symptoms, <underline>you would like to assess</underline>
<underline>his current depression medications and understand his treatment course</underline>
<underline>up until now</underline>.</p></list-item></list></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Tier 1 - Perception Example</td><td valign="top" align="left" rowspan="1" colspan="1">Which medication(s) is the patient currently taking for diabetes?</td><td valign="top" align="left" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>metformin</p></list-item><list-item><p>insulin</p></list-item><list-item><p>lisinopril</p></list-item><list-item><p>glipizide</p></list-item><list-item><p>amlodipine</p></list-item></list>
</td><td valign="top" align="left" rowspan="1" colspan="1"><bold><italic>Tier 2 - Comprehension Example</italic></bold></td><td valign="top" align="left" rowspan="1" colspan="1">Over time, Mr. Smith&#x02019;s blood pressure still continued to increase despite his compliance with his hydrochlorothiazide (HCTZ). Another medication was added to his hypertension medication regimen. Which new class of hypertensive medication was added?</td><td valign="top" align="left" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Calcium channel blockers</p></list-item><list-item><p>ACE inhibitors</p></list-item><list-item><p>Alpha agonist</p></list-item><list-item><p>Thiazides</p></list-item></list></td><td valign="top" align="left" rowspan="1" colspan="1"><bold><italic>Tier 3 - Projection Example</italic></bold></td><td valign="top" align="left" rowspan="1" colspan="1">Why do you think the provider chose bupropion to prescribe in 2006?</td><td valign="top" align="left" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>The patient may have been experiencing side effects of Sertraline, therefore switched to Bupropion as monotherapy instead.</p></list-item><list-item><p>Bupropion is in the SSRI drug class. The provider may have desired to try another SSRI agent.</p></list-item><list-item><p>Sertraline was used as a monotherapy and was escalated in dose. It may not have been effective at the high dose, and therefore another agent, Bupropion was added.</p></list-item><list-item><p>Bupropion was effective for this patient when it was used 10 years ago.</p></list-item></list></td></tr></tbody></table><table-wrap-foot><fn id="tf1-2609765"><p>**Of note: For the purposes of the experiment, FILL STATUS will imply compliance to medications.**</p></fn></table-wrap-foot></table-wrap><table-wrap id="t2-2609765" position="float"><label>Table&#x000a0;2.</label><caption><p>Control and Intervention Data from Triangulation of Methodologies</p></caption><table frame="box" rules="none"><thead><tr><th valign="top" align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Intervention</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>P-value (&#x0003c;0.05)</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">(1) Software Analytics &#x02013; <italic>Optimizely</italic></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Engaged users</td><td valign="top" align="center" rowspan="1" colspan="1">64</td><td valign="top" align="center" rowspan="1" colspan="1">78</td><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Average Clicks Per User</td><td valign="top" align="center" rowspan="1" colspan="1">32</td><td valign="top" align="center" rowspan="1" colspan="1">69</td><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="center" colspan="3" rowspan="1"><bold>2) Clinical Reasoning &#x00026; Situational Awareness - <italic>Clinical Questionnaire</italic></bold></td><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Participants</td><td valign="top" align="center" rowspan="1" colspan="1">65</td><td valign="top" align="center" rowspan="1" colspan="1">68</td><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Total Average Score</td><td valign="top" align="center" rowspan="1" colspan="1">20.4 out of 24 (SD 4.6)</td><td valign="top" align="center" rowspan="1" colspan="1">19.0 out of 24 (SD 4.6)</td><td valign="top" align="center" rowspan="1" colspan="1">0.09</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Tier 1 Score (Perception)</td><td valign="top" align="center" rowspan="1" colspan="1">5.6 out of 6 (SD 1.18)</td><td valign="top" align="center" rowspan="1" colspan="1">5.37 out of 6 (SD 1.19)</td><td valign="top" align="center" rowspan="1" colspan="1">0.27</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Tier 2 Score (Comprehension)</td><td valign="top" align="center" rowspan="1" colspan="1">10.95 out of 11 (SD 2.67)</td><td valign="top" align="center" rowspan="1" colspan="1">10.06 out of 11 (SD 2.71)</td><td valign="top" align="center" rowspan="1" colspan="1">0.06</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Tier 3 Score (Projection)</td><td valign="top" align="center" rowspan="1" colspan="1">3.8 out of 5 (SD 1.17)</td><td valign="top" align="center" rowspan="1" colspan="1">3.38 out of 5 (SD 1.28)</td><td valign="top" align="center" rowspan="1" colspan="1">0.31</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Average Total Duration</td><td valign="top" align="center" rowspan="1" colspan="1">12.77&#x000a0;min (SD 5.04)</td><td valign="top" align="center" rowspan="1" colspan="1">13.59&#x000a0;min (SD 5.68)</td><td valign="top" align="center" rowspan="1" colspan="1">0.39</td></tr><tr><td valign="top" align="center" colspan="4" rowspan="1"><bold>(3) Human Factors - <italic>System Usability Scale (SUS), NASA - Task Load Index (TLX), User Satisfaction</italic></bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SUS</td><td valign="top" align="center" rowspan="1" colspan="1">43.9 out of 50 (SD 12.7)</td><td valign="top" align="center" rowspan="1" colspan="1">49.1 out of 50 (SD 13.0)</td><td valign="top" align="center" rowspan="1" colspan="1">0.02</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">NASA &#x02013; TLX</td><td valign="top" align="center" rowspan="1" colspan="1">72.4 out of 100 (SD 14.4)</td><td valign="top" align="center" rowspan="1" colspan="1">76.2 out of 100 (SD 14.9)</td><td valign="top" align="center" rowspan="1" colspan="1">0.14</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">User Satisfaction</td><td valign="top" align="center" rowspan="1" colspan="1">10.73 out of 15 (SD 3.13)</td><td valign="top" align="center" rowspan="1" colspan="1">12.28 out of 15 (SD 2.25)</td><td valign="top" align="center" rowspan="1" colspan="1">0.0014</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold><italic>User Comments and Suggestions</italic></bold></td><td valign="top" align="left" rowspan="1" colspan="1"><bold>Medication List (Control)</bold></td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;This application is significantly improved over the current medication display in [our EHR]. One issue I ran into is that a lot of the questions were about drugs prescribed for particular conditions, and there was no clear way to identify an indication within this display. I would also like it if the current drugs were more clearly identified, as by a different color, or something like that.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;It would be better if medications were categorized according to which chronic condition they were prescribed for. You could click on the chronic condition, and then see the medications that had been prescribed.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;A few more columns with additional information available would be nice to avoid having to click on small rows to get a specific medication. Also, it might be nice to have prescriptions ranging from most recent to oldest. This would alleviate having to repeatedly scroll up and down a long list and look closely at the dates to see which one you want to click on. Finally, some additional drug information would be nice - maybe a free text box for why it was prescribed, dose changed, etc.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>Medication Timeline (Intervention)</bold></td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Really fantastically designed and easy to use MAR. However, to be truly useful, it would require patients to have been part of a single EMR (or a linked EMR) for the duration of their treatments, which often is not the case. I believe that a situation similar to the case presented here, in which a patient was followed for 20-years, would be extremely rare.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;I liked how the medication information was split up by class and condition. This made it easier to track medication changes. While I liked being able to see all the medication across their lifespan of being prescribed, I didn&#x02019;t like how I had to click on the bar to get more information about the prescription. I also didn&#x02019;t like how I had to zoom in/out in order to see the information I wanted.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;[The intervention] was extremely intuitive and easy to use. I watched the video tutorial, but think that I could&#x02019;ve easily figured it out if I was asked to use it without prior instruction. I want this program in my life now!!!</td></tr></tbody></table></table-wrap></floats-group></article>