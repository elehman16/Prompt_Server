<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26029138</article-id><article-id pub-id-type="pmc">4428074</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2015.00598</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>An eye movement pre-training fosters the comprehension of processes and functions in technical systems</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Skuballa</surname><given-names>Irene T.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/207156"/></contrib><contrib contrib-type="author"><name><surname>Fortunski</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Renkl</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/162971"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Applied Cognitive Psychology and Media Psychology, University of T&#x000fc;bingen</institution><country>T&#x000fc;bingen, Germany</country></aff><aff id="aff2"><sup>2</sup><institution>Educational and Developmental Psychology, University of Freiburg</institution><country>Freiburg, Germany</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Bernhard Hommel, Leiden University, Netherlands</p></fn><fn fn-type="edited-by"><p>Reviewed by: Ulrich Ansorge, University of Vienna, Austria; Agnieszka Wykowska, Ludwig-Maximilians-Universit&#x000e4;t, Germany</p></fn><corresp id="fn001">*Correspondence: Irene T. Skuballa, Faculty of Science, Department of Applied Cognitive Psychology and Media Psychology, University of T&#x000fc;bingen, Schleichstr. 4, 72076 T&#x000fc;bingen, Germany <email xlink:type="simple">irene.skuballa@uni-tuebingen.de</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Cognition, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>12</day><month>5</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>6</volume><elocation-id>598</elocation-id><history><date date-type="received"><day>28</day><month>1</month><year>2015</year></date><date date-type="accepted"><day>22</day><month>4</month><year>2015</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2015 Skuballa, Fortunski and Renkl.</copyright-statement><copyright-year>2015</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>The main research goal of the present study was to investigate in how far pre-training eye movements can facilitate knowledge acquisition in multimedia (pre-training principle). We combined considerations from research on eye movement modeling and pre-training to design and test a non-verbal eye movement-based pre-training. Participants in the experimental condition watched an animated circle moving in close spatial resemblance to a static visualization of a solar plant accompanied by a narration in a subsequently presented learning environment. This training was expected to foster top-down processes as reflected in gaze behavior during the learning process and enhance knowledge acquisition. We compared two groups (<italic>N</italic> = 45): participants in the experimental condition received pre-training in a first step and processed the learning material in a second step, whereas the control group underwent the second step without any pre-training. The pre-training group outperformed the control group in their learning outcomes, particularly in knowledge about processes and functions of the solar plant. However, the superior learning outcomes in the pre-training group could not be explained by eye-movement patterns. Furthermore, the pre-training moderated the relationship between experienced stress and learning outcomes. In the control group, high stress levels hindered learning, which was not found for the pre-training group. On a delayed posttest participants were requested to draw a picture of the learning content. Despite a non-significant effect of training on the quality of drawings, the pre-training showed associations between learning outcomes at the first testing time and process-related aspects in the quality of their drawings. Overall, non-verbal pre-training is a successful instructional intervention to promote learning processes in novices although these processes did not directly reflect in learners' eye movement behavior during learning.</p></abstract><kwd-group><kwd>eye movement</kwd><kwd>pre-training</kwd><kwd>top-down process</kwd><kwd>stress</kwd><kwd>learning</kwd></kwd-group><counts><fig-count count="5"/><table-count count="2"/><equation-count count="0"/><ref-count count="39"/><page-count count="13"/><word-count count="10114"/></counts></article-meta></front><body><sec sec-type="introduction" id="s1"><title>Introduction</title><p>The present study investigates a non-verbal eye movement pre-training on learning. This instructional intervention was designed to foster the comprehension of processes and functions in a static representation of a technical system. Research on the pre-training principle in multimedia demonstrates that prior knowledge provokes top-down processes and can enhance understanding of unfamiliar materials (Mayer, <xref rid="B25" ref-type="bibr">2009</xref>). Feedforward trainings and modeling of eye movements were shown successful in guiding learners' visual attention and in enhancing comprehension (Nalanagula et al., <xref rid="B28" ref-type="bibr">2006</xref>; Jarodzka et al., <xref rid="B15" ref-type="bibr">2013</xref>). Based on these findings, we introduce a pre-training which provides prior knowledge about motions of flow in the to-be-learned technical system by guiding learners' eye movements in a content-free environment without verbalizing any further information. The eye movement pre-training is characterized by dynamic events through guided eye movements that should be originally and &#x0201c;naturally&#x0201d; accomplished when actively processing the displayed technical system by mental simulation.</p><p>The rationale behind our research was to manipulate top-down processes via prior knowledge about dynamic processes (Kriz and Hegarty, <xref rid="B19" ref-type="bibr">2007</xref>; Lowe and Boucheix, <xref rid="B22" ref-type="bibr">2008</xref>). We tested whether the pre-training would have a transfer effect on the subsequently presented technical system and, as a consequence, lead to better learning outcomes. In addition, we tested the effects of pre-training on learners' eye movement behavior, cognitive load, and experienced stress levels during the learning phase.</p></sec><sec><title>Importance of prior knowledge</title><p>The perception of an external stimulus presented on a screen marks the starting point of multimedia learning (Hegarty, <xref rid="B9" ref-type="bibr">2005</xref>; Mayer, <xref rid="B25" ref-type="bibr">2009</xref>). This learning process is guided actively through enhancing attention allocation processes. Only information (i.e., visual and auditory) that is actively processed can be encoded and incorporated into an internal representation of the subject matter. During the course of learning different pieces of information are connected with learners' prior knowledge and integrated into an internal mental representation.</p><p>The framework proposed by Kriz and Hegarty (<xref rid="B19" ref-type="bibr">2007</xref>) distinguishes two perspectives on the comprehension of multimedia: a top-down and a bottom-up perspective. The bottom-up perspective interprets learning as a result of the quality of the displayed representation. Bottom-up processes are automatic and driven by properties inherent in stimuli attracting the learner's attention. This means that learners do not spontaneously attend to the most relevant information but rather to most prominent, salient, or distractive stimuli (Lowe and Boucheix, <xref rid="B22" ref-type="bibr">2008</xref>). These processes can be manipulated by instructional design. Design principles such as arrows, spotlights, or instructions aim to guide learners' visual attention allocation to predefined relevant information areas (Mautone and Mayer, <xref rid="B24" ref-type="bibr">2007</xref>; Plass et al., <xref rid="B31" ref-type="bibr">2009</xref>). The addition of non-content information, however, is controversial. Cues may prevent a holistic view and do not necessarily lead to better learning outcomes (De Koning et al., <xref rid="B4" ref-type="bibr">2010</xref>). In line with these reservations, Kriz and Hegarty (<xref rid="B19" ref-type="bibr">2007</xref>) found that manipulating bottom-up processes by adding interactivity or arrows to an animation did not successfully enhance learning performance.</p><p>Top-down processes, on the other hand, are regulated by the learner's prior knowledge (Kriz and Hegarty, <xref rid="B19" ref-type="bibr">2007</xref>). Perception and encoding of new learning contents are determined by the accuracy and quantity of preexisting knowledge. Equipping learners with knowledge can guide their attention and thus lead to top-down processing: participants with higher levels of domain knowledge were better in constructing accurate mental models and in revising previous knowledge deficits, that means, identifying and closing knowledge gaps (Kriz and Hegarty, <xref rid="B19" ref-type="bibr">2007</xref>). Top-down processing is reflected in the pre-training principle.</p></sec><sec><title>The pre-training principle</title><p>Presenting content-specific information prior to a main learning phase aims to promote top-down processes. It prevents learners from being distracted by salient but less relevant information when learning, relieves cognitive load and thus facilitates learning performance, especially in high-element interactivity environments when the visual and auditory channels are already working to capacity (Mayer and Moreno, <xref rid="B27" ref-type="bibr">2003</xref>; Sweller et al., <xref rid="B38" ref-type="bibr">2011</xref>). This strategy is known as pre-training and refers to delivery of preceding information on components or structures of the learning content to foster the generation of initial basic knowledge (Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>). The benefits of pre-training are interpreted in terms of a two-stage theory of mental model construction. According to this model, learners should construct a mental representation of a component model in a first stage followed by a model of the entire system in a second stage (Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>). The first stage aims at teaching learners about the isolated components of a system and their changes on a local level; the second stage aims at teaching learners the cause-and-effect relationships between the previously learned components on a global level (Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>).</p><p>The pre-training principle was confirmed in several experiments on learning about technical systems. Positive effects of a pre-training treatment were found in paper-pencil, computer-based, and hands-on learning environments as well as with static and animated learning materials (Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>; Pollock et al., <xref rid="B32" ref-type="bibr">2002</xref>). In the aforementioned experiments pre-training equipped learners with declarative knowledge about the structures or components of the respective systems but not with knowledge about the global dynamic processes. The learning environments demonstrated processes and functions, whereas the components were learned beforehand in pre-training. It remains unclear whether pre-training is solely effective in providing prior knowledge on components or whether other domain-specific and relevant features such as the processes of the system can also be pre-trained. As many technical systems explain dynamic processes and flow directions, it is worth considering whether pre-training can also provide knowledge on motion events.</p><p>When a representation is presented in a static manner and, thus, visual dynamics are absent, learners must mentally animate the motions to infer processes and mechanics (Hegarty, <xref rid="B8" ref-type="bibr">1992</xref>). In an attempt to foster the mental simulation of motions in a technical system, we developed a gaze based pre-training. We examined whether a non-verbal pre-training on eye movements could positively influence the construction of a mental model from a static representation in order to foster comprehension of the dynamics in a technical system.</p></sec><sec><title>Learning by seeing through an expert's eyes</title><p>Type of task and level of expertise can affect gaze behavior. Experts and novices not only systematically differ in their performance as a result of their actions but also in the eye movement patterns that lead to their outcomes (e.g., Charness et al., <xref rid="B1" ref-type="bibr">2001</xref>). For instance, a meta-analysis on visual expertise by Gegenfurtner et al. (<xref rid="B5" ref-type="bibr">2011</xref>) showed that experts processed information faster and neglected task-irrelevant information for the benefit of task-relevant information. Experts' information processing was manifested in shorter fixation durations and a selective attention on task-relevant information. These results lead to the question whether expertise can be acquired faster when novices observe the eye movements of an expert (Gegenfurtner et al., <xref rid="B5" ref-type="bibr">2011</xref>).</p><p>The presentation of experts' gaze to novices can facilitate search performance. In terms of feedforward training, Nalanagula et al. (<xref rid="B28" ref-type="bibr">2006</xref>) demonstrated how eye movements can be successfully implemented to pre-train novices in a visual inspection task. The tested feedforward training applied eye movement data as prior information to promote search performance in novices. Feedforward training refers to the provision of task-dependent knowledge before a person performs a task. Here, the task was to detect defects in visually presented circuit boards. For the feedforward training the authors, first, recorded the eye movements of an expert performing the search task and, then, superimposed the expert's scanpath on the visual stimulus, namely the circuit board. Before inspecting circuit boards and detecting defects themselves, participants received one of three trainings. One group saw a static of a circuit board with a static and complete scanpath representing eye movement behavior (static condition), another group watched a circle representing the fixation of an eye superimposed on the same material (dynamic condition), and a third group watched a dynamic scanpath with a circle which developed over the time of inspection (hybrid condition). Afterwards participants had to search for defects in unfamiliar circuit boards. Overall, a dynamic and hybrid feedforward training had beneficial transfer effects on the new tasks. Participants in these conditions outperformed the static group and a control group without training. The authors conclude that the eye movements in the training might have offered insight into the models performance processes making easier to the novices to understand the processes of the inspection task. As the participants' eye movement data were not analyzed, it remained unanswered whether the beneficial effects of the feedforward training were due to a mediation of the participants' gaze behavior. Similarly, Litchfield and colleagues showed in a series of experiments that novices who observed the eye movements of an expert who was searching for pulmonary nodules in chest x-rays identified more nodules correctly when they had to search for nodules themselves (Litchfield et al., <xref rid="B21" ref-type="bibr">2010</xref>). More specifically it was shown that it was not the model's expertise but the task-specificity of eye movements in the pre-training that fostered search performance. Taken together, watching a model's eye movements functions as a scaffold. The model's eye movements were marked by specific eye movement patterns, however, no information was provided on transfer of the training on the gaze behavior performed by the participants who observed the models. Novices might have profited from the prior information because they reenacted the experts' gaze. Alternatively, they might have profited from the training without having to perform the same eye movement patterns.</p><p>Findings on eye movement modeling examples (EMMEs) show similarly promising results plus a slight transfer effect on gaze behavior. EMMEs can be created by recording the experts' eye movements when performing a visual task and replaying these recordings superimposed on the learning content (Jarodzka et al., <xref rid="B13" ref-type="bibr">2012</xref>). Such EMMEs can be considered as worked-out examples demonstrating where and when to look at specific regions of the learning content. EMMEs visualize an expert model's eye movements on a stimulus providing the basis for information processes and verbal explanations of the model. It is suggested that observing experts how they are selecting and organizing visual information could elicit the same processes in a novice. Sepp&#x000e4;nen and Gegenfurtner (<xref rid="B37" ref-type="bibr">2012</xref>) asked participants to interpret a computer tomography scan. Participants who watched a video replaying an expert's eye movements augmented by verbal interpretations of such a scan improved in diagnosing, fixated more task-relevant information and less task-redundant information. Modeling eye movements by spotlights guided attention more successfully and helped learners to identify relevant information at an earlier stage as well as fixate task-relevant information for a longer time (Jarodzka et al., <xref rid="B12" ref-type="bibr">2010a</xref>, <xref rid="B13" ref-type="bibr">2012</xref>). Other studies demonstrated that, in addition to the superior learning outcomes, this type of eye movement training can provoke more similar, that is coherent, eye movement scanpaths within a training condition (Jarodzka et al., <xref rid="B15" ref-type="bibr">2013</xref>).</p><p>Cognitive guidance via gaze behavior can be successful even without verbalized directions (Grant and Spivey, <xref rid="B6" ref-type="bibr">2003</xref>). In an experiment on problem solving, the eye movements of successful problem-solvers were used to develop cues for participants who were unfamiliar to the problem. Short flashes were implemented as cues to attract attention and trigger useful and beneficial eye movements for solving the task. Participants who were exposed to the gaze attracting cues outperformed participants who learned with noncritical cues or no cues. Based on these results, Thomas and Lleras (<xref rid="B39" ref-type="bibr">2007</xref>) made an attempt to facilitate successful problem solving by making their participants &#x0201c;move their eyes in a pattern that embodied the problem's solution&#x0201d; (p. 664). Comparing several conditions, the authors not only corroborated the results by Grant and Spivey (<xref rid="B6" ref-type="bibr">2003</xref>), but also found a relationship between eye movements and spatial cognition: the closer the resemblance between the spatiality of real eye movements and cues, the better the solution rate of learners. Learners were not aware of the connection between the cues and eye movements.</p><p>Even though these studies do not provide instructional information on the components of the learning contents, the results can be explained within the two-stage framework of mental model construction (Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>). Here, we can generalize the model as follows: In a first stage, learners acquire prior knowledge which enables them to build an initial and possibly incomplete mental model which is not restricted to components only. In a second stage, further incoming information can be encoded more easily and integrated with the schemata constructed during the first stage.</p></sec><sec><title>Knowledge about technical systems</title><p>Dynamics and movements are prominent and specific attributes of physical, technical, mechanical, and even business systems (Clark et al., <xref rid="B2" ref-type="bibr">2006</xref>). To understand how a technical system works learners must understand the processes and motions underlying the technical device which, in turn, can determine its functions.</p><p>Comprehension of technical systems comprises different types of knowledge (Hegarty, <xref rid="B9" ref-type="bibr">2005</xref>). First, learners must acquaint themselves with the components of a technical system. Based on the configuration of the system's parts, learners can construct a static model of the technical system (Hegarty, <xref rid="B9" ref-type="bibr">2005</xref>). Next, learners must acquire knowledge of the movements and causal interdependencies within the technical system. Based on knowledge about the behaviors and processes of a system, learners can construct a dynamic mental model of the system. The functions of a technical system describe its purpose and how the structures and processes of the system operate in order to make it functional in attending to its purpose. Last, by combining knowledge of its structures, processes, and functions, learners can construct a full internal representation of a technical device (Hegarty, <xref rid="B9" ref-type="bibr">2005</xref>). In line with these observations, Kalyuga and Hanham (<xref rid="B17" ref-type="bibr">2011</xref>) argue for a functions-processes-structures framework when describing technical systems to novice learners. Whereas structures are visible information pieces which are easy to access and process, processes and functions must often be inferred and, therefore, represent deeper understanding (Hmelo-Silver and Pfeffer, <xref rid="B10" ref-type="bibr">2004</xref>). Due to its relevance and challenges for mental animation we decided to use a static visual representation of a technical system, a solar plant, to test the effectiveness of our pre-training. In addition, we applied the functions-processes-structures framework to capture comprehension.</p></sec><sec><title>The present study</title><p>Against the backdrop of these considerations we developed a pre-training that tracked the dynamics in a technical system explained in a narration. The pre-training required participants to follow a black circle which was moving in spatial correspondence to the contents of the learning environment. However, the background was gray and contents were not revealed during the pre-training phase. After the pre-training, participants listened to a narration explaining the structures, processes, and functions of a solar plant while they were watching a static representation of the system. We compared two conditions: the experimental condition watched the pre-training in a first step and the learning environment on a solar plant in a second step; the control condition watched the learning environment on a solar plant without any preceding information. The pre-training was presented in a dynamic way where the circle cue moved around; the learning environment was presented in a static visualization. We addressed the following expectations:</p><sec><title>Learning outcomes</title><p>According to the functions-processes-structures framework (Hmelo-Silver and Pfeffer, <xref rid="B10" ref-type="bibr">2004</xref>; Hegarty, <xref rid="B9" ref-type="bibr">2005</xref>; Kalyuga and Hanham, <xref rid="B17" ref-type="bibr">2011</xref>), we distinguished between structures, processes, and functions when assessing knowledge. Adding extra interventions such as pre-training should result in better learning outcomes. We therefore expected the pre-training group to outperform the no-training group (i.e., control group) on overall learning outcomes. Next, we examined the different knowledge types for technical systems (i.e., knowledge about structures, processes, and functions). As the pre-training provided information on motions and causal relationships we expected the pre-training group to achieve better learning outcomes on processes. In addition, we analyzed knowledge about functions and structures separately.</p></sec><sec><title>Self-report measures on experiences during learning</title><p>It is predicted that a pre-training intervention can unfold its facilitating effects on comprehension processes by reducing adverse experiences such as cognitive load and mental effort during learning (Paas and van Merri&#x000eb;nboer, <xref rid="B29" ref-type="bibr">1993</xref>; Sweller et al., <xref rid="B38" ref-type="bibr">2011</xref>). Cognitive load and mental effort can be measured by asking learners how difficult it was to comprehend or to study the instructional material. Complementary, experienced stress can have also detrimental effects on learning outcomes. Experienced stress during learning can impair learning in terms of memorizing, retention, and recall: recent research demonstrates that stress has a negative influence on the quantity and quality of memory formation in learning situations (Schwabe et al., <xref rid="B35" ref-type="bibr">2010</xref>). More specifically, it was found that the different effects of stress on learning are time-dependent and can affect encoding, consolidation, retrieval, and reconsolidation processes (Schwabe et al., <xref rid="B33" ref-type="bibr">2012</xref>). Self-report measures of stress are time-saving and valid (Schwabe and Wolf, <xref rid="B34" ref-type="bibr">2010</xref>). We expected that pre-training would result in lower levels of cognitive load, mental effort, and experienced stress.</p></sec><sec><title>Eye movement behavior</title><p>Finally, we were interested in how far a pre-training based on eye movements could impact eye movements performed during the learning phase. As part of our manipulation check, we first examined whether and for how long participants in the pre-training group followed the circle cue from the pre-training stage that primed the processes in the subsequent learning environment.</p><p>For all analyses of eye movements we defined semantic areas of interest (AOIs) in the learning environment. AOIs were bound to visual key information that was crucial for comprehension and understanding of how the technical device was composed and of how it worked. Because the pre-training should enhance the awareness for content-relevant information, we expected the pre-training group to show longer dwell times on task relevant AOIs in the learning environment. Next, we examined how the pre-training would reflect on the saccades performed during the inspection of the learning environment. We expected the pre-training group to demonstrate more saccades in the direction of the fluids of the to-be-learned technical system as it was described by the narration. Finally, since the eye movement pre-training trained participants' eye movements to perform a specific order of movements as predetermined by the learning environment, we expected eye movements in the pre-training group to be more homogeneous in terms of similarity of strings analyzed by the Levenshtein distance.</p></sec><sec><title>Delayed posttest</title><p>Some benefits of multimedia learning principles can decline over time (Schweppe and Rummer, <xref rid="B36" ref-type="bibr">2012</xref>). Therefore, we asked our participants to take part in a follow-up posttest 1 week later. Participants were required to create a picture of the learning content by implementing arrows to represent the direction of motion in the system. The quality of the drawings was scored and compared in an explorative manner. We had no specific expectations in this respect.</p></sec></sec><sec sec-type="methods" id="s2"><title>Method</title><sec><title>Sample and design</title><p>Participants were 45 psychology students from the University of Freiburg who received course credit points for participation. They were randomly assigned either to an experimental group with eye movement pre-training prior to the learning phase or a control group without such pre-training. Neither participants nor experimenters were aware of the purpose of the study. The procedure was highly standardized by reducing personal contact between participant and experimenter to a minimum. Instructions were provided in written form on paper or screen. One participant in the pre-training group disclosed the purpose of the experiment and was thus excluded from the analysis, leaving 22 participants in each condition for our analysis (36 female; <italic>M</italic><sub>age</sub> = 22.67, <italic>SD</italic> = 4.81). Participants were tested in individual sessions of approximately 60 min. This experiment was conducted in accordance with the German Psychological Society (DGPs) ethical guidelines (2004, CIII) and the APA ethical standards. Participation was voluntary and confidential. Data collection was anonymized by participant codes. Participants provided verbal informed consent and could withdraw at any time without consequences. Contact information from the research team was provided to give participants the opportunity to withdraw their data or ask for further information following the experiment. After data collection was finished, participants were informed about the experiment's purpose and previous results in a lecture on educational psychology.</p></sec><sec><title>Learning material</title><p>The learning material consisted of a static and plane picture of a solar power plant illustrating the conversion of solar radiation into electricity (Figure <xref ref-type="fig" rid="F1">1</xref>). The representation was accompanied by an audio narration presented via headphones. An excerpt from the narration is provided in the Appendix.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Screenshot of the learning environment: solar plant (adapted from <ext-link ext-link-type="uri" xlink:href="http://www.solarmillennium-invest.de/cms/upload/Flash/andasol_blue.swf">http://www.solarmillennium-invest.de/cms/upload/Flash/andasol_blue.swf</ext-link>)</bold>.</p></caption><graphic xlink:href="fpsyg-06-00598-g0001"/></fig><p>The learning environment showed three operational and temporarily overlapping cycles. First, the topic and its relevance were introduced, then, the cycles of the system and their interdependencies were detailed. The components (i.e., structures) were labeled&#x02014;facilitating orientation&#x02014;and referred to the individual parts of the technical device. The pipes of the system are filled with different fluids which move in various directions through the course of energy conversion. These motions, however, were not displayed in the visual representation, but described by the narration. The flow of the fluids, as explained in the narration, was taken as an anchor for the pre-training. This material was chosen for two reasons. First, to understand the solar plant learners must mentally simulate dynamic processes. Second, it offers dense information and causal relationships within the material so that full comprehension might be challenging without any additional support in form of cueing or, in this case, pre-training.</p></sec><sec><title>Pre-training</title><p>The eye movement pre-training in the experimental condition contained an animated single black circle (0.3 cm in diameter) moving smoothly and analogically to the pipes of the technical device that was presented in the subsequent learning phase (see Video <xref ref-type="supplementary-material" rid="SM1">1</xref> in Supplement Data). Note, however, that during the whole pre-training the background of the screen did not display the actual learning environment (see Figure <xref ref-type="fig" rid="F2">2</xref> and Video <xref ref-type="supplementary-material" rid="SM1">1</xref>). So, contrary to the feedforward training by Nalanagula et al. (<xref rid="B28" ref-type="bibr">2006</xref>), the task was not visible.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Schematic illustration of the eye movement pre-training</bold>. The black circle represents the animated stimulus for the pre-training, the black arrow represents the direction of the animated stimulus, and the dashed lines represent its movements. Note that neither arrow nor dashed lines were visible to the participants.</p></caption><graphic xlink:href="fpsyg-06-00598-g0002"/></fig><p>The direction and order of the circle's movements were congruent to the narration that accompanied the learning material. The black circle in the pre-training was identical to the stimulus used during the calibration process of the eye tracking device. Participants in the pre-training group were instructed to follow the circle as they were previously doing for the calibration process. The close spatial resemblance between pre-training and the upcoming learning environment, however, was not revealed in the instructions. The pre-training lasted for about 2 min and simulated the movements of all three causal cycles depicted by the solar plant. The pre-training aimed at promoting attention to the processes of the technical system and thereby at fostering the understanding of the causal relationships between the components.</p></sec><sec><title>Prior knowledge</title><p>When testing new instructional design formats, it is important to take learners' prior knowledge into account because it can moderate the beneficial effects of instructional design (expertise reversal effect, e.g., Kalyuga, <xref rid="B16" ref-type="bibr">2007</xref>). We developed a test with open questions on domain-specific contents related to the learning material to assess prior knowledge. Overall, prior knowledge as assessed by the pretest was very low, <italic>M</italic> = 5.83 (percentage score), <italic>SD</italic> = 3.60, indicating that learners had hardly any prior knowledge about the tested learning contents. Since the learning material contained technical concepts of heat transfer and movements, we asked the participants to report their last school grade in physics (1 = <italic>very good</italic>; 6 = <italic>fail</italic>) as an indicator of general domain knowledge. Prior knowledge and last grade in physics were assessed as potential predictors and covariates for the learning outcomes.</p></sec><sec><title>Learning outcomes</title><p>To assess learning outcomes, we developed a test based on the functions-processes-structures framework by Kalyuga and Hanham (<xref rid="B17" ref-type="bibr">2011</xref>). The test consisted of open questions on the domain-specific content focusing on structures, processes, and functions. Structures are the components a technical device contains, processes are operations within a device, and functions refer to the purpose the components serve. The structures corresponded to the labeled components directly presented in the learning material (e.g., Please, name the components of a solar plant.) whereas the processes (e.g., Please, describe the processes in the water-steam cycle.) and functions (e.g., Please, describe how a turbine works.) could be deduced from the narration in combination with the visual stimulus. Structures, processes, and functions were assessed by three questions each. The answer to each question consisted of several aspects or items, respectively. All answers were scored by a rater unaware of the participant's condition. A subset of 25% was scored by a second rater and revealed high interrater reliability (ICC using mixed model, absolute type): 15 items on structures, <italic>ICC</italic> = 0.989, 15 items on processes: <italic>ICC</italic> = 0.959, 10 items on functions: <italic>ICC</italic> = 0.958. All disagreements were resolved by consensus.</p></sec><sec><title>Load, mental effort, and stress measurement</title><p>Self-report measures referred to the experience during the learning phase and were assessed with three items on a 9-point-Likert scale. Participants were asked to indicate how difficult it was to comprehend the presented learning content (load measure: 1 = <italic>not at all difficult</italic>; 9 = <italic>very difficult</italic>), how much mental effort they invested to comprehend the learning environment (mental effort: 1 = <italic>not at all</italic>; 9 = <italic>very much</italic>), and how stressed they felt during the learning process (stress: 1 = <italic>not at all stressed</italic>; 9 = <italic>very stressed</italic>).</p></sec><sec><title>Apparatus</title><p>Gaze data were recorded by a SensoMotoric Instruments Remote Eye-tracking Device and iView X 2.7 (120 Hz, angular error &#x0003c; 0.5). The stimulus was presented via ExperimentCenter 3.0 (22&#x02033; monitor, display resolution of 1680 &#x000d7; 1050, set 60&#x02013;80 cm in front of the participant). For the export of the gaze data we used BeGaze 3.0 software (<ext-link ext-link-type="uri" xlink:href="http://www.smivision.com">www.smivision.com</ext-link>).</p></sec><sec><title>Procedure</title><p>First, participants answered a questionnaire on demographics and worked on a test on prior knowledge. After calibration, participants were randomly assigned to either a condition with pre-training or a condition without pre-training. While the pre-training group was instructed to follow a black circle on a content-free screen prior to the learning environment (Figure <xref ref-type="fig" rid="F2">2</xref>), the control group continued immediately with the learning environment. After the learning phase, participants were asked to report how difficult it was to comprehend the presented learning contents to assess cognitive load, <italic>M</italic> = 3.89, <italic>SD</italic> = 2.10, how much mental effort they have invested, <italic>M</italic> = 4.91, <italic>SD</italic> = 2.03, and how stressed they felt during the learning unit, <italic>M</italic> = 3.82, <italic>SD</italic> = 2.18. Then, learning outcomes were assessed by a domain-specific posttest. There was no time limit for knowledge assessment, neither for the prior knowledge test nor for the learning outcomes posttest. Participants in the pre-training group were requested to reproduce the direction and events of the pre-training on a sheet of paper. In the final steps, participants were asked to write down the assumed purpose of the experiment. Also, they were invited to take part in a follow-up of the experiment 1 week later. All participants were debriefed when the experiment was finished.</p></sec><sec><title>Data analysis</title><sec><title>Eye movement analysis</title><p>We applied different eye movement parameters to investigate the specific expectations on eye movement behavior. The learning environment was accompanied by a narration, therefore we used dynamic AOIs which were temporally activated for as long as a specific region of the learning environment was concurrent with the narration. Figure <xref ref-type="fig" rid="F3">3</xref> gives examples of the semantic AOIs applied. Note that not all AOIs were activated at the same time.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Screenshots of the learning environment with areas of interest (yellow rectangles) used to investigate dwell time on semantic, content-relevant structures</bold>.</p></caption><graphic xlink:href="fpsyg-06-00598-g0003"/></fig><p>We used duration of dwell<bold>&#x02014;</bold>defined as the sum of durations for all gaze data samples that hit an area<bold>&#x02014;</bold>to analyze how long participants dwelled on an AOI. AOIs in the learning content contained learning relevant information and were used to determine the mean of durations of dwell on these AOIs. Examples of AOIs are the turbine, the cooling tower, single pipes, and salt tank. The dwell times on all AOIs were summed up for the final analysis.</p><p>To find out how the pre-training affected saccades that were performed during the learning phase we used defined AOIs corresponding to description in the narration and the pre-training. For example, Figure <xref ref-type="fig" rid="F4">4</xref> demonstrates two yellow AOIs on pipes filled with fluids running from left to right and upwards, respectively. Vectors within a 90&#x000b0; angle between every two fixations that hit the AOIs were recorded and aggregated to represent the number of saccades accomplished. We counted only vectors with the correct direction corresponding to the direction flow of the fluids and, thus, eye movements initiated in the pre-training. This procedure was repeated for all areas in the learning content that required direction interpretation.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Representations of two exemplary AOIs (yellow) which were applied to analyse saccades corresponding to the learning content and pre-training in direction</bold>.</p></caption><graphic xlink:href="fpsyg-06-00598-g0004"/></fig><p>To answer questions about group differences on coherence of strings we computed the Levenshtein distance for each participant within the respective groups (Levenshtein, <xref rid="B20" ref-type="bibr">1966</xref>). The Levenshtein distance is the minimum of insertions, deletions, and substitutions to transform one string of fixations into another string. All fixations on AOIs of one participant were arranged in a chronological sequence, for example, B-A-B-C-B-C-B-A (each character represents a fixation on an AOI). Then, we compressed the strings meaning that repeated fixations on the same area were collapsed into a single one, for example B-A-A-B-B-B-C was transferred into a string with four characters, namely B-A-B-C (Holmqvist, <xref rid="B11" ref-type="bibr">2011</xref>). First, we calculated pairwise distances between each participant and its other group members in a matrix. Because each group comprised many strings (one string for each participant), we calculated the mean of all distances from one participant to each of his/her group members divided by n-1. A low Levenshtein distance means that few operations are necessary to transfer one string into another string. This occurs when both strings are rather similar. High Levenshtein distances, on the contrary, represent dissimilar strings suggesting that many transformations are necessary to bring all strings down to a common string.</p><p>All participants had normal or corrected-to-normal vision. With respect to the obtained gaze data, the tracking ratio for the learning environment was at 92 % and the mean deviation for both eyes was at 0.69&#x000b0; indicating a good quality of eye movement data (Holmqvist, <xref rid="B11" ref-type="bibr">2011</xref>).</p></sec><sec><title>Coding of drawings</title><p>One week after the experiment, participants were asked to create a drawing of the solar plant they learned about the week before. They were provided colored pencils and were instructed to draw a picture of the system including arrows to indicate the direction of fluid flow. The drawing product was coded as follows: one point was assigned per each component that was represented in the solar plant, one point was assigned for correct placement of a component within the system, and one point for correct labeling of a component. In total, there were nine components and therefore a maximum score of 27 could be achieved. In addition, the number of arrows which represented the direction of flow was counted and the quality of the cycles was evaluated. The latter was realized by assigning one point for a correct oil-cycle, one point for a correct salt cycle, and one point for a correct water cycle. An incomplete cycle or open cycles received 0.5 points. Here, a maximum score of 3 could be achieved. Taken together, the quality of the drawings was described by three measures: component quality (max. 27 points), number of arrows, and cycle quality (max. 3 points).</p></sec></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Pre-analyses</title><p>For all statistical tests, we used an alpha level of 0.05. Table <xref ref-type="table" rid="T1">1</xref> displays the descriptive statistics (means and standard deviations) for all reported variables. Whenever reporting significant <italic>t</italic>-tests we report Cohen's d as effect size. Here, <italic>d</italic> &#x02264; 0.20 is a small effect size, <italic>d</italic> = 0.50 is a moderate effect size, and <italic>d</italic> &#x02265; 0.80 is a large effect size (Cohen, <xref rid="B3" ref-type="bibr">1992</xref>). Whenever we report a significant analysis of variance (ANOVA) we specify the effect size by &#x003b7;<sup>2</sup>. An effect size &#x003b7;<sup>2</sup> = 0.01 is small, &#x003b7;<sup>2</sup> = 0.06 is moderate, and &#x003b7;<sup>2</sup> &#x02265; 0.14 is considered large.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Means (and standard deviations) for all variables of interest in total and by condition (because of ANCOVAs adjusted means are reported for learning outcomes)</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th align="center" colspan="2" rowspan="1"><bold>Conditions</bold></th><th rowspan="1" colspan="1"/></tr><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"><bold>Total (<italic>n</italic> = 44)</bold></th><th align="center" rowspan="1" colspan="1"><bold>No-Training (<italic>n</italic> = 22)</bold></th><th align="center" rowspan="1" colspan="1"><bold>Pre-Training (<italic>n</italic> = 22)</bold></th><th align="center" rowspan="1" colspan="1"><bold><italic>p</italic></bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Prior knowledge, %</td><td align="center" rowspan="1" colspan="1">5.83 (3.60)</td><td align="center" rowspan="1" colspan="1">5.61 (3.15)</td><td align="center" rowspan="1" colspan="1">6.06 (4.07)</td><td align="center" rowspan="1" colspan="1">0.681</td></tr><tr><td align="left" rowspan="1" colspan="1">Grade in physics (1&#x02013;6)</td><td align="center" rowspan="1" colspan="1">2.35 (1.05)</td><td align="center" rowspan="1" colspan="1">2.23 (1.15)</td><td align="center" rowspan="1" colspan="1">2.48 (0.96)</td><td align="center" rowspan="1" colspan="1">0.440</td></tr><tr><td align="left" colspan="5" rowspan="1"><bold>COMPREHENSION MEASURES</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Learning outcomes, %</td><td align="center" rowspan="1" colspan="1">54.80 (14.47)</td><td align="center" rowspan="1" colspan="1">49.75 (14.52)</td><td align="center" rowspan="1" colspan="1">59.86 (14.52)</td><td align="center" rowspan="1" colspan="1">0.027</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;Structures, %</td><td align="center" rowspan="1" colspan="1">74.17 (16.43)</td><td align="center" rowspan="1" colspan="1">72.07 (16.49)</td><td align="center" rowspan="1" colspan="1">76.27 (16.49)</td><td align="center" rowspan="1" colspan="1">0.404</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;Processes, %</td><td align="center" rowspan="1" colspan="1">47.12 (19.29)</td><td align="center" rowspan="1" colspan="1">39.17 (19.36)</td><td align="center" rowspan="1" colspan="1">55.07 (19.36)</td><td align="center" rowspan="1" colspan="1">0.010</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;Functions, %</td><td align="center" rowspan="1" colspan="1">37.27 (15.48)</td><td align="center" rowspan="1" colspan="1">32.14 (15.53)</td><td align="center" rowspan="1" colspan="1">42.41 (15.53)</td><td align="center" rowspan="1" colspan="1">0.035</td></tr><tr><td align="left" colspan="5" rowspan="1"><bold>SELF-REPORT MEASURES</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Mental effort (1&#x02013;9)</td><td align="center" rowspan="1" colspan="1">4.91 (2.03)</td><td align="center" rowspan="1" colspan="1">4.82 (2.32)</td><td align="center" rowspan="1" colspan="1">5.00 (1.75)</td><td align="center" rowspan="1" colspan="1">0.771</td></tr><tr><td align="left" rowspan="1" colspan="1">Cognitive load (1&#x02013;9)</td><td align="center" rowspan="1" colspan="1">3.89 (2.10)</td><td align="center" rowspan="1" colspan="1">4.05 (2.40)</td><td align="center" rowspan="1" colspan="1">3.73 (1.80)</td><td align="center" rowspan="1" colspan="1">0.622</td></tr><tr><td align="left" rowspan="1" colspan="1">Stress (1&#x02013;9)</td><td align="center" rowspan="1" colspan="1">3.82 (2.18)</td><td align="center" rowspan="1" colspan="1">3.86 (2.25)</td><td align="center" rowspan="1" colspan="1">3.77 (2.16)</td><td align="center" rowspan="1" colspan="1">0.892</td></tr><tr><td align="left" colspan="5" rowspan="1"><bold>EYE MOVEMENT DATA</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Dwell time, total (s)</td><td align="center" rowspan="1" colspan="1">99.05 (26.02)</td><td align="center" rowspan="1" colspan="1">102.37 (26.46)</td><td align="center" rowspan="1" colspan="1">95.74 (25.85)</td><td align="center" rowspan="1" colspan="1">0.370</td></tr><tr><td align="left" rowspan="1" colspan="1">Saccades, total</td><td align="center" rowspan="1" colspan="1">24.62 (13.53)</td><td align="center" rowspan="1" colspan="1">24.18 (12.55)</td><td align="center" rowspan="1" colspan="1">25.07 (14.77)</td><td align="center" rowspan="1" colspan="1">0.843</td></tr><tr><td align="left" rowspan="1" colspan="1">Coherence, total</td><td align="center" rowspan="1" colspan="1">25.07 (5.20)</td><td align="center" rowspan="1" colspan="1">24.94 (18.94)</td><td align="center" rowspan="1" colspan="1">25.20 (5.77)</td><td align="center" rowspan="1" colspan="1">0.863</td></tr></tbody></table></table-wrap><p>First, we tested effects of prior knowledge on learning outcomes to determine whether prior knowledge should be considered in further tests of our hypotheses on learning outcomes. Within both conditions learning outcomes were highly correlated with the last physics grade (no-training: <italic>r</italic> = &#x02212;0.765, <italic>p</italic> &#x0003c; 0.001; pre-training: <italic>r</italic> = &#x02212;0.561, <italic>p</italic> = 0.007): better grades were associated with higher learning performance as assessed by the domain specific posttest (coding of grades: 1 = <italic>very good</italic>; 6 = <italic>fail</italic>). Moreover, groups did not differ on last grade in physics, <italic>t</italic><sub>(42)</sub> = &#x02212;0.780, <italic>p</italic> = 0.440. For this reason, we included last physics grade as a covariate to investigate whether pre-training had effects on learning outcomes (analysis of covariance). There were also no group differences with respect to the prior knowledge test, <italic>t</italic><sub>(42)</sub> = &#x02212;0.414, <italic>p</italic> = 0.681. However, pretest and learning outcomes were not correlated for either condition (no-training: <italic>r</italic> = 0.385, <italic>p</italic> = 0.077; pre-training: <italic>r</italic> = 0.230, <italic>p</italic> = 0.303). Therefore, pretest score was not included as covariate.</p></sec><sec><title>Learning outcomes</title><p>When analyzing the overall learning outcomes, we found a significant pre-training effect, <italic>F</italic><sub>(1, 41)</sub> = 5.291, <italic>p</italic> = 0.027, &#x003b7;<sup>2</sup><sub><italic>p</italic></sub> = 0.114. In line with our expectations, the pre-training group learned more about the presented content as compared with the no-training group. Next, we examined the subscales of the posttest and tested whether this effect holds for knowledge on structures, processes, and functions. There was a non-significant effect of pre-training on knowledge about structures, <italic>F</italic><sub>(1, 41)</sub> = 0.710, <italic>p</italic> = 0.404, &#x003b7;<sup>2</sup><sub><italic>p</italic></sub> = 0.017. However, there was a significant and large effect on processes, <italic>F</italic><sub>(1, 41)</sub> = 7.372, <italic>p</italic> = 0.010, &#x003b7;<sup>2</sup><sub><italic>p</italic></sub> = 0.152, as well as on functions, <italic>F</italic><sub>(1, 41)</sub> = 4.779, <italic>p</italic> = 0.035, &#x003b7;<sup>2</sup><sub><italic>p</italic></sub> = 0.104, indicating more effective learning in favor of the pre-training group. In sum, the pre-training group showed better learning outcomes as measured by the domain-specific post-test. This superiority is in particular due to knowledge about the processes and functions of the to-be-learned technical system.</p><p>Finally, we also examined the drawings participants in the pre-training group were required to reproduce the movements of the circle cue. This procedure was part of a manipulation check to monitor whether participants in the experimental group consciously perceived the pre-training. In total, we received 17 drawings, 14 of which specified the correct direction by arrows and 16 indicated more than one cycle, but only three drawings had a close resemblance to the schematic illustration of the pre-training as demonstrated in Figure <xref ref-type="fig" rid="F2">2</xref>.</p></sec><sec><title>Self-report measures on experiences during learning</title><p>The group condition had no effect on experienced cognitive load, <italic>t</italic><sub>(42)</sub> = 0.497, <italic>p</italic> = 0.622. There was a highly negative correlation between cognitive load and the learning outcomes, <italic>r</italic> = &#x02212;0.783, <italic>p</italic> &#x0003c; 0.001, which was also found within both conditions (pre-training: <italic>r</italic> = &#x02212;0.663, <italic>p</italic> = 0.001; no pre-training: <italic>r</italic> = &#x02212;0.865, <italic>p</italic> &#x0003c; 0.001). The less cognitive load participants experienced during the learning phase the better their learning outcomes were.</p><p>Concerning mental effort we found no effect of condition, <italic>t</italic><sub>(39)</sub> = &#x02212;0.0294, <italic>p</italic> = 0.771. Overall, mental effort was negatively associated with learning outcomes, <italic>r</italic> = &#x02212;0.508; <italic>p</italic> &#x0003c; 0.001. The less mental effort had to be invested to process the learning environment the better learning outcomes were. This trend was apparent in both conditions, namely the control group, <italic>r</italic> = &#x02212;0.587, <italic>p</italic> = 0.004, and the pre-training group, <italic>r</italic> = &#x02212;0.434, <italic>p</italic> = 0.044.</p><p>There was no difference between both groups on stress, <italic>t</italic><sub>(42)</sub> = 0.137, <italic>p</italic> = 0.892. Although there was no correlation between reported stress and the learning outcomes in the pre-training group, <italic>r</italic> = 0.202, <italic>p</italic> = 0.368, there was a correlation between reported stress and learning outcomes in the no-training group, <italic>r</italic> = &#x02212;0.566, <italic>p</italic> = 0.006. In order to test whether the relations between stress and learning outcomes differed significantly between conditions, we tested for an interaction effect using a regression in which learning outcomes were predicted from condition, experienced stress (moderator), and the interaction between condition and stress. Again, we controlled for grade in physics (Hayes, <xref rid="B7" ref-type="bibr">2012</xref>). The predictors were transformed using grand mean centering. There was a significant effect of condition, <italic>b</italic> = 0.503, <italic>SE</italic> = 0.222, <italic>t</italic> = 2.268, <italic>p</italic> = 0.029, and no effect of stress, <italic>b</italic> = &#x02212;0.004, <italic>SE</italic> = 0.060, <italic>t</italic> = &#x02212;0.059, <italic>p</italic> = 0.953. The interaction effect, however, was significant, <italic>b</italic> = 0.268, <italic>SE</italic> = 0.101, <italic>t</italic> = 2.665, <italic>p</italic> = 0.011. We followed up this finding with simple slopes analysis where we investigated the relationship between condition and learning outcomes at low, moderate, and high levels of experienced stress (Figure <xref ref-type="fig" rid="F5">5</xref>). When participants experienced low stress levels, there was a non-significant relationship between condition and learning outcomes, <italic>b</italic> = &#x02212;0.081, <italic>t</italic> = &#x02212;0.217, <italic>p</italic> = 0.829. When stress levels were moderate, we found a significant relationship between condition and learning outcomes, <italic>b</italic> = 0.503, <italic>t</italic> = 2.268, <italic>p</italic> = 0.029, indicating the pre-training group performed better. At high levels of experienced stress, we found a highly significant relationship, <italic>b</italic> = 1.087, <italic>t</italic> = 4.550, <italic>p</italic> &#x0003c; 0.001, showing that the learning performance of the no-training group dropped when participants experienced higher levels of stress. In sum, the positive effects of the pre-training condition become more evident the more stress learners experience; the pre-training has no effect when learners experience low stress.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Moderation between condition and experienced stress</bold>.</p></caption><graphic xlink:href="fpsyg-06-00598-g0005"/></fig></sec><sec><title>Eye movement behavior</title><p>First, as part of our manipulation check, we tested whether the pre-training group followed the black circle as intended by the pre-training procedure. Therefore, we measured for how long the participants in the pre-training group dwelled on the black circle cue during the pre-training (Figure <xref ref-type="fig" rid="F2">2</xref>). On average, participants demonstrated cue obedience and focused on the circle for 81.45% (<italic>SD</italic> = 0.96) of the time.</p><p>Our first hypothesis on eye movement behavior stated that the pre-training group should dwell longer on the relevant learning contents. There was no significant effect of pre-training, <italic>U</italic> = 149.00, z = &#x02212;0.92, <italic>p</italic> = 0.370. However, there was a positive correlation between duration of dwell on relevant areas and learning outcomes, <italic>r</italic> = 0.380, <italic>p</italic> = 0.019.</p><p>Next, we analyzed direction-conform saccades that were performed during the learning phase. There was no overall effect of pre-training on saccades, <italic>t</italic><sub>(36)</sub> = &#x02212;0.200, <italic>p</italic> = 0.843. In addition, there was no correlation between number of performed saccades and learning outcomes, <italic>r</italic> = 0.075, <italic>p</italic> = 0.653. Finally, testing the hypothesis whether the eye movements would be more coherent in the pre-training group we found no effect of training, <italic>U</italic> = 174.00, <italic>z</italic> = &#x02212;0.190, <italic>p</italic> = 0.863.</p></sec><sec><title>Delayed posttest</title><p>All participants were invited to a follow-up posttest 1 week later. In total, 34 participants took part in the follow-up test. Data sets from two participants were excluded from the follow-up analyses as they underwent the test on more or less than seven days after the main experiment, leaving 16 participants in each condition.</p><p>We tested the effect of pre-training on three quality measures: correctness of components, cycle correctness, and number of arrows. There were no significant effects, all <italic>p</italic>s &#x0003e; 0.05. Next, we checked for correlations between learning outcomes in the main experiment and the quality of drawing in the delayed posttest when controlling for physics grade (Table <xref ref-type="table" rid="T2">2</xref>).</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Overall correlations between learning outcomes at the first test time and the quality of drawings produced at the second test time when controlled for last grade in physics</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"><bold>Overall</bold></th><th align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th align="center" rowspan="1" colspan="1"><bold>Pre-training</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Component correctness</td><td align="center" rowspan="1" colspan="1">0.423<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td align="center" rowspan="1" colspan="1">0.364</td><td align="center" rowspan="1" colspan="1">0.355</td></tr><tr><td align="left" rowspan="1" colspan="1">Cycle correctness</td><td align="center" rowspan="1" colspan="1">0.466<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></td><td align="center" rowspan="1" colspan="1">0.499</td><td align="center" rowspan="1" colspan="1">0.556<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Arrow number</td><td align="center" rowspan="1" colspan="1">0.471<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></td><td align="center" rowspan="1" colspan="1">0.415</td><td align="center" rowspan="1" colspan="1">0.657<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></td></tr></tbody></table><table-wrap-foot><fn id="TN1"><label>*</label><p>p &#x0003c; 0.05;</p></fn><fn id="TN2"><label>**</label><p>p &#x0003c; 0.01.</p></fn></table-wrap-foot></table-wrap><p>Remarkably, overall learning outcomes correlated with all quality measures. When analysing these findings per condition, only two positive correlations in the pre-training group remained. The correctness of the cycles and the number of arrows implemented to represent direction flow correlated with learning outcomes. Both drawing quality measures are associated with knowledge about processes.</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>Based on recent approaches to model eye movements and the pre-training principle, the present study investigated the effects of an eye movement pre-training to foster comprehension of a technical system. We assumed that such pre-training would also reflect on oculomotor aspects in terms of eye movement parameters. In line with our expectations, the pre-training facilitated knowledge acquisition of the technical system. However, it did not influence learners' gaze behavior in the expected way. In addition, we found a relationship between experienced cognitive load, mental effort, experienced stress, and learning outcomes, indicating that the more load, effort, and stress learners experienced the poorer their learning performance was. However, this effect could not be ascribed to the pre-training of eye movements. We found that the effect of pre-training on learning performance changes as a function of experienced stress: the pre-training &#x0201c;assisted&#x0201d; learners who experienced moderate or high levels of stress. In sum, we found a clear positive effect on learning outcomes, some mixed effects with respect to self-report measures, and unexpected non-significant results on eye movement behavior. Last, a delayed posttest requiring participants to draw a picture of the learning material showed no effect of condition, but revealed associations between the quality of the picture and the learning outcomes at the first testing time which could only be ascribed to the pre-training group. The delayed posttest has an explorative character and can be considered a starting point for further research when it comes to visualizations of motion knowledge and long-term effects.</p><p>Training gaze had a positive effect on learning outcomes and successfully fostered the comprehension of a technical system. This was especially true for knowledge about processes and functions which can be considered more elaborated knowledge as compared to knowledge about structures (Kriz and Hegarty, <xref rid="B19" ref-type="bibr">2007</xref>; Kalyuga and Hanham, <xref rid="B17" ref-type="bibr">2011</xref>). One might argue that the performance scores were rather in the middle range leaving space for improvement. Note, however, that the learning environment was presented only once to learners who had hardly any prior knowledge of the learning contents. In addition, the posttest was extensive and exhausted all aspects of the learning environment. It is suggested that novice learners can benefit from repeated exposures of particularly complex learning environments (Lowe and Boucheix, <xref rid="B23" ref-type="bibr">2011</xref>). To test the effectiveness of our pre-training we restricted the presentation time to only one viewing round.</p><p>The findings on experienced stress show that effective interventions can alleviate negative consequences of stress and preserve performance at a good level. In line with Schwabe et al. (<xref rid="B35" ref-type="bibr">2010</xref>), we confer that experienced stress could shed some light on the outcomes of multimedia effects and could help explaining multimedia effects in greater detail. More sophisticated measurements of stress might help investigate different facets of experienced emotional states such as challenge or hindrance in encoding or retrieval (Pekrun and Linnenbrink-Garcia, <xref rid="B30" ref-type="bibr">2014</xref>).</p><p>In general, we found no effects of training on gaze behavior as assessed by dynamic and semantic areas of interest. There was just one correlation showing that the longer participants looked on areas which were temporally focused by the narration the better their learning outcomes were. However, an effect of pre-training was not found. In our analyses, we accumulated eye movement information over all temporal AOIs so that dwell time, number of saccades, and similarity were represented by one single score, respectively. This is rather a coarse-grained approach and does not allow for insights into the development of eye movement behavior during the course of learning. More fine-grained analyses might depict the development of eye movements and, thus, cognitive processing over time in more detail. Vector-based analyses are very promising in this respect and should be made applicable to complex materials (Jarodzka et al., <xref rid="B14" ref-type="bibr">2010b</xref>). Similar to findings by Thomas and Lleras (<xref rid="B39" ref-type="bibr">2007</xref>), we can conclude that the intervention was successful although differences in eye movements were not &#x0201c;carried over when participants were free to look&#x0201d; (p. 668) during inspection of the visual representation.</p><p>Our pre-training was successful and can be regarded as a supplement to the pre-training principle described by Mayer (<xref rid="B25" ref-type="bibr">2009</xref>). However, it is important to make a differentiation. Instructing students to learn about components of a system requires conscious processes. Moreover, such instructions tell the students that they should memorize the names of the components because there will be subsequent information on the causal relationships between these components. In contrast, delivering an eye-movement pre-training without revealing the learning content and the specific connection to the learning material might have worked in a different way as no content processing was incorporated. To examine this conjecture, we asked participants to write down their assumptions about the purpose of the experiment. Only one participant detected the actual link between the eye movement pre-training and the learning content. Most participants perceived the pre-training to be part of the calibration process of the eye tracking device. Therefore, we have reason to believe that our pre-training worked unconsciously similar to the aforementioned findings on problem solving (Grant and Spivey, <xref rid="B6" ref-type="bibr">2003</xref>; Thomas and Lleras, <xref rid="B39" ref-type="bibr">2007</xref>). On the other hand, when explicitly asked to sketch the pre-training, most participants in the pre-training group correctly remembered the cue and its motions. We cannot tell in how far embodied movements of the pre-training phase triggered the mental animation during the learning process. Memory traces of the motions might have been built without the necessity to perform them in the further course. To test our tentative explanations, it is sensible to collect think aloud data during learning in order to gain some insight into the learners' internal processes and maybe even detect mental animation processes which could not be captured by our eye movement parameters. Alternatively, the pre-training might have boosted the participants' concentration without affecting their eye movement behavior or the comprehension of the motions in the learning environment. However, to rule out alternative interpretations diverse variations of eye movement pre-trainings have to be tested, for instance, pre-training eye movements incongruent to the learning environment or just a random sequence of eye movements. Such control conditions could be contrasted with trainings focusing on the static aspects of the learning content, for example the components of the solar plant, to test in how far this would elicit comprehension about structures. A significant correlation between dwell time on the structures of the material and learning outcomes, especially knowledge about structures, <italic>r</italic> = 0.497, <italic>p</italic> = 0.001, indicates that this might be the case. Moreover, the findings of this experiment could be used to investigate whether pre-training would be also beneficial for other learning materials, such as dynamic representations or non-technical contents.</p><p>Finally, some methodological concerns should be mentioned: due to the pre-training intervention the pre-training condition was longer. Both groups received identical learning material, with the exception that the pre-training group additionally received an eye movement pre-training. One might raise the objection that the no-training group should have received some other treatment to keep the overall time constant. Then, however, we would have tested two different trainings not knowing how participants would react in a control group without any support. There is evidence that keeping the overall learning time constant by reversing the order of pre-training and learning phase does not <italic>per se</italic> promote learning (Experiment 3 in Mayer et al., <xref rid="B26" ref-type="bibr">2002</xref>). However, as this study on this type of eye movement pre-training is the first of its kind, further studies testing different materials, and target groups in different (experimental) settings should follow.</p><p>So far, the framework applied has effectively discriminated poor learners from good learners in terms of learning outcomes. Results were reported on an overall level and on the level of the subscales. Despite good reliabilities, the subscales were intercorrelated (all <italic>ps</italic> &#x0003c; 0.001). This problem was not addressed by previous research using this framework (Hmelo-Silver and Pfeffer, <xref rid="B10" ref-type="bibr">2004</xref>; Kalyuga and Hanham, <xref rid="B17" ref-type="bibr">2011</xref>) and should therefore receive more attention. This is a drawback that might make the functions-processes-structures framework less attractive. On the other hand, it should be discussed whether the subscales reflecting knowledge of structures, processes, and functions must be orthogonal. As proposed by Kalyuga and Hanham (also: Kalyuga et al., <xref rid="B18" ref-type="bibr">2010</xref>), there is a hierarchical interdependence between these knowledge constructs, either from general to specific or specific to general knowledge. The latter approach reflects the fact that knowledge about structures is necessary to understand processes and functions.</p><p>Overall, we present a new approach to pre-training by using eye movements to foster comprehension and mental animation in a static picture. The pre-training was successful in at least two ways: (a) it supported participants' understanding of the processes and functions of a technical system, and (b) it revealed that the negative relationship between experienced stress and learning outcomes can be compensated by a non-verbal eye movement pre-training.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We acknowledge support by Deutsche Forschungsgemeinschaft and Open Access Publishing Fund of University of T&#x000fc;bingen. Moreover, we wish to acknowledge Adrian Skuballa for developing our analysis tools, and Michael Kutz and Clara Pieck for designing our learning environment. Also, we especially thank Nicole Dillner and Sabina Panetta for assisting in conducting this study.</p></ack><sec sec-type="supplementary-material" id="s5"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="http://journal.frontiersin.org/article/10.3389/fpsyg.2015.00598/abstract">http://journal.frontiersin.org/article/10.3389/fpsyg.2015.00598/abstract</ext-link></p><supplementary-material content-type="local-data" id="SM1"><media xlink:href="Video1.AVI"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charness</surname><given-names>N.</given-names></name><name><surname>Reingold</surname><given-names>E.</given-names></name><name><surname>Pomplun</surname><given-names>M.</given-names></name><name><surname>Stampe</surname><given-names>D.</given-names></name></person-group> (<year>2001</year>). <article-title>The perceptual aspect of skilled performance in chess: evidence from eye movements</article-title>. <source>Mem. Cognit</source>. <volume>29</volume>, <fpage>1146</fpage>&#x02013;<lpage>1152</lpage>. <pub-id pub-id-type="doi">10.3758/BF03206384</pub-id><pub-id pub-id-type="pmid">11913751</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>R. C.</given-names></name><name><surname>Nguyen</surname><given-names>F.</given-names></name><name><surname>Sweller</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <source>Efficiency in Learning: Evidence-Based Guidelines to Manage Cognitive Load</source>. <publisher-loc>San Francisco, CA</publisher-loc>: <publisher-name>Jossey-Bass</publisher-name>.</mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J.</given-names></name></person-group> (<year>1992</year>). <article-title>A power primer</article-title>. <source>Psychol. Bull</source>. <volume>112</volume>, <fpage>155</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.112.1.155</pub-id><pub-id pub-id-type="pmid">19565683</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Koning</surname><given-names>B. B.</given-names></name><name><surname>Tabbers</surname><given-names>H. K.</given-names></name><name><surname>Rikers</surname><given-names>R. M. J. P.</given-names></name><name><surname>Paas</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>Attention guidance in learning from a complex animation: seeing is understanding?</article-title>
<source>Learn. Instruct</source>. <volume>20</volume>, <fpage>111</fpage>&#x02013;<lpage>122</lpage>
<pub-id pub-id-type="doi">10.1016/j.learninstruc.2009.02.010</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gegenfurtner</surname><given-names>A.</given-names></name><name><surname>Lehtinen</surname><given-names>E.</given-names></name><name><surname>S&#x000e4;lj&#x000f6;</surname><given-names>R.</given-names></name></person-group> (<year>2011</year>). <article-title>Expertise differences in the comprehension of visualizations: a meta-analysis of eye-tracking research in professional domains</article-title>. <source>Educ. Psychol. Rev</source>. <volume>23</volume>, <fpage>523</fpage>&#x02013;<lpage>552</lpage>
<pub-id pub-id-type="doi">10.1007/s10648-011-9174-7</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grant</surname><given-names>E. R.</given-names></name><name><surname>Spivey</surname><given-names>M. J.</given-names></name></person-group> (<year>2003</year>). <article-title>Eye movements and problem solving: guiding attention guides thought</article-title>. <source>Psychol. Sci</source>. <volume>14</volume>, <fpage>462</fpage>&#x02013;<lpage>466</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9280.02454</pub-id><pub-id pub-id-type="pmid">12930477</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Hayes</surname><given-names>A. F.</given-names></name></person-group> (<year>2012</year>). <source>PROCESS: A Versatile Computational Tool for Observed Variable Mediation, Moderation, and Conditional Process Modeling [White paper]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/SobelTest?action=AttachFile&#x00026;do=getandtarget=process.pdf">http://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/SobelTest?action=AttachFile&#x00026;do=getandtarget=process.pdf</ext-link></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegarty</surname><given-names>M.</given-names></name></person-group> (<year>1992</year>). <article-title>Mental animation: inferring motion from static displays of mechanical systems</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn</source>. <volume>18</volume>, <fpage>1084</fpage>&#x02013;<lpage>1102</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.18.5.1084</pub-id><pub-id pub-id-type="pmid">1402712</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hegarty</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Multimedia learning about physical systems</article-title>, in <source>The Cambridge Handbook of Multimedia Learning</source>, ed <person-group person-group-type="editor"><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>), <fpage>447</fpage>&#x02013;<lpage>466</lpage>
<pub-id pub-id-type="doi">10.1017/CBO9780511816819.029</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hmelo-Silver</surname><given-names>C. E.</given-names></name><name><surname>Pfeffer</surname><given-names>M. G.</given-names></name></person-group> (<year>2004</year>). <article-title>Comparing expert and novice understanding of a complex system from the perspective of structures, behaviors, and functions</article-title>. <source>Cogn. Sci</source>. <volume>28</volume>, <fpage>127</fpage>&#x02013;<lpage>138</lpage>
<pub-id pub-id-type="doi">10.1207/s15516709cog2801_7</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holmqvist</surname><given-names>K.</given-names></name></person-group> (<year>2011</year>). <source>Eye Tracking: A Comprehensive Guide to Methods and Measures</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jarodzka</surname><given-names>H.</given-names></name><name><surname>Balslev</surname><given-names>T.</given-names></name><name><surname>Holmqvist</surname><given-names>K.</given-names></name><name><surname>Nystr&#x000f6;m</surname><given-names>M.</given-names></name><name><surname>Scheiter</surname><given-names>K.</given-names></name><name><surname>Gerjets</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2010a</year>). <article-title>Learning perceptual aspects of diagnosis in medicine via eye movement modeling examples on patient video cases</article-title>, in <source>Proceedings of the 32nd Annual Conference of the Cognitive Science Society</source>, eds <person-group person-group-type="editor"><name><surname>Ohlson</surname><given-names>S.</given-names></name><name><surname>Catrambone</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Austin, TX</publisher-loc>: <publisher-name>Cognitive Science Society</publisher-name>), <fpage>1703</fpage>&#x02013;<lpage>1708</lpage>.</mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarodzka</surname><given-names>H.</given-names></name><name><surname>Balslev</surname><given-names>T.</given-names></name><name><surname>Holmqvist</surname><given-names>K.</given-names></name><name><surname>Nystr&#x000f6;m</surname><given-names>M.</given-names></name><name><surname>Scheiter</surname><given-names>K.</given-names></name><name><surname>Gerjets</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Conveying clinical reasoning based on visual observation via eye-movement modelling examples</article-title>. <source>Instruct. Sci</source>. <volume>40</volume>, <fpage>813</fpage>&#x02013;<lpage>827</lpage>
<pub-id pub-id-type="doi">10.1007/s11251-012-9218-5</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jarodzka</surname><given-names>H.</given-names></name><name><surname>Holmqvist</surname><given-names>K.</given-names></name><name><surname>Nystr&#x000f6;m</surname><given-names>M.</given-names></name></person-group> (<year>2010b</year>). <article-title>A vector-based multidimensional scanpath similarity measure</article-title>, in <source>Proceedings of the 2010 Symposium on Eye-Tracking Research and Applications (ETRA)</source>, eds <person-group person-group-type="editor"><name><surname>Morimoto</surname><given-names>C. H.</given-names></name><name><surname>Istance</surname><given-names>H.</given-names></name><name><surname>Hyrskykari</surname><given-names>A.</given-names></name><name><surname>Ji</surname><given-names>Q.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>), <fpage>211</fpage>&#x02013;<lpage>218</lpage>
<pub-id pub-id-type="doi">10.1145/1743666.1743718</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarodzka</surname><given-names>H.</given-names></name><name><surname>van Gog</surname><given-names>T.</given-names></name><name><surname>Dorr</surname><given-names>M.</given-names></name><name><surname>Scheiter</surname><given-names>K.</given-names></name><name><surname>Gerjets</surname><given-names>P.</given-names></name></person-group> (<year>2013</year>). <article-title>Learning to see: guiding students' attention via a model's eye movements fosters learning</article-title>. <source>Learn. Instruct</source>. <volume>25</volume>, <fpage>62</fpage>&#x02013;<lpage>70</lpage>
<pub-id pub-id-type="doi">10.1016/j.learninstruc.2012.11.004</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalyuga</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Expertise reversal effect and its implications for learner-tailored instruction</article-title>. <source>Educ. Psychol. Rev</source>. <volume>19</volume>, <fpage>509</fpage>&#x02013;<lpage>539</lpage>. <pub-id pub-id-type="doi">10.1007/s10648-007-9054-3</pub-id><pub-id pub-id-type="pmid">21443379</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalyuga</surname><given-names>S.</given-names></name><name><surname>Hanham</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Instructing in generalized knowledge structures to develop flexible problem solving skills</article-title>. <source>Comput. Hum. Behav</source>. <volume>27</volume>, <fpage>63</fpage>&#x02013;<lpage>68</lpage>
<pub-id pub-id-type="doi">10.1016/j.chb.2010.05.024</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalyuga</surname><given-names>S.</given-names></name><name><surname>Renkl</surname><given-names>A.</given-names></name><name><surname>Paas</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>Facilitating flexible problem solving: a cognitive load perspective</article-title>. <source>Educ. Psychol. Rev</source>. <volume>22</volume>, <fpage>175</fpage>&#x02013;<lpage>186</lpage>
<pub-id pub-id-type="doi">10.1007/s10648-010-9132-9</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriz</surname><given-names>S.</given-names></name><name><surname>Hegarty</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Top-down and bottom-up influences on learning from animations</article-title>. <source>Int. J. Hum. Comput. Stud</source>. <volume>65</volume>, <fpage>911</fpage>&#x02013;<lpage>930</lpage>
<pub-id pub-id-type="doi">10.1016/j.ijhcs.2007.06.005</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levenshtein</surname><given-names>V. I.</given-names></name></person-group> (<year>1966</year>). <article-title>Binary codes capable of correcting deletions, insertions, and reversals</article-title>. <source>Soviet Phys. Doklady</source>
<volume>10</volume>, <fpage>707</fpage>&#x02013;<lpage>710</lpage>.</mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litchfield</surname><given-names>D.</given-names></name><name><surname>Ball</surname><given-names>L. J.</given-names></name><name><surname>Donovan</surname><given-names>T.</given-names></name><name><surname>Manning</surname><given-names>D. J.</given-names></name><name><surname>Crawford</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Viewing another person's eye movements improves identification of pulmonary nodules in chest x-ray inspection</article-title>. <source>J. Exp. Psychol. Appl</source>. <volume>16</volume>, <fpage>251</fpage>&#x02013;<lpage>262</lpage>. <pub-id pub-id-type="doi">10.1037/a0020082</pub-id><pub-id pub-id-type="pmid">20853985</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lowe</surname><given-names>R.</given-names></name><name><surname>Boucheix</surname><given-names>J.-M.</given-names></name></person-group> (<year>2008</year>). <article-title>Learning from animated diagrams: How are mental models built?</article-title> in <source>Diagrammatic Representation and Inference. 5th International Conference, Diagrams 2008, Herrsching, Germany, September 19-21, 2008; Proceedings</source>, eds <person-group person-group-type="editor"><name><surname>Stapleton</surname><given-names>G.</given-names></name><name><surname>Howse</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>266</fpage>&#x02013;<lpage>281</lpage>.</mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowe</surname><given-names>R.</given-names></name><name><surname>Boucheix</surname><given-names>J.-M.</given-names></name></person-group> (<year>2011</year>). <article-title>Cueing complex animations: does direction of attention foster learning processes?</article-title>
<source>Learn. Instruct</source>. <volume>21</volume>, <fpage>650</fpage>&#x02013;<lpage>663</lpage>
<pub-id pub-id-type="doi">10.1016/j.learninstruc.2011.02.002</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mautone</surname><given-names>P. D.</given-names></name><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2007</year>). <article-title>Cognitive aids for guiding graph comprehension</article-title>. <source>J. Educ. Psychol</source>. <volume>99</volume>, <fpage>640</fpage>&#x02013;<lpage>652</lpage>
<pub-id pub-id-type="doi">10.1037/0022-0663.99.3.640</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2009</year>). <source>Multimedia Learning</source>, <edition>2nd Edn</edition>
<publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>
<pub-id pub-id-type="doi">10.1017/CBO9780511811678</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name><name><surname>Mathias</surname><given-names>A.</given-names></name><name><surname>Wetzell</surname><given-names>K.</given-names></name></person-group> (<year>2002</year>). <article-title>Fostering understanding of multimedia messages through pre-training: evidence for a two-stage theory of mental model construction</article-title>. <source>J. Exp. Psychol. Appl</source>. <volume>8</volume>, <fpage>147</fpage>&#x02013;<lpage>154</lpage>. <pub-id pub-id-type="doi">10.1037/1076-898X.8.3.147</pub-id><pub-id pub-id-type="pmid">12240927</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name><name><surname>Moreno</surname><given-names>R.</given-names></name></person-group> (<year>2003</year>). <article-title>Nine ways to reduce cognitive load in multimedia learning</article-title>. <source>Educ. Psychol</source>. <volume>38</volume>, <fpage>43</fpage>&#x02013;<lpage>52</lpage>
<pub-id pub-id-type="doi">10.1207/S15326985EP3801_6</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nalanagula</surname><given-names>D.</given-names></name><name><surname>Greenstein</surname><given-names>J. S.</given-names></name><name><surname>Gramopadhye</surname><given-names>A. K.</given-names></name></person-group> (<year>2006</year>). <article-title>Evaluation of the effect of feedforward training displays of search strategy on visual search performance</article-title>. <source>Int. J. Ind. Ergon</source>. <volume>36</volume>, <fpage>289</fpage>&#x02013;<lpage>300</lpage>
<pub-id pub-id-type="doi">10.1016/j.ergon.2005.11.008</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paas</surname><given-names>F. G. W. C.</given-names></name><name><surname>van Merri&#x000eb;nboer</surname><given-names>J. J. G.</given-names></name></person-group> (<year>1993</year>). <article-title>The efficiency of instructional conditions: an approach to combine mental effort and performance measures</article-title>. <source>Hum. Factors J. Hum. Factors Ergon. Soc</source>. <volume>35</volume>, <fpage>737</fpage>&#x02013;<lpage>743</lpage>.</mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Pekrun</surname><given-names>R.</given-names></name><name><surname>Linnenbrink-Garcia</surname><given-names>L.</given-names></name></person-group> (eds.). (<year>2014</year>). <source>Inernational Handbook of Emotions in Education</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Francis and Taylor/Routledge</publisher-name>.</mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plass</surname><given-names>J. L.</given-names></name><name><surname>Homer</surname><given-names>B. D.</given-names></name><name><surname>Hayward</surname><given-names>E. O.</given-names></name></person-group> (<year>2009</year>). <article-title>Design factors for educationally effective animations and simulations</article-title>. <source>J. Comput. High. Educ</source>. <volume>21</volume>, <fpage>31</fpage>&#x02013;<lpage>61</lpage>
<pub-id pub-id-type="doi">10.1007/s12528-009-9011-x</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollock</surname><given-names>E.</given-names></name><name><surname>Chandler</surname><given-names>P.</given-names></name><name><surname>Sweller</surname><given-names>J.</given-names></name></person-group> (<year>2002</year>). <article-title>Assimilating complex information</article-title>. <source>Learn. Instruct</source>. <volume>12</volume>, <fpage>61</fpage>&#x02013;<lpage>86</lpage>
<pub-id pub-id-type="doi">10.1016/S0959-4752(01)00016-0</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwabe</surname><given-names>L.</given-names></name><name><surname>Jo&#x000eb;ls</surname><given-names>M.</given-names></name><name><surname>Roozendaal</surname><given-names>B.</given-names></name><name><surname>Wolf</surname><given-names>O. T.</given-names></name><name><surname>Oitzl</surname><given-names>M. S.</given-names></name></person-group> (<year>2012</year>). <article-title>Stress effects on memory: an update and integration</article-title>. <source>Mem. Formation</source>
<volume>36</volume>, <fpage>1740</fpage>&#x02013;<lpage>1749</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2011.07.002</pub-id><pub-id pub-id-type="pmid">21771612</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwabe</surname><given-names>L.</given-names></name><name><surname>Wolf</surname><given-names>O. T.</given-names></name></person-group> (<year>2010</year>). <article-title>Learning under stress impairs memory formation</article-title>. <source>Neurobiol. Learn. Mem</source>. <volume>93</volume>, <fpage>183</fpage>&#x02013;<lpage>188</lpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2009.09.009</pub-id><pub-id pub-id-type="pmid">19796703</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwabe</surname><given-names>L.</given-names></name><name><surname>Wolf</surname><given-names>O. T.</given-names></name><name><surname>Oitzl</surname><given-names>M. S.</given-names></name></person-group> (<year>2010</year>). <article-title>Memory formation under stress: quantity and quality</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>34</volume>, <fpage>584</fpage>&#x02013;<lpage>591</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.11.015</pub-id><pub-id pub-id-type="pmid">19931555</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schweppe</surname><given-names>J.</given-names></name><name><surname>Rummer</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Long-term multimedia learning</article-title>, in <source>Staging Knowledge and Experience: How to Take Advantage of Representational Technologies in Education and Training?</source> eds <person-group person-group-type="editor"><name><surname>de Vries</surname><given-names>E.</given-names></name><name><surname>Scheiter</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>Grenoble</publisher-loc>: <publisher-name>University of Grenoble</publisher-name>), <fpage>196</fpage>&#x02013;<lpage>198</lpage>.</mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sepp&#x000e4;nen</surname><given-names>M.</given-names></name><name><surname>Gegenfurtner</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>Seeing through a teacher's eyes improves students' imaging interpretation</article-title>. <source>Med. Educ</source>. <volume>1</volume>, <fpage>1113</fpage>&#x02013;<lpage>1114</lpage>. <pub-id pub-id-type="doi">10.1111/medu.12041</pub-id><pub-id pub-id-type="pmid">23078702</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sweller</surname><given-names>J.</given-names></name><name><surname>Ayres</surname><given-names>P. L.</given-names></name><name><surname>Kalyuga</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). <source>Cognitive Load Theory</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>
<pub-id pub-id-type="doi">10.1007/978-1-4419-8126-4</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>L. E.</given-names></name><name><surname>Lleras</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Moving eyes and moving thought: on the spatial compatibility between eye movements and cognition</article-title>. <source>Psychon. Bull. Rev</source>. <volume>14</volume>, <fpage>663</fpage>&#x02013;<lpage>668</lpage>. <pub-id pub-id-type="doi">10.3758/BF03196818</pub-id><pub-id pub-id-type="pmid">17972730</pub-id></mixed-citation></ref></ref-list><app-group><app><title>Appendix</title><sec><title>English excerpt of the narration which accompanied the static representation of the solar plant</title><p>The first cycle is called oil cycle. This cycle consists of a solar field and pipes filled with thermal oil. The second cycle is called water-steam cycle. The pipes of this cycle are filled with water and steam, respectively. This cycle consists of a turbine, a generator, a cooling tower and two warm exchange heaters. The third and last cycle is called salt cycle, because its pipes transport melted salt. In the following, the single cycles and its components will be examined in more detail.</p><p>A solar field consists of several, gutter typed parabolic reflectors, which are also called solar panels. The parabolic mirrors adjust their orientation according to the position of the sun to enable a constant and high energy yield. With the first sun rays and in the course of the day the parabolic mirrors concentrate the incoming sunlight. In the focal point of the reflector there runs thermal oil in the tube. The focused sunlight increases the temperature of the thermal oil to some 400&#x000b0;C. As the parabolic reflectors use a wide spectral range the solar field can increase the temperature of the thermal oil even during cloudiness.</p><p>The hot thermal oil runs to a heat exchanger. The oil runs through the heat exchanger and gives off heat to water circulating in the adjacent cycle. The heated thermal oil runs again through the tube in the solar field where its temperature can be increased again. By heating the steam in the heat exchanger the temperature and consequently the specific volume increase. The so called live stream leaves the heat exchanger at high pressure. The steam runs through pipes and flows through moving and stationary blades of a turbine. In general, the turbine operates similar to many consecutive windmills. This way the steam's temperature and pressure decrease. A generator is connected to the turbine. The generator transforms kinetic energy into electric energy. The electricity supplies single households via a network. When the cooled steam leaves the turbine it condenses into water in the cooling tower. The water runs back to the heat exchanger where it vaporizes all over again.</p></sec></app></app-group></back></article>