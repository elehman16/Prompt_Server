<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biomed Res Int</journal-id><journal-id journal-id-type="iso-abbrev">Biomed Res Int</journal-id><journal-id journal-id-type="publisher-id">BMRI</journal-id><journal-title-group><journal-title>BioMed Research International</journal-title></journal-title-group><issn pub-type="ppub">2314-6133</issn><issn pub-type="epub">2314-6141</issn><publisher><publisher-name>Hindawi Publishing Corporation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24829910</article-id><article-id pub-id-type="pmc">4009317</article-id><article-id pub-id-type="doi">10.1155/2014/646347</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Ghostman: Augmented Reality Application for Telerehabilitation and Remote Instruction of a Novel Motor Skill</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Chinthammit</surname><given-names>Winyu</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-1721-3956</contrib-id><name><surname>Merritt</surname><given-names>Troy</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8566-7693</contrib-id><name><surname>Pedersen</surname><given-names>Scott</given-names></name><xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-8863-3491</contrib-id><name><surname>Williams</surname><given-names>Andrew</given-names></name><xref ref-type="aff" rid="I3">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Visentin</surname><given-names>Denis</given-names></name><xref ref-type="aff" rid="I3">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9480-7822</contrib-id><name><surname>Rowe</surname><given-names>Robert</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9240-5475</contrib-id><name><surname>Furness</surname><given-names>Thomas</given-names></name><xref ref-type="aff" rid="I4">
<sup>4</sup>
</xref></contrib></contrib-group><aff id="I1"><sup>1</sup>Human Interface Technology Laboratory Australia (HIT Lab AU), School of Engineering and ICT, University of Tasmania, Launceston, Tas 7250, Australia</aff><aff id="I2"><sup>2</sup>Active Work Laboratory, Faculty of Education, University of Tasmania, Launceston, Tas 7250, Australia</aff><aff id="I3"><sup>3</sup>School of Health Sciences, University of Tasmania, Launceston, Tas 7250, Australia</aff><aff id="I4"><sup>4</sup>Human Interface Technology Laboratory (HIT Lab), University of Washington, Seattle, WA 98195, USA</aff><author-notes><corresp id="cor1">*Winyu Chinthammit: <email>winyu.chinthammit@utas.edu.au</email></corresp><fn fn-type="other"><p>Academic Editor: Alessandro De Mauro</p></fn></author-notes><pub-date pub-type="ppub"><year>2014</year></pub-date><pub-date pub-type="epub"><day>15</day><month>4</month><year>2014</year></pub-date><volume>2014</volume><elocation-id>646347</elocation-id><history><date date-type="received"><day>28</day><month>1</month><year>2014</year></date><date date-type="rev-recd"><day>12</day><month>3</month><year>2014</year></date><date date-type="accepted"><day>13</day><month>3</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Winyu Chinthammit et al.</copyright-statement><copyright-year>2014</copyright-year><license xlink:href="https://creativecommons.org/licenses/by/3.0/"><license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>This paper describes a pilot study using a prototype telerehabilitation system (Ghostman). Ghostman is a visual augmentation system designed to allow a physical therapist and patient to inhabit each other's viewpoint in an augmented real-world environment. This allows the therapist to deliver instruction remotely and observe performance of a motor skill through the patient's point of view. In a pilot study, we investigated the efficacy of Ghostman by using it to teach participants to use chopsticks. Participants were randomized to a single training session, receiving either Ghostman or face-to-face instructions by the same skilled instructor. Learning was assessed by measuring retention of skills at 24-hour and 7-day post instruction. As hypothesised, there were no differences in reduction of error or time to completion between participants using Ghostman compared to those receiving face-to-face instruction. These initial results in a healthy population are promising and demonstrate the potential application of this technology to patients requiring learning or relearning of motor skills as may be required following a stroke or brain injury.</p></abstract></article-meta></front><body><sec id="sec1"><title>1. Introduction</title><p>
To minimise ongoing disability and its associated costs, rehabilitation following surgery, stroke, or a musculoskeletal injury typically requires a course of frequent consultations with allied health professionals to determine and direct a treatment during the rehabilitation period [<xref rid="B21" ref-type="bibr">1</xref>]. Ageing is associated with increased disability. As the population ages the need for rehabilitation services will increase, placing additional stress on health services staff and budgets [<xref rid="B24" ref-type="bibr">2</xref>]. In addition, costs associated with transporting patients long distances and associated decreases in productivity, particularly for patients from rural areas, will add to the community burden of delivering appropriate services. This will place increasing stress on health services and consequently therapeutic solutions need to become more flexible in delivery.</p><p>Best practice face-to-face instruction involves the therapist describing the movement with focus on key areas, performing the movement observed by the trainee and then the trainee practising the movement while the trainer provides verbal feedback on performance, and in some cases manually assisting the target movement. In this situation it has been demonstrated that facilitation of the patient's movement or motor performance is a critical part of the prescribed exercise [<xref rid="B15" ref-type="bibr">3</xref>]. In contrast, the lower end of the therapeutic scale may involve patients only receiving brief instruction in the therapist's office and then being sent home to practice the new skills by themselves with only a printed sheet of verbal instructions provided by the therapist to consult (sometimes with model drawings). Alarmingly, the latter example is the most common and is usually attributed to high patient caseloads and limited availability of specialists concentrated within geographical locations outside of metropolitan areas.</p><p>Telerehabilitation combines telecommunication, sensing and display technologies, and computing technologies to enable rehabilitation to be conducted at a distance [<xref rid="B9" ref-type="bibr">4</xref>]. A telerehabilitation system can increase the reach of a therapist, by enabling them to deliver instruction and assess patient performance remotely. To facilitate this increase in reach and reduction in cost, a system must allow the therapist to perform these services remotely. That is, by reducing the need for patient travel, the cost of accessing rehabilitation services is reduced. There is also a lower chance of further injury and less discomfort for the patient, which may also reduce the impact on the patient's caregiver. By using technology to measure and assess the patient's performance, less time is needed for assessment and, consequently, the efficiency of the therapist may also be improved. By improving the intensity of therapy sessions, greater functional gains can occur [<xref rid="B4" ref-type="bibr">5</xref>].</p><p>Video-based approaches allow for the remote delivery of instruction and the monitoring of patient performance [<xref rid="B10" ref-type="bibr">6</xref>, <xref rid="B18" ref-type="bibr">7</xref>]. Another approach is to capture patient performance and display it in a virtual environment. Performance capture can be achieved via sensor-based approaches, such as data gloves [<xref rid="B23" ref-type="bibr">8</xref>, <xref rid="B27" ref-type="bibr">9</xref>] and electromagnetic trackers [<xref rid="B23" ref-type="bibr">8</xref>, <xref rid="B7" ref-type="bibr">10</xref>&#x02013;<xref rid="B25" ref-type="bibr">12</xref>], or vision-based approaches such as a webcam [<xref rid="B17" ref-type="bibr">13</xref>] or marker tracking [<xref rid="B2" ref-type="bibr">14</xref>&#x02013;<xref rid="B16" ref-type="bibr">16</xref>]. This performance information can be displayed in a completely virtual environment [<xref rid="B7" ref-type="bibr">10</xref>] or augmented into the real world [<xref rid="B2" ref-type="bibr">14</xref>].</p><p>Virtual reality (VR) and augmented reality (AR) are potential methods of delivering rehabilitative health services remotely. Both have been effective in the delivery of finger and hand rehabilitation after stroke [<xref rid="B1" ref-type="bibr">17</xref>, <xref rid="B22" ref-type="bibr">18</xref>] while VR has also been shown to result in significant improvements in motor function and laterality index score in chronic stroke patients [<xref rid="B29" ref-type="bibr">19</xref>]. VR systems have been effectively implemented in telerehabilitation [<xref rid="B26" ref-type="bibr">20</xref>] and for remote training [<xref rid="B19" ref-type="bibr">21</xref>]. AR systems have been shown to be capable of measuring task-completion time, compactness of task, and speed of hand movement by capturing the patients' hand movements whilst moving a tangible object [<xref rid="B2" ref-type="bibr">14</xref>] or with marker-based tracking [<xref rid="B13" ref-type="bibr">15</xref>]. Khademi et al. [<xref rid="B16" ref-type="bibr">16</xref>] used haptic feedback in conjunction with AR to measure stiffness in a user's arm.</p><p>There is evidence that training outcomes are positive when users utilised a first-person viewpoint [<xref rid="B18" ref-type="bibr">7</xref>, <xref rid="B28" ref-type="bibr">22</xref>]. Yang et al. used a VR approach with &#x0201c;ghost&#x0201d; metaphor and a first-person viewpoint. The motions of trainer/trainee were captured and recreated entirely in the virtual environment in which the trainer operated. However, the use of the VR approach prevents the trainer to view the real environment, which raises concerns in safety issues and a lack of ability to view other subtle visual cues in the environment such as other parts of the limbs not being tracked/targeted. Kumagai et al. [<xref rid="B18" ref-type="bibr">7</xref>] used an AR approach. While it is rendered with a first-person viewpoint, the trainer/trainee was viewing the scene via external computer monitors, as a result, causing a viewpoint displacement between the physical limbs and displayed limbs. The displacement requires users to perform an additional cognitive step, a hand-eye coordination operation (similar to using a computer mouse to move a cursor on the display screen). Nevertheless, the benefit of the first-person view is still evident and likely due to the fact that there is a more direct and correct transfer of proprioceptive information [<xref rid="B28" ref-type="bibr">22</xref>], which leads to the core of our proposed Ghostman Design.</p></sec><sec id="sec2"><title>2. Ghostman Design</title><p>This paper discusses proof of concept of our proposed telerehabilitation system, called &#x0201c;Ghostman.&#x0201d; Ghostman is a wearable visual augmentation system in egocentric view through which users can observe their own movement being overlaid with a &#x0201c;ghost&#x0201d; image of the instructor's body in real time. Unlike Yang and Kim [<xref rid="B28" ref-type="bibr">22</xref>], the Ghostman uses an AR approach, in which the viewing of the real-world environment is preserved. This allows the users to &#x0201c;inhabit&#x0201d; the other's viewpoint, in a technique we call<italic> inhabiting visual augmentation</italic>, illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The use of AR technology enables Ghostman to closely match sensory modalities of the user such as correct and natural visual cues. The Ghostman makes use of a wearable display, a head mounted display (HMD), which helps minimize the viewpoint displacement between the rendered limbs and the actual limbs. By wearing an HMD, trainees can intuitively mimic the movements of the trainer by observing both their own and the trainer's movements simultaneously through the use of colocated overlaying AR images. An HMD with a pair of inbuilt stereoscopic cameras is connected to a desktop computer, which processes and renders the video, as well as providing network communication.</p><p>Ghostman consists of two subsystems: one is operated by a trainee (patient) and the other by a trainer (therapist), as illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The two subsystems communicate over the internet network, which enables Ghostman to be applied remotely in telepresence applications. Each of the Ghostman subsystems consists of an AR HMD (Vuzix 920AR) that contains a pair of 640 &#x000d7; 480 liquid crystal displays (LCD), a pair of 640 &#x000d7; 480 video cameras, and 3 degrees-of-freedom (DoF) orientation sensors (pitch, yaw, and roll). Each camera is located directly in front of the LCD for each eye minimizing the eye displacement between the display viewpoint and the camera viewpoint, allowing the user to effectively &#x0201c;see through&#x0201d; the HMD with a video see-through AR view. A key design for Ghostman is its ability to visually align the viewpoints of the two HMDs. In order to achieve this posture alignment, one would have to capture the complete movement (6 DoF: 3 orientations and 3 translations) of the heads and hands of both trainer and trainee. However, in this initial study, our aim was to study the performance of a given task with a focus on using the inhabiting visual augmentation technique. Therefore, we decided to limit our task with only orientation head movement to simplify our setup; as a result, our Ghostman proof-of-concept system used only the HMD inbuilt orientation sensor to generate a navigation cue (shown at the top right-handed corner in <xref ref-type="fig" rid="fig2">Figure 2</xref>) within the HMD display to allow the trainer to align his head orientation with the trainee's prior to the instructions being given. Furthermore, in order to properly visually align the body parts of the trainer and the trainee, we would have to rescale the overlaid remote limb (depending upon if it is a trainer or trainee) to match the scale of the local limb (undistorted) prior to the overlaying process. The rescaling process is a complicated process, which requires the system to estimate the size of the limbs (e.g., the length of forearm, fingers, and position of elbow) of both trainer/trainee and then rescale the remote limb to match the local limb in real time. However, the focus of this initial study is on the effectiveness of using an inhabiting visual augmentation technique; consequentially, we simplified the setup by assuming the size of the limb (i.e., hand) is the same across all users and therefore there is no rescaling required. It is worth noting that this limb size assumption is not detrimental to this pilot study, as the only visible limb is the hand and lower part of the forearm; thus the effect of rescaling is very small.</p><p>Learning by imitation is a key motor learning strategy that has been used previously to evaluate telerehabilitation systems [<xref rid="B11" ref-type="bibr">23</xref>]. With Ghostman, the trainee can learn the movements of the trainer by<italic> simultaneously</italic> observing both his/her own and the trainer's movements through the use of real-time overlaying images. Furthermore, Ghostman works in reciprocal fashion allowing the trainer to provide corrective movement feedback in real time.</p><p>Ghostman provides a unique environment in delivering movement instructions in egocentric view with a method of integrating description (audio), performance/practice (visual), and assistance/correction (evaluation). With its real-time capability, Ghostman also has the advantage of having the timing of movements as a natural feature of the system, overcoming one of the obstacles when learning a new skill. Therefore, Ghostman might provide an alternative solution in providing therapeutic instructions where more traditional face-to-face methods are difficult to negotiate.</p><p>For the cost analysis, each Ghostman system costs approximately $3,000 (AUD) to implement with current hardware. The current cost may not really be suitable for large-scale deployment to patients' home but could be more practical to a remote healthcare community facility where it would only require patients to travel for a short distance.</p></sec><sec id="sec3"><title>3. Pilot Study</title><p>To prove the concept of system a pilot study was conducted to determine the effectiveness of Ghostman in comparison to a best practice method used by physio- and occupational therapists to deliver a complex motor learning sequence to patients. A key component of rehabilitation is the teaching of simple motor skills. The teaching of these skills requires time and expertise of a therapist. The availability and cost of these demands are leading to the use of a telerehabilitation model to reach a wider population of potential clients. The results of this study might provide valuable information regarding the effectiveness of this innovation for motor skill learning, with important implications for the delivery of therapy in an e-health environment.</p><p>The aim of this study was to determine the effectiveness of using Ghostman in assisting individuals to learn to perform a novel motor skill using their dominant hand (manipulating chopsticks). The use of chopsticks is a task that can be described as a novel skill that can be learnt within a few minutes and can lead to various levels of expertise. Due to the limitations of the field of view of the Ghostman HMD's cameras, this task was deemed suitable for instructional purposes.</p><p>We hypothesise that novice individuals, who use Ghostman to shadow a skilled performer in real time, will be as effective in learning chopstick manipulation technique as individuals who will be similarly trained using a traditional therapeutic method of observing and receiving feedback from a skilled performer in a face-to-face clinical environment. Thus, we tested the null hypothesis with the aim to accept this hypothesis demonstrating that the two types of service delivery are not significantly different in terms of motor learning a novel skill. Due to the limited availability of rehabilitation patients we chose to conduct this pilot study on a healthy population using a convenient sample to provide data for proof of concept of this telerehabilitation.</p></sec><sec id="sec4"><title>4. Experiment Design</title><p>A randomised controlled pilot study was conducted to evaluate the efficacy of the Ghostman prototype as a tool for remote teaching of a novel motor skill using chopsticks. Participants were randomised to receive one teaching session with a skilled instructor delivering the lesson via traditional face-to-face interaction or delivering the lesson via an inhabiting visual augmentation system (Ghostman).</p><sec id="sec4.1"><title>4.1. Inclusion Criteria</title><p>Adult participants were self-identified as right-handed, as the skilled instructor was right-handed. All participants, who were unfamiliar with using chopsticks (&#x02264; once per year), were recruited through the use of flyers advertising the study.</p></sec><sec id="sec4.2"><title>4.2. Exclusion Criteria</title><p>Individuals with previously diagnosed dementia or who were unable to comprehend English, individuals with neurological disorders that may affect their ability to learn motor skills, and individuals who had any other conditions preventing use of their right hand were excluded from the study.</p></sec><sec id="sec4.3"><title>4.3. Protocol</title><p>Degree of handedness was assessed using a widely used and validated inventory [<xref rid="B5" ref-type="bibr">24</xref>]. The testing protocol was designed to follow standard motor learning experiment principles that separate actual skill learning from performance improvements through the use of retention tests [<xref rid="B6" ref-type="bibr">25</xref>]. The protocol involved a 7-minute training session and four identical performance tests that were performed at four different sequential times: prior to training (pretest), 5 minutes after training (posttest), 24 hours after training (retention 1), and 7 days after training (retention 2). In each of the tests, participants were seated in front of two identical shallow bowls at a distance of 30&#x02009;cm from the edge of the table where the participant seated (<xref ref-type="fig" rid="fig3">Figure 3</xref>&#x02014;experiment setup). The source bowl was placed 15&#x02009;cm to the left side of the participant's midline (xiphoid process) and contained 20 small plastic blocks, all of similar size. The target bowl, which was placed 15&#x02009;cm to the right side of the participant's midline, was initially empty. Participants were presented with a pair of chopsticks and instructed to transfer all the blocks one at a time to the target bowl. The instructor replaced all dropped pieces back into the source bowl. Total skill errors, the primary dependent variable, were defined as any drops (either within the source bowl or in transit between the two bowls) or gripping errors within the source bowl. The number of skill errors made during each test session was recorded. When blocks were dropped in transit, the instructor collected the errant piece and placed it in the source bowl by hand while the participant continued with the task by attempting to move the next piece. Task completion time, the secondary dependent variable, was measured using a stopwatch to record the time taken to successfully transfer 20 blocks from the source bowl to the target bowl.</p><p>Both groups received standardised training from the same expert instructor. The only difference was the method of delivery: Ghostman or face-to-face. The training sessions commenced with instruction on how to hold chopsticks, followed by how to pick up objects with chopsticks. Participants then proceeded to perform a series of practice exercises using blocks of various sizes and received ongoing feedback about their performance from the instructor continuously throughout the seven-minute training session. No feedback was provided during the testing sessions. Ghostman participants were located within the same room as the instructor who was concealed behind a screen, whereas the face-to-face participants had the instructor sitting next to the participant for the duration of the training session. Video recordings of the hand movement and a top view of the test area (i.e., table, bowls) were made of each testing and training session for later analysis.</p><p>A user experience questionnaire was provided to assess user perceptions of the instruction methods. Participants were provided a questionnaire to rate their perceptions of the training methods. The five following statements were presented and answered using a 5-point Likert scale, with anchors of 5 corresponding to strong agreement with the statement and 1 indicating strong disagreement with the statement:</p><p>
<list list-type="order"><list-item><p>the instructions I was given were easy to follow,</p></list-item><list-item><p>the instructions helped me learn how to use chopsticks,</p></list-item><list-item><p>the instructor clearly showed me how to hold the chopsticks,</p></list-item><list-item><p>the training programme helped me to learn how to use chopsticks,</p></list-item><list-item><p>I feel I am better able to use chopsticks than before the study.</p></list-item></list>
</p></sec><sec id="sec4.4"><title>4.4. Data Analysis</title><p>Demographic data were compared at baseline using independent samples<italic> t</italic>-tests. Questionnaire data were analysed using independent samples<italic> t</italic>-tests to determine any group differences. A 2 (group) X 4 (test) mixed design ANOVA with repeated measures on the last factor was used to test for significant differences for the two dependent variables (total skill error and task completion time) separately, with an alpha level set at 0.05. All statistics were analyzed using IBM SPSS Statistics package version 22. Descriptive statistics were reported as means and standard deviations.</p></sec></sec><sec id="sec5"><title>5. Results</title><p>Preliminary data were collected from 12 participants (6 Ghostman/6 face-to-face), except for the questionnaire data where data were obtained for only five Ghostman participants. There were no differences between the two groups for any variable at baseline (<xref ref-type="table" rid="tab1">Table 1</xref>).</p><p>Regarding the primary dependent variable, there was no significant interaction (<italic>F</italic>(3,30) = 0.55, <italic>P</italic> = 0.65) or main effects for group (<italic>F</italic>(1,10) = 0.40, <italic>P</italic> = 0.54) or test (<italic>F</italic>(3,30) = 1.00, <italic>P</italic> = 0.40) for total skill errors (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><p>As illustrated in <xref ref-type="fig" rid="fig4">Figure 4</xref>, the Ghostman group improved their total skill errors throughout the study as can be interpreted in the mean values from pretest (<italic>M</italic> = 6.33 &#x000b1; 6.28) to posttest (<italic>M</italic> = 5.83 &#x000b1; 1.94) to 24-hour retention (<italic>M</italic> = 4.67 &#x000b1; 1.63) to seven-day retention (<italic>M</italic> = 4.33 &#x000b1; 3.20), whereas the face group got worse from pretest (<italic>M</italic> = 5.50 &#x000b1; 2.43) to posttest (M = 7.67 &#x000b1; 2.58), showed slight improvements after 24 hours (<italic>M</italic> = 6.00 &#x000b1; 3.29), and finally returned to baseline performance after seven days (<italic>M</italic> = 5.50 &#x000b1; 3.45) although none of these differences were significant.</p><p>Similarly, for the task completion time dependent variable there was no significant interaction (<italic>F</italic>(3,30) = 0.85, <italic>P</italic> = 0.48) or main effects for group (<italic>F</italic>(1,10) = 0.11, <italic>P</italic> = 0.75) or test (<italic>F</italic>(3,30) = 2.23, <italic>P</italic> = 0.10) (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The detail data of <xref ref-type="fig" rid="fig5">Figure 5</xref> are as follows: pretest (Ghostman: <italic>M</italic> = 70.50 &#x000b1; 16.05, face-to-face: <italic>M</italic> = 72.50 &#x000b1; 27.42), posttest (Ghostman: <italic>M</italic> = 62.33 &#x000b1; 12.37, face-to-face: <italic>M</italic> = 69.67 &#x000b1; 23.19), 24-hour retention (Ghostman: <italic>M</italic> = 64.33 &#x000b1; 28.12, face-to-face: <italic>M</italic> = 60.17 &#x000b1; 16.57), and 7-day retention (Ghostman: <italic>M</italic> = 57.50 &#x000b1; 12.29, face-to-face: <italic>M</italic> = 65.50 &#x000b1; 14.90)</p><p>Finally, there were no differences between groups for any of the Likert scale statements regarding user perceptions of the training methods (<xref ref-type="table" rid="tab2">Table 2</xref>).</p></sec><sec id="sec6"><title>6. Discussion</title><p>The primary outcome of this study (Figures <xref ref-type="fig" rid="fig4">4</xref> and <xref ref-type="fig" rid="fig5">5</xref>) demonstrated that Ghostman is as effective, in terms of reduction in skill errors and improvements in task completion time, as current best practice face-to-face instruction for learning a novel skill (null hypothesis). Moreover, from the user experience questionnaires (<xref ref-type="table" rid="tab2">Table 2</xref>), participants also felt Ghostman training was as effective as face-to-face training. This provided early evidence that the inhabiting visual augmentation (Ghostman) could be an effective technique for motor learning in a telerehabilitation context. As this is the first study of its kind using telerehabilitation to test the learning of novel skills and there is no previous data for comparison, this pilot study provides promising results for future studies.</p><p>Previously, home-based rehabilitation has been demonstrated to be more cost effective than hospital-based rehabilitation [<xref rid="B3" ref-type="bibr">26</xref>]. Traditionally, both forms of rehabilitation involve colocation of a therapist and a patient in the same setting, which involves costs associated with transport of the patient/therapist to the setting. The results of the current study indicate that Ghostman is an effective learning tool, which provides further support for the efficacy of a telerehabilitation approach. In addition, telerehabilitation has real potential to reduce cost of rehabilitation delivery by reducing time and travel-related expenses for practitioners and patients alike. However, the cost effectiveness of telerehabilitation delivery has yet to be established [<xref rid="B20" ref-type="bibr">27</xref>]. Moreover, the Ghostman telerehabilitation system requires further, larger-scale investigations into the efficacy of this system with clinical populations requiring physical rehabilitation, such as stroke patients or those suffering Parkinson's disease.</p><sec id="sec6.1"><title>6.1. Limitations</title><p>Caution in interpreting these data is warranted due to the small, convenient sample size used in this study (<italic>n</italic> = 12). As a result, it might be suggested that the lack of statistically significant difference in outcomes between the two training methods might be due to the study being underpowered and thereby making Ghostman appear to be as effective a learning tool as traditional methods. To test the theory that the study was underpowered thereby making Ghostman appear more effective than it is, we conducted post hoc power calculations on the data obtained in this study. These analyses demonstrated that, on the basis of existing data, a total of 508 participants would be required to yield a statistically significant difference in changes in error rate, while 840 participants would be required to produce a statistically significant difference in changes in time to complete the task. In addition, there were greater mean improvements in learning (24-hour and 7-day retention tests) as identified by reductions in skill errors and task completion time when using Ghostman indicating that obtaining a sample size of that projected magnitude would be likely to demonstrate Ghostman to be a more effective learning tool than face-to-face instruction. Another limitation of the study was the training period. Training consisted of a single 7-minute session, regardless of the group. This may not have been a long enough exposure to produce significant improvements in participants. However, this brief amount of training time is consistent with the instruction time typically utilized by therapists when first meeting with new patients. Finally, participants that have been used in this research have been drawn from a healthy population. As such, it is difficult to claim that the technique is valid without examining its efficacy with participants that are currently completing a course of rehabilitation.</p></sec></sec><sec id="sec7"><title>7. Conclusions</title><p>This paper describes our proposed telerehabilitation system (Ghostman) and a pilot study using Ghostman for remotely teaching a novel motor skill. Findings from the pilot study indicated that Ghostman is as effective for motor learning, in terms of reduction in skill errors and improvements in task completion time, as the current best practice face-to-face training. This suggests that Ghostman could be an effective technique for telerehabilitation and for remote instruction of novel motor skill learning applications by physio- and occupational therapists. Given the difficulties that rural and remote communities experience in gaining face-to-face access to health professionals, this outcome holds promise for future development of this technology.</p><p>While the early results are encouraging, further development of the Ghostman system and larger-scale studies are required to determine its efficacy in telerehabilitation context. The future development on the current Ghostman system will address the following three main areas: (1) the limited field of view of the camera and of the display (HMD), (2) the rescaling of the remote user's limb (to match with the (undistorted) local limb), and (3) the reduction of the unit cost for large-scale deployment. With these technical improvements, the Ghostman system can then be tested in a large group of participants with more comprehensive case studies that includes expanding ranges of the user movement and working with full-bodied tasks. Ultimately, this would provide valid evidence that the system is ready for real patient trials.</p></sec></body><back><ack><title>Acknowledgments</title><p>The authors would like to thank the University of Tasmania, the Deputy Vice Chancellor (Research) Professor Patrick Nixon, and Pro-Vice Chancellor (Regional Development) Professor Janelle Allison for their support to the project. Also, the authors would like to thank Bruce Andrews, Jonathan O'Duffy, Peter Seaton, Shannon Woolley, Shaun Walker, and Yuzhe Yang for their contribution to the project.</p></ack><sec sec-type="conflict"><title>Conflict of Interests</title><p>The authors declare that there is no conflict of interests regarding the publication of this paper.</p></sec><ref-list><ref id="B21"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levin</surname><given-names>S</given-names></name></person-group><article-title>Early mobilization speeds recovery</article-title><source><italic>Physician and Sportsmedicine</italic></source><year>1993</year><volume>21</volume><issue>8</issue><fpage>70</fpage><lpage>74</lpage><pub-id pub-id-type="other">2-s2.0-0027323139</pub-id><pub-id pub-id-type="pmid">27439131</pub-id></element-citation></ref><ref id="B24"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendelson</surname><given-names>DN</given-names></name><name><surname>Schwartz</surname><given-names>WB</given-names></name></person-group><article-title>The effects of aging and population growth on health care costs</article-title><source><italic>Health Affairs</italic></source><year>1993</year><volume>12</volume><issue>1</issue><fpage>119</fpage><lpage>125</lpage><pub-id pub-id-type="other">2-s2.0-0027318269</pub-id><pub-id pub-id-type="pmid">8509013</pub-id></element-citation></ref><ref id="B15"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>GM</given-names></name><name><surname>Gwyer</surname><given-names>J</given-names></name><name><surname>Shepard</surname><given-names>KF</given-names></name><name><surname>Hack</surname><given-names>LM</given-names></name></person-group><article-title>Expert practice in physical therapy</article-title><source><italic>Physical Therapy</italic></source><year>2000</year><volume>80</volume><issue>1</issue><fpage>28</fpage><lpage>52</lpage><pub-id pub-id-type="other">2-s2.0-0033958791</pub-id><pub-id pub-id-type="pmid">10623958</pub-id></element-citation></ref><ref id="B9"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>RA</given-names></name><name><surname>Fitzgerald</surname><given-names>SG</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><etal/></person-group><article-title>Telerehabilitation: expanding access to rehabilitation expertise</article-title><source><italic>Proceedings of the IEEE</italic></source><year>2001</year><volume>89</volume><issue>8</issue><fpage>1174</fpage><lpage>1193</lpage><pub-id pub-id-type="other">2-s2.0-11144281858</pub-id></element-citation></ref><ref id="B4"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bode</surname><given-names>RK</given-names></name><name><surname>Heinemann</surname><given-names>AW</given-names></name><name><surname>Semik</surname><given-names>P</given-names></name><name><surname>Mallinson</surname><given-names>T</given-names></name></person-group><article-title>Relative importance of rehabilitation therapy characteristics on functional outcomes for persons with stroke</article-title><source><italic>Stroke</italic></source><year>2004</year><volume>35</volume><issue>11</issue><fpage>2537</fpage><lpage>2542</lpage><pub-id pub-id-type="other">2-s2.0-7644224204</pub-id><pub-id pub-id-type="pmid">15472085</pub-id></element-citation></ref><ref id="B10"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durfee</surname><given-names>WK</given-names></name><name><surname>Savard</surname><given-names>L</given-names></name><name><surname>Weinstein</surname><given-names>S</given-names></name></person-group><article-title>Technical feasibility of teleassessments for rehabilitation</article-title><source><italic>IEEE Transactions on Neural Systems and Rehabilitation Engineering</italic></source><year>2007</year><volume>15</volume><issue>1</issue><fpage>23</fpage><lpage>29</lpage><pub-id pub-id-type="other">2-s2.0-34248586395</pub-id><pub-id pub-id-type="pmid">17436872</pub-id></element-citation></ref><ref id="B18"><label>7</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kumagai</surname><given-names>T</given-names></name><name><surname>Yamashita</surname><given-names>J</given-names></name><name><surname>Morikawa</surname><given-names>O</given-names></name><etal/></person-group><article-title>Distance education system for teaching manual skills in endoscopic paranasal sinus surgery using &#x0201c;HyperMirror&#x0201d; telecommunication interface</article-title><conf-name>Proceedings of the IEEE Virtual Reality (VR '08)</conf-name><conf-date>March 2008</conf-date><fpage>233</fpage><lpage>236</lpage><pub-id pub-id-type="other">2-s2.0-50249170457</pub-id></element-citation></ref><ref id="B23"><label>8</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McNeill</surname><given-names>M</given-names></name><name><surname>Pokluda</surname><given-names>L</given-names></name><name><surname>McDonough</surname><given-names>S</given-names></name><name><surname>Crosbie</surname><given-names>J</given-names></name></person-group><article-title>Immersive virtual reality for upper limb rehabilitation following stroke</article-title><conf-name>Proceedings of the IEEE International Conference on Systems, Man and Cybernetics (SMC '04)</conf-name><conf-date>October 2004</conf-date><fpage>2783</fpage><lpage>2789</lpage><pub-id pub-id-type="other">2-s2.0-15744393732</pub-id></element-citation></ref><ref id="B27"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subramanian</surname><given-names>S</given-names></name><name><surname>Knaut</surname><given-names>LA</given-names></name><name><surname>Beaudoin</surname><given-names>C</given-names></name><name><surname>McFadyen</surname><given-names>BJ</given-names></name><name><surname>Feldman</surname><given-names>AG</given-names></name><name><surname>Levin</surname><given-names>MF</given-names></name></person-group><article-title>Virtual reality environments for post-stroke arm rehabilitation</article-title><source><italic>Journal of NeuroEngineering and Rehabilitation</italic></source><year>2007</year><volume>4, article 20</volume><pub-id pub-id-type="other">2-s2.0-34447502329</pub-id></element-citation></ref><ref id="B7"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burdea</surname><given-names>G</given-names></name><name><surname>Popescu</surname><given-names>V</given-names></name><name><surname>Hentz</surname><given-names>V</given-names></name><name><surname>Colbert</surname><given-names>K</given-names></name></person-group><article-title>Virtual reality-based orthopedic telerehabilitation</article-title><source><italic>IEEE Transactions on Rehabilitation Engineering</italic></source><year>2000</year><volume>8</volume><issue>3</issue><fpage>430</fpage><lpage>432</lpage><pub-id pub-id-type="other">2-s2.0-0034283143</pub-id><pub-id pub-id-type="pmid">11001524</pub-id></element-citation></ref><ref id="B12"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holden</surname><given-names>MK</given-names></name><name><surname>Todorov</surname><given-names>E</given-names></name></person-group><article-title>Use of virtual environments in motor learning and rehabilitation</article-title><source><italic>Handbook of Virtual Environments: Design, Implementation, and Applications</italic></source><year>2002</year><volume>44</volume><fpage>1</fpage><lpage>35</lpage></element-citation></ref><ref id="B25"><label>12</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Piron</surname><given-names>L</given-names></name><name><surname>Tonin</surname><given-names>P</given-names></name><name><surname>Cortese</surname><given-names>F</given-names></name><etal/></person-group><article-title>Post-stroke arm motor telerehabilitation web-based</article-title><conf-name>Proceedings of the 5th International Workshop on Virtual Rehabilitation (IWVR '06)</conf-name><conf-date>August 2006</conf-date><fpage>145</fpage><lpage>148</lpage><pub-id pub-id-type="other">2-s2.0-41649110244</pub-id></element-citation></ref><ref id="B17"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kizony</surname><given-names>R</given-names></name><name><surname>Weiss</surname><given-names>PL</given-names></name><name><surname>Shahar</surname><given-names>M</given-names></name><name><surname>Rand</surname><given-names>D</given-names></name></person-group><article-title>TheraGame: a home based virtual reality rehabilitation system</article-title><source><italic>International Journal on Disability and Human Development</italic></source><year>2006</year><volume>5</volume><issue>3</issue><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="other">2-s2.0-34247195421</pub-id></element-citation></ref><ref id="B2"><label>14</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Alamri</surname><given-names>A</given-names></name><name><surname>Cha</surname><given-names>J</given-names></name><name><surname>Eid</surname><given-names>M</given-names></name><name><surname>Saddik</surname><given-names>AE</given-names></name></person-group><article-title>Evaluating the post-stroke patients progress using an augmented reality rehabilitation system</article-title><conf-name>Proceedings of the IEEE International Workshop on Medical Measurements and Applications (MeMeA '09)</conf-name><conf-date>May 2009</conf-date><fpage>89</fpage><lpage>94</lpage><pub-id pub-id-type="other">2-s2.0-70449645186</pub-id></element-citation></ref><ref id="B13"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hondori</surname><given-names>HM</given-names></name><name><surname>Khademi</surname><given-names>M</given-names></name><name><surname>Dodakian</surname><given-names>L</given-names></name><name><surname>Cramer</surname><given-names>SC</given-names></name><name><surname>Lopes</surname><given-names>CV</given-names></name></person-group><article-title>A spatial augmented reality rehab system for post-stroke hand rehabilitation</article-title><source><italic>Studies in Health Technology and Informatics</italic></source><year>2013</year><volume>184</volume><fpage>279</fpage><lpage>285</lpage><pub-id pub-id-type="pmid">23400171</pub-id></element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Khademi</surname><given-names>M</given-names></name><name><surname>Mousavi Hondori</surname><given-names>H</given-names></name><name><surname>Lopes</surname><given-names>CV</given-names></name><name><surname>Dodakian</surname><given-names>L</given-names></name><name><surname>Cramer</surname><given-names>SC</given-names></name></person-group><article-title>Haptic augmented reality to monitor human arm's stiffness in rehabilitation</article-title><conf-name>Proceedings of the IEEE Conference on Biomedical Engineering and Sciences (IECBES '12)</conf-name><conf-date>2012</conf-date><fpage>892</fpage><lpage>895</lpage></element-citation></ref><ref id="B1"><label>17</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Adamovich</surname><given-names>SV</given-names></name><name><surname>Merians</surname><given-names>AS</given-names></name><name><surname>Boian</surname><given-names>R</given-names></name><etal/></person-group><article-title>A virtual reality based exercise system for hand rehabilitation post-stroke: transfer to function</article-title><conf-name>Proceedings of the 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC '04)</conf-name><conf-date>September 2004</conf-date><fpage>4936</fpage><lpage>4939</lpage><pub-id pub-id-type="other">2-s2.0-11144291509</pub-id></element-citation></ref><ref id="B22"><label>18</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>X</given-names></name><name><surname>Kline</surname><given-names>T</given-names></name><name><surname>Fischer</surname><given-names>HC</given-names></name><name><surname>Stubblefield</surname><given-names>KA</given-names></name><name><surname>Kenyon</surname><given-names>RV</given-names></name><name><surname>Kamper</surname><given-names>DG</given-names></name></person-group><article-title>Integration of augmented reality and assistive devices for post-stroke hand opening rehabilitation</article-title><volume>7</volume><conf-name>Proceedings of the 27th Annual International Conference of the Engineering in Medicine and Biology Society (IEEE-EMBS '05)</conf-name><conf-date>September 2005</conf-date><fpage>6855</fpage><lpage>6858</lpage><pub-id pub-id-type="other">2-s2.0-33846931850</pub-id></element-citation></ref><ref id="B29"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>You</surname><given-names>SH</given-names></name><name><surname>Jang</surname><given-names>SH</given-names></name><name><surname>Kim</surname><given-names>Y-H</given-names></name><etal/></person-group><article-title>Virtual reality-induced cortical reorganization and associated locomotor recovery in chronic stroke: an experimenter-blind randomized study</article-title><source><italic>Stroke</italic></source><year>2005</year><volume>36</volume><issue>6</issue><fpage>1166</fpage><lpage>1171</lpage><pub-id pub-id-type="other">2-s2.0-20444369115</pub-id><pub-id pub-id-type="pmid">15890990</pub-id></element-citation></ref><ref id="B26"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosen</surname><given-names>MJ</given-names></name></person-group><article-title>Telerehabilitation</article-title><source><italic>NeuroRehabilitation</italic></source><year>1999</year><volume>12</volume><issue>1</issue><fpage>11</fpage><lpage>26</lpage><pub-id pub-id-type="other">2-s2.0-0032922499</pub-id></element-citation></ref><ref id="B19"><label>21</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kurillo</surname><given-names>G</given-names></name><name><surname>Bajcsy</surname><given-names>R</given-names></name><name><surname>Nahrsted</surname><given-names>K</given-names></name><name><surname>Kreylos</surname><given-names>O</given-names></name></person-group><article-title>Immersive 3D environment for remote collaboration and training of physical activities</article-title><conf-name>Proceedings of the IEEE Virtual Reality (VR '08)</conf-name><conf-date>March 2008</conf-date><fpage>269</fpage><lpage>270</lpage><pub-id pub-id-type="other">2-s2.0-50249168373</pub-id></element-citation></ref><ref id="B28"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>U</given-names></name><name><surname>Kim</surname><given-names>GJ</given-names></name></person-group><article-title>Implementation and evaluation of &#x0201c;just follow me&#x0201d;: an immersive, VR-based, motion-training system</article-title><source><italic>Presence: Teleoperators and Virtual Environments</italic></source><year>2002</year><volume>11</volume><issue>3</issue><fpage>304</fpage><lpage>323</lpage><pub-id pub-id-type="other">2-s2.0-0036625537</pub-id></element-citation></ref><ref id="B11"><label>23</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holden</surname><given-names>MK</given-names></name></person-group><article-title>Neurorehabilitation using &#x0201c;learning by imitation&#x0201d; in virtual environments</article-title><source><italic>Usability Evaluation and Interface Design: Cognitive Engineering, Intelligent Agents and Virtual Reality</italic></source><year>2001</year><publisher-loc>London, UK</publisher-loc><publisher-name>Lawrence Erlbaum</publisher-name><fpage>624</fpage><lpage>628</lpage></element-citation></ref><ref id="B5"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bryden</surname><given-names>MP</given-names></name></person-group><article-title>Measuring handedness with questionnaires</article-title><source><italic>Neuropsychologia</italic></source><year>1977</year><volume>15</volume><issue>4-5</issue><fpage>617</fpage><lpage>624</lpage><pub-id pub-id-type="other">2-s2.0-0017338397</pub-id><pub-id pub-id-type="pmid">896019</pub-id></element-citation></ref><ref id="B6"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shea</surname><given-names>JB</given-names></name><name><surname>Morgan</surname><given-names>RL</given-names></name></person-group><article-title>Contextual interference effects on the acquisition, retention, and transfer of a motor skill</article-title><source><italic>Journal of Experimental Psychology: Human Learning and Memory</italic></source><year>1979</year><volume>5</volume><issue>2</issue><fpage>179</fpage><lpage>187</lpage><pub-id pub-id-type="other">2-s2.0-0000635383</pub-id></element-citation></ref><ref id="B3"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>C</given-names></name><name><surname>Mhurchu</surname><given-names>CN</given-names></name><name><surname>Rubenach</surname><given-names>S</given-names></name><name><surname>Clark</surname><given-names>M</given-names></name><name><surname>Spencer</surname><given-names>C</given-names></name><name><surname>Winsor</surname><given-names>A</given-names></name></person-group><article-title>Home or hospital for stroke rehabilitation? Results of a randomized controlled trial. II: cost minimization analysis at 6 months</article-title><source><italic>Stroke</italic></source><year>2000</year><volume>31</volume><issue>5</issue><fpage>1032</fpage><lpage>1037</lpage><pub-id pub-id-type="other">2-s2.0-0343238899</pub-id><pub-id pub-id-type="pmid">10797162</pub-id></element-citation></ref><ref id="B20"><label>27</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Laver</surname><given-names>KE</given-names></name><name><surname>Schoene</surname><given-names>D</given-names></name><name><surname>Crotty</surname><given-names>M</given-names></name><name><surname>George</surname><given-names>S</given-names></name><name><surname>Lannin</surname><given-names>NA</given-names></name><name><surname>Sherrington</surname><given-names>C</given-names></name></person-group><source><italic>Telerehabilitation Services for Stroke</italic></source><year>2012</year><publisher-name>The Cochrane Library</publisher-name></element-citation></ref></ref-list></back><floats-group><fig id="fig1" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Ghostman setup.</p></caption><graphic xlink:href="BMRI2014-646347.001"/></fig><fig id="fig2" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Inhabiting visual augmentation.</p></caption><graphic xlink:href="BMRI2014-646347.002"/></fig><fig id="fig3" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Experiment setup.</p></caption><graphic xlink:href="BMRI2014-646347.003"/></fig><fig id="fig4" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Group by test descriptive statistics (mean &#x000b1; standard deviation) for total skills errors (frequency count).</p></caption><graphic xlink:href="BMRI2014-646347.004"/></fig><fig id="fig5" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Group by test descriptive statistics (mean &#x000b1; standard deviation) for task completion time (seconds).</p></caption><graphic xlink:href="BMRI2014-646347.005"/></fig><table-wrap id="tab1" orientation="portrait" position="float"><label>Table 1</label><caption><p>Comparison of demographic data between the treatment groups (mean &#x000b1; standard deviation).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="center" rowspan="1" colspan="1">Ghostman</th><th align="center" rowspan="1" colspan="1">Face-to-face</th><th align="center" rowspan="1" colspan="1">Significance (<italic>P</italic>)</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Gender (M/F)</td><td align="center" rowspan="1" colspan="1">4/2</td><td align="center" rowspan="1" colspan="1">4/2</td><td align="center" rowspan="1" colspan="1">&#x02009;</td></tr><tr><td align="left" rowspan="1" colspan="1">Age (years)</td><td align="center" rowspan="1" colspan="1">36.7 &#x000b1; 11.8</td><td align="center" rowspan="1" colspan="1">42.2 &#x000b1; 14.7</td><td align="center" rowspan="1" colspan="1">0.49</td></tr><tr><td align="left" rowspan="1" colspan="1">Experience <break/>(previous uses)</td><td align="center" rowspan="1" colspan="1">0.2 &#x000b1; 0.4</td><td align="center" rowspan="1" colspan="1">1.0 &#x000b1; 1.5</td><td align="center" rowspan="1" colspan="1">0.23</td></tr><tr><td align="left" rowspan="1" colspan="1">Right handedness (%)</td><td align="center" rowspan="1" colspan="1">74.1 &#x000b1; 23.6</td><td align="center" rowspan="1" colspan="1">93.6 &#x000b1; 9.9</td><td align="center" rowspan="1" colspan="1">0.09</td></tr></tbody></table></table-wrap><table-wrap id="tab2" orientation="portrait" position="float"><label>Table 2</label><caption><p>Group by statement descriptive statistics (mean &#x000b1; standard deviation) for questionnaire data (5-point Likert scale).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">&#x02009;</th><th align="center" rowspan="1" colspan="1">Ghostman <break/>(<italic>n</italic> = 5)</th><th align="center" rowspan="1" colspan="1">Face-to-face <break/>(<italic>n</italic> = 6)</th><th align="center" rowspan="1" colspan="1">Significance <break/>(<italic>P</italic>)</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Statement 1</td><td align="center" rowspan="1" colspan="1">4.60 &#x000b1; 0.55</td><td align="center" rowspan="1" colspan="1">4.67 &#x000b1; 0.52</td><td align="center" rowspan="1" colspan="1">0.84</td></tr><tr><td align="left" rowspan="1" colspan="1">Statement 2</td><td align="center" rowspan="1" colspan="1">4.20 &#x000b1; 0.84</td><td align="center" rowspan="1" colspan="1">4.50 &#x000b1; 0.55</td><td align="center" rowspan="1" colspan="1">0.51</td></tr><tr><td align="left" rowspan="1" colspan="1">Statement 3</td><td align="center" rowspan="1" colspan="1">4.80 &#x000b1; 0.45</td><td align="center" rowspan="1" colspan="1">4.83 &#x000b1; 0.41</td><td align="center" rowspan="1" colspan="1">0.90</td></tr><tr><td align="left" rowspan="1" colspan="1">Statement 4</td><td align="center" rowspan="1" colspan="1">4.40 &#x000b1; 0.55</td><td align="center" rowspan="1" colspan="1">4.17 &#x000b1; 0.75</td><td align="center" rowspan="1" colspan="1">0.57</td></tr><tr><td align="left" rowspan="1" colspan="1">Statement 5</td><td align="center" rowspan="1" colspan="1">4.60 &#x000b1; 0.55</td><td align="center" rowspan="1" colspan="1">4.17 &#x000b1; 0.98</td><td align="center" rowspan="1" colspan="1">0.38</td></tr></tbody></table></table-wrap></floats-group></article>