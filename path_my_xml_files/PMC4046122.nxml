<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24926279</article-id><article-id pub-id-type="pmc">4046122</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2014.00548</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Evaluating visual and auditory contributions to the cognitive restoration effect</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Emfield</surname><given-names>Adam G.</given-names></name><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/131260"/></contrib><contrib contrib-type="author"><name><surname>Neider</surname><given-names>Mark B.</given-names></name><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/46961"/></contrib></contrib-group><aff><institution>Applied Cognition and Aging Lab, Department of Psychology, University of Central Florida</institution><country>Orlando, FL, USA</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Daniel Lakens, Eindhoven University of Technology, Netherlands</p></fn><fn fn-type="edited-by"><p>Reviewed by: Femke Beute, Eindhoven University of Technology, Netherlands; Agnes Elizabeth Van Den Berg, University of Groningen, Netherlands</p></fn><corresp id="fn001">*Correspondence: Mark B. Neider, Department of Psychology, University of Central Florida, 4111 Pictor Ln., Psychology Building 99 Ste. 320, Orlando, FL 32816-1390, USA e-mail: <email xlink:type="simple">mark.neider@ucf.edu</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Cognition, a section of the journal Frontiers in Psychology.</p></fn></author-notes><pub-date pub-type="epub"><day>05</day><month>6</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>5</volume><elocation-id>548</elocation-id><history><date date-type="received"><day>03</day><month>2</month><year>2014</year></date><date date-type="accepted"><day>17</day><month>5</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Emfield and Neider.</copyright-statement><copyright-year>2014</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>It has been suggested that certain real-world environments can have a restorative effect on an individual, as expressed in changes in cognitive performance and mood. Much of this research builds on Attention Restoration Theory (ART), which suggests that environments that have certain characteristics induce cognitive restoration via variations in attentional demands. Specifically, natural environments that require little top-down processing have a positive effect on cognitive performance, while city-like environments show no effect. We characterized the cognitive restoration effect further by examining (1) whether natural visual stimuli, such as blue spaces, were more likely to provide a restorative effect over urban visual stimuli, (2) if increasing immersion with environment-related sound produces a similar or superior effect, (3) if this effect extends to other cognitive tasks, such as the functional field of view (FFOV), and (4) if we could better understand this effect by providing controls beyond previous works. We had 202 participants complete a cognitive task battery, consisting of a reverse digit span task, the attention network task, and the FFOV task prior to and immediately after a restoration period. In the restoration period, participants were assigned to one of seven conditions in which they listened to natural or urban sounds, watched images of natural or urban environments, or a combination of both. Additionally, some participants were in a control group with exposure to neither picture nor sound. While we found some indication of practice effects, there were no differential effects of restoration observed in any of our cognitive tasks, regardless of condition. We did, however, find evidence that our nature images and sounds were more relaxing than their urban counterparts. Overall, our findings suggest that acute exposure to relaxing pictorial and auditory stimulus is insufficient to induce improvements in cognitive performance.</p></abstract><kwd-group><kwd>cognitive restoration</kwd><kwd>Attention Restoration Theory</kwd><kwd>natural environments</kwd><kwd>urban environments</kwd><kwd>immersion</kwd><kwd>mood</kwd><kwd>attention</kwd></kwd-group><counts><fig-count count="1"/><table-count count="5"/><equation-count count="0"/><ref-count count="57"/><page-count count="11"/><word-count count="9934"/></counts></article-meta></front><body><sec sec-type="introduction" id="s1"><title>Introduction</title><p>An increasing number of people have chosen to call urban areas their homes. In the US, it is estimated that 82% of the population resides in cities and suburbs. World-wide, the urban population is approximately 50.5%, with an annual increase of 1.85% (Urbanization, <xref rid="B50" ref-type="bibr">2011</xref>). Despite our continued urbanization, many people spend a fair amount of their time and money trying to <italic>leave</italic> urban environments in favor of recreational activities in locales where nature is more prevalent than concrete (e.g., taking a hike in the woods or spending a day at the beach). Given the trend that people migrate toward urban areas when establishing residence, what is it that draws them back out to nature, and are there tangible benefits associated with natural environments?</p><p>The desire to spend time in natural environments has been discussed extensively, and considered heavily in the context of urban planning (Olmsted, <xref rid="B33" ref-type="bibr">1870</xref>). A growing number of studies seem to support increased access to nature-like environments in urban settings (e.g., parks). There also appears to be an emerging consensus that spending time in natural environments engenders tangible benefits in both self-reported well-being (Ulrich et al., <xref rid="B49" ref-type="bibr">1991</xref>; Herzog et al., <xref rid="B22" ref-type="bibr">1997</xref>; Staats and Hartig, <xref rid="B41" ref-type="bibr">2004</xref>; Hartig and Staats, <xref rid="B21" ref-type="bibr">2006</xref>) and overall cognitive function (Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>). Furthermore, it has been suggested that exposure to pictures of natural environments may reduce pain in patients undergoing bone marrow aspiration and biopsies (Lechtzin et al., <xref rid="B30" ref-type="bibr">2010</xref>), and can result in many other health and wellness benefits (Velarde et al., <xref rid="B52" ref-type="bibr">2007</xref>; Depledge et al., <xref rid="B12" ref-type="bibr">2011</xref>).</p><p>The mechanisms underlying these nature-related benefits, however, have been the subject of much debate, and several theories have emerged to provide a framework within which existing findings might be contextualized. Two of these theories are Stress Reduction Theory (SRT; Ulrich, <xref rid="B48" ref-type="bibr">1983</xref>) and Attention Restoration Theory (Kaplan and Kaplan, <xref rid="B25" ref-type="bibr">1989</xref>; Kaplan, <xref rid="B26" ref-type="bibr">1995</xref>). SRT focuses primarily on the effects of natural environments on affect, and suggests that spending time in natural environments evokes a positive initial affective response and concomitant change in physiological responses indicative of stress reduction. Indeed, numerous studies have provided some support for this by demonstrating an increase in positive affect and a drop in blood pressure (Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>), reduced heart rate (Laumann et al., <xref rid="B29" ref-type="bibr">2003</xref>), and a series of other physiological stress measures (Ulrich et al., <xref rid="B49" ref-type="bibr">1991</xref>; van den Berg and Custers, <xref rid="B50a" ref-type="bibr">2011</xref>) when observers are exposed to natural environments. However, the benefits of exposure to natural environments are not limited to improvements in affect and reductions in physiological stress; changes in cognitive function may also reflect benefits.</p><p>Here we focus on ART, which credits improvements in cognitive performance to the restoration of direct attention after fatigue (Kaplan, <xref rid="B26" ref-type="bibr">1995</xref>). Specifically, ART argues that the act of directing attention requires effort and leads to fatigue, reducing a person's ability to maintain performance, remain vigilant, and even increases the likelihood of irritability. One key element of this fatigue is a reduced ability to inhibit distraction. Importantly, once attentional capacity begins to diminish, it may be restored through various means, including traditional rest and sleep. However, interesting questions also arise when this is examined in the short-term; ART argues that, under the correct circumstances, the restoration of direct attention can take place by being exposed to the correct type of environment. In order to overcome fatigue, this environment must have four elements: (1) it must <italic>be away</italic> from the fatigue-inducing environment and from the typical daily environment of a person; (2) it must <italic>have extent</italic>, or be coherent, connected, and extensive enough to provide sufficient richness to captivate the mind; (3) it must <italic>cause soft fascination</italic>, or effortlessly hold the individual's attention; and (4) it must <italic>be compatible</italic> with the person's task-at-hand, such that it allows for restoration without distraction. Per ART, an environment which contains all four of these elements, in sufficient quantity, should be restorative.</p><p>Traditionally, the literature has discussed nature as being a fine exemplar of a restorative environment. In particular, the aquatic environments used in the current study meet the four requirements for restorativeness (Kaplan, <xref rid="B26" ref-type="bibr">1995</xref>). Oceans and beaches meet the criteria of being away conceptually. These spaces are also coherent and rich, and can engage the mind, giving them extent. They also cause soft fascination, or involuntary attention capture, through a moderate level of stimulation that requires limited need for thought. Finally, a person who seeks such an environment as a method of restoration and reflection will find compatibility, with little to distract from these goals. The theory also argues that most urban environments are sufficiently lacking in one or more of these areas (Herzog et al., <xref rid="B22" ref-type="bibr">1997</xref>), though some urban environments, such as museums, may still fit the bill for restoration (Kaplan et al., <xref rid="B27" ref-type="bibr">1993</xref>).</p><p>The criteria for elucidating soft fascination warrants further discussion in the context of cognitive restoration. More recently, research has begun to discuss ART in the context of the different cognitive processes that attention may require (Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>). The involuntary attention capture in nature primarily requires bottom-up processing, which is sufficient to hold attention, but in a limited manner. Conversely, an urban environment results in more dramatic attention capture and a greater level of directed attention.</p><p>Research on the benefits of cognitive restoration has focused on the observation of changes in task performance after exposure to natural or urban environments. When exposed to a natural environment, directly or through pictures, research has shown improved performance on the Necker Cube Pattern Control Task (Tennessen and Cimprich, <xref rid="B45" ref-type="bibr">1995</xref>; Taylor et al., <xref rid="B44" ref-type="bibr">2002</xref>; Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>), the digit span task (Tennessen and Cimprich, <xref rid="B45" ref-type="bibr">1995</xref>; Taylor et al., <xref rid="B44" ref-type="bibr">2002</xref>; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>), and the Attention Network Task (ANT; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>). For example, Berman et al. (<xref rid="B5" ref-type="bibr">2008</xref>) demonstrated that the number of correct trials on a digit span task increased three times as much after walking in a natural environment compared to walking in an urban setting, and increased by nearly 30% after simply viewing pictures of Nova Scotia when compared to exposure to urban pictures. Likewise, performance on the executive control portion of the ANT improved when participants were exposed to nature pictures, and decreased when participants were exposed to urban pictures. A similar pattern has been observed on the backward digit span task in individuals with depression (Berman et al., <xref rid="B6" ref-type="bibr">2012</xref>) and in children with attention deficits (Taylor and Kuo, <xref rid="B43" ref-type="bibr">2009</xref>).</p><p>However, despite previous studies, questions regarding the robustness of the cognitive restoration effect remain open. White et al. (<xref rid="B54" ref-type="bibr">2010</xref>) raised concerns about the images in previous studies lacking standardization; in some cases, there were people in the nature images and natural elements such as trees and water in the urban scenes. In fact, this study indicated that blue spaces and coastal regions (White et al., <xref rid="B55" ref-type="bibr">2013</xref>) are perceived as particularly restorative, and are perceived as more restorative than primarily &#x0201c;green&#x0201d; nature scenes. Thus, we focused on aquatic environments containing some vegetation in the present study. Further, the presence of people in these environments has a certain social element, which may influence the results as well (Staats and Hartig, <xref rid="B41" ref-type="bibr">2004</xref>). For example, a natural scene that could potentially be dangerous may appear safer when another person is present. This is an even larger concern in studies where participants walk in real-world environments, as control over the environment is limited at best. Additionally, in some cases significance was found on a given cognitive task, such as the search and memory test (Hartig et al., <xref rid="B19a" ref-type="bibr">1996</xref>) in one experiment, but was not replicated in other experiments (Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>). In a similar study that used the ANT (Larsen, <xref rid="B28" ref-type="bibr">2011</xref>), no restorative effects on cognitive performance were detected, despite an effort to address many of the previous concerns. Indeed, a meta-analysis comparing the results in many of these studies found that, while nature shows beneficial effects on cognitive performance, these effects are no longer significant when adjustments are made for pre-test differences (Bowler et al., <xref rid="B8" ref-type="bibr">2010</xref>).</p><p>The strength of the cognitive restoration effect has also been recently called into question. Specifically, when using pictures alone, restorative effects are often attenuated when compared to walking in the environments. In fact, in many cases, follow-up studies intended to characterize the cognitive restoration effect have reverted to using an actual walk in nature in lieu of pictures-based exposure (e.g., Berman et al., <xref rid="B6" ref-type="bibr">2012</xref> compared to Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>). The trade-off between ecological validity and experimental control becomes particularly difficult to manage in fully realistic environments (e.g., walking through an urban area), and thus far little has been done to try to balance both. Immersive environments might provide one way to reconcile ecological validity with experimental control. In the domain of virtual reality, much research has been done to investigate how to make a person feel more present, or immersed, in a virtual environment (Stone, <xref rid="B42" ref-type="bibr">2008</xref>). In this context, immersion can be loosely equated to the realism of an environment (Brown and Cairns, <xref rid="B9" ref-type="bibr">2004</xref>). While some have proposed the creation of life-like virtual reality and the use of CAVEs to further control studies evaluating ART (Depledge et al., <xref rid="B12" ref-type="bibr">2011</xref>), there may be simpler ways to increase immersion in the laboratory without the risks of virtual reality, such as motion sickness and nausea. For example, the simple addition of sound has been shown to increase immersion in video games (Grimshaw, <xref rid="B18" ref-type="bibr">2008</xref>; Grimshaw et al., <xref rid="B19" ref-type="bibr">2008</xref>) and in virtual reality (Serafin and Serafin, <xref rid="B39" ref-type="bibr">2004</xref>; Sanders and Cairns, <xref rid="B38" ref-type="bibr">2010</xref>). Additionally, nature sounds, such as birdsong, are perceived to be restorative (Ratcliffe et al., <xref rid="B35" ref-type="bibr">2013</xref>). In the context of ART, the addition of sound should help increase the level of <italic>extent</italic> found in a natural environment.</p><p>The current study had four primary goals. First, we aimed to replicate the previous work of Berman et al. (<xref rid="B5" ref-type="bibr">2008</xref>) using a similar experimental design and set of tasks to investigate the effects of natural environments on both cognitive performance and mood. Second, we attempted to increase the level of environmental immersion by including environmentally consistent sounds, with the supplementary aim of increasing ecological validity above that of pictures alone, while maintaining experimental control above that of walking in the environments. Additionally, this allowed us to extend the current literature by investigating the effect that nature and urban sounds alone have on restoration. Third, we extended our research to include another cognitive task&#x02014;the functional field of view (FFOV; Mackworth, <xref rid="B31" ref-type="bibr">1965</xref>; Engel, <xref rid="B13" ref-type="bibr">1971</xref>, <xref rid="B14" ref-type="bibr">1977</xref>; Bouma, <xref rid="B7" ref-type="bibr">1978</xref>; Ball et al., <xref rid="B3" ref-type="bibr">1988</xref>) test. This test assesses the breadth of attentional distribution from the point of regard and is thought to indicate from which portions of the field of view useful information can be extracted. Performance on this task has been shown to be related to performance on driving tasks, which also require directed attention (e.g., Crundall et al., <xref rid="B11" ref-type="bibr">1999</xref>; Roenker et al., <xref rid="B37" ref-type="bibr">2003</xref>; Atchley and Dressel, <xref rid="B1" ref-type="bibr">2004</xref>) and has been shown to be malleable through training (Ball et al., <xref rid="B2" ref-type="bibr">2007</xref>; Belchior et al., <xref rid="B4" ref-type="bibr">2013</xref>). It stands to reason that if a person has a greater ability to use directed attention (as they might after cognitive restoration), the person should perform this task more quickly after restoration. Finally, we included a control group that did not get access to any of the environments, against which we could compare environmentally induced changes in cognitive performance. Previous studies have neglected to include a control group (e.g., Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>, <xref rid="B6" ref-type="bibr">2012</xref>), and by including one here we accounted for some of the concerns raised by others (White et al., <xref rid="B54" ref-type="bibr">2010</xref>; Depledge et al., <xref rid="B12" ref-type="bibr">2011</xref>).</p><p>To accomplish these goals, we had participants complete a battery of cognitive tasks, including several that have been previously found to be sensitive to cognitive restoration (e.g., Tennessen and Cimprich, <xref rid="B45" ref-type="bibr">1995</xref>; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>, <xref rid="B6" ref-type="bibr">2012</xref>; Taylor and Kuo, <xref rid="B43" ref-type="bibr">2009</xref>), and the additional FFOV. Participants also rated current affect using the Positive and Negative Affect Scale (PANAS; Watson and Clark, <xref rid="B53" ref-type="bibr">1988</xref>). After completing the cognitive battery and affect measure, participants were exposed to pictures (urban or nature), sounds (urban or nature), or a combination of both for a set amount of time (participants subjectively rated how relaxing the stimuli were during exposure). After viewing/listening to the picture/auditory stimuli, participants completed the cognitive test battery a second time. Changes in performance on the cognitive battery between the first and second administration provided evidence for or against the cognitive restoration effect.</p><p>Our predictions were largely consistent with the previous literature on ART and SRT. We expected that participants would rate the nature images and sounds as more relaxing than urban images and sounds. We also predicted that participants in the nature conditions would exhibit a larger increase in positive affect than control and urban conditions, with a greater decrease in negative affect (as measured by the PANAS). Additionally, we predicted that those in the nature conditions would experience greater improvements in cognitive performance on the cognitive task battery when compared to control and urban conditions. Finally, we expected that when both pictures and sounds were combined in either type of environment, the resulting effect (benefit for nature scenes and cost for urban scenes) would be stronger than when visual or auditory stimuli of either environment type were presented in isolation.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec><title>Participants</title><p>Participants were 202 undergraduate students (128 female; age <italic>M</italic> = 19.8) recruited from the University of Central Florida's psychology department subject pool, and were compensated with course credit. Research was approved by the university's Institutional Review Board, and all participants provided informed consent. Vision was tested using a Snellen chart, with all participants scoring 20/25 vision or better. Color blindness was evaluated using the Ishihara color plates 1&#x02013;13; any participants displaying any color vision impairment were excluded. Ten participants were excluded (1 female); two due to technical difficulties, four due to color blindness, three for failing to follow the experimental protocol, and one voluntarily withdrew.</p><p>Demographic information was collected from all participants and included age, gender, race, handedness, and level of education. In addition, we asked about the location in which participants lived for the longest period of time: Urban, Suburban, or Rural, with participants predominantly from suburban areas (124), and an equal number from rural and urban areas (34 each). Participants reported their current waking state and arousal level using the Stanford Sleepiness Scale (Hoddes et al., <xref rid="B23" ref-type="bibr">1973</xref>).</p></sec><sec><title>Design</title><p>We employed a between-subjects design in our study. Participants were randomly assigned to one of seven conditions, where numbers in parentheses indicate number of participants per condition: Control (27), Nature Sounds (28), Nature Pictures (27), Nature Both (28), Urban Sounds (28), Urban Pictures (27), or Urban Both (27).</p></sec><sec><title>Apparatus</title><p>Data were collected using two Dell Inspiron 570 computers, each with a Dell P190S 19&#x02033; flat panel LCD monitor. Participants were seated 65 cm from the monitor, and wore Audio-Technica ATH-ANC7B noise-cancelling headphones throughout the experiment.</p></sec><sec><title>Materials</title><p>The image sets were created from a large number of pictures collected from various sources on the internet, as well as from some personal collections. From the large set, we selected 50 images for nature and 50 for urban environments that best fit our criteria for a controlled image set. For both sets, images were taken at approximately eye height, were high resolution, and could be fit to the screen without any skew or blur. All images were taken with good lighting during the daytime, in good weather, with consistency in lighting and weather across images. The resolution of all images met or exceeded the resolution of the display, preventing any blurring or stretching of images, which was one a concern noted in a previous study on the topic (Larsen, <xref rid="B28" ref-type="bibr">2011</xref>). Additionally, images were required to be subjectively coherent with each other, such that no image stood out from the rest in the set. Sample images for each image set (natural and urban) are displayed in Figure <xref ref-type="fig" rid="F1">1</xref>.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Sample images from the experiment</bold>. <bold>(A)</bold> Images are from the urban set, while <bold>(B)</bold> are from the nature set.</p></caption><graphic xlink:href="fpsyg-05-00548-g0001"/></fig><p>For the nature images, we chose to use images of the beach and ocean. None of the images were composed entirely of water or of beach, with some containing trees and grass, nor did they contain any people or man-made objects or structures, in an attempt to reduce the need for top-down processing and to limit the presence of elements that might co-occur in urban environments. In order to limit the likelihood of causing a stress or negative affect response, we avoided images with features such as large waves or large cliffs.</p><p>The urban images were all of large, major cities in the United States or in Europe. Images were required to have people present and be primarily composed of man-made structures, consistent with most modern urban environments. Additionally, urban scenes typically contained some automobile traffic. Efforts were made to ensure urban images contained as little &#x0201c;nature&#x0201d; (e.g., trees, water, etc.) as possible, and no image had any major natural features. If any signs were present, they were in English.</p><p>For environmental sounds, we chose sounds that were as consistent as possible with their respective picture conditions, with the intention of increasing immersion and minimizing dissonance of the conditions with both images and sound. For the nature conditions, we used a single audio track of gentle waves lapping on the beach, with some occasional sounds of a light breeze or of seagulls (Joseph, <xref rid="B24" ref-type="bibr">2010</xref>). For the urban conditions, we used an audio track recorded in Times Square in New York City (Times Square, <xref rid="B47" ref-type="bibr">2000</xref>). This included the sounds of people talking, cars driving and honking, and other background noises from the city.</p></sec><sec><title>Measures</title><p>Mood was evaluated using the PANAS. The PANAS is a test that has participants rate their mood at &#x0201c;the current moment&#x0201d; when presented with a word, such as &#x0201c;excited.&#x0201d; All ratings are given on a 5-point Likert scale, where 1 = very slightly or not at all, and 5 = extremely. On the PANAS, a higher score indicates a higher level of affect in a given direction; that is, a high score on the negative component indicates a greater level of negative affect. Scores range between 10 and 50 for each type of affect. Word order was determined randomly for each participant. Ratings are divided into two categories, resulting in a score for positive affect and another for negative affect. It has been used in previous studies investigating ART (e.g., Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>, <xref rid="B6" ref-type="bibr">2012</xref>), though findings related to the PANAS have not always been consistent across studies.</p><p>Cognitive performance was evaluated using a task battery consisting of the backward digit span task (Cowan, <xref rid="B10" ref-type="bibr">2001</xref>), the ANT (Fan et al., <xref rid="B17" ref-type="bibr">2002</xref>), and a FFOV task. Each of these tasks, as well as the PANAS, was presented using the E-Prime 2.0 software (Psychology Software Tools, Pittsburgh, PA).</p><p>Images and sounds were rated for how relaxing the participants found them, using a 7-point Likert scale. In picture and both conditions, all images were rated, and in sound and both conditions, the sound file was rated. A score of &#x0201c;1&#x0201d; represented the &#x0201c;least relaxing,&#x0201d; and a score of &#x0201c;7&#x0201d; was the &#x0201c;most relaxing.&#x0201d;</p><sec><title>Backward digit span task</title><p>The backward digit span task is one of the most frequently used tasks in studies investigating ART, and one with some of the most consistent findings. Participants were presented with a series of numbers 3&#x02013;9 digits long through noise-canceling headphones. After the series of numbers finished playing, participants entered the digits in reverse order using the keyboard. Any time a participant completed two trials correctly the length of the subsequent string increased by one digit. If either trial contained a mistake, the string length decreased by one digit. There were a total of 14 trials, resulting in a maximum string length of nine digits. The score was determined by the last string length in which two trials were correct, indicating the participant's digit span capacity.</p><p>It is worth noting that in scoring the backward digit-span task, some previous studies have used number of correct trials as a score (e.g., Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>); however, our scores represent digit span <italic>capacity</italic>, not the number of correct trials. For example, two different participants with a digit span capacity of 7 can have a different number of correct trials; the first participant could have 10 correct trials in a row, and then miss the final four trials, while the second could also get 10 correct in a row, and then make a mistake on every other one for the remaining four, resulting in 12 correct trials.</p></sec><sec><title>ANT task</title><p>The ANT (Fan et al., <xref rid="B17" ref-type="bibr">2002</xref>, <xref rid="B16" ref-type="bibr">2005</xref>) task is a combination of the Posner spatial cueing task (Posner, <xref rid="B34" ref-type="bibr">1980</xref>) and the Ericksen flanker task (Eriksen and Eriksen, <xref rid="B15" ref-type="bibr">1971</xref>), and was obtained from the Sackler Institute website (<ext-link ext-link-type="uri" xlink:href="http://www.sacklerinstitute.org">http://www.sacklerinstitute.org</ext-link>). The script was originally written for an older version of E-Prime, but was converted to version 2.0 for the current study. It differentiates between alerting, orienting, and executive attentional functions through the use of two different types of cues&#x02014;spatial and temporal. In this task, spatial cues indicate the location or the orientation of the target stimulus, while the temporal cues alert the participant to the approximate onset of the target. Each trial was composed of a fixation, followed by a cue, and the presentation of the target and its flankers. The target was &#x0201c;flanked&#x0201d; by two arrows on each side, which either pointed in the same direction (congruent) or in the opposite direction (incongruent) as the target. Additionally, flankers could be neutral, with dashes flanking the target. The participant's task was to indicate which direction the central arrow in an array of five arrows was pointing using the left or right button on a mouse, which was held in both hands. For our experiment, participants completed 24 practice trials, followed by 144 experimental trials (48 neutral, 48 congruent, 48 incongruent for the flankers; 36 spatial-cue, 36 central-cue, 36 no-cue, and 36 double-cue).</p></sec><sec><title>Functional field of view task</title><p>In the FFOV task, each trial began with a central fixation square superimposed over a black background for 1.25 s. Next, a screen appeared with 24 distractor squares distributed symmetrically at 10, 20, and 30&#x000b0; on eight different lines, or &#x0201c;spokes.&#x0201d; Between two of the spokes, one target triangle enclosed in a circle appeared at 10, 20, and 30&#x000b0; for 25, 50, or 75 ms during practice, and 10 ms during experimental trials. Once the target disappeared, participants viewed a screen with the eight spokes, and were instructed to click the spoke located in the same location as the target stimulus (regardless of distance from the center). Participants received accuracy feedback after each trial.</p></sec></sec><sec><title>Procedure</title><p>After providing informed consent, participants were screened for suitability for the study, and then seated in front of the experimental computer. They completed the demographic form and a PANAS to establish baseline affect. After the PANAS, participants completed the first cognitive test battery (pre-test), with the order of the tasks determined at random. Participants were not given a break between tasks, and quickly moved from one task to the next, in order to facilitate fatigue of directed attention. Approximate duration of the task battery was 30 min.</p><p>After completing the pre-test for the cognitive battery participants were exposed to the assigned treatment or control condition (restoration period). For the sound only conditions, participants listened to the appropriate sound (nature or urban) for 350 s while looking at a neutral gray screen, and selected the relaxation rating at the end of the restoration period. For the picture only conditions, participants viewed 50 images (nature or urban) for 7 s each, rating the how relaxing the image was after each image. For combined conditions, participants experienced both pictures and sounds, rated each image, and rated the sound at the end of the restoration period. For the control condition, participants viewed a neutral gray screen without sound for 7 min. The entire restoration period (exposure to pictures, sounds, or nothing) lasted approximately 7&#x02013;10 min, depending on the speed at which participants rated images (actual exposure to stimuli was identical across all participants).</p><p>After the restoration period, the participants immediately completed the PANAS, followed by the post-test battery, which was identical to the pre-test. Tests were randomized independently of the pre-test order. Participants were then debriefed. The entire experiment lasted for approximately 90 min.</p></sec><sec><title>Statistical analyses</title><p>Unless otherwise noted, analyses were conducted using two-way mixed ANOVAs, with time (pre-test, post-test) as the repeated-measure variable and the type of environment (condition; nature sounds, nature pictures, nature both, urban sounds, urban pictures, urban both, or control) as the between-subject variable. Any main effects of time indicate practice effects, regardless of condition; however, it is the interaction between time and condition that is of the most relevance to our predictions; a significant interaction would indicate that the exposure to an environment resulted in a differential change over time on performance on the cognitive tasks.</p><p>Additionally, to better characterize support for null effects in our data set, we also report posterior probabilities [<italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D)], which provide a graded probability indicating which hypothesis (the null or alternative) is better supported by the data. A <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) &#x0003e;0.5 indicates support for the alternative hypothesis, whereas a <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) &#x0003c; 0.5 indicates support for the null hypothesis (Masson, <xref rid="B32" ref-type="bibr">2011</xref>). All reported <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) values are rounded to the second decimal.</p></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>Groups were compared for baseline differences prior to conducting further analyses. Chi-square tests were used to compare group differences on the demographic measures of gender, racial category, handedness, education level, current arousal level, and the type of town/city where participants had lived most of their life, with no significant differences (all <italic>p</italic>s &#x0003e; 0.20). Cognitive task performance on ANT, FFOV, and digit span measures were compared at pre-test using One-Way ANOVAs, and there were no differences between groups (all <italic>p</italic>s &#x0003e; 0.35). Additionally, One-Way ANOVAs indicated that pre-test affect (positive and negative) was similar between groups (all <italic>p</italic>s &#x0003e; 0.08).</p><sec><title>Image and sound ratings</title><p>Participants in the control condition were not exposed to any sounds or images, so there were no rating scores for that group. For ratings, ANOVAs were conducted comparing the conditions with sound to each other, and the conditions with pictures to each other. All image ratings are displayed in Table <xref ref-type="table" rid="T1">1</xref>.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Ratings of relaxation for sounds and for images</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Rating type</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature sound</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban sound</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Total</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Sound</td><td align="center" rowspan="1" colspan="1">4.75 (1.76)</td><td align="center" rowspan="1" colspan="1">2.25 (1.24)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">5.43 (1.45)</td><td align="center" rowspan="1" colspan="1">2.81 (1.89)</td><td align="center" rowspan="1" colspan="1">3.82 (2.05)<xref ref-type="table-fn" rid="TN1"><sup>c</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Image</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">4.50 (1.09)</td><td align="center" rowspan="1" colspan="1">3.34 (1.09)</td><td align="center" rowspan="1" colspan="1">5.13 (1.09)</td><td align="center" rowspan="1" colspan="1">3.15 (1.19)</td><td align="center" rowspan="1" colspan="1">4.05 (1.37)<xref ref-type="table-fn" rid="TN1"><sup>c</sup></xref></td></tr></tbody></table><table-wrap-foot><p>Only four conditions contained images, and four contained sound. Ratings were between 1 and 7, where 1 is the least relaxing and 7 is the most relaxing. Standard deviation is provided in parentheses. There was a main effect of rating for both sound and image ANOVAs.</p><fn id="TN1"><label>c</label><p>p &#x0003c; 0.001.</p></fn></table-wrap-foot></table-wrap><p>There was a main effect of image type, <italic>F</italic><sub>(3, 105)</sub> = 19.12, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.26, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00, with LSD <italic>post-hoc</italic> tests indicating that Nature Both was rated as the most relaxing, followed by Nature Pictures, with both significantly better than both Urban Pictures and Urban Both (all <italic>p</italic>s &#x0003c; 0.05). The urban image ratings were not significantly different from each other. Additionally, there was a main effect of sound type, <italic>F</italic><sub>(3, 107)</sub> = 25.74, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.30, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00. For sound, both Nature Sounds and Nature Both were rated as significantly more relaxing than both Urban groups; however, Nature Sound and Nature Both were not significantly different than each other, nor were Urban Sounds and Urban Both. This seems to indicate that participants found the nature conditions more relaxing than the urban conditions.</p></sec><sec><title>Mood ratings</title><p>We examined both positive and negative affect. Scores for both can be found in Table <xref ref-type="table" rid="T2">2</xref>.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Positive and negative affect scores on the PANAS by condition</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Total</bold></th></tr></thead><tbody><tr><td align="left" colspan="9" rowspan="1"><bold>POSITIVE AFFECT</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">32.7 (6.66)</td><td align="center" rowspan="1" colspan="1">34.4 (7.23)</td><td align="center" rowspan="1" colspan="1">32.6 (5.76)</td><td align="center" rowspan="1" colspan="1">33.8 (8.87)</td><td align="center" rowspan="1" colspan="1">31.2 (7.05)</td><td align="center" rowspan="1" colspan="1">33.2 (6.17)</td><td align="center" rowspan="1" colspan="1">28.9 (7.00)</td><td align="center" rowspan="1" colspan="1">32.4 (7.08)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">25.4 (8.11)</td><td align="center" rowspan="1" colspan="1">29.0 (8.45)</td><td align="center" rowspan="1" colspan="1">27.3 (7.62)</td><td align="center" rowspan="1" colspan="1">28.0 (9.74)</td><td align="center" rowspan="1" colspan="1">28.4 (7.42)</td><td align="center" rowspan="1" colspan="1">29.6 (5.93)</td><td align="center" rowspan="1" colspan="1">24.7 (7.72)</td><td align="center" rowspan="1" colspan="1">27.4 (7.96)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">&#x02212;7.3</td><td align="center" rowspan="1" colspan="1">&#x02212;5.4</td><td align="center" rowspan="1" colspan="1">&#x02212;5.3</td><td align="center" rowspan="1" colspan="1">&#x02212;5.8</td><td align="center" rowspan="1" colspan="1">&#x02212;2.8</td><td align="center" rowspan="1" colspan="1">&#x02212;3.6</td><td align="center" rowspan="1" colspan="1">&#x02212;4.2</td><td align="center" rowspan="1" colspan="1">&#x02212;4.9<xref ref-type="table-fn" rid="TN3"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>NEGATIVE AFFECT</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">14.2 (4.71)</td><td align="center" rowspan="1" colspan="1">19.2 (6.68)</td><td align="center" rowspan="1" colspan="1">16.0 (7.06)</td><td align="center" rowspan="1" colspan="1">17.8 (6.28)</td><td align="center" rowspan="1" colspan="1">16.4 (5.32)</td><td align="center" rowspan="1" colspan="1">18.8 (7.78)</td><td align="center" rowspan="1" colspan="1">15.6 (6.09)</td><td align="center" rowspan="1" colspan="1">16.8 (6.45)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">15.3 (7.21)</td><td align="center" rowspan="1" colspan="1">19.3 (9.25)</td><td align="center" rowspan="1" colspan="1">17.4 (7.74)</td><td align="center" rowspan="1" colspan="1">19.0 (8.01)</td><td align="center" rowspan="1" colspan="1">17.9 (6.73)</td><td align="center" rowspan="1" colspan="1">19.9 (8.12)</td><td align="center" rowspan="1" colspan="1">16.5 (7.58)</td><td align="center" rowspan="1" colspan="1">17.9 (7.83)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">1.1</td><td align="center" rowspan="1" colspan="1">0.1</td><td align="center" rowspan="1" colspan="1">1.4</td><td align="center" rowspan="1" colspan="1">1.2</td><td align="center" rowspan="1" colspan="1">1.5</td><td align="center" rowspan="1" colspan="1">1.1</td><td align="center" rowspan="1" colspan="1">0.9</td><td align="center" rowspan="1" colspan="1">1.0<xref ref-type="table-fn" rid="TN2"><sup>a</sup></xref></td></tr></tbody></table><table-wrap-foot><p>Positive affect and negative affect scores shown separately. Scores range between 5 and 50, with 5 indicating a low affect in the positive/negative direction, and 50 indicating high affect. Standard deviation is provided in parentheses. There was a main effect of time for both sound and image. However, there were no main effects of condition and there was no interaction.</p><fn id="TN2"><label>a</label><p>p &#x0003c; 0.05, and</p></fn><fn id="TN3"><label>c</label><p>p &#x0003c; 0.001.</p></fn></table-wrap-foot></table-wrap><sec><title>Positive affect</title><p>There was a main effect of time, <italic>F</italic><sub>(1, 167)</sub> = 90.85, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.352, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00, with the post-test affect score (<italic>M</italic> = 27.5, <italic>SD</italic> = 7.93) dropping below the pre-test score (<italic>M</italic> = 32.4, <italic>SD</italic> = 7.00), indicating a decrease in positive affect. There was no main effect of condition, <italic>F</italic><sub>(6, 167)</sub> = 1.56, <italic>p</italic> = 0.16, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.053, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00, and the interaction was not significant, <italic>F</italic><sub>(6, 167)</sub> = 1.20, <italic>p</italic> = 0.31, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.041, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00, which seems to indicate that participants may have become fatigued by the experiment regardless of condition and this fatigue was not mitigated by any particular environment.</p></sec><sec><title>Negative affect</title><p>There was a main effect of time, <italic>F</italic><sub>(1, 166)</sub> = 5.55, <italic>p</italic> = 0.02, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.032, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.57, with the post-test affect score (<italic>M</italic> = 18.0, <italic>SD</italic> = 7.87) significantly higher than the pre-test score (<italic>M</italic> = 16.9, <italic>SD</italic> = 6.44), indicating greater levels of negative affect after completing the experiment. There was no main effect of condition, <italic>F</italic><sub>(6, 166)</sub> = 1.71, <italic>p</italic> = 0.12, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.058, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00, and the interaction was not significant, <italic>F</italic><sub>(6, 167)</sub> = 0.17, <italic>p</italic> = 0.99, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.006, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00, further supporting the idea that participants may have been experiencing fatigue.</p></sec></sec><sec><title>Cognitive task performance</title><sec><title>Backward digit span</title><p>Backward digit span capacities as a function of experimental group are shown in Table <xref ref-type="table" rid="T3">3</xref>. There was a main effect of time, <italic>F</italic><sub>(1, 175)</sub> = 5.10, <italic>p</italic> = 0.025, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.028, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.503, indicating that participants could remember more digits on the post-test (<italic>M</italic> = 5.66, <italic>SD</italic> = 1.26) than on the pre-test (<italic>M</italic> = 5.41, <italic>SD</italic> = 1.18). There was no main effect of condition, <italic>F</italic><sub>(6, 175)</sub> = 1.44, <italic>p</italic> = 0.20, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.047, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00, and no significant interaction, <italic>F</italic><sub>(6, 175)</sub> = 1.23, <italic>p</italic> = 0.29, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.040, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00. While participants did show some improvement in digit span capacity at post-test, those improvements were independent of the type of environment experienced, suggesting they were due to increased familiarity with the task when performing it for a second time.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p><bold>Digit span capacity by condition</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Time</bold></th><th align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Total</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">4.96 (1.14)</td><td align="center" rowspan="1" colspan="1">5.30 (1.44)</td><td align="center" rowspan="1" colspan="1">5.75 (1.04)</td><td align="center" rowspan="1" colspan="1">5.28 (0.98)</td><td align="center" rowspan="1" colspan="1">5.64 (1.22)</td><td align="center" rowspan="1" colspan="1">5.40 (1.16)</td><td align="center" rowspan="1" colspan="1">5.52 (1.16)</td><td align="center" rowspan="1" colspan="1">5.41 (1.18)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">5.24 (1.09)</td><td align="center" rowspan="1" colspan="1">6.11 (1.42)</td><td align="center" rowspan="1" colspan="1">5.79 (1.23)</td><td align="center" rowspan="1" colspan="1">5.52 (1.33)</td><td align="center" rowspan="1" colspan="1">5.60 (1.23)</td><td align="center" rowspan="1" colspan="1">5.88 (1.20)</td><td align="center" rowspan="1" colspan="1">5.44 (1.25)</td><td align="center" rowspan="1" colspan="1">5.66 (1.26)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">0.28</td><td align="center" rowspan="1" colspan="1">0.81</td><td align="center" rowspan="1" colspan="1">0.04</td><td align="center" rowspan="1" colspan="1">0.24</td><td align="center" rowspan="1" colspan="1">&#x02212;0.04</td><td align="center" rowspan="1" colspan="1">0.48</td><td align="center" rowspan="1" colspan="1">&#x02212;0.08</td><td align="center" rowspan="1" colspan="1">0.25<xref ref-type="table-fn" rid="TN4"><sup>a</sup></xref></td></tr></tbody></table><table-wrap-foot><p>Maximum capacity scores are 9, with minimum scores of 3. Standard deviations shown in parentheses. There was a main effect of time. However, there were no main effects of condition and there was no interaction.</p><fn id="TN4"><label>a</label><p>p &#x0003c; 0.05.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Attention network task</title><p>For the ANT, we only tested for differences in the executive control component, as the alerting and orienting components only require involuntary attention. Based on previous findings (Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>, <xref rid="B6" ref-type="bibr">2012</xref>), we predicted that performance would be better for the nature conditions compared to the urban and control conditions. Additionally, we expected that the Nature Both condition would have the lowest executive control cost from pre to post-test, as it should be the most immersive. Note that better performance is indicated by a lower reaction time cost, as this is the time required to filter out incongruent information.</p><p>The means and standard deviations for each condition are reported in Table <xref ref-type="table" rid="T4">4</xref>. There was no main effect of time, <italic>F</italic><sub>(1, 179)</sub> = 1.37, <italic>p</italic> = 0.24, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.008, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.13, or condition, <italic>F</italic><sub>(6, 179)</sub> = 0.95, <italic>p</italic> = 0.46, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.031, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00. Additionally, the interaction of time and condition was not significant, <italic>F</italic><sub>(6, 179)</sub> = 0.48, <italic>p</italic> = 0.82, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.016, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00. Contrary to previous findings, these results indicate that natural pictures and sounds did not produce any restorative effects, as indicated by more positive changes in executive function in natural relative to urban pictures and sounds.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p><bold>Scores from the Attention Network Task (ANT) executive component, for all conditions</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Executive cost</bold></th><th align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Total</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">123 (62.1)</td><td align="center" rowspan="1" colspan="1">105 (36.0)</td><td align="center" rowspan="1" colspan="1">118 (36.8)</td><td align="center" rowspan="1" colspan="1">110 (52.6)</td><td align="center" rowspan="1" colspan="1">113 (32.9)</td><td align="center" rowspan="1" colspan="1">117 (54.7)</td><td align="center" rowspan="1" colspan="1">114 (41.5)</td><td align="center" rowspan="1" colspan="1">114 (46.0)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">124 (46.4)</td><td align="center" rowspan="1" colspan="1">102 (35.7)</td><td align="center" rowspan="1" colspan="1">107 (35.5)</td><td align="center" rowspan="1" colspan="1">101 (52.2)</td><td align="center" rowspan="1" colspan="1">106 (34.7)</td><td align="center" rowspan="1" colspan="1">124 (49.9)</td><td align="center" rowspan="1" colspan="1">110 (30.4)</td><td align="center" rowspan="1" colspan="1">111 (41.9)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">&#x02212;3</td><td align="center" rowspan="1" colspan="1">&#x02212;11</td><td align="center" rowspan="1" colspan="1">&#x02212;9</td><td align="center" rowspan="1" colspan="1">&#x02212;7</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">&#x02212;4</td><td align="center" rowspan="1" colspan="1">&#x02212;3</td></tr></tbody></table><table-wrap-foot><p>Scores are in milliseconds, and represent the time difference between congruent and incongruent trials. Higher scores indicate worse performance. There were no main effects of time, condition, or any interactions.</p></table-wrap-foot></table-wrap></sec><sec><title>Functional field of view</title><p>We also conducted Two-Way mixed ANOVAs on the FFOV reaction time scores and accuracy (separately) to determine if exposure to the different environments produced a differential improvement in performance. In this case, improvement would be indicated by a reduction in reaction time or increase in accuracy. Separate ANOVAs were conducted for 10, 20, and 30&#x000b0;. For all accuracy and reaction time results, refer to Table <xref ref-type="table" rid="T5">5</xref>.</p><table-wrap id="T5" position="float"><label>Table 5</label><caption><p><bold>Reaction time and accuracy for all conditions on the functional field of view task</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"><bold>Control</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban sounds</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban pictures</bold></th><th align="center" rowspan="1" colspan="1"><bold>Nature both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Urban both</bold></th><th align="center" rowspan="1" colspan="1"><bold>Total</bold></th></tr></thead><tbody><tr><td align="left" colspan="9" rowspan="1"><bold>REACTION TIME&#x02014;10&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">949 (337)</td><td align="center" rowspan="1" colspan="1">935 (253)</td><td align="center" rowspan="1" colspan="1">951 (240)</td><td align="center" rowspan="1" colspan="1">933 (250)</td><td align="center" rowspan="1" colspan="1">993 (299)</td><td align="center" rowspan="1" colspan="1">961 (304)</td><td align="center" rowspan="1" colspan="1">909 (278)</td><td align="center" rowspan="1" colspan="1">947 (279)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">811 (268)</td><td align="center" rowspan="1" colspan="1">811 (232)</td><td align="center" rowspan="1" colspan="1">779 (204)</td><td align="center" rowspan="1" colspan="1">739 (200)</td><td align="center" rowspan="1" colspan="1">823 (246)</td><td align="center" rowspan="1" colspan="1">817 (288)</td><td align="center" rowspan="1" colspan="1">740 (200)</td><td align="center" rowspan="1" colspan="1">789 (234)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">&#x02212;138</td><td align="center" rowspan="1" colspan="1">&#x02212;124</td><td align="center" rowspan="1" colspan="1">&#x02212;172</td><td align="center" rowspan="1" colspan="1">&#x02212;194</td><td align="center" rowspan="1" colspan="1">&#x02212;170</td><td align="center" rowspan="1" colspan="1">&#x02212;144</td><td align="center" rowspan="1" colspan="1">&#x02212;169</td><td align="center" rowspan="1" colspan="1">&#x02212;158<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>REACTION TIME&#x02014;20&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">949 (302)</td><td align="center" rowspan="1" colspan="1">1018 (294)</td><td align="center" rowspan="1" colspan="1">941 (224)</td><td align="center" rowspan="1" colspan="1">959 (269)</td><td align="center" rowspan="1" colspan="1">949 (292)</td><td align="center" rowspan="1" colspan="1">979 (300)</td><td align="center" rowspan="1" colspan="1">914 (263)</td><td align="center" rowspan="1" colspan="1">958 (275)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">786 (230)</td><td align="center" rowspan="1" colspan="1">834 (236)</td><td align="center" rowspan="1" colspan="1">790 (208)</td><td align="center" rowspan="1" colspan="1">743 (210)</td><td align="center" rowspan="1" colspan="1">804 (229)</td><td align="center" rowspan="1" colspan="1">816 (279)</td><td align="center" rowspan="1" colspan="1">756 (219)</td><td align="center" rowspan="1" colspan="1">790 (229)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">&#x02212;163</td><td align="center" rowspan="1" colspan="1">&#x02212;184</td><td align="center" rowspan="1" colspan="1">&#x02212;151</td><td align="center" rowspan="1" colspan="1">&#x02212;216</td><td align="center" rowspan="1" colspan="1">&#x02212;145</td><td align="center" rowspan="1" colspan="1">&#x02212;163</td><td align="center" rowspan="1" colspan="1">&#x02212;158</td><td align="center" rowspan="1" colspan="1">&#x02212;168<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>REACTION TIME&#x02014;30&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">1007 (356)</td><td align="center" rowspan="1" colspan="1">1064 (381)</td><td align="center" rowspan="1" colspan="1">989 (249)</td><td align="center" rowspan="1" colspan="1">989 (263)</td><td align="center" rowspan="1" colspan="1">999 (297)</td><td align="center" rowspan="1" colspan="1">983 (317)</td><td align="center" rowspan="1" colspan="1">934 (274)</td><td align="center" rowspan="1" colspan="1">996 (306)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">836 (249)</td><td align="center" rowspan="1" colspan="1">851 (258)</td><td align="center" rowspan="1" colspan="1">804 (210)</td><td align="center" rowspan="1" colspan="1">795 (237)</td><td align="center" rowspan="1" colspan="1">834 (252)</td><td align="center" rowspan="1" colspan="1">820 (308)</td><td align="center" rowspan="1" colspan="1">767 (249)</td><td align="center" rowspan="1" colspan="1">816 (249)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">&#x02212;171</td><td align="center" rowspan="1" colspan="1">&#x02212;213</td><td align="center" rowspan="1" colspan="1">&#x02212;185</td><td align="center" rowspan="1" colspan="1">&#x02212;194</td><td align="center" rowspan="1" colspan="1">&#x02212;165</td><td align="center" rowspan="1" colspan="1">&#x02212;163</td><td align="center" rowspan="1" colspan="1">&#x02212;167</td><td align="center" rowspan="1" colspan="1">&#x02212;180<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>ACCURACY&#x02014;10&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">0.839 (0.216)</td><td align="center" rowspan="1" colspan="1">0.768 (0.309)</td><td align="center" rowspan="1" colspan="1">0.791 (0.204)</td><td align="center" rowspan="1" colspan="1">0.768 (0.232)</td><td align="center" rowspan="1" colspan="1">0.729 (0.316)</td><td align="center" rowspan="1" colspan="1">0.746 (0.320)</td><td align="center" rowspan="1" colspan="1">0.828 (0.231)</td><td align="center" rowspan="1" colspan="1">0.781 (0.263)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">0.877 (0.206)</td><td align="center" rowspan="1" colspan="1">0.848 (0.151)</td><td align="center" rowspan="1" colspan="1">0.912 (0.113)</td><td align="center" rowspan="1" colspan="1">0.864 (0.151)</td><td align="center" rowspan="1" colspan="1">0.814 (0.249)</td><td align="center" rowspan="1" colspan="1">0.846 (0.266)</td><td align="center" rowspan="1" colspan="1">0.896 (0.126)</td><td align="center" rowspan="1" colspan="1">0.870 (0.203)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">0.038</td><td align="center" rowspan="1" colspan="1">0.080</td><td align="center" rowspan="1" colspan="1">0.121</td><td align="center" rowspan="1" colspan="1">0.096</td><td align="center" rowspan="1" colspan="1">0.085</td><td align="center" rowspan="1" colspan="1">0.100</td><td align="center" rowspan="1" colspan="1">0.068</td><td align="center" rowspan="1" colspan="1">0.089<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>ACCURACY&#x02014;20&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">0.730 (0.280)</td><td align="center" rowspan="1" colspan="1">0.651 (0.283)</td><td align="center" rowspan="1" colspan="1">0.703 (0.243)</td><td align="center" rowspan="1" colspan="1">0.681 (0.293)</td><td align="center" rowspan="1" colspan="1">0.659 (0.321)</td><td align="center" rowspan="1" colspan="1">0.698 (0.311)</td><td align="center" rowspan="1" colspan="1">0.800 (0.225)</td><td align="center" rowspan="1" colspan="1">0.703 (0.280)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">0.814 (0.246)</td><td align="center" rowspan="1" colspan="1">0.759 (0.277)</td><td align="center" rowspan="1" colspan="1">0.849 (0.144)</td><td align="center" rowspan="1" colspan="1">0.824 (0.171)</td><td align="center" rowspan="1" colspan="1">0.754 (0.284)</td><td align="center" rowspan="1" colspan="1">0.800 (0.275)</td><td align="center" rowspan="1" colspan="1">0.861 (0.148)</td><td align="center" rowspan="1" colspan="1">0.808 (0.228)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">0.084</td><td align="center" rowspan="1" colspan="1">0.108</td><td align="center" rowspan="1" colspan="1">0.146</td><td align="center" rowspan="1" colspan="1">0.143</td><td align="center" rowspan="1" colspan="1">0.095</td><td align="center" rowspan="1" colspan="1">0.102</td><td align="center" rowspan="1" colspan="1">0.061</td><td align="center" rowspan="1" colspan="1">0.105<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>ACCURACY&#x02014;30&#x000b0;</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pre-test</td><td align="center" rowspan="1" colspan="1">0.552 (0.266)</td><td align="center" rowspan="1" colspan="1">0.543 (0.238)</td><td align="center" rowspan="1" colspan="1">0.535 (0.217)</td><td align="center" rowspan="1" colspan="1">0.511 (0.268)</td><td align="center" rowspan="1" colspan="1">0.524 (0.268)</td><td align="center" rowspan="1" colspan="1">0.564 (0.306)</td><td align="center" rowspan="1" colspan="1">0.659 (0.149)</td><td align="center" rowspan="1" colspan="1">0.554 (0.249)</td></tr><tr><td align="left" rowspan="1" colspan="1">Post-test</td><td align="center" rowspan="1" colspan="1">0.625 (0.264)</td><td align="center" rowspan="1" colspan="1">0.662 (0.200)</td><td align="center" rowspan="1" colspan="1">0.627 (0.174)</td><td align="center" rowspan="1" colspan="1">0.619 (0.247)</td><td align="center" rowspan="1" colspan="1">0.608 (0.256)</td><td align="center" rowspan="1" colspan="1">0.634 (0.284)</td><td align="center" rowspan="1" colspan="1">0.710 (0.147)</td><td align="center" rowspan="1" colspan="1">0.640 (0.228)</td></tr><tr><td align="left" rowspan="1" colspan="1">Difference</td><td align="center" rowspan="1" colspan="1">0.073</td><td align="center" rowspan="1" colspan="1">0.119</td><td align="center" rowspan="1" colspan="1">0.092</td><td align="center" rowspan="1" colspan="1">0.108</td><td align="center" rowspan="1" colspan="1">0.084</td><td align="center" rowspan="1" colspan="1">0.070</td><td align="center" rowspan="1" colspan="1">0.051</td><td align="center" rowspan="1" colspan="1">0.086<xref ref-type="table-fn" rid="TN5"><sup>c</sup></xref></td></tr></tbody></table><table-wrap-foot><p>Reaction times are in milliseconds, and indicate the time it took to identify the location of the target on correct trials only. An increase in accuracy from pre-test to post-test indicates an improvement in performance. For all eccentricities, there were main effects for accuracy and reaction time. However, there were no main effects of condition and no interactions.</p><fn id="TN5"><label>c</label><p>p &#x0003c; 0.001.</p></fn></table-wrap-foot></table-wrap><p>For all visual distances, there was a main effect of time on reaction time [10&#x000b0; <italic>F</italic><sub>(1, 175)</sub> = 126.90, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.42, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00; 20&#x000b0; <italic>F</italic><sub>(1, 176)</sub> = 197.16, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.528, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00; 30&#x000b0; <italic>F</italic><sub>(1, 177)</sub> = 164.35, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.481, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00], with a decrease in reaction time from pre- to post-test. However, there were no main effects of condition on reaction time [10&#x000b0; <italic>F</italic><sub>(6, 175)</sub> = 0.37, <italic>p</italic> = 0.90, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.013, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 20&#x000b0; <italic>F</italic><sub>(6, 176)</sub> = 0.40, <italic>p</italic> = 0.88, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.013, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 30&#x000b0; <italic>F</italic><sub>(6, 177)</sub> = 0.39, <italic>p</italic> = 0.88, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.013, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00]. Additionally, none of the interactions of condition and time were significant [10&#x000b0; <italic>F</italic><sub>(6, 175)</sub> = 0.41, <italic>p</italic> = 0.87, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.014, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 20&#x000b0; <italic>F</italic><sub>(6, 176)</sub> = 0.58, <italic>p</italic> = 0.75, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.019, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 30&#x000b0; <italic>F</italic><sub>(6, 177)</sub> = 0.26, <italic>p</italic> = 0.95, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.009, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00]. While these data consistently indicate that participants were getting better at the task over time, there was no indication of environmental condition producing a difference in restorative effects that influenced performance on this cognitive task, and overall, the data are better explained as practice effects.</p><p>The same pattern of improvement was observed for accuracy, with significant main effects of time on accuracy [10&#x000b0; <italic>F</italic><sub>(1, 170)</sub> = 59.66, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.26, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00; 20&#x000b0; <italic>F</italic><sub>(1, 174)</sub> = 85.16, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.329, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00; 30&#x000b0; <italic>F</italic><sub>(1, 170)</sub> = 59.32, <italic>p</italic> &#x0003c; 0.001, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.259, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 1.00]. Once again, there was no main effect of condition on accuracy [10&#x000b0; <italic>F</italic><sub>(6, 170)</sub> = 0.80, <italic>p</italic> = 0.80, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.018, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 20&#x000b0; <italic>F</italic><sub>(6, 174)</sub> = 0.82, <italic>p</italic> = 0.56, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.027, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 30&#x000b0; <italic>F</italic><sub>(6, 170)</sub> = 0.75, <italic>p</italic> = 0.61, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.026, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00], nor were there any interactions of condition and time [10&#x000b0; <italic>F</italic><sub>(6, 170)</sub> = 0.90, <italic>p</italic> = 0.50, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.031, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; 20&#x000b0; <italic>F</italic><sub>(6, 174)</sub> = 1.00, <italic>p</italic> = 0.43, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.033, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00; and 30&#x000b0; <italic>F</italic><sub>(6, 170)</sub> = 0.60, <italic>p</italic> = 0.73, <italic>partial</italic> &#x003b7;<sup>2</sup> = 0.021, <italic>p</italic><sub>BIC</sub>(H<sub>1</sub> | D) = 0.00].</p><p>In summary, our findings suggest that participants become more accurate and faster at the FFOV task, indicating a practice effect. However, there were no effects of the experimental conditions.</p></sec></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>Based on previous research on ART (Tennessen and Cimprich, <xref rid="B45" ref-type="bibr">1995</xref>; Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>, <xref rid="B6" ref-type="bibr">2012</xref>; Taylor and Kuo, <xref rid="B43" ref-type="bibr">2009</xref>), we predicted that images and sounds of natural environments would have a restorative effect on direct attention, thus resulting in improved performance on cognitive tasks that require sustained direct attention. However, in all three of our cognitive tasks we failed to find support for this hypothesis, a finding inconsistent with some of the previous research in the cognitive restoration domain (e.g., Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>; Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>), but consistent with other studies that have failed to replicate restorative effects. For example, while Hartig et al. (<xref rid="B20" ref-type="bibr">2003</xref>) found an improvement in performance on the necker cube task when participants were exposed to natural settings, they were unable to replicate previous findings (Hartig et al., <xref rid="B19a" ref-type="bibr">1996</xref>) non search and memory tests.</p><p>Consistent with prior studies (Hartig and Staats, <xref rid="B21" ref-type="bibr">2006</xref>; White et al., <xref rid="B54" ref-type="bibr">2010</xref>), our prediction that nature sounds and images would be percieved as more relaxing than urban sounds and images was supported. However, while previous SRT research would predict a restorative effect would be reflected in affect (Ulrich, <xref rid="B48" ref-type="bibr">1983</xref>; Hartig et al., <xref rid="B20" ref-type="bibr">2003</xref>; van den Berg et al., <xref rid="B51" ref-type="bibr">2003</xref>), we were surprised to see that our participants scored significantly higher on the negative affect component of the PANAS, and significantly lower on the positive affect component at post-test compared to pre-test. Interestingly, these effects were consistent across all restoration conditions. This may suggest that the cognitive tasks resulted in some fatigue, and that the restoration periods (regardless of the type) were not sufficient to overcome the fatigue. Previous research would lead us to believe that the restorative effects of the nature conditions should help overcome the effects of fatigue on the cognitive tasks, and that it should do the same for affect, so it is surprising that this was not the case in our study. Alternatively, it is also possible that the tasks we used in and of themselves may have contributed to the general trend away from positive and toward negative affect over time. Consider, for example, that sitting on a real beach does not require much thought, nor does it require any real-world analog to our rating task. Hence, the rating task that participants were required to perform may have unintendidly irritated participants, though it should be noted that we have no evidence of this. Similarly, viewing many highly similar nature pictures may have induced boredom, and this in turn may have also contributed to the trend toward higher negative affect over time. Again, we have no direct evidence, however, that this was in fact the case.</p><p>Notably, there was an absence of any restorative effect on the executive component of the ANT. In previous work (Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>), the effect of a restoration period associated with natural environments on this measure was particularly notable. In our study, we found no evidence of restorative effects on executive function as measured by the ANT task. It is possible that there were some subtle methodological differences between our study and previous work that may have contributed to these inconsistent findings, possibly including our use of acquatic environments. However, since blue spaces containing vegetation have been reported to be perceived as the most restorative (White et al., <xref rid="B54" ref-type="bibr">2010</xref>), we do not believe this would result in the lack of an effect in our study. Overall, our data appear to be quite consistent and offer support the for the possibility that restorative stimuli, viewed or listened to in the lab, may not be sufficient for producing acute improvements in exective function, at least in the context measured here.</p><p>In addition to characterizing previously studied contexts within which cognitive restoration has been shown to occur, our study is also the first, to our knowledge, to explore whether the FFOV task is amenable to cognitive restoration. Unfortunately, our data provided no evidence that attentional breadth, as measured by the FFOV, is sensitive to a cognitive restoration period, when presented on a computer screen or auditorily through a headset. Perhaps exposure to more immersive restoration techniques, such as an actual walk through a natural environment, might produce a different outcome. Given that the FFOV has been shown to have strong relationships to tasks requiring directed attention, such as driving (e.g., Crundall et al., <xref rid="B11" ref-type="bibr">1999</xref>; Roenker et al., <xref rid="B37" ref-type="bibr">2003</xref>; Atchley and Dressel, <xref rid="B1" ref-type="bibr">2004</xref>), further examination of the task might prove fruitful.</p><p>Our study is also, to our knowledge, the first in this domain to exclusively look at ocean images as opposed to other natural environments, which are generally composed of greenery. This decision was partly influenced by previous work indicating that the presence of blue space may be particularly robust in inducing the cognitive restoration effect (White et al., <xref rid="B54" ref-type="bibr">2010</xref>). Using ocean-based images also allowed us a level of control over the nature image set that has been somewhat elusive in previous studies. Given previous findings, we expected that ocean images would evoke a greater level of restoration than park-like images; however, our data did not support our prediction. In fact, our findings strongly suggest that the effect of the color blue in natural environments may not be as restorative as previously suggested.</p><p>There are a number factors that may have contributed to our failure to replicate some previous findings of restoration effects on cognition, despite our having used a fairly typical paradigm from the literature. One possibility is that a bias against the publication of null effects might be preventing some failures to replicate from reaching the broader community. Another possibility, which has not received much attention, is that performance on the cognitive tasks that we (as well as others) used could be moderated by arousal levels (Yerkes and Dodson, <xref rid="B56" ref-type="bibr">1908</xref>; Solomon and Corbit, <xref rid="B40" ref-type="bibr">1974</xref>; Thompson et al., <xref rid="B46" ref-type="bibr">2001</xref>). One adaptation of the popular Yerkes-Dodson law can be instantiated though an inverted-U curve describing the relationship between performance and arousal. When arousal is too low or too high, performance suffers; when it is moderate, performance is at its peak. From this, it is possible that our nature condition reduced arousal to such a level that the relationship between restoration and performance was moderated by arousal, reducing performance from what may have occurred had arousal been moderate. Conversely, the arousal level for the urban conditions may have resulted in an increased level of performance. The combination of these two may have diluted the effect, thus resulting in a null result. It is also possible that the rating task itself inhibited the restorative effect by causing additional fatigue, though this was likely insufficient to cause the null result, as previous studies (Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>) have used similar tasks. Another possibility is that the overall task may not have sufficiently caused fatigue, since the control condition also exhibited similar practice effects as the other groups.</p><p>Another potential explanation could be the duration of the restoration period. Many of the experiments that find restorative effects take place with walks lasting nearly an hour. Although effects have been previously observed in studies using the same restoration period duration that we used (Berman et al., <xref rid="B5" ref-type="bibr">2008</xref>), other studies suggest that performance differences may not appear when restoration exposure remains less than 15&#x02013;20 min (Hartig et al., <xref rid="B19a" ref-type="bibr">1996</xref>, <xref rid="B20" ref-type="bibr">2003</xref>; Laumann et al., <xref rid="B29" ref-type="bibr">2003</xref>). Additionally, it is possible that the presence of people in our urban images could could have interfered with the restorative effects. Although little of the previous research has attempted to control for the presence of people, the presence of others has been shown to effect the perception of restorativeness of different types of environments (Staats and Hartig, <xref rid="B41" ref-type="bibr">2004</xref>).</p></sec><sec sec-type="conclusion" id="s5"><title>Conclusion</title><p>ART has garnered a good deal of support since it was first proposed. In particular, its relationship with cognitive performance has been studied with various tasks, ranging from walking through real-world environments, to viewing simple sets of images. While ART and SRT indicate that the restorative effects of nature should be observed after a restoration period, we were unable to find evidence in support of these assertions in a variety of cognitive tasks, despite designing our restoration period to provide all four requirements of restorative environments. Instead, our data suggest that short term exposure to images and sounds of nature do not provide any additional cognitive benefit above exposure to urban environments. Importantly, our null results are supported not only by traditional ANOVA, but also by bayesion posterior probabilities. Further investigation should be conducted to determine where cognitive restoration occurs and under what conditions, and should also investigate other cognitive tasks that may help build a better understanding of how this restoration can have real-world implications.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We would like to extend a special thanks to the undergraduate RAs who assisted in collecting data from over 200 participants: Natalie Paquette, Steven Shultz, Caroline Ciaffone, Samantha Rodriguez, and Monica Rosen.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atchley</surname><given-names>P.</given-names></name><name><surname>Dressel</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>Conversation limits the functional field of view</article-title>. <source>Hum. Factors</source>
<volume>46</volume>, <fpage>664</fpage>&#x02013;<lpage>673</lpage>
<pub-id pub-id-type="doi">10.1518/hfes.46.4.664.56808</pub-id><pub-id pub-id-type="pmid">15709328</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ball</surname><given-names>K.</given-names></name><name><surname>Edwards</surname><given-names>J. D.</given-names></name><name><surname>Ross</surname><given-names>L. A.</given-names></name></person-group> (<year>2007</year>). <article-title>The impact of speed of processing training on cognitive and everyday functions</article-title>. <source>J. Gerontol. B Psychol. Sci. Soc. Sci</source>. <volume>62</volume>, <fpage>19</fpage>&#x02013;<lpage>31</lpage>
<pub-id pub-id-type="doi">10.1093/geronb/62.special_issue_1.19</pub-id><pub-id pub-id-type="pmid">17565162</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ball</surname><given-names>K. K.</given-names></name><name><surname>Beard</surname><given-names>B. L.</given-names></name><name><surname>Roenker</surname><given-names>D. L.</given-names></name><name><surname>Miller</surname><given-names>R. L.</given-names></name><name><surname>Griggs</surname><given-names>D. S.</given-names></name></person-group> (<year>1988</year>). <article-title>Age and visual search: expanding the useful field of view</article-title>. <source>J. Opt. Soc. Am. A</source>
<volume>5</volume>, <fpage>2210</fpage>&#x02013;<lpage>2219</lpage>
<pub-id pub-id-type="doi">10.1364/JOSAA.5.002210</pub-id><pub-id pub-id-type="pmid">3230491</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belchior</surname><given-names>P.</given-names></name><name><surname>Marsiske</surname><given-names>M.</given-names></name><name><surname>Sisco</surname><given-names>S. M.</given-names></name><name><surname>Yam</surname><given-names>A.</given-names></name><name><surname>Bavelier</surname><given-names>D.</given-names></name><name><surname>Ball</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Video game training to improve selective visual attention in older adults</article-title>. <source>Comput. Human Behav</source>. <volume>29</volume>, <fpage>1318</fpage>&#x02013;<lpage>1324</lpage>
<pub-id pub-id-type="doi">10.1016/j.chb.2013.01.034</pub-id><pub-id pub-id-type="pmid">24003265</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>M. G.</given-names></name><name><surname>Jonides</surname><given-names>J.</given-names></name><name><surname>Kaplan</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>). <article-title>The cognitive benefits of interacting with nature</article-title>. <source>Psychol. Sci</source>. <volume>19</volume>, <fpage>1207</fpage>&#x02013;<lpage>1212</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02225.x</pub-id><pub-id pub-id-type="pmid">19121124</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>M. G.</given-names></name><name><surname>Kross</surname><given-names>E.</given-names></name><name><surname>Krpan</surname><given-names>K. M.</given-names></name><name><surname>Askren</surname><given-names>M. K.</given-names></name><name><surname>Burson</surname><given-names>A.</given-names></name><name><surname>Deldin</surname><given-names>P. J.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Interacting with nature improves cognition and affect for individuals with depression</article-title>. <source>J. Affect. Disord</source>. <volume>140</volume>, <fpage>300</fpage>&#x02013;<lpage>305</lpage>
<pub-id pub-id-type="doi">10.1016/j.jad.2012.03.012</pub-id><pub-id pub-id-type="pmid">22464936</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bouma</surname><given-names>H.</given-names></name></person-group> (<year>1978</year>). <article-title>Visual search and reading: eye movements and functional visual field: a tutorial review</article-title>, in <source>Attention and Performance VII</source>, ed <person-group person-group-type="editor"><name><surname>Requin</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>), <fpage>115</fpage>&#x02013;<lpage>146</lpage></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowler</surname><given-names>D.</given-names></name><name><surname>Buyung-Ali</surname><given-names>L.</given-names></name><name><surname>Knight</surname><given-names>T.</given-names></name><name><surname>Pullin</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>A systematic review of evidence for the added benefits to health of exposure to natural environments</article-title>. <source>BMC Public Health</source>
<volume>10</volume>:<fpage>456</fpage>
<pub-id pub-id-type="doi">10.1186/1471-2458-10-456</pub-id><pub-id pub-id-type="pmid">20684754</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>E.</given-names></name><name><surname>Cairns</surname><given-names>P.</given-names></name></person-group> (<year>2004</year>). <article-title>A grounded investigation of game immersion</article-title>, in <source>CHI '04 Extended Abstracts on Human Factors in Computing Systems</source> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>), <fpage>1297</fpage>&#x02013;<lpage>1300</lpage></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N.</given-names></name></person-group> (<year>2001</year>). <article-title>The magical number 4 in short-term memory: a reconsideration of mental storage capacity</article-title>. <source>Behav. Brain Sci</source>. <volume>24</volume>, <fpage>87</fpage>&#x02013;<lpage>114</lpage>
<pub-id pub-id-type="doi">10.1017/S0140525X01003922</pub-id><pub-id pub-id-type="pmid">11515286</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crundall</surname><given-names>D.</given-names></name><name><surname>Underwood</surname><given-names>G.</given-names></name><name><surname>Chapman</surname><given-names>P.</given-names></name></person-group> (<year>1999</year>). <article-title>Driving experience and the functional field of view</article-title>. <source>Perception</source>
<volume>28</volume>, <fpage>1075</fpage>&#x02013;<lpage>1088</lpage>
<pub-id pub-id-type="doi">10.1068/p2894</pub-id><pub-id pub-id-type="pmid">10694958</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Depledge</surname><given-names>M. H.</given-names></name><name><surname>Stone</surname><given-names>R. J.</given-names></name><name><surname>Bird</surname><given-names>W. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Can natural and virtual environments be used to promote improved human health and wellbeing?</article-title>
<source>Environ. Sci. Technol</source>. <volume>45</volume>, <fpage>4660</fpage>&#x02013;<lpage>4665</lpage>
<pub-id pub-id-type="doi">10.1021/es103907m</pub-id><pub-id pub-id-type="pmid">21504154</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>F. L.</given-names></name></person-group> (<year>1971</year>). <article-title>Visual conspicuity, directed attention and retinal locus</article-title>. <source>Vision Res</source>. <volume>11</volume>, <fpage>563</fpage>&#x02013;<lpage>575</lpage>
<pub-id pub-id-type="doi">10.1016/0042-6989(71)90077-0</pub-id><pub-id pub-id-type="pmid">5558576</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>F. L.</given-names></name></person-group> (<year>1977</year>). <article-title>Visual conspicuity, visual search and fixation tendencies of the eye</article-title>. <source>Vision Res</source>. <volume>17</volume>, <fpage>95</fpage>&#x02013;<lpage>108</lpage>
<pub-id pub-id-type="doi">10.1016/0042-6989(77)90207-3</pub-id><pub-id pub-id-type="pmid">855214</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eriksen</surname><given-names>B. A.</given-names></name><name><surname>Eriksen</surname><given-names>C. W.</given-names></name></person-group> (<year>1971</year>). <article-title>Effects of noise letters upon the identification of a target letter in a nonsearch task</article-title>. <source>Percept. Psychophys</source>. <volume>16</volume>, <fpage>143</fpage>&#x02013;<lpage>149</lpage>
<pub-id pub-id-type="doi">10.3758/BF03203267</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>J.</given-names></name><name><surname>McCandliss</surname><given-names>B. D.</given-names></name><name><surname>Fossella</surname><given-names>J.</given-names></name><name><surname>Flombaum</surname><given-names>J. I.</given-names></name><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>2005</year>). <article-title>The activation of attentional networks</article-title>. <source>Neuroimage</source>
<volume>26</volume>, <fpage>471</fpage>&#x02013;<lpage>479</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.02.004</pub-id><pub-id pub-id-type="pmid">15907304</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>J.</given-names></name><name><surname>McCandliss</surname><given-names>B. D.</given-names></name><name><surname>Sommer</surname><given-names>T.</given-names></name><name><surname>Raz</surname><given-names>A.</given-names></name><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>2002</year>). <article-title>Testing the efficiency and independence of attentional networks</article-title>. <source>J. Cogn. Neurosci</source>. <volume>14</volume>, <fpage>340</fpage>&#x02013;<lpage>347</lpage>
<pub-id pub-id-type="doi">10.1162/089892902317361886</pub-id><pub-id pub-id-type="pmid">11970796</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimshaw</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Sound and immersion in the first-person shooter</article-title>. <source>Int. J. Intell. Games Simul</source>. <volume>5</volume>, <fpage>119</fpage>&#x02013;<lpage>124</lpage></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grimshaw</surname><given-names>M.</given-names></name><name><surname>Lindley</surname><given-names>C. A.</given-names></name><name><surname>Nacke</surname><given-names>L.</given-names></name></person-group> (<year>2008</year>). <article-title>Sound and immersion in the first-person shooter: mixed measurement of the player's sonic experience</article-title>, in <source>Proceedings of Audio Mostly Conference</source> (Pite&#x000e5;), <fpage>1</fpage>&#x02013;<lpage>7</lpage></mixed-citation></ref><ref id="B19a"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartig</surname><given-names>T.</given-names></name><name><surname>B&#x000f6;&#x000f6;k</surname><given-names>A.</given-names></name><name><surname>Garvill</surname><given-names>J.</given-names></name><name><surname>Olsson</surname><given-names>T.</given-names></name><name><surname>G&#x000e4;rling</surname><given-names>T.</given-names></name></person-group> (<year>1996</year>). <article-title>Environmental influences on psychological restoration</article-title>. <source>Scand. J. Psychol</source>. <volume>37</volume>, <fpage>378</fpage>&#x02013;<lpage>393</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9450.1996.tb00670.x</pub-id><pub-id pub-id-type="pmid">8931393</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartig</surname><given-names>T.</given-names></name><name><surname>Evans</surname><given-names>G. W.</given-names></name><name><surname>Jamner</surname><given-names>L. D.</given-names></name><name><surname>Davis</surname><given-names>D. S.</given-names></name><name><surname>Garling</surname><given-names>T.</given-names></name></person-group> (<year>2003</year>). <article-title>Tracking restoration in natural and urban field settings</article-title>. <source>J. Environ. Psychol</source>. <volume>23</volume>, <fpage>109</fpage>&#x02013;<lpage>123</lpage>
<pub-id pub-id-type="doi">10.1016/S0272-4944(02)00109-3</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartig</surname><given-names>T.</given-names></name><name><surname>Staats</surname><given-names>H.</given-names></name></person-group> (<year>2006</year>). <article-title>The need for psychological restoration as a determinant of environmental preferences</article-title>. <source>J. Environ. Psychol</source>. <volume>26</volume>, <fpage>215</fpage>&#x02013;<lpage>226</lpage>
<pub-id pub-id-type="doi">10.1016/J.JENVP.2006.07.007</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzog</surname><given-names>T. R.</given-names></name><name><surname>Black</surname><given-names>A. M.</given-names></name><name><surname>Fountaine</surname><given-names>K. A.</given-names></name><name><surname>Knotts</surname><given-names>D. J.</given-names></name></person-group> (<year>1997</year>). <article-title>Reflection and attentional recovery as distinctive benefits of restorative environments</article-title>. <source>J. Environ. Psychol</source>. <volume>17</volume>, <fpage>165</fpage>&#x02013;<lpage>170</lpage>
<pub-id pub-id-type="doi">10.1006/jevp.1997.0051</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoddes</surname><given-names>E.</given-names></name><name><surname>Zarcone</surname><given-names>V.</given-names></name><name><surname>Smythe</surname><given-names>H.</given-names></name><name><surname>Phillips</surname><given-names>R.</given-names></name><name><surname>Dement</surname><given-names>W. C.</given-names></name></person-group> (<year>1973</year>). <article-title>Quantification of sleepiness: a new approach</article-title>. <source>Psychophysiology</source>
<volume>10</volume>, <fpage>431</fpage>&#x02013;<lpage>436</lpage>
<pub-id pub-id-type="pmid">4719486</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Joseph</surname><given-names>B.</given-names></name><collab>(Composer)</collab></person-group> (<year>2010</year>). <source>Ocean Waves. On Ocean Waves [CD]</source>. <publisher-loc>Vadnals Heights; Minnesota</publisher-loc>: <publisher-name>Robbins Island Music</publisher-name></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>R.</given-names></name><name><surname>Kaplan</surname><given-names>S.</given-names></name></person-group> (<year>1989</year>). <source>The Experience of Nature: A Psychological Perspective</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>S.</given-names></name></person-group> (<year>1995</year>). <article-title>The restorative benefits of nature: toward an integrative framework</article-title>. <source>J. Environ. Psychol</source>. <volume>15</volume>, <fpage>169</fpage>&#x02013;<lpage>182</lpage>
<pub-id pub-id-type="doi">10.1016/0272-4944(95)90001-2</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>S.</given-names></name><name><surname>Bardwell</surname><given-names>L. B.</given-names></name><name><surname>Slakter</surname><given-names>D. B.</given-names></name></person-group> (<year>1993</year>). <article-title>The museum as a restorative environment</article-title>. <source>Environ. Behav</source>. <volume>25</volume>, <fpage>725</fpage>&#x02013;<lpage>742</lpage>
<pub-id pub-id-type="doi">10.1177/0013916593256004</pub-id><pub-id pub-id-type="pmid">24639076</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Larsen</surname><given-names>V. A.</given-names></name></person-group> (<year>2011</year>). <source>When the Going Gets Tough, Will Nature Get you Going? The Effect of Water, Natural and Urban Landscapes on Cognitive Control</source>. Unpublished doctoral dissertation, <publisher-name>University of Oslo</publisher-name>, <publisher-loc>Oslo</publisher-loc></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laumann</surname><given-names>K.</given-names></name><name><surname>G&#x000e4;rling</surname><given-names>T.</given-names></name><name><surname>Stormark</surname><given-names>K. M.</given-names></name></person-group> (<year>2003</year>). <article-title>Selective attention and heart rate responses to natural and urban environments</article-title>. <source>J. Environ. Psychol</source>. <volume>23</volume>, <fpage>125</fpage>&#x02013;<lpage>134</lpage>
<pub-id pub-id-type="doi">10.1016/S0272-4944(02)00110-X</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lechtzin</surname><given-names>N.</given-names></name><name><surname>Busse</surname><given-names>A. M.</given-names></name><name><surname>Smith</surname><given-names>M. T.</given-names></name><name><surname>Grossman</surname><given-names>S.</given-names></name><name><surname>Nesbit</surname><given-names>S.</given-names></name><name><surname>Diette</surname><given-names>G. B.</given-names></name></person-group> (<year>2010</year>). <article-title>A randomized trial of nature scenery and sounds versus urban scenery and sounds to reduce pain in adults undergoing bone marrow aspirate and biopsy</article-title>. <source>J. Alter. Complement. Med</source>. <volume>16</volume>, <fpage>965</fpage>&#x02013;<lpage>972</lpage>
<pub-id pub-id-type="doi">10.1089/acm.2009.0531</pub-id><pub-id pub-id-type="pmid">20799901</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackworth</surname><given-names>N. H.</given-names></name></person-group> (<year>1965</year>). <article-title>Visual noise causes tunnel vision</article-title>. <source>Psychon. Sci</source>. <volume>3</volume>, <fpage>67</fpage>&#x02013;<lpage>68</lpage>
<pub-id pub-id-type="pmid">21842405</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masson</surname><given-names>M. E.</given-names></name></person-group> (<year>2011</year>). <article-title>A tutorial on practical Bayesian alternative to null-hypothesis significance testing</article-title>. <source>Behav. Res. Methods</source>
<volume>43</volume>, <fpage>679</fpage>&#x02013;<lpage>690</lpage>
<pub-id pub-id-type="doi">10.3758/s13428-010-0049-5</pub-id><pub-id pub-id-type="pmid">21302025</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Olmsted</surname><given-names>F. L.</given-names></name></person-group> (<year>1870</year>). <source>Public Parks and the Englargement of Towns</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Riverside Press</publisher-name></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>1980</year>). <article-title>Orienting of attention</article-title>. <source>Q. J. Exp. Psychol</source>. <volume>32</volume>, <fpage>3</fpage>&#x02013;<lpage>25</lpage>
<pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id><pub-id pub-id-type="pmid">7367577</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliffe</surname><given-names>E.</given-names></name><name><surname>Gatersleben</surname><given-names>B.</given-names></name><name><surname>Sowden</surname><given-names>P. T.</given-names></name></person-group> (<year>2013</year>). <article-title>Bird sounds and their contributions to perceived attention restoration and stress recovery</article-title>. <source>J. Environ. Psychol</source>. <volume>36</volume>, <fpage>221</fpage>&#x02013;<lpage>228</lpage>
<pub-id pub-id-type="doi">10.1016/j.jenvp.2013.08.004</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roenker</surname><given-names>D. L.</given-names></name><name><surname>Cissell</surname><given-names>G. M.</given-names></name><name><surname>Ball</surname><given-names>K. K.</given-names></name><name><surname>Wadley</surname><given-names>V. G.</given-names></name><name><surname>Edwards</surname><given-names>J. D.</given-names></name></person-group> (<year>2003</year>). <article-title>Speed-of-processing and driving simulator training result in improved driving performance</article-title>. <source>Hum. Factors</source>
<volume>45</volume>, <fpage>218</fpage>&#x02013;<lpage>233</lpage>
<pub-id pub-id-type="doi">10.1518/hfes.45.2.218.27241</pub-id><pub-id pub-id-type="pmid">14529195</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>T.</given-names></name><name><surname>Cairns</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>). <article-title>Time perception, immersion and music in videogames</article-title>, in <source>Proceedings of the 24th BCS Interaction Specialist Group Conference</source> (<publisher-loc>Swinton</publisher-loc>), <fpage>160</fpage>&#x02013;<lpage>167</lpage></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Serafin</surname><given-names>S.</given-names></name><name><surname>Serafin</surname><given-names>G.</given-names></name></person-group> (<year>2004</year>). <article-title>Sound design to enhance presence in photorealistic virtual reality</article-title>, in <source>Proceedings of ICAD 04-Tenth Meeting of the International Conference on Auditory Display</source> (<publisher-loc>Sydney, NSW</publisher-loc>).</mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solomon</surname><given-names>R. L.</given-names></name><name><surname>Corbit</surname><given-names>J. D.</given-names></name></person-group> (<year>1974</year>). <article-title>An opponent-process theory of motivation. I. Temporal dynamics of affect</article-title>. <source>Psychol. Rev</source>. <volume>81</volume>, <fpage>119</fpage>&#x02013;<lpage>145</lpage>
<pub-id pub-id-type="doi">10.1037/h0036128</pub-id><pub-id pub-id-type="pmid">4817611</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staats</surname><given-names>H.</given-names></name><name><surname>Hartig</surname><given-names>T.</given-names></name></person-group> (<year>2004</year>). <article-title>Alone or with a friend: a social context for psychological restoration and environmental preferences</article-title>. <source>J. Environ. Psychol</source>. <volume>24</volume>, <fpage>199</fpage>&#x02013;<lpage>211</lpage>
<pub-id pub-id-type="doi">10.1016/j.jenvp.2003.12.005</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>R. J.</given-names></name></person-group> (<year>2008</year>). <source>Human Factors Guidelines for Interatcive 3D and Game-Based Training Systems Design, 1st Edn. Human Factors Integration Defence Technology Centre Publication</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.hfidtc.com">http://www.hfidtc.com</ext-link></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>A. F.</given-names></name><name><surname>Kuo</surname><given-names>F. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Children with attention deficits concentrate better after walk in the park</article-title>. <source>J. Affect. Disord</source>. <volume>12</volume>, <fpage>402</fpage>&#x02013;<lpage>409</lpage>
<pub-id pub-id-type="doi">10.1177/1087054708323000</pub-id><pub-id pub-id-type="pmid">18725656</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>A. F.</given-names></name><name><surname>Kuo</surname><given-names>F. E.</given-names></name><name><surname>Sullivan</surname><given-names>W. C.</given-names></name></person-group> (<year>2002</year>). <article-title>Views of nature and self-discipline: evidence from inner city children</article-title>. <source>J. Environ. Psychol</source>. <volume>22</volume>, <fpage>49</fpage>&#x02013;<lpage>63</lpage>
<pub-id pub-id-type="doi">10.1006/jevp.2001.0241</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tennessen</surname><given-names>C. M.</given-names></name><name><surname>Cimprich</surname><given-names>B.</given-names></name></person-group> (<year>1995</year>). <article-title>Views to nature: effects on attention</article-title>. <source>J. Environ. Psychol</source>. <volume>15</volume>, <fpage>77</fpage>&#x02013;<lpage>85</lpage>
<pub-id pub-id-type="doi">10.1016/0272-4944(95)90016-0</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Schellenberg</surname><given-names>E. G.</given-names></name><name><surname>Husain</surname><given-names>G.</given-names></name></person-group> (<year>2001</year>). <article-title>Arousal, mood, and the mozart effect</article-title>. <source>Psychol. Sci</source>. <volume>12</volume>, <fpage>248</fpage>&#x02013;<lpage>251</lpage>
<pub-id pub-id-type="doi">10.1111/1467-9280.00345</pub-id><pub-id pub-id-type="pmid">11437309</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Times Square</collab></person-group> (<year>2000</year>). <source>On The Sound of New York City [CD]</source>. LoganMedia.</mixed-citation></ref><ref id="B48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ulrich</surname><given-names>R. S.</given-names></name></person-group> (<year>1983</year>). <article-title>Aesthetic and affective response to natural environment</article-title>, in <source>Behavior and the Natural Environment</source>, eds <person-group person-group-type="editor"><name><surname>Altman</surname><given-names>I.</given-names></name><name><surname>Wohlwill</surname><given-names>J. F.</given-names></name></person-group> (<publisher-loc>New Yrok, NY</publisher-loc>: <publisher-name>Plenum Press</publisher-name>), <fpage>85</fpage>&#x02013;<lpage>125</lpage></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulrich</surname><given-names>R. S.</given-names></name><name><surname>Simons</surname><given-names>R. F.</given-names></name><name><surname>Losito</surname><given-names>B. D.</given-names></name><name><surname>Fiorito</surname><given-names>E.</given-names></name><name><surname>Miles</surname><given-names>M. A.</given-names></name><name><surname>Zelson</surname><given-names>M.</given-names></name></person-group> (<year>1991</year>). <article-title>Stress recovery during exposure to natural and urban environments</article-title>. <source>J. Environ. Psychol</source>. <volume>11</volume>, <fpage>201</fpage>&#x02013;<lpage>230</lpage>
<pub-id pub-id-type="doi">10.1016/S0272-4944(05)80184-7</pub-id><pub-id pub-id-type="pmid">20617017</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="webpage"><person-group person-group-type="author"><collab>Urbanization</collab></person-group> (<year>2011</year>). <source>U.S. Central Intelligence Agency. From CIA World Factbook</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://www.cia.gov/library/publications/the-world-factbook/fields/2212.html">https://www.cia.gov/library/publications/the-world-factbook/fields/2212.html</ext-link> (Retrieved June 17, 2013).</mixed-citation></ref><ref id="B50a"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>A. E.</given-names></name><name><surname>Custers</surname><given-names>M. H. G.</given-names></name></person-group> (<year>2011</year>). <article-title>Gardening promotes neuroendocrine and affective restoration from stress</article-title>. <source>J. Health Psychol</source>. <volume>16</volume>, <fpage>3</fpage>&#x02013;<lpage>11</lpage>
<pub-id pub-id-type="doi">10.1177/1359105310365577</pub-id><pub-id pub-id-type="pmid">20522508</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>A. E.</given-names></name><name><surname>Koole</surname><given-names>S. L.</given-names></name><name><surname>Van der Wulp</surname><given-names>N. Y.</given-names></name></person-group> (<year>2003</year>). <article-title>Environmental preference and restoration: (How) are they related?</article-title>
<source>J. Environ. Psychol</source>. <volume>23</volume>, <fpage>135</fpage>&#x02013;<lpage>146</lpage>
<pub-id pub-id-type="doi">10.1016/S0272-4944(02)00111-1</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Velarde</surname><given-names>M. D.</given-names></name><name><surname>Fry</surname><given-names>G.</given-names></name><name><surname>Tveit</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Health effects of viewing landscapes -landscape types in environmental psychology</article-title>. <source>Urban For. Urban Gree</source>. <volume>6</volume>, <fpage>199</fpage>&#x02013;<lpage>212</lpage>
<pub-id pub-id-type="doi">10.1016/j.ufug.2007.07.001</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>D.</given-names></name><name><surname>Clark</surname><given-names>L. A.</given-names></name></person-group> (<year>1988</year>). <article-title>Development and validation of breif measures of positive and negative affect: the PANAS scales</article-title>. <source>J. Pers. Soc. Psychol</source>. <volume>54</volume>, <fpage>1063</fpage>&#x02013;<lpage>1070</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.54.6.1063</pub-id><pub-id pub-id-type="pmid">3397865</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>A.</given-names></name><name><surname>Humphryes</surname><given-names>K.</given-names></name><name><surname>Pahl</surname><given-names>S.</given-names></name><name><surname>Snelling</surname><given-names>D.</given-names></name><name><surname>Depledge</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Blue space: the importance of water for preference, affect, and restorativeness ratings of natural and built scenes</article-title>. <source>J. Environ. Psychol</source>. <volume>30</volume>, <fpage>482</fpage>&#x02013;<lpage>493</lpage>
<pub-id pub-id-type="doi">10.1016/j.jenvp.2010.04.004</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>M. P.</given-names></name><name><surname>Pahl</surname><given-names>S.</given-names></name><name><surname>Ashbullby</surname><given-names>K.</given-names></name><name><surname>Herbert</surname><given-names>S.</given-names></name><name><surname>Depledge</surname><given-names>M. H.</given-names></name></person-group> (<year>2013</year>). <article-title>Feelings of restoration from recent nature visits</article-title>. <source>J. Environ. Psychol</source>. <volume>35</volume>, <fpage>40</fpage>&#x02013;<lpage>51</lpage>
<pub-id pub-id-type="doi">10.1016/j.jenvp.2013.04.002</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yerkes</surname><given-names>R. M.</given-names></name><name><surname>Dodson</surname><given-names>J. D.</given-names></name></person-group> (<year>1908</year>). <article-title>The relation of strength of stimulus to rapidity of habit-forming</article-title>. <source>J. Comp. Neurol. Psychol</source>. <volume>18</volume>, <fpage>459</fpage>&#x02013;<lpage>482</lpage>
<pub-id pub-id-type="doi">10.1002/cne.920180503</pub-id></mixed-citation></ref></ref-list></back></article>