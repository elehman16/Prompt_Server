<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">22389671</article-id><article-id pub-id-type="pmc">3289622</article-id><article-id pub-id-type="publisher-id">PONE-D-11-19888</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0031634</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Neuroscience</subject></subj-group><subj-group><subject>Sensory Perception</subject></subj-group><subj-group><subject>Sensory Systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine</subject><subj-group><subject>Mental Health</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Social and Behavioral Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Involuntary Monitoring of Sound Signals in Noise Is Reflected in the Human Auditory Evoked N1m Response</article-title><alt-title alt-title-type="running-head">N1m Indexes Monitoring of Sound Signals in Noise</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lagemann</surname><given-names>Lothar</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>&#x0002a;</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Okamoto</surname><given-names>Hidehiko</given-names></name><xref ref-type="aff" rid="aff2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Teismann</surname><given-names>Henning</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Pantev</surname><given-names>Christo</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="aff1">
<label>1</label>
<addr-line>Institut f&#x000fc;r Biomagnetismus und Biosignalanalyse, Westf&#x000e4;lische Wilhelms-Universit&#x000e4;t M&#x000fc;nster, M&#x000fc;nster, Germany</addr-line>
</aff><aff id="aff2">
<label>2</label>
<addr-line>Department of Integrative Physiology, National Institute for Physiological Sciences, Okazaki, Japan</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Alain</surname><given-names>Claude</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">Baycrest Hospital, Canada</aff><author-notes><corresp id="cor1">&#x0002a; E-mail: <email>L.Lagemann@uni-muenster.de</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: LL HO. Performed the experiments: LL. Analyzed the data: LL. Contributed reagents/materials/analysis tools: CP. Wrote the paper: LL. Interpretation of data: LL HO HT CP. Revising the article: HO HT CP. Final approval of the manuscript: LL HO HT CP.</p></fn></author-notes><pub-date pub-type="collection"><year>2012</year></pub-date><pub-date pub-type="epub"><day>28</day><month>2</month><year>2012</year></pub-date><volume>7</volume><issue>2</issue><elocation-id>e31634</elocation-id><history><date date-type="received"><day>9</day><month>10</month><year>2011</year></date><date date-type="accepted"><day>10</day><month>1</month><year>2012</year></date></history><permissions><copyright-statement>Lagemann et al.</copyright-statement><copyright-year>2012</copyright-year><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><abstract><p>Constant sound sequencing as operationalized by repeated stimulation with tones of the same frequency has multiple effects. On the one hand, it activates mechanisms of habituation and refractoriness, which are reflected in the decrease of response amplitude of evoked responses. On the other hand, the constant sequencing acts as spectral cueing, resulting in tones being detected faster and more accurately. With the present study, by means of magnetoencephalography, we investigated the impact of repeated tone stimulation on the N1m auditory evoked fields, while listeners were distracted from the test sounds. We stimulated subjects with trains of either four tones of the same frequency, or with trains of randomly assigned frequencies. The trains were presented either in a silent or in a noisy background. In silence, the patterns of source strength decline originating from repeated stimulation suggested both, refractoriness as well as habituation as underlying mechanisms. In noise, in contrast, there was no indication of source strength decline. Furthermore, we found facilitating effects of constant sequencing regarding the detection of the single tones as indexed by a shortening of N1m latency. We interpret our findings as a correlate of a bottom-up mechanism that is constantly monitoring the incoming auditory information, even when voluntary attention is directed to a different modality.</p></abstract><counts><page-count count="7"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>It is a vital capability of the human auditory system to detect and track sounds emitted by potentially important sources. In most cases, an acoustic signal reaching the ear is a mixture of sounds emitted by several different objects or events. One of the most crucial tasks for the auditory system is thus to separate sounds coming from distinct sources and to keep track of them. Sound features that distinguish sources from each other are e.g. spectrum, intensity, or phase <xref rid="pone.0031634-Bregman1" ref-type="bibr">[1]</xref>. In previous behavioral studies it was shown that it is easier for subjects to detect tones if these are cued by the context presented beforehand <xref rid="pone.0031634-Hafter1" ref-type="bibr">[2]</xref>&#x02013;<xref rid="pone.0031634-Scharf1" ref-type="bibr">[5]</xref>. Cues can be e.g. auditory stimuli that have the same pitch as the target stimulus, stimuli that have a fixed pitch relation to the target <xref rid="pone.0031634-Hafter1" ref-type="bibr">[2]</xref>, or patterns that allow conclusions about the pitch of the target <xref rid="pone.0031634-Lange1" ref-type="bibr">[4]</xref>. Besides the fact that a tone can cue a subsequent tone of the same frequency, it is well established that the repetitive presentation of the same tone can lead to a decrease of the neural response to that tone <xref rid="pone.0031634-Barry1" ref-type="bibr">[6]</xref>&#x02013;<xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>.</p><p>In a previous study <xref rid="pone.0031634-Lagemann1" ref-type="bibr">[11]</xref>, we presented subjects either constantly the same frequency, or randomly changing frequencies while the subjects' attention was directed away from the auditory input towards the visual modality. The tones were either presented in silence or embedded in noise. While in the &#x0201c;constant sequencing condition&#x0201d; stimuli were cued by the preceding tone of the same frequency, this was not the case in the &#x0201c;random sequencing condition&#x0201d;, in which the stimuli alternated randomly. In the silent condition, we found differences in N1m source strength depending on the sequencing mode, with less activation in the constant sequencing condition than in the random sequencing condition. We attributed this finding to habituation and/or refractory mechanisms acting differently depending on the type of sequencing. Moreover, we found that when the tones were presented in noise, the average latency in the constant sequencing condition was significantly shorter compared to random sequencing, which we attributed to cueing mechanisms. The results indicated that background noise has a strong impact on cueing and mechanisms of habituation and/or refractoriness and that this impact is displayed in the N1m auditory evoked field originating in the human auditory cortex.</p><p>The goal of the present study was to address two general issues: First, we investigated the time course of N1m source strength in silence and noise. Second, we attempted to determine the number of repetitions of the same stimulus that are needed to establish and stabilize a sequencing effect with regard to N1m latency. To study these matters, subjects were presented with sound trains composed of four tones of either the same frequency or of randomly changing frequencies. The trains were presented either in silence or embedded in noise. We hypothesized that in silence we would find differences regarding source strength decline between sequencing conditions. Concerning the latencies, we expected differences between sequencing conditions to occur in the noisy condition.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec id="s2a"><title>Stimuli and experimental design</title><p>40 Hz amplitude-modulated tones (modulation depth 100&#x00025;) of eight different carrier frequencies (250, 450, 700, 1000, 1370, 1850, 2500, 3400 Hz) with a duration of 500 ms were used as test stimuli (TS). The stimuli were concatenated to stimulus trains of 4 items. The trains consisted either of tones of identical frequency (constant sequencing condition) or of tones randomly chosen from the eight frequencies (random sequencing condition). The randomization was controlled to ensure that the same tone could appear at maximum two times in a row within a random train. In each sequencing (constant vs. random) and noise (noise vs. silence) condition 96 trains were presented, amounting to 382 trains in total. The stimuli were prepared using MATLAB (The MathWorks Inc.) and CoolEdit (Syntrillium). The inter-stimulus-interval (ISI) was fixed to 500 ms, and the inter-train-interval (ITI) was randomized between 2.5 and 3.5 s, resulting in an average ITI of 3 s. In the noise condition, 8000 Hz low-pass filtered white noise was added to the stimuli. The total root mean square (RMS) intensity of the noise was 10 dB above stimulus intensity. The noise blocks were linearly faded in and out for 50 ms. Each run consisted of alternating blocks of different signal-to-noise ratios (i.e. noise vs. silence), containing trains of constant sequencing and trains of random sequencing that were succeeding randomly. An idealized depiction of the stimulation is shown in <xref ref-type="fig" rid="pone-0031634-g001">Figure 1</xref>.</p><fig id="pone-0031634-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0031634.g001</object-id><label>Figure 1</label><caption><title>Schematic depiction of the stimulation.</title><p>On the x- and y-axis, time and frequency are indicated. Black bars represent individual tones (duration&#x0200a;=&#x0200a;500 ms). Blocks of noisy and silent backgrounds were presented alternately. Each block consisted of ten trains of four tones in random sequencing and ten trains of four tones of constant sequencing that were randomly distributed across the whole block.</p></caption><graphic xlink:href="pone.0031634.g001"/></fig><p>We used Presentation (Neurobehavioral Systems, Albany, CA, United States) to control the timing of sound presentation, and SRM-212 electrostatic earphones (Stax, Saitama, Japan) to transduce sound stimuli. All sounds were presented diotically through silicon tubes (length: 60 cm; inner diameter: 5 mm) and silicon earpieces adjusted to individually fit into each subject's ears. Before starting the magnetoencephalography (MEG) acquisition, each subject's hearing threshold for the 1000 Hz carrier frequency TS was measured for each ear. During the MEG session, the tonal stimuli were presented at an intensity of 40 dB above this individual threshold. During stimulus presentation, subjects were watching a silent movie, and after each of the six runs questions regarding the content of the movie were asked, thus ensuring that attention had been directed to the visual domain and was therefore distracted from the auditory modality.</p><p>We tested 16 healthy subjects (age 22&#x02013;30 years), 9 of which were females. All subjects had normal hearing and were right handed as assessed with the Edinburgh Handedness Inventory <xref rid="pone.0031634-Oldfield1" ref-type="bibr">[12]</xref>. All subjects were fully informed about the study and gave written consent for their participation. The study was approved by the Ethics Commission of the Medical Faculty of the University of M&#x000fc;nster and conformed to The Code of Ethics of the World Medical Association (Declaration of Helsinki).</p></sec><sec id="s2b"><title>Data acquisition and analysis</title><p>The auditory evoked fields were recorded with a whole-head 275 channels MEG system (Omega; CTF Systems, Coquitlam, British Columbia, Canada) in a magnetically shielded and acoustically silent room. Subjects were instructed not to move their head and were monitored by means of video camera by the experimenter. The magnetic fields were digitized with a sampling rate of 600 Hz. The magnetic fields evoked by each tone were averaged for each signal-to-noise condition (silence and noise), sequencing condition(random and constant), and tone position (1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup>), starting 200 ms prior to TS-onset, and ending 800 ms after TS-onset, applying a 1&#x02013;20 Hz band-pass filter and baseline correction relative to the 100 ms pre-stimulus interval. Epochs containing field changes larger than 2.5 pT were rejected as artifact epochs.</p><p>We evaluated the auditory evoked fields with regard to the N1m response. Since MEG sensors have very little sensitivity to purely radially oriented sources, the N1m basically has its origin in neuronal currents that have a component oriented tangentially to the skull <xref rid="pone.0031634-LopesdaSilva1" ref-type="bibr">[13]</xref>, <xref rid="pone.0031634-Hillebrand1" ref-type="bibr">[14]</xref> and is thought to reflect mainly temporal lobe activity <xref rid="pone.0031634-Ntnen1" ref-type="bibr">[15]</xref>. For the source localization of the N1m response, the auditory evoked fields across all conditions of the first run were averaged. Then, the N1m response was identified as the time point of maximal RMS value of the global field amplitude around 150 ms after TS-onset. A 10 ms interval around this N1m peak latency was selected, and the source locations and orientations were estimated by single equivalent current dipole modeling (one dipole for each hemisphere) for each subject individually <xref rid="pone.0031634-Salmelin1" ref-type="bibr">[16]</xref>. As source space we used a spherical head model derived from anatomical magnetic resonance images (MRIs) of each subject. Dipole estimations with an error rate exceeding 10&#x00025; (i.e. a goodness of fit lower than 90&#x00025;) were excluded from further analysis, reducing the number of subjects to n&#x0200a;=&#x0200a;12. The mean goodness of fit for the dipoles of the subjects who were not rejected was 96.7&#x00025;. The estimated sources were fixed in location and orientation for each hemisphere of each subject as a spatial filter <xref rid="pone.0031634-Tesche1" ref-type="bibr">[17]</xref>. Using this spatial filter, source waveforms of the averaged auditory evoked fields from each run were calculated for each respective condition. The obtained source waveforms were then averaged across all six runs for each condition and hemisphere. The average of the peaks with the highest source strength for each hemisphere in each condition in the time range between 90 and 220 ms was used for further statistical analysis. N1m source strength and latency elicited by the TS were analyzed separately for each noise condition via repeated-measures analyses of variance (ANOVA) using two factors: SEQUENCING (constant vs. random), and TONE-POSITION (position 1&#x02013;4). Before calculating the ANOVAs, Mauchly's test was conducted. In cases where sphericity of the data was not given, we report Greenhouse-Geisser corrected values. Predicted differences between tone pairs were tested via planned comparisons. Differences between condition pairs for which we did not have a priori hypotheses were investigated using Bonferroni-Holm corrected post-hoc tests <xref rid="pone.0031634-Holm1" ref-type="bibr">[18]</xref>.</p></sec></sec><sec id="s3"><title>Results</title><p>Sensor space data of a representative subject is depicted in <xref ref-type="fig" rid="pone-0031634-g002">Figure 2</xref>. <xref ref-type="fig" rid="pone-0031634-g003">Figure 3</xref> shows the individual source wave forms of the N1m responses of the same subject to stimulus trains within the different conditions.</p><fig id="pone-0031634-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0031634.g002</object-id><label>Figure 2</label><caption><title>Individual auditory evoked field data.</title><p>Top: response averaged across all stimuli presented in the first run; an articulate N1m peak is discernible. The green area indicates the 10 ms time range around the latency of highest RMS field amplitude of all sensors. This time range was taken for source reconstruction. Bottom: the magnetic flux at 130 ms, the point of highest RMS field amplitude demonstrates clear dipolar field distribution.</p></caption><graphic xlink:href="pone.0031634.g002"/></fig><fig id="pone-0031634-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0031634.g003</object-id><label>Figure 3</label><caption><title>Individual source wave forms of the N1m responses.</title><p>The x-axis shows the time in ms related to stimulus onset. On the y-axis source strength in nAm is denoted. Upper panel: source wave forms to tone trains presented in silence in the constant condition (black line) and in the random condition (red line). Bottom: source wave forms to tone trains presented in noise (color coding same as in the upper panel).</p></caption><graphic xlink:href="pone.0031634.g003"/></fig><sec id="s3a"><title>Source strength</title><p>The interaction plots for N1m source strength are shown in <xref ref-type="fig" rid="pone-0031634-g004">Figure 4</xref>. In silence a clear drop in source strength can be seen between first and second tone in the constant sequencing condition, but not in the random sequencing condition. To check for possible main effects and interactions, we conducted an ANOVA with the factors SEQUENCING (constant vs. random) and TONEPOSITION (position 1&#x02013;4) for silent and noisy backgrounds separately. For the noisy background, the ANOVA yielded neither significant main effects nor interactions (SEQUENCING (F(1,11)&#x0200a;=&#x0200a;1.102, n.s.), TONE-POSITION(F(1.69,18.59)&#x0200a;=&#x0200a;2.52, n.s.), SEQUENCING&#x000d7;TONEPOSITION (F(3,33)&#x0200a;=&#x0200a;0.598, n.s.)). Since the ANOVA did not yield any significant results, and since we did not predict any differences in this condition, we did not further analyze these data. The ANOVA for the silent surrounding showed the following: SEQUENCING (F(1,11)&#x0200a;=&#x0200a;54.991, p&#x0003c;0.001), TONE-POSITION (F(1.425,15.683)&#x0200a;=&#x0200a;23.456, p&#x0003c;0.001), SEQUENCING&#x000d7;TONE-POSITION (F(1.699,18.690)&#x0200a;=&#x0200a;14.654, p&#x0003c;0.001).</p><fig id="pone-0031634-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0031634.g004</object-id><label>Figure 4</label><caption><title>N1m source strength in each condition.</title><p>The x-axis depicts the respective tone positions. The y-axis denotes the mean N1m source strength. Red color symbolizes the random condition, and black the constant sequencing condition. Values in the silent condition are drawn with solid lines, and values in the noise condition are symbolized by dashed lines. Single colored asterisks mark significant differences between tones of the same sequencing condition. Double colored asterisks mark differences between tones of different sequencing conditions in the same respective position. Error-bars denote the 95&#x00025; confidence interval limits of the arithmetic mean across subjects.</p></caption><graphic xlink:href="pone.0031634.g004"/></fig><p>Due to the repeated presentation of the same stimulus in the constant sequencing condition, we expected significant differences between the first tone and each of the following three tones. Planned comparisons showed this difference: the source strength drop between first and second tone reached significance (t(11)&#x0200a;=&#x0200a;5.532, p&#x0003c;0.001), and also first and third (t(11)&#x0200a;=&#x0200a;10.061, p&#x0003c;0.001) and first and fourth tone (t(11)&#x0200a;=&#x0200a;8. 079, p&#x0003c;0.001) differed significantly. We further expected larger source strength values for the tones at positions two to four in the random sequencing condition compared to the tones at the same respective positions in the constant sequencing condition. Again, planned comparisons revealed that the values differed significantly (tone pair position 2: t(11)&#x0200a;=&#x0200a;&#x02212;5.612, p&#x0003c;0.001; tone pair position 3: t(11)&#x0200a;=&#x0200a;&#x02212;7.894, p&#x0003c;0.001; tone pair position 4: t(11)&#x0200a;=&#x0200a;&#x02212;6.455, p&#x0003c;0.001).). For the remaining contrasts we did not have hypotheses, thus further source strength differences were evaluated using Bonferroni-Holmes corrected post-hoc tests. The decrease of source strength from first to second tone in the random sequencing condition was not significant (t(11)&#x0200a;=&#x0200a;1.817, n.s.). The source strength decline from the first tone was significant at the third tone (t(11)&#x0200a;=&#x0200a;4.669, p&#x0003c;0.01). The difference between the first and the fourth tone in the random sequencing condition was not significant (t(11)&#x0200a;=&#x0200a;2.752, n.s.). Source strength values between the second and the third as well as between the third and the fourth tone did not differ significantly. This held true for the constant sequencing condition (second to third: t(11)&#x0200a;=&#x0200a;&#x02212;0.81, n.s.; third to fourth: t(11)&#x0200a;=&#x0200a;0.293, n.s.) as well as for the random sequencing condition (second to third: t(11)&#x0200a;=&#x0200a;1.309, n.s.; third to fourth: t(11)&#x0200a;=&#x0200a;&#x02212;0.63, n.s.).</p></sec><sec id="s3b"><title>Latency</title><p>N1m latency is visualized in <xref ref-type="fig" rid="pone-0031634-g005">Figure 5</xref>. Obvious differences show between the first and the second, the first and the third and the first and the fourth tone in the constant sequencing condition in noise. The ANOVA for the silent condition did not show any significant main effects for SEQUENCING (F(1,11)&#x0200a;=&#x0200a;5.22, n.s.) or for TONEPOSITION (F(3,33)&#x0200a;=&#x0200a;1.286, n.s.). Also, there was no significant interaction between SEQUENCING and TONEPOSITION (F(3,33)&#x0200a;=&#x0200a;2.465, n.s.). Due to the lack of significant results in the ANOVA, and since we did not expect latency differences between sequencing conditions in silence, we did not further examine latency values elicited by tones presented in silence. The ANOVA for the N1m peak latency values in noise showed significant effects for all factors and interactions: SEQUENCING: (F(1,11)&#x0200a;=&#x0200a;29.144, p&#x0003c;0.001), TONEPOSITION: (F(3,33)&#x0200a;=&#x0200a;7.913, p&#x0003c;0.001), and SEQUENCING&#x000d7;TONEPOSITION: (F(3,33)&#x0200a;=&#x0200a;2.897, p&#x0200a;=&#x0200a;0.05).</p><fig id="pone-0031634-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0031634.g005</object-id><label>Figure 5</label><caption><title>N1m latencies in each condition.</title><p>N1m latency values in milliseconds are displayed on the y-axis. The x-axis shows the respective tone positions. Figure legend according to <xref ref-type="fig" rid="pone-0031634-g004">Figure 4</xref>.</p></caption><graphic xlink:href="pone.0031634.g005"/></fig><p>We predicted latency differences between sequencing conditions in two tone pairs: We expected the cueing effect to set in latest at the fourth tone in the constant sequencing condition, but not in the random sequencing condition. Thus, we expected the N1m latency to the fourth tone in the constant sequencing condition to be shorter than the N1m to the respective tone in the random sequencing condition. Accordingly, we also expected tone four in the constant sequencing condition to differ significantly from tone one. The conducted planned contrasts showed the expected differences between those tones: tone four constant vs. tone four random t(11)&#x0200a;=&#x0200a;&#x02212;2.603, p&#x0003c;0.05; tone one constant vs. tone four constant t(11)&#x0200a;=&#x0200a;4.182, p&#x0003c;0.01. To further investigate latency differences in noise, we performed post-hoc tests for remaining 11 pairs of interest. The reported p-values are Bonferroni-Holms corrected. N1m latency dropped significantly from the first to the second tone (t(11)&#x0200a;=&#x0200a;3.480, p&#x0003c;0.05) in the constant sequencing condition. In the constant sequencing condition also the latency difference between the first and the third tone was significant (t(11)&#x0200a;=&#x0200a;5.079, p&#x0003c;0.01). In the random sequencing condition, the difference between the first and the second tone was not significant (t(11)&#x0200a;=&#x0200a;0.788, n.s.). Also, the differences between the first and the third tone (t(11)&#x0200a;=&#x0200a;2.706, n.s.) and between the first and the fourth tone did not reach significance (t(11)&#x0200a;=&#x0200a;1.577, n.s.). There were no significant differences between the second and the third and the third and the fourth tone in any of the two sequencing conditions (constant: second vs. third t(11)&#x0200a;=&#x0200a;0.427, n.s.; third vs. fourth t(11)&#x0200a;=&#x0200a;0.575, n.s.; random: second vs. third t(11)&#x0200a;=&#x0200a;2.267, n.s.; third vs. fourth t(11)&#x0200a;=&#x0200a;&#x02212;0.355, n.s.). Comparing the respective tone positions two and three between sequencing conditions, we found significantly shorter latencies for the second (t(11)&#x0200a;=&#x0200a;&#x02212;4.214, p&#x0003c;0.05)as well as for the third position(t(11)&#x0200a;=&#x0200a;&#x02212;3.056, p&#x0003c;0.05) for tones presented in constant order.</p></sec></sec><sec id="s4"><title>Discussion</title><p>We presented trains of four tones embedded either in noise or in a silent surrounding. The tones of a train were either of the same frequency or of randomly changing frequencies. Across the whole experiment, the tones presented to the subjects in each condition were identical. The tones only differed in the way they were sequenced within the trains. Several previous studies investigated the influence of noise on the detection of test stimuli and the influences of noise on N1m amplitude and latency. For this, mostly conditions with noisy background were compared to conditions without noise. While low levels of noise seem to enhance the N1m amplitude <xref rid="pone.0031634-Alain1" ref-type="bibr">[19]</xref>, high levels of noise consistently yield lower N1m amplitudes and longer peak latencies compared to the N1m elicited in a silent background <xref rid="pone.0031634-Lagemann1" ref-type="bibr">[11]</xref>, <xref rid="pone.0031634-Hari1" ref-type="bibr">[20]</xref>, <xref rid="pone.0031634-Morita1" ref-type="bibr">[21]</xref>. Here, we did not investigate the influence of noise per se, but how stimulus sequencing and noisy background interact.</p><p>In the silent background, we did not find any differences regarding the latencies of the N1m to the tones with respect to sequencing condition or tone position. The N1m source strength on the other hand did differ depending on both, sequencing condition as well as tone position: In the constant sequencing condition, we found a sharp drop between first and second tone, with no further reduction thereafter. In the random sequencing condition, we found a more gradual decrease of source strength. While the difference between first and second tone was not significant in random sequencing, the difference between first and third tone was.</p><p>In the noisy surrounding, we did not find any differences in N1m source strength between the different sequencing conditions. The latencies of the N1m responses however did differ between sequencing conditions. In the constant sequencing condition, the latency dropped from first to second tone, but not any further for tones three and four. In the randomly sequenced stimulus trains, we could not find any significant differences between the tones.</p><p>Several previous studies have investigated the mechanisms driving response decline with repeated stimulation. The two explanations that are considered most are habituation and refractoriness. While habituation is thought to be a learning mechanism <xref rid="pone.0031634-Thompson1" ref-type="bibr">[9]</xref>, refractoriness depends on the recovery cycles of the stimulated sensory cells <xref rid="pone.0031634-Ritter1" ref-type="bibr">[7]</xref>, <xref rid="pone.0031634-Rosburg1" ref-type="bibr">[8]</xref>, <xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>. The most obvious difference between refractoriness and habituation is the time course of response decline: habituation is characterized by an ongoing slow decrease of the response with repeated stimulation, while refractory mechanisms would elicit a fast drop of the response strength from the first to the second stimulation, but no further decline from the third stimulation on <xref rid="pone.0031634-Rosburg1" ref-type="bibr">[8]</xref>, <xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>. While some studies reported evidence for habituation <xref rid="pone.0031634-Thompson1" ref-type="bibr">[9]</xref>, <xref rid="pone.0031634-Condon1" ref-type="bibr">[22]</xref>, others found characteristics of refractoriness in the patterns of source strength decline with repeated stimulation <xref rid="pone.0031634-Barry1" ref-type="bibr">[6]</xref>, <xref rid="pone.0031634-Rosburg1" ref-type="bibr">[8]</xref>. It has to be mentioned though, that the two mechanisms are not per se exclusive, and they may arise from different stages in the auditory processing pathway <xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>, <xref rid="pone.0031634-Ulanovsky1" ref-type="bibr">[23]</xref>.</p><p>Here, regarding the pattern of N1m source strength decline in the silent condition, we found a steep drop of source strength in the constant sequencing condition. After this drop, no further decline in source strength took place. This pattern thus seems to favor refractory mechanisms as suggested in previous studies <xref rid="pone.0031634-Rosburg1" ref-type="bibr">[8]</xref>, <xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>. However, in the random sequencing condition we also found a drop in source strength. This drop was not significant from first to the second tone, but it was from the first to the third. Hence, the pattern reflects the gradual decrease usually associated with habituation. The reason that we did not see any indication of habituation in the constant condition might be due to complete &#x0201c;coverage&#x0201d; by the much stronger source strength decline resulting from refractory mechanisms.</p><p>An alternative approach might be to explain the decrease in source strength of the N1m by the mechanics of lateral/surround inhibition <xref rid="pone.0031634-Jskelinen1" ref-type="bibr">[24]</xref>, <xref rid="pone.0031634-May1" ref-type="bibr">[25]</xref>. This approach suggests that the stimulation by the first test tone excites a rather broad patch of neurons at and around the neurons with the best frequency. On the second presentation of the same tone solely the neural population tuned to the test tone frequency responds while the activity in the patch of adjacent neurons is suppressed. This narrowing down becomes apparent in the decrease of source strength since less neurons are activated than in the first instance of stimulation. J&#x000e4;&#x000e4;skel&#x000e4;inen and colleagues <xref rid="pone.0031634-Jskelinen1" ref-type="bibr">[24]</xref> suggest this mechanism as the basis for cueing. From our results it is not possible to tell apart surround inhibition from refractory mechanisms, since the source strength decline would look the same. Another finding though makes lateral/surround inhibition seem improbable in our case: May and colleagues <xref rid="pone.0031634-May1" ref-type="bibr">[25]</xref> state after simulating and empirically validating a model on adaptation and lateral inhibition that their results &#x0201c;suggest that lateral inhibition on the cortical level is either strong but decays with a fast time constant (of the order of 100 ms) or that it is weak but decays slowly&#x0201d; (p.116). With an ISI of 500 ms our presentation rate was thus out of the time range in which lateral/surround inhibition is postulated to show its effects.</p><p>Our present results thus confirm the view that in the temporal range of our stimulation, habituation as well as refractory mechanisms are responsible for the source strength decline after repeated stimulation in silence. The findings support the hypothesis that in the short time range investigated, refractoriness has the larger impact compared to habituation <xref rid="pone.0031634-Budd1" ref-type="bibr">[10]</xref>. When tones were presented against a noisy background, there were no significant source strength differences between different tone positions. It thus seems that the refractoriness of the sound-processing neurons caused by noise evened out any potential differences arising from repeated tonal stimulation or differential sequencing.</p><p>Several authors have found indications that the auditory N1m might be driven by at least two sources: a posterior source that peaks about 20&#x02013;30 ms earlier than a more anterior source peaking accordingly later. It is also reported that the N1m to a rare stimulus gets more contribution from the anterior source than if it is played frequently or as a second tone after a first stimulus <xref rid="pone.0031634-Jskelinen2" ref-type="bibr">[26]</xref>&#x02013;<xref rid="pone.0031634-Sams1" ref-type="bibr">[28]</xref>. This might have played a role in our results but from our data we would not be able to tell a systematic source location difference. To do this we would have to perform a source localization for the N1m of every single frequency at every single tone position in every single sequencing and noise condition. This would decrease our SNR too much to perform a reliable dipole fit. In order to counterbalance the physical sound properties between constant and random conditions we averaged the obtained auditory evoked fields irrespective of the tone position or the TS frequencies. Considering the tonotopic organization of the auditory cortex <xref rid="pone.0031634-Pantev1" ref-type="bibr">[29]</xref>&#x02013;<xref rid="pone.0031634-Romani1" ref-type="bibr">[31]</xref>, this procedure probably blurred the source localization of the N1m responses, disallowing any statement on subtle location differences.</p><p>As described before, in silent background we found differences between sequencing conditions and tone positions regarding the source strength, but not the latency values. In the noisy background the opposite hold true: while there are no differences regarding the source strength, the latency pattern shows a clear drop between first and second tone in the constant condition, but not in the random sequencing condition. It has been shown in several psychophysical studies that cueing a tone with a tone of the same frequency (sometimes termed &#x0201c;iconic cueing&#x0201d;) facilitates the active detection of this tone <xref rid="pone.0031634-Hafter1" ref-type="bibr">[2]</xref>, <xref rid="pone.0031634-Scharf1" ref-type="bibr">[5]</xref>, <xref rid="pone.0031634-Hubner1" ref-type="bibr">[32]</xref>. Using an active detection task in noise, Okamoto and colleagues <xref rid="pone.0031634-Okamoto1" ref-type="bibr">[33]</xref> showed that reaction times were faster with constant sequencing, and that shorter N1m latencies went along with faster reaction times. In our previous study <xref rid="pone.0031634-Lagemann1" ref-type="bibr">[11]</xref>, we furthermore found hints that this also holds true for involuntary tone detection, i.e. when attention is directed away from the auditory domain. The present study confirmed that spectral cueing via constant sequencing seems to facilitate detection of tones in noise even under distracted conditions. Additionally, we could show that this sequencing effect sets in very fast: the effect could be seen already at the first repetition of the same tone.</p><p>Natural sounds elicited by the same source can be characterized -among other features- by the fact that they develop over time and thus do not normally change their spectral content abruptly, but rather gradually. An important task for the auditory system is to assign incoming sound signals to distinct sources and to monitor them. For solving this task it is reasonable to expect sounds coming from the same source to be in the spectral vicinity of the signal previously detected. The course of latency decrease observed in our present data seems to be a correlate of the detection and tracking of regular information even under distracted or pre-attentive conditions. In other words, the incoming information is constantly monitored even if voluntary attention is directed to a different modality. In case of the appearance of a salient and potentially important stimulus, this bottom up mechanism can trigger top down processes that might lead to the allocation of attentional resources to the new event <xref rid="pone.0031634-Knudsen1" ref-type="bibr">[34]</xref>, <xref rid="pone.0031634-Luo1" ref-type="bibr">[35]</xref>. A stimulus is salient if it is sufficiently different from the context in which it occurs. Therefore, a context has to be established in the first place. In silence, we saw a correlate of the build-up of a context in the rapid decrease of source strength after repeated stimulation by the same stimulus as was evident in the constant sequencing condition. A change in stimulation frequency would have resulted in a stronger activation compared to the preceding context <xref rid="pone.0031634-Barry1" ref-type="bibr">[6]</xref>. In noise, we did not see any differences in source strength, probably because of noise induced refractoriness of the auditory neurons which was the same in constant as well as in random sequencing. What we did see though was a shortening of the N1m latency, which indicated the accelerated detection of stimuli of the same frequency as the preceding context. Pre-attentive tracking of non-attended input was recently shown to be visible even in the auditory evoked brain stem response <xref rid="pone.0031634-Skoe1" ref-type="bibr">[36]</xref>, <xref rid="pone.0031634-Chandrasekaran1" ref-type="bibr">[37]</xref>. The authors of those studies reported enhanced activity to stimuli occurring repeatedly on a regular basis on local as well as on global time scales. It is feasible that enhanced processing in an early stage such as the brain stem also propagates to higher stages of the auditory pathway and can eventually be seen as faster processing of stimuli with regular properties in the auditory N1m. The reason that we did not see any latency differences between sequencing conditions in the silent condition probably is a ceiling effect: The detection of a tone of sufficient intensity in a quiet surrounding as reflected in the N1m is very fast, independent of the sequencing. Hence, the constant order did not yield any temporal detection advantages compared to random ordering.</p><sec id="s4a"><title>Conclusion</title><p>Our results showed that mainly refractoriness was responsible for N1m source strength decrement after repeated presentation of the identical tonal stimulus in a silent surrounding. In a noisy surrounding, neural refractoriness caused by noise which contained the frequency spectrum of the test stimuli completely evened out any source strength differences that might arise from repeated stimulation. In noise, spectral cueing may play a major role for the tracking of incoming stimuli, even if the auditory input is not attended actively. A stimulus is detected faster at its first repetition already. We interpret these data as a correlate of a bottom-up mechanism that helps to constantly monitor incoming information &#x02013;this might enable the listener to direct top-down attentional resources to the input, in case a salient and potentially important change occurs.</p></sec></sec></body><back><ack><p>We would like to thank Karin Berning, Hildegard Deitermann, and Ute Trompeter for helping to acquire the data, as well as Andreas Wollbrink for technical support.</p></ack><fn-group><fn fn-type="COI-statement"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="financial-disclosure"><p><bold>Funding: </bold>This work was funded by the Tinnitus Research Initiative <ext-link ext-link-type="uri" xlink:href="http://www.tinnitusresearch.org/">http://www.tinnitusresearch.org/</ext-link>, The Japan Society for the Promotion of Science for Young Scientists (grant number 23689070) and The Strategic Research Program for Brain Sciences (Development of Biomarker Candidates for Social Behavior). The authors also acknowledge support by Deutsche Forschungsgemeinschaft and the Open Access Publication Fund of the University of Muenster. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></fn></fn-group><ref-list><title>References</title><ref id="pone.0031634-Bregman1"><label>1</label><element-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Bregman</surname><given-names>AS</given-names></name></person-group>
<year>1990</year>
<source>Auditory scene analysis: the perceptual organization of sound</source>
<publisher-loc>Cambridge, Mass.</publisher-loc>
<publisher-name>MIT Press</publisher-name>
<fpage>xiii, 773</fpage>
</element-citation></ref><ref id="pone.0031634-Hafter1"><label>2</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hafter</surname><given-names>ER</given-names></name><name><surname>Schlauch</surname><given-names>RS</given-names></name><name><surname>Tang</surname><given-names>J</given-names></name></person-group>
<year>1993</year>
<article-title>Attending to auditory filters that were not stimulated directly.</article-title>
<source>The Journal of the Acoustical Society of America</source>
<volume>94</volume>
<fpage>743</fpage>
<lpage>747</lpage>
<pub-id pub-id-type="pmid">8370880</pub-id></element-citation></ref><ref id="pone.0031634-Hbner1"><label>3</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>H&#x000fc;bner</surname><given-names>R</given-names></name><name><surname>Hafter</surname><given-names>ER</given-names></name></person-group>
<year>1995</year>
<article-title>Cuing mechanisms in auditory signal detection.</article-title>
<source>Perception &#x00026; psychophysics</source>
<volume>57</volume>
<fpage>197</fpage>
<lpage>202</lpage>
<pub-id pub-id-type="pmid">7885818</pub-id></element-citation></ref><ref id="pone.0031634-Lange1"><label>4</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lange</surname><given-names>K</given-names></name></person-group>
<year>2009</year>
<article-title>Brain correlates of early auditory processing are attenuated by expectations for time and pitch.</article-title>
<source>Brain and Cognition</source>
<volume>69</volume>
<fpage>127</fpage>
<lpage>137</lpage>
<pub-id pub-id-type="pmid">18644669</pub-id></element-citation></ref><ref id="pone.0031634-Scharf1"><label>5</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Scharf</surname><given-names>B</given-names></name><name><surname>Reeves</surname><given-names>A</given-names></name><name><surname>Suciu</surname><given-names>J</given-names></name></person-group>
<year>2007</year>
<article-title>The time required to focus on a cued signal frequency.</article-title>
<source>Journal of the Acoustical Society of America</source>
<volume>121</volume>
<fpage>2149</fpage>
<lpage>2157</lpage>
<pub-id pub-id-type="pmid">17471729</pub-id></element-citation></ref><ref id="pone.0031634-Barry1"><label>6</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Barry</surname><given-names>RJ</given-names></name><name><surname>Cocker</surname><given-names>KI</given-names></name><name><surname>Anderson</surname><given-names>JW</given-names></name><name><surname>Gordon</surname><given-names>E</given-names></name><name><surname>Rennie</surname><given-names>C</given-names></name></person-group>
<year>1992</year>
<article-title>Does the N100 evoked potential really habituate? Evidence from a paradigm appropriate to a clinical setting.</article-title>
<source>International Journal of Psychophysiology</source>
<volume>13</volume>
<fpage>9</fpage>
<pub-id pub-id-type="pmid">1522037</pub-id></element-citation></ref><ref id="pone.0031634-Ritter1"><label>7</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Ritter</surname><given-names>W</given-names></name><name><surname>Vaughan</surname><given-names>HG</given-names><suffix>Jr</suffix></name><name><surname>Costa</surname><given-names>LD</given-names></name></person-group>
<year>1968</year>
<article-title>Orienting and habituation to auditory stimuli: a study of short term changes in average evoked responses.</article-title>
<source>Electroencephalogr Clin Neurophysiol</source>
<volume>25</volume>
<fpage>550</fpage>
<lpage>556</lpage>
<pub-id pub-id-type="pmid">4178749</pub-id></element-citation></ref><ref id="pone.0031634-Rosburg1"><label>8</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Rosburg</surname><given-names>T</given-names></name><name><surname>Zimmerer</surname><given-names>K</given-names></name><name><surname>Huonker</surname><given-names>R</given-names></name></person-group>
<year>2010</year>
<article-title>Short-term habituation of auditory evoked potential and neuromagnetic field components in dependence of the interstimulus interval.</article-title>
<source>Experimental Brain Research</source>
<volume>205</volume>
<fpage>559</fpage>
<lpage>570</lpage>
<pub-id pub-id-type="pmid">20711562</pub-id></element-citation></ref><ref id="pone.0031634-Thompson1"><label>9</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Thompson</surname><given-names>RF</given-names></name><name><surname>Spencer</surname><given-names>WA</given-names></name></person-group>
<year>1966</year>
<article-title>Habituation: a model phenomenon for the study of neuronal substrates of behavior.</article-title>
<source>Psychological Review</source>
<volume>73</volume>
<fpage>16</fpage>
<lpage>43</lpage>
<pub-id pub-id-type="pmid">5324565</pub-id></element-citation></ref><ref id="pone.0031634-Budd1"><label>10</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Budd</surname><given-names>TW</given-names></name><name><surname>Barry</surname><given-names>RJ</given-names></name><name><surname>Gordon</surname><given-names>E</given-names></name><name><surname>Rennie</surname><given-names>C</given-names></name><name><surname>Michie</surname><given-names>PT</given-names></name></person-group>
<year>1998</year>
<article-title>Decrement of the N1 auditory event-related potential with stimulus repetition: habituation vs. refractoriness.</article-title>
<source>Int J Psychophysiol</source>
<volume>31</volume>
<fpage>51</fpage>
<lpage>68</lpage>
<pub-id pub-id-type="pmid">9934621</pub-id></element-citation></ref><ref id="pone.0031634-Lagemann1"><label>11</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lagemann</surname><given-names>L</given-names></name><name><surname>Okamoto</surname><given-names>H</given-names></name><name><surname>Teismann</surname><given-names>H</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name></person-group>
<year>2010</year>
<article-title>Bottom-up driven involuntary attention modulates auditory signal in noise processing.</article-title>
<source>BMC neuroscience</source>
<volume>11</volume>
<fpage>156</fpage>
<lpage>162</lpage>
<pub-id pub-id-type="pmid">21192798</pub-id></element-citation></ref><ref id="pone.0031634-Oldfield1"><label>12</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>RC</given-names></name></person-group>
<year>1971</year>
<article-title>The assessment and analysis of handedness: the Edinburgh inventory.</article-title>
<source>Neuropsychologia</source>
<volume>9</volume>
<fpage>97</fpage>
<lpage>113</lpage>
<pub-id pub-id-type="pmid">5146491</pub-id></element-citation></ref><ref id="pone.0031634-LopesdaSilva1"><label>13</label><element-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Lopes da Silva</surname><given-names>FH</given-names></name></person-group>
<year>2010</year>
<article-title>Electrophysiological Basis of MEG Signals.</article-title>
<person-group person-group-type="editor"><name><surname>Hansen</surname><given-names>P</given-names></name><name><surname>Kringelbach</surname><given-names>M</given-names></name><name><surname>Salmelin</surname><given-names>R</given-names></name></person-group>
<source>MEG: An Introduction to Methods</source>
<publisher-loc>New York</publisher-loc>
<publisher-name>Oxford University Press</publisher-name>
<fpage>1</fpage>
<lpage>23</lpage>
</element-citation></ref><ref id="pone.0031634-Hillebrand1"><label>14</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hillebrand</surname><given-names>A</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name></person-group>
<year>2002</year>
<article-title>A quantitative assessment of the sensitivity of whole-head MEG to activity in the adult human cortex.</article-title>
<source>Neuroimage</source>
<volume>16</volume>
<fpage>638</fpage>
<lpage>650</lpage>
<pub-id pub-id-type="pmid">12169249</pub-id></element-citation></ref><ref id="pone.0031634-Ntnen1"><label>15</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name><name><surname>Picton</surname><given-names>T</given-names></name></person-group>
<year>1987</year>
<article-title>The N1 Wave of the Human Electric and Magnetic Response to Sound: A Review and an Analysis of the Component Structure.</article-title>
<source>Psychophysiology</source>
<volume>24</volume>
<fpage>375</fpage>
<lpage>425</lpage>
<pub-id pub-id-type="pmid">3615753</pub-id></element-citation></ref><ref id="pone.0031634-Salmelin1"><label>16</label><element-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Salmelin</surname><given-names>R</given-names></name></person-group>
<year>2010</year>
<article-title>Multi-Dipole Modeling in MEG.</article-title>
<person-group person-group-type="editor"><name><surname>Hansen</surname><given-names>P</given-names></name><name><surname>Kringelbach</surname><given-names>M</given-names></name><name><surname>Salmelin</surname><given-names>R</given-names></name></person-group>
<source>MEG: An Introduction to Methods</source>
<publisher-loc>New York</publisher-loc>
<publisher-name>Oxford University Press</publisher-name>
<fpage>124</fpage>
<lpage>155</lpage>
</element-citation></ref><ref id="pone.0031634-Tesche1"><label>17</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Tesche</surname><given-names>CD</given-names></name><name><surname>Uusitalo</surname><given-names>MA</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Kajola</surname><given-names>M</given-names></name><etal/></person-group>
<year>1995</year>
<article-title>Signal-space projections of MEG data characterize both distributed and well-localized neuronal sources.</article-title>
<source>Electroencephalogr Clin Neurophysiol</source>
<volume>95</volume>
<fpage>189</fpage>
<lpage>200</lpage>
<pub-id pub-id-type="pmid">7555909</pub-id></element-citation></ref><ref id="pone.0031634-Holm1"><label>18</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Holm</surname><given-names>S</given-names></name></person-group>
<year>1979</year>
<article-title>A simple sequentially rejective multiple test procedure.</article-title>
<source>Scandinavian Journal of Statistics</source>
<volume>6</volume>
<fpage>65</fpage>
<lpage>70</lpage>
</element-citation></ref><ref id="pone.0031634-Alain1"><label>19</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Alain</surname><given-names>C</given-names></name><name><surname>Quan</surname><given-names>J</given-names></name><name><surname>McDonald</surname><given-names>K</given-names></name><name><surname>Van Roon</surname><given-names>P</given-names></name></person-group>
<year>2009</year>
<article-title>Noise-induced increase in human auditory evoked neuromagnetic fields.</article-title>
<source>The European journal of neuroscience</source>
<volume>30</volume>
<fpage>132</fpage>
<lpage>142</lpage>
<pub-id pub-id-type="pmid">19558607</pub-id></element-citation></ref><ref id="pone.0031634-Hari1"><label>20</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>M&#x000e4;kel&#x000e4;</surname><given-names>JP</given-names></name></person-group>
<year>1988</year>
<article-title>Modification of neuromagnetic responses of the human auditory cortex by masking sounds.</article-title>
<source>Exp Brain Res</source>
<volume>71</volume>
<fpage>87</fpage>
<lpage>92</lpage>
<pub-id pub-id-type="pmid">3416961</pub-id></element-citation></ref><ref id="pone.0031634-Morita1"><label>21</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Morita</surname><given-names>T</given-names></name><name><surname>Fujiki</surname><given-names>N</given-names></name><name><surname>Nagamine</surname><given-names>T</given-names></name><name><surname>Hiraumi</surname><given-names>H</given-names></name><name><surname>Naito</surname><given-names>Y</given-names></name><etal/></person-group>
<year>2006</year>
<article-title>Effects of continuous masking noise on tone-evoked magnetic fields in humans.</article-title>
<source>Brain Res</source>
<volume>1087</volume>
<fpage>151</fpage>
<lpage>158</lpage>
<pub-id pub-id-type="pmid">16626668</pub-id></element-citation></ref><ref id="pone.0031634-Condon1"><label>22</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Condon</surname><given-names>CD</given-names></name><name><surname>Weinberger</surname><given-names>NM</given-names></name></person-group>
<year>1991</year>
<article-title>Habituation produces frequency-specific plasticity of receptive fields in the auditory cortex.</article-title>
<source>Behavioral neuroscience</source>
<volume>105</volume>
<fpage>416</fpage>
<lpage>430</lpage>
<pub-id pub-id-type="pmid">1863363</pub-id></element-citation></ref><ref id="pone.0031634-Ulanovsky1"><label>23</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group>
<year>2003</year>
<article-title>Processing of low-probability sounds by cortical neurons.</article-title>
<source>NATURE NEUROSCIENCE</source>
<volume>6</volume>
<fpage>391</fpage>
<lpage>398</lpage>
<pub-id pub-id-type="pmid">12652303</pub-id></element-citation></ref><ref id="pone.0031634-Jskelinen1"><label>24</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>J&#x000e4;&#x000e4;skel&#x000e4;inen</surname><given-names>IP</given-names></name><name><surname>Ahveninen</surname><given-names>J</given-names></name><name><surname>Andermann</surname><given-names>ML</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Raij</surname><given-names>T</given-names></name><etal/></person-group>
<year>2011</year>
<article-title>Short-term plasticity as a neural mechanism supporting memory and attentional functions.</article-title>
<source>Brain Research</source>
<volume>1422</volume>
<fpage>66</fpage>
<lpage>81</lpage>
<pub-id pub-id-type="pmid">21985958</pub-id></element-citation></ref><ref id="pone.0031634-May1"><label>25</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>May</surname><given-names>P</given-names></name><name><surname>Tiitinen</surname><given-names>H</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Nyman</surname><given-names>Gt</given-names></name><name><surname>Taylor</surname><given-names>JG</given-names></name><etal/></person-group>
<year>1999</year>
<article-title>Frequency Change Detection in Human Auditory Cortex.</article-title>
<source>Journal of Computational Neuroscience</source>
</element-citation></ref><ref id="pone.0031634-Jskelinen2"><label>26</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>J&#x000e4;&#x000e4;skel&#x000e4;inen</surname><given-names>IP</given-names></name><name><surname>Ahveninen</surname><given-names>J</given-names></name><name><surname>Bonmassar</surname><given-names>G</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><etal/></person-group>
<year>2004</year>
<article-title>Human posterior auditory cortex gates novel sounds to consciousness.</article-title>
<source>Proceedings of the National Academy of Sciences of the United States of America</source>
<volume>101</volume>
<fpage>6809</fpage>
<lpage>6814</lpage>
<pub-id pub-id-type="pmid">15096618</pub-id></element-citation></ref><ref id="pone.0031634-McEvoy1"><label>27</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>McEvoy</surname><given-names>L</given-names></name><name><surname>Levanen</surname><given-names>S</given-names></name><name><surname>Loveless</surname><given-names>N</given-names></name></person-group>
<year>1997</year>
<article-title>Temporal characteristics of auditory sensory memory: neuromagnetic evidence.</article-title>
<source>Psychophysiology</source>
<volume>34</volume>
<fpage>308</fpage>
<lpage>316</lpage>
<pub-id pub-id-type="pmid">9175445</pub-id></element-citation></ref><ref id="pone.0031634-Sams1"><label>28</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Sams</surname><given-names>M</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Rif</surname><given-names>J</given-names></name><name><surname>Knuutila</surname><given-names>J</given-names></name></person-group>
<year>1993</year>
<article-title>The Human Auditory Sensory Memory Trace Persists about 10 sec: Neuromagnetic Evidence.</article-title>
<source>Journal of Cognitive Neuroscience</source>
<volume>5</volume>
<fpage>363</fpage>
<lpage>370</lpage>
<pub-id pub-id-type="pmid">23972223</pub-id></element-citation></ref><ref id="pone.0031634-Pantev1"><label>29</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pantev</surname><given-names>C</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name><name><surname>Eulitz</surname><given-names>C</given-names></name><name><surname>Verkindt</surname><given-names>C</given-names></name><name><surname>Hampson</surname><given-names>S</given-names></name><etal/></person-group>
<year>1995</year>
<article-title>Specific tonotopic organizations of different areas of the human auditory cortex revealed by simultaneous magnetic and electric recordings.</article-title>
<source>Electroencephalogr Clin Neurophysiol</source>
<volume>94</volume>
<fpage>26</fpage>
<lpage>40</lpage>
<pub-id pub-id-type="pmid">7530637</pub-id></element-citation></ref><ref id="pone.0031634-Pantev2"><label>30</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pantev</surname><given-names>C</given-names></name><name><surname>Hoke</surname><given-names>M</given-names></name><name><surname>Lutkenhoner</surname><given-names>B</given-names></name><name><surname>Lehnertz</surname><given-names>K</given-names></name></person-group>
<year>1989</year>
<article-title>Tonotopic organization of the auditory cortex: pitch versus frequency representation.</article-title>
<source>Science</source>
<volume>246</volume>
<fpage>486</fpage>
<lpage>488</lpage>
<pub-id pub-id-type="pmid">2814476</pub-id></element-citation></ref><ref id="pone.0031634-Romani1"><label>31</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Romani</surname><given-names>GL</given-names></name><name><surname>Williamson</surname><given-names>SJ</given-names></name><name><surname>Kaufman</surname><given-names>L</given-names></name></person-group>
<year>1982</year>
<article-title>Tonotopic organization of the human auditory cortex.</article-title>
<source>Science</source>
<volume>216</volume>
<fpage>1339</fpage>
<lpage>1340</lpage>
<pub-id pub-id-type="pmid">7079770</pub-id></element-citation></ref><ref id="pone.0031634-Hubner1"><label>32</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hubner</surname><given-names>R</given-names></name><name><surname>Hafter</surname><given-names>ER</given-names></name></person-group>
<year>1995</year>
<article-title>Cuing mechanisms in auditory signal detection.</article-title>
<source>Perception &#x00026; psychophysics</source>
<volume>57</volume>
<fpage>197</fpage>
<lpage>202</lpage>
<pub-id pub-id-type="pmid">7885818</pub-id></element-citation></ref><ref id="pone.0031634-Okamoto1"><label>33</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Okamoto</surname><given-names>H</given-names></name><name><surname>Stracke</surname><given-names>H</given-names></name><name><surname>Zwitserlood</surname><given-names>P</given-names></name><name><surname>Roberts</surname><given-names>LE</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name></person-group>
<year>2009</year>
<article-title>Frequency-specific modulation of population-level frequency tuning in human auditory cortex.</article-title>
<source>BMC Neuroscience</source>
<volume>10</volume>
<fpage>1</fpage>
<pub-id pub-id-type="pmid">19126204</pub-id></element-citation></ref><ref id="pone.0031634-Knudsen1"><label>34</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Knudsen</surname><given-names>EI</given-names></name></person-group>
<year>2007</year>
<article-title>Fundamental Components of Attention.</article-title>
<source>Annual Review of Neuroscience</source>
<volume>30</volume>
<fpage>57</fpage>
<lpage>78</lpage>
</element-citation></ref><ref id="pone.0031634-Luo1"><label>35</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Luo</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Alireza</surname><given-names>K</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name></person-group>
<year>2008</year>
<article-title>Corticofugal Modulation of Initial Sound Processing in the Brain.</article-title>
<source>Journal of Neuroscience</source>
<volume>28</volume>
<fpage>11615</fpage>
<lpage>11621</lpage>
<pub-id pub-id-type="pmid">18987197</pub-id></element-citation></ref><ref id="pone.0031634-Skoe1"><label>36</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Skoe</surname><given-names>E</given-names></name><name><surname>Kraus</surname><given-names>N</given-names></name></person-group>
<year>2010</year>
<article-title>Auditory brain stem response to complex sounds: a tutorial.</article-title>
<source>Ear &#x00026; Hearing</source>
<volume>31</volume>
<fpage>302</fpage>
<lpage>324</lpage>
<pub-id pub-id-type="pmid">20084007</pub-id></element-citation></ref><ref id="pone.0031634-Chandrasekaran1"><label>37</label><element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Chandrasekaran</surname><given-names>B</given-names></name><name><surname>Hornickel</surname><given-names>J</given-names></name><name><surname>Skoe</surname><given-names>E</given-names></name><name><surname>Nicol</surname><given-names>T</given-names></name><name><surname>Kraus</surname><given-names>N</given-names></name></person-group>
<year>2009</year>
<article-title>Context-Dependent Encoding in the Human Auditory Brainstem Relates to Hearing Speech in Noise: Implications for Developmental Dyslexia.</article-title>
<source>Neuron</source>
<volume>64</volume>
<fpage>311</fpage>
<lpage>319</lpage>
<pub-id pub-id-type="pmid">19914180</pub-id></element-citation></ref></ref-list></back></article>