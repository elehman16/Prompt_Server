<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28723943</article-id><article-id pub-id-type="pmc">5516979</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0180588</article-id><article-id pub-id-type="publisher-id">PONE-D-17-08484</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Habits</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Human Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Behavioral Addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Addiction</subject><subj-group><subject>Behavioral Addiction</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Neuroscience</subject><subj-group><subject>Cognitive Neurology</subject><subj-group><subject>Cognitive Impairment</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Neuroscience</subject><subj-group><subject>Cognitive Neurology</subject><subj-group><subject>Cognitive Impairment</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Neurology</subject><subj-group><subject>Cognitive Neurology</subject><subj-group><subject>Cognitive Impairment</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Endocrinology</subject></subj-group></subj-group></article-categories><title-group><article-title>Stress enhances model-free reinforcement learning only after negative outcome</article-title><alt-title alt-title-type="running-head">The effects of stress on reinforcement learning</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4971-9756</contrib-id><name><surname>Park</surname><given-names>Heyeon</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="author-notes" rid="currentaff001"><sup>&#x000a4;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Daeyeol</given-names></name><xref ref-type="aff" rid="aff002"><sup>2</sup></xref><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5371-7783</contrib-id><name><surname>Chey</surname><given-names>Jeanyung</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Department of Psychology, Seoul National University, Seoul, Korea</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Department of Neuroscience, Department of Psychiatry, Yale School of Medicine, New Haven, United States of America</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Department of Psychology, Yale University, New Haven, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Boraud</surname><given-names>Thomas</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Centre national de la recherche scientifique, FRANCE</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con"><p><list list-type="simple"><list-item><p><bold>Conceptualization:</bold> HP JC DL.</p></list-item><list-item><p><bold>Formal analysis:</bold> HP DL.</p></list-item><list-item><p><bold>Funding acquisition:</bold> JC.</p></list-item><list-item><p><bold>Investigation:</bold> HP JC.</p></list-item><list-item><p><bold>Methodology:</bold> DL HP.</p></list-item><list-item><p><bold>Project administration:</bold> JC.</p></list-item><list-item><p><bold>Resources:</bold> JC.</p></list-item><list-item><p><bold>Software:</bold> HP DL.</p></list-item><list-item><p><bold>Supervision:</bold> JC.</p></list-item><list-item><p><bold>Validation:</bold> DL JC HP.</p></list-item><list-item><p><bold>Visualization:</bold> HP.</p></list-item><list-item><p><bold>Writing &#x02013; original draft:</bold> HP.</p></list-item><list-item><p><bold>Writing &#x02013; review &#x00026; editing:</bold> JC DL HP.</p></list-item></list>
</p></fn><fn fn-type="current-aff" id="currentaff001"><label>&#x000a4;</label><p>Current address: Department of Public Health Medical Services, Seoul National University Bundang Hospital, Seongnam, Korea</p></fn><corresp id="cor001">* E-mail: <email>jychey@snu.ac.kr</email></corresp></author-notes><pub-date pub-type="epub"><day>19</day><month>7</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>12</volume><issue>7</issue><elocation-id>e0180588</elocation-id><history><date date-type="received"><day>3</day><month>3</month><year>2017</year></date><date date-type="accepted"><day>16</day><month>6</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; 2017 Park et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Park et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0180588.pdf"/><abstract><p>Previous studies found that stress shifts behavioral control by promoting habits while decreasing goal-directed behaviors during reward-based decision-making. It is, however, unclear how stress disrupts the relative contribution of the two systems controlling reward-seeking behavior, i.e. model-free (or habit) and model-based (or goal-directed). Here, we investigated whether stress biases the contribution of model-free and model-based reinforcement learning processes differently depending on the valence of outcome, and whether stress alters the learning rate, i.e., how quickly information from the new environment is incorporated into choices. Participants were randomly assigned to either a stress or a control condition, and performed a two-stage Markov decision-making task in which the reward probabilities underwent periodic reversals without notice. We found that stress increased the contribution of model-free reinforcement learning only after negative outcome. Furthermore, stress decreased the learning rate. The results suggest that stress diminishes one&#x02019;s ability to make adaptive choices in multiple aspects of reinforcement learning. This finding has implications for understanding how stress facilitates maladaptive habits, such as addictive behavior, and other dysfunctional behaviors associated with stress in clinical and educational contexts.</p></abstract><funding-group><funding-statement>This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF), funded by the Ministry of Education, Science and Technology (No. 2011-0005029). The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="1"/><page-count count="12"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper and its Supporting Information files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Reward-seeking behaviors can be described by two different computational principles that might be supported by distinct neuroanatomical substrates [<xref rid="pone.0180588.ref001" ref-type="bibr">1</xref>&#x02013;<xref rid="pone.0180588.ref004" ref-type="bibr">4</xref>]. On the one hand, a goal-directed controller selects behaviors expected to produce the best outcomes according to the knowledge of the decision-maker&#x02019;s environment and motivational state. The process by which the knowledge is updated and outcomes expected from alternative actions are derived from this knowledge is referred to as model-based reinforcement learning (RL). On the other hand, a habit controller relies on the expected values of outcome adjusted incrementally by trial and error, and results in automatic and less computationally demanding action selection. Accordingly, these goal-directed and habit systems might favor different actions, when the motivational status of the actor or the properties of environment change rapidly. However, precisely how the balance between these two controllers is adjusted across different behavioral settings remains poorly understood.</p><p>Stress might influence the arbitration between a goal-directed and a habit controller during decision making. Previous studies showed that stress causes humans to repeat behavior previously learned despite environmental changes [<xref rid="pone.0180588.ref005" ref-type="bibr">5</xref>&#x02013;<xref rid="pone.0180588.ref009" ref-type="bibr">9</xref>] and tends to impair episodic memory while enhancing sensory processing [<xref rid="pone.0180588.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0180588.ref012" ref-type="bibr">12</xref>], raising the possibility that stress might promote a switch from a high-order cognitive control to a simpler stimulus-response mapping. However, these previous studies have not examined precisely whether and how different aspects of learning and action selection are influenced by stress in a dynamic environment.</p><p>One of the critical issues regarding the relationship between stress and decision-making is how stress has an impact on the trade-off between habit and goal-directed behaviors. More specifically, whether stress leads to more habitual behaviors by either selectively weakening the process of goal-directed behaviors, by merely strengthening the process of habit or both. It is also possible that the effect of stress on behavior might vary depending on whether the result of previous behavior was positive or negative. Indeed, previous studies have suggested that stress might differently influence decisions depending on the valence of the outcome [<xref rid="pone.0180588.ref013" ref-type="bibr">13</xref>&#x02013;<xref rid="pone.0180588.ref015" ref-type="bibr">15</xref>]. Considering that the neural circuits of reward processing frequently reflects valence-dependent activity of outcome [<xref rid="pone.0180588.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0180588.ref017" ref-type="bibr">17</xref>], it is possible that stress alters the neural processing of reinforcement and punishment differentially. In other words, stress may boost the neural signals related to decision-making differentially depending on the valence of outcomes. Finally, it remains unclear whether persistent behaviors resulting from stress simply reflects a decrease in the ability to incorporate the information about environmental changes, as quantified by the rate of learning, rather than changes in the nature of RL itself.</p><p>In the present study, we investigated the effects of stress on multiple aspects of RL such as model-free and model-based tendency according to the valence of the outcome and the learning rate. Participants were assigned to either a stress or a control condition before performing a multiple-stage decision-making task designed to distinguish model-based behavior from model-free RL behavior. In this task, reward probabilities associated with different choices were periodically reversed. By applying computational models to choice data, we quantified the extent to which choices were influenced by model-free vs. model-based RL, and dissociated the RL processing according to whether decision was followed by positive or negative outcome. Also, how the learning rate was affected by stress was examined.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and methods</title><p>This study was approved by the Seoul National University Institutional Review Board (SNUIRB), and all participants provided written informed consent.</p><sec id="sec003"><title>Participants</title><p>Fifty six healthy undergraduate students participated in this study (29 women, 27 men; age, 20.36 &#x000b1; 1.91; body mass index 21.00 &#x000b1; 2.52). Individuals who met any of the following criteria were excluded from participation: history of head injury, treatment with psychotropic medications, steroids, or any other medication that affects the central nervous system or the endocrine systems, current medical illness, self-report of mental disorder or substance abuse, existence of current stressful episode or major life event. Also, smokers and women taking oral contraceptives were excluded from the study due to possible effects of nicotine and oral contraceptive on the neuroendocrine stress response [<xref rid="pone.0180588.ref018" ref-type="bibr">18</xref>, <xref rid="pone.0180588.ref019" ref-type="bibr">19</xref>]. Although gender could affect the hypothalamus-pituitary-adrenal cortex responsiveness to psychosocial stress differently, it has been demonstrated that there were no differences in salivary cortisol response between men and women in the luteal phase [<xref rid="pone.0180588.ref018" ref-type="bibr">18</xref>]. Therefore, women in the late luteal phase (after Day 21 and before the start of the next cycle) of the menstrual cycle were included in this study. Participants were asked to refrain from caffeine and physical exercise during the 6 hours prior to participation, and then were randomly assigned to the stress and the control conditions. Age (<italic>t</italic><sub>50</sub> = 1.23, <italic>p</italic> = .226), body mass index (<italic>t</italic><sub>50</sub> = -.20, <italic>p</italic> = .846), and perceived stress during the past month (<italic>t</italic><sub>50</sub> = .71, <italic>p</italic> = .483), assessed with Perceived Stress Scale [<xref rid="pone.0180588.ref020" ref-type="bibr">20</xref>], were not significantly different between participants in the two conditions. Four participants (two from each condition), who continued to choose the same action in more than 95% of the trials during the task, were excluded from the analysis, since this reflected lack of learning.</p></sec><sec id="sec004"><title>Stress protocol</title><p>The socially evaluated cold pressor test (SECPT) [<xref rid="pone.0180588.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0180588.ref021" ref-type="bibr">21</xref>] was administered to the participants in the stress condition (15 women and 13 men). They immersed one hand (left-handed, right; right-handed, left) up to and including the wrist for 3 minutes (2 participants did it for 2 minutes which was their limits) into ice water (0 ~ 2<sup>&#x000b0;</sup>C). During hand immersion, they were recorded on video by an unfamiliar person. Participants in the control condition (14 women and 14 men) submerged one hand up to and including the wrist for 1 minute in warm water (36 ~ 38<sup>&#x000b0;</sup>C), and they were not recorded on video. To assess whether the treatments were successful, participants were required to report subjective stress on the visual analogue scale (VAS), with the lower and upper bound of the scale marked with numbers 0 and 100, representing a range from &#x0201c;no stress&#x0201d; to &#x0201c;the most stressful.&#x0201d; All experiments took place between 1:00 P.M. and 5:40 P.M. to control for diurnal rhythm of the stress hormone (cortisol). Ten minutes after the cessation of the SECPT or the control procedure, the participants performed a two-stage reversal learning task described below.</p></sec><sec id="sec005"><title>Behavioral task</title><p>We used a two-stage reversal learning task which combined a reversal learning paradigm with the two-stage Markov decision task developed by Daw and his colleagues [<xref rid="pone.0180588.ref022" ref-type="bibr">22</xref>] (see <xref ref-type="fig" rid="pone.0180588.g001">Fig 1</xref> for details). The two-stage Markov decision task has been used to distinguish the contribution of model-free and model-based RL to action selection. We also adopted the reversal learning paradigm, so that the participants were faced with a changing environment, and their choices in response to discrete environmental change could be investigated. The task consisted of six blocks of 40 trials, totaling 240 trials without any breaks. There was no explicit cue for block transition.</p><fig id="pone.0180588.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0180588.g001</object-id><label>Fig 1</label><caption><title>Task design.</title><p>(A) Task structure. Choice in the first stage leads probabilistically to different states in the second stage. Each stimulus in the second-stage resulted in either 0 or 100 points with different probabilities. (B) Timeline of events in a single trial. (C) Reward-probabilities of four options in stage 2.</p></caption><graphic xlink:href="pone.0180588.g001"/></fig><p>Each trial required two successive choices. In the first stage (&#x0201c;state 1&#x0201d;), participants chose between two options, represented by figures similar to Tibetan characters in green-colored boxes. The first-stage choice led probabilistically to one of the two second-stage states (&#x0201c;state 2&#x0201d; and &#x0201c;state 3&#x0201d;), represented by different colors (pink and blue). Each of the first-stage options was associated strongly (with a chance of 70%) with one of the two states in the second-stage, and this contingency was fixed throughout the experiment (<xref ref-type="fig" rid="pone.0180588.g001">Fig 1A</xref>). In the second-stage, subjects made another binary choice, and this second choice was linked to either 100 or 0 points depending on reward probability that was predetermined (<xref ref-type="fig" rid="pone.0180588.g001">Fig 1C</xref>). The assignment of two colors (pink or blue) to state 2 and 3 was counterbalanced across subjects, and the locations of two options in each state were randomized from trial to trial.</p><p>The reward probabilities for the two options in the second stage changed from block to block, employing the reversal learning paradigm as shown in <xref ref-type="fig" rid="pone.0180588.g001">Fig 1C</xref>. In the first block, both states 2 and 3 had one option leading to 60% chance of reward while the other leading to 20% chance. Therefore, in block 1, the two options in the first stage were equally favorable. In block 2, however, the two options in state 2 were rewarded with 80% and 20%, respectively, while both options in state 3 were rewarded with 20%. Therefore, it was more advantageous to choose the option more strongly associated with state 2 in the first-stage. In the following blocks, the advantageous choice in the first stage (&#x0201c;state 1&#x0201d;) alternated as the reward probabilities of the options were switched between two states of the stage 2 after each block transition.</p><p>Prior to the experiment, the participants were informed that the reward probabilities for different choices in second stage would change, and that the probabilities of the transitions from the first state to different states in the second stage were fixed throughout the experiment. A practice session was given to familiarize the participants with the structure of the task. The practice session comprised of thirty trials, with five trials in each block.</p></sec><sec id="sec006"><title>Behavioral analyses</title><p>A series of two-tailed t-tests were used to examine whether there were differences in task performance between the two conditions. As different measures of performance, we analyzed the average response time to make a choice in the first stage, total points (cumulated reward), and overall probability of selecting the advantageous option (the option more strongly associated with &#x0201c;state 2&#x0201d; in block 2, 4, and 6, and the option more strongly associated with &#x0201c;state 3&#x0201d; in block 3 and 5) in the first stage. Next, a mixed-design ANOVA with outcome type (rewarded or unrewarded), and transition type (common or rare) as within-subjects factors, and treatment (stress or control condition) as between-subjects factors was used to examine whether staying probabilities (the probability of choosing the same option as in the preceding trial) in the first-stage varied significantly with stress, reward on previous trial, and transition type in previous trial. The data were analyzed using the IBM SPSS statistics 21 software.</p></sec><sec id="sec007"><title>Computational modeling</title><p>We used a RL model to characterize the trial-by-trial choice dynamics. Various different RL algorithms have been proposed to predict the reward from each option. In this study, we adopted the modified version of the Q-learning model since it performed better than the standard RL model to account for choice behaviors [<xref rid="pone.0180588.ref023" ref-type="bibr">23</xref>]. In the Q-learning model, action values are updated via a simple Rescorla-Wagner (RW) rule [<xref rid="pone.0180588.ref024" ref-type="bibr">24</xref>], and therefore, for a simple binary choice, the value function, V<sub>t</sub>(x), for option x can be updated after each trial t according to the following:
<disp-formula id="pone.0180588.e001"><alternatives><graphic xlink:href="pone.0180588.e001.jpg" id="pone.0180588.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
where R<sub>t</sub> means the outcome of the action at the trial t. This is equivalent to the following.
<disp-formula id="pone.0180588.e002"><alternatives><graphic xlink:href="pone.0180588.e002.jpg" id="pone.0180588.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
In the present study, this RL model was modified to quantify model-free and model-based choice behaviors in the first stage of the task [<xref rid="pone.0180588.ref023" ref-type="bibr">23</xref>, <xref rid="pone.0180588.ref025" ref-type="bibr">25</xref>]. In the model, the action values are updated according to the following:
<disp-formula id="pone.0180588.e003"><alternatives><graphic xlink:href="pone.0180588.e003.jpg" id="pone.0180588.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="0.25em"/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>&#x003ba;</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="3em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">it</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">is</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">rewarded</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="0.20em"/><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>&#x003ba;</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">it</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">is</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">unrewarded</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
where &#x003b1; was the learning rate for the selected option. The parameter &#x003ba;<sub>+</sub> represented the strength of reinforcement by the reward outcome, and &#x003ba;<sub>_</sub> represented the strength of punishment by the no-reward outcome. In the present study, this model was expanded to update the value function for the choice in the first stage differently depending on the type of state transition in the same trial. Namely, the perturbation term &#x003ba; was duplicated to reflect the components expected from model-free (&#x003ba;<sup>mf</sup>) and mode-based (&#x003ba;<sup>mb</sup>) RL model. For example, if reward occurred after a common transition, the value function of the option participants chose in the first stage (&#x0201c;state 1&#x0201d;) was updated by &#x003ba;<sub>+</sub><sup>mf</sup> + &#x003ba;<sub>+</sub><sup>mb</sup>, since in this case, both model-free and model-based algorithms would attribute the positive outcome to the chosen action. By contrast, if reward occurred after a rare transition, the value function for the option selected in the first stage (&#x0201c;state 1&#x0201d;) was updated by &#x003ba;<sub>+</sub><sup>mf</sup>, while the value function for the option unselected was updated by &#x003ba;<sub>+</sub><sup>mb</sup>, since in this case, model-free algorithms would attribute this positive outcome to the option chosen and the model-based learning would attribute the positive outcome to the option unchosen. Similarly, if reward did not occur after common transition, the value function of the chosen option was updated by &#x003ba;<sub>_</sub><sup>mf</sup> + &#x003ba;<sub>_</sub><sup>mb</sup>. If there was no reward after a rare transition, the value function for the chosen option was updated by &#x003ba;<sub>_</sub><sup>mf</sup><sub>,</sub> while the value function for the other option was updated by &#x003ba;<sub>_</sub><sup>mb</sup>.</p><p>We found that for some subjects, the value of &#x003b1; and &#x003ba; parameters estimated using the above equations were not stable, since the value of &#x003ba; could increase in order to compensate a vanishingly small value of the learning rate. Therefore, model parameters were estimated using the following equation, which is mathematically equivalent to (3).
<disp-formula id="pone.0180588.e004"><alternatives><graphic xlink:href="pone.0180588.e004.jpg" id="pone.0180588.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="0.5em"/><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="3em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">it</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">is</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">rewarded</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">it</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">is</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">unrewarded</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
where, &#x003b3; = 1 &#x02013;&#x003b1; and represents a decay (or discount) factor, a weighting parameter given to the previous value estimate, and &#x00394; = &#x003b1;&#x003ba;, represents the change in the value function determined by the participant&#x02019;s choice and its outcome [<xref rid="pone.0180588.ref025" ref-type="bibr">25</xref>]. In other words, &#x00394;<sub>+</sub><sup>mf</sup>, &#x00394;<sub>+</sub><sup>mb</sup>, &#x00394;<sub>_</sub><sup>mf</sup>, and &#x00394;<sub>_</sub><sup>mb</sup> replaced &#x003b1;&#x003ba;<sub>+</sub><sup>mf</sup>, &#x003b1;&#x003ba;<sub>+</sub><sup>mb</sup>, &#x003b1;&#x003ba;<sub>_</sub><sup>mf</sup>, and &#x003b1;&#x003ba;<sub>_</sub><sup>mb</sup>, respectively. In this RL model, the tendency to switch away from the unrewarded action corresponds to &#x00394;<sub>_</sub> &#x0003c; 0 while the tendency to stay with the same action regardless of no-reward corresponds to &#x00394;<sub>_</sub> &#x0003e; 0. More specifically, if &#x00394;<sub>_</sub><sup>mf</sup> and &#x00394;<sub>_</sub><sup>mb</sup> are negative, their magnitudes quantify how strongly model-free and model-based RL predict the tendency to switch to a different option after no reward.</p><p>The probability of choosing each option was given by the probability from softmax function related to the difference between the value functions. In other words, denoting the first stage actions by a<sub>1</sub> and a<sub>2</sub>,
<disp-formula id="pone.0180588.e005"><alternatives><graphic xlink:href="pone.0180588.e005.jpg" id="pone.0180588.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula>
It should be noted that this model does not require any inverse temperature to determine the randomness in the participant&#x02019;s choices, since this can be changed by the magnitude of other model parameters (&#x00394;&#x02019;s). This model is similar to the model used in Daw and his colleagues (2011), except that the value functions for unchosen actions decay gradually.</p><p>Parameters of the models were estimated separately for each participant. To maximize the log-likelihood of the data for each subject, we used the Nelder-Mead simplex algorithm [<xref rid="pone.0180588.ref026" ref-type="bibr">26</xref>]. We constrained discount factor to lie between zero and one, and allowed four change parameters to float arbitrarily. Model fitting was iterated 500 times with randomly chosen initial values in order to minimize the risk of finding a local but not global optimal solution.</p><p>A series of two-tailed t-tests were used to examine whether there were differences in parameter estimates of the RL models between the two conditions. Also, to test whether stress independently influences the learning rate and the weight of model-free &#x00026; model-based RL, we performed regression on the model-free or model-based parameter estimate with a decay parameter and a treatment (stress vs. control) for each individual. The data were analyzed using the IBM SPSS statistics 21 software.</p></sec></sec><sec sec-type="results" id="sec008"><title>Results</title><sec id="sec009"><title>Effects of stress on decision-making performance</title><p>We analyzed the choice behaviors of 52 participants (26 in each condition) during the two-stage reversal learning task following either stress-inducing or control treatment. Task performance of each participant is in <xref ref-type="supplementary-material" rid="pone.0180588.s001">S1 Table</xref>. As expected, participants in the stress condition rated the hand immersion as significantly more stressful (two-tailed t-test: <italic>t</italic><sub>50</sub> = 8.61, <italic>p</italic> &#x0003c; 0.001) than participants in the control condition. Average reaction times for choices in the first stage did not differ significantly for stress and control conditions (two-tailed t-test, <italic>t</italic><sub>50</sub> = 1.6, <italic>p</italic> = .116). By contrast, total earnings were significantly lower in the stress condition than in the control condition (<italic>t</italic><sub>50</sub> = 2.52, <italic>p</italic> = .015). Also, the probabilities of selecting the advantageous option in the first stage were lower in the stress condition than those in the control condition (<italic>t</italic><sub>50</sub> = 2.90, <italic>p</italic> = .006).</p><p>In order to examine how stress might alter the model-free and model-based RL overall, we analyzed the stay-vs.-shift behavior in the first stage. Model-free RL assumes that participants select action solely based on previous choice outcome (reward or no-reward), whereas model-based RL assumes that they choose the optimal actions using their knowledge of the task structure. Therefore, participants relying on model-based RL would tend to stay with the same action even after no reward if this was preceded by a rare transition. By contrast, participants behaving strictly according to model-free RL would choose the same option in the first stage as in the previous trial when the same choice was rewarded in the previous trial, regardless of whether the outcome was preceded by a common or rare transition (<xref ref-type="fig" rid="pone.0180588.g002">Fig 2A</xref>). The results from the mixed-design ANOVA revealed a significant main effect of outcome (<italic>F</italic><sub>(1,50)</sub> = 18.44, <italic>p</italic> &#x0003c; 0.001), reflecting the pattern predicted for model-free RL. Moreover, a significant reward &#x000d7; transition type interaction (<italic>F</italic><sub>(1,50)</sub> = 14.06, <italic>p</italic> &#x0003c; 0.001) showed that there was also a significant effect of model-based RL. More importantly, a significant stress &#x000d7; reward &#x000d7; transition type interaction (<italic>F</italic><sub>(1,50)</sub> = 8.86, <italic>p</italic> = 0.004) demonstrated a modulatory role of stress in the coordination of model-free and model-based performance in the task (<xref ref-type="fig" rid="pone.0180588.g002">Fig 2B</xref>). Neither stress &#x000d7; reward (<italic>F</italic><sub>(1,50)</sub> = 0.06, <italic>p</italic> = 0.81) nor stress &#x000d7; transition type interactions (<italic>F</italic><sub>(1,50)</sub> = 0.09, <italic>p</italic> = 0.76) were significant.</p><fig id="pone.0180588.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0180588.g002</object-id><label>Fig 2</label><caption><title>The effects of stress on decision-making.</title><p>(A) The hypothetic results of stay-shift analysis expected for model-based (left) and model-free (right) reinforcement learning. (B) The behavioral results of stay-shift analysis. Participants&#x02019; task performance in control condition showed characteristics of both model-free and model-based influences, while stressed participants showed stronger characteristic of model-free reinforcement learning. The stress &#x000d7; reward &#x000d7; transition interaction, <italic>p</italic> = .004. (C) The results of parameter estimation of a reinforcement learning model. Stress heightened the discount factor, &#x003b3; (which means stress declined the learning rate) (<italic>p</italic> = .002) and boosted only model-free tendency to switch to a different option after no reward (&#x00394;<sub>_</sub><sup>mf</sup>) (<italic>p</italic> &#x0003c; .001). Error bars represent SEM. &#x00394;<sub>+</sub><sup>mb</sup> &#x00394;<sub>_</sub><sup>mb</sup>, and &#x00394;<sub>+</sub><sup>mf</sup> are parameters of the RL model which indicate the model-based tendency after reward, the model-based tendency after no-reward, and the model-free tendency after reward, respectively.</p></caption><graphic xlink:href="pone.0180588.g002"/></fig></sec><sec id="sec010"><title>Effects of stress on reinforcement learning model parameters</title><p>In order to test multiple factors involved in decision making, and how they are modulated by stress, we applied the RL model that differentiates the model-free and model-based components of action selection. We found that the maximum likelihood estimates of the model parameter for the effect of negative outcome in the model-free learning (&#x00394;<sub>_</sub><sup>mf</sup>) was significantly positive in the control condition (<italic>t</italic><sub>25</sub> = 5.17, <italic>p</italic> &#x0003c; 0.001) (<xref ref-type="table" rid="pone.0180588.t001">Table 1</xref>). Presumably, the positive value of this parameter indicates that the subjects tended to stay with the same option in the first stage even when the previous outcome was negative. More importantly, the value of this parameter was significantly reduced in the stress condition (<italic>t</italic><sub>50</sub> = 3.52, <italic>p</italic> = 0.001) (<xref ref-type="table" rid="pone.0180588.t001">Table 1</xref>, <xref ref-type="fig" rid="pone.0180588.g002">Fig 2C</xref>), suggesting that the tendency to avoid the option with the negative outcome was strengthened by stress. There was no significant difference in the model-free effect of positive outcome (&#x00394;<sub>+</sub><sup>mf</sup>) between the two conditions. Also, stress did not alter the parameters associated with model-based RL (&#x00394;<sub>+</sub><sup>mb</sup> and &#x00394;<sub>_</sub><sup>mb</sup>). Instead, we found that the discount factor, &#x003b3;, was significantly higher in the stress compared to the control condition (<italic>t</italic><sub>50</sub> = <sub>_</sub>3.31, <italic>p</italic> = 0.002). The discount factor determines how rapidly the previous value function is forgotten, and is related to the learning rate &#x003b1; (&#x003b3; = 1<sub>_</sub> &#x003b1;). Thus, it appears that stress boosted only model-free tendency to switch to a different option after no reward and decreased the learning rate, i.e., the ability to incorporate new information into decision-making.</p><table-wrap id="pone.0180588.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0180588.t001</object-id><label>Table 1</label><caption><title>Best-fitting parameter estimates, shown as median plus quartiles across conditions.</title></caption><alternatives><graphic id="pone.0180588.t001g" xlink:href="pone.0180588.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr style="border-top:thick"><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">&#x003b3;<xref ref-type="table-fn" rid="t001fn002"><sup>*</sup></xref></th><th align="center" rowspan="1" colspan="1">&#x00394;<sub>+</sub><sup>mf</sup></th><th align="center" rowspan="1" colspan="1">&#x00394;<sub>+</sub><sup>mb</sup></th><th align="center" rowspan="1" colspan="1">&#x00394;<sub>_</sub><sup>mf</sup><xref ref-type="table-fn" rid="t001fn003"><sup>**</sup></xref></th><th align="center" rowspan="1" colspan="1">&#x00394;<sub>_</sub><sup>mb</sup></th></tr></thead><tbody><tr><td align="left" colspan="6" style="background-color:#D9D9D9" rowspan="1"><bold>CONTROL</bold></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>25</bold><sup><bold>th</bold></sup></td><td align="center" rowspan="1" colspan="1">0.23</td><td align="center" rowspan="1" colspan="1">0.70</td><td align="center" rowspan="1" colspan="1">0.10</td><td align="center" rowspan="1" colspan="1">0.12</td><td align="center" rowspan="1" colspan="1">-0.41</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Median</bold></td><td align="center" rowspan="1" colspan="1">0.47</td><td align="center" rowspan="1" colspan="1">1.09</td><td align="center" rowspan="1" colspan="1">0.33</td><td align="center" rowspan="1" colspan="1">0.48</td><td align="center" rowspan="1" colspan="1">-0.14</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>75</bold><sup><bold>th</bold></sup></td><td align="center" rowspan="1" colspan="1">0.60</td><td align="center" rowspan="1" colspan="1">1.67</td><td align="center" rowspan="1" colspan="1">0.80</td><td align="center" rowspan="1" colspan="1">0.78</td><td align="center" rowspan="1" colspan="1">0.04</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold><italic>T</italic></bold></td><td align="center" rowspan="1" colspan="1">8.41<xref ref-type="table-fn" rid="t001fn003">**</xref></td><td align="center" rowspan="1" colspan="1">3.30<xref ref-type="table-fn" rid="t001fn002">*</xref></td><td align="center" rowspan="1" colspan="1">2.00</td><td align="center" rowspan="1" colspan="1">5.17<xref ref-type="table-fn" rid="t001fn003">**</xref></td><td align="center" rowspan="1" colspan="1">-2.74</td></tr><tr><td align="left" colspan="6" style="background-color:#D9D9D9" rowspan="1"><bold>STRESS</bold></td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>25</bold><sup><bold>th</bold></sup></td><td align="center" rowspan="1" colspan="1">0.56</td><td align="center" rowspan="1" colspan="1">0.04</td><td align="center" rowspan="1" colspan="1">-0.23</td><td align="center" rowspan="1" colspan="1">-0.10</td><td align="center" rowspan="1" colspan="1">-0.13</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>Median</bold></td><td align="center" rowspan="1" colspan="1">0.73</td><td align="center" rowspan="1" colspan="1">0.50</td><td align="center" rowspan="1" colspan="1">-0.04</td><td align="center" rowspan="1" colspan="1">0.02</td><td align="center" rowspan="1" colspan="1">-0.01</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>75</bold><sup><bold>th</bold></sup></td><td align="center" rowspan="1" colspan="1">0.95</td><td align="center" rowspan="1" colspan="1">1.06</td><td align="center" rowspan="1" colspan="1">0.18</td><td align="center" rowspan="1" colspan="1">0.14</td><td align="center" rowspan="1" colspan="1">0.11</td></tr><tr style="border-bottom:thick"><td align="left" rowspan="1" colspan="1"><bold><italic>T</italic></bold></td><td align="center" rowspan="1" colspan="1">11.50<xref ref-type="table-fn" rid="t001fn003">**</xref></td><td align="center" rowspan="1" colspan="1">3.84<xref ref-type="table-fn" rid="t001fn002">*</xref></td><td align="center" rowspan="1" colspan="1">.02</td><td align="center" rowspan="1" colspan="1">.62</td><td align="center" rowspan="1" colspan="1">-.89</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>Notes: &#x00394;<sub>+</sub><sup>mb</sup> and &#x00394;<sub>_</sub><sup>mb</sup> are parameters which represent the model-based tendency after reward and no-reward, respectively. &#x00394;<sub>+</sub><sup>mf</sup> and &#x00394;<sub>+</sub><sup>mf</sup> are parameters which indicate the model-free tendency after reward and no-reward, respectively.</p></fn><fn id="t001fn002"><p>* <italic>p</italic> &#x0003c; 0.01</p></fn><fn id="t001fn003"><p><sup>**</sup>
<italic>p</italic> &#x0003c; 0.001. T is the <italic>t</italic> value from the paired t-test which was performed to investigate whether each parameter was significantly different from zero.</p></fn></table-wrap-foot></table-wrap><p>We performed additional analyses in order to clarify further how the changes in model-free RL were related to stress treatments. First, to test whether stress independently influences the learning rate and the weight of model-free RL after negative outcome, we performed regression on the model-free parameter estimate (&#x00394;<sub>_</sub><sup>mf</sup>) with a decay parameter and a treatment (stressed or not) for each subject. The results confirmed that the effect of stress on model-free RL after negative outcome (&#x00394;<sub>_</sub><sup>mf</sup>) was significant (B = -0.433, SE = 0.133, <italic>&#x003b2;</italic> = -0.459, <italic>p</italic> = 0.002) even after controlling for the effect of stress on the learning rate (B = 0.049, SE = 0.218, <italic>&#x003b2;</italic> = 0.032, <italic>p</italic> = 0.822). Second, we conducted the ANCOVA with the probability of the advantageous action as a covariate. In the present study, a reversal learning component was incorporated into the two-stage decision-making task [<xref rid="pone.0180588.ref022" ref-type="bibr">22</xref>]. During a two-stage decision task with reversal, subjects with model-free tendency, who simply choose the advantageous option in each block, might appear to have a model-based tendency [<xref rid="pone.0180588.ref027" ref-type="bibr">27</xref>]. The ANCOVA results showed that the effect of stress on the strength of model-free RL after receiving negative outcome was significant even after controlling for the probability of the advantageous action (<italic>F</italic><sub><italic>(1</italic>,<italic>49)</italic></sub> = 8.01, <italic>p</italic> = 0.007). Taken together, these results suggest that stress increased the contribution of model-free RL only after negative outcomes.</p></sec></sec><sec sec-type="conclusions" id="sec011"><title>Discussion</title><p>In this study, we found that stress impaired the reward-seeking behavior and demonstrated that the inferior performance under stress might be due to at least two different mechanisms. First, stress increased the influence of the model-free reinforcement learning, particularly the likelihood of switching to an alternative choice when the previous choice led to an undesirable outcome. Second, stress decreased the learning rate, namely, the degree to which new information is incorporated into trial-by-trial decision making. These findings suggest that maladaptive choice behavior under stress might be attributable to both a slower learning rate and the strengthening of model-free RL after a negative outcome.</p><p>It has not been investigated clearly whether stress leads to more habitual behaviors by selectively weakening the process of goal-directed behaviors, by merely strengthening the process of habit, or both. In order to investigate the effect of acute stress on the distinct contributions of habit and goal-directed processing, recent researches have tried to use computational modeling for reinforcement learning (RL) to separate the habit and goal-directed processing into two RL algorithms, model-free and model-based, respectively. In previous computational studies, however, the effects of acute stress on the two RL were inconsistent [<xref rid="pone.0180588.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0180588.ref029" ref-type="bibr">29</xref>]. Otto and his colleagues showed that stress-related physiological (cortisol) response was negatively correlated with model-based but not model-free contributions. However, their study did not demonstrate the effect of stress on decision making itself. Also, Radenbach and his colleagues reported the effect of stress on the ratio of model-based RL to model-free RL, but without clearly separating out the effects of stress on model-based RL from those of model-free RL[<xref rid="pone.0180588.ref029" ref-type="bibr">29</xref>]. Thus, how acute stress facilitates habit or model-free choice behavior remained incompletely understood.</p><p>In this study, we investigated the effects of stress on model-free and model-based RL using a 2-step decision task incorporating the reversal learning paradigm and showed that stress increased the model-free RL without altering the strength of model-based RL. These results suggested that stress-enhancement of habit behavior may not be merely compensatory byproduct of impaired model-based RL behavior. Also, habitual processing might be strengthened by stress because stress disrupts inhibition of the model-free processing which could be a default model of RL[<xref rid="pone.0180588.ref030" ref-type="bibr">30</xref>]. Furthermore, we differentiated the model-free tendency to make a shift following no-reward (lose-switch) and to stay following a reward (win-stay), and showed that stress increased the model-free RL after no-reward selectively without affecting the model-free RL after reward. These results suggest that stress may disproportionately boost the neural processing of decision-making involved in model-free learning from negative outcomes. Our findings are consistent with previous studies showing there are separate neural processing for reinforcement and punishment [<xref rid="pone.0180588.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0180588.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0180588.ref031" ref-type="bibr">31</xref>].</p><p>Although the 2-step decision task has been designed to distinguish model-free and model-based RL, a recent study revealed that the original task does not lead to significant difference in performance (points or income) predicted by model-based vs. model-free RL approach, through a computational simulation [<xref rid="pone.0180588.ref027" ref-type="bibr">27</xref>]. Therefore, we incorporated a reversal learning paradigm into the original task, which produced more consistent difference in the performance for the two RL strategies. However, in a reversal learning task, decision-makers can learn that there are two distinct latent states of the task and rely on such inference about the current latent state to make their choices [<xref rid="pone.0180588.ref032" ref-type="bibr">32</xref>, <xref rid="pone.0180588.ref033" ref-type="bibr">33</xref>]. The decision-maker who infers and uses latent state of the task could outperform a standard model-free RL and looks like a model-based decision-maker, even without using the knowledge of the transition structure linking the first actions to the states of the second stage [<xref rid="pone.0180588.ref034" ref-type="bibr">34</xref>]. In this study, stress enhanced only model-free RL without impairing model-based RL. We conducted the ANCOVA with the probability of selecting the advantageous action as a covariate, which would reflect the tendency to make choices based on the inference about a latent state. The results from this analysis showed that the effect of stress on the strength of model-free RL after receiving negative outcome was significant even after controlling for the probability of the advantageous action. Therefore, stress might increase the contribution of model-free RL regardless of its effect on the ability to make choices based on the inferred state of the environment.</p><p>Also, we found that stress decreased the learning rate during a reward-based choice task. In the RL model, the learning rate reflects how quickly the valuation of selected action is updated by the difference between the prediction and the actual outcome, referred to as the prediction error [<xref rid="pone.0180588.ref002" ref-type="bibr">2</xref>]. Therefore, it represents how rapidly new information from the environment is incorporated in subsequent actions [<xref rid="pone.0180588.ref035" ref-type="bibr">35</xref>&#x02013;<xref rid="pone.0180588.ref037" ref-type="bibr">37</xref>]. For adaptive decision making, it is critical to utilize new information efficiently and to avoid maladaptive perseverative behaviors when faced with environmental change. Decision-makers with low learning rate would fail to switch their behaviors flexibly in response to unexpected changes in the real world. It is possible that a decrease in learning rate under stress may be an important factor contributing to stress-induced alteration in RL. However, we could not examine the effect of stress on the distinct learning rate of model-free and model-based RL, because we estimated a single learning rate from observed choices and rewards for each subject. Further investigations are necessary to clarify whether stress changes learning rate during both model-free and model-based RL.</p></sec><sec sec-type="conclusions" id="sec012"><title>Conclusions</title><p>This study characterized the effect of stress on adaptive decision making, by providing participants with a changing environment where their choice behaviors were modeled in a computational framework of reinforcement learning. We found that stress facilitated the habitual, model-free RL process to shift away from unrewarded action, and that it also interrupted the subjects from incorporating new information into their subsequent choices. These findings provide insight as to the mechanism by which stress diminishes the ability to behave flexibly in reward-based decision making, and have significant implications for understanding and treating stress-related maladaptive conditions characterized by enhanced habit behavior such as addiction and impulse control disorders.</p></sec><sec sec-type="supplementary-material" id="sec013"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0180588.s001"><label>S1 Table</label><caption><title>Task performance for each subject.</title><p>(XLSX)</p></caption><media xlink:href="pone.0180588.s001.xlsx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pone.0180588.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Doll</surname><given-names>BB</given-names></name>, <name><surname>Simon</surname><given-names>DA</given-names></name>, <name><surname>Daw</surname><given-names>ND</given-names></name>. <article-title>The ubiquity of model-based reinforcement learning</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2012</year>.</mixed-citation></ref><ref id="pone.0180588.ref002"><label>2</label><mixed-citation publication-type="book"><name><surname>Sutton</surname><given-names>RS</given-names></name>, <name><surname>Barto</surname><given-names>AG</given-names></name>. <source>Reinforcement Learning: An Introduction</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation></ref><ref id="pone.0180588.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>D</given-names></name>. <article-title>Decision making: from neuroscience to psychiatry</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>78</volume>(<issue>2</issue>):<fpage>233</fpage>&#x02013;<lpage>48</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.04.008">10.1016/j.neuron.2013.04.008</ext-link></comment>
<pub-id pub-id-type="pmid">23622061</pub-id></mixed-citation></ref><ref id="pone.0180588.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Penner</surname><given-names>MR</given-names></name>, <name><surname>Mizumori</surname><given-names>SJ</given-names></name>. <article-title>Neural systems analysis of decision making during goal-directed navigation</article-title>. <source>Progress in neurobiology</source>. <year>2012</year>;<volume>96</volume>(<issue>1</issue>):<fpage>96</fpage>&#x02013;<lpage>135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.pneurobio.2011.08.010">10.1016/j.pneurobio.2011.08.010</ext-link></comment>
<pub-id pub-id-type="pmid">21964237</pub-id></mixed-citation></ref><ref id="pone.0180588.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L</given-names></name>, <name><surname>Wolf</surname><given-names>OT</given-names></name>. <article-title>Stress prompts habit behavior in humans</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>22</issue>):<fpage>7191</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0979-09.2009">10.1523/JNEUROSCI.0979-09.2009</ext-link></comment>
<pub-id pub-id-type="pmid">19494141</pub-id></mixed-citation></ref><ref id="pone.0180588.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Dias-Ferreira</surname><given-names>E</given-names></name>, <name><surname>Sousa</surname><given-names>JC</given-names></name>, <name><surname>Melo</surname><given-names>I</given-names></name>, <name><surname>Morgado</surname><given-names>P</given-names></name>, <name><surname>Mesquita</surname><given-names>AR</given-names></name>, <name><surname>Cerqueira</surname><given-names>JJ</given-names></name>, <etal>et al</etal>
<article-title>Chronic stress causes frontostriatal reorganization and affects decision-making</article-title>. <source>Science</source>. <year>2009</year>;<volume>325</volume>(<issue>5940</issue>):<fpage>621</fpage>&#x02013;<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1171203">10.1126/science.1171203</ext-link></comment>
<pub-id pub-id-type="pmid">19644122</pub-id></mixed-citation></ref><ref id="pone.0180588.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L</given-names></name>, <name><surname>Dalm</surname><given-names>S</given-names></name>, <name><surname>Sch&#x000e4;chinger</surname><given-names>H</given-names></name>, <name><surname>Oitzl</surname><given-names>MS</given-names></name>. <article-title>Chronic stress modulates the use of spatial and stimulus-response learning strategies in mice and man</article-title>. <source>Neurobiology of learning and memory</source>. <year>2008</year>;<volume>90</volume>(<issue>3</issue>):<fpage>495</fpage>&#x02013;<lpage>503</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.nlm.2008.07.015">10.1016/j.nlm.2008.07.015</ext-link></comment>
<pub-id pub-id-type="pmid">18707011</pub-id></mixed-citation></ref><ref id="pone.0180588.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L</given-names></name>, <name><surname>Oitzl</surname><given-names>MS</given-names></name>, <name><surname>Philippsen</surname><given-names>C</given-names></name>, <name><surname>Richter</surname><given-names>S</given-names></name>, <name><surname>Bohringer</surname><given-names>A</given-names></name>, <name><surname>Wippich</surname><given-names>W</given-names></name>, <etal>et al</etal>
<article-title>Stress modulates the use of spatial versus stimulus-response learning strategies in humans</article-title>. <source>Learning &#x00026; Memory</source>. <year>2007</year>;<volume>14</volume>(<issue>1&#x02013;2</issue>):<fpage>109</fpage>&#x02013;<lpage>16</lpage>.<pub-id pub-id-type="pmid">17272656</pub-id></mixed-citation></ref><ref id="pone.0180588.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L</given-names></name>, <name><surname>Sch&#x000e4;chinger</surname><given-names>H</given-names></name>, <name><surname>de Kloet</surname><given-names>ER</given-names></name>, <name><surname>Oitzl</surname><given-names>MS</given-names></name>. <article-title>Corticosteroids operate as a switch between memory systems</article-title>. <source>Journal of cognitive neuroscience</source>. <year>2010</year>;<volume>22</volume>(<issue>7</issue>):<fpage>1362</fpage>&#x02013;<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2009.21278">10.1162/jocn.2009.21278</ext-link></comment>
<pub-id pub-id-type="pmid">19445601</pub-id></mixed-citation></ref><ref id="pone.0180588.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Kim</surname><given-names>J</given-names></name>, <name><surname>Diamond</surname><given-names>DM</given-names></name>. <article-title>The stressed hippocampus, synaptic plasticity and lost memories</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2002</year>;<volume>3</volume>(<issue>6</issue>):<fpage>453</fpage>&#x02013;<lpage>62</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn849">10.1038/nrn849</ext-link></comment>
<pub-id pub-id-type="pmid">12042880</pub-id></mixed-citation></ref><ref id="pone.0180588.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Henckens</surname><given-names>MJ</given-names></name>, <name><surname>Hermans</surname><given-names>EJ</given-names></name>, <name><surname>Pu</surname><given-names>Z</given-names></name>, <name><surname>Jo&#x000eb;ls</surname><given-names>M</given-names></name>, <name><surname>Fern&#x000e1;ndez</surname><given-names>G</given-names></name>. <article-title>Stressed memories: how acute stress affects memory formation in humans</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>32</issue>):<fpage>10111</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1184-09.2009">10.1523/JNEUROSCI.1184-09.2009</ext-link></comment>
<pub-id pub-id-type="pmid">19675245</pub-id></mixed-citation></ref><ref id="pone.0180588.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Ferragud</surname><given-names>A</given-names></name>, <name><surname>Haro</surname><given-names>A</given-names></name>, <name><surname>Sylvain</surname><given-names>A</given-names></name>, <name><surname>Velazquez-Sanchez</surname><given-names>C</given-names></name>, <name><surname>Hernandez-Rabaza</surname><given-names>V</given-names></name>, <name><surname>Canales</surname><given-names>J</given-names></name>. <article-title>Enhanced habit-based learning and decreased neurogenesis in the adult hippocampus in a murine model of chronic social stress</article-title>. <source>Behavioural brain research</source>. <year>2010</year>;<volume>210</volume>(<issue>1</issue>):<fpage>134</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.bbr.2010.02.013">10.1016/j.bbr.2010.02.013</ext-link></comment>
<pub-id pub-id-type="pmid">20153381</pub-id></mixed-citation></ref><ref id="pone.0180588.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Porcelli</surname><given-names>AJ</given-names></name>, <name><surname>Delgado</surname><given-names>MR</given-names></name>. <article-title>Acute stress modulates risk taking in financial decision making</article-title>. <source>Psychological Science</source>. <year>2009</year>;<volume>20</volume>(<issue>3</issue>):<fpage>278</fpage>&#x02013;<lpage>83</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2009.02288.x">10.1111/j.1467-9280.2009.02288.x</ext-link></comment>
<pub-id pub-id-type="pmid">19207694</pub-id></mixed-citation></ref><ref id="pone.0180588.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Lighthall</surname><given-names>NR</given-names></name>, <name><surname>Gorlick</surname><given-names>MA</given-names></name>, <name><surname>Schoeke</surname><given-names>A</given-names></name>, <name><surname>Frank</surname><given-names>MJ</given-names></name>, <name><surname>Mather</surname><given-names>M</given-names></name>. <article-title>Stress modulates reinforcement learning in younger and older adults</article-title>. <source>Psychology and aging</source>. <year>2013</year>;<volume>28</volume>(<issue>1</issue>):<fpage>35</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0029823">10.1037/a0029823</ext-link></comment>
<pub-id pub-id-type="pmid">22946523</pub-id></mixed-citation></ref><ref id="pone.0180588.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Cavanagh</surname><given-names>JF</given-names></name>, <name><surname>Frank</surname><given-names>MJ</given-names></name>, <name><surname>Allen</surname><given-names>JJ</given-names></name>. <article-title>Social stress reactivity alters reward and punishment learning</article-title>. <source>Social cognitive and affective neuroscience</source>. <year>2011</year>;<volume>6</volume>(<issue>3</issue>):<fpage>311</fpage>&#x02013;<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/scan/nsq041">10.1093/scan/nsq041</ext-link></comment>
<pub-id pub-id-type="pmid">20453038</pub-id></mixed-citation></ref><ref id="pone.0180588.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Jensen</surname><given-names>J</given-names></name>, <name><surname>Smith</surname><given-names>AJ</given-names></name>, <name><surname>Willeit</surname><given-names>M</given-names></name>, <name><surname>Crawley</surname><given-names>AP</given-names></name>, <name><surname>Mikulis</surname><given-names>DJ</given-names></name>, <name><surname>Vitcu</surname><given-names>I</given-names></name>, <etal>et al</etal>
<article-title>Separate brain regions code for salience vs. valence during reward prediction in humans</article-title>. <source>Human brain mapping</source>. <year>2007</year>;<volume>28</volume>(<issue>4</issue>):<fpage>294</fpage>&#x02013;<lpage>302</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.20274">10.1002/hbm.20274</ext-link></comment>
<pub-id pub-id-type="pmid">16779798</pub-id></mixed-citation></ref><ref id="pone.0180588.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name>, <name><surname>Matsumoto</surname><given-names>M</given-names></name>, <name><surname>Hikosaka</surname><given-names>O</given-names></name>. <article-title>Dopamine in motivational control: rewarding, aversive, and alerting</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>68</volume>(<issue>5</issue>):<fpage>815</fpage>&#x02013;<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.11.022">10.1016/j.neuron.2010.11.022</ext-link></comment>
<pub-id pub-id-type="pmid">21144997</pub-id></mixed-citation></ref><ref id="pone.0180588.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Kirschbaum</surname><given-names>C</given-names></name>, <name><surname>Kudielka</surname><given-names>BM</given-names></name>, <name><surname>Gaab</surname><given-names>J</given-names></name>, <name><surname>Schommer</surname><given-names>NC</given-names></name>, <name><surname>Hellhammer</surname><given-names>DH</given-names></name>. <article-title>Impact of gender, menstrual cycle phase, and oral contraceptives on the activity of the hypothalamus-pituitary-adrenal axis</article-title>. <source>Psychosomatic medicine</source>. <year>1999</year>;<volume>61</volume>(<issue>2</issue>):<fpage>154</fpage>&#x02013;<lpage>62</lpage>. Epub 1999/04/16. .<pub-id pub-id-type="pmid">10204967</pub-id></mixed-citation></ref><ref id="pone.0180588.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Mendelson</surname><given-names>JH</given-names></name>, <name><surname>Sholar</surname><given-names>MB</given-names></name>, <name><surname>Goletiani</surname><given-names>N</given-names></name>, <name><surname>Siegel</surname><given-names>AJ</given-names></name>, <name><surname>Mello</surname><given-names>NK</given-names></name>. <article-title>Effects of low- and high-nicotine cigarette smoking on mood states and the HPA axis in men</article-title>. <source>Neuropsychopharmacology: official publication of the American College of Neuropsychopharmacology</source>. <year>2005</year>;<volume>30</volume>(<issue>9</issue>):<fpage>1751</fpage>&#x02013;<lpage>63</lpage>. Epub 2005/05/05. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/sj.npp.1300753">10.1038/sj.npp.1300753</ext-link></comment> ; PubMed Central PMCID: PMCPMC1383570.<pub-id pub-id-type="pmid">15870834</pub-id></mixed-citation></ref><ref id="pone.0180588.ref020"><label>20</label><mixed-citation publication-type="book"><name><surname>Cohen</surname><given-names>S</given-names></name>, <name><surname>Williamson</surname><given-names>GM</given-names></name>. <chapter-title>Perceived stress in a probability sample of the United states</chapter-title> In: <name><surname>Spacapan</surname><given-names>S</given-names></name>, <name><surname>Oskamp</surname><given-names>S</given-names></name>, editors. <source>the social psychology of health: claremont symposium on applied social psychology</source>
<publisher-loc>Newbury Park, CA</publisher-loc>: <publisher-name>Sage</publisher-name>; <year>1988</year>.</mixed-citation></ref><ref id="pone.0180588.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L</given-names></name>, <name><surname>Haddad</surname><given-names>L</given-names></name>, <name><surname>Schachinger</surname><given-names>H</given-names></name>. <article-title>HPA axis activation by a socially evaluated cold-pressor test</article-title>. <source>Psychoneuroendocrinology</source>. <year>2008</year>;<volume>33</volume>(<issue>6</issue>):<fpage>890</fpage>&#x02013;<lpage>5</lpage>. Epub 2008/04/12. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.psyneuen.2008.03.001">10.1016/j.psyneuen.2008.03.001</ext-link></comment> .<pub-id pub-id-type="pmid">18403130</pub-id></mixed-citation></ref><ref id="pone.0180588.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Daw</surname><given-names>ND</given-names></name>, <name><surname>Gershman</surname><given-names>SJ</given-names></name>, <name><surname>Seymour</surname><given-names>B</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>, <name><surname>Dolan</surname><given-names>RJ</given-names></name>. <article-title>Model-based influences on humans' choices and striatal prediction errors</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>69</volume>(<issue>6</issue>):<fpage>1204</fpage>&#x02013;<lpage>15</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.02.027">10.1016/j.neuron.2011.02.027</ext-link></comment>
<pub-id pub-id-type="pmid">21435563</pub-id></mixed-citation></ref><ref id="pone.0180588.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Ito</surname><given-names>M</given-names></name>, <name><surname>Doya</surname><given-names>K</given-names></name>. <article-title>Validation of decision-making models and analysis of decision variables in the rat basal ganglia</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>(<issue>31</issue>):<fpage>9861</fpage>&#x02013;<lpage>74</lpage>. Epub 2009/08/07. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.6157-08.2009">10.1523/JNEUROSCI.6157-08.2009</ext-link></comment> .<pub-id pub-id-type="pmid">19657038</pub-id></mixed-citation></ref><ref id="pone.0180588.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Rescorla</surname><given-names>RA</given-names></name>, <name><surname>Wagner</surname><given-names>AR</given-names></name>. <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. <source>Classical conditioning II: Current research and theory</source>. <year>1972</year>;<volume>2</volume>:<fpage>64</fpage>&#x02013;<lpage>99</lpage>.</mixed-citation></ref><ref id="pone.0180588.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Barraclough</surname><given-names>DJ</given-names></name>, <name><surname>Conroy</surname><given-names>ML</given-names></name>, <name><surname>Lee</surname><given-names>D</given-names></name>. <article-title>Prefrontal cortex and decision making in a mixed-strategy game</article-title>. <source>Nat Neurosci</source>. <year>2004</year>;<volume>7</volume>(<issue>4</issue>):<fpage>404</fpage>&#x02013;<lpage>10</lpage>. Epub 2004/03/09. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1209">10.1038/nn1209</ext-link></comment> .<pub-id pub-id-type="pmid">15004564</pub-id></mixed-citation></ref><ref id="pone.0180588.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Lagarias</surname><given-names>JC</given-names></name>, <name><surname>Reeds</surname><given-names>JA</given-names></name>, <name><surname>Wright</surname><given-names>MH</given-names></name>, <name><surname>Wright</surname><given-names>PE</given-names></name>. <article-title>Convergence properties of the Nelder&#x02014;Mead simplex method in low dimensions</article-title>. <source>SIAM Journal on optimization</source>. <year>1998</year>;<volume>9</volume>(<issue>1</issue>):<fpage>112</fpage>&#x02013;<lpage>47</lpage>.</mixed-citation></ref><ref id="pone.0180588.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Akam</surname><given-names>T</given-names></name>, <name><surname>Costa</surname><given-names>R</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>. <article-title>Simple Plans or Sophisticated Habits? State, Transition and Learning Interactions in the Two-Step Task</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>12</issue>):<fpage>e1004648</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004648">10.1371/journal.pcbi.1004648</ext-link></comment>
<pub-id pub-id-type="pmid">26657806</pub-id></mixed-citation></ref><ref id="pone.0180588.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Otto</surname><given-names>AR</given-names></name>, <name><surname>Raio</surname><given-names>CM</given-names></name>, <name><surname>Chiang</surname><given-names>A</given-names></name>, <name><surname>Phelps</surname><given-names>EA</given-names></name>, <name><surname>Daw</surname><given-names>ND</given-names></name>. <article-title>Working-memory capacity protects model-based learning from stress</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>52</issue>):<fpage>20941</fpage>&#x02013;<lpage>6</lpage>.</mixed-citation></ref><ref id="pone.0180588.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Radenbach</surname><given-names>C</given-names></name>, <name><surname>Reiter</surname><given-names>AM</given-names></name>, <name><surname>Engert</surname><given-names>V</given-names></name>, <name><surname>Sjoerds</surname><given-names>Z</given-names></name>, <name><surname>Villringer</surname><given-names>A</given-names></name>, <name><surname>Heinze</surname><given-names>H-J</given-names></name>, <etal>et al</etal>
<article-title>The interaction of acute and chronic stress impairs model-based behavioral control</article-title>. <source>Psychoneuroendocrinology</source>. <year>2015</year>;<volume>53</volume>:<fpage>268</fpage>&#x02013;<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.psyneuen.2014.12.017">10.1016/j.psyneuen.2014.12.017</ext-link></comment>
<pub-id pub-id-type="pmid">25662093</pub-id></mixed-citation></ref><ref id="pone.0180588.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Lee Sang</surname><given-names>W</given-names></name>, <name><surname>Shimojo</surname><given-names>S</given-names></name>, <name><surname>O&#x02019;Doherty John</surname><given-names>P</given-names></name>. <article-title>Neural Computations Underlying Arbitration between Model-Based and Model-free Learning</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>81</volume>(<issue>3</issue>):<fpage>687</fpage>&#x02013;<lpage>99</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2013.11.028">http://dx.doi.org/10.1016/j.neuron.2013.11.028</ext-link></comment>
<pub-id pub-id-type="pmid">24507199</pub-id></mixed-citation></ref><ref id="pone.0180588.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Worbe</surname><given-names>Y</given-names></name>, <name><surname>Palminteri</surname><given-names>S</given-names></name>, <name><surname>Savulich</surname><given-names>G</given-names></name>, <name><surname>Daw</surname><given-names>N</given-names></name>, <name><surname>Fernandez-Egea</surname><given-names>E</given-names></name>, <name><surname>Robbins</surname><given-names>T</given-names></name>, <etal>et al</etal>
<article-title>Valence-dependent influence of serotonin depletion on model-based choice strategy</article-title>. <source>Molecular psychiatry</source>. <year>2016</year>;<volume>21</volume>(<issue>5</issue>):<fpage>624</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/mp.2015.46">10.1038/mp.2015.46</ext-link></comment>
<pub-id pub-id-type="pmid">25869808</pub-id></mixed-citation></ref><ref id="pone.0180588.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Costa</surname><given-names>VD</given-names></name>, <name><surname>Tran</surname><given-names>VL</given-names></name>, <name><surname>Turchi</surname><given-names>J</given-names></name>, <name><surname>Averbeck</surname><given-names>BB</given-names></name>. <article-title>Reversal learning and dopamine: a Bayesian perspective</article-title>. <source>Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>6</issue>):<fpage>2407</fpage>&#x02013;<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1989-14.2015">10.1523/JNEUROSCI.1989-14.2015</ext-link></comment>
<pub-id pub-id-type="pmid">25673835</pub-id></mixed-citation></ref><ref id="pone.0180588.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Hampton</surname><given-names>AN</given-names></name>, <name><surname>Bossaerts</surname><given-names>P</given-names></name>, <name><surname>O&#x02019;doherty</surname><given-names>JP</given-names></name>. <article-title>The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans</article-title>. <source>The Journal of Neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>32</issue>):<fpage>8360</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1010-06.2006">10.1523/JNEUROSCI.1010-06.2006</ext-link></comment>
<pub-id pub-id-type="pmid">16899731</pub-id></mixed-citation></ref><ref id="pone.0180588.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Akam</surname><given-names>T</given-names></name>, <name><surname>Costa</surname><given-names>R</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>. <article-title>Simple Plans or Sophisticated Habits? State, Transition and Learning Interactions in the Two-step Task</article-title>. <source>bioRxiv</source>. <year>2015</year>:<fpage>021428</fpage>.</mixed-citation></ref><ref id="pone.0180588.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Behrens</surname><given-names>TE</given-names></name>, <name><surname>Woolrich</surname><given-names>MW</given-names></name>, <name><surname>Walton</surname><given-names>ME</given-names></name>, <name><surname>Rushworth</surname><given-names>MF</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>&#x02013;<lpage>21</lpage>. Epub 2007/08/07. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954">10.1038/nn1954</ext-link></comment> .<pub-id pub-id-type="pmid">17676057</pub-id></mixed-citation></ref><ref id="pone.0180588.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Bernacchia</surname><given-names>A</given-names></name>, <name><surname>Seo</surname><given-names>H</given-names></name>, <name><surname>Lee</surname><given-names>D</given-names></name>, <name><surname>Wang</surname><given-names>XJ</given-names></name>. <article-title>A reservoir of time constants for memory traces in cortical neurons</article-title>. <source>Nature neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>3</issue>):<fpage>366</fpage>&#x02013;<lpage>72</lpage>. Epub 2011/02/15. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2752">10.1038/nn.2752</ext-link></comment> ; PubMed Central PMCID: PMCPMC3079398.<pub-id pub-id-type="pmid">21317906</pub-id></mixed-citation></ref><ref id="pone.0180588.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Simon</surname><given-names>DA</given-names></name>, <name><surname>Daw</surname><given-names>ND</given-names></name>. <article-title>Environmental statistics and the trade-off between model-based and TD learning in humans</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2011</year>;<volume>24</volume>:<fpage>127</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref></ref-list></back></article>