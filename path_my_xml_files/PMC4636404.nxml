<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PeerJ</journal-id><journal-id journal-id-type="iso-abbrev">PeerJ</journal-id><journal-id journal-id-type="pmc">PeerJ</journal-id><journal-id journal-id-type="publisher-id">PeerJ</journal-id><journal-title-group><journal-title>PeerJ</journal-title></journal-title-group><issn pub-type="epub">2167-8359</issn><publisher><publisher-name>PeerJ Inc.</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26557429</article-id><article-id pub-id-type="pmc">4636404</article-id><article-id pub-id-type="publisher-id">1297</article-id><article-id pub-id-type="doi">10.7717/peerj.1297</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychiatry and Psychology</subject></subj-group><subj-group subj-group-type="heading"><subject>Human&#x02013;Computer Interaction</subject></subj-group></article-categories><title-group><article-title>Effects of mediated social touch on affective experiences and trust</article-title></title-group><contrib-group><contrib id="author-1" contrib-type="author"><name><surname>Erk</surname><given-names>Stefanie M.</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib><contrib id="author-2" contrib-type="author" corresp="yes"><name><surname>Toet</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="aff-1">1</xref><xref ref-type="aff" rid="aff-2">2</xref><email>lextoet@gmail.com</email></contrib><contrib id="author-3" contrib-type="author"><name><surname>Van Erp</surname><given-names>Jan B.F.</given-names></name><xref ref-type="aff" rid="aff-1">1</xref><xref ref-type="aff" rid="aff-3">3</xref></contrib><aff id="aff-1"><label>1</label><institution>TNO</institution>, <addr-line>Soesterberg</addr-line>, <country>Netherlands</country></aff><aff id="aff-2"><label>2</label><institution>Experimental Psychology, Helmholtz Institute, Utrecht University</institution>, <addr-line>Utrecht</addr-line>, <country>Netherlands</country></aff><aff id="aff-3"><label>3</label><institution>Human Media Interaction, University of Twente</institution>, <addr-line>Enschede</addr-line>, <country>Netherlands</country></aff></contrib-group><contrib-group><contrib id="editor-1" contrib-type="editor"><name><surname>Iacoboni</surname><given-names>Marco</given-names></name></contrib></contrib-group><pub-date pub-type="epub" date-type="pub" iso-8601-date="2015-10-06"><day>6</day><month>10</month><year iso-8601-date="2015">2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>3</volume><elocation-id>e1297</elocation-id><history><date date-type="received" iso-8601-date="2015-05-23"><day>23</day><month>5</month><year iso-8601-date="2015">2015</year></date><date date-type="accepted" iso-8601-date="2015-09-16"><day>16</day><month>9</month><year iso-8601-date="2015">2015</year></date></history><permissions><copyright-statement>&#x000a9; 2015 Erk et al.</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Erk et al.</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p></license></permissions><self-uri xlink:href="https://peerj.com/articles/1297"/><abstract><p>This study investigated whether communication via mediated hand pressure during a remotely shared experience (watching an amusing video) can (1) enhance recovery from sadness, (2) enhance the affective quality of the experience, and (3) increase trust towards the communication partner. Thereto participants first watched a sad movie clip to elicit sadness, followed by a funny one to stimulate recovery from sadness. While watching the funny clip they signaled a hypothetical fellow participant every time they felt amused. In the experimental condition the participants responded by pressing a hand-held two-way mediated touch device (a Frebble), which also provided haptic feedback via simulated hand squeezes. In the control condition they responded by pressing a button and they received abstract visual feedback. Objective (heart rate, galvanic skin conductance, number and duration of joystick or Frebble presses) and subjective (questionnaires) data were collected to assess the emotional reactions of the participants. The subjective measurements confirmed that the sad movie successfully induced sadness while the funny movie indeed evoked more positive feelings. Although their ranking agreed with the subjective measurements, the physiological measurements confirmed this conclusion only for the funny movie. The results show that recovery from movie induced sadness, the affective experience of the amusing movie, and trust towards the communication partner did not differ between both experimental conditions. Hence, feedback via mediated hand touching did not enhance either of these factors compared to visual feedback. Further analysis of the data showed that participants scoring low on <italic>Extraversion</italic> (i.e., persons that are more introvert) or low on <italic>Touch Receptivity</italic> (i.e., persons who do not like to be touched by others) felt better understood by their communication partner when receiving mediated touch feedback instead of visual feedback, while the opposite was found for participants scoring high on these factors. The implications of these results for further research are discussed, and some suggestions for follow-up experiments are presented.</p></abstract><kwd-group kwd-group-type="author"><kwd>Social touch</kwd><kwd>Psychophysics</kwd><kwd>Mediated touch</kwd><kwd>Interpersonal touch</kwd><kwd>Trust</kwd><kwd>Affective experience</kwd></kwd-group><funding-group><funding-statement>The authors received no funding for this work.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><sec><title>Aim of this study</title><p>Touch provides a powerful means of evoking and modulating human emotion. Touching someone&#x02014;as well as being touched by someone&#x02014;can have a positive and calming effect. People who are touched more often by their partner also report better psychological well-being (<xref rid="ref-23" ref-type="bibr">Debrot et al., 2013</xref>; <xref rid="ref-24" ref-type="bibr">Debrot et al., 2014</xref>). From nursing care it is known that human touch can promote physical, emotional, social and spiritual comfort (<xref rid="ref-20" ref-type="bibr">Chang, 2001</xref>; <xref rid="ref-85" ref-type="bibr">Whitcher &#x00026; Fisher, 1979</xref>; see also <xref rid="ref-28" ref-type="bibr">Field, 2010</xref>), for instance by effectively reducing worries (<xref rid="ref-85" ref-type="bibr">Whitcher &#x00026; Fisher, 1979</xref>), anxiety and pain (<xref rid="ref-3" ref-type="bibr">Anderson, 2001</xref>).</p><p>In daily life the action of touching or holding hands is an important empathic experience for dyads that elicits a strong sense of togetherness, while signaling trust, understanding and social support (<xref rid="ref-28" ref-type="bibr">Field, 2010</xref>). Haptic devices that mediate the act of holding hands via the internet may therefore provide a means to foster a powerful sense of intimacy and connectedness between physically separated dyads (<xref rid="ref-80" ref-type="bibr">Toet et al., 2013</xref>; <xref rid="ref-83" ref-type="bibr">Van Erp &#x00026; Toet, 2015</xref>). The present study was performed to investigate whether mediated touch can elicit some of the beneficial effects reported for direct touch and can therefore be used to improve the quality of interpersonal contact and communication at a distance. In particular, this study investigates whether sharing emotions via mediated social touch can (1) enhance recovery (i.e., the return to a more positive emotional state) after a negative (sad) experience, (2) enhance a positive (amusing) experience, and (3) increase trust towards the communication partner. At this stage the focus of our research is primarily on eliciting affective responses similar to those that occur while holding hands, and not so much on a realistic simulation of the feeling of a human hand (skin texture and temperature).</p></sec><sec><title>The importance of interpersonal touch</title><p>Touch is the preferred nonverbal communication channel for conveying intimate emotions like love and sympathy (<xref rid="ref-4" ref-type="bibr">App et al., 2011</xref>). Interpersonal touch can promote physical, emotional, social and spiritual wellbeing (<xref rid="ref-28" ref-type="bibr">Field, 2010</xref>). The gentle touch from another person influences our readiness to empathize with and support that person (<xref rid="ref-35" ref-type="bibr">Gu&#x000e9;guen &#x00026; Fischer-Lokou, 2003</xref>). A handshake, an encouraging pat, a sensual caress, a nudge for attention, or a gentle brush can all convey a vitality and immediacy that is at times far more powerful than language (<xref rid="ref-47" ref-type="bibr">Jones &#x00026; Yarbrough, 1985</xref>).</p><p>Geographically separated people in need of social support often long for each other&#x02019;s physical presence. Typical examples are family members who are separated by great distances, such as grandparents who live far from their grandchildren, a child who is sick in a hospital far from family members, a parent who is away on a business trip, people with parents in nursing homes, etc. The development and diffusion of internet-based technologies has enabled people who are globally separated to easily interact with each other. However, most of the currently available technologies do not include the tactile aspects of interpersonal communication, which are known to play a crucial role in establishing a sense of togetherness.</p></sec><sec><title>Mediated touch</title><p>Motivated by the fundamental importance of touch as a channel to convey human emotions, and the fact that even simple haptic stimulation can carry emotional information (<xref rid="ref-71" ref-type="bibr">Salminen et al., 2008</xref>), there has recently been an increasing interest in mediating touch for interpersonal communication in addition to vision and audition (<xref rid="ref-80" ref-type="bibr">Toet et al., 2013</xref>; <xref rid="ref-83" ref-type="bibr">Van Erp &#x00026; Toet, 2015</xref>). Tactile or kinesthetic interfaces that enable haptic communication between people who are physically apart may thus provide the experiences of connection and engagement, with all the physical, emotional and intellectual feedback it supplies (<xref rid="ref-21" ref-type="bibr">Cranny-Francis, 2011</xref>). It has been shown that mediated handshaking can indeed enhance the feeling of social presence (<xref rid="ref-62" ref-type="bibr">Nakanishi, Tanaka &#x00026; Wada, 2014</xref>). Also, haptic telecommunication can increase the quality of a shared experience and enhance the intimacy felt towards the other person (<xref rid="ref-79" ref-type="bibr">Takahashi et al., 2011</xref>) by intensifying the emotional displays from other (e.g., visual, auditory) modalities (<xref rid="ref-50" ref-type="bibr">Knapp &#x00026; Hall, 2010</xref>) and by conveying specific emotions (<xref rid="ref-43" ref-type="bibr">Hertenstein et al., 2006</xref>). Recent technologies like HugMe (<xref rid="ref-19" ref-type="bibr">Cha et al., 2009</xref>), iFeel_ IM (<xref rid="ref-82" ref-type="bibr">Tsetserukou et al., 2009</xref>) and the Frebble (<xref ref-type="fig" rid="fig-1">Fig. 1</xref> ; see also <xref rid="ref-80" ref-type="bibr">Toet et al., 2013</xref> and <uri xlink:href="http://myfrebble.com">http://myfrebble.com</uri>) therefore focus on the enhancement of social interactivity by enabling online communication programs (like MSN or Skype) to convey affective and intimate haptic messages. It has also been suggested that this technology can be used to record affective touch patterns from loved ones for later replay (<xref rid="ref-14" ref-type="bibr">Brown, 2015</xref>). However, until now only few studies have actually investigated affect conveyance through mediated social touch (<xref rid="ref-80" ref-type="bibr">Toet et al., 2013</xref>). Although it appears that mediated touch can indeed to some extent convey emotions (<xref rid="ref-8" ref-type="bibr">Bailenson et al., 2007</xref>) and induce prosocial behavior (the Midas effect, <xref rid="ref-39" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2009</xref>), it is still not known to what extent it can also elicit affective experiences (<xref rid="ref-29" ref-type="bibr">Gallace &#x00026; Spence, 2010</xref>; <xref rid="ref-38" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2006</xref>).</p><fig id="fig-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-1</object-id><label>Figure 1</label><caption><title>A participant&#x02019;s hand holding a Frebble mediated touch device.</title></caption><graphic xlink:href="peerj-03-1297-g001"/></fig></sec><sec><title>Recovery from a sad experience</title><p>People feel a fundamental need to share their feelings (<xref rid="ref-65" ref-type="bibr">Rim&#x000e9;, 2009</xref>) and often seek haptic feedback (e.g., a hug, a pat on the arm or hand), especially after experiencing negative emotions since this type of feedback is highly effective in conveying support and providing comfort (<xref rid="ref-25" ref-type="bibr">Dolin &#x00026; Booth-Butterfield, 1993</xref>). Responsive social touch not only positively affects the receiver but also the touching partner (<xref rid="ref-23" ref-type="bibr">Debrot et al., 2013</xref>; <xref rid="ref-24" ref-type="bibr">Debrot et al., 2014</xref>). A recent study found that even mediated touch can modulate emotion: mediated pressure to the forearm reduced heartbeat rates of participants after they had watched a sad video clip (<xref rid="ref-17" ref-type="bibr">Cabibihan, Zheng &#x00026; Cher, 2012</xref>). Based on these findings we hypothesize that:</p><p><bold>H1</bold>: Feedback via mediated hand touching enhances recovery from movie induced sadness to a larger extent than visual feedback.</p></sec><sec><title>Intensified affective experience</title><p>People feel a need to communicate intense emotions with each other (<xref rid="ref-65" ref-type="bibr">Rim&#x000e9;, 2009</xref>). It has been found that people who experienced negative emotions (sadness, fear, disgust) after watching negative emotional movie clips shared more information and experiences with their friends than participants who watched neutral movie clips (<xref rid="ref-57" ref-type="bibr">Luminet et al., 2000</xref>). But people also like to share positive emotions like happiness and joy with each other, probably because sharing increases the possibility of personal rewards and consequently results in even more optimistic and positive feelings (<xref rid="ref-7" ref-type="bibr">Bagozzi, Gopinath &#x00026; Nyer, 1999</xref>). Laughing together at a comedy show or sharing other moments of fun with each other improves and strengthens relationships and is an opportunity to create connections and bonds between people (<xref rid="ref-49" ref-type="bibr">Klein, 1989</xref>). Laughing is a natural social response that is contagious (<xref rid="ref-66" ref-type="bibr">Rizzolatti et al., 1999</xref>): people laugh more if others in their environment are also laughing (<xref rid="ref-67" ref-type="bibr">Robinson &#x00026; Smith-Lovin, 2001</xref>). Touch can effectively intensify affective feelings and communication, even when it is mediated. For instance, mediated touch can enhance the affective quality of phone messages (<xref rid="ref-72" ref-type="bibr">Salminen et al., 2012</xref>) and remotely shared experiences (e.g., the hilariousness of a movie: <xref rid="ref-79" ref-type="bibr">Takahashi et al., 2011</xref>). A study on the added value of mediated touch enabled phone communication showed that couples are naturally inclined to use touch to express their amusement (<xref rid="ref-63" ref-type="bibr">Park, Baek &#x00026; Nam, 2013</xref>). Given that amusement can be communicated by touching hands (<xref rid="ref-42" ref-type="bibr">Hertenstein et al., 2009</xref>), and that touch is capable to enhance affective feelings, our second hypothesis is therefore:</p><p><bold>H2</bold>: Feedback via mediated hand touching enhances the experience of an amusing movie compared to visual feedback.</p></sec><sec><title>Increase of trust</title><p>In a supportive setting interpersonal touch tends to increase trust, even among strangers (<xref rid="ref-15" ref-type="bibr">Burgoon, Walther &#x00026; Baesler, 1992</xref>). It has been shown that mediated communication can also establish trust at a distance (<xref rid="ref-11" ref-type="bibr">Bos et al., 2002</xref>; <xref rid="ref-87" ref-type="bibr">Zheng et al., 2002</xref>). Although the effectiveness of mediated communication for establishing trust increases with media richness, trust is still highest when people can meet face-to-face (<xref rid="ref-11" ref-type="bibr">Bos et al., 2002</xref>; <xref rid="ref-87" ref-type="bibr">Zheng et al., 2002</xref>). This observation has simply been stated as &#x0201c;trust need touch&#x0201d; (<xref rid="ref-41" ref-type="bibr">Handy, 1995</xref>). The current study aims to investigate if mediated touch can also serve to establish trust. Our third hypothesis is therefore:</p><p><bold>H3:</bold> Feedback through mediated hand touching increases trust towards another person compared to abstract visual feedback.</p></sec><sec><title>Present study</title><p>To test the first two hypotheses (H1 and H2) participants first watched a sad movie clip to induce sadness, followed by a funny one to stimulate recovery from sadness. While watching the funny clip they signaled a hypothetical fellow participant (who was supposedly watching the same movies in an adjacent room) every time they were amused. These conditions were chosen since (1) people feel a fundamental need to share their feelings after watching a sad movie clip (<xref rid="ref-57" ref-type="bibr">Luminet et al., 2000</xref>), (2) they are inclined to use touch to express their amusement (<xref rid="ref-63" ref-type="bibr">Park, Baek &#x00026; Nam, 2013</xref>), (3) feelings of amusement can be communicated by touching hands (<xref rid="ref-42" ref-type="bibr">Hertenstein et al., 2009</xref>), and (4) mediated tactile stimulation may enhance the experience of an amusing movie (<xref rid="ref-79" ref-type="bibr">Takahashi et al., 2011</xref>). In the experimental condition the participants responded by pressing a hand-held mediated touch device, which also provided haptic feedback (from the ostensible fellow participant) via a simulated hand squeeze. In the control condition they communicated by pressing a button and they received abstract visual feedback. Thus, participants gave haptic response in both conditions, and received haptic feedback in the experimental condition and abstract visual feedback in the control condition. Objective (physiological measurements) and subjective (questionnaires) measures were obtained to verify the hypotheses H1 and H2. To test whether mediated hand touching increased trust (H3) the participants played a trust game with their ostensible fellow participant at the end of the experiment.</p></sec></sec><sec sec-type="methods"><title>Method</title><sec sec-type="subjects"><title>Participants</title><p>A total of <italic>N</italic> = 39 participants took part in this experiment. The data from two participants was excluded (one because of technical problems, and the other one was excluded because the participant provided no response during the experiment), resulting in a sample of <italic>N</italic> = 37. Of those, 23 were female and 14 were male, aged from 19 to 50 years (<italic>M</italic> = 30.16, <italic>SD</italic> = 10.49). The participants were recruited from the TNO database of volunteers and received 20 Euros for their participation. All participants gave their written consent. After the experiment the aim of the study was explained in a debriefing, with the exception that the participants were not informed that the feedback they had received during the experiment had been scripted and was not sent by a fellow participant. This was done to prevent them from passing this information on to future participants.</p><p>None of the participants had critical heart diseases or used antidepressants that could affect heart rate. Participants were randomly assigned to either the control or the experimental condition. 18 participants performed in the control condition and 19 in the experimental condition. <xref ref-type="table" rid="table-1">Table 1</xref> shows how the participants were distributed over the experimental conditions with respect to sex and age.</p><table-wrap id="table-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/table-1</object-id><label>Table 1</label><caption><title>Sample size (<italic>N</italic>), mean (<italic>M</italic>) and standard deviations (<italic>SD</italic>) for both conditions.</title></caption><alternatives><graphic xlink:href="peerj-03-1297-g008"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="6" rowspan="1">Age</th></tr><tr><th rowspan="1" colspan="1"/><th align="center" colspan="3" rowspan="1">Men</th><th align="center" colspan="3" rowspan="1">Women</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Control condition</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">29.57</td><td rowspan="1" colspan="1">11.55</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">28.00</td><td rowspan="1" colspan="1">10.46</td></tr><tr><td rowspan="1" colspan="1">Experimental condition</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">34.14</td><td rowspan="1" colspan="1">11.38</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">30.17</td><td rowspan="1" colspan="1">10.13</td></tr></tbody></table></alternatives></table-wrap></sec><sec><title>Experimental design</title><p>In a between-subjects design participants watched two emotional video clips while sharing their emotions in one of two ways with an ostensible fellow participant. In the experimental condition they signaled their own emotion by squeezing a mediated touch device, and they received haptic feedback about the feelings of their fellow participant in the form of hand squeezes presented via the same device. In the control condition they signaled their own emotions by squeezing the button on a joystick, and they received feedback in the form of an abstract visual cue.</p><p>Emotional video clips are known to effectively evoke and sustain affective experiences over longer time periods at both subjective and physiological levels (<xref rid="ref-18" ref-type="bibr">Carvalho et al., 2012</xref>). In this study the participants successively watched two emotional video clips: a sad one that served to elicit feelings of sadness followed by a funny one that was supposed to stimulate recovery from sadness. The participants were led to believe that they would be able to communicate with a fellow participant who would simultaneously be watching the same video clips in an adjacent room. In reality the feedback was scripted and no fellow participant was present. The two (control and experimental) conditions of this study differed only in the communication mode during the presentation of the second (funny) video clip (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>). In the control condition participants signaled which scenes they found funny by pressing a button on a joystick (haptic input), while visual feedback indicated whenever their ostensible fellow participant found a video segment funny. In the experimental condition participants held a mediated touch device in their hand which they could press (haptic input) to indicate which scenes they found funny. The same device squeezed their hand in return (haptic feedback) whenever their fellow participant supposedly found a video segment funny. Note that the haptic input modes in both conditions are equivalent since squeezing the joystick button required a similar action as squeezing the mediated touch device. The main difference between both conditions was the feedback mode, which was visual in the control condition and haptic in the experimental condition.</p><fig id="fig-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-2</object-id><label>Figure 2</label><caption><title>Control (A) and experimental (B) conditions with response and feedback channels.</title></caption><graphic xlink:href="peerj-03-1297-g002"/></fig></sec><sec><title>Apparatus and stimuli</title><sec><title>Video clips and presentation</title><p>The clip that served to elicit sadness was a scene (with a duration of 686 s) from the &#x02018;The Champ&#x02019; (<xref rid="ref-55" ref-type="bibr">Lovell &#x00026; Zeffirelli, 1979</xref>) showing a boy who cries after his father&#x02019;s death. Several previous studies have shown that this scene successfully elicits feelings of sadness (<xref rid="ref-26" ref-type="bibr">Ellard, Farchione &#x00026; Barlow, 2012</xref>; <xref rid="ref-33" ref-type="bibr">Goldberg, Preminger &#x00026; Malach, 2014</xref>; <xref rid="ref-34" ref-type="bibr">Gross &#x00026; Levenson, 1995</xref>; <xref rid="ref-68" ref-type="bibr">Rottenberg, Ray &#x00026; Gross, 2007</xref>). The funny video (with a total duration of 595 s) was a compilation of 35 different scenes from funny home movies (<uri xlink:href="http://www.youtube.com">www.youtube.com</uri>) showing hilarious scenes with animals and young children. In a pilot study this compilation was indeed rated on a 10-point semantic differential Likert Scale (1 = <italic>not funny at all</italic> ; 10 = <italic>very funny</italic>) as being funny (<italic>M</italic> = 7.86; <italic>SD</italic> = 1.45; <italic>N</italic> = 8). The video clips used in this study had a resolution of 1,920 &#x000d7; 1,080 pixels. A PC equipped with a Sanyo PLC-WL2500A beamer (<uri xlink:href="http://www.panasonic.com">www.panasonic.com</uri>) projected the video onto an area of 190 &#x000d7; 107 cm<sup>2</sup> of the wall-mounted projection screen. Custom-made software was used both to present the scripted feedback and to play the movies. In the control condition a grey square (60 &#x000d7; 60 pixels) in the middle of the right hand side of the screen turned blue to signal which scenes which the ostensible fellow participant found funny (visual feedback). The entire video presentation (including the instructions that appeared between the two video clips) lasted 21 min and 51 s.</p></sec><sec><title>Joystick</title><p>In the control condition participants squeezed the rapid-fire trigger of a Logitech Extreme 3D Pro joystick (<uri xlink:href="http://www.logitech.com">www.logitech.com</uri>) to signal to their fellow participant which video segments they found amusing.</p></sec><sec><title>Frebble</title><p>In the experimental condition participants used a Frebble (Holland Haptics, Delft, The Netherlands; <uri xlink:href="http://myfrebble.com">http://myfrebble.com</uri>) to communicate with their ostensible fellow participant. A Frebble is an ergonomically designed haptic device (<xref ref-type="fig" rid="fig-1">Fig. 1</xref>, see also <xref rid="ref-80" ref-type="bibr">Toet et al., 2013</xref>) that comfortably fits in (and encloses the back of) the hand and simulates both the touch of holding and squeezing another person&#x02019;s hand&#x02014;and having that feeling reciprocated (see also <uri xlink:href="http://vimeo.com/86103101">http://vimeo.com/86103101</uri>). Frebbles can communicate with one another via internet or Bluetooth. When a Frebble is squeezed, the corresponding gadget gently applies pressure to the back of a partner&#x02019;s hand, to simulate the feeling of holding hands. Two pressure sensors at the front of the device register squeezing while two vibration motors and a &#x02018;squeeze bar&#x02019; provide the sensation of squeezing back. The bar is like a little lever that extends against the back of the hand. Frebbles are designed to enable mediated affective touch between physically separated partners. Users can communicate and receive haptic signals simultaneously. The pair of Frebbles used in this study consisted of one slave and one master, identical in size (12 cm high with a scope of 17 cm at the bottom and 11 cm at the top of the extension) and shape. Both Frebbles communicated with each other via Bluetooth. The pressure of the haptic signals provided by a Frebbble can vary from soft to hard. In this study the master Frebble was connected to the computer of the experimenter (via a USB connection) and sent scripted feedback to the slave Frebble (which was held by the participant) using a fixed pressure intensity, which resulted in a firm but comfortable squeeze (as established in a pilot test). Participants squeezed the Frebble to signal which video segments they found amusing, and the Frebble squeezed their hand in return whenever their fellow participant was supposedly amused.</p></sec><sec><title>Scripted feedback</title><p>The scripted feedback for both conditions was determined from a pilot study in which 6 participants watched the funny video clip. Three participants used a joystick and three others used a Frebble to signal their response. They were instructed to press the button of the joystick or Frebble every time they were amused by the video clip. It was their own choice how often, for how long, and how firm they applied the pressure. The average of all participants&#x02019; responses (duration and pressure level) was calculated and used as scripted feedback for the experiment. Although the fine nuances of the touch were lost by using a constant (average) pressure level, it makes the Frebble condition more comparable to the joystick condition (both are on or off at the same moments during the video clip). The scripted feedback was tested with two other participants to ensure that it was perceived as realistic and only occurred during video segments that could indeed be classified as amusing. The final feedback, which was used for the experiment, consisted of 57 presses with a total length of 191 s. The shortest response took 1 s and the longest 15 s.</p><p>During the experiment the same binary feedback track was used in both (visual and haptic feedback) conditions. In the control condition it resulted in visual feedback and in the experimental condition it led to a haptic (Frebble) feedback.</p></sec><sec><title>Physiological measurements</title><p>Seven Ag&#x02013;AgCL Flat electrodes were used to measure heart rate (HR) and skin conductance level (SCL). For the ground and reference measurement one electrode was placed on the neck of the participant and one behind each ear. The electrodes for the ECG signal were placed one at the right collarbone and one at the left floating rib. Two electrodes for the GSR signal were placed on the palm of the non-dominant hand of the participant (the hand not used to respond in the experiment), one right below the forefinger and the other one in the middle of the hand palm. The physiological signals were recorded with a computer using ActiView BioSemi software (<uri xlink:href="http://www.biosemi.com">www.biosemi.com</uri>) at a sampling rate of 512 Hz. The ECG signal was filtered using a 0.5&#x02013;100 Hz bandpass filter, and afterwards by a 2.5 Hz high-pass 2-sided Butterworth filter. The GSC signal was filtered by a 30 Hz low-pass 2-sided Butterworth filter.</p></sec><sec><title>Set-up conditions</title><p>The experiments were performed in a small, well-ventilated, and sound-proof windowless room. The lights were dimmed during the video presentation. The participants were seated comfortably on a coach facing a wall mounted projection screen from a mean distance of 3.20 m. To enable later analysis of their facial expressions participants were recorded on video during the experiment using a Panasonic WV-BP330/GE camera (<uri xlink:href="http://www.panasonic.com">www.panasonic.com</uri>) in combination with an infrared light source.</p></sec></sec><sec><title>Measures</title><sec><title>Objective measures</title><p>Heart rate and skin conductance level were used to quantify a participant&#x02019;s physical reactions to the video clips (<xref rid="ref-22" ref-type="bibr">Davydov, Zech &#x00026; Luminet, 2011</xref>; <xref rid="ref-51" ref-type="bibr">Kreibig, 2010</xref>). Both heart rate (<xref rid="ref-58" ref-type="bibr">Mandryk, Inkpen &#x00026; Calvert, 2006</xref>) and skin conductance level (<xref rid="ref-53" ref-type="bibr">Lang, 1995</xref>) are known to reflect emotional activity (<xref rid="ref-13" ref-type="bibr">Brouwer et al., 2013</xref>). Sad film clips typically evoke a decreased skin conductance level and a decreased heart rate (i.e., when participants do not cry in response to watching the film: <xref rid="ref-51" ref-type="bibr">Kreibig, 2010</xref>). In contrast, amusing film clips typically evoke an increase in skin conductance level, often accompanied by an increase in heart rate (although the heart rate response is not unequivocal: <xref rid="ref-51" ref-type="bibr">Kreibig, 2010</xref>). The physiological data were processed and analyzed in Matlab 8.0 (<uri xlink:href="http://www.mathworks.com">www.mathworks.com</uri>). The mean value of a participant&#x02019;s heart rate and skin conductance level were computed over the following three time intervals (later referred to as the <italic>time of measurement</italic>): (1) the preparation period before watching the movie clips (this served as a personal baseline), (2) the last four minutes of &#x02018;The Champ&#x02019; (just after the father&#x02019;s death, which is the saddest part of the movie) and (3) the first 90 s of the funny video clip (the period during which recovery effects are most likely to occur).</p><p>In a previous study on empathic touch by relational agents <xref rid="ref-10" ref-type="bibr">Bickmore et al. (2010)</xref> observed that the number of hand squeezes and squeeze duration were associated with affect valence when mediated touch was used as the only feedback mode. In the present study we therefore adopted the number and duration of Frebble responses and the total duration of smiling (estimated from the analysis of the video recordings of a participant&#x02019;s facial expressions) during the presentation of the funny video clip as additional objective measures of the participant&#x02019;s affective response to the clip.</p><p>The duration of a participant&#x02019;s smile while watching the funny video clip was measured from the video recording of the participant&#x02019;s facial expressions using The Observer XT 11.5 software tool (<uri xlink:href="http://www.noldus.com">www.noldus.com</uri>). Therefore the experimenter watched the video recording of each participant and judged once per second whether the participant was smiling or not. A smile was recognized according to the definition of a Duchenne smile (<xref rid="ref-77" ref-type="bibr">Soussignan, 2002</xref>). To assess the reliability of this annotation method two additional observers also annotated five randomly selected videos and their inter-rater reliability (Person&#x02019;s <italic>r</italic>) with the experimenter was calculated. The inter-rater reliability between the observers and the experimenter was high: <italic>r</italic> = .89 for both observers.</p><p>The amount of money set in during the trust game was used as an objective measurement of trust towards the fellow participant.</p></sec><sec><title>Subjective measures</title><p>During the experiment each participant filled out three questionnaires: the first one at the start of the experiment (70 questions and statements), the second one after watching the movie clips (32 questions and statements) and the third one at the end of the experiment when the experimenter pretended to play a trust game with the fellow participant (16 questions and statements).</p></sec></sec><sec><title>Questionnaire 1</title><p>The first questionnaire contained demographic questions about gender, age, heart or other diseases, and use of medicines. To explain possible outliers in the physiological data the participants were also asked how much time had passed since they smoked, drank coffee or alcohol, or had any physical exercise before the experiment. Also, questions were asked about their current mood, personality and touch receptivity. These questions served to check whether the groups of participants in both experimental conditions were comparable in terms of current mood, personality and touch receptivity.</p><p>The <italic>current mood</italic> of the participants was measured with the &#x02018;Brief Mood Introspection Scale&#x02019; (BMIS: <xref rid="ref-59" ref-type="bibr">Mayer &#x00026; Gaschke, 1988</xref>) which consisted of 16 adjectives (such as <italic>lively</italic>, <italic>happy</italic>, <italic>sad</italic> and <italic>tired</italic>) that could be rated on a 4-point Likert Scale (1 = <italic>definitely do not feel</italic>; 4 = <italic>definitely feel</italic>). The reliability (Cronbach&#x02019;s alpha) of the BMIS for the sample in this study was <italic>&#x003b1;</italic> = .82. The &#x02018;Self-Assessment Manikin&#x02019; (SAM: <xref rid="ref-12" ref-type="bibr">Bradley &#x00026; Lang, 1994</xref>) was also used to assess the current mood. The SAM is a nine-point pictorial rating scale that measures pleasure, arousal and dominance. The SAM provides a simple, fast, and non-linguistic way of assessing a person&#x02019;s mental state along the principal emotional dimensions and is highly suitable to measure transient (short term) emotional states. The reliability for this scale was <italic>&#x003b1;</italic> = .63.</p><p>Three personality traits (<italic>Extraversion</italic>, <italic>Openness</italic> and <italic>Agreeableness</italic>) were measured with the Dutch version (<xref rid="ref-84" ref-type="bibr">Van Heck et al., 1994</xref>) of the original &#x02018;Big 5&#x02019; questionnaire (<xref rid="ref-32" ref-type="bibr">Goldberg, 1992</xref>). For each personality trait 10 statements had to be answered on a 5-point Likert Scale (1 = <italic>strongly disagree</italic>; 5 = <italic>strongly agree</italic>). An example question for measuring Extraversion was: &#x0201c;<italic>I feel comfortable around people</italic>&#x0201d;. The reliabilities were <italic>&#x003b1;</italic> = .88 for <italic>Extraversion</italic>, <italic>&#x003b1;</italic> = .85 for <italic>Openness</italic> and <italic>&#x003b1;</italic> = .56 for <italic>Agreeableness</italic>.</p><p>Eight items from the Touch Receptivity Questionnaire (the same items used by <xref rid="ref-10" ref-type="bibr">Bickmore et al., 2010</xref>, for example: &#x0201c;<italic>I like people who shake hands with me.</italic>&#x0201d;) were used to measure how comfortable participants were with being touched by someone else. The eight items were translated into Dutch and were answered on a 7-point Likert Scale (1 = <italic>disagree completely</italic>, 7 = <italic>agree completely</italic>). They had a reliability of <italic>&#x003b1;</italic> = .76.</p></sec><sec><title>Questionnaire 2</title><p>After watching both movie clips the participants were asked to fill out a second questionnaire to measure their affective experience. In addition to questions about the movie itself this questionnaire also presented the BMIS and SAM again (for the second time). This was done to identify possible changes in mood after watching the movie clips.</p><p>Participants were asked to indicate how entertaining they found the funny movie clip on a 10-point semantic differential Likert Scale (1 = <italic>not funny at all</italic> ; 10 = <italic>very funny</italic>). In addition they were asked to rate their overall feeling while watching the funny clip by rating 10 adjectives (<italic>interested</italic>, <italic>joyful, sad, angry, fearful, terrified, contempt, disgusted, surprised, happy</italic>) on a 6-point Likert Scale (1 = <italic>not at all</italic>; 6 = <italic>very intense</italic>; e.g., <xref rid="ref-22" ref-type="bibr">Davydov, Zech &#x00026; Luminet, 2011</xref>; <xref rid="ref-73" ref-type="bibr">Schaefer et al., 2003</xref>). The reliability of these items was <italic>&#x003b1;</italic> = .91. Together these questionnaires provided an impression of the overall affective experience of the funny movie clip.</p><p>Participants were also asked whether they had ever seen the first movie clip (&#x02018;The Champ&#x02019;) before and rated on a 10 point scale how sad they experienced it (1 = <italic>not at all</italic>, 10 = <italic>very intense</italic>).</p></sec><sec><title>Questionnaire 3</title><p>A third questionnaire served measured the participant&#x02019;s impression of the (ostensible) fellow participant.</p><p>Affective trust is the confidence one places in a partner on the basis of feelings generated by the level of care and concern the partner demonstrates (<xref rid="ref-46" ref-type="bibr">Johnson &#x00026; Grayson, 2005</xref>). In this study affective trust towards the fellow participant was measured with one item (&#x0201c;<italic>I felt that the other person understood me.</italic>&#x0201d; ) that was rated on a 7-point Likert Scale (1 = <italic>completely disagree</italic>; 7 = <italic>completely agree</italic>).</p><p>A single item (&#x0201c;<italic>I felt that the other person had the same humor.</italic>&#x0201d;) rated on a 7-point Likert Scale (1 = <italic>completely disagree</italic>; 7 = <italic>completely agree</italic>) measured whether the participant thought that the fellow participant appreciated the same kind of humor.</p><p>Attachment was measured with an adapted version of a questionnaire that was originally developed to measure consumer-product attachment (<xref rid="ref-74" ref-type="bibr">Schifferstein &#x00026; Zwartkruis-Pelgrim, 2008</xref>). This questionnaire contained five items (&#x0201c;<italic>I felt emotionally connected with my fellow participant.</italic>&#x0201d;, &#x0201c;<italic>The fellow participant was dear to me</italic>&#x0201d;., &#x0201c;<italic>I had a bond with my fellow participant</italic>.&#x0201d;, &#x0201c;<italic>The fellow participant had no</italic>special<italic>meaning for me</italic>.&#x0201d;, &#x0201c;<italic>I had no feelings for my fellow participant</italic>.&#x0201d;) that could be rated on a 7-point Likert Scale (1 = <italic>completely disagree</italic>, 7 = <italic>completely agree</italic>). This questionnaire had a reliability of <italic>&#x003b1;</italic> = .89.</p><p>Perceived trustworthiness of the fellow participant was measured on the dimensions trust, immediacy, reliability, and credibility (<xref rid="ref-69" ref-type="bibr">Rubin et al., 2009</xref>) using eight 7-Point bipolar semantic differential Likert scales (<italic>cold&#x02013;warm, familiar&#x02013;unfamiliar, friendly-unfriendly, distant&#x02013;close, kind&#x02013;cruel, active&#x02013;passive, reliable&#x02013;unreliable, direct&#x02013;indirect</italic>). The reliability of this questionnaire was <italic>&#x003b1;</italic> = .73.</p><p>The &#x02018;Inclusion of Other in the Self&#x02019; Scale (IOS: <xref rid="ref-5" ref-type="bibr">Aron, Aron &#x00026; Smollan, 1992</xref>) is a single-item, pictorial measurement of closeness between two persons. It shows seven pairs of circles (one circle representing the Self and the other one representing the partner) with different degrees of overlap representing different degrees of interpersonal interconnectedness. The degree of overlap between the circles increases linearly from non-overlapping (1; representing <italic>no interpersonal connection</italic>) to almost completely overlapping (7; representing <italic>a strong interpersonal connection</italic>). The participants were asked to mark the picture which best described the relationship they experienced to their fellow participant.</p></sec><sec><title>Trust game</title><p>To test whether mediated hand touching can increase trust towards another person (H3) the participants were invited to play a trust game with their ostensible fellow participant at the end of the experiment. After watching both movies and filling out the second questionnaire the experimenter thanked the participants and handed them their show-up fee. At that time the experimenter informed the participants that they were given a chance to increase their fee by participating in a game. The participants were free to decide whether or not to participate in the game and how much of their fee they would send to their fellow participant. They were told that their fellow participant would receive twice the amount of money they sent and that he/she could decide whether to keep the money or to return a certain amount to the sender. In this game, sending money to the other player is risky but can also lead to an expanded profit, if returned by the other player. The amount of money that the sender decides to transfer to the recipient can be seen as a (behavioral) measure of the sender&#x02019;s trust towards the other person. This so called &#x02018;trust game&#x02019; is a well-established method to measure the degree of trust between persons (<xref rid="ref-9" ref-type="bibr">Berg, Dickhaut &#x00026; McCabe, 1995</xref>; <xref rid="ref-31" ref-type="bibr">Glaeser et al., 2000</xref>; <xref rid="ref-54" ref-type="bibr">Lazzarini et al., 2004</xref>). In the current study there was actually no second player involved, and the experimenter returned all participants the same amount they gave away.</p></sec><sec><title>Statistical analysis</title><p>The statistical data analysis was done with IBM SPSS 20.0 (<uri xlink:href="http://www.ibm.com">www.ibm.com</uri>). The dependent variables of this study were: the physiological measurement of heart rate and skin conductance level, the variables of the questionnaires, the Frebble and joystick response behavior (number and duration of responses) while watching the funny movie clips, the amount of money set in at the trust game, and the facial expression data (smile duration). Independent sample <italic>t</italic>-tests and mixed design analyses of variance (ANOVAs) were conducted for the normally distributed dependent variables. A Wilcoxon&#x02013;Mann&#x02013;Whitney test was conducted for the dependent variables of Frebble press behavior (duration and number of response) and the smile duration, because these data were not normally distributed. Three participants incorrectly used the &#x0201c;<italic>movie rating</italic>&#x0201d; answer categories. It was therefore decided to exclude their answers from the analysis of the dependent variable &#x02018;<italic>movie rating adjectives&#x02019;</italic>. All analyses of the physiological measurements were done both with difference scores (difference between the individual baseline and the measured value during the movie clips) as well as with mean scores (mean value of all participants measured during the movie clips). Because both analyses showed no difference in outcomes only the mean values of heart rate and skin conductance level are reported this study.</p></sec><sec><title>Procedure</title><p>The timeline of the experimental procedure is shown in <xref ref-type="fig" rid="fig-3">Fig. 3</xref>. After having been picked up and greeted in the entrance hall by the experimenter the participant was guided to the test room, sat down on a sofa, and read and signed an informed consent form. The participant was then told that the experimenter had to return to the entrance hall to pick up a second participant, who was intentionally invited 5 min later to prevent both participants from meeting each other. The participant was informed that it was necessary to avoid a physical encounter with the other participant since a first impression of the other participant based on factors like gender and attractiveness might influence the outcome of the study. The experimenter asked the participant to fill out the first questionnaire in the meantime and to wait until she would return. In fact the experimenter waited outside the test room and returned 15 min later when the participant had finished the questionnaire. This procedure served to enhance the illusion that there was indeed a fellow participant present in a room next to the test room. The experimenter explained that the purpose of the study was to investigate people&#x02019;s emotions while watching emotional video clips. Therefore the participant would watch two video clips that were also simultaneously being watched by the fellow participant in the adjacent room. The participant was asked to simply watch the first video clip, and to signal the fellow participant in the other room whenever an amusing episode occurred in the second video clip by pressing the Frebble (experimental condition) or by pressing the button of the joystick (control condition). The participant was told that the fellow participant would do the same. The feedback of the fellow participant was either in the form of a simulated hand press via the feedback mechanisms of the Frebble (experimental condition&#x02014;haptic feedback) or shown on the projection screen in the form of a grey square that turned blue whenever the fellow participant signaled the occurrence of an amusing episode (control condition&#x02014;visual feedback). In the experimental condition the participants were led to believe that their fellow participant also held a Frebble device and would experience their responses as hand squeezes. In the control condition they were told that their fellow participant would see their response as a color change of a square shown on the projection screen. The way to use the Frebble or the joystick to send information and the meaning of the feedback (either presented via the Frebble or via the colored square) were explained and the participant was given the opportunity to experience it and to ask questions. If there were no further questions the electrodes to measure heart rate and skin conductance level were attached to the participant. Then the participant was asked to sit calmly for a few minutes before the video clips would start. The participant was informed that this was necessary because the experimenter also needed to explain the experiment to the other participant. The participant was left alone and the video clips would start automatically after eight minutes. The sound of the video clips was played through headphones to exclude any noise from the Frebble&#x02019;s actuators. After the first video clip (&#x02018;The Champ&#x02019;) a text appeared on the screen instructing the participant to use the joystick or Frebble to communicate with the fellow participant during the presentation of the second video clip. After the second video clip the participant filled out a second questionnaire. After a short waiting period the experimenter returned in the room, removed the sensors from the participant&#x02019;s body, placed the participant&#x02019;s fee on the table (20 coins of 1 Euro) and asked if the participant would like to play a game with the fellow participant. The experimenter explained the game and then played the first round with the participant. Next she pretended to play the second round with the fellow participant in the adjacent room. While the experimenter was outside the room pretending to play the game with the fellow participant, the participant completed the last (third) questionnaire. The experimenter returned after a few minutes with the same amount of Euros the participant had previously sent to the fellow participant. All of the 37 participants agreed to play the game. The total duration of the experiment was about 60 min for each participant. The experimental protocol was reviewed and approved by the TNO internal review board on experiments with human participants (TNO Soesterberg, The Netherlands), and was in accordance with the Helsinki Declaration of 1975, as revised in 2000 (<xref rid="ref-86" ref-type="bibr">World Medical Association, 2000</xref>).</p><fig id="fig-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-3</object-id><label>Figure 3</label><caption><title>Timeline of the experimental procedure.</title></caption><graphic xlink:href="peerj-03-1297-g003"/></fig></sec></sec><sec sec-type="results"><title>Results</title><p>An independent <italic>t</italic>-test on the scores on the Touch Receptivity Questionnaire, the BMIS, the three dimensions of the SAM (pleasure, arousal and dominance) and the three personality traits of the BIG 5 (<italic>Extraversion</italic>, <italic>Openness</italic> and <italic>Agreeableness</italic>) from Questionnaire 1 showed no significant differences between both experimental groups (all <italic>p</italic>-values &#x0003e;.05; see <xref ref-type="table" rid="table-2">Table 2</xref>). Hence, both groups are indeed equivalent, which makes any differences between their responses to Questionnaires 2 and 3 most likely the result of the different experimental conditions.</p><table-wrap id="table-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/table-2</object-id><label>Table 2</label><caption><title>Sample size (<italic>N</italic>), means (<italic>M</italic>), standard deviations (<italic>SD</italic>) for the joystick and Frebble condition.</title><p>Also shown are the <italic>p</italic>-values of the independent samples <italic>t</italic>-test for each variable between both conditions.</p></caption><alternatives><graphic xlink:href="peerj-03-1297-g009"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="3" rowspan="1">Joystick</th><th align="center" colspan="3" rowspan="1">Frebble</th><th rowspan="1" colspan="1"><italic>t</italic>-test</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th><th rowspan="1" colspan="1">
<italic>p</italic>
</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Brief Mood Introspection Scale (BMIS)</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.14</td><td rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.13</td><td rowspan="1" colspan="1">0.35</td><td rowspan="1" colspan="1">.915</td></tr><tr><td rowspan="1" colspan="1">Self-Assessment Manikin (SAM)&#x02014;pleasure</td><td rowspan="1" colspan="1">17</td><td rowspan="1" colspan="1">6.94</td><td rowspan="1" colspan="1">0.75</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">6.68</td><td rowspan="1" colspan="1">1.34</td><td rowspan="1" colspan="1">.476</td></tr><tr><td rowspan="1" colspan="1">Self-Assessment Manikin (SAM)&#x02014;arousal</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.50</td><td rowspan="1" colspan="1">1.76</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">2.58</td><td rowspan="1" colspan="1">1.54</td><td rowspan="1" colspan="1">.098</td></tr><tr><td rowspan="1" colspan="1">Self-Assessment Manikin (SAM)&#x02014;dominance</td><td rowspan="1" colspan="1">17</td><td rowspan="1" colspan="1">4.94</td><td rowspan="1" colspan="1">0.83</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">5.42</td><td rowspan="1" colspan="1">1.84</td><td rowspan="1" colspan="1">.313</td></tr><tr><td rowspan="1" colspan="1">BIG 5&#x02014;extraversion</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.17</td><td rowspan="1" colspan="1">0.68</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.56</td><td rowspan="1" colspan="1">0.63</td><td rowspan="1" colspan="1">.078</td></tr><tr><td rowspan="1" colspan="1">BIG 5&#x02014;openness</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.49</td><td rowspan="1" colspan="1">0.56</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.61</td><td rowspan="1" colspan="1">0.61</td><td rowspan="1" colspan="1">.567</td></tr><tr><td rowspan="1" colspan="1">BIG 5&#x02014;agreeableness</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.47</td><td rowspan="1" colspan="1">0.46</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.48</td><td rowspan="1" colspan="1">0.31</td><td rowspan="1" colspan="1">.958</td></tr><tr><td rowspan="1" colspan="1">Touch receptivity</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">4.76</td><td rowspan="1" colspan="1">1.01</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">4.57</td><td rowspan="1" colspan="1">0.95</td><td rowspan="1" colspan="1">.565</td></tr></tbody></table></alternatives></table-wrap><sec><title>Emotion elicitation</title><p>A prerequisite for testing the three hypotheses was that the video clip from &#x02018;The Champ&#x02019; would elicit sad emotions whereas the funny video clips would cheer people up. Objective and subjective measurements were therefore analyzed to investigate if these manipulations had been successful.</p></sec><sec><title>Objective measurements</title><p>The mean value of a participant&#x02019;s heart rate and skin conductance level were computed over the following three time intervals: (1) the preparation period before watching the movie clips (this served as a personal baseline), (2) the last four minutes of &#x02018;The Champ&#x02019; (the part after the father&#x02019;s death) and (3) the first 90 s of the funny video clip. <xref ref-type="fig" rid="fig-4">Figure 4</xref> shows the mean values of these measures over all participants. On first inspection the ranking of the mean heart rate and mean skin conductance levels during the three time intervals appears to agree with our expectations: the mean levels of these parameters during the sad and funny movie periods were respectively lower and higher than their corresponding values during the baseline period.</p><fig id="fig-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-4</object-id><label>Figure 4</label><caption><title>Mean (over all participants) heart rate (A) and galvanic skin conductance (B) at different times of measurement.</title><p>Measurements were obtained before seeing the videos (baseline), during the last part of the &#x02018;The Champ&#x02019;, and during the funny video clip. The error bars represent confidence intervals, while &#x02217; indicates that Bonferroni post-hoc comparison was significant (<italic>p</italic> &#x0003c; 0.05).</p></caption><graphic xlink:href="peerj-03-1297-g004"/></fig><p>A repeated measures ANOVA was conducted to investigate whether the mean heart rate differed significantly between the three times of measurement. The results showed that the heart rate was indeed significantly affected by the time of measurement, <italic>F</italic>(2, 72) = 4.58, <italic>p</italic> = .013, <italic>&#x003b7;</italic><sup>4</sup> = .113. A Bonferroni post-hoc comparison of the three intervals indicated that the heart rate during the last minutes of &#x02018;The Champ&#x02019; (<italic>M</italic> = 68.20, 95% CI [65.77&#x02013;70.63]) was significantly lower than during the first 90 s of the funny video clips (<italic>M</italic> = 69.92, 95% CI [67.08&#x02013;72.75]), <italic>p</italic> = .020. The baseline (<italic>M</italic> = 69.03, 95% CI [66.41&#x02013;71.64]) did not differ significantly from &#x02018;The Champ&#x02019; (<italic>p</italic> = .30) and the funny video clips (<italic>p</italic> = .46).</p><p>A repeated measures ANOVA between the three times of measurement was also conducted for the mean skin conductance level. The analysis showed that the mean skin conductance level was significantly affected by the time of measurement, <italic>F</italic>(2, 72) = 13.73, <italic>p</italic> &#x0003c; .001, <italic>&#x003b7;</italic><sup>2</sup> = .276. A Bonferroni post-hoc comparison indicated that the skin conductance level was significantly lower during the baseline period (<italic>M</italic> = 5.88, 95% CI [5.05&#x02013;6.71]) than during the presentation of the funny video clip (<italic>M</italic> = 7.09, 95% CI [6.27&#x02013;7.91]), <italic>p</italic> = .001. The skin conductance level during the last four minutes of &#x02018;The Champ&#x0201d; (<italic>M</italic> = 5.77, 95% CI [4.84&#x02013;6.70]) was also significantly lower than the skin conductance level during the funny video clip, <italic>p</italic> &#x0003c; .001. There was no significant difference between the skin conductance level during the baseline period and during &#x02018;The Champ&#x02019; (<italic>p</italic> = 1.00).</p></sec><sec><title>Subjective measurements</title><p>&#x02018;The Champ&#x02019; scored on average 7.09 (<italic>SD</italic> = 1.79) on a scale from 0 (<italic>not sad at all</italic>) up to 10 (<italic>very sad</italic>) on the self-reporting questionnaire. The funny video clip scored on average 6.84 (<italic>SD</italic> = 1.42) on a scale from 0 (<italic>not funny at all</italic>) to 10 (<italic>very funny</italic>). In addition, in response to the 10 questions about their feelings while watching the funny movie clips it appears that participants on average felt quite positive: <italic>M</italic> = 5.03 (<italic>SD</italic> = 0.57) on a 6 point Likert scale.</p></sec><sec><title>Conclusion</title><p>The subjective measurements indicated that both movies served their purpose: &#x02018;The Champ&#x02019; indeed elicited sad emotions while the funny video clip appeared to evoke more positive feelings. Although the ranking of the objective measurements (mean heart rate and mean skin conductance levels) agrees with the subjective measurements, this conclusion was only confirmed for the funny video clip (both heart rate and skin conduction level were significantly higher than the baseline value during the first 90 s of the funny movie), but not for the sad video clip (both heart rate and skin conduction level while watching &#x02018;The Champ&#x02019; were not significantly different from the baseline value).</p></sec><sec><title>Hypothesis I: Recovery from a sad experience</title><p>To test whether mediated touch communication enhances recovery from movie induced sadness to a larger extent than visual feedback (H1) the physiological measurements (heart rate and skin conductance level) in the control and Frebble conditions were compared between &#x02018;The Champ&#x02019; (last four minutes after the father&#x02019;s death) and the recovery period during the funny video clip (the first 90 s) using a mixed-model ANOVA.</p><sec><title>Heart rate</title><p>A mixed-model ANOVA revealed that there was a main effect of <italic>time of measurement</italic> between &#x02018;The Champ&#x02019; and the funny video clip, <italic>F</italic>(1, 35) = 21.093, <italic>p</italic> &#x0003c; .001, <italic>&#x003b7;</italic><sup>2</sup> = .376 (<xref ref-type="fig" rid="fig-5">Fig. 5A</xref>). However there was no significant main effect of <italic>condition</italic>, <italic>F</italic>(1, 35) = 0.172, <italic>p</italic> = .680, <italic>&#x003b7;</italic><sup>2</sup> = .122, and no interaction effect between time <italic>of measurement</italic> and <italic>condition</italic>, <italic>F</italic>(1, 35) = 0.332, <italic>p</italic> = .568, <italic>&#x003b7;</italic><sup>2</sup> = .014. This indicates that the participants&#x02019; heart rate did not differ significantly between the control and Frebble conditions over the period defined by the presentation of &#x02018;The Champ&#x02019; and the first 90 s of the funny video clip.</p><fig id="fig-5" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-5</object-id><label>Figure 5</label><caption><title>Mean heart rate (A) and mean galvanic skin conductance (B).</title><p>Measurements were obtained during &#x02018;The Champ&#x02019; and at the beginning of the funny movie clips in respectively the joystick and Frebble conditions.</p></caption><graphic xlink:href="peerj-03-1297-g005"/></fig></sec><sec><title>Skin conductance</title><p>A mixed-model ANOVA again revealed that there was a main effect of <italic>time of measurement</italic> between &#x02018;The Champ&#x02019; and the funny movie clips, <italic>F</italic>(1, 35) = 329.62, <italic>p</italic> &#x0003c; .001, <italic>&#x003b7;</italic><sup>2</sup> = .904 (<xref ref-type="fig" rid="fig-5">Fig. 5B</xref>). However, there was no significant main effect of <italic>condition</italic>, <italic>F</italic>(1, 35) = 0.62, <italic>p</italic> = .434, , <italic>&#x003b7;</italic><sup>2</sup> = .072. and no interaction effect between <italic>time of measurement</italic> and <italic>condition</italic>, <italic>F</italic>(1, 35) = 0.627, <italic>p</italic> = .434, <italic>&#x003b7;</italic><sup>2</sup> = .015. This also indicates that there was no significant difference between the joystick and Frebble condition during both time intervals.</p></sec><sec><title>Conclusion</title><p>The variation in mean heart rate and mean skin conductance level over both measurement intervals (the last four minutes of &#x02018;The Champ&#x02019; and the first 90 s of the funny video clip) indicates that the participants did indeed recover from the sad movie over the associated time period. However, mean heart rate or mean skin conductance level did not differ significantly between both conditions over these measurement intervals. Hence, feedback via mediated hand touching did not enhance the recovery from movie induced sadness to a larger extent than visual feedback (H1). Hypothesis 1 was therefore not confirmed.</p></sec></sec><sec><title>Hypothesis 2: Intensified affective experience</title><p>To test whether feedback via mediated hand touching enhances the experience of an amusing movie relative to visual feedback (H2) we compared the objective (press and smiling behavior) and subjective (questions about the affective experience in Questionnaire 2) measurements in the control and Frebble conditions.</p><sec><title>Objective measurements</title><p>The objective measurements of the press behavior (duration and number of responses) and the time the participants were smiling were not completely normally distributed. Therefore, a non-parametric Kolmogorov&#x02013;Smirnov test with ranked scores and a Wilcoxon&#x02013;Mann&#x02013;Whitney test were used to analyze these three dependent variables. Because the results were almost identical only the results of the Wilcoxon&#x02013;Mann&#x02013;Whitney test will be reported.</p><p>The time during which the joystick was pressed while watching the funny video clip (<italic>Press duration</italic>) in the control condition (<italic>Mdn</italic> = 59.56) did not differ significantly from the time during which the Frebble was pressed in the experimental condition (<italic>Mdn</italic> = 86.61), <italic>U</italic> = 227.00, <italic>z</italic> = &#x02212; 1.702, <italic>p</italic> =.092, ns. Also, the number of presses in the control condition (<italic>Mdn</italic> = 49.00) did not differ from the number in the Frebble condition (<italic>Mdn</italic> = 52.00), <italic>U</italic> = 151.50, <italic>z</italic> = &#x02212; 0.593, <italic>p</italic> = .563, ns. The annotation of the facial expression indicated that the time the participants were smiling while watching the funny video clip also did not differ significantly between both conditions (joystick: <italic>Mdn</italic> = 166.00; Frebble: <italic>Mdn</italic> = 225.00), <italic>U</italic> = 138.50, <italic>z</italic> = &#x02212; 0.988, <italic>p</italic> = .331 ns.</p><p><italic>Press duration</italic> correlated significantly with: <italic>Openness</italic> (<italic>r</italic> = .34, <italic>p</italic> &#x0003c; .05), the amount of money set in the trust game (<italic>r</italic> =.35, <italic>p</italic> &#x0003c; .05), and with affective trust towards the fellow participant (&#x0201c;<italic>I felt that the other person understood me</italic>&#x0201d;: <italic>r</italic> =.43, <italic>p</italic> &#x0003c; .01). <italic>Number of presses</italic> is significantly correlated with the amusement rating of the funny movie clip (<italic>r</italic> =.43, <italic>p</italic> &#x0003c; .01), the score on the second BMIS (after watching the funny movie: <italic>r</italic> = .35, <italic>p</italic> &#x0003c; .05), the <italic>Pleasure</italic> score on the SAM (<italic>r</italic> = .42, <italic>p</italic> &#x0003c; .01), affective trust towards the fellow participant (<italic>r</italic> = .52, <italic>p</italic> &#x0003c; .01), and the assessment of the fellow particpant&#x02019;s sense of humor (&#x0201c;<italic>I felt that the other person had the same humor</italic>&#x0201d;: <italic>r</italic> = .57, <italic>p</italic> &#x0003c; .01). <italic>Number of presses</italic> and <italic>press duration</italic>were also significantly correlated (<italic>r</italic> = .41, <italic>p</italic> &#x0003c; .05).</p><p>Finally, an independent samples <italic>t</italic>-test was used to investigate whether the mean heart rate and skin conductance measurements (both registered while watching the funny video clip) differed significantly between both conditions. For mean heart rate there was no significant difference between the control (<italic>M</italic> = 69.55; <italic>SD</italic> = 7.76) and the Frebble condition (<italic>M</italic> = 70.27; <italic>SD</italic> = 9.37), <italic>t</italic>(35) = &#x02212; 0.253, <italic>p</italic> = .801, ns. For skin conductance the control (<italic>M</italic> = 7.60; <italic>SD</italic> = 2.69) and Frebble (<italic>M</italic> = 6.61; <italic>SD</italic> = 2.16) conditions showed no significant difference either, <italic>t</italic>(35) = 1.240, <italic>p</italic> = .223, ns.</p></sec><sec><title>Subjective measurements</title><p>An independent samples <italic>t</italic>-test was used to investigate whether the participants scored differently in the control and Frebble conditions on the questions about their affective experience of the funny movie clips. For the rating score (from 0 to 10) about how amusing the participants found the movie there was no significant difference between the control (<italic>M</italic> = 6.67; <italic>SD</italic> = 1.65) and the Frebble conditions (<italic>M</italic> = 7.00; <italic>SD</italic> = 1.20), <italic>t</italic>(35) = &#x02212; 0.707, <italic>p</italic> = .485, ns. For the rating of the movie using adjectives there was also no significant difference (control: <italic>M</italic> = 5.09; <italic>SD</italic> = 0.65; Frebble: <italic>M</italic> = 4.98; <italic>SD</italic> = 0.51), <italic>t</italic>(32) = 0.526, <italic>p</italic> = .603, ns.</p></sec><sec><title>Conclusion</title><p>Neither the objective nor the subjective measurements showed any significant difference between the affective experience of the funny movie in both experimental conditions. Hypothesis 2 (feedback via mediated hand touching enhances the experience of an amusing movie compared to visual feedback) was therefore not confirmed.</p></sec></sec><sec><title>Hypothesis 3: Increase of trust</title><p>To test whether feedback through mediated hand touching increases trust towards another person relative to abstract visual feedback (H3) we compared the objective (amount of money bet during the trust game) and the subjective (questions concerning the impression of the other participant in Questionnaire 3) measurements in the control and Frebble conditions.</p><sec><title>Objective measurements</title><p>The amount of money bet during the trust game was used to measure trust towards the other person. An independent <italic>t</italic>-test between the control (<italic>M</italic> = 6.83, <italic>SD</italic> = 5.76) and the Frebble condition (<italic>M</italic> = 6.21, <italic>SD</italic> = 5.91) showed that there was no significant difference between the amount of money set in in both conditions; <italic>t</italic>(35) = 0.324, <italic>p</italic> = .748, ns.</p></sec><sec><title>Subjective measurements</title><p>At the end of the experiment questions were also asked concerning the impression of the other participant. None of these items showed a significant difference between the conditions (all <italic>p</italic>-values &#x0003e;.05). The results of the independent <italic>t</italic>-tests are shown in <xref ref-type="table" rid="table-3">Table 3</xref>.</p><table-wrap id="table-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/table-3</object-id><label>Table 3</label><caption><title>Sample size (<italic>N</italic>), means (<italic>M</italic>), standard deviations (<italic>SD</italic>) for the variables concerning the other person, split up for the control and Frebble condition.</title><p>Also shown are the <italic>p</italic>-values of the independent samples <italic>t</italic>-test for each variable between both conditions.</p></caption><alternatives><graphic xlink:href="peerj-03-1297-g010"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="3" rowspan="1">Joystick</th><th align="center" colspan="3" rowspan="1">Frebble</th><th rowspan="1" colspan="1"><italic>t</italic>-test</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">
<italic>M</italic>
</th><th rowspan="1" colspan="1">
<italic>SD</italic>
</th><th rowspan="1" colspan="1">
<italic>p</italic>
</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Affective trust</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.44</td><td rowspan="1" colspan="1">1.38</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.84</td><td rowspan="1" colspan="1">1.61</td><td rowspan="1" colspan="1">.426</td></tr><tr><td rowspan="1" colspan="1">Humor</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.83</td><td rowspan="1" colspan="1">1.89</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.58</td><td rowspan="1" colspan="1">1.58</td><td rowspan="1" colspan="1">.658</td></tr><tr><td rowspan="1" colspan="1">Attachment</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">3.03</td><td rowspan="1" colspan="1">1.21</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">3.31</td><td rowspan="1" colspan="1">1.54</td><td rowspan="1" colspan="1">.557</td></tr><tr><td rowspan="1" colspan="1">Impression of the other person</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">4.43</td><td rowspan="1" colspan="1">0.80</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">4.45</td><td rowspan="1" colspan="1">0.73</td><td rowspan="1" colspan="1">.926</td></tr><tr><td rowspan="1" colspan="1">Inclusion of Other in the Seelf (IOS)</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">2.33</td><td rowspan="1" colspan="1">0.97</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">2.58</td><td rowspan="1" colspan="1">1.35</td><td rowspan="1" colspan="1">.531</td></tr></tbody></table></alternatives></table-wrap></sec><sec><title>Conclusion</title><p>The results of both the objective and subjective measurements indicate that compared to visual feedback, mediated haptic communication leads neither to more trust nor to a different impression of the other person. Hypothesis 3 (feedback through mediated hand touching increases trust towards another person compared to abstract visual feedback) was therefore not confirmed.</p></sec></sec><sec><title>Sample characteristics</title><p>The current mood (BMIS) and emotional state (SAM) of the participants were again measured after watching both video clips. To test whether mood and emotional state were affected differently in both conditions, for all four dependent variables a mixed-design ANOVA with a within-subjects independent variable of <italic>time of measurement</italic> (before and afterwards) and a between-subjects independent variable of <italic>condition</italic> (control vs. Frebble) was conducted.</p><p>For the BMIS there were no main effects of <italic>time of measurement</italic>, <italic>F</italic>(1, 35) = 2.164, <italic>p</italic> = .150, ns and condition, <italic>F</italic>(1, 35) = 0.518, <italic>p</italic> = .518, ns, nor was there an interaction between BMIS and condition, <italic>F</italic>(1, 35) = 0.102, <italic>p</italic> = .752, ns.</p><p>For the <italic>Pleasure</italic> measurement (SAM) there were no effects of <italic>time of measurement,</italic>
<italic>F</italic>(1, 34) = 0.003, <italic>p</italic> = .956, ns and <italic>condition</italic>, <italic>F</italic>(1, 34) = 0.007, <italic>p</italic> = .934, ns. There was also no interaction between <italic>time of measurement</italic> and <italic>condition</italic>, <italic>F</italic>(1, 34) = 1.007, <italic>p</italic> = .323, ns.</p><p>The <italic>Arousal</italic> measurement (SAM) showed a main effect of <italic>time of measurement</italic>, <italic>F</italic>(1, 35) = 4.513, <italic>p</italic> = .041, <italic>&#x003b7;</italic><sup>2</sup> = .114 and a significant interaction between <italic>time of measurement</italic> and <italic>condition</italic>, <italic>F</italic>(1, 35) = 7.674, <italic>p</italic> = .009, <italic>&#x003b7;</italic><sup>2</sup> = .180 (<xref ref-type="fig" rid="fig-6">Fig. 6</xref>). However, there was no main effect for <italic>condition</italic>, <italic>F</italic>(1, 35) = 0.151, <italic>p</italic> = .700, ns (<xref ref-type="fig" rid="fig-6">Fig. 6</xref>).</p><fig id="fig-6" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-6</object-id><label>Figure 6</label><caption><title>Mean arousal scores (SAM) before and after the experiment, for the joystick and Frebble conditions.</title></caption><graphic xlink:href="peerj-03-1297-g006"/></fig><p>Main effects of <italic>time of measurement</italic>, <italic>dominance</italic> (SAM), <italic>F</italic>(1, 34) = 1.575, <italic>p</italic> = .218, ns and <italic>condition</italic>, <italic>F</italic>(1, 34) = 2.532, <italic>p</italic> = .121, ns as well as the interaction between the <italic>dominance</italic> and <italic>condition</italic>, <italic>F</italic>(1, 34) = 0.827, <italic>p</italic> = .370, ns were not statistically significant.</p></sec><sec><title>Explorative analyses</title><p>Besides testing the hypotheses of the present study there were also data collected concerning age, gender, mood (BMIS), emotions (SAM), Touch Receptivity, and personality traits (BIG 5). To investigate whether these factors may have an effect on the dependent variables some explorative analyzes were conducted. Therefore separate analyses of covariance for each dependent variable were conducted with each of the listed factors (age, gender, mood and emotions) as a covariate. The results showed no significant results. None of the factors influenced the outcome of the dependent variables as a covariate.</p><p>In addition, possible effects on the dependent variables were investigated by a two-way ANOVA having two levels for each factor (<xref ref-type="table" rid="table-4">Table 4</xref>) and two levels of conditions (control vs. Frebble). Therefore each factor was subdivided in two levels based on the median score. The factors: <italic>mood</italic> (BMIS), <italic>emotions</italic> (all three SAM measurements), <italic>Openness</italic> and <italic>Agreeableness</italic> were excluded from this analysis because the scores were extremely right skewed with less than 15% of the scores being lower than the mean score. The independent variables used for the analyses with their two levels are shown in <xref ref-type="table" rid="table-4">Table 4</xref>. All effects were statistically significant at the .05 significance level. It is chosen to only report significant results.</p><table-wrap id="table-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/table-4</object-id><label>Table 4</label><caption><title>Sample size (<italic>N</italic>) and values for both levels of each factor based on the mean scores.</title></caption><alternatives><graphic xlink:href="peerj-03-1297-g011"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" colspan="2" rowspan="1">Level 1</th><th align="center" colspan="2" rowspan="1">Level 2</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">Values</th><th rowspan="1" colspan="1">
<italic>N</italic>
</th><th rowspan="1" colspan="1">Values</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Age (in years)</td><td rowspan="1" colspan="1">25</td><td rowspan="1" colspan="1">Young (18&#x02013;35)</td><td rowspan="1" colspan="1">12</td><td rowspan="1" colspan="1">Old (36&#x02013;50)</td></tr><tr><td rowspan="1" colspan="1">Gender</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">Men</td><td rowspan="1" colspan="1">23</td><td rowspan="1" colspan="1">Women</td></tr><tr><td rowspan="1" colspan="1">Touch receptivity</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">Low (1&#x02013;4, 5)</td><td rowspan="1" colspan="1">19</td><td rowspan="1" colspan="1">High (4, 6&#x02013;7)</td></tr><tr><td rowspan="1" colspan="1">Extraversion</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">Low (1&#x02013;3)</td><td rowspan="1" colspan="1">26</td><td rowspan="1" colspan="1">High (3, 1&#x02013;5)</td></tr></tbody></table></alternatives></table-wrap><p>There were no main effects of <italic>Touch Receptivity</italic>, <italic>F</italic>(1, 33) = 1.584, <italic>p</italic> = .217, ns or <italic>condition</italic>, <italic>F</italic>(1, 33) = 1.584, <italic>p</italic> = .217, ns, on the dependent variable of <italic>Affective Trust</italic>. However, there was a significant interaction effect between <italic>Touch Receptivity</italic> and <italic>condition</italic> on <italic>Affective Trust</italic>, <italic>F</italic>(1, 33) = 4.537, <italic>p</italic> = .041, <italic>&#x003b7;</italic><sup>2</sup> = .121. Specifically, participants who scored low on <italic>Touch Receptivity</italic> reported higher <italic>Affective Trust</italic> towards their fellow participant when using a Frebble (<italic>M</italic> = 4.00, <italic>SD</italic> = 0.41) than when using a joystick (<italic>M</italic> = 2.33, <italic>SD</italic> = 0.58; <xref ref-type="fig" rid="fig-7">Fig. 7A</xref>).</p><fig id="fig-7" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.1297/fig-7</object-id><label>Figure 7</label><caption><title>Mean scores on affective trust in the joystick and Frebble conditions for the factors Touch Receptivity (A) and Extraversion (B).</title></caption><graphic xlink:href="peerj-03-1297-g007"/></fig><p>There were no main effects of <italic>Extraversion</italic>, <italic>F</italic>(1, 33) = 1.82, <italic>p</italic> = .187, ns, or <italic>condition</italic>, <italic>F</italic>(1, 33) = 2.20, <italic>p</italic> = .148, ns on the dependent variable of <italic>Affective Trust</italic>. However, again a significant interaction effect was found between <italic>Extraversion</italic> and <italic>condition</italic> on <italic>Affective Trust</italic>, <italic>F</italic>(1, 33) = 5.56, <italic>p</italic> = .024, <italic>&#x003b7;</italic><sup>2</sup> = .144. Participants who scored low on <italic>Extraversion</italic> reported lower <italic>Affective Trust</italic> towards their fellow participant when using a joystick (<italic>M</italic> = 2.29, <italic>SD</italic> = 0.95) than when using a Frebble (<italic>M</italic> = 4.25, <italic>SD</italic> = 2.22; <xref ref-type="fig" rid="fig-7">Fig. 7B</xref>).</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>This study was performed to investigate whether mediated hand touching can have some of the same beneficial effects as reported for interpersonal touch. Therefore participants successively watched two emotional video clips and were led to believe that a fellow participant in an adjacent room simultaneously watched the same clips. The first video clip was intended to induce sadness while the second one was intended to cheer up the participants. While watching the second (funny) video clip the participants were asked to signal their fellow participant whenever they were amused, either via a mediated hand touch device or via a joystick. They received either haptic or visual feedback: whenever their fellow participant found the video amusing they received a mediated hand press (experimental condition) or a visual cue (a gray square on the screen turned blue&#x02014;control condition). In reality there was no fellow participant present and a computer sent standardized feedback that had been scripted in advance.</p><p>It was expected that, compared to the control condition, communication with mediated hand touch feedback would (H1) enhance recovery from the sad mood, (H2) intensify the affective experience of the funny movie clips, and (H3) increase trust towards the fellow participant.</p><sec><title>Experimental manipulation</title><p>Analysis of the physiological measurements showed that the funny video clip indeed successfully elicited the desired emotion of amusement. While watching the funny video clip the participants&#x02019; heart rate and skin conductance level increased significantly compared to both their baseline levels and their levels during the sad video clip. The selected sad movie only resulted in moderate emotional effect: heart rate and skin conductance level both decreased relative to their baseline levels but this difference was not significant. An explanation for the different extent of the physiological reactions to respectively the sad and funny video clips may be found in the dimensionality of emotions. Emotion has been conceptualized as a dimensional construct with valence and arousal as the main dimensions (<xref rid="ref-61" ref-type="bibr">Mehrabian &#x00026; Russell, 1974</xref>). Valence refers to whether an experience is pleasurable (pleasant vs. unpleasant), and arousal refers to autonomic arousal associated with the experience (relaxed vs. aroused). In this view sadness can be described as a negative experience with a neutral level of associated arousal, while amusement can be described as a pleasant experience with a high level of associated arousal. The stronger physiological reactions to the funny video clip are probably due to a higher level of arousal, whereas the neutral arousal level induced by the sad video clip probably resulted in weaker physiological responses (<xref rid="ref-27" ref-type="bibr">Fern&#x000e1;ndez et al., 2012</xref>; <xref rid="ref-36" ref-type="bibr">Gunes &#x00026; Pantic, 2010</xref>). Here we should note that results in the literature on skin conductance responses to watching sad movies are also not unequivocal (both increases, decreases and the absence of skin conductance responses have been reported: <xref rid="ref-51" ref-type="bibr">Kreibig, 2010</xref>). Therefore it is also important to take the self-report questionnaires into account. The participants reported moderately high sadness scores on the sad video clip and moderately high amusement scores on the funny video clip. It can therefore be concluded that the induction of amusement was successful both on a subjective and on an objective level, whereas the induction of sadness was confirmed on a subjective level. Although this is not the most extreme manipulation thinkable, we consider the effects sufficient for the current experiment.</p></sec><sec><title>Recovery from sad mood</title><p>Previous studies indicate that interpersonal touch leads to a faster recovery from a sad mood or anxious events (<xref rid="ref-23" ref-type="bibr">Debrot et al., 2013</xref>; <xref rid="ref-85" ref-type="bibr">Whitcher &#x00026; Fisher, 1979</xref>). However, this effect has not been widely examined for mediated touch (<xref rid="ref-37" ref-type="bibr">Haans, de Bruijn &#x00026; IJsselsteijn, 2014</xref>). Only one study (<xref rid="ref-17" ref-type="bibr">Cabibihan, Zheng &#x00026; Cher, 2012</xref>) reported a faster recovery during a resting period after watching a sad movie with both human and mediated touch. The present study tried to replicate this effect for mediated hand touching and to extend our understanding of this effect. But contrary to prior expectations, communication via a mediated touch device did not lead to enhanced recovery from a negative mood induced by watching a sad movie clip. Participants in both conditions showed a clear increase in heart rate and skin conductance level when watching the funny video clip (as expected), but the extent of the increase was not significantly different between the visual and mediated hand touching feedback conditions.</p><p>A possible reason that there was no difference in recovery between the two experimental conditions in the present study could be due to the fact that the mediated touch used here differed in one important aspect from the one used by Cabibihan and colleagues (<xref rid="ref-17" ref-type="bibr">2012</xref>). In Cabibihan&#x02019;s study the mediated touch device did not only provide haptic stimulation (like the Frebble did in the present study), but also provided warmth. A lack of warmth could cause the unsuccessful replication of their results in the present study. Generally, the effect of pleasant touch (strokes) is larger for stimuli at skin temperature (<xref rid="ref-56" ref-type="bibr">Lucas et al., 2014</xref>).</p><p>As mentioned before, the communication of amusement from the participant to the imaginary fellow participant was similar in both conditions (pressing the button on the joystick versus squeezing the Frebble). The main difference between both groups was the feedback mode, which was either visual or haptic. It is known that simple signals may be sufficient to mediate affective communication (<xref rid="ref-45" ref-type="bibr">Janssen, IJsselsteijn &#x00026; Westerink, 2014</xref>) and that sharing feelings per se may already account for a certain amount of recovery. This effect could not be measured in this study because both groups communicated their feelings. Hence, the fact that participants in both conditions were able to communicate their feelings could account for the main effect independent of the actual nature of the mediated feedback (visual or haptic).</p></sec><sec><title>Affective experience</title><p>This study also investigated whether the affective experience itself can be influenced by the use of a mediated hand touching device. Subjective measurements in the form of self-report questionnaires and objective measurements like number and duration of presses and facial expressions served to assess the affective experience. None of these measures revealed significant differences between the control and experimental condition. However, all objective measurements showed a marginal trend towards a more intense affective experience with the mediated touch device. Participants in the mediated touch condition smiled for longer periods and pressed the device more often and longer than participants in the control condition. Note that although these measures are taken to characterize a participant&#x02019;s affective response to the video clip, they could also be influenced by the novelty of the interface. Despite these trends, it remains unclear why the use of the mediated touch device did not lead to a more intense affective experience.</p><p>The absence of a more intense affective experience may imply either that this effect cannot be induced by mediated touch at all or that the used form of mediated touch in this study was inappropriate. It is therefore important to investigate other aspects of mediated touch (like warmth) to get more insight about the possible effects of mediated touch on affective experience. Another element of mediated touch which is known to influence affective communication, but which was not tested in this study, is visual stimulation. It has been found that adding a mutually shared haptic sensation to a video conferencing system can significantly enhance the experience of social telepresence and mediated touch, provided that the mediated social touch is mutual but not visually duplicated (i.e., one should be able to see the partner and his movements to grasp the intention of the touch, but not one&#x02019;s own body part that is being touched, since this disturbs the illusion: <xref rid="ref-62" ref-type="bibr">Nakanishi, Tanaka &#x00026; Wada, 2014</xref>).</p><p>The absence of a difference between the control and experimental conditions may also be due to the way feedback was provided during this study. Previous studies show that the quality of a conversation may depend on the richness of its content (<xref rid="ref-38" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2006</xref>). In this study the participants used a very simple, non-rich tactile code to communicate their feelings to their fellow participant (one press = feeling amused) in both conditions. Although the haptic device was able to deliver richer touch cues, we deliberately reduced the richness of its code to the level of richness of the visual cue (to make both feedback modes more comparable). Also, the feedback of the fellow participant was clear and unambiguous (color change of a square or haptic stimulation = feeling amused). The only difference between both conditions was the channel used for the feedback: haptic feedback in the experimental condition versus visual feedback in the control condition. It could be that the absence of a difference between both conditions means that the most important requirement for a shared affective experience is the ability to communicate feelings to another person, irrespective of the communication mode (as also suggested by <xref rid="ref-78" ref-type="bibr">Spap&#x000e9; et al., 2015</xref>). If so, haptic feedback has no benefit over visual feedback for affective communication. This hypothesis could be verified by including a condition in which the participants cannot communicate their feelings. Finding (1) a difference between conditions in which feelings are either shared or not shared, and finding (2) no difference between conditions in which feelings are shared through different communication channels, would confirm the idea that the mere ability to share feelings with another person is sufficient to mediate an affective experience (<xref rid="ref-78" ref-type="bibr">Spap&#x000e9; et al., 2015</xref>). However, this does not exclude that increased haptic communication effects may occur when the haptic messages become richer.</p><p>In addition, the mediated haptic feedback provided through a Frebble device (which resembles more a mechanical contact than the touch of a real human hand) may require cognitive effort on the part of the receiver to be understood and may therefore have lost its unique affective quality. Although laboratory studies indicate that emotional information can to some degree be transmitted between two persons via (even very simple) mediated haptics (<xref rid="ref-8" ref-type="bibr">Bailenson et al., 2007</xref>; <xref rid="ref-39" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2009</xref>; <xref rid="ref-64" ref-type="bibr">Rantala et al., 2013</xref>; <xref rid="ref-76" ref-type="bibr">Smith &#x00026; MacLean, 2007</xref>), and that real and simulated mediated handshakes are similar to some degree (<xref rid="ref-30" ref-type="bibr">Giannopoulos et al., 2011</xref>), it is still unknown to what extent mediated haptic experiences can actually approach direct interpersonal haptic interactions (<xref rid="ref-29" ref-type="bibr">Gallace &#x00026; Spence, 2010</xref>).</p><p>Participants in both conditions reported that the constant feedback of their fellow participant led them to press their device more often than they would have done without feedback. They felt committed to reciprocate the presses of their communication partner. This may indicate a high social conformity in both conditions. Social conformity means that people change their behavior and confirm to the expectations of the other person (<xref rid="ref-1" ref-type="bibr">Aarts &#x00026; Dijksterhuis, 2003</xref>; <xref rid="ref-6" ref-type="bibr">Aronson, Wilson &#x00026; Akert, 2010</xref>; <xref rid="ref-48" ref-type="bibr">Kiesler &#x00026; Kiesler, 1969</xref>). If so, a ceiling effect may have occurred caused by the set-up with pre-scripted communication, which makes it difficult to find differences in press behavior between the experimental and control condition.</p><p>Although there was no difference in affective experience the arousal level of the participants in the experimental condition (the Frebble users) was significantly higher after watching both movie clips compared to the arousal level before the experiment. In contrast, the arousal level of the joystick users decreased. A high arousal level can indicate two emotional states: stress or excitement (<xref rid="ref-70" ref-type="bibr">Russell, Weiss &#x00026; Mendelson, 1989</xref>). In combination with positive feelings measured after the funny movie clips, it most likely indicates excitement here. This result suggests that mediated touch does not influence the valence of the affective experience directly, but only indirectly through increasing arousal levels. It may be that haptic communication in itself is arousing (especially with an unfamiliar partner), or that the use of a new haptic gadget is interesting and exciting for the participants and thus increases the self-reported arousal level.</p></sec><sec><title>Trust</title><p>Finally the Hypothesis H3 that mediated touch increases trust towards another person more than abstract visual feedback was tested by playing the trust game. This game is designed to measure trust towards another person (<xref rid="ref-9" ref-type="bibr">Berg, Dickhaut &#x00026; McCabe, 1995</xref>; <xref rid="ref-52" ref-type="bibr">Kreps, 1990</xref>; <xref rid="ref-54" ref-type="bibr">Lazzarini et al., 2004</xref>). When used in combination with self-report questionnaires it can provide an accurate and reliable picture of trust (<xref rid="ref-31" ref-type="bibr">Glaeser et al., 2000</xref>). However, the average amount of money set in, as well as self-report questions concerning the other person, showed no indications that mediated touch enhanced feelings of trust relative to visual feedback. Because it is known that social touch generally tends to increase trust (<xref rid="ref-8" ref-type="bibr">Bailenson et al., 2007</xref>), the question arises whether the lack of an effect indicates that some essential elements of mediated touch were missing in this study, with the result that mediated social touch was not able to affect trust. Again, it is also possible that the ability to share feelings is by itself already sufficient to establish a certain level of trust (independent of the mode of communication) and that the difference between visual or mediated feedback therefore does not add any extra value. Another option is again the lack of warming actuators. Using warmth as an element of mediated touch is not only important for building the feeling of comfort, it is also essential for building trust (<xref rid="ref-16" ref-type="bibr">Cabibihan et al., 2010</xref>; <xref rid="ref-38" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2006</xref>).</p></sec><sec><title>Limitations</title><p>Although the present study provides new insights on the effects of mediated touch some limitations should be mentioned. The experiment took place in a laboratory setting with only binary (visual or tactile) feedback. The fully scripted protocol did not resemble a natural conversation between two persons, and made it complicated to test acquainted dyads. The advantage of this controlled set-up is that the results are analyzable in a standardized way. However, a disadvantage is that the content of the conversation is strictly limited by the experimental paradigm and does not resemble real life content (<xref rid="ref-37" ref-type="bibr">Haans, de Bruijn &#x00026; IJsselsteijn, 2014</xref>). Although squeezing each other&#x02019;s hand over distance while watching a funny movie may currently not be a common practice, there could be (subtle) effects of touch which might make this new technique interesting for certain applications. Note that techniques like texting and apping were initially also considered highly unnatural while they have become common practice in many situations nowadays. A second limitation of this study is that the experiment was not conducted with two persons who are related with each other or who have even met before. Previous studies have shown that the effects of mediated touch strongly depend on the familiarity of the persons and their relationships (<xref rid="ref-10" ref-type="bibr">Bickmore et al., 2010</xref>). In general, people consider mediated touch only appropriate as a means of communication between partners in close personal relationships (e.g., <xref rid="ref-64" ref-type="bibr">Rantala et al., 2013</xref>), and even mediated touch communication between strangers can cause discomfort (<xref rid="ref-76" ref-type="bibr">Smith &#x00026; MacLean, 2007</xref>). Although feelings of amusement can effectively be communicated between unacquainted dyads by touching hands (<xref rid="ref-43" ref-type="bibr">Hertenstein et al., 2006</xref>) and although (mediated) social touch can positively affect human feelings and behavior even between strangers (e.g., the Midas touch; <xref rid="ref-39" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2009</xref>), touch may not be the right modality to share feelings of sadness or amusement between strangers. It is also uncertain whether the illusion of a fellow participant really worked and whether all participants believed that there was a fellow participant in the other room. This was intentionally not checked afterwards to avoid raising suspicion which might be communicated to future participants. A third limitation was the fact that participants reported that a Frebble squeeze resembled more a mechanical contact than a real human hand. In addition, squeezes may not have been the most appropriate form of interaction, since they are typically associated with unpleasant and aroused emotional intentions, while finger touch (stroking, tickling) is more often associated with pleasant and relaxed emotional intentions (<xref rid="ref-64" ref-type="bibr">Rantala et al., 2013</xref>). However, given the fact that simple mechanical pokes can effectively convey affective messages and elicit a Midas Touch effect (<xref rid="ref-39" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2009</xref>; <xref rid="ref-78" ref-type="bibr">Spap&#x000e9; et al., 2015</xref>), it has been suggested that it is not so much the type of touch but more its meaning that determines the receiver&#x02019;s response in a certain context (<xref rid="ref-39" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2009</xref>; <xref rid="ref-44" ref-type="bibr">Hoggan et al., 2012</xref>).</p></sec><sec><title>Future research</title><p>The mediated touch device used in this study was a prototype and should be improved before being used in further studies. Other studies indicate electromechanical actuators alone may not simulate accurately the feeling of being touched by a human hand (<xref rid="ref-37" ref-type="bibr">Haans, de Bruijn &#x00026; IJsselsteijn, 2014</xref>). Therefore it would be beneficial to add warmth to the device as well as to a more humanlike surface of the device (softer and smoother). <xref rid="ref-10" ref-type="bibr">Bickmore et al. (2010)</xref> also state that mediated touch should resemble more a stroke than a pressing contact. The form of the device (which evoked the feeling of another hand enclosing the own one), as well as the fact that the device was held in the hand, was evaluated during the debriefing as positive by the participants and should not be changed. This impression corresponds to studies which confirm that touching hands is associated with loving, friendly and pleasant feelings (<xref rid="ref-10" ref-type="bibr">Bickmore et al., 2010</xref>).</p><p>Second, it may be interesting to conduct research in a more natural setting. First of all this involves the use of participants who know each other. On the one hand this may lead to more realistic communication and on the other hand it is known that this can improve the effects of mediated touch (<xref rid="ref-81" ref-type="bibr">Tolmie &#x00026; Boyle, 2000</xref>). In a future laboratory study it is recommendable to use the mediated touch device in an open and more realistic conversation rather than a strict and limited conversation with only binary feedback as used in the present study. For a field study the mediated touch device could be integrated into the daily lives of dyads who know each other well and regularly use mediated communication. It is also known that long term effects of emotions are different from short living emotions, like film induced emotions (<xref rid="ref-38" ref-type="bibr">Haans &#x00026; IJsselsteijn, 2006</xref>). Therefore, it could be useful to conduct a longitudinal study wherein mediated touch communication is observed over a longer period and can be compared to communication without a mediated touch device. Including these aspects will lead to a more natural context and thereby increase the ecological validity of the study.</p><p>Third, the present study used touch in isolation from vision and sound. It is known that visual and auditory cues are the major factors that influence the outcome of virtual communication (<xref rid="ref-40" ref-type="bibr">Hammick &#x00026; Lee, 2014</xref>) and that the provision of facial expressions and speech enhances arousal and valence during a conversation (<xref rid="ref-10" ref-type="bibr">Bickmore et al., 2010</xref>). Although previous studies have shown that specific emotions can be encoded and decoded using touch, the effectiveness of touch in real life may also be in its complementary role to visual and auditory information. It would therefore be interesting to investigate how mediated touched moderates communication through other channels.</p><p>Finally, exploratory analyses of the present results revealed some interesting findings on the effects of <italic>Extraversion</italic> and <italic>Touch Receptivity</italic>. Using mediated touch via a Frebble device enabled participants scoring low on <italic>Extraversion</italic> or on <italic>Touch Receptivity</italic> to achieve the same level of trust towards their communication partner as participants scoring high on these factors, while they only achieved much lower levels when using a joystick. This suggests that people who are not extroverts or who do not like to touch other persons felt better understood by their fellow participants when using mediated touch. These findings agree with the observation that introverted people communicate their &#x02018;real me&#x02019; on the internet (i.e., in the absence of physical interaction) more easily than in real (physical) social interactions (<xref rid="ref-2" ref-type="bibr">Amichai-Hamburger, Wainapel &#x00026; Fox, 2002</xref>), are more inclined to form online relationships (<xref rid="ref-60" ref-type="bibr">McKenna &#x00026; Bargh, 1999</xref>), and feel more successful in online than in face-to-face interactions (<xref rid="ref-75" ref-type="bibr">Shalom et al., 2015</xref>). Since the present results are only explorative, future research should try to gain more insight on the effects of <italic>Extraversion</italic> and <italic>Touch Receptivity</italic> on mediated touch communication.</p></sec></sec><sec><title>Conclusion</title><p>This study investigated whether mediated hand touching has the ability to (1) enhance recovery from sadness (i.e., the return to a more positive emotional state) after watching a sad movie, (2) enhance a positive experience (watching a funny movie), and (3) increase trust towards the communication partner. The analysis of objective and subjective measurements showed no significant benefits of mediated touch communication (two-way tactile communication) above a control condition (tactile response and visual feedback). The present results do not allow us to conclude whether mediated touch is not able to do so in general or whether the used mediated touch device with only haptic stimulation is not sufficient and should be adapted. In both experimental conditions participants used a haptic channel to express their emotions. Only the feedback modality differed and was either visual or haptic. Giving and receiving mediated feedback can play a different role and giving input may already be sufficient to achieve the desired effects. This study therefore only allows conclusions about the reception of mediated touch. All-in-all, we were not able to replicate earlier favorable effects of mediated touch. This may indicate that these favorable effects may only occur under specific conditions. Future research should investigate the influence of personality, type of relationship with the other person, the effects of giving mediated versus non-mediated feedback, the role of intention, and the added value of respectively warming actuators and the visualization of the conversation partner to mediated touch.</p><p>The limitations of this study were that the participant was unfamiliar with the fellow participant and that the device was used in a limited and unnatural conversation. Besides adapting the mediated touch device, a suggestion for further research is to use a realistic conversation between dyads who are acquainted.</p></sec><sec sec-type="supplementary-material" id="supplemental-information"><title>Supplemental Information</title><supplementary-material content-type="local-data" id="supp-1"><object-id pub-id-type="doi">10.7717/peerj.1297/supp-1</object-id><label>Supplemental Information 1</label><caption><title>Experimental data files</title></caption><media xlink:href="peerj-03-1297-s001.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><sec sec-type="additional-information"><title>Additional Information and Declarations</title><fn-group content-type="competing-interests"><title>Competing Interests</title><fn id="conflict-1" fn-type="conflict"><p>The authors declare there are no competing interests. Stefanie M. Erk, Alexander Toet and Jan B.F. Van Erp are employees of TNO.</p></fn></fn-group><fn-group content-type="author-contributions"><title>Author Contributions</title><fn id="contribution-1" fn-type="con"><p><xref ref-type="contrib" rid="author-1">Stefanie M. Erk</xref> conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, reviewed drafts of the paper.</p></fn><fn id="contribution-2" fn-type="con"><p><xref ref-type="contrib" rid="author-2">Alexander Toet</xref> conceived and designed the experiments, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, reviewed drafts of the paper.</p></fn><fn id="contribution-3" fn-type="con"><p><xref ref-type="contrib" rid="author-3">Jan B.F. Van Erp</xref> conceived and designed the experiments, wrote the paper, reviewed drafts of the paper.</p></fn></fn-group><fn-group content-type="other"><title>Human Ethics</title><fn id="addinfo-1" fn-type="other"><p>The following information was supplied relating to ethical approvals (i.e., approving body and any reference numbers):</p><p>TNO Internal Review Board.</p></fn></fn-group></sec><ref-list content-type="authoryear"><title>References</title><ref id="ref-1"><label>Aarts &#x00026; Dijksterhuis (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aarts</surname><given-names>H</given-names></name><name><surname>Dijksterhuis</surname><given-names>A</given-names></name></person-group><article-title>The silence of the library: environment, situational norm, and social behavior</article-title><source>Journal of Personality and Social Psychology</source><issue>1</issue><year>2003</year><volume>84</volume><fpage>18</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.84.1.18</pub-id><pub-id pub-id-type="pmid">12518968</pub-id></element-citation></ref><ref id="ref-2"><label>Amichai-Hamburger, Wainapel &#x00026; Fox (2002)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amichai-Hamburger</surname><given-names>Y</given-names></name><name><surname>Wainapel</surname><given-names>G</given-names></name><name><surname>Fox</surname><given-names>S</given-names></name></person-group><article-title>&#x0201c;On the internet no one knows I&#x02019;m an introvert&#x0201d;: extroversion, neuroticism, and internet interaction</article-title><source>CyberPsychology &#x00026; Behavior</source><issue>2</issue><year>2002</year><volume>5</volume><fpage>125</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1089/109493102753770507</pub-id><pub-id pub-id-type="pmid">12025878</pub-id></element-citation></ref><ref id="ref-3"><label>Anderson (2001)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>EZ</given-names></name></person-group><article-title>Energy therapies for physical and occupational therapists working with older adults</article-title><source>Physical &#x00026; Occupational Therapy in Geriatrics</source><issue>4</issue><year>2001</year><volume>18</volume><fpage>35</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1080/J148v18n04_04</pub-id></element-citation></ref><ref id="ref-4"><label>App et al. (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>App</surname><given-names>B</given-names></name><name><surname>McIntosh</surname><given-names>DN</given-names></name><name><surname>Reed</surname><given-names>CL</given-names></name><name><surname>Hertenstein</surname><given-names>MJ</given-names></name></person-group><article-title>Nonverbal channel use in communication of emotion: how may depend on why</article-title><source>Emotion</source><issue>3</issue><year>2011</year><volume>11</volume><fpage>603</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1037/a0023164</pub-id><pub-id pub-id-type="pmid">21668111</pub-id></element-citation></ref><ref id="ref-5"><label>Aron, Aron &#x00026; Smollan (1992)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aron</surname><given-names>A</given-names></name><name><surname>Aron</surname><given-names>EN</given-names></name><name><surname>Smollan</surname><given-names>D</given-names></name></person-group><article-title>Inclusion of Other in the Self Scale and the structure of interpersonal closeness</article-title><source>Journal of Personality and Social Psychology</source><issue>4</issue><year>1992</year><volume>63</volume><fpage>596</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.63.4.596</pub-id></element-citation></ref><ref id="ref-6"><label>Aronson, Wilson &#x00026; Akert (2010)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Aronson</surname><given-names>E</given-names></name><name><surname>Wilson</surname><given-names>TD</given-names></name><name><surname>Akert</surname><given-names>RM</given-names></name></person-group><source>Social psychology</source><edition designator="7">7th edition</edition><year>2010</year><publisher-loc>Upper Saddle River</publisher-loc><publisher-name>Pearson Education, Inc</publisher-name></element-citation></ref><ref id="ref-7"><label>Bagozzi, Gopinath &#x00026; Nyer (1999)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagozzi</surname><given-names>RP</given-names></name><name><surname>Gopinath</surname><given-names>M</given-names></name><name><surname>Nyer</surname><given-names>PU</given-names></name></person-group><article-title>The role of emotions in marketing</article-title><source>Journal of the Academy of Marketing Science</source><issue>2</issue><year>1999</year><volume>27</volume><fpage>184</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1177/0092070399272005</pub-id></element-citation></ref><ref id="ref-8"><label>Bailenson et al. (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bailenson</surname><given-names>JN</given-names></name><name><surname>Yee</surname><given-names>N</given-names></name><name><surname>Brave</surname><given-names>S</given-names></name><name><surname>Merget</surname><given-names>D</given-names></name><name><surname>Koslow</surname><given-names>D</given-names></name></person-group><article-title>Virtual interpersonal touch: expressing and recognizing emotions through haptic devices</article-title><source>Human&#x02013;Computer Interaction</source><issue>3</issue><year>2007</year><volume>22</volume><fpage>325</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1080/07370020701493509</pub-id></element-citation></ref><ref id="ref-9"><label>Berg, Dickhaut &#x00026; McCabe (1995)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname><given-names>J</given-names></name><name><surname>Dickhaut</surname><given-names>J</given-names></name><name><surname>McCabe</surname><given-names>K</given-names></name></person-group><article-title>Trust, reciprocity, and social history</article-title><source>Games and Economic Behavior</source><issue>1</issue><year>1995</year><volume>10</volume><fpage>122</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1006/game.1995.1027</pub-id></element-citation></ref><ref id="ref-10"><label>Bickmore et al. (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bickmore</surname><given-names>TW</given-names></name><name><surname>Fernando</surname><given-names>R</given-names></name><name><surname>Ring</surname><given-names>L</given-names></name><name><surname>Schulman</surname><given-names>D</given-names></name></person-group><article-title>Empathic touch by relational agents</article-title><source>IEEE Transactions on Affective Computing</source><issue>1</issue><year>2010</year><volume>1</volume><fpage>60</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1109/T-AFFC.2010.4</pub-id></element-citation></ref><ref id="ref-11"><label>Bos et al. (2002)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bos</surname><given-names>N</given-names></name><name><surname>Olson</surname><given-names>J</given-names></name><name><surname>Gergle</surname><given-names>D</given-names></name><name><surname>Olson</surname><given-names>G</given-names></name><name><surname>Wright</surname><given-names>Z</given-names></name></person-group><article-title>Effects of four computer-mediated communications channels on trust development</article-title><conf-name>Proceedings of the SIGCHI conference on human factors in computing systems (CHI&#x02019;02)</conf-name><year>2002</year><conf-sponsor>ACM Press</conf-sponsor><conf-loc>New York</conf-loc><fpage>135</fpage><lpage>140</lpage></element-citation></ref><ref id="ref-12"><label>Bradley &#x00026; Lang (1994)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><article-title>Measuring emotion: the self-assessment manikin and the semantic differential</article-title><source>Journal of Behavior Therapy and Experimental Psychiatry</source><issue>1</issue><year>1994</year><volume>25</volume><fpage>49</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/0005-7916(94)90063-9</pub-id><pub-id pub-id-type="pmid">7962581</pub-id></element-citation></ref><ref id="ref-13"><label>Brouwer et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>A-M</given-names></name><name><surname>Van Wouwe</surname><given-names>N</given-names></name><name><surname>Muehl</surname><given-names>C</given-names></name><name><surname>Van Erp</surname><given-names>JBF</given-names></name><name><surname>Toet</surname><given-names>A</given-names></name></person-group><article-title>Perceiving blocks of emotional pictures and sounds: effects on physiological variables</article-title><source>Frontiers in Human Neuroscience</source><year>2013</year><volume>7</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2013.00295</pub-id><pub-id pub-id-type="pmid">23355817</pub-id></element-citation></ref><ref id="ref-14"><label>Brown (2015)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>JNA</given-names></name></person-group><article-title>&#x0201c;Once More, With Feeling&#x0201d;: using haptics to preserve tactile memories</article-title><source>International Journal of Human&#x02013;Computer Interaction</source><issue>1</issue><year>2015</year><volume>31</volume><fpage>65</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1080/10447318.2014.959100</pub-id></element-citation></ref><ref id="ref-15"><label>Burgoon, Walther &#x00026; Baesler (1992)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgoon</surname><given-names>JK</given-names></name><name><surname>Walther</surname><given-names>JB</given-names></name><name><surname>Baesler</surname><given-names>EJ</given-names></name></person-group><article-title>Interpretations, evaluations, and consequences of interpersonal touch</article-title><source>Human Communication Research</source><issue>2</issue><year>1992</year><volume>19</volume><fpage>237</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1111/j.1468-2958.1992.tb00301.x</pub-id></element-citation></ref><ref id="ref-16"><label>Cabibihan et al. (2010)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cabibihan</surname><given-names>J-J</given-names></name><name><surname>Jegadeesan</surname><given-names>R</given-names></name><name><surname>Salehi</surname><given-names>S</given-names></name><name><surname>Ge</surname><given-names>S</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Ge</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Cabibihan</surname><given-names>JJ</given-names></name><name><surname>Tan</surname><given-names>Y</given-names></name></person-group><article-title>Synthetic skins with humanlike warmth</article-title><source>Social robotics</source><year>2010</year><publisher-loc>Berlin- Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>362</fpage><lpage>371</lpage></element-citation></ref><ref id="ref-17"><label>Cabibihan, Zheng &#x00026; Cher (2012)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cabibihan</surname><given-names>J-J</given-names></name><name><surname>Zheng</surname><given-names>L</given-names></name><name><surname>Cher</surname><given-names>CKT</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Ge</surname><given-names>S</given-names></name><name><surname>Khatib</surname><given-names>O</given-names></name><name><surname>Cabibihan</surname><given-names>JJ</given-names></name><name><surname>Simmons</surname><given-names>R</given-names></name><name><surname>Williams</surname><given-names>MA</given-names></name></person-group><article-title>Affective tele-touch</article-title><source>Social robotics</source><series>LNCS</series><volume>vol. 7621</volume><year>2012</year><publisher-loc>Berlin-Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>348</fpage><lpage>356</lpage></element-citation></ref><ref id="ref-18"><label>Carvalho et al. (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho</surname><given-names>S</given-names></name><name><surname>Leite</surname><given-names>J</given-names></name><name><surname>Galdo-&#x000c1;lvarez</surname><given-names>S</given-names></name><name><surname>Gon&#x000e7;alves</surname><given-names>&#x000d3;F</given-names></name></person-group><article-title>The emotional movie database (EMDB): a self-report and psychophysiological study</article-title><source>Applied Psychophysiology and Biofeedback</source><issue>4</issue><year>2012</year><volume>37</volume><fpage>279</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1007/s10484-012-9201-6</pub-id><pub-id pub-id-type="pmid">22767079</pub-id></element-citation></ref><ref id="ref-19"><label>Cha et al. (2009)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cha</surname><given-names>KR</given-names></name><name><surname>Eid</surname><given-names>M</given-names></name><name><surname>Barghout</surname><given-names>A</given-names></name><name><surname>Rahman</surname><given-names>ASMM</given-names></name><name><surname>El Saddik</surname><given-names>A</given-names></name></person-group><article-title>HugMe: synchronous haptic teleconferencing</article-title><conf-name>Proceedings of the 17th ACM international conference on multimedia MM &#x02019;09</conf-name><year>2009</year><conf-sponsor>ACM</conf-sponsor><conf-loc>New York</conf-loc><fpage>1135</fpage><lpage>1136</lpage></element-citation></ref><ref id="ref-20"><label>Chang (2001)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>SO</given-names></name></person-group><article-title>The conceptual structure of physical touch in caring</article-title><source>Journal of Advanced Nursing</source><issue>6</issue><year>2001</year><volume>33</volume><fpage>820</fpage><lpage>827</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2648.2001.01721.x</pub-id><pub-id pub-id-type="pmid">11298220</pub-id></element-citation></ref><ref id="ref-21"><label>Cranny-Francis (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cranny-Francis</surname><given-names>A</given-names></name></person-group><article-title>Semefulness: a social semiotics of touch</article-title><source>Social Semiotics</source><issue>4</issue><year>2011</year><volume>21</volume><fpage>463</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1080/10350330.2011.591993</pub-id></element-citation></ref><ref id="ref-22"><label>Davydov, Zech &#x00026; Luminet (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davydov</surname><given-names>DM</given-names></name><name><surname>Zech</surname><given-names>E</given-names></name><name><surname>Luminet</surname><given-names>O</given-names></name></person-group><article-title>Affective context of sadness and physiological response patterns</article-title><source>Journal of Psychophysiology</source><issue>2</issue><year>2011</year><volume>25</volume><fpage>67</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1027/0269-8803/a000031</pub-id></element-citation></ref><ref id="ref-23"><label>Debrot et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debrot</surname><given-names>A</given-names></name><name><surname>Schoebi</surname><given-names>D</given-names></name><name><surname>Perrez</surname><given-names>M</given-names></name><name><surname>Horn</surname><given-names>AB</given-names></name></person-group><article-title>Touch as an interpersonal emotion regulation process in couples&#x02019; daily lives: the mediating role of psychological intimacy</article-title><source>Personality and Social Psychology Bulletin</source><issue>10</issue><year>2013</year><volume>39</volume><fpage>1373</fpage><lpage>1385</lpage><pub-id pub-id-type="doi">10.1177/0146167213497592</pub-id><pub-id pub-id-type="pmid">23885034</pub-id></element-citation></ref><ref id="ref-24"><label>Debrot et al. (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debrot</surname><given-names>A</given-names></name><name><surname>Schoebi</surname><given-names>D</given-names></name><name><surname>Perrez</surname><given-names>M</given-names></name><name><surname>Horn</surname><given-names>AB</given-names></name></person-group><article-title>Stroking your beloved one&#x02019;s white bear: responsive touch by the romantic partner buffers the negative effects of thought suppression on daily mood</article-title><source>Journal of Social and Clinical Psychology</source><issue>1</issue><year>2014</year><volume>33</volume><fpage>75</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1521/jscp.2014.33.1.75</pub-id></element-citation></ref><ref id="ref-25"><label>Dolin &#x00026; Booth-Butterfield (1993)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolin</surname><given-names>DJ</given-names></name><name><surname>Booth-Butterfield</surname><given-names>M</given-names></name></person-group><article-title>Reach out and touch someone: analysis of nonverbal comforting responses</article-title><source>Communication Quarterly</source><issue>4</issue><year>1993</year><volume>41</volume><fpage>383</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1080/01463379309369899</pub-id></element-citation></ref><ref id="ref-26"><label>Ellard, Farchione &#x00026; Barlow (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ellard</surname><given-names>KK</given-names></name><name><surname>Farchione</surname><given-names>TJ</given-names></name><name><surname>Barlow</surname><given-names>DH</given-names></name></person-group><article-title>Relative effectiveness of emotion induction procedures and the role of personal relevance in a clinical ample: a comparison of film, images, and music</article-title><source>Journal of Psychopatholy and Behavioral Assessment</source><issue>2</issue><year>2012</year><volume>34</volume><fpage>232</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1007/s10862-011-9271-4</pub-id></element-citation></ref><ref id="ref-27"><label>Fern&#x000e1;ndez et al. (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fern&#x000e1;ndez</surname><given-names>C</given-names></name><name><surname>Pascual</surname><given-names>J</given-names></name><name><surname>Soler</surname><given-names>J</given-names></name><name><surname>Elices</surname><given-names>M</given-names></name><name><surname>Portella</surname><given-names>M</given-names></name><name><surname>Fern&#x000e1;ndez-Abascal</surname><given-names>E</given-names></name></person-group><article-title>Physiological responses induced by emotion-eliciting films</article-title><source>Applied Psychophysiology and Biofeedback</source><issue>2</issue><year>2012</year><volume>37</volume><fpage>73</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1007/s10484-012-9180-7</pub-id><pub-id pub-id-type="pmid">22311202</pub-id></element-citation></ref><ref id="ref-28"><label>Field (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Field</surname><given-names>T</given-names></name></person-group><article-title>Touch for socioemotional and physical well-being: a review</article-title><source>Developmental Review</source><issue>4</issue><year>2010</year><volume>30</volume><fpage>367</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1016/j.dr.2011.01.001</pub-id></element-citation></ref><ref id="ref-29"><label>Gallace &#x00026; Spence (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallace</surname><given-names>A</given-names></name><name><surname>Spence</surname><given-names>C</given-names></name></person-group><article-title>The science of interpersonal touch: an overview</article-title><source>Neuroscience &#x00026; Biobehavioral Reviews</source><issue>2</issue><year>2010</year><volume>34</volume><fpage>246</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2008.10.004</pub-id><pub-id pub-id-type="pmid">18992276</pub-id></element-citation></ref><ref id="ref-30"><label>Giannopoulos et al. (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giannopoulos</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Peer</surname><given-names>A</given-names></name><name><surname>Buss</surname><given-names>M</given-names></name><name><surname>Slater</surname><given-names>M</given-names></name></person-group><article-title>Comparison of people&#x02019;s responses to real and virtual handshakes within a virtual environment</article-title><source>Brain Research Bulletin</source><issue>5</issue><year>2011</year><volume>85</volume><fpage>276</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1016/j.brainresbull.2010.11.012</pub-id><pub-id pub-id-type="pmid">21112376</pub-id></element-citation></ref><ref id="ref-31"><label>Glaeser et al. (2000)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaeser</surname><given-names>EL</given-names></name><name><surname>Laibson</surname><given-names>DI</given-names></name><name><surname>Scheinkman</surname><given-names>JA</given-names></name><name><surname>Soutter</surname><given-names>CL</given-names></name></person-group><article-title>Measuring trust</article-title><source>Quarterly Journal of Economics</source><issue>3</issue><year>2000</year><volume>115</volume><fpage>811</fpage><lpage>846</lpage><pub-id pub-id-type="doi">10.1162/003355300554926</pub-id></element-citation></ref><ref id="ref-32"><label>Goldberg (1992)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>LR</given-names></name></person-group><article-title>The development of markers for the Big-Five factor structure</article-title><source>Psychological Assessment</source><issue>1</issue><year>1992</year><volume>4</volume><fpage>26</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1037/1040-3590.4.1.26</pub-id></element-citation></ref><ref id="ref-33"><label>Goldberg, Preminger &#x00026; Malach (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>H</given-names></name><name><surname>Preminger</surname><given-names>S</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><article-title>The emotion-action link? Naturalistic emotional stimuli preferentially activate the human dorsal visual stream</article-title><source>Neuroimage</source><year>2014</year><volume>84</volume><fpage>254</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.032</pub-id><pub-id pub-id-type="pmid">23994457</pub-id></element-citation></ref><ref id="ref-34"><label>Gross &#x00026; Levenson (1995)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>JJ</given-names></name><name><surname>Levenson</surname><given-names>RW</given-names></name></person-group><article-title>Emotion elicitation using films</article-title><source>Cognition and Emotion</source><issue>1</issue><year>1995</year><volume>9</volume><fpage>87</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1080/02699939508408966</pub-id></element-citation></ref><ref id="ref-35"><label>Gu&#x000e9;guen &#x00026; Fischer-Lokou (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu&#x000e9;guen</surname><given-names>N</given-names></name><name><surname>Fischer-Lokou</surname><given-names>J</given-names></name></person-group><article-title>Tactile contact and spontaneous help: an evaluation in a natural setting</article-title><source>The Journal of Social Psychology</source><issue>6</issue><year>2003</year><volume>143</volume><fpage>785</fpage><lpage>787</lpage><pub-id pub-id-type="doi">10.1080/00224540309600431</pub-id><pub-id pub-id-type="pmid">14658752</pub-id></element-citation></ref><ref id="ref-36"><label>Gunes &#x00026; Pantic (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gunes</surname><given-names>H</given-names></name><name><surname>Pantic</surname><given-names>M</given-names></name></person-group><article-title>Automatic, dimensional and continuous emotion recognition</article-title><source>International Journal of Synthetic Emotions</source><issue>1</issue><year>2010</year><volume>1</volume><fpage>68</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.4018/jse.2010101605</pub-id></element-citation></ref><ref id="ref-37"><label>Haans, de Bruijn &#x00026; IJsselsteijn (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haans</surname><given-names>A</given-names></name><name><surname>De Bruijn</surname><given-names>R</given-names></name><name><surname>IJsselsteijn</surname><given-names>WA</given-names></name></person-group><article-title>A virtual midas touch? Touch, compliance, and confederate bias in mediated communication</article-title><source>Journal of Nonverbal Behavior</source><issue>3</issue><year>2014</year><volume>38</volume><fpage>301</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1007/s10919-014-0184-2</pub-id></element-citation></ref><ref id="ref-38"><label>Haans &#x00026; IJsselsteijn (2006)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haans</surname><given-names>A</given-names></name><name><surname>IJsselsteijn</surname><given-names>W</given-names></name></person-group><article-title>Mediated social touch: a review of current research and future directions</article-title><source>Virtual Reality</source><issue>2</issue><year>2006</year><volume>9</volume><fpage>149</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1007/s10055-005-0014-2</pub-id></element-citation></ref><ref id="ref-39"><label>Haans &#x00026; IJsselsteijn (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haans</surname><given-names>A</given-names></name><name><surname>IJsselsteijn</surname><given-names>WA</given-names></name></person-group><article-title>The virtual midas touch: helping behavior after a mediated social touch</article-title><source>IEEE Transactions on Haptics</source><issue>3</issue><year>2009</year><volume>2</volume><fpage>136</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1109/TOH.2009.20</pub-id></element-citation></ref><ref id="ref-40"><label>Hammick &#x00026; Lee (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammick</surname><given-names>JK</given-names></name><name><surname>Lee</surname><given-names>MJ</given-names></name></person-group><article-title>Do shy people feel less communication apprehension online? The effects of virtual reality on the relationship between personality characteristics and communication outcomes</article-title><source>Computers in Human Behavior</source><issue>0</issue><year>2014</year><volume>33</volume><fpage>302</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1016/j.chb.2013.01.046</pub-id></element-citation></ref><ref id="ref-41"><label>Handy (1995)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Handy</surname><given-names>C</given-names></name></person-group><article-title>Trust and the virtual organization</article-title><source>Harvard Business Review</source><issue>3</issue><year>1995</year><volume>73</volume><fpage>40</fpage><lpage>50</lpage></element-citation></ref><ref id="ref-42"><label>Hertenstein et al. (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertenstein</surname><given-names>MJ</given-names></name><name><surname>Holmes</surname><given-names>R</given-names></name><name><surname>McCullough</surname><given-names>M</given-names></name><name><surname>Keltner</surname><given-names>D</given-names></name></person-group><article-title>The communication of emotion via touch</article-title><source>Emotion</source><issue>4</issue><year>2009</year><volume>9</volume><fpage>566</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1037/a0016108</pub-id><pub-id pub-id-type="pmid">19653781</pub-id></element-citation></ref><ref id="ref-43"><label>Hertenstein et al. (2006)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertenstein</surname><given-names>MJ</given-names></name><name><surname>Keltner</surname><given-names>D</given-names></name><name><surname>App</surname><given-names>B</given-names></name><name><surname>Bulleit</surname><given-names>BA</given-names></name><name><surname>Jaskolka</surname><given-names>AR</given-names></name></person-group><article-title>Touch communicates distinct emotions</article-title><source>Emotion</source><issue>3</issue><year>2006</year><volume>6</volume><fpage>528</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1037/1528-3542.6.3.528</pub-id><pub-id pub-id-type="pmid">16938094</pub-id></element-citation></ref><ref id="ref-44"><label>Hoggan et al. (2012)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hoggan</surname><given-names>E</given-names></name><name><surname>Stewart</surname><given-names>C</given-names></name><name><surname>Haverinen</surname><given-names>L</given-names></name><name><surname>Jacucci</surname><given-names>G</given-names></name><name><surname>Lantz</surname><given-names>V</given-names></name></person-group><article-title>Pressages: augmenting phone calls with non-verbal messages</article-title><conf-name>Proceedings of the 25th annual ACM symposium on user interface software and technology (UIST &#x02019;12)</conf-name><year>2012</year><conf-sponsor>ACM</conf-sponsor><conf-loc>New York</conf-loc><fpage>555</fpage><lpage>562</lpage></element-citation></ref><ref id="ref-45"><label>Janssen, IJsselsteijn &#x00026; Westerink (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janssen</surname><given-names>JH</given-names></name><name><surname>IJsselsteijn</surname><given-names>WA</given-names></name><name><surname>Westerink</surname><given-names>JHDM</given-names></name></person-group><article-title>How affective technologies can influence intimate interactions and improve social connectedness</article-title><source>International Journal of Human&#x02013;Computer Studies</source><issue>1</issue><year>2014</year><volume>72</volume><fpage>33</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.ijhcs.2013.09.007</pub-id></element-citation></ref><ref id="ref-46"><label>Johnson &#x00026; Grayson (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>D</given-names></name><name><surname>Grayson</surname><given-names>K</given-names></name></person-group><article-title>Cognitive and affective trust in service relationships</article-title><source>Journal of Business Research</source><issue>4</issue><year>2005</year><volume>58</volume><fpage>500</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/S0148-2963(03)00140-1</pub-id></element-citation></ref><ref id="ref-47"><label>Jones &#x00026; Yarbrough (1985)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>SE</given-names></name><name><surname>Yarbrough</surname><given-names>AE</given-names></name></person-group><article-title>A naturalistic study of the meanings of touch</article-title><source>Communication Monographs</source><issue>1</issue><year>1985</year><volume>52</volume><fpage>19</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1080/03637758509376094</pub-id></element-citation></ref><ref id="ref-48"><label>Kiesler &#x00026; Kiesler (1969)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kiesler</surname><given-names>CA</given-names></name><name><surname>Kiesler</surname><given-names>SB</given-names></name></person-group><source>Conformity</source><year>1969</year><publisher-loc>Reading</publisher-loc><publisher-name>Addison-Wesley</publisher-name></element-citation></ref><ref id="ref-49"><label>Klein (1989)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>A</given-names></name></person-group><source>The healing power of humor</source><year>1989</year><publisher-loc>Los Angeles</publisher-loc><publisher-name>Tarcher/Putnam Publishers</publisher-name></element-citation></ref><ref id="ref-50"><label>Knapp &#x00026; Hall (2010)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Knapp</surname><given-names>ML</given-names></name><name><surname>Hall</surname><given-names>JA</given-names></name></person-group><source>Nonverbal communication in human interaction</source><edition designator="7">7th edition</edition><year>2010</year><publisher-loc>Boston</publisher-loc><publisher-name>Wadsworth, CENGAGE Learning</publisher-name></element-citation></ref><ref id="ref-51"><label>Kreibig (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreibig</surname><given-names>SD</given-names></name></person-group><article-title>Autonomic nervous system activity in emotion: a review</article-title><source>Biological Psychology</source><issue>3</issue><year>2010</year><volume>84</volume><fpage>394</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2010.03.010</pub-id><pub-id pub-id-type="pmid">20371374</pub-id></element-citation></ref><ref id="ref-52"><label>Kreps (1990)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kreps</surname><given-names>DM</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Alt</surname><given-names>JE</given-names></name><name><surname>Shepsle</surname><given-names>K</given-names></name></person-group><article-title>Corporate culture and economic theory</article-title><source>Perspectives on positive political economy</source><volume>vol. 90</volume><year>1990</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>109</fpage><lpage>110</lpage></element-citation></ref><ref id="ref-53"><label>Lang (1995)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><article-title>The emotion probe: studies of motivation and attention</article-title><source>American Psychologist</source><issue>5</issue><year>1995</year><volume>50</volume><fpage>372</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.50.5.372</pub-id><pub-id pub-id-type="pmid">7762889</pub-id></element-citation></ref><ref id="ref-54"><label>Lazzarini et al. (2004)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lazzarini</surname><given-names>SG</given-names></name><name><surname>Madalozzo</surname><given-names>R</given-names></name><name><surname>Artes</surname><given-names>R</given-names></name><name><surname>De Oliveira Siqueira</surname><given-names>J</given-names></name></person-group><source>Measuring trust: an experiment in Brazil. <italic>Insper Working Papers</italic>, WPE: 049/2004</source><year>2004</year><publisher-loc>S&#x000e3;o Paulo</publisher-loc><publisher-name>Insper Instituto de Ensino e Pesquisa</publisher-name></element-citation></ref><ref id="ref-55"><label>Lovell &#x00026; Zeffirelli (1979)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lovell</surname><given-names>D</given-names></name><name><surname>Zeffirelli</surname><given-names>F</given-names></name></person-group><source>The champ [Film]</source><year>1979</year><publisher-loc>Culver City</publisher-loc><publisher-name>MGM/UA</publisher-name></element-citation></ref><ref id="ref-56"><label>Lucas et al. (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lucas</surname><given-names>MV</given-names></name><name><surname>Anderson</surname><given-names>LC</given-names></name><name><surname>Bolling</surname><given-names>DZ</given-names></name><name><surname>Pelphrey</surname><given-names>KA</given-names></name><name><surname>Kaiser</surname><given-names>MD</given-names></name></person-group><article-title>Dissociating the neural correlates of experiencing and imagining affective touch</article-title><source>Cerebral Cortex</source><issue>9</issue><year>2014</year><volume>25</volume><fpage>2623</fpage><lpage>2630</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu061</pub-id><pub-id pub-id-type="pmid">24700583</pub-id></element-citation></ref><ref id="ref-57"><label>Luminet et al. (2000)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luminet</surname><given-names>O</given-names></name><name><surname>Bouts</surname><given-names>P</given-names></name><name><surname>Delie</surname><given-names>F</given-names></name><name><surname>Manstead</surname><given-names>ASR</given-names></name><name><surname>Rim&#x000e9;</surname><given-names>B</given-names></name></person-group><article-title>Social sharing of emotion following exposure to a negatively valenced situation</article-title><source>Cognition &#x00026; Emotion</source><issue>5</issue><year>2000</year><volume>14</volume><fpage>661</fpage><lpage>688</lpage><pub-id pub-id-type="doi">10.1080/02699930050117666</pub-id></element-citation></ref><ref id="ref-58"><label>Mandryk, Inkpen &#x00026; Calvert (2006)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandryk</surname><given-names>RL</given-names></name><name><surname>Inkpen</surname><given-names>KM</given-names></name><name><surname>Calvert</surname><given-names>TW</given-names></name></person-group><article-title>Using psychophysiological techniques to measure user experience with entertainment technologies</article-title><source>Behaviour and Information Technology</source><issue>2</issue><year>2006</year><volume>25</volume><fpage>141</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1080/01449290500331156</pub-id></element-citation></ref><ref id="ref-59"><label>Mayer &#x00026; Gaschke (1988)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>JD</given-names></name><name><surname>Gaschke</surname><given-names>YN</given-names></name></person-group><article-title>The experience and meta-experience of mood</article-title><source>Journal of Personality and Social Psychology</source><issue>1</issue><year>1988</year><volume>55</volume><fpage>102</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.55.1.102</pub-id><pub-id pub-id-type="pmid">3418484</pub-id></element-citation></ref><ref id="ref-60"><label>McKenna &#x00026; Bargh (1999)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenna</surname><given-names>KYA</given-names></name><name><surname>Bargh</surname><given-names>JA</given-names></name></person-group><article-title>Causes and consequences of social interaction on the internet: a conceptual framework</article-title><source>Media Psychology</source><issue>3</issue><year>1999</year><volume>1</volume><fpage>249</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1207/s1532785xmep0103_4</pub-id></element-citation></ref><ref id="ref-61"><label>Mehrabian &#x00026; Russell (1974)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mehrabian</surname><given-names>A</given-names></name><name><surname>Russell</surname><given-names>JA</given-names></name></person-group><source>An approach to environmental psychology</source><year>1974</year><publisher-loc>Boston</publisher-loc><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="ref-62"><label>Nakanishi, Tanaka &#x00026; Wada (2014)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Nakanishi</surname><given-names>H</given-names></name><name><surname>Tanaka</surname><given-names>K</given-names></name><name><surname>Wada</surname><given-names>Y</given-names></name></person-group><article-title>Remote handshaking: touch enhances video-mediated social telepresence</article-title><conf-name>Proceedings of the SIGCHI conference on human factors in computing systems CHI&#x02019;14</conf-name><year>2014</year><conf-sponsor>ACM</conf-sponsor><conf-loc>New York</conf-loc><fpage>2143</fpage><lpage>2152</lpage></element-citation></ref><ref id="ref-63"><label>Park, Baek &#x00026; Nam (2013)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Park</surname><given-names>YW</given-names></name><name><surname>Baek</surname><given-names>KM</given-names></name><name><surname>Nam</surname><given-names>TJ</given-names></name></person-group><article-title>The roles of touch during phone conversations: long-distance couples&#x02019; use of POKE in their homes</article-title><conf-name>Proceedings of the SIGCHI conference on human factors in computing systems (CHI &#x02019;13)</conf-name><year>2013</year><conf-sponsor>ACM</conf-sponsor><conf-loc>New York</conf-loc><fpage>1679</fpage><lpage>1688</lpage></element-citation></ref><ref id="ref-64"><label>Rantala et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rantala</surname><given-names>J</given-names></name><name><surname>Salminen</surname><given-names>K</given-names></name><name><surname>Raisamo</surname><given-names>R</given-names></name><name><surname>Surakka</surname><given-names>V</given-names></name></person-group><article-title>Touch gestures in communicating emotional intention via vibrotactile stimulation</article-title><source>International Journal of Human&#x02013;Computer Studies</source><issue>6</issue><year>2013</year><volume>7</volume><fpage>679</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1016/j.ijhcs.2013.02.004</pub-id></element-citation></ref><ref id="ref-65"><label>Rim&#x000e9; (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rim&#x000e9;</surname><given-names>B</given-names></name></person-group><article-title>Emotion elicits the social sharing of emotion: theory and empirical review</article-title><source>Emotion Review</source><issue>1</issue><year>2009</year><volume>1</volume><fpage>60</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1177/1754073908097189</pub-id></element-citation></ref><ref id="ref-66"><label>Rizzolatti et al. (1999)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Fadiga</surname><given-names>L</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name></person-group><article-title>Resonance behaviors and mirror neurons</article-title><source>Archives Italiennes de Biologie</source><issue>2&#x02013;3</issue><year>1999</year><volume>137</volume><fpage>85</fpage><lpage>100</lpage><pub-id pub-id-type="pmid">10349488</pub-id></element-citation></ref><ref id="ref-67"><label>Robinson &#x00026; Smith-Lovin (2001)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>DT</given-names></name><name><surname>Smith-Lovin</surname><given-names>L</given-names></name></person-group><article-title>Getting a laugh: gender, status, and humor in task discussions</article-title><source>Social Forces</source><issue>1</issue><year>2001</year><volume>80</volume><fpage>123</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1353/sof.2001.0085</pub-id></element-citation></ref><ref id="ref-68"><label>Rottenberg, Ray &#x00026; Gross (2007)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rottenberg</surname><given-names>J</given-names></name><name><surname>Ray</surname><given-names>RR</given-names></name><name><surname>Gross</surname><given-names>JJ</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Coan</surname><given-names>JA</given-names></name><name><surname>Allen</surname><given-names>JJB</given-names></name></person-group><article-title>Emotion elicitation using films</article-title><source>Handbook of emotion elicitation and assessment. Series in affective science</source><year>2007</year><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>9</fpage><lpage>28</lpage></element-citation></ref><ref id="ref-69"><label>Rubin et al. (2009)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>RB</given-names></name><name><surname>Rubin</surname><given-names>AM</given-names></name><name><surname>Perse</surname><given-names>EM</given-names></name><name><surname>Graham</surname><given-names>E</given-names></name><name><surname>Seibold</surname><given-names>D</given-names></name></person-group><source>Communication research measures II. A sourcebook</source><year>2009</year><publisher-loc>New York</publisher-loc><publisher-name>Routledge</publisher-name></element-citation></ref><ref id="ref-70"><label>Russell, Weiss &#x00026; Mendelson (1989)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>JA</given-names></name><name><surname>Weiss</surname><given-names>A</given-names></name><name><surname>Mendelson</surname><given-names>GA</given-names></name></person-group><article-title>Affect grid: a single-item scale of pleasure and arousal</article-title><source>Journal of Personality and Social Psychology</source><issue>3</issue><year>1989</year><volume>57</volume><fpage>493</fpage><lpage>502</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.57.3.493</pub-id></element-citation></ref><ref id="ref-71"><label>Salminen et al. (2008)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Salminen</surname><given-names>K</given-names></name><name><surname>Surakka</surname><given-names>V</given-names></name><name><surname>Lylykangas</surname><given-names>J</given-names></name><name><surname>Raisamo</surname><given-names>R</given-names></name><name><surname>Saarinen</surname><given-names>R</given-names></name><name><surname>Raisamo</surname><given-names>R</given-names></name><name><surname>Rantala</surname><given-names>J</given-names></name><name><surname>Evreinov</surname><given-names>G</given-names></name></person-group><article-title>Emotional and behavioral responses to haptic stimulation</article-title><conf-name>Proceeding of the twenty-sixth annual SIGCHI conference on human factors in computing systems</conf-name><year>2008</year><conf-sponsor>ACM Press</conf-sponsor><conf-loc>New York</conf-loc><fpage>1555</fpage><lpage>1562</lpage></element-citation></ref><ref id="ref-72"><label>Salminen et al. (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salminen</surname><given-names>K</given-names></name><name><surname>Surakka</surname><given-names>V</given-names></name><name><surname>Lylykangas</surname><given-names>J</given-names></name><name><surname>Rantala</surname><given-names>J</given-names></name><name><surname>Ahmaniemi</surname><given-names>T</given-names></name><name><surname>Raisamo</surname><given-names>R</given-names></name><name><surname>Trendafilov</surname><given-names>D</given-names></name><name><surname>Kildal</surname><given-names>J</given-names></name></person-group><article-title>Tactile modulation of emotional speech samples</article-title><source>Advances in Human&#x02013;Computer Interaction</source><year>2012</year><volume>2012</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1155/2012/741304</pub-id></element-citation></ref><ref id="ref-73"><label>Schaefer et al. (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Collette</surname><given-names>F</given-names></name><name><surname>Philippot</surname><given-names>P</given-names></name><name><surname>Linden</surname><given-names>MVd</given-names></name><name><surname>Laureys</surname><given-names>S</given-names></name><name><surname>Delfiore</surname><given-names>G</given-names></name><name><surname>Degueldre</surname><given-names>C</given-names></name><name><surname>Maquet</surname><given-names>P</given-names></name><name><surname>Luxen</surname><given-names>A</given-names></name><name><surname>Salmon</surname><given-names>E</given-names></name></person-group><article-title>Neural correlates of &#x0201c;hot&#x0201d; and &#x0201c;cold&#x0201d; emotional processing: a multilevel approach to the functional anatomy of emotion</article-title><source>Neuroimage</source><issue>4</issue><year>2003</year><volume>18</volume><fpage>938</fpage><lpage>949</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00009-0</pub-id><pub-id pub-id-type="pmid">12725769</pub-id></element-citation></ref><ref id="ref-74"><label>Schifferstein &#x00026; Zwartkruis-Pelgrim (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schifferstein</surname><given-names>HNJ</given-names></name><name><surname>Zwartkruis-Pelgrim</surname><given-names>PH</given-names></name></person-group><article-title>Consumer-product attachment: measurement and design implications</article-title><source>International Journal of Design</source><issue>3</issue><year>2008</year><volume>2</volume><fpage>1</fpage><lpage>13</lpage></element-citation></ref><ref id="ref-75"><label>Shalom et al. (2015)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shalom</surname><given-names>JG</given-names></name><name><surname>Israeli</surname><given-names>H</given-names></name><name><surname>Markovitzky</surname><given-names>O</given-names></name><name><surname>Lipsitz</surname><given-names>JD</given-names></name></person-group><article-title>Social anxiety and physiological arousal during computer mediated vs. face to face communication</article-title><source>Computers in Human Behavior</source><year>2015</year><volume>44</volume><fpage>202</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.chb.2014.11.056</pub-id></element-citation></ref><ref id="ref-76"><label>Smith &#x00026; MacLean (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>J</given-names></name><name><surname>MacLean</surname><given-names>K</given-names></name></person-group><article-title>Communicating emotion through a haptic link: design space and methodology</article-title><source>International Journal of Human&#x02013;Computer Studies</source><issue>4</issue><year>2007</year><volume>65</volume><fpage>376</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1016/j.ijhcs.2006.11.006</pub-id></element-citation></ref><ref id="ref-77"><label>Soussignan (2002)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soussignan</surname><given-names>R</given-names></name></person-group><article-title>Duchenne smile, emotional experience, and autonomic reactivity: a test of the facial feedback hypothesis</article-title><source>Emotion</source><issue>1</issue><year>2002</year><volume>2</volume><fpage>52</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1037/1528-3542.2.1.52</pub-id><pub-id pub-id-type="pmid">12899366</pub-id></element-citation></ref><ref id="ref-78"><label>Spap&#x000e9; et al. (2015)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spap&#x000e9;</surname><given-names>MM</given-names></name><name><surname>Hoggan</surname><given-names>EE</given-names></name><name><surname>Jacucci</surname><given-names>G</given-names></name><name><surname>Ravaja</surname><given-names>N</given-names></name></person-group><article-title>The meaning of the virtual Midas touch: an ERP study in economic decision making</article-title><source>Psychophysiology</source><issue>3</issue><year>2015</year><volume>52</volume><fpage>378</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1111/psyp.12361</pub-id><pub-id pub-id-type="pmid">25265874</pub-id></element-citation></ref><ref id="ref-79"><label>Takahashi et al. (2011)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Mitsuhashi</surname><given-names>H</given-names></name><name><surname>Murata</surname><given-names>K</given-names></name><name><surname>Norieda</surname><given-names>S</given-names></name><name><surname>Watanabe</surname><given-names>K</given-names></name></person-group><article-title>Improving shared experiences by haptic telecommunication</article-title><conf-name>2011 international conference on biometrics and kansei engineering (ICBAKE)</conf-name><year>2011</year><conf-sponsor>IEEE</conf-sponsor><conf-loc>Los Alamitos</conf-loc><fpage>210</fpage><lpage>215</lpage></element-citation></ref><ref id="ref-80"><label>Toet et al. (2013)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Toet</surname><given-names>A</given-names></name><name><surname>Van Erp</surname><given-names>JBF</given-names></name><name><surname>Petrignani</surname><given-names>FF</given-names></name><name><surname>Dufrasnes</surname><given-names>MH</given-names></name><name><surname>Sadhashivan</surname><given-names>A</given-names></name><name><surname>Van Alphen</surname><given-names>D</given-names></name><name><surname>Boeree</surname><given-names>F</given-names></name><name><surname>De Gruijter</surname><given-names>HO</given-names></name><name><surname>Hoeksema</surname><given-names>J</given-names></name><name><surname>Stamhuis</surname><given-names>CT</given-names></name><name><surname>Steenbergen</surname><given-names>PJ</given-names></name></person-group><article-title>Reach out and touch somebody&#x02019;s virtual hand. Affectively connected through mediated touch</article-title><conf-name>Proceedings of the 2013 humaine association conference on affective computing and intelligent interaction</conf-name><year>2013</year><conf-sponsor>IEEE Computer Society</conf-sponsor><conf-loc>Piscataway</conf-loc><fpage>786</fpage><lpage>791</lpage></element-citation></ref><ref id="ref-81"><label>Tolmie &#x00026; Boyle (2000)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolmie</surname><given-names>A</given-names></name><name><surname>Boyle</surname><given-names>J</given-names></name></person-group><article-title>Factors influencing the success of computer mediated communication (CMC) environments in university teaching: a review and case study</article-title><source>Computers &#x00026; Education</source><issue>2</issue><year>2000</year><volume>34</volume><fpage>119</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/S0360-1315(00)00008-7</pub-id></element-citation></ref><ref id="ref-82"><label>Tsetserukou et al. (2009)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tsetserukou</surname><given-names>D</given-names></name><name><surname>Neviarouskaya</surname><given-names>A</given-names></name><name><surname>Prendinger</surname><given-names>H</given-names></name><name><surname>Kawakami</surname><given-names>N</given-names></name><name><surname>Ishizuka</surname><given-names>M</given-names></name><name><surname>Tachi</surname><given-names>S</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Smith</surname><given-names>MJ</given-names></name><name><surname>Salvendy</surname><given-names>G</given-names></name></person-group><article-title>iFeel_ IM! Emotion enhancing garment for communication in affect sensitive instant messenger</article-title><conf-name>Proceedings of the symposium on human interface (HCII 2009). Part I</conf-name><year>2009</year><conf-sponsor>Springer-Verlag</conf-sponsor><conf-loc>Berlin-Heidelberg</conf-loc><fpage>628</fpage><lpage>637</lpage></element-citation></ref><ref id="ref-83"><label>Van Erp &#x00026; Toet (2015)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Erp</surname><given-names>JBF</given-names></name><name><surname>Toet</surname><given-names>A</given-names></name></person-group><article-title>Social touch in human computer interaction</article-title><source>Frontiers in Digital Humanities</source><issue>Article 2</issue><year>2015</year><volume>2</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3389/fdigh.2015.00002</pub-id></element-citation></ref><ref id="ref-84"><label>Van Heck et al. (1994)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Heck</surname><given-names>GL</given-names></name><name><surname>Perugini</surname><given-names>M</given-names></name><name><surname>Caprara</surname><given-names>GV</given-names></name><name><surname>Fr&#x000f6;ger</surname><given-names>J</given-names></name></person-group><article-title>The big five as tendencies in situations</article-title><source>Personality and Individual Differences</source><issue>5</issue><year>1994</year><volume>16</volume><fpage>715</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1016/0191-8869(94)90213-5</pub-id></element-citation></ref><ref id="ref-85"><label>Whitcher &#x00026; Fisher (1979)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitcher</surname><given-names>SJ</given-names></name><name><surname>Fisher</surname><given-names>JD</given-names></name></person-group><article-title>Multidimensional reaction to therapeutic touch in a hospital setting</article-title><source>Journal of Personality and Social Psychology</source><issue>1</issue><year>1979</year><volume>37</volume><fpage>87</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.37.1.87</pub-id><pub-id pub-id-type="pmid">458550</pub-id></element-citation></ref><ref id="ref-86"><label>World Medical Association (2000)</label><element-citation publication-type="journal"><person-group person-group-type="author"><collab><institution>World Medical Association</institution></collab></person-group><article-title>World medical association declaration of Helsinki: ethical principles for medical research involving human subjects</article-title><source>The Journal of the American Medical Association</source><issue>23</issue><year>2000</year><volume>284</volume><fpage>3043</fpage><lpage>3045</lpage><pub-id pub-id-type="doi">10.1001/jama.284.23.3043</pub-id><pub-id pub-id-type="pmid">11122593</pub-id></element-citation></ref><ref id="ref-87"><label>Zheng et al. (2002)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Veinott</surname><given-names>E</given-names></name><name><surname>Bos</surname><given-names>N</given-names></name><name><surname>Olson</surname><given-names>JS</given-names></name><name><surname>Olson</surname><given-names>GM</given-names></name></person-group><article-title>Trust without touch: jumpstarting long-distance trust with initial social activities</article-title><conf-name>Proceedings of the SIGCHI conference on human factors in computing systems (CHI &#x02019;02)</conf-name><year>2002</year><conf-sponsor>ACM</conf-sponsor><conf-loc>New York</conf-loc><fpage>141</fpage><lpage>146</lpage></element-citation></ref></ref-list></back></article>