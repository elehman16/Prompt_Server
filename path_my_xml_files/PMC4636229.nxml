<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26544974</article-id><article-id pub-id-type="pmc">4636229</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0141981</article-id><article-id pub-id-type="publisher-id">PONE-D-15-24922</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>A New Extension of the Binomial Error Model for Responses to Items of Varying Difficulty in Educational Testing and Attitude Surveys</article-title><alt-title alt-title-type="running-head">A New Extension of the Binomial Error Model</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wiley</surname><given-names>James A.</given-names></name><xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Martin</surname><given-names>John Levi</given-names></name><xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Herschkorn</surname><given-names>Stephen J.</given-names></name><xref ref-type="aff" rid="aff003">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Bond</surname><given-names>Jason</given-names></name><xref ref-type="aff" rid="aff004">
<sup>4</sup>
</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Department of Family and Community Medicine and Institute for Health Policy Studies, School of Medicine, University of California San Francisco, San Francisco, California, United States of America</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Sociology Department, University of Chicago, Chicago, Illinois, United States of America</addr-line>
</aff><aff id="aff003">
<label>3</label>
<addr-line>Department of Mathematics, College of Staten Island, New York City, New York, United States of America</addr-line>
</aff><aff id="aff004">
<label>4</label>
<addr-line>Alcohol Research Group, Emeryville, California, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Rapallo</surname><given-names>Fabio</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>University of East Piedmont, ITALY</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con" id="contrib001"><p>Analyzed the data: JAW JLM JB. Contributed reagents/materials/analysis tools: JAW. Wrote the paper: JAW JLM. Mathematical solutions: SJH. Identifiability checks: SJH. Algorithm: SJH JLM JAW. Programming: JLM JB.</p></fn><corresp id="cor001">* E-mail: <email>jlmartin@uchicago.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>6</day><month>11</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>10</volume><issue>11</issue><elocation-id>e0141981</elocation-id><history><date date-type="received"><day>8</day><month>6</month><year>2015</year></date><date date-type="accepted"><day>15</day><month>10</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; 2015 Wiley et al</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Wiley et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:type="simple" xlink:href="pone.0141981.pdf"/><abstract><p>We put forward a new item response model which is an extension of the binomial error model first introduced by Keats and Lord. Like the binomial error model, the basic latent variable can be interpreted as a probability of responding in a certain way to an arbitrarily specified item. For a set of dichotomous items, this model gives predictions that are similar to other single parameter IRT models (such as the Rasch model) but has certain advantages in more complex cases. The first is that in specifying a flexible two-parameter Beta distribution for the latent variable, it is easy to formulate models for randomized experiments in which there is no reason to believe that either the latent variable or its distribution vary over randomly composed experimental groups. Second, the elementary response function is such that extensions to more complex cases (e.g., polychotomous responses, unfolding scales) are straightforward. Third, the probability metric of the latent trait allows tractable extensions to cover a wide variety of stochastic response processes.</p></abstract><funding-group><funding-statement>The authors have no support or funding to report.</funding-statement></funding-group><counts><fig-count count="0"/><table-count count="6"/><page-count count="16"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>In this paper we introduce a class of item response models for the analysis of response distributions derived from survey data. The simplest item response function in this class is a generalization of the binomial error model for ability testing of Keats and Lord [<xref rid="pone.0141981.ref001" ref-type="bibr">1</xref>]. Similar item response functions were considered briefly by Lazarsfeld [<xref rid="pone.0141981.ref002" ref-type="bibr">2</xref>] and Coleman [<xref rid="pone.0141981.ref003" ref-type="bibr">3</xref>] but not implemented as models for response data. The distinguishing characteristic of the approach taken here is that the probability of an item response is written as a function of a latent variable that can also be interpreted as a probability. The choice of a probability metric suggests the Beta density as a natural choice to model the distribution of the latent variable. Furthermore, a response function formulated in this way is easy to modify to accommodate variations in the nature and complexity of response tasks.</p><p>We first introduce the extended binomial error (EBE) model as a generalization of the binomial error model. We discuss issues of identifiability, estimation and fit, and give two examples, one for a single sample, and another for data from two independent samples, noting the similarities in fit between the extended binomial error and loglinear Rasch models. Finally, we discuss extensions for polychotomous data and for modeling responses produced by non-cumulative response functions.</p><p>The resulting class of models have special utility for the investigation of substantively important questions about the nature of response (as opposed to scoring long tests), Further, in contrast to the loglinear Rasch models that have been most influential in sociology due to the work of Duncan [<xref rid="pone.0141981.ref004" ref-type="bibr">4</xref>] in particular, this approach allows us to make strong assertions about the social <italic>distribution</italic> of the latent trait.</p></sec><sec id="sec002"><title>The Extended Binomial Error Model</title><sec id="sec003"><title>Introducing item difficulty into the binomial error model for dichotomous responses</title><p>The binomial error model for test scores was introduced by Keats and Lord [<xref rid="pone.0141981.ref001" ref-type="bibr">1</xref>] [<xref rid="pone.0141981.ref005" ref-type="bibr">5</xref>] as a strong true score theory for dichotomous test items of more or less equal difficulty. This model is based on the assumption that the conditional distribution of the observed score given the true score (conceived as a theoretical &#x0201c;proportion correct&#x0201d; measure) is binomial, with the true score playing the role of the constant probability of a correct answer in <italic>M</italic> independent trials where <italic>M</italic> is the number of items. With no additional specifications, Keats and Lord were able to show that the first <italic>M</italic> moments of the true score distribution can be determined from the moments of the observed score distribution. Furthermore, they showed [<xref rid="pone.0141981.ref006" ref-type="bibr">6</xref>] that a linear regression of true on observed score implies and is implied by a negative hypergeometric distribution of the observed scores. They also proved that a two-parameter Beta distribution for the true scores implies a linear regression of true score on observed score and a negative hypergeometric distribution for the observed scores.</p><p>Of course, it is infrequent that we analyze a set of dichotomous items with the same levels of difficulty (see also [<xref rid="pone.0141981.ref007" ref-type="bibr">7</xref>]); hence Keats and Lord indirectly incorporated variations in item difficulties in their compound binomial model, which accordingly lost many of the most attractive features of the binomial error model. Some other modifications of the binomial error assumptions have been proposed [<xref rid="pone.0141981.ref008" ref-type="bibr">8</xref>], but these are not often implemented as IRT models.</p><p>We propose to modify the binomial error model by direct incorporation of item-difficulty parameters and by assuming a bounded proportion-like latent trait. The model assumptions allow a compact expression for the probability of any observed response pattern in terms of item-difficulty parameters and the parameters of the distribution of the latent trait, assumed to be two-parameter Beta. This expression leads in turn to an algorithm for simultaneous ML estimation of both sets of parameters. In contrast to a Rasch model, therefore, our estimation of item parameters is not separable from the estimation of person parameters; the advantage of specifying a flexible family of distributions like the Beta comes in the capacity to easily analyze factorial experiments in which either the trait, or item hardnesses, or both may be affected by treatments, as we show below.</p></sec><sec id="sec004"><title>A Generalization</title><p>Let <bold>x</bold> = [<italic>x</italic>
<sub>1</sub>, <italic>x</italic>
<sub>2</sub>,..,<italic>x</italic>
<sub>M</sub>] be a response vector for a set of <italic>M</italic> dichotomous items, coded so that <italic>x</italic>
<sub>i</sub> = 1 implies completion of a task related to some underlying ability or acceptance of a statement consistent with some hypothesized underlying attitude dimension and <italic>x</italic>
<sub>i</sub> = 0 otherwise. (The 1/0 coding of responses is arbitrary but useful in writing down the probabilities associated with complete response patterns.) Consider a latent variable <italic>y</italic>, where 0&#x0003c;<italic>y</italic>&#x0003c;1, and let the difficulty of the i<sup>th</sup> item be <italic>k</italic>
<sub>i</sub> (<italic>k</italic>
<sub>i</sub>&#x0003e;0 for all i). We propose the simple response function
<disp-formula id="pone.0141981.e001"><alternatives><graphic xlink:href="pone.0141981.e001.jpg" id="pone.0141981.e001g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>i</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mtext>i</mml:mtext></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
The conditional probability of any set of <italic>M</italic> responses under conditional independence is
<disp-formula id="pone.0141981.e002"><alternatives><graphic xlink:href="pone.0141981.e002.jpg" id="pone.0141981.e002g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
and the unconditional probability is
<disp-formula id="pone.0141981.e003"><alternatives><graphic xlink:href="pone.0141981.e003.jpg" id="pone.0141981.e003g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M3"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mi>&#x003c6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
where &#x003d5;(<italic>y</italic>) is the density of <italic>y</italic>.</p><p>There are a number of advantages to constructing the model using the form of <xref rid="pone.0141981.e001" ref-type="disp-formula">Eq 1</xref>, as the latent trait may be interpreted as the probability of answering standardized (<italic>k</italic>
<sub>i</sub> = 1) item in a positive direction. However, a complication arises for the interpretation of standard errors of the <italic>k</italic> parameters given that they must be strictly non-negative. As is the case for other models with necessarily non-negative parameters (such as models for variances), the standard errors cannot be interpreted symmetrically; indeed, in cases of very poor fit, standard errors may imply that the true population value might quite plausibly be negative. When the model fits well, these issues are minor, but it makes sense to carry out statistical tests on the equivalence of <italic>k</italic> parameters not by comparison of standard errors, but by the comparison of chi-squares of nested models constraining or not constraining parameters to be equal. If the use of confidence intervals is required, one can rewrite the item response function as a double-exponential whose argument is the difference between an unbounded latent variable <italic>&#x003be;</italic> and an unbounded item difficulty parameter &#x003c7;<sub>i</sub>, where <italic>&#x003be;</italic> = -log[-log(<italic>y</italic>)] and &#x003c7;<sub>i</sub> = log(<italic>k</italic>
<sub>i</sub>), <italic>&#x003be;</italic>, -&#x0221e;&#x0003c; <italic>&#x003be;</italic>, &#x003c7;<sub>i</sub> &#x0003c;+&#x0221e;. Thus we can write
<disp-formula id="pone.0141981.e004"><alternatives><graphic xlink:href="pone.0141981.e004.jpg" id="pone.0141981.e004g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mrow><mml:mo>]</mml:mo><mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mo>[</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003be;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003c7;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
We note, however, that in contrast to a Rasch model, <xref rid="pone.0141981.e004" ref-type="disp-formula">Eq 4</xref> does not imply equiprobability when &#x003be; = &#x003c7;<sub>i</sub>; instead, Pr[<italic>x</italic>
<sub>i</sub> = 1|&#x003be;] = .5 when (&#x003be;-&#x003c7;<sub>i</sub>) = -.3665. Given that <xref rid="pone.0141981.e001" ref-type="disp-formula">Eq 1</xref> has the more intuitive relation to a probability statement, we prefer this for the development of a family of models for stochastic response.</p><p>The choice of a probability metric suggests the Beta density as a natural choice to model the distribution of the latent variable, as it, like a probability, is defined for the interval [0,1]. Thus we propose:
<disp-formula id="pone.0141981.e005"><alternatives><graphic xlink:href="pone.0141981.e005.jpg" id="pone.0141981.e005g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>a</mml:mo><mml:mo>+</mml:mo><mml:mo>b</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic>a</italic>, <italic>b</italic>&#x0003e;0, 0&#x0003c;<italic>y</italic>&#x0003c;1, and &#x00393; is the complete gamma function. (We note that such a specification was suggested but not implemented by Lazarsfeld [<xref rid="pone.0141981.ref002" ref-type="bibr">2</xref>].) Note that E[<italic>y</italic>] = <italic>a</italic>/(<italic>a+b</italic>); V[<italic>y</italic>] = <italic>ab</italic>/[(<italic>a+b</italic>)<sup>2</sup>(<italic>a+b</italic>+1)]. For <italic>k</italic>
<sub>i</sub> = <italic>k</italic> for all i, this leads to the binomial error model with a Beta density for the latent trait, sometimes called the beta-binomial model [<xref rid="pone.0141981.ref007" ref-type="bibr">7</xref>].</p><p>It can be shown that given this density, for any <italic>k</italic>&#x0003e;0,
<disp-formula id="pone.0141981.e006"><alternatives><graphic xlink:href="pone.0141981.e006.jpg" id="pone.0141981.e006g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>a</mml:mo><mml:mo>+</mml:mo><mml:mo>b</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>a</mml:mo><mml:mo>+</mml:mo><mml:mo>k</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>a</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x00393;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>a</mml:mo><mml:mo>+</mml:mo><mml:mo>b</mml:mo><mml:mo>+</mml:mo><mml:mo>k</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(6)</label></disp-formula>
Thus, for example, the unconditional probability of the unit response vector <bold>x</bold> = [1,1,1,&#x02026;,1] is simply
<disp-formula id="pone.0141981.e007"><alternatives><graphic xlink:href="pone.0141981.e007.jpg" id="pone.0141981.e007g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>&#x02026;</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>&#x02026;</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula>
More generally, any Pr[<bold>x</bold>] may be written as a function of gamma functions whose arguments are the sums of the distribution parameters <italic>a</italic> and <italic>b</italic> and/or item difficulties <italic>k</italic>
<sub>i</sub>.</p></sec><sec id="sec005"><title>Representation of the Unconditional Response Probabilities</title><p>Let Pr[<bold>x</bold>] represent the unconditional probability of a response. For any <bold>x</bold>, let <italic>I</italic>(<bold>x</bold>) = {i: <italic>x</italic>
<sub>i</sub> = 0} and <italic>C</italic>(<bold>x</bold>) = {i: <italic>x</italic>
<sub>i</sub> = 1}. Let <italic>A</italic> be any subset of <italic>I</italic>(<bold>x</bold>), including the null set &#x000d8; and let |<italic>A</italic>| be the number of elements in <italic>A</italic>. Given these definitions, we show in Appendix A that
<disp-formula id="pone.0141981.e008"><alternatives><graphic xlink:href="pone.0141981.e008.jpg" id="pone.0141981.e008g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>&#x02026;</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(8)</label></disp-formula>
with
<disp-formula id="pone.0141981.e009"><alternatives><graphic xlink:href="pone.0141981.e009.jpg" id="pone.0141981.e009g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M9"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(9)</label></disp-formula>
for the EBE model. These equations are useful for constructing joint item response functions in programming routines for ML estimation.</p><p>Initial estimates for the model parameters may be obtained from bivariate cross-classifications. Given the resulting table from any such cross-classification of the i<sup>th</sup> and j<sup>th</sup> items, and fixing one of the two relevant item parameters (say <italic>k</italic>
<sub>i</sub>) = 1, the other three parameters <italic>k</italic>
<sub>j</sub>, <italic>a</italic> and <italic>b</italic> can be estimated from the three degrees of freedom in the 2&#x000d7;2 table. Repeating this <italic>M</italic>-1 times for all cross classifications of the i<sup>th</sup> item with all other items produces a complete vector of starting values. (We give the details in <xref rid="sec018" ref-type="sec">Appendix B</xref>.) We then use the Polak and Ribi&#x000e8;re [<xref rid="pone.0141981.ref009" ref-type="bibr">9</xref>] version of the Fletcher and Reeves conjugate gradient method [<xref rid="pone.0141981.ref010" ref-type="bibr">10</xref>] to find maximum likelihood estimates; we also use the Nelder and Mead [<xref rid="pone.0141981.ref011" ref-type="bibr">11</xref>] simplex methods to check that there are no preferable solutions in the area of the start values. In no case did we find that our maximum was local only.</p></sec><sec id="sec006"><title>Scores and Score Variances from the Posterior Distribution of <italic>y</italic> given x</title><p>The posterior density of <italic>y</italic> given <bold>x</bold> is defined as
<disp-formula id="pone.0141981.e010"><alternatives><graphic xlink:href="pone.0141981.e010.jpg" id="pone.0141981.e010g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>&#x003c6;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(10)</label></disp-formula>
Accordingly, the expectation of the trait score associated with a manifest response vector is just
<disp-formula id="pone.0141981.e011"><alternatives><graphic xlink:href="pone.0141981.e011.jpg" id="pone.0141981.e011g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mi>y</mml:mi><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mi>y</mml:mi><mml:mi>&#x003c6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>d</mml:mtext><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(11)</label></disp-formula>
We shall regard E[<italic>y</italic>|<bold>x</bold>] as an estimate of the person score corresponding to the response vector <bold>x</bold>. The variance of the posterior distribution serves as a measure of the precision of E[<italic>y</italic>|<bold>x</bold>] as a representation of the person score and can be calculated from the relation V[<italic>y</italic>|<bold>x</bold>] = E[<italic>y</italic>
<sup><italic>2</italic></sup>|<bold>x</bold>]-[E[<italic>y</italic>|<bold>x</bold>]]<sup>2</sup>. As discussed in Appendix A, there is a form for the score of any <bold>x</bold> that is similar to Eqs <xref rid="pone.0141981.e008" ref-type="disp-formula">8</xref> and <xref rid="pone.0141981.e009" ref-type="disp-formula">9</xref>.</p></sec><sec id="sec007"><title>Local Identifiability</title><p>
<xref rid="pone.0141981.e008" ref-type="disp-formula">Eq 8</xref> is locally identifiable if the Jacobian matrix of the transformation from model parameters to response probabilities has full column rank for a given vector of parameter values [<xref rid="pone.0141981.ref012" ref-type="bibr">12</xref>]. Our numerical explorations suggest that this model, without the imposition of any additional constraints, is locally identifiable for plausible regions of the parameter space. Nevertheless, the imposition of normalizations of the form <italic>k</italic>
<sub>i</sub> = 1 for some i, providing an item-specific metric of the latent variable, produces more stable full-information maximum likelihood estimates than the unconstrained model. This is the result of the following interesting circumstance: the power of a Beta-distributed random variable is a random variable that is nearly&#x02014;but not quite&#x02014;distributed as Beta variable. The choice of i to fix is arbitrary in the following senses: a) the fit of the model to data is virtually independent of this choice and b) ML estimates of item parameters for all normalizations are related in a simple way. This last point deserves a brief elaboration.</p><p>Suppose for some set of data the model is normalized with respect to the h<sup>th</sup> item and that ML estimates are written as <italic>k</italic>
<sub>i</sub>
<sup>h</sup>, and <italic>a</italic>
<sup>h</sup>, <italic>b</italic>
<sup>h</sup> with <italic>k</italic>
<sub>i</sub>
<sup>h</sup> = 1 if i = h. Let <italic>k</italic>
<sub>i</sub>
<sup>h</sup> and <italic>a</italic>
<sup>h</sup>, <italic>b</italic>
<sup>h</sup> be the ML estimates for normalization with respect to item h so that <italic>k</italic>
<sub>i</sub>
<sup>h</sup> = 1 if i = h. To a close approximation, <italic>k</italic>
<sub>i</sub>
<sup>j</sup> = <italic>k</italic>
<sub>i</sub>
<sup>h</sup> / <italic>k</italic>
<sub>j</sub>
<sup>h</sup>. We also note that the special case in which the <italic>b</italic> parameter is set <italic>a priori</italic> to 1 is underidentified and requires an arbitrary constraint on one item parameter or, equivalently, on the <italic>a</italic> distribution parameter. With this constraint, there are simple closed form solutions for the ratios of item parameters to the single distributional parameter. For this case, <xref rid="pone.0141981.e006" ref-type="disp-formula">Eq 6</xref> simplifies to
<disp-formula id="pone.0141981.e012"><alternatives><graphic xlink:href="pone.0141981.e012.jpg" id="pone.0141981.e012g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(12)</label></disp-formula>
and hence
<disp-formula id="pone.0141981.e013"><alternatives><graphic xlink:href="pone.0141981.e013.jpg" id="pone.0141981.e013g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>a</mml:mi></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(13)</label></disp-formula>
Thus the ratio of any item hardness to the single distribution parameter can be recreated simply as a ratio of failures to successes at the marginals.</p></sec></sec><sec id="sec008"><title>Illustrative Analyses of Dichotomous Responses</title><sec id="sec009"><title>Issues of Fit</title><p>We go on to apply this model to sets of dichotomous items, making comparisons to results obtained with the Rasch model [<xref rid="pone.0141981.ref013" ref-type="bibr">13</xref>] for the simplest cases. The overall fit of the model can be assessed using the likelihood ratio chi-square, which can also be used to test nested models we shall introduce below. But for comparison of non-nested models, we use the model selection criterion of Raftery&#x02019;s BIC [<xref rid="pone.0141981.ref014" ref-type="bibr">14</xref>], which is equal to <italic>L</italic>
<sup>2</sup>&#x02014;df*ln(<italic>N</italic>), where <italic>L</italic>
<sup>2</sup> is the likelihood ratio chi-square, df represents the degrees of freedom, and <italic>N</italic> the number of persons in the sample. (The saturated model has a BIC of 0, any model with a negative BIC is preferred to the saturated model, and the model with the lowest BIC is preferred.) As recently emphasized by Weakliem [<xref rid="pone.0141981.ref015" ref-type="bibr">15</xref>], BIC is not without its drawbacks, and more rigorous implementations of Bayesian logic are now tractable [<xref rid="pone.0141981.ref016" ref-type="bibr">16</xref>]. However, the chief practical drawback of BIC seems to be its overly conservative nature, as it prefers more parsimonious models, and given the temptation to over-fit data sets, we think that BIC serves well as a general criterion for model comparison in which many models are fit to the same data set.</p></sec><sec id="sec010"><title>The Single Group Case</title><p>We begin by re-analyzing the classic Army data presented by Stouffer [<xref rid="pone.0141981.ref017" ref-type="bibr">17</xref>] and analyzed using a Rasch model by Duncan [<xref rid="pone.0141981.ref004" ref-type="bibr">4</xref>] and Kelderman [<xref rid="pone.0141981.ref018" ref-type="bibr">18</xref>]. The data are to be found in <xref rid="pone.0141981.t001" ref-type="table">Table 1</xref>. We present the model that results when we constrain <italic>k</italic>
<sub>4</sub> = 1; the likelihood chi-square is 17.42, with 10 degrees of freedom (p = .066). Raftery&#x02019;s BIC for this model is &#x02013;51.66. By contrast, the Rasch model implemented by Duncan had a likelihood ratio chi-square of 10.93 at 8 degrees of freedom, (p = .206) leading to a BIC of &#x02013;44.33. In sum, the loglinear Rasch model has a closer fit but uses up more degrees of freedom; while deviations from the extended binomial error are marginally significant according classical criteria, the more parsimonious model is preferred according to the Bayesian criterion.</p><table-wrap id="pone.0141981.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t001</object-id><label>Table 1</label><caption><title>Stouffer&#x02019;s Army Data.</title></caption><alternatives><graphic id="pone.0141981.t001g" xlink:href="pone.0141981.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Item <italic>A</italic>
</th><th align="center" rowspan="1" colspan="1">Item <italic>B</italic>
</th><th align="center" rowspan="1" colspan="1">Item <italic>C</italic>
</th><th align="center" rowspan="1" colspan="1">Item <italic>D</italic>
</th><th align="center" rowspan="1" colspan="1">Frequency</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">229</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">199</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">52</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">96</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">25</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">60</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">16</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">69</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">16</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">45</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">8</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">55</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">10</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">42</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">3</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">75</td></tr></tbody></table></alternatives></table-wrap><p>Most importantly, the two models agree closely as to the positions of the different items. We find a correlation &#x0003e; .99 between the natural log of the extended binomial error model&#x02019;s item parameters and those of the Rasch model. (Here we use results from a conditional maximum likelihood fit. Duncan&#x02019;s item parameters are quite different, which we assume to be a mistake, since the order of parameter hardnesses differs not only from our Rasch analyses, but from the marginal distribution of the items. Kelderman did not report item parameters.) Inspection of the estimated scores (<xref rid="pone.0141981.t002" ref-type="table">Table 2</xref>) from the extended binomial error (<xref rid="pone.0141981.e011" ref-type="disp-formula">Eq 11</xref>) model shows that while there are clear score differences between patterns with the same Rasch raw score (the number of &#x0201c;positive&#x0201d; responses), the ranking of respondents with respect to posterior scores is roughly the same as the ranking with respect to raw scores. The differences between posterior expected value scores over response patterns are small compared to the posterior standard deviations for each pattern; this is to be expected given that the number of items is small.</p><table-wrap id="pone.0141981.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t002</object-id><label>Table 2</label><caption><title>Results of Fit to Army Data.</title></caption><alternatives><graphic id="pone.0141981.t002g" xlink:href="pone.0141981.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Parameter</th><th align="left" rowspan="1" colspan="1">Value</th><th align="left" rowspan="1" colspan="1">Standard Error</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">
<bold><italic>k</italic>1</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>4.0879</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.3124</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>k</italic>
<sub>2</sub>
</td><td align="char" char="." rowspan="1" colspan="1">3.4005</td><td align="char" char="." rowspan="1" colspan="1">.2534</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>k</italic>
<sub>3</sub>
</td><td align="char" char="." rowspan="1" colspan="1">2.5674</td><td align="char" char="." rowspan="1" colspan="1">.1875</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>k</italic>
<sub>4</sub>
</td><td align="char" char="." rowspan="1" colspan="1">1.0000<xref rid="t002fn001" ref-type="table-fn">*</xref>
</td><td align="left" rowspan="1" colspan="1">-------</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>a</italic>
</td><td align="char" char="." rowspan="1" colspan="1">3.0223</td><td align="char" char="." rowspan="1" colspan="1">.3350</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>b</italic>
</td><td align="char" char="." rowspan="1" colspan="1">1.7173</td><td align="char" char="." rowspan="1" colspan="1">.1623</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p>* = fixed; Log-likelihood chi-square = 17.422; df = 10; p = .066.</p></fn></table-wrap-foot></table-wrap><p>In this case and most others we have investigated the log linear version of the Rasch and extended binomial error models lead to similar conclusions, though latter tends to be more parsimonious and the former to fit somewhat better, as it has <italic>M</italic>-2 more free parameters. Nevertheless, the two need not agree. Numerical investigations demonstrate the existence of cases in which response distributions generated by the extended binomial error model parameters fit the Rasch model well (as judged by goodness-of-fit measures) but produced estimates of log-linear trait distribution parameters that violate the moment inequalities conditions of Cressie and Holland [<xref rid="pone.0141981.ref019" ref-type="bibr">19</xref>].</p><p>In sum, the EBE behaves similarly to the Rasch model; given an implementation involving greater distributional flexibility (the loglinear version) the Rasch model will naturally fit somewhat better at the cost of more parameters. There are, however, data that are fit by one model and not by the other. Most importantly, the probability-like metric of the latent trait allows for extensions that may be of great interest when we wish to examine the mechanisms of response processes (as opposed to scoring long tests). We go on to examine several such extensions, starting with models for independent groups under experimental conditions.</p></sec><sec id="sec011"><title>The Multiple Group Case</title><p>The multiple group extension of the extended binomial error model permits investigation of issues related to item bias and, under certain conditions, study of group differences in the distribution of the latent trait. Let g = 1,&#x02026;,<italic>G</italic> index groups which may be formed by partitioning a single random sample, sampling from diverse populations, or by random assignment of different item formats. To allow for differences in item and distribution parameters over these groups, we may rewrite Eqs <xref rid="pone.0141981.e004" ref-type="disp-formula">4</xref> and <xref rid="pone.0141981.e005" ref-type="disp-formula">5</xref> as follows:
<disp-formula id="pone.0141981.e014"><alternatives><graphic xlink:href="pone.0141981.e014.jpg" id="pone.0141981.e014g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M14"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(14)</label></disp-formula>
<disp-formula id="pone.0141981.e015"><alternatives><graphic xlink:href="pone.0141981.e015.jpg" id="pone.0141981.e015g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:msub><mml:mi>&#x003c6;</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(15)</label></disp-formula>
</p><p>To illustrate, we take data from a national telephone survey of Italian adults 18&#x02013;69 years old that was conducted in April and May, 1994 [<xref rid="pone.0141981.ref020" ref-type="bibr">20</xref>]. The survey was part of a study of regional and ethnic prejudice in Italy and included a series of items dealing with stereotypical beliefs about Africans and East Europeans living in Italy. Each respondent was assigned at random to a set of questions targeted at one of three immigrant groups: a) North Africans, such as Moroccans, Tunisians, or Algerians (probability = .25); b) Africans from regions of Central Africa, such as Senegal and Somalia (probability = .25); and c) Eastern Europeans, such as Poles, Albanians, or Slavs (probability = .5). For each target group, the respondent was presented with a statement incorporating a positive or negative adjective pertaining to the group, e.g.: &#x0201c;do you agree that most of them are complainers? (they try to make others feel sorry for them)&#x0201d;. The interviewer then asked respondents &#x0201c;Do you agree strongly, agree somewhat, disagree somewhat, or disagree strongly with this description?&#x0201d;</p><p>For our example, we selected responses to items incorporating four negative adjectives which roughly translate into &#x0201c;selfish&#x0201d;, &#x0201c;slackers&#x0201d;, &#x0201c;violent&#x0201d;, and &#x0201c;complainers&#x0201d;, combined the North and Central African target groups into a single target group (based on similarity of the marginal distributions), and dichotomized the responses into &#x0201c;Agree&#x0201d; (coded 1) and &#x0201c;Disagree&#x0201d; (coded 0). The response distribution for <italic>N</italic> = 2001 respondents in the 1994 survey is shown in <xref rid="pone.0141981.t003" ref-type="table">Table 3</xref>.</p><table-wrap id="pone.0141981.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t003</object-id><label>Table 3</label><caption><title>1994 Italian Survey: Stereotype Data (Sniderman, et al., 1995).</title></caption><alternatives><graphic id="pone.0141981.t003g" xlink:href="pone.0141981.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Item 1</th><th align="center" rowspan="1" colspan="1">Item 2</th><th align="center" rowspan="1" colspan="1">Item 3</th><th align="center" rowspan="1" colspan="1">Item 4</th><th align="left" rowspan="1" colspan="1">Immigrants are African</th><th align="left" rowspan="1" colspan="1">Immigrants are East European</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">342</td><td align="right" rowspan="1" colspan="1">361</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">164</td><td align="right" rowspan="1" colspan="1">129</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">35</td><td align="right" rowspan="1" colspan="1">32</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">44</td><td align="right" rowspan="1" colspan="1">47</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">53</td><td align="right" rowspan="1" colspan="1">41</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">60</td><td align="right" rowspan="1" colspan="1">51</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">18</td><td align="right" rowspan="1" colspan="1">20</td></tr><tr><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">51</td><td align="right" rowspan="1" colspan="1">38</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">35</td><td align="right" rowspan="1" colspan="1">45</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">39</td><td align="right" rowspan="1" colspan="1">47</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">9</td><td align="right" rowspan="1" colspan="1">20</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">28</td><td align="right" rowspan="1" colspan="1">27</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">11</td><td align="right" rowspan="1" colspan="1">10</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">39</td><td align="right" rowspan="1" colspan="1">36</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0</td><td align="right" rowspan="1" colspan="1">13</td><td align="right" rowspan="1" colspan="1">17</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">66</td><td align="right" rowspan="1" colspan="1">73</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>Totals</bold>
</td><td align="right" rowspan="1" colspan="1">
<bold>1007</bold>
</td><td align="right" rowspan="1" colspan="1">
<bold>994</bold>
</td></tr></tbody></table></alternatives></table-wrap><p>As an exercise, we can use these data to determine whether the responses are consistent with the hypothesis of an underlying trait of prejudice or hostility to minorities, and if so, if Africans and Eastern Europeans are perceived identically. If there are differences in the perception of Africans and Eastern Europeans, we can determine whether there is still a single trait of &#x0201c;prejudice&#x0201d; with perhaps different thresholds for attributing negative characteristics to Africans and Eastern Europeans, or whether there seem to be different latent traits involved when it comes to judging members of the two target groups.</p><p>
<xref rid="pone.0141981.t004" ref-type="table">Table 4</xref> presents fit statistics for selected models for these data. The first model corresponds to Eqs <xref rid="pone.0141981.e014" ref-type="disp-formula">14</xref> and <xref rid="pone.0141981.e015" ref-type="disp-formula">15</xref>, only adding the constraint <italic>k</italic>
<sub>3g</sub> = 1 for g = 1,2 (the reason the third item is chosen will become clear below). This model fits quite well, generating a likelihood ratio chi-square of 15.93 with 20 degrees of freedom (p = .721). Models 2 and 3 impose substantively important constraints. Model 2 sets <italic>k</italic>
<sub>ig</sub> = <italic>k</italic>
<sub>i</sub> for all i; it is a test of identical item meanings (semantic invariance) that allows the choice of target group to evoke different traits (e.g., degree of hostility to Africans or degree of hostility to Eastern Europeans). This sort of model might be used to examine item bias across two non-experimental groups; if this model failed to fit one could attempt to see if there were particular items that had different hardnesses across groups.</p><table-wrap id="pone.0141981.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t004</object-id><label>Table 4</label><caption><title>Results of Fitting Models to Italian Data.</title></caption><alternatives><graphic id="pone.0141981.t004g" xlink:href="pone.0141981.t004"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Model</th><th align="center" rowspan="1" colspan="1">Parameters Constrained To Be Identical Across Groups</th><th align="center" rowspan="1" colspan="1">Likelihood Ratio Chi-Sq</th><th align="center" rowspan="1" colspan="1">df</th><th align="left" rowspan="1" colspan="1">Probability</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">
<bold>1</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref></bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>15.93</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>20</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.721</bold>
</td></tr><tr><td align="center" rowspan="1" colspan="1">
<bold>2</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>1, <italic>k</italic>2, <italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref>, <italic>k</italic>4</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>26.24</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>23</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.290</bold>
</td></tr><tr><td align="center" rowspan="1" colspan="1">
<bold>3</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref>, <italic>a</italic>, <italic>b</italic></bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>16.55</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>22</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.788</bold>
</td></tr><tr><td align="center" rowspan="1" colspan="1">
<bold>4</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>2, <italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref>, <italic>a</italic>, <italic>b</italic></bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>18.56</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>23</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.726</bold>
</td></tr><tr><td align="center" rowspan="1" colspan="1">
<bold>5</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>2, <italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref>, <italic>k</italic>4, <italic>a</italic>, <italic>b</italic></bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>21.49</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>24</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.610</bold>
</td></tr><tr><td align="center" rowspan="1" colspan="1">
<bold>6</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold><italic>k</italic>1, <italic>k</italic>2, <italic>k</italic>3<xref rid="t004fn001" ref-type="table-fn">*</xref>, <italic>k</italic>4, <italic>a</italic>, <italic>b</italic></bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>27.61</bold>
</td><td align="center" rowspan="1" colspan="1">
<bold>25</bold>
</td><td align="char" char="." rowspan="1" colspan="1">
<bold>.326</bold>
</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><p>* = fixed parameter</p></fn></table-wrap-foot></table-wrap><p>Given that our groups are the results of experimental treatments, however, we may instead begin by assuming identity of the distribution of the latent trait. Model 3 sets <italic>a</italic>
<sub>g</sub> = <italic>a</italic> and <italic>b</italic>
<sub>g</sub> = <italic>b</italic>; given the normalization <italic>k</italic>
<sub>3g</sub> = 1 for g = 1,2 this is equivalent to saying that there is only one trait of overall prejudice, but the items (except for the third) can have different hardnesses depending on the target group.</p><p>Given model 1, model 2 must clearly be rejected as the difference in chi-square is significant (10.31 at 3 df, p = .016). Given model 1, however, loss of fit due to the constraints associated with model 3 is insignificant (chi-square of .62 at 2 df, p = .733). (The results here are not independent of the choice of item that is fixed; setting <italic>k</italic>
<sub>3g</sub> = 1 for g = 1, 2 resulted in the lowest chi-square for model 3 and was hence also used for models 1 and 2.) Further, model 4 demonstrates that the location of item 2 can also be equated for the two groups (the chi-square difference of 2.01 between models 3 and 4 is insignificant at 1 df with p = .156), although models 5 and 6 demonstrate that this is not true of items 1 and 4. Inspection of the item parameters demonstrates that the item locations are more spread out on the underlying continuum when the target group is Africans than when the target is Europeans. Such a result is consistent with the interpretation that there is a single trait of out-group hostility among the respondents, but that Italians have a more differentiated stereotype of Africans than they do of Eastern Europeans.</p></sec></sec><sec id="sec012"><title>Other Extensions</title><sec id="sec013"><title>Generalization To Ordered Polychotomies</title><p>The generalization of the extended binomial error model to ordered polychotomies relies on a standard threshold parameterization for ordered categories that was developed in an IRT context by Edwards and Thurstone [<xref rid="pone.0141981.ref021" ref-type="bibr">21</xref>] and also for regression analysis of ordered categories (see, for example, [<xref rid="pone.0141981.ref022" ref-type="bibr">22</xref>&#x02013;<xref rid="pone.0141981.ref024" ref-type="bibr">24</xref>]). Let j = 1,&#x02026;, <italic>J</italic> represent the <italic>a priori</italic> order of the response categories for the i<sup>th</sup> item where j = 1 is &#x0201c;low&#x0201d; and j = <italic>J</italic> is &#x0201c;high&#x0201d;. We denote the hardness of each of these response categories as <italic>k</italic>
<sub>i,j</sub>, where <italic>k</italic>
<sub>i,1</sub>&#x0003c;<italic>k</italic>
<sub>i,2</sub>&#x0003c; &#x02026;.&#x0003c; <italic>k</italic>
<sub>i,J-1.</sub> By analogy with <xref rid="pone.0141981.e001" ref-type="disp-formula">Eq 1</xref> for dichotomous responses, we write the probability of that a response fall into category j <italic>or higher</italic> as
<disp-formula id="pone.0141981.e016"><alternatives><graphic xlink:href="pone.0141981.e016.jpg" id="pone.0141981.e016g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M16"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02265;</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(16)</label></disp-formula>
For a fixed <italic>y</italic> value, the probabilities thus defined diminish as j increases. Given this definition, the probabilities of the intermediate response categories are calculated as differences between the probabilities associated with adjacent dichotomizations. This then implies that the model for ordered categories can be written as follows:
<disp-formula id="pone.0141981.e017"><alternatives><graphic xlink:href="pone.0141981.e017.jpg" id="pone.0141981.e017g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M17"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mtext>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;</mml:mtext></mml:mrow></mml:math></alternatives><label>(17)</label></disp-formula>
where we set the second term to zero for <italic>j</italic> = <italic>J</italic>.</p><p>The model given as <xref rid="pone.0141981.e017" ref-type="disp-formula">Eq 17</xref> has a number of welcome features. First, the probability function for any category j is single-peaked; if we denote its maximum <italic>y*</italic>
<sub>j</sub> then (j &#x0003c; k) &#x021d4; (<italic>y*</italic>
<sub>j</sub> &#x0003c; <italic>y*</italic>
<sub>k</sub>); <italic>y*</italic>
<sub>1</sub> = 0 and <italic>y*</italic>
<sub><italic>J</italic></sub> = 1. Finally, because this is a threshold model, it satisfies the two principles Jansen and Roskam [<xref rid="pone.0141981.ref025" ref-type="bibr">25</xref>] called the <italic>joining assumption</italic> (the probability of an aggregated response category is the sum of the probabilities of its constituent, usually adjacent, response categories) and <italic>&#x003be;-equivalence</italic> (the latent traits embedded in aggregated and disaggregated versions of the item response functions are identical or are related by an admissable transformation). In contrast, the most methodologically tractable generalizations to the polychotomous case in the Rasch model (the rating scale and partial credit models and their relatives [<xref rid="pone.0141981.ref026" ref-type="bibr">26</xref>]) do not satisfy these criteria which means that a model that fits the polychotomous data may not fit dichotomous or otherwise collapsed data [<xref rid="pone.0141981.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0141981.ref030" ref-type="bibr">30</xref>]. (The graded response model [<xref rid="pone.0141981.ref031" ref-type="bibr">31</xref>] does satisfy the collapsing conditions but is somewhat more complex.)</p></sec><sec id="sec014"><title>An Illustration of the Model for Ordered Polychotomies</title><p>To illustrate the application of the polychotomous model to social data, we use a small example drawn from the 2000 U.S. National Alcohol Survey, a cross-sectional national probability household survey on alcohol use and problems [<xref rid="pone.0141981.ref032" ref-type="bibr">32</xref>]. <xref rid="pone.0141981.t005" ref-type="table">Table 5</xref> shows the response distribution pertaining to a cross-classification of two 4-category items dealing with reasons for abstention from alcohol in a sample of 547 women aged 18&#x02013;29. They were asked &#x0201c;how important to you are each of the following reasons for abstaining from alcohol beverages or being careful about how much you drink.&#x0201d; The two reasons represented in <xref rid="pone.0141981.t006" ref-type="table">Table 6</xref> are &#x0201c;drinking is bad for your health&#x0201d; and &#x0201c;drinking can get you sick&#x0201d; and the response categories for both reasons are &#x0201c;not a reason at all,&#x0201d; &#x0201c;not an important reason,&#x0201d; &#x0201c;somewhat important&#x0201d; and &#x0201c;very important.&#x0201d; In this illustration, the category response functions are written so that high values are associated with responses indicating the reasons stated are important for decisions to abstain or to be careful about drinking. Thus <italic>y</italic>
<sup>k1,1</sup> is the conditional probability, given <italic>y</italic>, that a respondent will regard the &#x0201c;drinking is bad for your health&#x0201d; as &#x0201c;an important reason&#x0201d; for abstaining or being careful about drinking.</p><table-wrap id="pone.0141981.t005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t005</object-id><label>Table 5</label><caption><title>National Alcohol Survey Data.</title></caption><alternatives><graphic id="pone.0141981.t005g" xlink:href="pone.0141981.t005"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Item 1</th><th align="center" rowspan="1" colspan="1">Item 2</th><th align="left" rowspan="1" colspan="1">Frequency</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">9</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="right" rowspan="1" colspan="1">3</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">3</td><td align="right" rowspan="1" colspan="1">7</td></tr><tr><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">4</td><td align="right" rowspan="1" colspan="1">1</td></tr><tr><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">4</td></tr><tr><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">2</td><td align="right" rowspan="1" colspan="1">3</td></tr><tr><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="right" rowspan="1" colspan="1">7</td></tr><tr><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">4</td><td align="right" rowspan="1" colspan="1">6</td></tr><tr><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">15</td></tr><tr><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">2</td><td align="right" rowspan="1" colspan="1">19</td></tr><tr><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">3</td><td align="right" rowspan="1" colspan="1">65</td></tr><tr><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="right" rowspan="1" colspan="1">51</td></tr><tr><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">1</td><td align="right" rowspan="1" colspan="1">15</td></tr><tr><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">2</td><td align="right" rowspan="1" colspan="1">14</td></tr><tr><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">3</td><td align="right" rowspan="1" colspan="1">80</td></tr><tr><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">4</td><td align="right" rowspan="1" colspan="1">248</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>Totals</bold>
</td><td align="right" rowspan="1" colspan="1">
<bold>547</bold>
</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t005fn001"><p>Response categories: 1 &#x02018;Not a reason&#x02019;, 2 &#x02018;Not an Important Reason&#x02019;, 3 &#x02018;Somewhat Important Reason&#x02019;, 4 &#x02018;Very Important.&#x02019; Item 1: &#x0201c;Drinking is bad for your health&#x0201d;; item 2: &#x0201c;Drinking can get you sick.&#x0201d;</p></fn></table-wrap-foot></table-wrap><table-wrap id="pone.0141981.t006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0141981.t006</object-id><label>Table 6</label><caption><title>Results of Fitting Models to Data in <xref rid="pone.0141981.t005" ref-type="table">Table 5</xref>.</title></caption><alternatives><graphic id="pone.0141981.t006g" xlink:href="pone.0141981.t006"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Parameter</th><th align="left" rowspan="1" colspan="1">Estimate</th><th align="left" rowspan="1" colspan="1">Standard Error</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>1,1</sub>
</td><td align="char" char="." rowspan="1" colspan="1">1.000<xref rid="t006fn001" ref-type="table-fn">*</xref>
</td><td align="left" rowspan="1" colspan="1">--</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>1,2</sub>
</td><td align="char" char="." rowspan="1" colspan="1">0.132</td><td align="char" char="." rowspan="1" colspan="1">0.021</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>1,3</sub>
</td><td align="char" char="." rowspan="1" colspan="1">0.062</td><td align="char" char="." rowspan="1" colspan="1">0.014</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>2,1</sub>
</td><td align="char" char="." rowspan="1" colspan="1">1.565</td><td align="char" char="." rowspan="1" colspan="1">0.177</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>2,2</sub>
</td><td align="char" char="." rowspan="1" colspan="1">0.301</td><td align="char" char="." rowspan="1" colspan="1">0.042</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>k</italic>
<sub>2,3</sub>
</td><td align="char" char="." rowspan="1" colspan="1">0.141</td><td align="char" char="." rowspan="1" colspan="1">0.025</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>a</italic>
</td><td align="char" char="." rowspan="1" colspan="1">1.112</td><td align="char" char="." rowspan="1" colspan="1">0.194</td></tr><tr><td align="center" rowspan="1" colspan="1">
<italic>b</italic>
</td><td align="char" char="." rowspan="1" colspan="1">0.598</td><td align="char" char="." rowspan="1" colspan="1">0.097</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t006fn001"><p>*fixed; Log-likelihood ratio chi-squared value = 12.78; df = 8; p&#x0003e;0.173</p></fn></table-wrap-foot></table-wrap><p>
<xref rid="pone.0141981.t006" ref-type="table">Table 6</xref> shows the parameter estimates and standard errors for fitting the extended binomial error model for ordered polychotomies to these data. As judged by the likelihood ratio chi-squared value (12.78, 8df), the fit of the model to these data is acceptable. The beta distribution generated by <italic>a</italic> = 1.112 and <italic>b</italic> = 0.598 is skewed toward high values of <italic>y</italic> implying that the majority of respondents consider both reasons for abstinence to be important. A comparison of the category threshold parameters indicates that &#x0201c;bad for your health&#x0201d; is considered a more compelling reason for abstinence than &#x0201c;getting sick&#x0201d; among the young adult women in the national sample.</p></sec><sec id="sec015"><title>Single-Peaked Response Functions</title><p>This threshold formulation can also be adapted to model response processes in which subjects are more likely to give a positive response to some item if that item&#x02019;s location is near their own on the latent trait. Following the method of Andrich and Luo [<xref rid="pone.0141981.ref033" ref-type="bibr">33</xref>&#x02013;<xref rid="pone.0141981.ref036" ref-type="bibr">36</xref>], each item is turned into a trichotomy, with two failure regions (the item is too far above the subject for her to answer in a positive direction and the item is too far below her), with the intermediate leading to a positive response. However, there is an alternative approach that is sufficiently flexible to handle a variety of empirical cases.</p><p>Here we approximate the response function in question for some set of such dichotomous items as follows:
<disp-formula id="pone.0141981.e018"><alternatives><graphic xlink:href="pone.0141981.e018.jpg" id="pone.0141981.e018g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M18"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives><label>(18)</label></disp-formula>
which is a unimodal function achieving its maximum when <italic>y</italic>
<sup>ki</sup> = .5, which is equivalent to &#x003be; = &#x003c7;<sub>i</sub> in an unbounded metric if we again define &#x003c7;<sub>&#x00269;</sub> = log(<italic>k</italic>
<sub>i</sub>), and <italic>&#x003be;</italic> = -log[-2log(<italic>y</italic>)]. The leading <italic>&#x003b1;</italic>
<sub>i</sub> may be considered akin to a discriminating ability parameter for cumulative models, or it may be considered an overall normalization factor if constrained <italic>&#x003b1;</italic>
<sub>i</sub> = <italic>&#x003b1;</italic> for all i; it may also be fixed in advance, such that (for example) the predicted probability of a positive response is 1 when &#x003be; = &#x003c7;<sub>i</sub>. Again, there is a parsimonious representation of the unconditional probability of any vector <bold>x</bold> for any set of parameter values <bold>h</bold> = (<italic>a</italic>,<italic>b</italic>,<italic>&#x003b1;</italic>
<sub>1</sub>, &#x02026; <italic>&#x003b1;</italic>
<sub>M</sub>, <italic>k</italic>
<sub>1</sub>,&#x02026;,<italic>k</italic>
<sub>M</sub>) (see <xref rid="sec017" ref-type="sec">Appendix A</xref>).</p></sec></sec><sec sec-type="conclusions" id="sec016"><title>Conclusion</title><p>In sociology the loglinear Rasch model has become the most widely known and used IRT model in sociology [<xref rid="pone.0141981.ref037" ref-type="bibr">37</xref>&#x02013;<xref rid="pone.0141981.ref041" ref-type="bibr">41</xref>]. There are two reasons for this popularity. First, Duncan [<xref rid="pone.0141981.ref004" ref-type="bibr">4</xref>] argued that its indifference to the distribution of the latent trait made it a better scientific instrument than the covariance-based methods that dominate social modeling. Second, the Rasch model&#x02019;s parameters turned out to be estimable with a very simple loglinear approach [<xref rid="pone.0141981.ref018" ref-type="bibr">18</xref>, <xref rid="pone.0141981.ref042" ref-type="bibr">42</xref>]. This approach treats the distribution of the latent variable as a set of nuisance parameters&#x02014;the total score preserves all useful information in grading respondents, and the item hardnesses can be estimated without further investigation of the distribution of the latent trait.</p><p>But preserving a metric representation of the trait aids the investigation of the response process. While other IRT models, including the Rasch model, can be adapted in this way, the model presented here allows for a wide-range of substantively important extensions to be modeled rather simply, due to the combination of a) a latent trait that can be interpreted as a probability, b) a simple family of response functions that can model dichotomous, ordered polychotomous, and unfolding-type responses, and c) a flexible two-parameter Beta distribution for the latent trait. Such a family of models can be particularly useful in the analysis of experiments that involve changes in wording, response formats, and item order.</p></sec><sec id="sec017"><title>Appendix A</title><p>A compact representation of the predicted response probabilities for any value of the parameters can be derived from the exclusion-inclusion theorem (see, e.g., [<xref rid="pone.0141981.ref043" ref-type="bibr">43</xref>], 72f). Let the vector <bold>h</bold> = (<italic>a</italic>,<italic>b</italic>,<italic>k</italic>
<sub>1</sub>,&#x02026;,<italic>k</italic>
<sub>M</sub>) represent the model parameters and Pr[<bold>x</bold>|<bold>h</bold>] the unconditional probability of a response for a given <bold>h</bold>. For any <bold>x</bold>, let <italic>I</italic>(<bold>x</bold>) = {i: <italic>x</italic>
<sub>i</sub> = 0} and <italic>C</italic>(<bold>x</bold>) = {i: <italic>x</italic>
<sub>i</sub> = 1). Let <italic>A</italic> be any subset of <italic>I</italic>(<bold>x</bold>), including the null set <bold>&#x000d8;</bold> and let |<italic>A</italic>| be the number of elements in <italic>A</italic>. Now since the responses to each item are assumed to be independent conditional on the value of the latent trait, we can write Pr[<bold>x</bold>|<bold>h</bold>] in product form, where the expectation is taken with respect to the distribution of the latent trait:
<disp-formula id="pone.0141981.e019"><alternatives><graphic xlink:href="pone.0141981.e019.jpg" id="pone.0141981.e019g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M19"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>&#x02026;</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>&#x02026;</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(A.1)</label></disp-formula>
This representation is valid for all latent trait models for dichotomous responses that assume conditional independence. For the extended binomial error model, we make the following substitution:
<disp-formula id="pone.0141981.e020"><alternatives><graphic xlink:href="pone.0141981.e020.jpg" id="pone.0141981.e020g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(A.2)</label></disp-formula>
</p><p>The response pattern score and score variance can be expressed similarly. Written in terms of the model parameters, the score E[<italic>y</italic>|<bold>x</bold>] is given as:
<disp-formula id="pone.0141981.e021"><alternatives><graphic xlink:href="pone.0141981.e021.jpg" id="pone.0141981.e021g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M21"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(A.3)</label></disp-formula>
</p><p>Finally, there is a parsimonious representation of the unconditional probability of any vector <bold>x</bold> for any set of parameter values in the unfolding-type model of Eq 19. With <italic>I</italic>(<bold>x</bold>) and <italic>C</italic>(<bold>x</bold>) defined as above, and <italic>A</italic> any subset of <italic>I</italic>(<bold>x</bold>), let <italic>B</italic> be any subset of the union of this <italic>A</italic> with <italic>C</italic>(<bold>x</bold>), and let |<italic>B</italic>| be the number of elements in <italic>B</italic>. Then it can be shown that
<disp-formula id="pone.0141981.e022"><alternatives><graphic xlink:href="pone.0141981.e022.jpg" id="pone.0141981.e022g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M22"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mo>&#x02282;</mml:mo><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>B</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(A.4)</label></disp-formula>
For the expectation involving <italic>y</italic> we make the following substitution
<disp-formula id="pone.0141981.e023"><alternatives><graphic xlink:href="pone.0141981.e023.jpg" id="pone.0141981.e023g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M23"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(A.5)</label></disp-formula>
and algorithms related to those discussed above can be used to obtain simultaneous estimates of score and distribution parameters.</p></sec><sec id="sec018"><title>Appendix B</title><p>The cross-classification of responses pertaining to any two items i and j generates a 2 by 2 table of population proportions. Consider three summary measures that are sufficient to reconstruct the marginal and interior probabilities of this table: Pr[<italic>x</italic>i = 1, <italic>x</italic>j = 1], Pr[<italic>x</italic>i = 1], and Pr[<italic>x</italic>j = 1]. (Note that here, Pr[] indicates <italic>observed</italic> probabilities.) Under the model represented by Eqs <xref rid="pone.0141981.e001" ref-type="disp-formula">1</xref> and <xref rid="pone.0141981.e005" ref-type="disp-formula">5</xref>, these have following structure:
<disp-formula id="pone.0141981.e024"><alternatives><graphic xlink:href="pone.0141981.e024.jpg" id="pone.0141981.e024g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M24"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.1)</label></disp-formula>
<disp-formula id="pone.0141981.e025"><alternatives><graphic xlink:href="pone.0141981.e025.jpg" id="pone.0141981.e025g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M25"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.2)</label></disp-formula>
<disp-formula id="pone.0141981.e026"><alternatives><graphic xlink:href="pone.0141981.e026.jpg" id="pone.0141981.e026g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M26"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.3)</label></disp-formula>
These equations cannot be solved uniquely to obtain <italic>a</italic>,<italic>b</italic>, <italic>k</italic>i, and <italic>k</italic>j. However, if we set <italic>k</italic>i = 1 (in effect, normalizing the model by setting <italic>y</italic> = Pr[<italic>x</italic>i = 1|<italic>y</italic>]) and use &#x00393;(s+1) = s&#x00393;(s), we get
<disp-formula id="pone.0141981.e027"><alternatives><graphic xlink:href="pone.0141981.e027.jpg" id="pone.0141981.e027g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M27"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.4)</label></disp-formula>
<disp-formula id="pone.0141981.e028"><alternatives><graphic xlink:href="pone.0141981.e028.jpg" id="pone.0141981.e028g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M28"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>a</mml:mi><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.5)</label></disp-formula>
It follows that
<disp-formula id="pone.0141981.e029"><alternatives><graphic xlink:href="pone.0141981.e029.jpg" id="pone.0141981.e029g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M29"><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.6)</label></disp-formula>
and with manipulation we get
<disp-formula id="pone.0141981.e030"><alternatives><graphic xlink:href="pone.0141981.e030.jpg" id="pone.0141981.e030g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M30"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives><label>(B.7)</label></disp-formula>
where
<disp-formula id="pone.0141981.e031"><alternatives><graphic xlink:href="pone.0141981.e031.jpg" id="pone.0141981.e031g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M31"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.8)</label></disp-formula>
for all i and j. Thus, for each item other than the i<sup>th</sup>, its cross-classification with <italic>x</italic>
<sub>i</sub> gives us its ratio to <italic>a</italic> + <italic>b</italic>.</p><p>To construct an initial estimate of <italic>a</italic> + <italic>b</italic>, which we will denote &#x00398; for brevity, we take advantage of the fact that from <xref rid="pone.0141981.e026" ref-type="disp-formula">Eq B.3</xref>,
<disp-formula id="pone.0141981.e032"><alternatives><graphic xlink:href="pone.0141981.e032.jpg" id="pone.0141981.e032g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M32"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x00398;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(B.9)</label></disp-formula>
and hence
<disp-formula id="pone.0141981.e033"><alternatives><graphic xlink:href="pone.0141981.e033.jpg" id="pone.0141981.e033g" position="anchor" mimetype="image" orientation="portrait"/><mml:math id="M33"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x00398;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x00393;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x00398;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives><label>(B.10)</label></disp-formula>
For admissible values of Pr[<italic>x</italic>i = 1], Pr[<italic>x</italic>j = 1], and Sj, <xref rid="pone.0141981.e033" ref-type="disp-formula">Eq B.10</xref> has a single positive root &#x00398;. When the model describes the data perfectly, the <italic>M</italic>-1 equations corresponding to each j (j &#x02260; i) should yield the same root. For actual data, we average our derived values of &#x00398;. We then substitute this value in <xref rid="pone.0141981.e030" ref-type="disp-formula">Eq B.7</xref> to get initial values of <italic>k</italic>j, j &#x02260; i. Our starting estimate of the parameter <italic>a</italic> can be recovered from the product of (<italic>a</italic> + <italic>b</italic>) and Pr[<italic>x</italic>i = 1] (given that, by construction, <italic>k</italic>i = 1), and that of <italic>b</italic> from <italic>b</italic> = &#x00398;&#x02014;<italic>a</italic>.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0141981.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Keats</surname><given-names>JA</given-names></name>, <name><surname>Lord</surname><given-names>FM</given-names></name>. <article-title>A theoretical distribution for mental test scores</article-title>. <source>Psychometrika</source>
<year>1962</year>; <volume>27</volume>:<fpage>59</fpage>&#x02013;<lpage>62</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref002"><label>2</label><mixed-citation publication-type="book">
<name><surname>Lazarsfeld</surname><given-names>PF</given-names></name>. <chapter-title>Latent structure analysis and test theory</chapter-title> In: <name><surname>Lazarsfeld</surname><given-names>PF</given-names></name>
<name><surname>Henry</surname><given-names>NW</given-names></name>, editors. <source>Readings in mathematical and social science</source>. <publisher-loc>Cambridge, Mass</publisher-loc>
<publisher-loc>.</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1966</year> p. <fpage>78</fpage>&#x02013;<lpage>88</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref003"><label>3</label><mixed-citation publication-type="book">
<name><surname>Coleman</surname><given-names>JS</given-names></name>. <source>Introduction to mathematical sociology</source>. <publisher-loc>Glencoe, Ill.</publisher-loc>: <publisher-name>Free Press</publisher-name>; <year>1964</year>.</mixed-citation></ref><ref id="pone.0141981.ref004"><label>4</label><mixed-citation publication-type="book">
<name><surname>Duncan</surname><given-names>OD</given-names></name>. <chapter-title>Rasch measurement in survey research: Further examples and discussion</chapter-title> In: <name><surname>Turner</surname><given-names>CF</given-names></name> and <name><surname>Martin</surname><given-names>E</given-names></name>, editors. <source>Surveying subjective phenomena</source>, <volume>Vol. II</volume>
<publisher-loc>New York</publisher-loc>: <publisher-name>Russell Sage Foundation</publisher-name>; <year>1984</year> p. <fpage>367</fpage>&#x02013;<lpage>404</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Keats</surname><given-names>JA</given-names></name>. <article-title>Some generalizations of a theoretical distribution of mental test scores</article-title>. <source>Psychometrika</source>
<year>1964</year>; <volume>29</volume>:<fpage>215</fpage>&#x02013;<lpage>231</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref006"><label>6</label><mixed-citation publication-type="book">
<name><surname>Lord</surname><given-names>RM</given-names></name>, <name><surname>Novick</surname><given-names>MR</given-names></name>. <source>Statistical theories of mental test scores</source>. <publisher-loc>Reading, Mass.</publisher-loc>: <publisher-name>Addison-Wesley</publisher-name>; <year>1968</year>.</mixed-citation></ref><ref id="pone.0141981.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Huynh</surname><given-names>H</given-names></name>. <article-title>Error rates in competency testing when test retaking is permitted</article-title>. <source>J of Ed Stats</source>
<year>1990</year>; <volume>15</volume>: <fpage>39</fpage>&#x02013;<lpage>52</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Wilcox</surname><given-names>RR</given-names></name>. <article-title>A review of the beta-binomial model and its extensions</article-title>. <source>J of Ed Stats</source>
<year>1981</year>; <volume>6</volume>:<fpage>3</fpage>&#x02013;<lpage>32</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Polak</surname><given-names>E</given-names></name>, <name><surname>Ribi&#x000e8;re</surname><given-names>G</given-names></name>. <article-title>Note sur la convergence de directions conjugu&#x000e9;e</article-title>. <source>Rev. Francaise Informat Recherche Operationelle</source>
<year>1969</year>; <volume>16</volume>: <fpage>35</fpage>&#x02013;<lpage>43</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Fletcher</surname><given-names>R</given-names></name>, <name><surname>Reeves</surname><given-names>CM</given-names></name>. <article-title>Function minimization by conjugate gradients</article-title>. <source>Comput J.</source>, <year>1964</year>; <volume>7</volume>: <fpage>149</fpage>&#x02013;<lpage>154</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Nelder</surname><given-names>JA</given-names></name>, <name><surname>Mead</surname><given-names>R</given-names></name>. <article-title>A simplex method for function minimization</article-title>. <source>Comput J</source>
<year>1965</year>; <volume>7</volume>: <fpage>308</fpage>&#x02013;<lpage>313</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref012"><label>12</label><mixed-citation publication-type="book">
<name><surname>Wald</surname><given-names>A</given-names></name>. <chapter-title>Note on the identification of economic relations</chapter-title> In: <name><surname>Koopmans</surname><given-names>TC</given-names></name>, editor. <source>Statistical inference in dynamic economic models</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1950</year> p. <fpage>305</fpage>&#x02013;<lpage>310</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref013"><label>13</label><mixed-citation publication-type="book">
<name><surname>Rasch</surname><given-names>G</given-names></name>. <source>Probabilistic models for some intelligence and attainment tests</source>. <publisher-loc>Copenhagen</publisher-loc>: <publisher-name>The Danish institute of educational research</publisher-name>; <year>1960</year>.</mixed-citation></ref><ref id="pone.0141981.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Raftery</surname><given-names>A</given-names></name>. <article-title>A note on Bayes factors for log-linear contingency table models with vague prior information</article-title>. <source>JRSS Ser. B</source>
<year>1985</year>; <volume>48</volume>: <fpage>249</fpage>&#x02013;<lpage>250</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Weakliem</surname><given-names>DL</given-names></name>. <article-title>A critique of the Bayesian information criterion for model selection</article-title>. <source>Sociological Methods and Research</source>
<year>1999</year>; <volume>27</volume>:<fpage>359</fpage>&#x02013;<lpage>397</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Raftery</surname><given-names>A</given-names></name>. <article-title>Bayes factors and BIC</article-title>. <source>Sociological Methods and Research</source>
<year>1999</year>; <volume>27</volume>:<fpage>411</fpage>&#x02013;<lpage>427</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref017"><label>17</label><mixed-citation publication-type="book">
<name><surname>Stouffer</surname><given-names>SA</given-names></name>, <name><surname>Guttman</surname><given-names>L</given-names></name>, <name><surname>Suchman</surname><given-names>EA</given-names></name>, <name><surname>Lazarsfeld</surname><given-names>PF</given-names></name>, <name><surname>Star</surname><given-names>SA</given-names></name>, <name><surname>Clausen</surname><given-names>JA</given-names></name>. <source>Measurement and prediction</source>. <publisher-loc>Princeton</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>; <year>1950</year>.</mixed-citation></ref><ref id="pone.0141981.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Kelderman</surname><given-names>H</given-names></name>. <article-title>Loglinear Rasch model tests</article-title>. <source>Psychometrika</source>
<year>1984</year>; <volume>49</volume>: <fpage>223</fpage>&#x02013;<lpage>245</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Cressie</surname><given-names>N</given-names></name>, <name><surname>Holland</surname><given-names>PW</given-names></name>. <article-title>Characterizing the manifest probabilities of latent trait models</article-title>.&#x0201d; <source>Psychometrika</source>
<year>1983</year>; <volume>48</volume>:<fpage>129</fpage>&#x02013;<lpage>141</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref020"><label>20</label><mixed-citation publication-type="book">
<name><surname>Sniderman</surname><given-names>P</given-names></name>, <name><surname>Piazza</surname><given-names>T</given-names></name>, <name><surname>Peri</surname><given-names>P</given-names></name>, <name><surname>Schizzerotto</surname><given-names>A</given-names></name>. <source>Codebook for the 1994 survey on regional and ethnic prejudice in Italy</source>. <publisher-loc>Berkeley</publisher-loc>: <publisher-name>Survey Research Center, University of California</publisher-name>; <year>1994</year>.</mixed-citation></ref><ref id="pone.0141981.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Edwards</surname><given-names>AL</given-names></name>, <name><surname>Thurstone</surname><given-names>LL</given-names></name>. <article-title>An internal consistency check for scale values determined by the method of successive integers</article-title>.&#x0201d; <source>Psychometrika</source>
<year>1952</year>; <volume>17</volume>:<fpage>169</fpage>&#x02013;<lpage>180</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref022"><label>22</label><mixed-citation publication-type="book">
<name><surname>Bock</surname><given-names>RD</given-names></name>. <source>Multivariate statistical methods in behavioral research</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>; <year>1975</year>.</mixed-citation></ref><ref id="pone.0141981.ref023"><label>23</label><mixed-citation publication-type="book">
<source>Cox DR Analysis of binary data</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Chapman and Hall Ltd</publisher-name>; <year>1970</year>.</mixed-citation></ref><ref id="pone.0141981.ref024"><label>24</label><mixed-citation publication-type="book">
<name><surname>Maddala</surname><given-names>GS</given-names></name>. <chapter-title>Limited dependent and qualitative variables in econometrics</chapter-title>
<source>Econometric Society Monograph 3</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1983</year>.</mixed-citation></ref><ref id="pone.0141981.ref025"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Jansen</surname><given-names>PGW</given-names></name>, <name><surname>Roskam</surname><given-names>EE</given-names></name>. <article-title>Latent trait models and dichotomization of graded responses</article-title>. <source>Psychometrika</source>
<year>1986</year>; <volume>51</volume>:<fpage>69</fpage>&#x02013;<lpage>91</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref026"><label>26</label><mixed-citation publication-type="journal">
<name><surname>Thissen</surname><given-names>D</given-names></name>, <name><surname>Steinberg</surname><given-names>L</given-names></name>. <article-title>A taxonomy of item response models</article-title>. <source>Psychometrika</source>
<year>1986</year>; <volume>51</volume>:<fpage>567</fpage>&#x02013;<lpage>577</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref027"><label>27</label><mixed-citation publication-type="book">
<name><surname>Rasch</surname><given-names>G</given-names></name>. <chapter-title>An individualistic approach to item analysis</chapter-title> In: <name><surname>Lazarsfeld</surname><given-names>PF</given-names></name>
<name><surname>Henry</surname><given-names>NW</given-names></name>, editors. <source>Readings in mathematical and social science</source>. <publisher-loc>Cambridge, Mass.</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1966</year> p. <fpage>89</fpage>&#x02013;<lpage>107</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref028"><label>28</label><mixed-citation publication-type="journal">
<name><surname>Andrich</surname><given-names>D</given-names></name>. <article-title>Models for measurement, precision, and the nondichotomization of graded responses</article-title>. <source>Psychometrika</source>
<year>1995</year>; <volume>60</volume>:<fpage>7</fpage>&#x02013;<lpage>26</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref029"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Andrich</surname><given-names>D</given-names></name>. <article-title>Further remarks on nondichotomization of graded responses</article-title>. <source>Psychometrika</source>
<year>1995</year>; <volume>60</volume>: <fpage>37</fpage>&#x02013;<lpage>46</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref030"><label>30</label><mixed-citation publication-type="journal">
<name><surname>Andrich</surname><given-names>D</given-names></name>. <article-title>Distinctive and incompatible properties of two common classes of IRT models for graded responses</article-title>. <source>Applied Psychological Measurement</source>
<year>1995</year>; <volume>19</volume>: <fpage>101</fpage>&#x02013;<lpage>119</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Roskam</surname><given-names>EE</given-names></name>. <article-title>Graded responses and joining categories: A rejoinder to Andrich&#x02019;s &#x02018;Models for measurement, precision, and the nondichotomization of graded responses</article-title>.&#x02019; <source>Psychometrika</source>
<year>1995</year>; <volume>60</volume>, <fpage>27</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref032"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Greenfield</surname><given-names>TK</given-names></name>, <name><surname>Nayak</surname><given-names>MB</given-names></name>, <name><surname>Bond</surname><given-names>J</given-names></name>, <name><surname>Ye</surname><given-names>Y</given-names></name>, <name><surname>Midanik</surname><given-names>LT</given-names></name>. <article-title>Maximum quantity consumed and alcohol-related problems: assessing the most alcohol drunk with two measures</article-title>. <source>Alcoholism: clinical and experimental research</source>
<year>2006</year>; <volume>30</volume>, <fpage>1576</fpage>&#x02013;<lpage>1582</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref033"><label>33</label><mixed-citation publication-type="journal">
<name><surname>Andrich</surname><given-names>D</given-names></name>, <name><surname>Luo</surname><given-names>G</given-names></name>. <article-title>A hyperbolic cosine latent trait model for unfolding dichotomous single-stimulus responses</article-title>. <source>Appl Psych Meas</source>
<year>1993</year>; <volume>17</volume>: <fpage>253</fpage>&#x02013;<lpage>176</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Andrich</surname><given-names>D</given-names></name>. <article-title>A hyperbolic cosine latent trait model for unfolding polytomous responses: Reconciling Thurstone and Likert methodologies</article-title>. <source>Brit J of Math and Stat Psych</source>
<year>1996</year>; <volume>49</volume>: <fpage>347</fpage>&#x02013;<lpage>365</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref035"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Luo</surname><given-names>G</given-names></name>. <article-title>A general formulation for unidimensional unfolding and pairwise preference models</article-title>. <source>J Math Psych</source>
<year>1998</year>; <volume>42</volume>:<fpage>400</fpage>&#x02013;<lpage>417</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref036"><label>36</label><mixed-citation publication-type="journal">
<name><surname>Luo</surname><given-names>G</given-names></name>. <article-title>A class of probabilistic unfolding models for polytomous responses</article-title>. <source>J Math Psych</source>
<year>2001</year>; <volume>45</volume>:<fpage>224</fpage>&#x02013;<lpage>248</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref037"><label>37</label><mixed-citation publication-type="journal">
<name><surname>MacIntosh</surname><given-names>R</given-names></name>. <article-title>Global attitude measurement: An assessment of the world values survey postmaterialism scale</article-title>. <source>Am Soc Rev</source>
<year>1998</year>; <volume>63</volume>: <fpage>452</fpage>&#x02013;<lpage>464</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref038"><label>38</label><mixed-citation publication-type="journal">
<name><surname>Hagan</surname><given-names>J</given-names></name>, <name><surname>Foster</surname><given-names>H</given-names></name>. <article-title>Youth violence and the end of adolescence</article-title>. <source>Am Soc Rev</source>
<year>2001</year>; <volume>66</volume>: <fpage>874</fpage>&#x02013;<lpage>899</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref039"><label>39</label><mixed-citation publication-type="journal">
<name><surname>Hout</surname><given-names>M</given-names></name>, <name><surname>Greeley</surname><given-names>AM</given-names></name>. <article-title>The center doesn't hold: Church attendance in the United States</article-title>, <year>1940</year>&#x02013;1984. <source>Am Soc Rev 1987</source>; <volume>52</volume>: <fpage>325</fpage>&#x02013;<lpage>345</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref040"><label>40</label><mixed-citation publication-type="journal">
<name><surname>Browning</surname><given-names>CR</given-names></name>, <name><surname>Leventhal</surname><given-names>T</given-names></name>, <name><surname>Brooks-Gunn</surname><given-names>J</given-names></name>. <article-title>Sexual initiation in early adolescence: The nexus of parental and community control</article-title>. <source>Am Soc Rev</source>
<year>2005</year>; <volume>70</volume>: <fpage>758</fpage>&#x02013;<lpage>778</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref041"><label>41</label><mixed-citation publication-type="journal">
<name><surname>Oegema</surname><given-names>D</given-names></name>, <name><surname>Klandermans</surname><given-names>B</given-names></name>. <article-title>Why social movement sympathizers don't participate: Erosion and nonconversion of support</article-title>. <source>Am Soc Rev</source>
<year>1994</year>; <volume>59</volume>: <fpage>703</fpage>&#x02013;<lpage>722</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref042"><label>42</label><mixed-citation publication-type="journal">
<name><surname>Kelderman</surname><given-names>H</given-names></name>. <article-title>Item bias detection using loglinear IRT</article-title>. <source>Psychometrika</source>
<year>1989</year>; <volume>54</volume>:<fpage>681</fpage>&#x02013;<lpage>697</lpage>.</mixed-citation></ref><ref id="pone.0141981.ref043"><label>43</label><mixed-citation publication-type="book">
<name><surname>Brualdi</surname><given-names>RA</given-names></name>. <source>Introductory Combinatorics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>North Holland</publisher-name>; <year>1977</year>.</mixed-citation></ref></ref-list></back></article>