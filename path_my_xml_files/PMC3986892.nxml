<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Behav Brain Funct</journal-id><journal-id journal-id-type="iso-abbrev">Behav Brain Funct</journal-id><journal-title-group><journal-title>Behavioral and Brain Functions : BBF</journal-title></journal-title-group><issn pub-type="epub">1744-9081</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24670048</article-id><article-id pub-id-type="pmc">3986892</article-id><article-id pub-id-type="publisher-id">1744-9081-10-10</article-id><article-id pub-id-type="doi">10.1186/1744-9081-10-10</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Verbal learning in the context of background music: no influence of vocals and instrumentals on verbal learning</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>J&#x000e4;ncke</surname><given-names>Lutz</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I3">3</xref><email>lutz.jaencke@uzh.ch</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Br&#x000fc;gger</surname><given-names>Eliane</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>embruegger@yahoo.de</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Brummer</surname><given-names>Moritz</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>moritzbrummer@web.de</email></contrib><contrib contrib-type="author" id="A4"><name><surname>Scherrer</surname><given-names>Stephanie</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>stephsch_17@hotmail.com</email></contrib><contrib contrib-type="author" id="A5"><name><surname>Alahmadi</surname><given-names>Nsreen</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>naalahmade@kau.edu.sa</email></contrib></contrib-group><aff id="I1"><label>1</label>Psychological Institute, Department of Neuropsychology, University of Zurich, Zurich, Switzerland</aff><aff id="I2"><label>2</label>Program of Higher Educational Studies, Department of Special Education, King Abdulaziz University, Jeddah, 21589, Saudi Arabia</aff><aff id="I3"><label>3</label>University of Zurich, Binzm&#x000fc;hlestrasse 14, Zurich, 8050, Switzerland</aff><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>26</day><month>3</month><year>2014</year></pub-date><volume>10</volume><fpage>10</fpage><lpage>10</lpage><history><date date-type="received"><day>12</day><month>1</month><year>2014</year></date><date date-type="accepted"><day>19</day><month>3</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 J&#x000e4;ncke et al.; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>J&#x000e4;ncke et al.; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><self-uri xlink:href="http://www.behavioralandbrainfunctions.com/content/10/1/10"/><abstract><sec><title>Background</title><p>Whether listening to background music enhances verbal learning performance is still a matter of dispute. In this study we investigated the influence of vocal and instrumental background music on verbal learning.</p></sec><sec><title>Methods</title><p>226 subjects were randomly assigned to one of five groups (one control group and 4 experimental groups). All participants were exposed to a verbal learning task. One group served as control group while the 4 further groups served as experimental groups. The control group learned without background music while the 4 experimental groups were exposed to vocal or instrumental musical pieces during learning with different subjective intensity and valence. Thus, we employed 4 music listening conditions (vocal music with high intensity: VOC_HIGH, vocal music with low intensity: VOC_LOW, instrumental music with high intensity: INST_HIGH, instrumental music with low intensity: INST_LOW) and one control condition (CONT) during which the subjects learned the word lists. Since it turned out that the high and low intensity groups did not differ in terms of the rated intensity during the main experiment these groups were lumped together. Thus, we worked with 3 groups: one control group and two groups, which were exposed to background music (vocal and instrumental) during verbal learning. As dependent variable, the number of learned words was used. Here we measured immediate recall during five learning sessions (recall 1 &#x02013; recall 5) and delayed recall for 15&#x000a0;minutes (recall 6) and 14&#x000a0;days (recall 7) after the last learning session.</p></sec><sec><title>Results</title><p>Verbal learning improved during the first 5 recall sessions without any strong difference between the control and experimental groups. Also the delayed recalls were similar for the three groups. There was only a trend for attenuated verbal learning for the group passively listened to vocals. This learning attenuation diminished during the following learning sessions.</p></sec><sec><title>Conclusions</title><p>The exposure to vocal or instrumental background music during encoding did not influence verbal learning. We suggest that the participants are easily able to cope with this background stimulation by ignoring this information channel in order to focus on the verbal learning task.</p></sec></abstract></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>It is a popular believe that background music during learning exerts beneficial effects on learning. For example, a modern internet platform provides playlists claiming to improve learning and mental focus (<ext-link ext-link-type="uri" xlink:href="https://play.spotify.com/album/3NOgHfjdYZQLdTsBZYhNrZ">https://play.spotify.com/album/3NOgHfjdYZQLdTsBZYhNrZ</ext-link>). The idea that listening to background music boosts learning has a long tradition and has especially been proposed by Georgi Lozanov, a Bulgarian psychotherapist [<xref ref-type="bibr" rid="B1">1</xref>] who developed a teaching method (<italic>suggestopedia</italic>) in which background music (mostly classical music) during learning plays a pivotal role. In a 1993 review 10 studies were summarized [<xref ref-type="bibr" rid="B2">2</xref>] supporting this view. Nine of the reviewed studies used classical music as background stimulation (mostly baroque music which has been suggested by Lazanov to be the most efficient learning enhancer).</p><p>Besides these studies, which have been designed in the context of Lozanov&#x02019;s suggestopedia, several further studies without any relation to the suggestopedia school have been conducted examining the influence of background music on learning. For example, when the text to be learned is sung instead of being spoken recall of these text passages is much better [<xref ref-type="bibr" rid="B3">3</xref>]. Language learning (especially learning a second language, L2) has been shown to benefit from music listening during learning or when the learning material has been transformed into sung melodies [<xref ref-type="bibr" rid="B4">4</xref>]. This has recently been replicated in a study during which a second language (here Mandarin) has been learned with accompanying music [<xref ref-type="bibr" rid="B5">5</xref>]. In this study, individuals who learned Chinese performed better on all tests examining the learning progress. However, this positive influence of music on learning a second language was only evident for the group learning Mandarin but not for a group learning Arabic. However, the allocation of the subjects to the Chinese and Arabic groups was not random, thus some cohort effects might had some influence here.</p><p>A recent paper has focused on the role of background music on memory consolidation [<xref ref-type="bibr" rid="B6">6</xref>]. The authors identified that listening to arousing music (irrespective of the experienced valence of the presented music) during memory consolidation improved memory performance. This effect has been attributed to a kind of general neurophysiological arousal associated with the depletion of glucocorticoids and catecholamines enhancing memory consolidation. A further paper supported this view in demonstrating that listening to relaxing music during memory consolidation reduces memory performance [<xref ref-type="bibr" rid="B7">7</xref>] thus supporting the view that neurophysiological arousal is beneficial for consolidation.</p><p>However, negative or non-existing effects have also been reported. For example Salame and Baddeley [<xref ref-type="bibr" rid="B8">8</xref>] reported that listening to background vocal music during encoding interferes with verbal learning and results in reduced memory performance. A more recent study of our group studied the influence of auditory background melodies on verbal learning and identified no influence on recall performance [<xref ref-type="bibr" rid="B9">9</xref>]. However, the simultaneously recorded EEG revealed that background music increases cortical activation, most likely indicating increased cortical (and cognitive) effort to inhibit and down-regulate the interfering melodies to achieve good performance in verbal learning. Thus, this study supports the view that although there might be no difference in the behavioral measures of verbal learning there are however, neurophysiological indices indicating the increased effort for learning while simultaneous background music stimulation was present. In some way this finding supports the wealth of studies supporting the view that background music mostly acts as a distraction to the primary tasks [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B11">11</xref>].</p><p>In this experiment we are interested in readdressing the question whether background music might have an effect on verbal learning. Based on our first experiment in which we found no effect of background stimulation on verbal learning [<xref ref-type="bibr" rid="B9">9</xref>] we redesigned our experimental design. First of all we now use real music and not as in the first experiment artificial tone sequences. Second we examined a larger sample, and thirdly, we studied how learning performance changes during the course of repeated learning in the context of background stimuli. It might be possible that background music exerts its negative (or positive) influence at different stages of learning. For example, background music could be more disturbing at the beginning of learning and the learner might adapt to the background music after a while. In addition, we are interested in studying whether vocals and instrumental music might influence verbal learning differently. Since the primary task is to learn words, vocal music might interfere more strongly with the encoding and recall of verbal material than instrumental music.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Participants</title><p>226 participants (133 women and 93 men) were recruited for this experiment. They were invited to take part in a learning experiment through flyers distributed around campuses of the UZH and the ETH, an internet webpage of the UZH and the ETH, online social networking, and word-of-mouth. All subjects underwent an evaluation to screen for chronic diseases, mental disorders, medication, drug or alcohol abuse, and were tested with different neuropsychological and psychological tests (for measuring mental rotation ability, attention, and psychometric intelligence). After this screening 199 subjects (133 women and 66 men) were subjected to the final statistical analysis. 27 subjects were excluded because of excessive drug intake or neurological or psychiatric disorders. In addition, the subjects completed a questionnaire asking for music preferences, how often they listened to music in especially during learning sessions, and which music genre and which particular musical pieces they prefer. In addition, all subjects indicated for how long they played a musical instrument. And how often they had practiced their instrument. According to this variable four groups were defined with one group never have played and practiced an instrument (no practice &#x02013; P-: n&#x02009;=&#x02009;35), a second group, which indicated to have practiced for on average 6.8&#x000a0;yrs (few practice &#x02013; P+: n&#x02009;=&#x02009;67), a third group with 9.5&#x000a0;yrs of musical practice (moderate practice &#x02013; P++: n&#x02009;=&#x02009;32), and finally a group, which has practiced quite a lot with on average 13&#x000a0;yrs (frequent practice &#x02013; P+++: n&#x02009;=&#x02009;27). This variable (musical practice: PRAC) was used as control variable for the statistical analysis. Normal hearing ability was confirmed for all subjects using standard audiometry. For intelligence assessment, a short test [<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B13">13</xref>] was used that is known to correlate with standard intelligence test batteries (r&#x02009;=&#x02009;0.7 - 0.8). In addition, the NEO-FFI [<xref ref-type="bibr" rid="B14">14</xref>] was used to measure the personality trait &#x0201c;extraversion&#x0201d; because of its strong correlation with dual task performance [<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B16">16</xref>]. All subjects were consistently right-handed, as assessed with the Annett-Handedness-Questionnaire [<xref ref-type="bibr" rid="B17">17</xref>]. All subjects indicated not having received formal musical education for more than five years during their school years and that they had not played any musical instrument in the last 5&#x000a0;years. We also asked the subjects whether they had previously learned while listening to music. Most of them confirmed having done so. Each subject gave informed consent and received 30 Swiss Francs for participation. The study was carried out in accordance with the Declaration of Helsinki principles and was approved by the ethics committee of the University of Zurich as part of a larger research project on music and cognition.</p></sec><sec><title>Study design</title><p>The basic principle of this study was to explore verbal memory performance under different music background stimulation conditions similar to a previous experiment of our group [<xref ref-type="bibr" rid="B9">9</xref>]. The subjects repeatedly performed a verbal learning test while musical pieces were presented during verbal encoding and recall. Verbal learning was examined using words from a standard verbal learning test, which is frequently used for neuropsychological examinations with German-speaking subjects (<italic>Verbaler Lerntest</italic>, VLT). This test has been shown to validly measure verbal short and long-term memory [<xref ref-type="bibr" rid="B18">18</xref>,<xref ref-type="bibr" rid="B19">19</xref>]. This test was slightly modified for the needs of this experiment. In this experiment we used 50 German words, with 30 words taken from the original verbal learning test. We included 20 new words to prevent ceiling effects. Thus, this test material was identical to the test material we have used in a previous experiment [<xref ref-type="bibr" rid="B20">20</xref>]. During encoding these 50 words were randomly presented for 3&#x000a0;seconds each via PowerPoint and a beamer to a screen in front of the subjects (font&#x02009;=&#x02009;Calibri; font size&#x02009;=&#x02009;96; color&#x02009;=&#x02009;black, distance from subject to screen 2&#x02013;3&#x000a0;m). The subjects were instructed to look at the words attentively and to learn them by heart. Those subjects learning during music stimulation were not specifically instructed how to cope with the background music. After the encoding phase (duration&#x02009;=&#x02009;150&#x000a0;seconds) the subjects were instructed to write down all remembered words on an answer sheet placed in front of them (recall phase; duration&#x02009;=&#x02009;4&#x000a0;minutes). After the recall phase a new trial started. This procedure was repeated 4 times (trial1 &#x02013; trial4) yielding 4 recall scores (RECALL1 - RECALL4). During these 4 phases subjects of the music background groups received music stimulation. After the 4th trial a break of 10&#x000a0;minutes was included followed by a further recall test (RECALL5). The 6th recall (RECALL6) followed 30&#x000a0;minutes after the 5th recall. Approximately 2&#x000a0;weeks (on average 13.4&#x000a0;days) after the 6th recall a long-term delayed recall test was performed (RECALL7). The recall tests 5, 6 and 7 were all conducted without any music stimulation even for the music listening groups. The tests were conducted as group tests with 4&#x02013;8 subjects participating simultaneously at each session. The music stimuli were presented via wireless headphones (Sennheiser HDR 130).</p></sec><sec><title>Musical stimuli and group allocation</title><p>Contrary to the previous study of our group we have used real musical pieces, which have been rated as emotionally positive. Our intention was to use positive music with high and low experienced intensity since the study of Judde et al. [<xref ref-type="bibr" rid="B6">6</xref>] has shown that the subjectively experienced intensity exerts strong influences on memory performance especially on memory consolidation. Furthermore, we were interested in testing whether verbal learning is influenced differently by simultaneously listening to vocals or to instrumental music. Thus, we also used vocal and instrumental music, resulting in 4 music listening conditions (vocal music with high intensity: VOC_HIGH, vocal music with low intensity: VOC_LOW, instrumental music with high intensity: INST_HIGH, instrumental music with low intensity: INST_LOW) and one control condition (CONT) during which the subjects learned the word lists in silence. All subjects were randomly assigned to one of these five experimental groups. These five groups did not differ significantly in terms of age, extraversion/introversion, attention performance, mental rotation performance, or educational level (all variables tested with Kruskal-Wallis-U-test). However, there was marginally significant differences for IQ (p&#x02009;=&#x02009;0.057), with subjects from the INST group demonstrating a slightly higher IQ. Therefore IQ was used as a covariate for the statistical analysis.</p><p>The musical pieces were collected on the basis of a pilot test during which 50 subjects (mostly university students from the UZH and ETH) evaluated 31 music pieces from a collection of modern music frequently presented in radio programs or which have been used in previous experiments [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B21">21</xref>]. These musical pieces were combined into a playlist using the internet platform <ext-link ext-link-type="uri" xlink:href="http://www.grooveshark.com">http://www.grooveshark.com</ext-link> and sent to these subjects via e-mail. The subjects were asked to rate these musical pieces with respect to the experienced valence and intensity using a 1&#x02013;9 Likert scales for intensity and valence (intensity: &#x0201c;1&#x0201d;&#x02009;=&#x02009;not at all arousing, &#x0201c;9&#x0201d;&#x02009;=&#x02009;very strongly arousing; valence: &#x0201c;1&#x0201d;&#x02009;=&#x02009;not at all liking, &#x0201c;9&#x0201d;&#x02009;=&#x02009;very strongly liking). Based on these ratings we selected 19 music pieces, which were rated at least as very positive (with a value of &#x0003e;5 on the valence scale). In addition, we selected musical pieces rated as arousing (with a value&#x02009;&#x0003e;&#x02009;5) and less arousing (value&#x02009;&#x0003c;&#x02009;4.8). Furthermore, we chose vocal and instrumental music. The chosen music pieces are listed in Table&#x000a0;<xref ref-type="table" rid="T1">1</xref>. These music pieces were also rated for valence and intensity during the main experiment. Contrary to the pilot experiment the music pieces, which have been rated as evoking low and high intensity did not differ in terms of the subjectively experienced intensity. Thus, we decided to combine the experimental groups receiving low and high intensity musical pieces during encoding and recall into one group. Thus, for the final analysis we worked with three groups: vocal (VOCAL) and instrumental (INST) music as well as the control group (CONT). The sample characteristics of the three groups are depicted in Table&#x000a0;<xref ref-type="table" rid="T2">2</xref>.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Used music with average rated valence and intensity</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="center"/><col align="center"/><col align="center"/></colgroup><thead valign="top"><tr><th align="left">&#x000a0;</th><th align="center"><bold>Duration (s)</bold></th><th align="center"><bold>Valence</bold></th><th align="center"><bold>Intensity</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom"><bold>
<italic>Vocal music (strong subjective intensity)</italic>
</bold><hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">(Peter Fox) Alles Neu<hr/></td><td align="center" valign="bottom">258<hr/></td><td align="center" valign="bottom">5.38<hr/></td><td align="center" valign="bottom">5.07<hr/></td></tr><tr><td align="left" valign="bottom">(Die Toten Hosen) Bonnie und Clyde<hr/></td><td align="center" valign="bottom">211<hr/></td><td align="center" valign="bottom">5.79<hr/></td><td align="center" valign="bottom">5.38<hr/></td></tr><tr><td align="left" valign="bottom">(Die Fantastischen Vier) Troy<hr/></td><td align="center" valign="bottom">210<hr/></td><td align="center" valign="bottom">5.33<hr/></td><td align="center" valign="bottom">5.58<hr/></td></tr><tr><td align="left" valign="bottom">(Die &#x000c4;rzte) Junge<hr/></td><td align="center" valign="bottom">188<hr/></td><td align="center" valign="bottom">5.00<hr/></td><td align="center" valign="bottom">5.80<hr/></td></tr><tr><td align="left" valign="bottom">(Xavier Naidoo) Sie sieht mich nicht<hr/></td><td align="center" valign="bottom">267<hr/></td><td align="center" valign="bottom">6.47<hr/></td><td align="center" valign="bottom">5.26<hr/></td></tr><tr><td align="left" valign="bottom"><bold>
<italic>Vocal music (weak subjective intensity)</italic>
</bold><hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">(Gisbert zu Knyphausen) Spieglein, Spieglein<hr/></td><td align="center" valign="bottom">160<hr/></td><td align="center" valign="bottom">5.21<hr/></td><td align="center" valign="bottom">4.69<hr/></td></tr><tr><td align="left" valign="bottom">(Die S&#x000f6;hne Mannheims) IzOn<hr/></td><td align="center" valign="bottom">298<hr/></td><td align="center" valign="bottom">5.14<hr/></td><td align="center" valign="bottom">4.55<hr/></td></tr><tr><td align="left" valign="bottom">(Die Fantastischen Vier) Tag am Meer<hr/></td><td align="center" valign="bottom">255<hr/></td><td align="center" valign="bottom">5.04<hr/></td><td align="center" valign="bottom">3.89<hr/></td></tr><tr><td align="left" valign="bottom">(Freundeskreis) Anna<hr/></td><td align="center" valign="bottom">366<hr/></td><td align="center" valign="bottom">5.38<hr/></td><td align="center" valign="bottom">4.72<hr/></td></tr><tr><td align="left" valign="bottom">(Wir sind Helden) Ode an die Arbeit<hr/></td><td align="center" valign="bottom">223<hr/></td><td align="center" valign="bottom">5.41<hr/></td><td align="center" valign="bottom">4.24<hr/></td></tr><tr><td align="left" valign="bottom"><bold>
<italic>Instrumental (strong subjective intensity)</italic>
</bold><hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">(Howard Show) Anduril<hr/></td><td align="center" valign="bottom">159<hr/></td><td align="center" valign="bottom">5.40<hr/></td><td align="center" valign="bottom">5.10<hr/></td></tr><tr><td align="left" valign="bottom">(Holst) The Planets - Jupiter, the Bringer<hr/></td><td align="center" valign="bottom">480<hr/></td><td align="center" valign="bottom">6.42<hr/></td><td align="center" valign="bottom">6.55<hr/></td></tr><tr><td align="left" valign="bottom">(Alvfen) Midsommarvaka<hr/></td><td align="center" valign="bottom">540<hr/></td><td align="center" valign="bottom">5.46<hr/></td><td align="center" valign="bottom">5.14<hr/></td></tr><tr><td align="left" valign="bottom">(Klaus Badelt) The Medallion Calls<hr/></td><td align="center" valign="bottom">112<hr/></td><td align="center" valign="bottom">5.50<hr/></td><td align="center" valign="bottom">5.80<hr/></td></tr><tr><td align="left" valign="bottom"><bold>
<italic>Instrumental (weak subjective intensity)</italic>
</bold><hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">(John Williams) Nocturnal Activities<hr/></td><td align="center" valign="bottom">360<hr/></td><td align="center" valign="bottom">5.40<hr/></td><td align="center" valign="bottom">3.90<hr/></td></tr><tr><td align="left" valign="bottom">(Bill Conti) Fanfare for Rocky<hr/></td><td align="center" valign="bottom">155<hr/></td><td align="center" valign="bottom">5.20<hr/></td><td align="center" valign="bottom">4.60<hr/></td></tr><tr><td align="left" valign="bottom">(John Williams) Scherzo for Motorcycle and Orchestra<hr/></td><td align="center" valign="bottom">169<hr/></td><td align="center" valign="bottom">5.30<hr/></td><td align="center" valign="bottom">4.40<hr/></td></tr><tr><td align="left" valign="bottom">(John Williams and William Ross) Reunion of Friends<hr/></td><td align="center" valign="bottom">300<hr/></td><td align="center" valign="bottom">5.70<hr/></td><td align="center" valign="bottom">4.40<hr/></td></tr><tr><td align="left">(New Worlds Orchestra) Many Meetings &#x02013; Soundtrack of Lord of the Rings</td><td align="center">194</td><td align="center">5.40</td><td align="center">4.80</td></tr></tbody></table><table-wrap-foot><p>(intensity: &#x0201c;1&#x0201d; = not at all arousing, &#x0201c;9&#x0201d; = very strongly arousing; valence: &#x0201c;1&#x0201d; = not at all liking, &#x0201c;9&#x0201d; = very strongly liking).</p></table-wrap-foot></table-wrap><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Mean sample characteristics of the three groups studied</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="center"/><col align="center"/><col align="center"/></colgroup><thead valign="top"><tr><th align="left">&#x000a0;</th><th align="center"><bold>Control</bold></th><th align="center"><bold>Vocal</bold></th><th align="center"><bold>Instrumental</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom">Age<hr/></td><td align="center" valign="bottom">25.6&#x02009;&#x000b1;&#x02009;5.9<hr/></td><td align="center" valign="bottom">25.23&#x02009;&#x000b1;&#x02009;5.43<hr/></td><td align="center" valign="bottom">26.65&#x02009;&#x000b1;&#x02009;6.76<hr/></td></tr><tr><td align="left" valign="bottom">Education (1: low 5 high)<hr/></td><td align="center" valign="bottom">3.4&#x02009;&#x000b1;&#x02009;1<hr/></td><td align="center" valign="bottom">3.5&#x02009;&#x000b1;&#x02009;1<hr/></td><td align="center" valign="bottom">3.5&#x02009;&#x000b1;&#x02009;0.9<hr/></td></tr><tr><td align="left" valign="bottom">IQ<hr/></td><td align="center" valign="bottom">100.2&#x02009;&#x000b1;&#x02009;10.7<hr/></td><td align="center" valign="bottom">101.9&#x02009;&#x000b1;&#x02009;11.9<hr/></td><td align="center" valign="bottom">105.7&#x02009;&#x000b1;&#x02009;14.0<hr/></td></tr><tr><td align="left" valign="bottom">Extraversion/Introversion<hr/></td><td align="center" valign="bottom">2.75&#x02009;&#x000b1;&#x02009;0.44<hr/></td><td align="center" valign="bottom">2.55&#x02009;&#x000b1;&#x02009;0.52<hr/></td><td align="center" valign="bottom">2.58&#x02009;&#x000b1;&#x02009;0.53<hr/></td></tr><tr><td align="left" valign="bottom">N of subjects<hr/></td><td align="center" valign="bottom">40<hr/></td><td align="center" valign="bottom">79<hr/></td><td align="center" valign="bottom">80<hr/></td></tr><tr><td align="left">% female</td><td align="center">67.5&#x000a0;%</td><td align="center">65.8&#x000a0;%</td><td align="center">67.5&#x000a0;%</td></tr></tbody></table></table-wrap></sec><sec><title>Statistical analysis</title><p>For the recall tests the number of correctly recalled words was calculated for each recall trial resulting in 7 recall measures for each group. Thus, we obtained three learning curves, one for each group. The mean recall scores for each group are depicted in Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>. These learning curves were subjected to a repeated measures ANCOVA with IQ as covariate. For the repeated measurements factor and the interaction including the repeated measurements factor we used the multivariate variant to cope with heteroscedasticity of variances [<xref ref-type="bibr" rid="B22">22</xref>]. In addition, we also performed a multivariate one-way MANCOVA for all recall measures with IQ as covariate to compare the recall performance of the three groups separately for each recall measure. In case of heterogeneity of variances we used the Brown-Forsyth correction. A p of&#x02009;&#x0003c;&#x02009;=0.05 was defined as significant. Besides the p values we also calculated effect size measures since it is important to quantify the effect independent of sample size. Here we used eta<sup>2</sup>.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Average recall performance (and standard errors of the mean) for the 7 recall stages (r1-r7) broken down for the three groups (control, vocal, and instrumental music).</bold> Recall 5 (r5) and recall 6 (r6) were conducted 10 and 30&#x000a0;minutes after recall 4 (r4). Recall 7 (r7) was conducted 2&#x000a0;weeks after the experiment. The participants of the vocal and instrumental groups received background music stimulation during the learning sessions r1-r4. The recall scores presented here are adjusted for psychometric intelligence.</p></caption><graphic xlink:href="1744-9081-10-10-1"/></fig></sec></sec><sec sec-type="results"><title>Results</title><p>As already mentioned above, the three groups did not differ in terms of age, education, mental rotation performance, attention performance, gender, and musical experience (all p values at least&#x02009;&#x0003e;&#x02009;0.15). However, there was a marginally significant difference between the groups for IQ (F(2,196)&#x02009;=&#x02009;3.025, p&#x02009;=&#x02009;0.051). Thus, we used IQ as covariate for the following statistical analyses.</p><p>First, we calculated a two-way repeated measures ANCOVA with <italic>Time</italic> as repeated measurements factor (recall1 &#x02013; recall7) and <italic>Group</italic> as grouping factor (CONT, VOC, INST). For testing the repeated measurements factor we used the MANCOVA approach to guard against heteroscedasticity. For the MANCOVA F-test we used Wilk&#x02019;s lambda. For <italic>Time</italic> we received a significant effect (F(6,190)&#x02009;=&#x02009;12.994, p &#x0003c;0.001, eta<sup>2</sup>&#x02009;=&#x02009;0.291) representing the fact that the recall score improves from trial 1 to 7. The interaction between <italic>Time</italic> and <italic>Group</italic> was not significant (F(12,382)&#x02009;=&#x02009;1.43, p&#x02009;=&#x02009;0.150, eta<sup>2</sup>&#x02009;=&#x02009;0.043). There was no general <italic>Group</italic> difference (F(2,195)&#x02009;=&#x02009;1.39, p&#x02009;=&#x02009;0.252, eta<sup>2</sup>&#x02009;=&#x02009;0.014). Planned trend analyses conducted within this ANCOVA revealed strong linear (F(1,195)&#x02009;=&#x02009;8.64, p&#x02009;=&#x02009;0.004, eta<sup>2</sup>&#x02009;=&#x02009;0.042) and quadratic trends (F(1,195)&#x02009;=&#x02009;52.685, p&#x02009;&#x0003c;&#x02009;0.001, eta<sup>2</sup>&#x02009;=&#x02009;0.213) for the learning curves with only one significant interaction with <italic>Group</italic> for the linear trend (F(2,195)&#x02009;=&#x02009;3.043, p&#x02009;=&#x02009;0.05, eta<sup>2</sup>&#x02009;=&#x02009;0.03). Graphical inspection of the learning curves revealed that the subjects of the VOCAL group showed lower recall scores for the first three learning sessions while the recall scores in sessions 4, 5, 6 and 7 seemed to be similar to the recall scores of the other two groups. Thus, we performed a further MANOVA with every recall score (recall1 &#x02013; recall7) as dependent variable and compared the VOCAL group with the other groups ((INST&#x02009;+&#x02009;CONT)/2). This MANCOVA revealed a trend for a significant multivariate between-groups difference (F(7,198)&#x02009;=&#x02009;1.94, p&#x02009;=&#x02009;0.064, eta<sup>2</sup>&#x02009;=&#x02009;0.067). The subsequently performed ANOVAs for the single recall scores (recall1 &#x02013; recall7) with the planned comparisons between the VOCAL group and the other groups revealed small differences between these groups for the first three recall scores (recall1: p&#x02009;=&#x02009;0.025, eta<sup>2</sup>&#x02009;=&#x02009;0.025; recall2: p&#x02009;=&#x02009;0.019, eta<sup>2</sup>&#x02009;=&#x02009;0.03; recall3: p&#x02009;=&#x02009;0.045, eta<sup>2</sup>&#x02009;=&#x02009;0.02).</p></sec><sec sec-type="discussion"><title>Discussion</title><p>This study is the second study of a series of experiments in which we examine the influence of background music on learning and in particular on verbal learning. In the first experiment of this series we used artificial melodies to control for individual differences in musical preference and for memory effects [<xref ref-type="bibr" rid="B9">9</xref>]. Using these stimuli we identified no influence of musical background on verbal learning. However, a critical aspect of this first study is the fact that the musical pieces we used were artificial and did not evoke strong emotions. Therefore, we designed the present study for which we employed &#x0201c;real&#x0201d; music and also used vocals as well as instrumentals to test whether these types of music exert different influences on verbal learning. A further point we tried to realize was to keep learning as natural as possible. Thus, we tested the subjects in groups (similar to a classroom setting) and continuously recorded their learning progress. In addition, we tried to separate immediate from delayed learning performance. After doing this, we identified no significant influence of background music on verbal learning. This non-detectable influence was evident for the immediate recall tests as well as for the delayed recall tests. It is worth mentioning that there was also no influence on late recall measured 14&#x000a0;days after learning.</p><p>Interestingly, there was no specific influence of the particular type of music on learning since vocals or instrumental music did not differ in terms of their non-detectable influence on learning. This is particularly important because we hypothesized that listening to vocals during learning would interfere especially with encoding, consolidation, and recall of verbal material. However, there was no strong and statistically significant influence of listening to vocals on verbal learning.</p><p>There was a small (non-significant) effect of listening to vocals upon verbal learning. The subjects who have been exposed to vocals demonstrated reduced recall in the first three recall sessions at the beginning of the experiment. This slight decrease in recall performance at the beginning disappeared throughout the experiment. This small effect might be due to an initially present interference effect of vocals on verbal learning and resembles the effect reported by Salame and Baddeley [<xref ref-type="bibr" rid="B8">8</xref>]. Salame and Baddeley tested verbal recall in the presence of vocal and instrumental music and identified that those subjects who heard vocal music performed worse than the subjects in a silent condition. This kind of verbal interference was quite small in our experiment and the subjects were able to efficiently cope with this interference, and they could do so even better and more efficiently at the end of the experiment. In our previous experiment we also obtained brain activation measures during learning and we identified that &#x0201c;demanding&#x0201d; background music (musical pieces which were fast and out-of-tune) was associated with increased brain activation. Obviously, the subjects could cope with detracting information by increasing the neurophysiological activation of the involved brain areas.</p><p>It is worth mentioning that there was even no positive and enhancing effect on verbal learning, an effect, which has been proposed by several researchers and theoreticians. For example it has been proposed that music would activate the brain thus evoking supporting chemical reactions (e.g., depletion of glucocorticoids and catecholamines) [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B7">7</xref>].</p><p>A possible reason for the non-existing influence of background music on verbal learning could be that verbal learning of this material was too easy. If the background music was too easy it could be not disturbing enough in order to interfere with verbal learning. If we would have used more demanding verbal stimuli (e.g., words in a foreign language) it might have been possible that more processing resources would have been devoted to control encoding, consolidation, and recall. Thus, background music might have been more interfering in this situation, like a kind of dual task, with background music as the secondary task and verbal learning as the primary task.</p><p>A further reason for the non-existing influence of background music could be that the subjects focused their attention strongly on the learning task. When doing this they literally ignored the background music. From neurophysiological studies it is known that ignoring external stimuli strongly attenuates activity in those brain areas and neural networks processing the ignored stimuli [<xref ref-type="bibr" rid="B23">23</xref>-<xref ref-type="bibr" rid="B25">25</xref>]. Thus, it could be that the background music is not processed that intensively, causing no strong neurophysiological and psychological interference. Possibly, if we would have asked the subjects to listen attentively to the music or to perform some kind of discrimination tasks with the musical pieces this would have exerted detrimental effects. Gopher and Donchin [<xref ref-type="bibr" rid="B26">26</xref>] have demonstrated that the amount of processing resources allocated to different information channels is most important for the influence of the secondary task on the processing of the primary task. The more processing resources are allocated to the secondary task the worse is the performance of the primary task. In the context of our experiment this implies that our subjects have spent more resources on the primary task (verbal learning) than on the secondary task (listening to the music).</p><p>However, a final question is still unanswered. As mentioned in the introduction there are some quite influential ideas appearing in the literature proposing that background music positively influences learning in general [<xref ref-type="bibr" rid="B1">1</xref>]. With our experiment we cannot support these views, at least not with the music used and in the context of our experimental paradigm. Despite the fact that we have used pleasant and arousing music, we did not detect positive influences on verbal learning. Maybe arousing music supports learning only when it is presented 15&#x02013;20&#x000a0;minutes after encoding of the learning material (and not during encoding as in our experiment). Or it could be that background music only exerts beneficial effects on learning when the subjects are under-activated, tired, less aroused, or their memory systems operate inefficiently due to neurological handicaps. In fact some studies have shown that background noise (not music) can enhance cognitive performance in inattentive participants [<xref ref-type="bibr" rid="B27">27</xref>]. Background stimulation might enhance arousal and diminishes drowsiness in these patients, which might also improve cognitive performance.</p><sec><title>Limitations</title><p>A methodological limitation of this study is that the participants listened to music that they didn&#x02019;t choose by themselves. Normally, when learning we choose the background music which we believe is most suitable for us to support learning. Thus, we will consciously or unconsciously choose the music which we believe would best fit our needs. We also choose how long and how often we listen to background music while learning, depending on our mood and/or attentional level. Thus, we decide when we listen to background music and which musical piece is running as background music. In our experiment this was not controlled for. However, future experiments should clarify whether these aspects might have influences on the effects of background music on cognition in general and learning in particular.</p></sec></sec><sec sec-type="conclusions"><title>Conclusion</title><p>Using pleasant and arousing vocal and instrumental background music we found no strong influence of background music on verbal learning. We suggest that the participants are easily able to cope with this background stimulation by ignoring this information channel in order to focus on the verbal learning task.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors&#x02019; contributions</title><p>LJ designed the experimental paradigm, performed the statistical analysis and drafted the manuscript. AN, EB, MB, and SS reviewed the statistical analysis and drafted the manuscript. All authors read and approved the final manuscript.</p></sec></body><back><sec><title>Acknowledgements</title><p>Eliane Br&#x000fc;gger, Moritz Brummer and Stephanie Scherrer used these data for finalising their Masters thesis in psychology.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="book"><name><surname>Lozanov</surname><given-names>G</given-names></name><source>Suggestology and Outlines of Suggestopedy</source><year>1978</year><publisher-name>New York: Gordon &#x00026; Breach</publisher-name></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Felix</surname><given-names>U</given-names></name><article-title>The contribution of background music to the enhancement of learning in suggestopedia: a critical review of the literature</article-title><source>J Soc Accel Learn Teach</source><year>1993</year><volume>10</volume><fpage>277</fpage><lpage>303</lpage></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Wallace</surname><given-names>WT</given-names></name><article-title>Memory for music: effect of melody on recall of text</article-title><source>J Exp Psychol Learn Mem Cogn</source><year>1994</year><volume>10</volume><fpage>1471</fpage><lpage>1485</lpage></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Legg</surname><given-names>R</given-names></name><article-title>Using music to accelerate language learning: an experimental study</article-title><source>Res Educ</source><year>2009</year><volume>10</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.7227/RIE.82.1</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="other"><name><surname>Kang</surname><given-names>HJ</given-names></name><name><surname>Williamson</surname><given-names>VJ</given-names></name><article-title>Background music can aid second language learning</article-title><source>Psychol Music</source><year>2013</year><comment>August</comment></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Judde</surname><given-names>S</given-names></name><name><surname>Rickard</surname><given-names>N</given-names></name><article-title>The effect of post-learning presentation of music on long-term word-list retention</article-title><source>Neurobiol Learn Mem</source><year>2010</year><volume>10</volume><fpage>13</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2010.03.002</pub-id><pub-id pub-id-type="pmid">20307678</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Rickard</surname><given-names>NS</given-names></name><name><surname>Wong</surname><given-names>WW</given-names></name><name><surname>Velik</surname><given-names>L</given-names></name><article-title>Relaxing music counters heightened consolidation of emotional memory</article-title><source>Neurobiol Learn Mem</source><year>2012</year><volume>10</volume><fpage>220</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2011.12.005</pub-id><pub-id pub-id-type="pmid">22207009</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Salam&#x000e9;</surname><given-names>P</given-names></name><name><surname>Baddeley</surname><given-names>A</given-names></name><article-title>Effects of background music on phonological short-term memory</article-title><source>Q J Exp Psychol Sect A</source><year>1989</year><volume>10</volume><fpage>107</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1080/14640748908402355</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>J&#x000e4;ncke</surname><given-names>L</given-names></name><name><surname>Sandmann</surname><given-names>P</given-names></name><article-title>Music listening while you learn: no influence of background music on verbal learning</article-title><source>Behav Brain Funct</source><year>2010</year><volume>10</volume><fpage>3</fpage><pub-id pub-id-type="doi">10.1186/1744-9081-6-3</pub-id><pub-id pub-id-type="pmid">20180945</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Klatte</surname><given-names>M</given-names></name><name><surname>Kilcher</surname><given-names>H</given-names></name><name><surname>Hellbruck</surname><given-names>J</given-names></name><article-title>The effects of temporal structure of background noise on working memory: theoretical and practical implications</article-title><source>Z Exp Psychol</source><year>1995</year><volume>10</volume><fpage>517</fpage><lpage>544</lpage></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Ellermeier</surname><given-names>W</given-names></name><name><surname>Hellbruck</surname><given-names>J</given-names></name><article-title>Is level irrelevant in &#x0201c;Irrelevant speech&#x0201d;? Effects of loudness, signal-to-noise ratio, and binaural unmasking</article-title><source>J Exp Psychol Hum</source><year>1998</year><volume>10</volume><fpage>1406</fpage><lpage>1414</lpage></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><name><surname>Lehrl</surname><given-names>S</given-names></name><name><surname>Gallwitz</surname><given-names>A</given-names></name><name><surname>Blaha</surname><given-names>L</given-names></name><name><surname>Fischer</surname><given-names>B</given-names></name><source>Geistige Leistungsf&#x000e4;higkeit - Theorie Und Messung Der Biologischen Intelligenz Mit Dem Kurztest KAI</source><year>1992</year><publisher-name>Vless: Ebersberg</publisher-name></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Lehrl</surname><given-names>S</given-names></name><name><surname>Triebig</surname><given-names>G</given-names></name><name><surname>Fischer</surname><given-names>B</given-names></name><article-title>Multiple-choice vocabulary-test Mwt as a valid and short test to estimate premorbid intelligence</article-title><source>Acta Neurol Scand</source><year>1995</year><volume>10</volume><fpage>335</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1111/j.1600-0404.1995.tb07018.x</pub-id><pub-id pub-id-type="pmid">7639062</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><name><surname>Borkenau</surname><given-names>P</given-names></name><name><surname>Ostendorf</surname><given-names>F</given-names></name><source>NEO-FFI NEO-F&#x000fc;nf-Faktoren Inventar Nach Costa Und McCrae</source><year>1993</year><publisher-name>G&#x000f6;ttingen: Hogrefe</publisher-name></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Furnham</surname><given-names>A</given-names></name><name><surname>Bradley</surname><given-names>A</given-names></name><article-title>Music while you work: the differential distraction of background music on the cognitive test performance of introverts and extraverts</article-title><source>Appl Cogn Psychol</source><year>1997</year><volume>10</volume><fpage>445</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1099-0720(199710)11:5&#x0003c;445::AID-ACP472&#x0003e;3.0.CO;2-R</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><name><surname>Furnham</surname><given-names>A</given-names></name><name><surname>Trew</surname><given-names>S</given-names></name><name><surname>Sneade</surname><given-names>I</given-names></name><article-title>The distracting effects of vocal and instrumental music on the cognitive test performance of introverts and extraverts</article-title><source>Pers Individ Dif</source><year>1999</year><volume>10</volume><fpage>381</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1016/S0191-8869(98)00249-9</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Annett</surname><given-names>M</given-names></name><article-title>A classification of hand preference by association analysis</article-title><source>Br J Psychol</source><year>1970</year><volume>10</volume><fpage>303</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8295.1970.tb01248.x</pub-id><pub-id pub-id-type="pmid">5457503</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="book"><name><surname>Helmstaedter</surname><given-names>C</given-names></name><name><surname>Lendt</surname><given-names>M</given-names></name><name><surname>Lux</surname><given-names>S</given-names></name><source>Verbaler Lern-Und Merkf&#x000e4;higkeitstest: Vlmt; Manual</source><year>2001</year><publisher-name>Beltz-Test</publisher-name></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><name><surname>Helmstaedter</surname><given-names>C</given-names></name><name><surname>Durwen</surname><given-names>HF</given-names></name><article-title>VLMT: Verbaler Lern- und Merkf&#x000e4;higkeitstest: Ein praktikables und differenziertes Instrumentarium zur Pr&#x000fc;fung der verbalen Ged&#x000e4;chtnisleistungen</article-title><source>Schweizer Arch f&#x000fc;r Neurol und Psychiatr</source><year>1990</year><volume>10</volume><fpage>21</fpage><lpage>30</lpage></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Elmer</surname><given-names>S</given-names></name><name><surname>Burkard</surname><given-names>M</given-names></name><name><surname>Renz</surname><given-names>B</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name><name><surname>Jancke</surname><given-names>L</given-names></name><article-title>Direct current induced short-term modulation of the left dorsolateral prefrontal cortex while learning auditory presented nouns</article-title><source>Behav Brain Funct</source><year>2009</year><volume>10</volume><fpage>29</fpage><pub-id pub-id-type="doi">10.1186/1744-9081-5-29</pub-id><pub-id pub-id-type="pmid">19604352</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Baumgartner</surname><given-names>T</given-names></name><name><surname>Esslen</surname><given-names>M</given-names></name><name><surname>J&#x000e4;ncke</surname><given-names>L</given-names></name><article-title>From emotion perception to emotion experience: emotions evoked by pictures and classical music</article-title><source>Int J Psychophysiol</source><year>2006</year><volume>10</volume><fpage>34</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2005.04.007</pub-id><pub-id pub-id-type="pmid">15993964</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>O&#x02019;Brien</surname><given-names>RG</given-names></name><name><surname>Kaiser</surname><given-names>MK</given-names></name><article-title>MANOVA method for analyzing repeated measures designs: an extensive primer</article-title><source>Psychol Bull</source><year>1985</year><volume>10</volume><fpage>316</fpage><lpage>333</lpage><pub-id pub-id-type="pmid">3983301</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Jancke</surname><given-names>L</given-names></name><name><surname>Mirzazade</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>NJ</given-names></name><article-title>Attention modulates the blood oxygen level dependent response in the primary visual cortex measured with functional magnetic resonance imaging</article-title><source>Naturwissenschaften</source><year>1999</year><volume>10</volume><fpage>79</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1007/s001140050575</pub-id><pub-id pub-id-type="pmid">10084151</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="other"><name><surname>J&#x000e4;ncke</surname><given-names>L</given-names></name><name><surname>Mirzazade</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>NJ</given-names></name><source>Attention Modulates Activity in the Primary and the Secondary Auditory Cortex: a Functional Magnetic Resonance Imaging Study in Human Subjects. Volume 266</source><year>1999</year><fpage>125</fpage><lpage>128</lpage></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Jancke</surname><given-names>L</given-names></name><name><surname>Buchanan</surname><given-names>TW</given-names></name><name><surname>Lutz</surname><given-names>K</given-names></name><name><surname>Shah</surname><given-names>NJ</given-names></name><article-title>Focused and nonfocused attention in verbal and emotional dichotic listening: an FMRI study</article-title><source>Brain Lang</source><year>2001</year><volume>10</volume><fpage>349</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1006/brln.2000.2476</pub-id><pub-id pub-id-type="pmid">11703062</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="book"><name><surname>Gopher</surname><given-names>D</given-names></name><name><surname>Donchin</surname><given-names>E</given-names></name><person-group person-group-type="editor">Boff KR, Kaufman L, Thomas JP</person-group><article-title>Workload: an examination of the concept</article-title><source>Handb Percept Hum Perform</source><year>1986</year><publisher-name>New York: Wiley &#x00026; Sons</publisher-name><fpage>41</fpage><lpage>49</lpage></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>S&#x000f6;derlund</surname><given-names>GBW</given-names></name><name><surname>Sikstr&#x000f6;m</surname><given-names>S</given-names></name><name><surname>Loftesnes</surname><given-names>JM</given-names></name><name><surname>Sonuga-Barke</surname><given-names>EJ</given-names></name><article-title>The effects of background white noise on memory performance in inattentive school children</article-title><source>Behav Brain Funct</source><year>2010</year><volume>10</volume><fpage>55</fpage><pub-id pub-id-type="doi">10.1186/1744-9081-6-55</pub-id><pub-id pub-id-type="pmid">20920224</pub-id></mixed-citation></ref></ref-list></back></article>