<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Korean J Med Educ</journal-id><journal-id journal-id-type="iso-abbrev">Korean J Med Educ</journal-id><journal-id journal-id-type="publisher-id">KJME</journal-id><journal-title-group><journal-title>Korean Journal of Medical Education</journal-title></journal-title-group><issn pub-type="ppub">2005-727X</issn><issn pub-type="epub">2005-7288</issn><publisher><publisher-name>Korean Society of Medical Education</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27240891</article-id><article-id pub-id-type="pmc">4951744</article-id><article-id pub-id-type="doi">10.3946/kjme.2016.28</article-id><article-id pub-id-type="publisher-id">kjme-2016-28</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Can disclosure of scoring rubric for basic clinical skills improve objective structured clinical examination?</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-3060-8933</contrib-id><name><surname>Chae</surname><given-names>Su Jin</given-names></name><xref ref-type="aff" rid="af1-kjme-2016-28"><sup>1</sup></xref><xref ref-type="aff" rid="af2-kjme-2016-28"><sup>2</sup></xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5553-5334</contrib-id><name><surname>Kim</surname><given-names>Miran</given-names></name><xref ref-type="corresp" rid="c1-kjme-2016-28"/><xref ref-type="aff" rid="af1-kjme-2016-28"><sup>1</sup></xref><xref ref-type="aff" rid="af3-kjme-2016-28"><sup>3</sup></xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3627-5642</contrib-id><name><surname>Chang</surname><given-names>Ki Hong</given-names></name><xref ref-type="aff" rid="af1-kjme-2016-28"><sup>1</sup></xref></contrib><aff id="af1-kjme-2016-28"><label>1</label>Office of Medical Education, Ajou University School of Medicine, Suwon, <country>Korea</country></aff><aff id="af2-kjme-2016-28"><label>2</label>Department of Medical Humanities &#x00026; Social Medicine, Ajou University School of Medicine, Suwon, <country>Korea</country></aff><aff id="af3-kjme-2016-28"><label>3</label>Department of Obstetrics &#x00026; Gynecology, Ajou University School of Medicine, Suwon, <country>Korea</country></aff></contrib-group><author-notes><corresp id="c1-kjme-2016-28">Corresponding Author: Corresponding Author: Miran Kim (<ext-link ext-link-type="uri" xlink:href="http://orcid.org/0000-0001-5553-5334">http://orcid.org/0000-0001-5553-5334</ext-link>) Department of Obstetrics &#x00026; Gynecology, Ajou University School of Medicine, 206 World cup-ro, Yeongtong-gu, Suwon 16499, Korea Tel: +82.31.219.5300 Fax: +82.31.219.4093 email: <email>kmr5300@ajou.ac.kr</email></corresp></author-notes><pub-date pub-type="ppub"><month>6</month><year>2016</year></pub-date><pub-date pub-type="epub"><day>27</day><month>5</month><year>2016</year></pub-date><volume>28</volume><issue>2</issue><fpage>179</fpage><lpage>183</lpage><history><date date-type="received"><day>2</day><month>3</month><year>2016</year></date><date date-type="rev-recd"><day>25</day><month>4</month><year>2016</year></date><date date-type="accepted"><day>25</day><month>4</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; The Korean Society of Medical Education. All rights reserved.</copyright-statement><copyright-year>2016</copyright-year><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><sec><title>Purpose:</title><p>To determine whether disclosure of scoring rubric for objective basic clinical skills can improve the scores on the objective structured clinical examination (OSCE) in medical students.</p></sec><sec><title>Methods:</title><p>Clinical performance score results of one university medical students (study group, n=345) were compared to those of another university (control group, n=1,847). Both groups took identical OSCE exam. OSCE rubric was not revealed to the study group until they were in the last 2 years of medical school.</p></sec><sec><title>Results:</title><p>There was no significant difference between before and after disclosure of rubric. However, history taking and physical examination scores of the study group were lower than those of the control group before the disclosure of rubric. After disclosure of rubric, the scores were either unchanged or slightly increased in the control group. Trend analysis of scores demonstrated that history taking and physical examination scores after the disclosure were significantly increased in the study group for 2 years.</p></sec><sec><title>Conclusion:</title><p>This study revealed that disclosure of basic clinical skills rubric to medical students could enhance their clinical performance, particularly in history taking and physical examination scores.</p></sec></abstract><kwd-group><kwd>Objective structured clinical examination</kwd><kwd>Rubric</kwd><kwd>Clinical performance</kwd><kwd>Scoring</kwd></kwd-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>Medical education largely consists of basic research on reasoning, problem based learning, performance assessment, and continuing education [<xref rid="b1-kjme-2016-28" ref-type="bibr">1</xref>]. Performance assessment plays a particularly determinant role in changing established paradigms of medical education, thus contributing significantly to the promotion of prompt interest and motivation for medical students in their learning processes [<xref rid="b2-kjme-2016-28" ref-type="bibr">2</xref>,<xref rid="b3-kjme-2016-28" ref-type="bibr">3</xref>].</p><p>Objective structured clinical examination (OSCE) introduced by Harden et al. [<xref rid="b4-kjme-2016-28" ref-type="bibr">4</xref>] has been the &#x0201c;gold standard for clinical performance assessment.&#x0201d; Well-designed OSCE especially draws out study motivation, consequently strengthening educational efficacy [<xref rid="b5-kjme-2016-28" ref-type="bibr">5</xref>]. However, whether a specific education method affords a positive effect on the recipient such as OSCE remains unclear. It has been proposed that lengthy training programs can enhance OSCE scores [<xref rid="b6-kjme-2016-28" ref-type="bibr">6</xref>], while others have suggested that analytic reasoning can induce higher diagnosis accuracy among novice doctors [<xref rid="b7-kjme-2016-28" ref-type="bibr">7</xref>]. Another opinion is that whole-task OSCE based on hypothesis-driven physical examination heightens diagnostic reasoning compared to OSCE focusing on a standard patient [<xref rid="b8-kjme-2016-28" ref-type="bibr">8</xref>]. Therefore, the purpose of this study was to determine whether disclosure of basic rubric clinical skills could affect performance assessment in medical students.</p></sec><sec><title>Subjects and methods</title><p>The clinical performance scores of Ajou University medical students (study group, n=345) were compared to those of another university (control group, n=1,847) of 2 years before and after basic clinical skills guideline disclosure (2011&#x02013;2014). All students took the exam when they were fourth year medical students. Rubric scores were not revealed to the study group until they were in the last 2 years of medical school. All students who took the exam were fourth year medical students who answered OSCE developed by Seoul Gyeonggi Clinical Performance Examination (CPX) Consortium. Analysis of overall assessment as well as detailed evaluation (history taking, physical examination, physician cordiality, patient education, and physician/patient relationships) was performed for the two groups of students and their results were compared to each other. Yearly change trends in the study group (perfect score of 100) were analyzed. SPSS version 12.0 (SPSS Inc., Chicago, USA) was used for statistical data analysis using t-test. Statistically significance was considered when p-value was less than 0.05.</p></sec><sec sec-type="results"><title>Results</title><p>There was no significant (p&#x0003e;0.05) difference in overall assessment before or after disclosure of basic clinical skills rubrics between the two groups. However, in 2011 (which was before disclosure of the rubrics), history taking scores (61.13&#x000b1;6.70 vs. 66.15&#x000b1;7.47, p=0.000) and physical examination scores (49.39&#x000b1;11.08 vs. 52.60&#x000b1;11.11, p=0.012) in the study group were significantly lower than those of the control group. In 2012, only physical examination scores in the study group were lower than those of the control group (45.38&#x000b1;10.57 vs. 50.25&#x000b1;9.51, p=0.000).</p><p>In 2013 and 2014, the 2 years after the disclosure of rubrics, there was no significant (p&#x0003e;0.05) difference in academic scores between the two groups. History taking (73.81&#x000b1;5.92 vs. 72.67&#x000b1;6.29, p=0.127; 65.22&#x000b1;6.67 vs. 66.24&#x000b1;7.23, p=0.241) and physical examination scores (54.94&#x000b1;8.16 vs. 55.61&#x000b1;10.01, p=0.557; 55.39&#x000b1;10.18 vs. 54.05&#x000b1;8.87, p=0.228) in the control group were either unchanged or slightly increased. Trend analysis of each year&#x02019;s scores demonstrated that history taking and physical examination scores in the study group were significantly increased after the disclosure for 2 years. History taking scores in 2013 were increased by 4.68 to 12.68 points compared to those before the disclosure of rubrics. Similarly, physical examination scores were increased by 5.55 to 9.56 points in 2013 compared to those prior to 2012. They were further increased by 6.01 to 10.01 points in 2014, the second year after the disclosure (<xref rid="t1-kjme-2016-28" ref-type="table">Tables 1</xref>, <xref rid="t2-kjme-2016-28" ref-type="table">2</xref>).</p></sec><sec sec-type="discussion"><title>Discussion</title><p>Most of the previous evaluation on the performance assessment have focused on developing detailed scenario and more objective scoring checklist. To our knowledge, this is the first study to evaluate the relationship between the disclosure of OSCE rubrics and the scores obtained on OSCE examination.</p><p>This study revealed that prior disclosure is not better than the control since two arms experimental design is stronger than one arm repeated measure analysis. There was no significant difference in overall assessment before or after disclosure of the rubrics between the experimental and the control group.</p><p>However, disclosure of basic clinical skill rubrics to medical students could enhance their clinical performance scores, particularly in history taking and physical examinations.</p><p>Despite the high cost of OSCE programs, many teaching institutions in developed countries still include this program in medical education and medical licensing examination procedures because OSCE is considered as the gold standard in clinical assessment [<xref rid="b9-kjme-2016-28" ref-type="bibr">9</xref>]. Recent trends towards outcome-based education in medical education have placed OSCE in a more significant place. Further trial and error investigations are needed to determine which medical education method is the best in promoting clinical performance. In the Republic of Korea, OSCE has been included in the national medical licensing examinations since 2009. Before that, there was considerable debate regarding the practicability and educational effectiveness among medical school professors [<xref rid="b10-kjme-2016-28" ref-type="bibr">10</xref>]. Even if it is proven to be effective, there is a paucity of understanding of these educational programs, leading to classroom instructions based on traditional lecture formats.</p><p>With these ideas as a basis, our teaching faculty formulated an educational program for clinical skills that could be provided and disclosed prior to examination objective rubrics. It was used to instruct only the essential and necessary materials within a set period of time.</p><p>This program rubric created and developed by our institution comprised of 41 clinical skill items included in the national medical licensure exams. They were drawn up by faculty members in their respective professional disciplines. Thereafter, all rubrics were scrutinized by a secondary faculty member whose academic field had no relationship with the topic being inspected so that the guideline could be provided in a succinct and clear context to students. Although these rubric formulation processes were arduous and time consuming, we found profound change in both our faculty members and students. As this rubric could be used to assess faculty colleagues, many teachers were instructing students on such a high professional level that some teachers were receiving unfavorable feedbacks from students for their lectures. Therefore, objective teaching assessment was direly required. These students were thus provided accurate clinical skill rubrics that could change previously difficult lectures into a comprehensive program that could be rehearsed in real practical and clinical settings. Consequently, these students obtained self-confidence. These disclosed rubrics resulted in better history taking and physical examination scores.</p><p>Although we were able to collect many student test scores from CPX consortium data, our data did not include the demographic details of the subjects. Further evaluation may be necessary to evaluate any effect of the demographics on the exam scores.</p><p>For outcome-based learning to be successful, assessment changes must be ensued. To establish assessment changes, the teaching and learning processes must also change. We were able to observe and experience positive student clinical performance after implementing changes in our teaching programs. More active student participation in future education programs is needed to develop faculty teaching methods.</p></sec></body><back><ref-list><title>References</title><ref id="b1-kjme-2016-28"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>G</given-names></name></person-group><article-title>Research in medical education: three decades of progress</article-title><source>BMJ</source><year>2002</year><volume>324</volume><fpage>1560</fpage><lpage>1562</lpage><pub-id pub-id-type="pmid">12089095</pub-id></element-citation></ref><ref id="b2-kjme-2016-28"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yim</surname><given-names>MK</given-names></name><name><surname>Lee</surname><given-names>GM</given-names></name></person-group><article-title>The school effect on the reliability of clinical performance examination in medical schools</article-title><source>Korean J Med Educ</source><year>2010</year><volume>22</volume><fpage>215</fpage><lpage>223</lpage><pub-id pub-id-type="pmid">25813946</pub-id></element-citation></ref><ref id="b3-kjme-2016-28"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Im</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>DK</given-names></name><name><surname>Kong</surname><given-names>HH</given-names></name><name><surname>Roh</surname><given-names>HR</given-names></name><name><surname>Oh</surname><given-names>YR</given-names></name><name><surname>Seo</surname><given-names>JH</given-names></name></person-group><article-title>Assessing clinical reasoning abilities of medical students using clinical performance examination</article-title><source>Korean J Med Educ</source><year>2016</year><volume>28</volume><fpage>35</fpage><lpage>47</lpage><pub-id pub-id-type="pmid">26838567</pub-id></element-citation></ref><ref id="b4-kjme-2016-28"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harden</surname><given-names>RM</given-names></name><name><surname>Stevenson</surname><given-names>M</given-names></name><name><surname>Downie</surname><given-names>WW</given-names></name><name><surname>Wilson</surname><given-names>GM</given-names></name></person-group><article-title>Assessment of clinical competence using objective structured examination</article-title><source>Br Med J</source><year>1975</year><volume>1</volume><fpage>447</fpage><lpage>451</lpage><pub-id pub-id-type="pmid">1115966</pub-id></element-citation></ref><ref id="b5-kjme-2016-28"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>KZ</given-names></name><name><surname>Ramachandran</surname><given-names>S</given-names></name><name><surname>Gaunt</surname><given-names>K</given-names></name><name><surname>Pushkar</surname><given-names>P</given-names></name></person-group><article-title>The objective structured clinical examination (OSCE): AMEE guide No. 81. Part I: an historical and theoretical perspective</article-title><source>Med Teach</source><year>2013</year><volume>35</volume><fpage>e1437</fpage><lpage>e1446</lpage><pub-id pub-id-type="pmid">23968323</pub-id></element-citation></ref><ref id="b6-kjme-2016-28"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pugh</surname><given-names>D</given-names></name><name><surname>Touchie</surname><given-names>C</given-names></name><name><surname>Wood</surname><given-names>TJ</given-names></name><name><surname>Humphrey-Murto</surname><given-names>S</given-names></name></person-group><article-title>Progress testing: is there a role for the OSCE?</article-title><source>Med Educ</source><year>2014</year><volume>48</volume><fpage>623</fpage><lpage>631</lpage><pub-id pub-id-type="pmid">24807438</pub-id></element-citation></ref><ref id="b7-kjme-2016-28"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myung</surname><given-names>SJ</given-names></name><name><surname>Kang</surname><given-names>SH</given-names></name><name><surname>Phyo</surname><given-names>SR</given-names></name><name><surname>Shin</surname><given-names>JS</given-names></name><name><surname>Park</surname><given-names>WB</given-names></name></person-group><article-title>Effect of enhanced analytic reasoning on diagnostic accuracy: a randomized controlled study</article-title><source>Med Teach</source><year>2013</year><volume>35</volume><fpage>248</fpage><lpage>250</lpage><pub-id pub-id-type="pmid">23327617</pub-id></element-citation></ref><ref id="b8-kjme-2016-28"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lafleur</surname><given-names>A</given-names></name><name><surname>C&#x000f4;t&#x000e9;</surname><given-names>L</given-names></name><name><surname>Leppink</surname><given-names>J</given-names></name></person-group><article-title>Influences of OSCE design on students' diagnostic reasoning</article-title><source>Med Educ</source><year>2015</year><volume>49</volume><fpage>203</fpage><lpage>214</lpage><pub-id pub-id-type="pmid">25626751</pub-id></element-citation></ref><ref id="b9-kjme-2016-28"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patr&#x000ed;cio</surname><given-names>MF</given-names></name><name><surname>Juli&#x000e3;o</surname><given-names>M</given-names></name><name><surname>Fareleira</surname><given-names>F</given-names></name><name><surname>Carneiro</surname><given-names>AV</given-names></name></person-group><article-title>Is the OSCE a feasible tool to assess competencies in undergraduate medical education?</article-title><source>Med Teach</source><year>2013</year><volume>35</volume><fpage>503</fpage><lpage>514</lpage><pub-id pub-id-type="pmid">23521582</pub-id></element-citation></ref><ref id="b10-kjme-2016-28"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>YM</given-names></name><name><surname>Ahn</surname><given-names>DS</given-names></name></person-group><article-title>The OSCE: a new challenge to the evaluation system in Korea</article-title><source>Med Teach</source><year>2006</year><volume>28</volume><fpage>377</fpage><lpage>379</lpage><pub-id pub-id-type="pmid">16807181</pub-id></element-citation></ref></ref-list></back><floats-group><table-wrap id="t1-kjme-2016-28" orientation="portrait" position="float"><label>Table 1.</label><caption><p>Comparison of Grade Point Average between Subjects before and after Disclosure of Clinical Skills Guidelines</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" rowspan="1" colspan="1">Year</th><th align="center" valign="middle" rowspan="1" colspan="1">Study group</th><th align="center" valign="middle" rowspan="1" colspan="1">Control group</th><th align="center" valign="middle" rowspan="1" colspan="1">p-value</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">2011</td><td align="center" valign="top" rowspan="1" colspan="1">n=86</td><td align="center" valign="top" rowspan="1" colspan="1">n=616</td><td align="center" valign="top" rowspan="1" colspan="1"/></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;History taking</td><td align="center" valign="top" rowspan="1" colspan="1">61.13&#x000b1;6.70</td><td align="center" valign="top" rowspan="1" colspan="1">66.15&#x000b1;7.47</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;Physical examination</td><td align="center" valign="top" rowspan="1" colspan="1">49.39&#x000b1;11.08</td><td align="center" valign="top" rowspan="1" colspan="1">52.60&#x000b1;11.11</td><td align="center" valign="top" rowspan="1" colspan="1">0.012</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">2012</td><td align="center" valign="top" rowspan="1" colspan="1">n=90</td><td align="center" valign="top" rowspan="1" colspan="1">n=444</td><td align="center" valign="top" rowspan="1" colspan="1"/></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;Physical examination</td><td align="center" valign="top" rowspan="1" colspan="1">45.38&#x000b1;10.57</td><td align="center" valign="top" rowspan="1" colspan="1">50.25&#x000b1;9.51</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">2013</td><td align="center" valign="top" rowspan="1" colspan="1">n=85</td><td align="center" valign="top" rowspan="1" colspan="1">n=433</td><td align="center" valign="top" rowspan="1" colspan="1"/></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;History taking</td><td align="center" valign="top" rowspan="1" colspan="1">73.81&#x000b1;5.92</td><td align="center" valign="top" rowspan="1" colspan="1">72.67&#x000b1;6.29</td><td align="center" valign="top" rowspan="1" colspan="1">0.127</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;Physical examination</td><td align="center" valign="top" rowspan="1" colspan="1">54.94&#x000b1;8.16</td><td align="center" valign="top" rowspan="1" colspan="1">55.61&#x000b1;10.01</td><td align="center" valign="top" rowspan="1" colspan="1">0.557</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">2014</td><td align="center" valign="top" rowspan="1" colspan="1">n=84</td><td align="center" valign="top" rowspan="1" colspan="1">n=354</td><td align="center" valign="top" rowspan="1" colspan="1"/></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;History taking</td><td align="center" valign="top" rowspan="1" colspan="1">65.22&#x000b1;6.67</td><td align="center" valign="top" rowspan="1" colspan="1">66.24&#x000b1;7.23</td><td align="center" valign="top" rowspan="1" colspan="1">0.241</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">&#x02003;Physical examination</td><td align="center" valign="top" rowspan="1" colspan="1">55.39&#x000b1;10.18</td><td align="center" valign="top" rowspan="1" colspan="1">54.05&#x000b1;8.87</td><td align="center" valign="top" rowspan="1" colspan="1">0.228</td></tr></tbody></table><table-wrap-foot><fn><p>Values are presented as mean&#x000b1;standard deviation.</p></fn></table-wrap-foot></table-wrap><table-wrap id="t2-kjme-2016-28" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Change of Grade Point Average within Subjects in Study Group after Disclosure of Clinical Skills Guidelines</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" rowspan="1" colspan="1">Year</th><th align="center" valign="middle" rowspan="1" colspan="1">History taking</th><th align="center" valign="middle" rowspan="1" colspan="1">p-value</th><th align="center" valign="middle" rowspan="1" colspan="1">Physical examination</th><th align="center" valign="middle" rowspan="1" colspan="1">p-value</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">2013</td><td align="left" valign="top" rowspan="1" colspan="1">(+) 12.67&#x000b1;0.99 than 2011</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td><td align="left" valign="top" rowspan="1" colspan="1">(+) 5.55&#x000b1;1.54 than 2011</td><td align="center" valign="top" rowspan="1" colspan="1">0.005</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1"/><td align="left" valign="top" rowspan="1" colspan="1">(+) 4.67&#x000b1;0.98 than 2012</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td><td align="left" valign="top" rowspan="1" colspan="1">(+) 9.56&#x000b1;1.52 than 2012</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">2014</td><td align="left" valign="top" rowspan="1" colspan="1">(+) 4.09&#x000b1;0.99 than 2011</td><td align="center" valign="top" rowspan="1" colspan="1">0.001</td><td align="left" valign="top" rowspan="1" colspan="1">(+) 6.01&#x000b1;1.54 than 2011</td><td align="center" valign="top" rowspan="1" colspan="1">0.002</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1"/><td align="left" valign="top" rowspan="1" colspan="1"/><td align="center" valign="top" rowspan="1" colspan="1"/><td align="left" valign="top" rowspan="1" colspan="1">(+) 10.01&#x000b1;1.53 than 2012</td><td align="center" valign="top" rowspan="1" colspan="1">0.000</td></tr></tbody></table><table-wrap-foot><fn><p>Values are presented as mean&#x000b1;standard deviation.</p></fn></table-wrap-foot></table-wrap></floats-group></article>