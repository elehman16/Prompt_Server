<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?properties manuscript?><front><journal-meta><journal-id journal-id-type="nlm-journal-id">9809671</journal-id><journal-id journal-id-type="pubmed-jr-id">21092</journal-id><journal-id journal-id-type="nlm-ta">Nat Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Nat. Neurosci.</journal-id><journal-title-group><journal-title>Nature neuroscience</journal-title></journal-title-group><issn pub-type="ppub">1097-6256</issn><issn pub-type="epub">1546-1726</issn></journal-meta><article-meta><article-id pub-id-type="pmid">25326691</article-id><article-id pub-id-type="pmc">4503317</article-id><article-id pub-id-type="doi">10.1038/nn.3842</article-id><article-id pub-id-type="manuscript">NIHMS629786</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Mind matters: Placebo enhances reward learning in Parkinson&#x02019;s disease</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Schmidt</surname><given-names>Liane</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Braun</surname><given-names>Erin Kendall</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Wager</surname><given-names>Tor D.</given-names></name><xref ref-type="aff" rid="A2">2</xref><xref rid="FN2" ref-type="author-notes">*</xref></contrib><contrib contrib-type="author"><name><surname>Shohamy</surname><given-names>Daphna</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A3">3</xref><xref rid="FN2" ref-type="author-notes">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Psychology Department, Columbia University, New York, New York</aff><aff id="A2"><label>2</label>Psychology Department, University of Colorado at Boulder, Colorado</aff><aff id="A3"><label>3</label>Kavli Center for Brain Science, Columbia University, New York, New York</aff><author-notes><corresp id="FN1">Correspondence should be addressed to: Daphna Shohamy, <email>ds2619@columbia.edu</email> or Tor Wager, <email>torwager@gmail.com</email></corresp><fn id="FN2" fn-type="equal"><label>*</label><p>Equal contributions</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>9</day><month>5</month><year>2015</year></pub-date><pub-date pub-type="epub"><day>19</day><month>10</month><year>2014</year></pub-date><pub-date pub-type="ppub"><month>12</month><year>2014</year></pub-date><pub-date pub-type="pmc-release"><day>15</day><month>7</month><year>2015</year></pub-date><volume>17</volume><issue>12</issue><fpage>1793</fpage><lpage>1797</lpage><!--elocation-id from pubmed: 10.1038/nn.3842--><permissions><license xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms"><license-p>Users may view, print, copy, and download text and data-mine the content in such documents, for the purposes of academic research, subject always to the full Conditions of use:<ext-link ext-link-type="uri" xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms">http://www.nature.com/authors/editorial_policies/license.html#terms</ext-link></license-p></license></permissions><abstract><p id="P1">Expectations have a powerful influence on how we experience the world. Neurobiological and computational models of learning suggest that dopamine is crucial for shaping expectations of reward and that expectations alone may influence dopamine levels. However, because expectations and reinforcers are typically manipulated together, the role of expectations per se has remained unclear. Here, we separated these two factors using a placebo dopaminergic manipulation in Parkinson&#x02019;s patients. We combined a reward learning task with fMRI to test how expectations of dopamine release modulate learning-related activity in the brain. We found that the mere expectation of dopamine release enhances reward learning and modulates learning-related signals in the striatum and the ventromedial prefrontal cortex. These effects were selective to learning from reward: neither medication nor placebo had an effect on learning to avoid monetary loss. These findings suggest a neurobiological mechanism by which expectations shape learning and affect.</p></abstract></article-meta></front><body><p id="P2">Expectations are profound incentives for behavior. They affect perception, decision making, and action. Perhaps the most striking example of the power of expectations is the &#x0201c;placebo effect,&#x0201d; wherein the mere expectation of medical treatment leads to physiological effects that mimic the benefits of the treatment itself. These effects pose a crucial challenge for clinical trials, as they can obscure the benefits of an effective intervention. However, if harnessed, they offer the promise of enhancing treatment by combining psychological and pharmacological factors. Thus, understanding the neurobiological basis of how placebo treatment affects behavior is of great importance.</p><p id="P3">In Parkinson&#x02019;s disease (PD) patients, preliminary data from clinical trials<sup><xref rid="R1" ref-type="bibr">1</xref>&#x02013;<xref rid="R3" ref-type="bibr">3</xref></sup> and a few landmark experimental studies<sup><xref rid="R4" ref-type="bibr">4</xref>&#x02013;<xref rid="R6" ref-type="bibr">6</xref></sup> suggest that placebo effects may be substantial and involve modulation of dopamine release in the striatum, presumably via nerve terminals whose origins are located in the midbrain. PD is characterized by changes in motor, cognitive, and emotional systems. Dopaminergic treatment can improve motor symptoms, but it also has broader consequences for behavior, including restored (and sometimes excessive) reward-driven motivation and learning<sup><xref rid="R7" ref-type="bibr">7</xref></sup>. Although there is evidence for placebo effects on motor function<sup><xref rid="R1" ref-type="bibr">1</xref>,<xref rid="R4" ref-type="bibr">4</xref></sup>, placebo effects on the cognitive and affective aspects of PD have not been examined.</p><p id="P4">Here we sought to investigate the effects of placebo on reward learning in PD and its neurobiological mechanisms. Building on prior data suggesting that placebo treatment may cause endogenous recruitment of brain mechanisms that underpin reward learning<sup><xref rid="R5" ref-type="bibr">5</xref>,<xref rid="R8" ref-type="bibr">8</xref>&#x02013;<xref rid="R10" ref-type="bibr">10</xref></sup>, we combined placebo and pharmacological manipulations with a well-characterized instrumental learning paradigm<sup><xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R11" ref-type="bibr">11</xref></sup> and used functional magnetic resonance imaging (fMRI) to link learning behavior to learning- and value-related brain activation.</p><p id="P5">The ability to learn from rewarding outcomes is known to depend on midbrain dopamine neurons and their striatal and prefrontal targets. In particular, computational models of reinforcement learning have highlighted two key variables related to such learning: <italic>expected value</italic> and <italic>prediction error</italic><sup><xref rid="R12" ref-type="bibr">12</xref></sup>. The expected value of an option is assumed to guide choices on each trial. After an outcome is received, this value is updated based on the prediction error, which quantifies how much the outcome deviated from what was expected based on past experience<sup><xref rid="R12" ref-type="bibr">12</xref>&#x02013;<xref rid="R15" ref-type="bibr">15</xref></sup>. FMRI studies in healthy participants have shown that expected value correlates with blood oxygen level-dependent (BOLD) activity in the ventromedial prefrontal cortex (vmPFC)<sup><xref rid="R16" ref-type="bibr">16</xref>&#x02013;<xref rid="R18" ref-type="bibr">18</xref></sup>, whereas reward prediction errors correlate with activity in the striatum<sup><xref rid="R19" ref-type="bibr">19</xref>&#x02013;<xref rid="R22" ref-type="bibr">22</xref></sup>. Moreover, the loss of midbrain dopamine neurons due to PD is associated with changes in these reward-related processes<sup><xref rid="R23" ref-type="bibr">23</xref>&#x02013;<xref rid="R25" ref-type="bibr">25</xref></sup>.</p><p id="P6">Guided by the well-established role of the vmPFC and the ventral striatum in feedback learning, we focused our hypotheses on these regions and asked: (1) Behaviorally, does placebo mimic the effects of dopaminergic medication on learning in PD patients? (2) Does placebo affect value representation in the vmPFC and prediction error representation in the ventral striatum? (3) Does placebo differentially affect learning from reward versus punishment? We predicted that placebo, like dopaminergic medication, will facilitate reward learning in PD; that this effect on behavior will be reflected in modulation of value coding in the vmPFC and reward prediction errors in the ventral striatum; and that the effects of placebo, like actual dopaminergic drugs, would be specific to learning to predict rewards but not learning to predict losses.</p><p id="P7">A within-patient design allowed us to selectively test the effects of dopaminergic medication (comparing on vs. off drug) and whether or not placebo had a similar effect (comparing placebo vs. off drug) (see <xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 1</xref> for a depiction of conditions and experimental design). Each patient was tested under three conditions: off drug (no treatment), placebo (sham treatment), and on drug (standard dopaminergic medication). In the off drug condition, participants were withdrawn overnight from dopaminergic medication. In the on drug condition, participants received their standard dopaminergic medication crushed into orange juice prior to scanning. In the placebo condition, participants watched their verum medication being crushed and dissolved in a glass of orange juice. Unbeknownst to them, they were administered a glass of orange juice containing crushed placebo (starch) pills.</p><p id="P8">While being scanned with fMRI, PD patients performed an instrumental learning task, (<xref rid="F1" ref-type="fig">Fig. 1</xref>) previously shown to be influenced by dopaminergic medication<sup><xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R11" ref-type="bibr">11</xref></sup>. Participants learned by trial-and-error to maximize monetary payoff. For each of a series of trials, participants had to choose between two shapes to obtain a monetary feedback: In the GAIN condition, the correct choice was usually reinforced with a reward of $10, while the incorrect choice was usually not reinforced ($0). This condition tested learning from monetary reward. In the LOSS condition, the correct choice was usually not reinforced ($0), and the incorrect choice was usually punished with a loss of $10. This condition tested learning from monetary punishment and served as a comparison condition against which to test the specificity of effects to reward learning. For each of the two pairs of shapes (i.e. gains, losses) feedback probabilities were either 0.75 or 0.25.</p><sec sec-type="results" id="S1"><title>RESULTS</title><sec id="S2"><title>Placebo mimics effects of medication enhancing reward learning</title><p id="P9">To test the effects of dopaminergic medication and placebo on learning, we estimated learning curves for each patient. These curves reflect the increase in the proportion of correct choices across time as learning progressed. Multilevel linear regression tested the effects of drug and placebo (vs. off drug). PD patients showed significant learning across all conditions. Importantly, there were fundamental differences in observed learning curves between conditions that were also captured by fitted learning curves derived from a standard reinforcement learning model (<xref rid="F2" ref-type="fig">Fig. 2</xref>).</p><p id="P10">As predicted, reward learning was modulated by both pharmacological (drug) and psychological (placebo) manipulations. Reward learning was enhanced when patients were on drug (block*On&#x0003e;Off drug: t<sub>14</sub>=1.8, p&#x0003c;.05). Critically, reward learning was also enhanced by placebo (block*Placebo&#x0003e;Off drug: t<sub>14</sub>=2.3, p&#x0003c;.05), with no difference between placebo and on drug conditions (block*On&#x0003e;Placebo: t<sub>14</sub>=&#x02212;0.2, p=.39). An exploratory analysis of individual differences in drug and placebo effects revealed that these learning effects paralleled drug and placebo effects on motor symptoms (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 2</xref>).</p><p id="P11">Finally, the effect of placebo on learning was selective to the gain condition, as indicated by a significant three-way interaction (block*Placebo&#x0003e;Off*Gains&#x0003e;Losses: t<sub>11</sub>=1.9, p&#x0003c;.05). In the loss condition, the slope of learning over time was not significantly enhanced by drug or placebo (block*On&#x0003e;Off drug: t<sub>14</sub>=0, p=0.49; block*Placebo&#x0003e;Off drug: t<sub>14</sub>=&#x02212;0.53, p=.3).</p><p id="P12">We next analyzed the behavioral data by applying a standard reinforcement learning model<sup><xref rid="R12" ref-type="bibr">12</xref>,<xref rid="R14" ref-type="bibr">14</xref></sup>. Quantification of model fits across the different conditions indicated that the model provided a good fit to the data in all conditions, with no differences between them (see <bold>Online Methods</bold>, <xref rid="SD1" ref-type="supplementary-material">Supplementary Table 1</xref>). Further, the model-derived learning curves across trials were consistent with the observed learning curves (<xref rid="F2" ref-type="fig">Fig. 2</xref>) confirming that the reinforcement learning model captured the qualitative pattern of performance improvements detailed above. Additionally, a comparison of model parameters revealed parallel effects of placebo and drug on the model-derived learning rate parameter (<xref rid="SD1" ref-type="supplementary-material">Supplementary Table 1</xref>). Specifically, in the gain condition the average learning rate under placebo was significantly lower than the learning rate in the off drug condition (t<sub>14</sub>= 2.6, p&#x0003c;0.05, two-tailed, paired t-test). The average learning rate on drug was numerically but not significantly lower than in the off drug condition (t<sub>14</sub>=1.5, p=0.16, two-tailed). There were no significant differences in learning rate between placebo and on drug (t<sub>14</sub>=1.24, p=0.23, two-tailed). In the loss condition, there were no differences in learning rates between treatment conditions (Off vs. Placebo: t<sub>14</sub>= &#x02212;0.73, p=0.47; Off vs. On: t<sub>14</sub>=&#x02212;1.79, p=0.10; On vs. Placebo: t<sub>14</sub>=0.97, p=0.34). The finding of reduced learning rates in the reinforcement learning model suggests greater integration of reward information across trials, which is beneficial for this kind of probabilistic learning task.</p></sec><sec id="S3"><title>Placebo enhances value representation in the vmPFC</title><p id="P13">Having established that placebo selectively enhances reward learning in PD, we next investigated the neural substrates of this effect. To determine whether placebo enhances BOLD correlates of learning, trial-by-trial measures of expected values and prediction errors were derived from the reinforcement learning model<sup><xref rid="R12" ref-type="bibr">12</xref>,<xref rid="R14" ref-type="bibr">14</xref></sup> and regressed against the BOLD signal at the time of choice and feedback, respectively.</p><p id="P14">Multilevel linear regression tested the effects of drug and placebo (vs. off drug) on parameter estimates from regions of interest in the vmPFC and the ventral striatum. Expected value was associated with vmPFC increases across all conditions (<xref rid="F3" ref-type="fig">Fig. 3</xref>). Crucially, we found that vmPFC activation related to the parameter of expected value was enhanced both by drug (On&#x0003e;Off: t<sub>11</sub>=2.8, p&#x0003c;0.05) and by placebo (Placebo&#x0003e;Off: t<sub>11</sub>=2.0, p&#x0003c;0.05), with no difference between drug and placebo (On&#x0003e;Placebo: t<sub>11</sub>=0.52, p=0.31). The enhancing effect of placebo on value representation in vmPFC was selective to the reward learning condition: vmPFC correlates of expected value during loss learning were not affected by either drug or placebo (On&#x0003e;Off: t<sub>11</sub>=0.1, p=0.46; Placebo&#x0003e;Off: t<sub>11</sub>=1.3, p=0.11). Similar results were obtained for correct vs. incorrect responses at time of choice, outside of the reinforcement learning framework, with stronger vmPFC responses during drug and placebo relative to off drug (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 3a</xref>).</p></sec><sec id="S4"><title>Placebo attenuates striatal prediction error responses</title><p id="P15">Next, we tested how drug and placebo affected striatal prediction errors at time of feedback. Reward prediction errors were associated with increased activation in the ventral striatum across all conditions (<xref rid="F4" ref-type="fig">Fig. 4</xref>). Prior studies in healthy participants suggest that dopamine increases the correlation between striatal BOLD and reward prediction error<sup><xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R23" ref-type="bibr">23</xref>&#x02013;<xref rid="R25" ref-type="bibr">25</xref></sup>. Interestingly, when we looked at the gain trials we found the opposite: a robust striatal prediction error response in the off drug condition which was weakened by dopaminergic medication (Off&#x0003e;On: t<sub>11</sub>=2.06, p&#x0003c;0.05) as well as by placebo (Off&#x0003e;Placebo: t<sub>11</sub>=2.13, p&#x0003c;0.05) (<xref rid="F4" ref-type="fig">Fig. 4b</xref>). As in the effect on expected value, effects on prediction error were found only for reward learning and not for loss learning (Off&#x0003e;Placebo*Gains&#x0003e;Losses: t<sub>8</sub>=2.58, p&#x0003c;0.05; Off&#x0003e;On: t<sub>11</sub>=0.19, p=0.42; Off&#x0003e;Placebo: t<sub>11</sub>=&#x02212;1.38, p=0.09). Here too a similar pattern of results was obtained for an analysis of actual observed correct vs. incorrect feedback at time of outcome, outside of the reinforcement learning framework (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 3b</xref>): Reward-related responses were reduced in both on drug and placebo responses relative to off drug.</p><p id="P16">An analysis breaking down the prediction error into its algebraic components<sup><xref rid="R26" ref-type="bibr">26</xref>&#x02013;<xref rid="R28" ref-type="bibr">28</xref></sup> (expected value and reward, at time of outcome) found that placebo effects on learning signals in the brain were underpinned by a significant effect on the reward component, but not the value component (<bold>Online Methods</bold> and <xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 4</xref>). Striatal responses to reward were significantly weaker under placebo than off drug (Placebo&#x0003c;Off: t<sub>14</sub>=2.14, p&#x0003c;0.05, two-tailed, paired t-test) and numerically but not significantly weaker responses in on drug compared to off drug (On&#x0003c;Off: t<sub>14</sub>=1.63, p=0.12, two-tailed, paired t-test), with no difference between placebo and on drug (Placebo&#x0003e;On: t<sub>14</sub>=&#x02212;0.21, p=0.83, two-tailed, paired t-test). By contrast, there were no differences across treatment conditions related to choice value (Placebo&#x0003c;Off: t<sub>14</sub>=1.14, p=0.27; On&#x0003c;Off: t<sub>14</sub>=0.45, p=0.65, and Placebo &#x0003e; On: t<sub>14</sub>= &#x02212;0.82, p=0.42, two-tailed, paired-t-test).</p><p id="P17">In summary, both drug and placebo were associated with better behavioral performance, enhanced value signals in the vmPFC, and weaker reward responses in the striatum. Notably, the selectivity of placebo and drug effects to the reward condition, in contrast to the null-effect on the loss condition, suggests that the placebo effects are not due to global effects of treatment on any broad psychological or physiological variables (see <bold>Online Methods</bold> for a detailed description of control analyses).</p></sec></sec><sec sec-type="discussion" id="S5"><title>DISCUSSION</title><p id="P18">Our results indicate a robust effect of placebo on brain and behavior. These findings suggests that mere expectations about dopamine release can be harnessed to enhance treatment by facilitating reward learning as well as motor symptoms, with potentially broad implications for appetitive motivation.</p><p id="P19">Expectations have long been known to have a substantial influence on how we experience the world<sup><xref rid="R29" ref-type="bibr">29</xref>,<xref rid="R30" ref-type="bibr">30</xref></sup>. Neurobiological and computational models of learning suggest that expected reward should lead to neurobiological changes in midbrain dopamine systems and their prefrontal and striatal targets. However, since a) the vast majority of studies manipulate expectations and reward at the same time, and b) motivational priming in the striatum can occur without conscious expectation<sup><xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32</xref></sup>, the role of expectations in and of themselves has remained unclear. Here we show that the mere expectation of dopaminergic treatment enhances reward learning, as we manipulated beliefs about treatment independent of drug-associated cues (both drug and placebo were delivered in orange juice, not in pills). Thus, it was the belief in treatment that influenced reward processing and learning, paralleling effects of instructions on affective processes in other domains<sup><xref rid="R33" ref-type="bibr">33</xref></sup>.</p><p id="P20">Expectations of dopaminergic effects without actual drug mimicked the effects of drug-induced dopaminergic modulation on both model-independent learning curves and model-based learning rates. These findings suggest that part of the benefit of open-label drug treatment delivered in standard clinical settings may be caused by the expectations of the patient. Moreover, our finding that responses to drug may be partly related to effects of expectation suggests that one of the basic assumptions of standard randomized controlled trials is violated. Attempts to screen out placebo responders or to subtract away placebo responses to reveal drug effects may be misguided, as the drug response will be eliminated along with the placebo<sup><xref rid="R34" ref-type="bibr">34</xref></sup>. Much prior work on these principles has been done in pain and depression<sup><xref rid="R35" ref-type="bibr">35</xref></sup>, and one study has shown that placebo- and levodopa-induced dopamine effects in PD patients can covary<sup><xref rid="R6" ref-type="bibr">6</xref></sup>. Our results extend these findings to appetitive processes and suggest that concerns about the non-independence of placebo and drug mechanisms extends to PD as well.</p><p id="P21">Importantly, the observed effects of placebo were selective to learning from gains, consistent with previous findings demonstrating asymmetry in the effects of dopamine modulation on appetitive vs. aversive learning<sup><xref rid="R11" ref-type="bibr">11</xref></sup>. However, while prior studies have reported that in some cases dopaminergic medication can impair loss learning<sup><xref rid="R36" ref-type="bibr">36</xref>&#x02013;<xref rid="R38" ref-type="bibr">38</xref></sup>, here we find a lack of effect on learning to avoid losses, both for medication and for placebo. This may be related to the specific design of our study, in which positive and negative prediction errors are present in both the reward and loss conditions and in which the lack of a loss outcome could be interpreted as a reward. Future studies constraining participants&#x02019; interpretation of gains vs. losses and comparing performance of value-learning and actor-critic models may be better suited to addressing this issue<sup><xref rid="R39" ref-type="bibr">39</xref>,<xref rid="R40" ref-type="bibr">40</xref></sup>.</p><p id="P22">Our findings demonstrated decreased ventral striatal BOLD responses to reward and prediction error under both dopaminergic medication and placebo treatment. The direction of this effect is somewhat surprising, given that dopaminergic medication (and, putatively, placebo) is known to increase striatal dopamine. One possible explanation relates to the mechanism by which dopamine modulates corticostriatal synaptic activity. It has been shown that dopamine can increase the signal to noise ratio in corticostriatal synapses via a combination of inhibition and excitation<sup><xref rid="R41" ref-type="bibr">41</xref>&#x02013;<xref rid="R43" ref-type="bibr">43</xref></sup>. Given the resolution of the BOLD response, such modulation could lead to a net decrease in reward related BOLD activity, while still reinforcing the behaviorally relevant synapses. Notably, reduced striatal responses related to rewards and prediction errors in PD have also been reported previously, though these effects may depend on the patient characteristics<sup><xref rid="R7" ref-type="bibr">7</xref></sup>. Though the precise relationships between dopamine release, circuit dynamics, and BOLD activity are largely unknown, these findings suggest that in PD patients, increased dopamine in the striatum may be accompanied by decreased prediction error-related BOLD signals.</p><p id="P23">Finally, placebo effects are widely thought to be created both by expectations and by learning, as conditioning has been shown to elicit some of the most robust placebo responses<sup><xref rid="R44" ref-type="bibr">44</xref>,<xref rid="R45" ref-type="bibr">45</xref></sup>. Here, we demonstrate that in addition to the effects of expectancy and learning on placebo effects in brain and behavior, there are also significant effects of expectancy induced by a placebo on learning and learning-related signals in the brain. Together with the assumption that placebo and drug effects in PD might be mediated by the same dopaminergic mechanism in the brain, this finding creates the potential for feedback cycles in which expectations and experienced reward are mutually reinforcing. Thus, the learned association between a drug and its outcome could be reinforced by expectations induced by verbal suggestions and other elements of the treatment context (e.g. the physical location of treatment and social interactions with care providers). Such synergy between expectations, pharmacology and behavior could have a positive cumulative effect on patients&#x02019; motivation, response to treatment, and quality of life.</p></sec><sec id="S7" specific-use="web-only"><title>ONLINE METHODS</title><sec id="S8" sec-type="subjects"><title>Participants</title><p id="P25">We recruited twenty-one patients with mild-to-moderate Parkinson&#x02019;s disease (PD; 13/8 male/female) through neurologists at Columbia University&#x02019;s Center for Parkinson&#x02019;s Disease and Other Movement Disorders and advertisements on the websites of the Michael J. Fox Foundation and the Parkinson&#x02019;s Disease Foundation. Columbia University Medical Center Institutional Review Board approved the study procedures, and we obtained informed written consent from all participants. During recruitment, patients were told that the study aim was to test how PD medications, such as carbidopa/levodopa, affects learning, memory and decision making and the way the brain functions. Thus until a final debriefing session at the end of the experiment, participants remained blind to the placebo. Patients were remunerated for their time ($20 per hour), as well as 5% of their winnings averaged across the six learning task runs.</p><p id="P26">Before participation, all of the patients were screened using the following inclusion criteria: Diagnosis of mild-to-moderate PD (Hoehn and Yahr stages 1 to 3), age between 50 and 85 years, treatment of PD by carbidopa/levodopa for at least 3 months, responsive to PD medication, medication schedule with at least 2 and up to 4 daily doses (e.g. morning, lunch, afternoon, bedtime), no report of psychiatric history or neurological disease other than PD, normal to corrected-to-normal vision, and right-handedness. It has been shown that even at the initial diagnosis, PD patients have already lost a significant amount of striatal dopamine<sup><xref rid="R46" ref-type="bibr">46</xref></sup>. Thus for this initial study, we deliberately recruited patients at a stage with substantial dopamine loss and enough experience with the medication to elicit expectations about its effects, while having mild enough symptoms to perform a cognitive task within an MRI scanner. A formal power analysis was not used to select the sample size a priori, as the effect sizes could not be estimated prior to the study. The sample sizes was chosen to be similar to those generally employed in the field.</p><p id="P27">All patients were treated with levodopa/carbidopa. Additionally patients were prescribed the following PD medications: Selegiline (5 patients), Rasagiline (5 patients), Amantadine (4 patients), Entacapone (1 patient), and Pramiprexole (1 patient). Because these medications were part of the PD treatment, they were crushed and dissolved in orange juice together with the levodopa/carbidopa medication. Some patients also were prescribed antidepressant and anxiolytic treatment that included Nortriptyline (2 patients), Amitriptyline (1 patient), Citalopram (1 patient), Clonazepam (2 patients), and Lorazepam (2 patients). On the morning of the experiment, patients did not take any antidepressant or anxiolytic medications.</p><p id="P28">We excluded six patients from analysis due to: a) extreme anxiety related to scanning (n=4, 2 of these 4 patients agreed to participate behaviorally, the other 2 patients withdrew completely), b) abnormally fast overall reaction times (3 SD below the group average response times), suggesting a failure to follow task instructions (n=1, excluded from both behavioral and imaging data), and c) poor fMRI image quality (n=1, included in the behavioral data analysis). In sum, we included 18 patients in the behavioral data analysis and 15 patients in the fMRI data analysis.</p></sec><sec id="S9"><title>Experimental design</title><p id="P29">To minimize variance due to individual differences, we employed a within-subject design in which each patient was scanned three times: off drug, on placebo and on drug (see <xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 1a</xref>). Patients refrained from taking their morning dose of PD medication, following conventional procedures for comparing PD patients on vs. off medication<sup><xref rid="R47" ref-type="bibr">47</xref>&#x02013;<xref rid="R50" ref-type="bibr">50</xref></sup>. Patients were withdrawn from their medication for at least 16 hours. The order of the off drug and placebo sessions was counterbalanced across patients; however, the on drug condition was always last, since the half-life of levodopa/carbidopa combination requires at least 7 hours to be metabolized and excreted. Placebo and levodopa/carbidopa treatment were each administered 30 minutes prior to scanning.</p></sec><sec id="S10"><title>Placebo administration</title><p id="P30">On the morning of the experiment and prior to scanning, patients were interviewed regarding their daily medication schedule. In particular, patients were asked: (1) how many daily doses they take, (2) at what time of the day, and (3) if and when they feel an improvement from the drug. Patients were told that because of the initial time to &#x02018;kick in&#x02019; between 30 to 45 minutes, their typical daily dose of medication would be administered 30 minutes prior to scanning and thus, together with the time it will take to place them in the scanner (15 minutes), they could expect to be at their best at start of the learning task.</p><p id="P31">All patients were off their PD medication during the placebo scan session, but they believed that they had taken their medication. Thirty minutes before the placebo scan session started, the patients observed the experimenter crushing and dissolving their daily morning PD medication into a glass of orange juice. Importantly, to avoid carry over into subsequent sessions, we told patients that the reason for crushing the medication (i.e. destroying its coating) and dissolving it into orange juice was to make it &#x02018;faster acting&#x02019; and &#x02018;shorter lasting&#x02019;. Unbeknownst to the patients, we replaced the glass of orange juice containing their medication with a glass of orange juice containing placebo (starch) pills. Thus, participants were led to expect that they were taking their typical medication, and it was implied that the medication would help them function optimally on all tasks, without providing specific expectancies about performance. Participants were not informed that their medication, or dopamine in general, might specifically improve reward&#x02013;based learning; however, in presenting patients with the set of tasks we did, it is likely that participants expected that performance on all tasks (gain&#x02013;based learning, loss&#x02013;based learning, motor) might depend on dopamine and be affected by their daily medication in some positive way.</p><p id="P32">All patients enrolled in this study were on medication schedules of two to four doses per day (e.g. morning, lunch, afternoon, bedtime). If the placebo session was the first scan session, patients were told they were taking their morning dose; if the placebo session was the second scan session, patients were told they were taking a late morning/lunch dose; and for the third on drug scan, patients were told that they were taking a late lunch/early afternoon dose.</p><p id="P33">The rationale for this placebo manipulation was that patients may benefit from conditioned responses that have built up over the duration of their Parkinson&#x02019;s therapy. Our goal was to address the question: Does the expectation of relief from PD symptoms associated to taking a medication affect reward learning and learning&#x02013;related signals in the brain? By making the patients believe they were taking their daily medication, we intended to induce patient-specific expectations and associations, which are built up over months and years of experience with the positive and negative contingencies of a daily medication and cannot be elicited by an unfamiliar study drug.</p></sec><sec id="S11"><title>Drug administration</title><p id="P34">The same procedure was repeated 30 minutes before the third scan session (on drug session). Again, the patients observed the experimenter crushing and dissolving their second dose of daily PD medication into orange juice; however, this time glasses were not switched, and the patients were administered their medication.</p></sec><sec id="S12"><title>Timing of sessions</title><p id="P35">Since we administered both the placebo and drug 30 minutes before scanning, each scan session last for 60 minutes and there was a 60 minutes break, the placebo session and the following session were separated by 2 hours and 30 minutes. This timing follows the design used by a PET study of placebo effects on dopamine release<sup><xref rid="R51" ref-type="bibr">51</xref></sup>.</p><p id="P36">Although we cannot completely rule out the possibility of a persistence of the placebo effect into subsequent scan sessions (i.e. off or on drug), we believe it is unlikely to confound our findings. The critical comparison between the placebo and off drug conditions was counterbalanced across patients. Any persistence of placebo effects into subsequent off drug sessions would decrease differential effects (i.e. placebo vs. off drug) on behavior and brain activity. Moreover, recent work by Benedetti et al. on placebo in PD suggests that placebo effects on PD last on the order of 30 minutes<sup><xref rid="R52" ref-type="bibr">52</xref>,<xref rid="R53" ref-type="bibr">53</xref></sup>, though much remains to be learned about the time course of placebo effects across samples and placebo inductions.</p></sec><sec id="S13"><title>Debriefing on placebo manipulation</title><p id="P37">At the end of the experiment, we informed patients that one of the two drug doses administered during testing was a placebo, and they were asked to guess which dose was the placebo. Five patients guessed incorrectly (i.e. they thought the placebo was the real drug), five patients guessed correctly, and seven patients reported that they could not guess.</p></sec><sec id="S14"><title>Effects of treatment on clinical symptoms</title><p id="P38">After each scan session, emotional symptoms were assessed using the Starkstein Apathy Scale<sup><xref rid="R54" ref-type="bibr">54</xref></sup> and the State&#x02013;Trait Anxiety Inventory (STAI)<sup><xref rid="R55" ref-type="bibr">55</xref></sup>. Working memory was assessed with the Digit Span, and motor symptoms were assessed with the Unified Parkinson&#x02019;s Disease Rating Scale III (UPDRS III)<sup><xref rid="R56" ref-type="bibr">56</xref></sup>. Additionally, expectancy ratings were collected before each scan session: patients indicated how much they expected their PD symptoms to improve following treatment using a visual analogous scale ranging from 0 (no improvement) to 100 (maximum improvement).</p><p id="P39">Paired one&#x02013;sample t&#x02013;tests between treatment conditions were not significant for apathy, anxiety or digit span measures. However, expectancy scores indicated that patients expected significantly more improvement after having been administered a placebo or their drug, relative to the off drug condition (Placebo&#x0003e;Off: t<sub>17</sub>=2.9, p&#x0003c;0.05; On&#x0003e;Off: t<sub>17</sub>=3.7, p&#x0003c;0.05, two&#x02013;tailed, paired t&#x02013;test) (<xref rid="SD2" ref-type="supplementary-material">Supplementary Table 2</xref>).</p><p id="P40">We videotaped patients while the UPDRS III was assessed (no rigidity measures were collected), and an experimenter blind to treatment rated motor symptoms. We observed a significant improvement due to being on drug in comparison to being either on placebo (On&#x0003e;Placebo: t<sub>17</sub>=&#x02212;5.1, p&#x0003c;0.001, two&#x02013;tailed) or off drug (On&#x0003e;Off: t<sub>17</sub>=&#x02212;4.1, p&#x0003c;0.001, two&#x02013;tailed). Since different individuals typically show medication-related improvements on a unique set of patient-specific motor behaviors, and patients were in the mild-to-moderate stages of the disease that may restrict drug effects to specific symptoms, we also calculated UPDRS III scores for off and placebo across the specific subset of items that showed a drug effect (items where On &#x02013; Off &#x0003c; 0) for each patient. We found that for the individualized sub-items that showed an improvement with medication we also found an improvement with placebo (Placebo&#x0003c;Off: 7.86&#x000b1;1.21 vs. 10.2&#x000b1;1.59: t<sub>17</sub>=4.2, p&#x0003c;0.001, two-tailed, paired t-test).</p></sec><sec id="S15"><title>Behavioral task</title><p id="P41">In each of the three fMRI scan sessions, patients performed two runs of an instrumental learning task. The aim of the task was to maximize monetary payoff. Each run consisted of 64 trials: 32 gain trials and 32 loss trials. Gain and loss trials were randomly intermixed within a run. On each trial, two shapes were displayed on a computer screen, and patients chose one of them to receive a monetary feedback. Choices were followed by one of three possible outcomes. Subjects could win $10, get nothing ($0), or lose $10. In the GAIN condition choosing the optimal (i.e. correct) shape was reinforced with a reward of $10 on 75% of trials (25% of trials were non-reinforced), while choosing the non-optimal (i.e. incorrect) shape was not reinforced ($0) in 75% of trials (25% of the trials were rewarded $10). In the LOSS condition, the optimal choice (i.e. correct) was not reinforced ($0) on 75% of trials (but was punished on 25% of trials &#x02212;$10), and the non-optimal (i.e. incorrect) choice was punished with a loss of $10 on 75% of trials (but 25% of trials were not punished $0). Thus, in gain trials we tested the ability to learn from financial rewards (reward learning), and in loss trials we tested the ability to avoid financial punishment (loss learning).</p><p id="P42">We jittered the duration of inter-trial intervals (2 to 6 s) and of the choice-feedback interval (0.5 to 3 s) by drawing from an exponential distribution. We paid the patients according to their performance (5% of the payoff averaged across the 6 learning task runs), in addition to compensation for their participation.</p></sec><sec id="S16"><title>Individual differences in drug and placebo effects</title><p id="P43">The effects of drug and placebo on the slope of reward learning trended towards a correlation across subjects, (zero-order correlation of placebo and drug effects: r=0.59, p&#x0003c;.01; partial correlation controlling for Off drug: r=0.34, p=.08, one&#x02013;tailed) (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 2</xref>). An exploratory analysis of the UPDRS III scores found parallel effects of placebo and drug for clinically relevant motor symptoms of PD (zero-order correlation placebo and drug effects: r=0.68, p&#x0003c;0.001; partial correlation controlling for Off drug: r=0.59, p&#x0003c;0.01).</p></sec><sec id="S17"><title>Computational model</title><p id="P44">We used a standard temporal difference learning algorithm to calculate the expected value of choices (i.e. choice value) and prediction error based on individual trial-by-trial choices and feedback<sup><xref rid="R57" ref-type="bibr">57</xref></sup>. The expected value (i.e. choice value), termed a Q-value, corresponded to the expected reward obtained by choosing a particular cue. Q-values were set to zero at the beginning of each run. After each trial, t&#x0003e;0, the value of the chosen cue was updated according to the rule, Q<sub>chosen_cue</sub>(t+1) = Q<sub>chosen_cue</sub>(t) + &#x003b1;*&#x003b4;(t). Central to this algorithm is prediction error, &#x003b4;(t), which is defined as &#x003b4;(t) = R(t) &#x02212; Q<sub>chosen_cue</sub>(t) or the difference between expected feedback Q<sub>chosen_cue</sub>(t) and actual feedback R(t). The reward magnitude was set +1, 0 and &#x02212;1 for outcomes +$10, $0 and &#x02212;$10, respectively.</p><p id="P45">Given the Q-values, the probability of selecting each action was calculated by implementing the softmax rule: 
<disp-formula id="FD1"><mml:math id="M1" display="block" overflow="scroll"><mml:msub><mml:mi mathvariant="normal">P</mml:mi><mml:mrow><mml:mtext>chosen</mml:mtext><mml:mo>_</mml:mo><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>exp</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Q</mml:mi><mml:mrow><mml:mtext>chosen</mml:mtext><mml:mo>_</mml:mo><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>exp</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Q</mml:mi><mml:mrow><mml:mtext>chosen</mml:mtext><mml:mo>_</mml:mo><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo>exp</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Q</mml:mi><mml:mrow><mml:mtext>unchosen</mml:mtext><mml:mo>_</mml:mo><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula></p><p id="P46">The two free parameters, &#x003b1; (learning rate) and &#x003b2; (temperature), were fit individually for each subject to maximize the probability of actual choices under the model. To improve the model&#x02019;s subsequent fit to fMRI data, we used the average estimates for &#x003b1; and &#x003b2; calculated across patients in each treatment condition.</p><p id="P47">Note that we tested potential confounds due to differences in learning rate and temperature between gain and loss trials. In a control analysis, one learning rate (&#x003b1;=0.2) and one temperature (&#x003b2;=0.4) fitted across all subjects, treatment and trial conditions was used to calculate trial-by-trial expected values and prediction errors. The control fMRI results were consistent with main findings and are reported below (see Effects of scaling expected value and prediction error).</p></sec><sec id="S18"><title>Comparison of RL model fits between treatments</title><p id="P48">To rule out potential confounds due to qualitative differences in model fit between off drug, placebo, and on drug, the following standard measures of model fit were calculated for each subject in each treatment condition: (1) the Bayesian Information Criterion defined by BIC=2*LLE+2*log(n), (2) the Akaike Information Criterion defined by AIC = 2 * LLE + 2 * 2, (3) pseudo R<sup>2</sup> values defined by pseudoR<sup>2</sup>=1&#x02212;LLE<sub>model</sub>/LLE<sub>chance</sub>. Moreover, we tested how well the RL model fits the observed data compared to chance by performing a likelihood ratio test defined by D=2*LLE<sub>model</sub>&#x02212;2*LLE<sub>chance</sub>. LLE<sub>model</sub> corresponds to the maximum logarithmic likelihood of the observed choices under the model. LLE<sub>chance</sub> corresponds to the logarithmic likelihood of choices at chance (LLE<sub>chance</sub>=n*log(0.5), with n=number of trials). The average of each measure across patients in each condition and treatment are reported in <xref rid="SD1" ref-type="supplementary-material">Supplementary Table 1</xref>.</p><p id="P49">Analysis of variance compared pseudo-R2 values across treatments (off drug, placebo, on drug,) and across learning conditions (gains, losses) and revealed no main effect of treatment (F(2,107)=0.79, p=0.45), no main effect of gains vs. losses (F(1,107)=2.38, p=0.12), and no interaction of treatment by gains vs. losses (F(2,107)=0.16, p=0.85). Post hoc, one-tailed t-tests further tested differences in pseudo-R2 values across treatments. These too revealed no significant differences between treatments (pseudo-R2 values: &#x02018;On &#x0003e;Off&#x02019; gains: t<sub>17</sub>=1.16, p=0.12; losses: t<sub>17</sub>=0.50, p=0.30; &#x02018;Placebo &#x0003e; Off&#x02019; gains: t<sub>17</sub>=0.26, p=0.39; losses: t<sub>17</sub>=-0.34, p=0.63; &#x02018;On&#x0003e;Placebo&#x02019; gains: t<sub>17</sub>=0.83, p=0.20; losses: t<sub>17</sub>=1.17, p=0.13).</p></sec><sec id="S19"><title>Treatment effects on reinforcement learning parameters</title><p id="P50">To investigate individual differences between treatment conditions, we individually estimated the free parameters, learning rate, and inverse softmax temperature, which are also referred to as random effect estimations (i.e. one set of parameters for each subject for each treatment condition). The average learning rates and temperature across subjects in each treatment condition are summarized in <xref rid="SD1" ref-type="supplementary-material">Supplementary Table 1</xref>. Analysis of variance tested for main effects of treatment, gains vs. losses, and the interaction of treatment by gains vs. losses in learning rates and softmax inverse temperature, separately.</p><p id="P51">For the learning rates, we found no main effect of treatment (F(2,89)=0.94, p=0.39), a significant main effect of trial type (F(1,89)=3.65, p&#x0003c;0.05), and a trend interaction treatment by gains vs. losses (F(2,89)=2.4, p=0.09). When comparing the treatments during learning from gains, patients on placebo had significantly smaller learning rates compared to off drug (Off&#x0003e;Placebo: t<sub>14</sub>=2.6, p&#x0003c;0.05) and smaller learning rates on drug compared to off drug (Off&#x0003e;On: t<sub>14</sub>=1.5, p=0.16), with no differences between placebo and on drug (On&#x0003e;Placebo: t<sub>14</sub>=1.24, p=0.11). The numerical differences in learning rate across treatment conditions, although less robust statistically, were consistent with behavioral performances and suggest that placebo led to more incremental learning. We did not find differences between treatment conditions for learning rates in the loss condition (Off&#x0003e;Placebo: t<sub>14</sub>=&#x02212;0.73, p=0.47; Off&#x0003e;On: t<sub>14</sub>=&#x02212;1.79, p=0.18; On&#x0003e;Placebo: t<sub>14</sub>=0.97, p=0.34) (<xref rid="SD1" ref-type="supplementary-material">Supplementary Table 1</xref>).</p></sec><sec id="S20"><title>Behavioral data analysis</title><p id="P52">Data collection and analysis were not performed blind to the conditions of the experiment, but all analyses were conducted using automated methods and a priori statistical tests to avoid the possibility of experimenter bias. All of the motor scores (UPDRS III) were coded by a rater blind to the experimental conditions.</p><p id="P53">To assess learning, the 32 gain and the 32 loss trials were each binned into 4 blocks of 8 trials (1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup> block). Within each block, we calculated the percentage of optimal choices, resulting in a learning curve composed of these 4 optimal choice scores for each patient. These curves reflected the increase in the proportion of correct choices across time (i.e. 1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup> block) as learning progressed. Multilevel general linear models (GLM) using iterative generalized least squares (IGLS)<sup><xref rid="R58" ref-type="bibr">58</xref></sup> tested for drug and placebo effects on reward and loss learning.</p><p id="P54">GLM1 tested for a drug effect and included the following 3 regressors:</p><p id="P55">Block, On &#x0003e; Off drug, Block*On &#x0003e; Off drug.</p><p id="P56">Block (dummy coded: &#x02212;3, &#x02212;1, 1, &#x02212;3) tested the increase of learning across time (i.e. the slope of learning over the 4 blocks of 8 trials). On&#x0003e;Off drug tested for a main effect of drug compared to Off drug (coded: &#x02212;1 for Off drug, 1 for On drug). Block*On&#x0003e;Off drug tested if the slope of learning On drug was enhanced compared to Off drug.</p><p id="P57">GLM2 tested for a placebo effect, analogous to GLM1:</p><p id="P58">Block, Placebo &#x0003e; Off drug, Block*Placebo &#x0003e; Off drug.</p><p id="P59">GLM3 tested for the selectivity of effects on reward learning compared to punishment learning. It included the following 6 regressors:</p><p id="P60">Block, Placebo &#x0003e; Off, Gains &#x0003e; Losses, Block*(Gains &#x0003e; Losses), (Placebo &#x0003e; Off drug)*Gains &#x0003e; Losses, Block*(Placebo &#x0003e; Off drug)*Gains &#x0003e; Losses.</p><p id="P61">We fit individual regression coefficients obtained for each regressor into a second-level group analysis to provide population inferences against zero. We entered the order of placebo administration as a second level covariate (see Order effect section, below, for further control analyses of potential confounds due to treatment order). We report the significance of regression coefficients at a threshold of p&#x0003c;0.05, one-tailed.</p><p id="P62">We applied an analogous analysis to parameter estimates extracted from regions of interest in the brain (see Analysis of parameter estimates) and reaction times for choices (see Reaction time).</p><p id="P63">To test if drug and placebo effects on reward learning covaried on the individual level, we obtained individual slopes of reward learning by multiplying the 4 trial blocks (dummy coded: &#x02212;3, &#x02212;1, 1, 3) by the percentage of optimal choices in each block. The differences in learning slopes, on &#x02013; off drug and placebo &#x02013; off drug, were then correlated across all patients by using Pearsons&#x02019;s correlation coefficient and partial correlations controlling for off drug (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 2</xref>). An analogous correlation analysis was done in order to test for individual placebo (i.e. placebo &#x02013; off drug) and drug effects (i.e. on &#x02013; off drug) on motor symptoms measured by the UPDRS III (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 2</xref>).</p><p id="P64">All statistical tests were conducted with the Matlab Statistical Toolbox (Matlab 2010b; The MathWorks) and a Matlab implementation of iterative generalized least squares (IGLS). No statistical methods were used to predetermine sample sizes, but our sample sizes are similar to those generally employed in the field. Data distribution was assumed to be normal and was examined visually to check for normality. Statistical tests for normality were not conducted, because they are generally inconclusive for sample sizes in the range employed here.</p></sec><sec id="S21"><title>Reaction times</title><p id="P65">Reaction times (RT) measured the time patients took to choose between the two shape choices on each trial. Average RTs for each patient were calculated for gain and loss trials separately. To test if there were significant differences in RTs across trials, we applied the same behavioral analysis used to assess learning to the RT data. RTs for gain and loss trials were averaged across blocks of 8 trials separately. Two GLMs, analogous to the GLMs that analyzed optimal choices, tested for placebo and drug effects, respectively (see behavioral analysis). RTs decreased with time in the gain condition (t<sub>14</sub>=&#x02212;6.1, p&#x0003c;0.05), but not in the loss condition (t<sub>14</sub>=&#x02212;0.64, p=0.5) (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 5</xref>). We found no significant effect of either drug or placebo on RTs.</p></sec><sec id="S22" sec-type="subjects"><title>Learning in the subset of fMRI patients</title><p id="P66">Behavioral results in the 15 fMRI patients were consistent with the findings observed across the whole patient group. Learning from gains was enhanced by dopaminergic medication (Block*On&#x0003e;Off: t<sub>11</sub>=1.8, p&#x0003c;0.05) and by placebo (Block*Placebo&#x0003e;Off: t<sub>11</sub>=2.3, p&#x0003c;0.05) (<xref rid="SD3" ref-type="supplementary-material">Supplementary Figs. 6 and 7</xref>). We did not observe treatment effects for learning from losses in the subset of fMRI patients either.</p></sec><sec id="S23"><title>Order effects</title><p id="P67">Although the order of placebo and off drug sessions was counterbalanced across patients, the on drug session was always the last session of the experiment. To control for order effects, we regressed the order (dummy coded: 1, 2, 3) of the scan sessions against optimal choices and parameter estimates from the ventromedial prefrontal cortex (vmPFC) and ventral striatum, separately. For both the gain and the loss condition, no significant effect of order was observed (on optimal choices in gain trials: t<sub>16</sub>=0.89, p&#x0003e;0.05; in loss trials: t<sub>16</sub>=1.6, p&#x0003e;0.05; on parameter estimates from the vmPFC for choice value in gain trials: t<sub>13</sub>=0.65, p&#x0003e;0.05; in loss trials: t<sub>13</sub>=&#x02212;0.10, p&#x0003e;0.05; on parameter estimates from the ventral striatum for prediction error in gain trials: t<sub>13</sub>=&#x02212;1.16, p&#x0003e;0.05; in loss trials: t<sub>13</sub>=&#x02212;0.2, p&#x0003e;0.05). To further test if the order of the placebo administration interacted with placebo effects, order (dummy coded: &#x02212;1 for placebo first, 1 for placebo second) was a second level covariate in the GLMs testing for placebo effects on optimal choices and parameter estimates from vmPFC and ventral striatum.</p><p id="P68">No second level interactions between order and block (t<sub>14</sub>=0.6, p&#x0003e;0.05), Placebo&#x0003e;Off drug (t<sub>14</sub>=0.09, p&#x0003e;0.05), or Block*Placebo&#x0003e;Off drug (t<sub>14</sub>=&#x02212;0.16, p&#x0003e;0.05) were found for learning from gains. Similarly, no second&#x02013;level interactions between order and block (t<sub>14</sub>=&#x02212;1.46, p&#x0003e;0.05), Placebo&#x0003e;Off drug (t<sub>14</sub>=1.1, P&#x0003e;0.05) or Block*Placebo&#x0003e;Off drug (t<sub>14</sub>=2.3, p&#x0003e;0.05) were observed for learning from losses.</p><p id="P69">Consistent with the behavioral findings, order of placebo administration did not interact with the effect of Block (gains: t<sub>11</sub>=0.2, p&#x0003e;0.05; losses: t<sub>11</sub>=0.76, p&#x0003e;0.05), Placebo&#x0003e;Off drug (gains: t<sub>11</sub>=&#x02212;0.2, p&#x0003e;0.05; losses: t<sub>11</sub>=&#x02212;1.3, p=0.05), On&#x0003e;Off (gains: t<sub>11</sub>=1.1, p&#x0003e;0.05; losses: t<sub>11</sub>=0.96, p&#x0003e;0.05), Block*Placebo&#x0003e;Off drug (gains: t<sub>11</sub>=0.4, p&#x0003e;0.05; losses: t<sub>11</sub>=&#x02212;0.4, p&#x0003e;0.05), or Block*On&#x0003e;Off drug (gains: t<sub>11</sub>=0.7, p&#x0003e;0.05; losses: t<sub>11</sub>=&#x02212;1.1, p&#x0003e;0.05), choice value activation in the vmPFC or prediction error activation in the ventral striatum (Block (gains: t<sub>11</sub>=0.7, p&#x0003e;0.05; losses: t<sub>11</sub>=0.9, p&#x0003e;0.05), Placebo&#x0003e;Off drug (gains: t<sub>11</sub>=&#x02212;0.7, p&#x0003e;0.05; losses: t<sub>11</sub>=0.2, p&#x0003e;0.05), On&#x0003e;Off (gains: t<sub>11</sub>=0.06, p&#x0003e;0.05; losses: t<sub>11</sub>=0.5, p&#x0003e;0.05), Block*Placebo&#x0003e;Off drug (gains: t<sub>11</sub>=&#x02212;0.7, p&#x0003e;0.05; losses: t<sub>11</sub>=0.5, p&#x0003e;0.05), or Block*On&#x0003e;Off drug (gains: t<sub>11</sub>=&#x02212;0.3, p&#x0003e;0.05; losses: t<sub>11</sub>=&#x02212;0.3, p&#x0003e;0.05)).</p></sec><sec id="S24"><title>Pleasantness and liking ratings of cues</title><p id="P70">Following each run of the learning task, patients were asked to rate their preference and liking of the shapes that were presented during learning. Patients rated preferences on a 4-point Lickert scale and liking on a visual analog scale that ranged from most unpleasant to most pleasant. Ratings were subjected to a three-way analysis of variance to test for effects of treatment (off, placebo, on drug), shape (optimal, non-optimal), and task condition (gains, losses). Analysis of variance revealed that patients preferred (F(1,211)=92.04, p&#x0003c;0.001) and liked (F(1,211)=60.2, p&#x0003c;0.001) the optimal shape more than the non&#x02013;optimal shape. This was selective to the gain condition (preferences: F(1,211)=30.7; p&#x0003c;0.001, liking: F(1,211)=14.97, p&#x0003c;0.001) as indicated by a significant interaction by task condition (preferences: F(1,211)=2.85, p=0.09; liking: F(1,211)=6.04, p&#x0003c;0.05). No main effect of treatment (preferences: F(2,211)=0.66, p=0.51), liking: (F(2,211)=0.76, p=0.47) or any other interaction were significant.</p></sec><sec id="S25"><title>Image acquisition</title><p id="P71">We acquired T2*-weighted echo spiral in/out images with blood oxygenation level dependent (BOLD) contrast using a 1.5 tesla scanner (GE Medical Systems). Each volume comprised of 26 interleaved, axial slices of 4 mm thickness and 3.5 mm in-plane resolution, using the following parameters: TR=2000 ms, TE=35 ms, flip angle=84&#x000b0;, FOV=192 mm, 64&#x000d7;64 matrix. For each subject a total number of 600 volumes were obtained, 300 in each learning task run, corresponding to 10 minutes of scanning for each run. Additionally, a single high resolution T1-weighted structural image (spoiled gradient echo sequence (SPGR)) was acquired for each patient at the beginning of the on drug scan session, prior to performing the on drug learning task runs of the experiment.</p></sec><sec id="S26"><title>FMRI analysis</title><p id="P72">All functional images were screened on quality using in house software. Specifically, spike and high movement time points were identified and corrected by interpolating adjacent time points. In addition to this, images were screened on fast movement (&#x02265;1 mm/TR) and corrected using the Art Repair toolbox<sup><xref rid="R59" ref-type="bibr">59</xref></sup>.</p><p id="P73">Analysis of fMRI data was conducted using the statistical parametric mapping software SPM8 (Wellcome Department of Imaging Neuroscience, London, UK). We normalized the structural scans to a standard T1 template and created a normalized structural average image upon which the t-maps were superimposed for anatomical localization. Preprocessing of the functional scans consisted of spatial realignment to the first volume, spatial normalization to a standard T2* template with a resampled voxel size of 2&#x000d7;2 mm, and spatial smoothing using a Gaussian kernel with a full width at half maximum of 6 mm. We analyzed the functional images in an event&#x02013;related manner, within a general linear model (GLM), and included subject specific realignment parameters into each GLM as covariates to control for motion artifacts.</p><p id="P74">First, we tested if expected value activated the vmPFC and if prediction error activated the ventral striatum irrespective of trial condition (i.e. gains, losses) or time point (1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, or 4<sup>th</sup> block). Two onset regressors (i.e. onset choice, onset feedback) were respectively modulated by expected value and prediction error, obtained for each trial by a standard temporal difference learning algorithm that assigns a value to each cue based on the subjects&#x02019; previous choices and reward received. Delta functions of onset regressors and parametric modulators were convolved with the canonical hemodynamic response function and regressed against each subject&#x02019;s fMRI data. Linear contrasts were fit into a second-level random effects analysis, which used one-sample t-tests to identify brain regions underpinning expected value and prediction error in each treatment condition. We applied small volume correction to determine the effects of expected value and prediction error in each treatment condition with a lenient initial threshold of p&#x0003c; 0.01, uncorrected.</p><p id="P75">Having identified vmPFC responses to expected value and ventral striatum responses to prediction error, we investigated the specificity of these activations. Building on the behavioral results that suggested that placebo and drug selectively enhance the slope of learning from gains, we used a second GLM to model fMRI data in each subject similarly to the behavioral analysis. Specifically, trials at time of choice and feedback were binned into four regressors per trial condition (i.e. gain trials, loss trials). Each onset regressor reflected a given time during the task (i.e. the 1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup> block of 8 trials) and was modulated by expected value (at choice onset) and prediction error (at feedback onset), respectively. Delta functions of the 16 onset regressors and the 16 parametric modulators were convolved with the canonical hemodynamic response function and regressed against each subject&#x02019;s fMRI data. Average parameter estimates for the parametric modulators were extracted from regions of interest (ROIs) located in the vmPFC (for expected value) and the ventral striatum (for prediction error). Thus, we obtained, per patient for both expected value and prediction error, 4 parameter estimates for the gain condition and 4 parameters estimates for the loss condition.</p></sec><sec id="S27"><title>Analysis of parameter estimates</title><p id="P76">A multilevel linear regression model using iterative generalized least squares (IGLS)<sup><xref rid="R58" ref-type="bibr">58</xref></sup> tested for drug and placebo effects. Analogous to the analysis of optimal choices, the parameter estimates from each ROI were fit by GLM1 (testing for drug effects), GLM2 (testing for placebo effects), and GLM3 (testing for interaction with trial type: gains, losses) from the behavioral analysis. Individual betas were entered into second&#x02013;level group analyses to provide population inferences against zero. We entered the order of placebo administration (dummy coded: &#x02212;1 for placebo first, 1 for placebo second) as a second&#x02013;level covariate. Similarly to our behavioral findings, order did not confound drug and placebo effects. We used a statistical significance threshold of p&#x0003c;0.05, one-tailed, to evaluate regression coefficients.</p><p id="P77">Note, we observed significant main effects of drug (On&#x0003e;Off drug) and placebo (Placebo&#x0003e;Off drug) on both vmPFC and the ventral striatum parameter estimates. To better display the main effects, parameter estimates were averaged across patients and blocks (i.e. the 1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup> block of 8 trials) in <xref rid="SD3" ref-type="supplementary-material">Figs. 5b and 6b</xref>.</p></sec><sec id="S28"><title>Regions of interest</title><p id="P78">Regions of interest in the vmPFC and the ventral striatum were defined a priori from independent fMRI studies. The vmPFC ROI was defined by the Montreal Neurological Institute (MNI) space coordinates [x=&#x02212;1, y=27, z=&#x02212;18] reported for value by Hare et al. 2008<sup><xref rid="R60" ref-type="bibr">60</xref></sup>. The ventral striatum ROI was defined by the MNI coordinates [x=&#x02212;10, y=12, z=&#x02212;8] reported for striatal prediction errors by Pessiglione et al. 2006<sup><xref rid="R61" ref-type="bibr">61</xref></sup>. Average parameter estimates (i.e. betas) were extracted from a 10 mm diameter sphere centered on the vmPFC and ventral striatal coordinates.</p></sec><sec id="S29"><title>Direct comparison of treatment conditions</title><p id="P79">Direct comparisons of treatment conditions did not reveal any differences in whole brain activation for expected value or prediction error at an uncorrected threshold of p&#x0003c;0.001. See <xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 8</xref> for whole brain activations at p&#x0003c;0.05 uncorrected.</p></sec><sec id="S30"><title>Effects of scaling choice value and prediction error</title><p id="P80">One possible interpretation of our findings is that the observed brain activations are due to individual variance in learning. For example, choice values or prediction errors may reach a different maximum and vary on different scales between treatment conditions and subjects. Thus, to rule out the possibility these differences in parametric modulators contributed to the observed drug and placebo effects, we z-scored expected values and prediction error regressors. The temporal difference learning algorithm used to obtain trial-by-trial expected values and prediction errors used one optimal learning rate (&#x003b1;=0.2) and one optimal temperature (&#x003b2;=0.4), which were fit across all subjects, treatment conditions, and trials. This was done in order to avoid additional confounds due to differences in learning model between subjects, treatment, and trial conditions (i.e. gains, losses).</p><p id="P81">Consistent with our main findings, this supplemental GLM analysis, which controlled for scaling and learning model differences, revealed that the placebo and on drug conditions enhanced choice value representation in the vmPFC (Placebo&#x0003e;Off drug: t<sub>11</sub>=1.4, p=0.08; On&#x0003e;Off drug: t<sub>11</sub>=1.7, p&#x0003c;0.05) compared to off drug, with no difference between placebo and on drug (On&#x0003e;Placebo: t<sub>11</sub>=0.75, p&#x0003e;0.05). Prediction error activation of the ventral striatum was decreased (Placebo&#x0003c;Off drug: t<sub>11</sub>=2.1, p&#x0003c;0.05; On&#x0003c;Off drug: t<sub>11</sub>=1.8, p&#x0003c;0.05) when patients were treated by a placebo or dopaminergic medication compared to off drug with no difference between placebo and on drug (On&#x0003c;Placebo: t<sub>11</sub>=0.23, p&#x0003e;0.05). The observed placebo and drug effects were selective to learning from gains. No significant differences in treatment conditions were observed for learning from losses. Therefore, we concluded that placebo and drug effects on vmPFC and ventral striatum BOLD responses were not confounded by individual differences in magnitude and scale of learning.</p></sec><sec id="S31"><title>Learning related brain responses outside the RL framework</title><p id="P82">To test for learning related responses in vmPFC and ventral striatum outside of a reinforcement learning model framework, we used raw observed responses and replaced the expected value regressor at time of choice with actual observed choices (dummy coded: 1 for optimal choice, &#x02212;1 for non-optimal choice) and replaced the prediction error regressor at time of outcome by actual observed feedback (dummy coded: 1 for correct, &#x02212;1 for incorrect). Delta functions of the onset regressors and parametric modulators were convolved with the canonical hemodynamic responses function and regressed against each individual&#x02019;s fMRI data. We then used paired t-tests to examine the effects of placebo and drug on parameter estimates in independently defined regions of interest in the vmPFC and the ventral striatum.</p><p id="P83">The results of this analysis are strikingly similar to what we observed with the model&#x02013;derived regressors for expected value and prediction error. Choice&#x02013;related activation in the vmPFC was enhanced both by drug and by placebo compared to off drug (On&#x0003e;Off drug: t<sub>14</sub>=2.9, p&#x0003c;0.05; Placebo&#x0003e;Off: t<sub>14</sub>=2.38, p&#x0003c;0.05, two&#x02013;tailed, paired t&#x02013;test), with no differences between drug and placebo (On&#x0003e;Placebo: t<sub>14</sub>=1.05, p=0.3, two-tailed) (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 3</xref>). Moreover, these effects were selective to learning from gains, as indicated by a trend interaction (Gains&#x0003e;Losses*Placebo&#x0003e;Off drug: t<sub>14</sub>=1.96, p=0.06, two&#x02013;tailed). The interaction was significant for (Gains&#x0003e;Losses*On&#x0003e;Off: t<sub>14</sub>=2.9, p&#x0003c;0.05, two&#x02013;tailed). No significant differences were found for learning from losses (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 3a</xref>).</p><p id="P84">Activation to correct vs. incorrect feedback in the ventral striatum was also similar to the results from RL-model derived analyses: we found greater activation for correct vs. incorrect feedback during learning from gains when patients were off drug compared to on drug (Off&#x0003e;On: t<sub>14</sub>=1.97, p=0.06, two&#x02013;tailed) or placebo (Off&#x0003e;Placebo: t<sub>14</sub>=2.27, p&#x0003c;0.05, two-tailed). No differences were observed between on drug and placebo (On&#x0003e;Placebo: t<sub>14</sub>=0.63, p=0.5, two-tailed). Again, this finding was selective to learning from gains: the interactions (Gains&#x0003e;Losses*Off&#x0003e;Placebo: t<sub>14</sub>=2.9, p&#x0003c;0.05, two&#x02013;tailed) and (Gains&#x0003e;Losses*Off&#x0003e;On: t<sub>14</sub>=1.7, p=0.10, two-tailed) were significant. No effects were found for learning from losses (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 3b</xref>).</p></sec><sec id="S32"><title>Striatal responses to components of the prediction error</title><p id="P85">To test how treatment affects different aspects of the reinforcement learning signal, we broke down the prediction error signal to its separate algebraic components &#x02013; expectation and reward (following<sup><xref rid="R62" ref-type="bibr">62</xref>&#x02013;<xref rid="R64" ref-type="bibr">64</xref></sup>) &#x02013; and examined how each of these signals were affected by treatment. Specifically, we built a GLM comprising two onset regressors: time of choice and time of outcome. Additionally, at time of outcome, two parametric modulators were included that corresponded to the algebraic components of the prediction error: expected value of the choice (derived from the RL model) and reward magnitude (dummy coded: 1 for a gain of $10, 0 for $0, and &#x02212;1 for a loss of $10). Delta functions of onset regressors and parametric modulators were convolved with the canonical hemodynamic response function and regressed against each subject&#x02019;s fMRI data. Individual parameter estimates for expected value and reward were extracted from the independently defined ventral striatum ROI (MNI coordinates=[&#x02212;10, 12, &#x02212;8] from Pessiglione et al. 2006<sup><xref rid="R61" ref-type="bibr">61</xref></sup>). Two&#x02013;tailed paired t&#x02013;tests were used to test for treatment effects on both expected value and reward related activation. While there were no significant treatment effects for expected value related ventral striatum activation (On&#x0003e;Off: t<sub>14</sub>=1.14; Placebo&#x0003e;Off: t<sub>14</sub>=0.45 and On&#x0003e;Placebo: t<sub>14</sub>=0.82, p&#x0003e;0.05), reward magnitude elicited significantly stronger responses off drug compared to placebo (Off&#x0003e;Placebo: t<sub>14</sub>=2.14, p&#x0003c;0.05) and numerically, but not significantly, stronger responses compared to on drug (Off&#x0003e;On: t<sub>14</sub>=1.63, p=0.12), with no differences between placebo and on drug (On&#x0003e;Placebo: t<sub>14</sub>=0.21, p&#x0003e;0.05) (<xref rid="SD3" ref-type="supplementary-material">Supplementary Fig. 4</xref>). We concluded from these finding that placebo and drug alter the reward component of the prediction error at time of outcome.</p></sec><sec id="S33"><title>Control analyses</title><p id="P86">If placebo and drug affected BOLD activity in general, rather than specifically affecting learning&#x02013;related activity, then effects of treatment would be expected (1) at task&#x02013;irrelevant events (e.g. fixation), and/or (2) in other brain regions.</p><sec id="S34"><title>1. Main effect of treatment condition at time of fixation</title><p id="P87">To test the possibility of a global effect of treatment on BOLD activity, we examined brain activation at time of fixation. The GLM included one regressor at onset fixation. Boxcar functions for the whole fixation duration were convolved with the hemodynamic response function in each trial. Individual contrast images were entered into a second&#x02013;level random effects analysis. A one-way ANOVA revealed no main effect of treatment conditions (F(2,42)=8.2, p&#x0003e;0.001, uncorrected).</p></sec><sec id="S35"><title>2. Treatment effects in control ROIs</title><p id="P88">To test the possibility of treatment effects on BOLD activity in other brain regions, we defined control regions of interest (ROI) in the primary motor cortex and the primary visual cortex. ROIs were defined anatomically using the AAL package implemented in the WFU-Pickatlas software of SPM8<sup><xref rid="R65" ref-type="bibr">65</xref></sup>. The motor cortex ROI comprised the left precentral gyrus and the visual cortex ROI comprised the calcarine sulcus. We applied small volume correction to determine the effects of value and prediction error in each treatment condition with a lenient initial threshold of p&#x0003c;0.01 uncorrected. We found no effect of drug or placebo on BOLD activity in these control regions for either value or prediction error related activity.</p></sec></sec><sec id="S36"><title>Task instructions</title><p id="P89">The game consists of 2 sessions, each comprising 64 trials and lasting for 10 minutes. The first session will be preceded by a training session outside the scanner comprising 32 trials.</p><p id="P90">The word &#x02018;ready&#x02019; will be displayed 6 seconds before the game starts.</p><p id="P91">In each trial you have to choose between the two cues displayed on the screen, on the left and right of a central cross.</p><list list-type="bullet" id="L1"><list-item><p id="P92">to choose the right cue, press the right mouse button</p></list-item><list-item><p id="P93">to choose the left cue, press the left mouse button</p></list-item></list><p id="P94">As soon as you press the button, a white arrow displayed at the bottom of the selected cue will indicate your choice.</p><p id="P95">As an outcome of your choice you may</p><list list-type="bullet" id="L2"><list-item><p id="P96">get nothing ($0)</p></list-item><list-item><p id="P97">win a ten dollar bill (+$10)</p></list-item><list-item><p id="P98">lose a ten dollar bill (&#x02212;$10)</p></list-item></list><p id="P99">To have a chance to win, you must make a choice and press one of the two buttons. If you do nothing, the white arrow will remain at the central cross.</p><p id="P100">The two cues displayed on a same screen are not equivalent in terms of outcome: with one you are more likely to get nothing than with the other. Each cue has got its own meaning, regardless of where (left or right of the central cross) or when it is displayed.</p><p id="P101">The aim of the game is to win as much money as possible.</p><p id="P102">Good luck!</p></sec></sec><sec sec-type="supplementary-material" id="S37"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>1</label><media xlink:href="NIHMS629786-supplement-1.doc" orientation="portrait" xlink:type="simple" id="d37e1340" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD2"><label>2</label><media xlink:href="NIHMS629786-supplement-2.doc" orientation="portrait" xlink:type="simple" id="d37e1344" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD3"><label>3</label><media xlink:href="NIHMS629786-supplement-3.pdf" orientation="portrait" xlink:type="simple" id="d37e1348" position="anchor"/></supplementary-material><supplementary-material content-type="local-data" id="SD4"><label>4</label><media xlink:href="NIHMS629786-supplement-4.pdf" orientation="portrait" xlink:type="simple" id="d37e1352" position="anchor"/></supplementary-material></sec></body><back><ack id="S38"><p>This study was supported by the Michael J. Fox Foundation and the NIH (R01MH076136). We thank Dr. Paul Greene, Dr. Roy Alcalay, Dr. Lucien Cot&#x000e9;, and the nursing staff of the Center for Parkinson&#x02019;s Disease and Other Movement Disorders at Columbia University Presbyterian Hospital for help with patient recruitment and discussion of the findings; Natalie Johnston and Blair Vail for help with data collection; Madeleine Sharp, Katherine Duncan, David Sulzer, Jochen Weber and Bradley Doll for insightful discussion; and Mathias Pessiglione and G. Elliott Wimmer for helpful comments on an earlier version of the manuscript.</p></ack><fn-group><fn id="FN3"><p><bold>NOTES</bold>: <xref rid="SD3" ref-type="supplementary-material">Supplementary Materials</xref> are available in the online version of the paper.</p></fn><fn id="FN4" fn-type="con"><p><bold>AUTHOR CONTRIBUTIONS</bold></p><p>D.S. and T.D.W. planned the experiment. L.S., T.D.W., and D.S. developed the experimental design. L.S. and E.K.B. collected data. L.S. analyzed data. D.S. and T.D.W. supervised and assisted in data analysis. L.S., E.K.B., T.D.W., and D.S. wrote the manuscript.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goetz</surname><given-names>CG</given-names></name><etal/></person-group><article-title>Placebo influences on dyskinesia in Parkinson&#x02019;s disease</article-title><source>Mov Disord</source><volume>23</volume><fpage>700</fpage><lpage>707</lpage><year>2008</year><pub-id pub-id-type="pmid">18175337</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goetz</surname><given-names>CG</given-names></name><etal/></person-group><article-title>Placebo response in Parkinson&#x02019;s disease: Comparisons among 11 trials covering medical and surgical interventions</article-title><source>Movement Disorders</source><volume>23</volume><fpage>690</fpage><lpage>699</lpage><year>2008</year><pub-id pub-id-type="pmid">18228568</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McRae</surname><given-names>C</given-names></name><etal/></person-group><article-title>Effects of perceived treatment on quality of life and medical outcomes in a double-blind placebo surgery trial</article-title><source>Arch Gen Psychiatry</source><volume>61</volume><fpage>412</fpage><lpage>420</lpage><year>2004</year><pub-id pub-id-type="pmid">15066900</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedetti</surname><given-names>F</given-names></name><etal/></person-group><article-title>Placebo-responsive Parkinson patients show decreased activity in single neurons of subthalamic nucleus</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>587</fpage><lpage>588</lpage><year>2004</year><pub-id pub-id-type="pmid">15146189</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Fuente-Fernandez</surname><given-names>R</given-names></name><etal/></person-group><article-title>Expectation and dopamine release: mechanism of the placebo effect in Parkinson&#x02019;s disease</article-title><source>Science</source><volume>293</volume><fpage>1164</fpage><lpage>1166</lpage><year>2001</year><pub-id pub-id-type="pmid">11498597</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lidstone</surname><given-names>SC</given-names></name><etal/></person-group><article-title>Effects of expectation on placebo-induced dopamine release in Parkinson disease</article-title><source>Arch Gen Psychiatry</source><volume>67</volume><fpage>857</fpage><lpage>865</lpage><year>2010</year><pub-id pub-id-type="pmid">20679593</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voon</surname><given-names>V</given-names></name><etal/></person-group><article-title>Mechanisms underlying dopamine-mediated reward bias in compulsive behaviors</article-title><source>Neuron</source><volume>65</volume><fpage>135</fpage><lpage>142</lpage><year>2010</year><pub-id pub-id-type="pmid">20152119</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Fuente-Fernandez</surname><given-names>R</given-names></name><etal/></person-group><article-title>Dopamine release in human ventral striatum and expectation of reward</article-title><source>Behav Brain Res</source><volume>136</volume><fpage>359</fpage><lpage>363</lpage><year>2002</year><pub-id pub-id-type="pmid">12429397</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schweinhardt</surname><given-names>P</given-names></name><name><surname>Seminowicz</surname><given-names>DA</given-names></name><name><surname>Jaeger</surname><given-names>E</given-names></name><name><surname>Duncan</surname><given-names>GH</given-names></name><name><surname>Bushnell</surname><given-names>MC</given-names></name></person-group><article-title>The anatomy of the mesolimbic reward system: a link between personality and the placebo analgesic response</article-title><source>J Neurosci</source><volume>29</volume><fpage>4882</fpage><lpage>4887</lpage><year>2009</year><pub-id pub-id-type="pmid">19369556</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zubieta</surname><given-names>JK</given-names></name><name><surname>Stohler</surname><given-names>CS</given-names></name></person-group><article-title>Neurobiological mechanisms of placebo responses</article-title><source>Ann N Y Acad Sci</source><volume>1156</volume><fpage>198</fpage><lpage>210</lpage><year>2009</year><pub-id pub-id-type="pmid">19338509</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title><source>Nature</source><volume>442</volume><fpage>1042</fpage><lpage>1045</lpage><year>2006</year><pub-id pub-id-type="pmid">16929307</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><source>Reinforcement learning: an introduction</source><publisher-name>A Bradford Book</publisher-name><year>1998</year></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><article-title>Reinforcement learning and dynamic programming</article-title><source>Analysis, Design and Evaluation of Man-Machine Systems 1995</source><volume>1 and 2</volume><fpage>407</fpage><lpage>412</lpage><year>1995</year></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><source>Decision making, affect, learning: attention and performance xxiii</source><volume>1</volume><person-group person-group-type="editor"><name><surname>Delgado</surname><given-names>MR</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><publisher-name>Oxford University Press</publisher-name><year>2011</year></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><year>2006</year><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>TA</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>J</given-names></name><name><surname>Camerer</surname><given-names>CF</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><article-title>Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors</article-title><source>J Neurosci</source><volume>28</volume><fpage>5623</fpage><lpage>5630</lpage><year>2008</year><pub-id pub-id-type="pmid">18509023</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>DJ</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><article-title>The root of all value: a neural common currency for choice</article-title><source>Curr Opin Neurobiol</source><volume>22</volume><year>2012</year></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plassmann</surname><given-names>H</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><article-title>Appetitive and aversive goal values are encoded in the medial orbitofrontal cortex at the time of decision making</article-title><source>J Neurosci</source><volume>30</volume><fpage>10799</fpage><lpage>10808</lpage><year>2010</year><pub-id pub-id-type="pmid">20702709</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClure</surname><given-names>SM</given-names></name><name><surname>Berns</surname><given-names>GS</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><article-title>Temporal prediction errors in a passive learning task activate human striatum</article-title><source>Neuron</source><volume>38</volume><fpage>339</fpage><lpage>346</lpage><year>2003</year><pub-id pub-id-type="pmid">12718866</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Critchley</surname><given-names>H</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Temporal difference models and reward-related learning in the human brain</article-title><source>Neuron</source><volume>38</volume><fpage>329</fpage><lpage>337</lpage><year>2003</year><pub-id pub-id-type="pmid">12718865</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Doya</surname><given-names>K</given-names></name></person-group><article-title>The computational neurobiology of learning and reward</article-title><source>Curr Opin Neurobiol</source><volume>16</volume><fpage>199</fpage><lpage>204</lpage><year>2006</year><pub-id pub-id-type="pmid">16563737</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><article-title>General mechanisms for decision making</article-title><source>Current Opinion in Neurobiologie</source><volume>19</volume><issue>75</issue><fpage>83</fpage><year>2009</year></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname><given-names>R</given-names></name><etal/></person-group><article-title>Dopamine restores reward prediction errors in old age</article-title><source>Nat Neurosci</source><volume>16</volume><fpage>648</fpage><lpage>653</lpage><year>2013</year><pub-id pub-id-type="pmid">23525044</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schonberg</surname><given-names>T</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Joel</surname><given-names>D</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name></person-group><article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making</article-title><source>J Neurosci</source><volume>27</volume><fpage>12860</fpage><lpage>12867</lpage><year>2007</year><pub-id pub-id-type="pmid">18032658</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schonberg</surname><given-names>T</given-names></name><etal/></person-group><article-title>Selective impairment of prediction error signaling in human dorsolateral but not ventral striatum in Parkinson&#x02019;s disease patients: evidence from a model-based fMRI study</article-title><source>Neuroimage</source><volume>49</volume><fpage>772</fpage><lpage>781</lpage><year>2010</year><pub-id pub-id-type="pmid">19682583</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><article-title>Associative learning of social value</article-title><source>Nature</source><volume>456</volume><fpage>245</fpage><lpage>249</lpage><year>2008</year><pub-id pub-id-type="pmid">19005555</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Delgado</surname><given-names>MR</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><article-title>How instructed knowledge modulates the neural systems of reward learning</article-title><source>Proc Natl Acad Sci U S A</source><volume>108</volume><fpage>55</fpage><lpage>60</lpage><year>2011</year><pub-id pub-id-type="pmid">21173266</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Edlund</surname><given-names>JA</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name></person-group><article-title>Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain</article-title><source>J Neurosci</source><volume>32</volume><fpage>551</fpage><lpage>562</lpage><year>2012</year><pub-id pub-id-type="pmid">22238090</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirsch</surname><given-names>I</given-names></name></person-group><article-title>Response expectancy as a determinant of experience and behavior</article-title><source>American Psychologist</source><year>1985</year></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wager</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Placebo-induced changes in FMRI in the anticipation and experience of pain</article-title><source>Science</source><volume>303</volume><fpage>1162</fpage><lpage>1167</lpage><year>2004</year><pub-id pub-id-type="pmid">14976306</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname><given-names>M</given-names></name><etal/></person-group><article-title>Subliminal instrumental conditioning demonstrated in the human brain</article-title><source>Neuron</source><volume>59</volume><fpage>561</fpage><lpage>567</lpage><year>2008</year><pub-id pub-id-type="pmid">18760693</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>L</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Lafargue</surname><given-names>G</given-names></name><name><surname>Pessiglione</surname><given-names>M</given-names></name></person-group><article-title>Splitting motivation: unilateral effects of subliminal incentives</article-title><source>Psychol Sci</source><volume>21</volume><fpage>977</fpage><lpage>983</lpage><year>2010</year><pub-id pub-id-type="pmid">20511391</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedetti</surname><given-names>F</given-names></name></person-group><article-title>How the doctor&#x02019;s words affect the patient&#x02019;s brain</article-title><source>Eval Health Prof</source><volume>25</volume><fpage>369</fpage><lpage>386</lpage><year>2002</year><pub-id pub-id-type="pmid">12449081</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fournier</surname><given-names>JC</given-names></name><etal/></person-group><article-title>Antidepressant drug effects and depression severity: a patient-level meta-analysis</article-title><source>JAMA</source><volume>303</volume><fpage>47</fpage><lpage>53</lpage><year>2010</year><pub-id pub-id-type="pmid">20051569</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirsch</surname><given-names>I</given-names></name><name><surname>Sapirstein</surname><given-names>G</given-names></name></person-group><article-title>Listening to Prozac but hearing placebo: A meta-analysis of antidepressant medication</article-title><source>Prevention &#x00026; Treatment</source><volume>1</volume><year>1998</year></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bodi</surname><given-names>N</given-names></name><etal/></person-group><article-title>Reward-learning and the novelty-seeking personality: a between- and within-subjects study of the effects of dopamine agonists on young Parkinson&#x02019;s patients</article-title><source>Brain</source><volume>132</volume><fpage>2385</fpage><lpage>2395</lpage><year>2009</year><pub-id pub-id-type="pmid">19416950</pub-id></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Seeberger</surname><given-names>LC</given-names></name><name><surname>O&#x02019;Reilly</surname><given-names>RC</given-names></name></person-group><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><year>2004</year><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname><given-names>S</given-names></name><etal/></person-group><article-title>Pharmacological modulation of subliminal learning in Parkinson&#x02019;s and Tourette&#x02019;s syndromes</article-title><source>Proc Natl Acad Sci U S A</source><volume>106</volume><fpage>19179</fpage><lpage>19184</lpage><year>2009</year><pub-id pub-id-type="pmid">19850878</pub-id></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maia</surname><given-names>TV</given-names></name></person-group><article-title>Reinforcement learning, conditioning, and the brain: Successes and challenges</article-title><source>Cogn Affect Behav Neurosci</source><volume>9</volume><fpage>343</fpage><lpage>364</lpage><year>2009</year><pub-id pub-id-type="pmid">19897789</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JM</given-names></name><etal/></person-group><article-title>Negative symptoms and the failure to represent the expected reward value of actions: behavioral and computational modeling evidence</article-title><source>Arch Gen Psychiatry</source><volume>69</volume><fpage>129</fpage><lpage>138</lpage><year>2012</year><pub-id pub-id-type="pmid">22310503</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bamford</surname><given-names>NS</given-names></name><etal/></person-group><article-title>Heterosynaptic dopamine neurotransmission selects sets of corticostriatal terminals</article-title><source>Neuron</source><volume>42</volume><fpage>653</fpage><lpage>663</lpage><year>2004</year><pub-id pub-id-type="pmid">15157425</pub-id></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>W</given-names></name><etal/></person-group><article-title>Regulation of prefrontal excitatory neurotransmission by dopamine in the nucleus accumbens core</article-title><source>J Physiol</source><volume>590</volume><fpage>3743</fpage><lpage>3769</lpage><year>2012</year><pub-id pub-id-type="pmid">22586226</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bamford</surname><given-names>NS</given-names></name><etal/></person-group><article-title>Dopamine modulates release from corticostriatal terminals</article-title><source>J Neurosci</source><volume>24</volume><year>2004</year></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colloca</surname><given-names>L</given-names></name><etal/></person-group><article-title>Learning potentiates neurophysiological and behavioral placebo analgesic responses</article-title><source>Pain</source><volume>139</volume><fpage>306</fpage><lpage>314</lpage><year>2008</year><pub-id pub-id-type="pmid">18538928</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voudouris</surname><given-names>NJ</given-names></name><name><surname>Peck</surname><given-names>CL</given-names></name><name><surname>Coleman</surname><given-names>G</given-names></name></person-group><article-title>The role of conditioning and verbal expectancy in the placebo response</article-title><source>Pain</source><volume>43</volume><fpage>121</fpage><lpage>128</lpage><year>1990</year><pub-id pub-id-type="pmid">2277714</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kordower</surname><given-names>JH</given-names></name><etal/></person-group><article-title>Disease duration and the integrity of the nigrostriatal system in disease</article-title><source>Brain</source><volume>136</volume><fpage>2419</fpage><lpage>2431</lpage><year>2013</year><pub-id pub-id-type="pmid">23884810</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Barker</surname><given-names>RA</given-names></name><name><surname>Sahakian</surname><given-names>BJ</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><article-title>Enhanced or impaired cognitive function in Parkinson&#x02019;s disease as a function of dopaminergic medication and task demands</article-title><source>Cereb Cortex</source><volume>11</volume><fpage>1136</fpage><lpage>1143</lpage><year>2001</year><pub-id pub-id-type="pmid">11709484</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Seeberger</surname><given-names>LC</given-names></name><name><surname>O&#x02019;Reilly</surname><given-names>RC</given-names></name></person-group><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><year>2004</year><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Geghman</surname><given-names>KD</given-names></name><name><surname>Sage</surname><given-names>J</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><article-title>L&#x02013;dopa impairs learning, but spares generalization, in Parkinson&#x02019;s disease</article-title><source>Neuropsychologia</source><volume>44</volume><fpage>774</fpage><lpage>784</lpage><year>2006</year><pub-id pub-id-type="pmid">16150469</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Grossman</surname><given-names>S</given-names></name><name><surname>Sage</surname><given-names>J</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><article-title>The role of dopamine in cognitive sequence learning: evidence from Parkinson&#x02019;s disease</article-title><source>Behav Brain Res</source><volume>156</volume><fpage>191</fpage><lpage>199</lpage><year>2005</year><pub-id pub-id-type="pmid">15582105</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de la Fuente&#x02013;Fernandez</surname><given-names>R</given-names></name><etal/></person-group><article-title>Expectation and dopamine release: mechanism of the placebo effect in Parkinson&#x02019;s disease</article-title><source>Science</source><volume>293</volume><fpage>1164</fpage><lpage>1166</lpage><year>2001</year><pub-id pub-id-type="pmid">11498597</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedetti</surname><given-names>F</given-names></name><etal/></person-group><article-title>Placebo&#x02013;responsive Parkinson patients show decreased activity in single neurons of subthalamic nucleus</article-title><source>Nat Neurosci</source><volume>7</volume><fpage>587</fpage><lpage>588</lpage><year>2004</year><pub-id pub-id-type="pmid">15146189</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedetti</surname><given-names>F</given-names></name><etal/></person-group><article-title>Electrophysiological properties of thalamic, subthalamic and nigral neurons during the anti&#x02013;parkinsonian placebo response</article-title><source>J Physiol</source><volume>587</volume><fpage>3869</fpage><lpage>3883</lpage><year>2009</year><pub-id pub-id-type="pmid">19546163</pub-id></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starkstein</surname><given-names>SE</given-names></name><etal/></person-group><article-title>Reliability, validity, and clinical correlates of apathy in Parkinson&#x02019;s disease</article-title><source>J Neuropsychiatry Clin Neurosci</source><volume>4</volume><fpage>134</fpage><lpage>139</lpage><year>1992</year><pub-id pub-id-type="pmid">1627973</pub-id></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spielberger</surname><given-names>CD</given-names></name></person-group><source>State&#x02013;Trait Anxiety Inventory: Bibliography</source><edition>2</edition><publisher-name>Consulting Psychologists Press</publisher-name><year>1989</year></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><collab>Movement Disorder Society Task Force on Rating Scales for Parkinson&#x02019;s Disease</collab><article-title>The Unified Parkinson&#x02019;s Disease Rating Scale (UPDRS): Status and Recommendations</article-title><source>Movement Disorders</source><volume>18</volume><fpage>738</fpage><lpage>750</lpage><year>2003</year><pub-id pub-id-type="pmid">12815652</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><source>Reinforcement learning: an introduction</source><publisher-name>A Bradford Book</publisher-name><year>1998</year></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindquist</surname><given-names>MA</given-names></name><name><surname>Spicer</surname><given-names>J</given-names></name><name><surname>Asllani</surname><given-names>I</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><article-title>Estimating and testing variance components in a multi&#x02013;level GLM</article-title><source>Neuroimage</source><volume>59</volume><fpage>490</fpage><lpage>501</lpage><year>2012</year><pub-id pub-id-type="pmid">21835242</pub-id></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mazaika</surname><given-names>P</given-names></name><name><surname>Hoeft</surname><given-names>F</given-names></name><name><surname>Glover</surname><given-names>GH</given-names></name><name><surname>Reiss</surname><given-names>AL</given-names></name></person-group><source>Human Brain Mapping</source><year>2009</year></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>TA</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>J</given-names></name><name><surname>Camerer</surname><given-names>CF</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><article-title>Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors</article-title><source>J Neurosci</source><volume>28</volume><fpage>5623</fpage><lpage>5630</lpage><year>2008</year><pub-id pub-id-type="pmid">18509023</pub-id></element-citation></ref><ref id="R61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessiglione</surname><given-names>M</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Dopamine&#x02013;dependent prediction errors underpin reward&#x02013;seeking behaviour in humans</article-title><source>Nature</source><volume>442</volume><fpage>1042</fpage><lpage>1045</lpage><year>2006</year><pub-id pub-id-type="pmid">16929307</pub-id></element-citation></ref><ref id="R62"><label>62</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><article-title>Associative learning of social value</article-title><source>Nature</source><volume>456</volume><fpage>245</fpage><lpage>249</lpage><year>2008</year><pub-id pub-id-type="pmid">19005555</pub-id></element-citation></ref><ref id="R63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Edlund</surname><given-names>JA</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>O&#x02019;Doherty</surname><given-names>JP</given-names></name></person-group><article-title>Neural prediction errors reveal a risk&#x02013;sensitive reinforcement&#x02013;learning process in the human brain</article-title><source>J Neurosci</source><volume>32</volume><fpage>551</fpage><lpage>562</lpage><year>2012</year><pub-id pub-id-type="pmid">22238090</pub-id></element-citation></ref><ref id="R64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Delgado</surname><given-names>MR</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><article-title>How instructed knowledge modulates the neural systems of reward learning</article-title><source>Proc Natl Acad Sci U S A</source><volume>108</volume><fpage>55</fpage><lpage>60</lpage><year>2011</year><pub-id pub-id-type="pmid">21173266</pub-id></element-citation></ref><ref id="R65"><label>65</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maldjian</surname><given-names>JA</given-names></name><name><surname>Laurienti</surname><given-names>PJ</given-names></name><name><surname>Kraft</surname><given-names>RA</given-names></name><name><surname>Burdette</surname><given-names>JH</given-names></name></person-group><article-title>An automated method for neuroanatomic and cytoarchitectonic atlas&#x02013;based interrogation of fMRI data sets</article-title><source>Neuroimage</source><volume>19</volume><year>2003</year></element-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Instrumental learning task. Successive screenshots are displayed for one trial with durations in milliseconds. On each trial, participants chose between two shapes and subsequently observed an outcome. Participants were instructed to maximize their winnings by learning the optimal shape. In this example (a gain trial), the choice is optimal, because 75% of the time it would lead to a monetary gain ($10) and only 25% of the time would lead to no reward ($0). During an alternative loss trial (not displayed), the optimal choice would lead to a monetary loss (&#x02212;$10) only 25% of the time and would lead to no reward ($0) 75% of the time. Gain and loss trials, distinguished by unique pairs of symbols, were randomly intermixed within a learning session.</p></caption><graphic xlink:href="nihms629786f1"/></fig><fig id="F2" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Behavioral results (n = 18). Percentage of optimal choices averaged across blocks (1<sup>st</sup>, 2<sup>nd</sup>, 3<sup>rd</sup>, and 4<sup>th</sup>) of 8 trials (left panel), smoothed (middle panel), and fitted by a standard reinforcement learning model (right panel) in the gain (top) and loss condition (bottom). The learning curves depict how often subjects chose the 75% rewarding cue during the gain condition (block: t<sub>14</sub> = 5.4, p &#x0003c; 0.001, multilevel linear regression), and the 75% nothing cue during the loss condition (block: t<sub>14</sub> = 3.5, p <italic>&#x0003c;</italic> 0.005, multilevel linear regression). Error bars represent within subject standard errors.</p></caption><graphic xlink:href="nihms629786f2"/></fig><fig id="F3" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Ventromedial prefrontal cortex (vmPFC) value activity (n = 15). <bold>(a)</bold> BOLD activity in the vmPFC correlated with expected value (<italic>p<sup>FWE</sup></italic> &#x0003c; 0.05, small volume corrected), collapsed across gain and loss conditions during learning. Statistical parametric maps (SPMs) are shown for each treatment condition at p &#x0003c; 0.005, uncorrected and masked for the vmPFC. <bold>(b)</bold> Parameter estimates (betas) for expected value from the vmPFC region of interest in the gain (left) and loss condition (right) for off drug (gray), placebo (blue), and on drug (black) treatments. Error bars represent within subject standard errors.</p></caption><graphic xlink:href="nihms629786f3"/></fig><fig id="F4" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Striatal prediction error activity (n = 15). <bold>(a)</bold> BOLD activity in the ventral striatum correlated with prediction error during the off drug and the placebo sessions (<italic>p<sup>FWE</sup></italic> &#x0003c; 0.05, small volume corrected), collapsed across gain and loss conditions during learning. SPMs are shown for each treatment condition at p &#x0003c; 0.005, uncorrected and masked for the ventral striatum. <bold>(b)</bold> Parameter estimates (betas) for prediction error from the ventral striatum region of interest in the gain (left) and loss condition (right) for off drug (gray), placebo (blue), and on drug (black) conditions. Error bars represent within subject standard errors.</p></caption><graphic xlink:href="nihms629786f4"/></fig></floats-group></article>