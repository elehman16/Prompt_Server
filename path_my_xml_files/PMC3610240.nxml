<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="other" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Womens Health</journal-id><journal-id journal-id-type="iso-abbrev">BMC Womens Health</journal-id><journal-title-group><journal-title>BMC Women's Health</journal-title></journal-title-group><issn pub-type="epub">1472-6874</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">23379630</article-id><article-id pub-id-type="pmc">3610240</article-id><article-id pub-id-type="publisher-id">1472-6874-13-3</article-id><article-id pub-id-type="doi">10.1186/1472-6874-13-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Correspondence</subject></subj-group></article-categories><title-group><article-title>Development of a diagnostic test set to assess agreement in breast pathology: practical application of the Guidelines for Reporting Reliability and Agreement Studies (GRRAS)</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Oster</surname><given-names>Natalia V</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>nvoster@uw.edu</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Carney</surname><given-names>Patricia A</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>carneyp@ohsu.edu</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Allison</surname><given-names>Kimberly H</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>allisonk@standford.edu</email></contrib><contrib contrib-type="author" id="A4"><name><surname>Weaver</surname><given-names>Donald L</given-names></name><xref ref-type="aff" rid="I4">4</xref><email>Donald.Weaver@vtmednet.org</email></contrib><contrib contrib-type="author" id="A5"><name><surname>Reisch</surname><given-names>Lisa M</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>lreisch@uw.edu</email></contrib><contrib contrib-type="author" id="A6"><name><surname>Longton</surname><given-names>Gary</given-names></name><xref ref-type="aff" rid="I5">5</xref><email>glongton@fhcrc.org</email></contrib><contrib contrib-type="author" id="A7"><name><surname>Onega</surname><given-names>Tracy</given-names></name><xref ref-type="aff" rid="I6">6</xref><email>Tracy.Onega@dartmouth.edu</email></contrib><contrib contrib-type="author" id="A8"><name><surname>Pepe</surname><given-names>Margaret</given-names></name><xref ref-type="aff" rid="I5">5</xref><email>mpepe@fhcrc.org</email></contrib><contrib contrib-type="author" id="A9"><name><surname>Geller</surname><given-names>Berta M</given-names></name><xref ref-type="aff" rid="I7">7</xref><email>berta.geller@uvm.edu</email></contrib><contrib contrib-type="author" id="A10"><name><surname>Nelson</surname><given-names>Heidi D</given-names></name><xref ref-type="aff" rid="I8">8</xref><email>nelsonh@ohsu.edu</email></contrib><contrib contrib-type="author" id="A11"><name><surname>Ross</surname><given-names>Tyler R</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>Tyler.Ray.Ross@gmail.com</email></contrib><contrib contrib-type="author" id="A12"><name><surname>Tosteson</surname><given-names>N AAnna</given-names></name><xref ref-type="aff" rid="I6">6</xref><email>Anna.Tosteson@dartmouth.edu</email></contrib><contrib contrib-type="author" id="A13"><name><surname>Elmore</surname><given-names>Joann G</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>jelmore@uw.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Medicine, University of Washington, Seattle, WA, USA</aff><aff id="I2"><label>2</label>Department of Family Medicine, Oregon Health and Science University, Portland, OR, USA</aff><aff id="I3"><label>3</label>Department of Pathology, Stanford University School of Medicine, Palo Alto, CA, USA</aff><aff id="I4"><label>4</label>Department of Pathology, University of Vermont and Vermont Cancer Center, Burlington, VT, USA</aff><aff id="I5"><label>5</label>Public Health Sciences Division, Fred Hutchinson Cancer Research Center, Seattle, WA, USA</aff><aff id="I6"><label>6</label>Norris Cotton Cancer Center and The Dartmouth Institute for Health Policy and Clinical Practice, Geisel School of Medicine at Dartmouth, Hanover, NH, USA</aff><aff id="I7"><label>7</label>Office of Health Promotion Research, University of Vermont, Burlington, VT, USA</aff><aff id="I8"><label>8</label>Department of Medical Informatics and Clinical Epidemiology, Oregon Health and Science University, Portland, OR, USA</aff><pub-date pub-type="collection"><year>2013</year></pub-date><pub-date pub-type="epub"><day>5</day><month>2</month><year>2013</year></pub-date><volume>13</volume><fpage>3</fpage><lpage>3</lpage><history><date date-type="received"><day>1</day><month>10</month><year>2012</year></date><date date-type="accepted"><day>18</day><month>1</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2013 Oster et al.; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2013</copyright-year><copyright-holder>Oster et al.; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.biomedcentral.com/1472-6874/13/3"/><abstract><sec><title>Background</title><p>Diagnostic test sets are a valuable research tool that contributes importantly to the validity and reliability of studies that assess agreement in breast pathology. In order to fully understand the strengths and weaknesses of any agreement and reliability study, however, the methods should be fully reported. In this paper we provide a step-by-step description of the methods used to create four complex test sets for a study of diagnostic agreement among pathologists interpreting breast biopsy specimens. We use the newly developed Guidelines for Reporting Reliability and Agreement Studies (GRRAS) as a basis to report these methods.</p></sec><sec><title>Methods</title><p>Breast tissue biopsies were selected from the National Cancer Institute-funded Breast Cancer Surveillance Consortium sites. We used a random sampling stratified according to woman&#x02019;s age (40&#x02013;49 vs. &#x02265;50), parenchymal breast density (low vs. high) and interpretation of the original pathologist. A 3-member panel of expert breast pathologists first independently interpreted each case using five primary diagnostic categories (non-proliferative changes, proliferative changes without atypia, atypical ductal hyperplasia, ductal carcinoma in situ, and invasive carcinoma). When the experts did not unanimously agree on a case diagnosis a modified Delphi method was used to determine the reference standard consensus diagnosis. The final test cases were stratified and randomly assigned into one of four unique test sets.</p></sec><sec><title>Conclusions</title><p>We found GRRAS recommendations to be very useful in reporting diagnostic test set development and recommend inclusion of two additional criteria: 1) characterizing the study population and 2) describing the methods for reference diagnosis, when applicable.</p></sec></abstract><kwd-group><kwd>Reporting guidelines</kwd><kwd>Reliability of results</kwd><kwd>Agreement studies</kwd><kwd>Breast</kwd><kwd>Pathology</kwd><kwd>Diagnostic techniques</kwd></kwd-group></article-meta></front><body><sec><title>Background</title><p>In 2011, the Guidelines for Reporting Reliability and Agreement Studies (GRRAS) were developed to outline and describe key methodological issues that should be addressed when reporting on reliability and agreement studies [<xref ref-type="bibr" rid="B1">1</xref>]. Clinicians&#x02019; interpretive reliability and diagnostic agreement are often evaluated using test sets. Yet, the methods used to develop these test sets are complex and multi-faceted. The development of test sets can lead to inherent biases, such as selecting high-quality cases only or selecting cases from unique clinical practices rather than random selection from large databases or populations [<xref ref-type="bibr" rid="B2">2</xref>-<xref ref-type="bibr" rid="B8">8</xref>]. To fully understand the strengths and weaknesses of any study that utilizes test set methodology, the development of the test set must be fully described and reported. The GRRAS recommendations provide a framework for doing so.</p><p>Most of the 15 GRRAS recommendations refer to the presentation of study methods and interpretation of results (Table&#x000a0;<xref ref-type="table" rid="T1">1</xref>). These include describing the diagnostic or measurement device of interest, specifying the rater population, and providing an in-depth description of the sampling methods and sample size for both the subject and rater populations.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Current GRRAS Guidelines and Suggested Additions to GRRAS</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th align="left">&#x000a0;</th><th align="left"><bold>Current Guidelines for Reporting Reliability and Agreement Studies (GRRAS) [</bold>[<xref ref-type="bibr" rid="B1">1</xref>]<bold>]</bold></th><th align="left"><bold>Suggested Additions to GRRAS</bold></th></tr></thead><tbody><tr><td align="left" valign="bottom">TITLE AND ABSTRACT<hr/></td><td align="left" valign="bottom">1. Identify in title or abstract that interrater/intrarater reliability or agreement was investigated.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">INTRODUCTION<hr/></td><td align="left" valign="bottom">2. Name and describe the diagnostic or measurement device of interest explicitly.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">3. Specify the subject population of interest.<hr/></td><td align="left" valign="bottom">Describe the database used to select the cases and the quality of that data.<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">4. Specify the rater population of interest (if applicable).<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">5. Describe what is already known about reliability and agreement and provide a rationale for the study (if applicable).<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">METHODS<hr/></td><td align="left" valign="bottom">6. Explain how the sample size was chosen. State the determined number of raters, subjects/objects, and replicate observations.<hr/></td><td align="left" valign="bottom">Describe the sampling method and the underlying population of both subjects and raters.<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">7. Define the Reference Standard diagnosis.<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">8. Describe the sampling method.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">9. Describe the measurement/rating process (e.g. time interval between repeated measurements, availability of clinical information, blinding).<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">10. State whether measurements/ratings were conducted independently.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">11. Describe the statistical analysis.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">RESULTS<hr/></td><td align="left" valign="bottom">12. State the actual number of raters and subjects/objects which were included and the number of replicate observations which were conducted.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">13. Describe the sample characteristics of raters and subjects (e.g. training, experience).<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="left" valign="bottom">14. Report estimates of reliability and agreement including measures of statistical uncertainty.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left" valign="bottom">DISCUSSION<hr/></td><td align="left" valign="bottom">15. Discuss the practical relevance of results.<hr/></td><td align="left" valign="bottom">&#x000a0;<hr/></td></tr><tr><td align="left">AUXILIARY MATERIAL</td><td align="left">16. Provide detailed results if possible (e.g. online).</td><td align="left">&#x000a0;</td></tr></tbody></table></table-wrap><p>In this paper, we use GRRAS recommendations to provide an overview of our methods to create four diagnostic test sets for a study assessing agreement among pathologists in the interpretation of breast biopsy specimens. The aims of the larger study include determining relationships between characteristics of patients and pathologists and diagnostic accuracy of biopsy specimens. In this paper, we focus on describing the sampling and random assignment methods (GRRAS criteria 1&#x02013;13, Table&#x000a0;<xref ref-type="table" rid="T1">1</xref>) used to create the diagnostic test sets, as well as the demographics of the patient subjects whose breast biopsies were included in the test set cases. We also identify and discuss important additional criteria that would make GRRAS stronger and potentially even more relevant when test sets are employed. The statistical analysis and results of the inter-rater agreement of the test set cases will be reported elsewhere.</p></sec><sec sec-type="materials|methods"><title>Methods and materials</title><sec><title>IRB approval and consenting process</title><p>Biopsy specimens for the test set cases were identified and obtained from the Breast Cancer Surveillance Consortium (BCSC) registries in Vermont and New Hampshire [<xref ref-type="bibr" rid="B9">9</xref>-<xref ref-type="bibr" rid="B11">11</xref>]. The BCSC is a collaborative network of five geographically distinct mammography registries with linkages to breast pathology and/or tumor registries [<xref ref-type="bibr" rid="B10">10</xref>]. BCSC procedures are Health Insurance Portability and Accountability Act (HIPAA) compliant and all registries have a Federal Certificate of Confidentiality and other protection for the identities of research subjects and the physicians and facilities that contribute data to the BCSC [<xref ref-type="bibr" rid="B12">12</xref>]. Women enrolled in BCSC registries provided prior consent to BCSC investigators allowing their archived tissue samples to be used for research [<xref ref-type="bibr" rid="B10">10</xref>]. Thus, the research subjects did not need to be re-consented for the development of the test sets created for the current study.</p><p>Institutional Review Boards at the University of Washington, Dartmouth College, the University of Vermont, Fred Hutchinson Cancer Research Center, and Providence Health &#x00026; Services of Oregon approved all test set study activities. A study-specific Certificate of Confidentiality (NCI 11&#x02013;049) was also obtained to protect the study findings from forced disclosure of identifiable information.</p></sec><sec><title>Test set case identification and selection</title><p>All biopsies used for the test set cases were performed between January 1, 2000 and December 31, 2008. Only excisional and core needle biopsies were used. Total mastectomy cases and fine needle aspiration specimens were excluded. Only one biopsy per woman was selected. When multiple biopsies were available from a single woman we randomly selected a biopsy within a hierarchical classification of cases with available clinical history. We prioritized biopsies in which the woman&#x02019;s hormone therapy (HT) status at time of biopsy was known. If HT status was unknown, cases were selected by availability of information on family history. If both HT and family history were unknown cases were selected by known race.</p><p>All women with a previous history of breast cancer were excluded. A family history of breast cancer was defined as having a first degree relative (i.e., mother, daughter or sister) with a breast cancer diagnosis. Breast cancer history was assessed through a yes/no response to the following questions, depending on the BCSC site, on a risk factor questionnaire: &#x0201c;Have you ever been diagnosed with breast cancer?&#x0201d; or &#x0201c;Has the patient ever had breast cancer?&#x0201d;. A total of 19,498 biopsies obtained from 13,677 distinct women met our eligibility requirements.</p><p>Test set cases were selected using random stratified sampling based on the age of the woman (40&#x02013;49 vs. &#x02265;50), breast density (low vs. high), and the final diagnostic interpretation of the original BCSC contributing pathologist who reviewed the woman&#x02019;s biopsy for clinical treatment and management. Contributing BCSC pathologists include a variety of practice settings ranging from private practices in small hospitals to large University-affiliated academic practices in tertiary medical centers. For all potential test set cases, we categorized the diagnostic interpretations of the BCSC pathologist into one of five diagnostic classifications (non-proliferative changes, proliferative changes without atypia, atypical ductal hyperplasia (ADH), ductal carcinoma in situ (DCIS), and invasive breast carcinoma). This resulted in 20 possible combinations of test set cases (5 diagnostic categories x 2 age groups x 2 breast density groups = 20 combinations). Low versus high breast density was defined as &#x02264; 50% fibroglandular (BI-RADS categories 1 and 2) or &#x02265; 51% fibroglandular (BI-RADS categories 3 and 4), respectively. Information on breast density was obtained from mammography exams in the three years prior to biopsy. We used data from the most proximal mammogram for women with multiple mammograms within the three year period.</p><p>We oversampled cases of ADH and DCIS compared to national estimates of biopsy outcomes in the U.S. [<xref ref-type="bibr" rid="B13">13</xref>] to increase statistical confidence and raw rates of inter-observer variation in areas of breast pathology that may be more challenging to interpret, are lower frequency diagnoses, and where disagreements would affect treatment. Population-based adjustments according to disease prevalence will be made during statistical analysis.</p><p>Previous studies have shown misclassification rates among pathologists of over 50% for ADH and 17% for DCIS [<xref ref-type="bibr" rid="B14">14</xref>]. Women in their 40s and women with dense breast tissue were also oversampled because age and breast density are known risk factors for both benign breast disease and breast cancer [<xref ref-type="bibr" rid="B15">15</xref>], and because our <italic>a priori</italic> hypotheses include that there is more diagnostic variability in biopsies from women aged 40&#x02013;49 years and women with dense breast tissue. By design, half of the test set cases were from women aged 40&#x02013;49 at the time of the biopsy and half were from women aged 50 and older, with no upper age limit. Also by design, half of the cases were from women with high-density breast tissue and half were from women with low-density breast tissue.</p><p>A listing of candidate cases was randomly identified from the Vermont and New Hampshire BCSC registries (data not shown). Tissue blocks and original slides were requested from clinical facilities in Vermont (n=8) and New Hampshire (n=8) for review by our expert pathology panel. If a facility did not send the material after three written requests and two phone requests, we removed that case from our selection and requested the next case on the list within the 20 selection categories until we met our target accrual of 425 cases (Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>). Not all cases were available at the time of request.&#x02009;Reasons for a case being unavailable included insufficient residual tissue in paraffin blocks, the facility required additional consent procedures, or the tissue had already been discarded.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Flow chart describing test set development.</p></caption><graphic xlink:href="1472-6874-13-3-1"/></fig></sec><sec><title>Initial review of biopsy material</title><p>An expert pathology panel comprised of three internationally recognized breast pathologists reviewed all selected cases. One expert panel member conducted an initial assessment of all original slides associated with the biopsy received from the clinical facility. The woman&#x02019;s age and biopsy type (core needle or excisional) were the only clinical history provided for each case. This expert was blinded to the original diagnosis made by the contributing pathologist. After the initial review was complete, new study-specific glass slides were created from each case&#x02019;s appropriate paraffin embedded tissue block(s) to ensure consistent staining and image quality. The newly created slides were used for the full expert panel review.</p></sec><sec><title>Standardized data collection</title><p>We developed a standardized histology data collection form, called the Breast Pathology Assessment Tool Hierarchy (B-PATH) form, which the expert pathologists used to record detailed diagnostic information about each case during their review. The B-PATH form included the same five diagnostic categories that were used for case selection (non-proliferative changes, proliferative changes without atypia, ADH, DCIS, and invasive breast carcinoma). The expert pathologists were asked to indicate if the case was borderline between two diagnostic categories and whether they would have requested a second diagnostic opinion for the case had they seen it in clinical practice. Finally, the B-PATH form asked pathologists to rate the level of diagnostic difficulty and their level of confidence in the assessment of each case using a 6-point Likert scale, with 1 representing &#x0201c;very easy&#x0201d; or &#x0201c;very confident&#x0201d; and 6 representing &#x0201c;very challenging&#x0201d; or &#x0201c;not confident&#x0201d;, respectively.</p></sec><sec><title>Independent and consensus review by expert panel</title><p>The 3-member expert pathologist panel (including the expert who conducted the initial review of the original tissue slides) performed blinded independent assessments on each slide using the standardized B-PATH form.</p><p>We used a modified Delphi approach [<xref ref-type="bibr" rid="B16">16</xref>] to establish the final reference standard diagnosis for each slide. This involved compiling the independent reviews for each case, providing the three experts with their initial interpretation of the slides, followed by a facilitated discussion of features and diagnostic criteria of areas where disagreement among the experts occurred during a re-review of the slide(s) at a multi-headed microscope. The facilitated discussion continued until a final consensus was reached among all three expert pathologists on the case interpretation. When more than one slide was available for a case, the panel selected the slide that was most representative of the diagnosis.</p></sec><sec><title>Sample size calculations and random assignment of cases into four diagnostic test sets</title><p>The number of cases per test set and the number of participating study pathologists were chosen to provide sufficient power to address the study aims. Using conservative assumptions about diagnostic variability among pathologists, [<xref ref-type="bibr" rid="B14">14</xref>] we determined that 60 cases per test set of glass slides interpreted by 100 participating pathologists would, for example, yield 90% power to detect an effect of patient age (40&#x02013;49 vs. &#x02265;50 years) on a misclassification rate difference as small as 4.8% when interpreting cases with atypia and DCIS.</p><p>After the three expert pathologists reached final diagnostic consensus, and each case had been mapped into one of five primary diagnostic categories (Table&#x000a0;<xref ref-type="table" rid="T2">2</xref>), 240 unique patient cases were randomly selected from a total of 336 cases reviewed by the expert panel (Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>). Selection was performed within cells defined by three stratification factors in order to obtain the desired distribution of cases across factors. These included 1) case diagnosis (using the five diagnostic categories on the B-PATH data collection form), 2) patient age (40&#x02013;49 vs. &#x02265;50), and 3) breast density (low vs. high), respectively. A permuted block randomization method with block size of four was used to assign cases to the four test sets. Blocks were defined within strata by similarity of case difficulty score (i.e., the mean Likert rating on the difficulty level assigned to each case by the three expert pathologists). For strata in which the cell total was not evenly divisible by four, random permutations of the relevant sets were assigned to the remaining partial block. Four final test sets were developed, each of which contained 60 unique patient cases.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Diagnostic Breast Pathology Assessment Tool Hierarchy (B-PATH) mapping categories for test set cases</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th align="left"><bold>Primary clinical diagnostic category</bold></th><th align="left"><bold>All diagnoses included in primary clinical diagnostic categories</bold></th></tr></thead><tbody valign="top"><tr><td rowspan="2" align="left" valign="bottom">I. Non-Proliferative*<hr/></td><td align="left" valign="bottom">Non-Proliferative only<hr/></td></tr><tr><td align="left" valign="bottom">Fibroadenoma<hr/></td></tr><tr><td rowspan="6" align="left" valign="bottom">II. Proliferative changes without atypia<hr/></td><td align="left" valign="bottom">Usual ductal hyperplasia<hr/></td></tr><tr><td align="left" valign="bottom">Columnar cell hyperplasia/columnar cell changes<hr/></td></tr><tr><td align="left" valign="bottom">Sclerosing adenosis<hr/></td></tr><tr><td align="left" valign="bottom">Radial Scar/complex sclerosing lesion<hr/></td></tr><tr><td align="left" valign="bottom">Flat epithelial atypia<hr/></td></tr><tr><td align="left" valign="bottom">Intraductal papilloma w/o atypia<hr/></td></tr><tr><td rowspan="2" align="left" valign="bottom">III. Atypical ductal hyperplasia (ADH)<hr/></td><td align="left" valign="bottom">Atypical ductal hyperplasia<hr/></td></tr><tr><td align="left" valign="bottom">Intraductal papilloma with atypia<hr/></td></tr><tr><td align="left" valign="bottom">IV. Ductal carcinoma in situ (DCIS)<hr/></td><td align="left" valign="bottom">Ductal carcinoma in situ<hr/></td></tr><tr><td align="left">V. Invasive breast cancer</td><td align="left">Invasive (ductal or lobular or other special type)</td></tr></tbody></table><table-wrap-foot><p>*For development of the test set, cases were categorized according to the highest ductal proliferative or malignant lesion present on the slide. When only lobular carcinoma in situ (LCIS) or atypical lobular hyperplasia (ALH) was present (n=2), we categorized cases as non-proliferative.</p></table-wrap-foot></table-wrap><p>We aimed to create a test set of slides that, as closely as possible, mirrored the quality and variety of cases observed in everyday clinical practice. We recognize that there is a wide range of diagnostic quality of source material; our statistical sampling and selection methods were designed to eliminate or minimize selection bias. Cases were deemed ineligible only when there was slide preparation artifact or insufficient tissue present to interpret the slide (n=40), tissue other than breast tissue was present on the slide due to a contributing facility supplying an incorrect block (n=5), the tissue block was unavailable (n=1), male breast tissue was present (n=1), or atypical lactation changes were present (n=1). The final set of eligible cases selected may not be considered necessarily easy or difficult to interpret, or ideal for teaching purposes because the selection process was designed to circumvent the type of selection bias that may exist in typical continuing medical educational conferences and courses.</p><p>The results of the inter-rater agreement of the test sets and a description of how the test sets will be used to assess agreement in pathologists&#x02019; diagnostic interpretation of breast tissue will be reported elsewhere. In brief, approximately 200 study pathologists will be invited to independently review the test set cases and provide their diagnostic interpretation. These interpretations will be compared to the reference standard diagnoses as determined by the expert pathology panel and to the interpretations of other pathologists in the study.</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>In this paper we provide an example of how GRRAS recommendations can be applied to developing and reporting the methods used to create diagnostic test sets to assess interpretive reliability and diagnostic agreement. Previous studies have described the poor quality of research reporting [<xref ref-type="bibr" rid="B17">17</xref>-<xref ref-type="bibr" rid="B19">19</xref>] but, encouragingly, research has also shown that the development and use of formalized guidelines improves the quality of reporting [<xref ref-type="bibr" rid="B20">20</xref>]. The methods that are used to develop test sets contribute importantly to the validity of study findings. Thus, providing a clear description of methodological details and standardized terminology [<xref ref-type="bibr" rid="B21">21</xref>] is critical in assisting readers to assess the strengths and shortcomings of the study findings, especially as they relate to implications for clinical care.</p><p>Because the GRRAS recommendations are new, Kottner et al. [<xref ref-type="bibr" rid="B1">1</xref>] invited researchers to provide feedback on whether use of the guidelines improves reporting for studies of reliability and agreement, and to suggest updates for the guidelines themselves. Our investigative team found GRRAS very helpful in describing the complex methods of developing a diagnostic breast pathology test set. In addition to the current GRRAS recommendations, we suggest the inclusion of additional guidelines for test set development that may be applicable to other studies. First, we suggest that data sources for patient populations be well characterized, both in terms of geographic and health system features. This is important because if patients are from a small geographic area (e.g., a single clinic or hospital) they will likely be different from those identified from a large geographic sample or dataset and as such will affect the generalizability of the study results. Second, if accuracy is being investigated, researchers should describe the methods used to define the reference diagnosis or gold standard. The importance of documenting this is widely recognized in guidelines for reporting diagnostic accuracy studies such as STARD [<xref ref-type="bibr" rid="B22">22</xref>]. While some studies of inter-rater reliability are designed to evaluate agreement, it is often more clinically useful to understand accuracy. Studies can be designed using external tests or additional clinical follow-up to define a reference standard diagnosis. For example, two years of follow-up can be used to determine if breast cancer develops in studies of variability of radiologists&#x02019; interpretation of mammography, [<xref ref-type="bibr" rid="B23">23</xref>] and echocardiography can be used as the reference standard to assess the diagnostic accuracy of physicians identifying cardiac lesion type and severity by auscultation [<xref ref-type="bibr" rid="B24">24</xref>].</p><p>Breast cancer diagnosis and treatment relies on pathologists&#x02019; interpretation of breast biopsy specimens. However, studies investigating levels of interpretive agreement when diagnosing breast cancer and precursor lesions are limited [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B14">14</xref>]. The substantial clinical disagreement in pathological interpretation of borderline cases raises concern about over or under treatment of women with precursor lesions such as ADH and DCIS. In addition, misclassifications alter the study of patient outcomes associated with effective treatment. The use of carefully developed test sets provides an opportunity to improve our understanding of interpretive variation and its underlying causes.</p><sec><title>Strengths and limitations</title><p>Studies of observer reliability and accuracy often rely on test sets. Yet, the use of test sets, no matter how carefully developed, opens the door to limitations shared by these studies, including ours. First, the use of test sets may cause clinicians to modify their opinion to reflect what they believe is the &#x0201c;right&#x0201d; response [<xref ref-type="bibr" rid="B25">25</xref>,<xref ref-type="bibr" rid="B26">26</xref>]. Second, performance on test sets may not reflect performance in clinical practice [<xref ref-type="bibr" rid="B25">25</xref>,<xref ref-type="bibr" rid="B27">27</xref>]. An ideal study design might include embedding test cases into actual clinical practice while keeping the interpreting clinician blinded to test cases. However, it is logistically impractical to keep pathologists blinded to test cases in studies that involve large numbers of physicians from multiple geographic locations and a large number of test cases. Third, as described by Kundel et al. [<xref ref-type="bibr" rid="B28">28</xref>] accuracy in many studies is only implied with the assumption that when readers agree they must be correct. However, readers may all agree and also be wrong. There is not a perfect method to define a reference standard, but studies have found that the use of consensus ratings by experts show more accurate estimates of case diagnosis and outcomes compared to non-consensus trials, even when raters&#x02019; bias is considered [<xref ref-type="bibr" rid="B29">29</xref>]. By requiring complete consensus of our experts on their diagnostic interpretation of all of our test set cases, we expect to achieve the most rigorous reference diagnosis possible for each test set case in this study.</p><p>Our meticulously developed test set used a random case selection process within specific diagnostic categories and had a large sample size, allowing our study design to modify some of the problems inherent in previously reported observer variability studies. Test sets are typically selected with a focus on difficult cases, narrowly selected diagnoses or cases handpicked for unique attributes or high quality. By contrast, our randomly selected test set excluded cases only when there was insufficient diagnostic tissue on the slide or incorrect source tissue blocks were supplied. For this reason, the test sets included cases that some clinicians might interpret as having borderline diagnoses and cases that may not typically be considered ideal for a teaching or training set, but that more accurately reflect the real-world spectrum of findings within each diagnostic category.</p><p>A unique strength of our study is that the case selection methods will allow us to eventually combine our test set interpretive findings with data on the diagnostic distributions of breast biopsy cases from all National Cancer Institute BCSC sites, which are representative of the U.S. population [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B30">30</xref>]. Because the study cases oversampled ADH and DCIS cases we will carefully model the data taking into consideration the prevalence of each diagnostic category in the U.S., based on previously published BCSC data [<xref ref-type="bibr" rid="B13">13</xref>] and new data that we are collecting from the BCSC. Study findings will be combined with other U.S. data to provide population estimates on the impact that alternative breast pathology reading practices may have on health and resource use among women undergoing breast biopsies.</p></sec></sec><sec sec-type="conclusions"><title>Conclusions</title><p>The use of test sets is a valuable research tool that contributes importantly to the reliability and face validity in studies on agreement in diagnosis of biopsy specimens. The methods used to develop these test sets, however, are complex and multi-faceted and contribute to the accuracy of study results. The intent of GRRAS is to provide a framework to fully describe the methods by which a score, rating, or measurement has been determined [<xref ref-type="bibr" rid="B1">1</xref>] so that practitioners and researchers alike can weigh this information along with the study findings. Formalized guidance in reporting is welcomed by many researchers, and the use of guidelines has been found to improve the reporting of research results. We found GRRAS recommendations to be helpful, and encourage their use along with our suggested additions to GRRAS, characterizing the study population and describing the methods used to define the reference diagnosis, when applicable.</p></sec><sec><title>Competing interests</title><p>In the past five years none of the authors have received reimbursements, fees, funding, or salary from an organization that may in any way gain or lose financially from the publication of this manuscript, either now or in the future. No financial organizations are financing this manuscript (including the article-processing charge). No authors hold stocks or shares in an organization that may in any way gain or lose financially from the publication of this manuscript, either now or in the future. None of the authors hold or are currently applying for any patents relating to the content of the manuscript. We have not received reimbursements, fees, funding, or salary from an organization that holds or has applied for patents relating to the content of the manuscript. We have no other financial competing interests to disclose. None of the authors have non-financial competing interests (political, personal, religious, ideological, academic, intellectual, commercial or any other) to declare in relation to this manuscript.</p></sec><sec><title>Authors&#x02019; contributions</title><p>NVO: Participated in study design and implementation. Drafted manuscript. PAC: A key participant in the study design and manuscript preparation. Developed and facilitated the modified Delphi method during the expert panel&#x02019;s consensus meetings which were used to determine the reference standard consensus diagnosis for test set cases. KHA: Participated in study design and conception. Edited manuscript. Key participant in diagnostic agreement discussions during expert consensus meetings. DLW: Key participant in expert consensus meeting and overall study design. Edited manuscript. LR: Participated in the study design and implementation. Facilitated diagnostic consensus meetings. Participated in drafting of manuscript. GL: Performed sample size calculations, performed random statistical assignment of all biopsy cases into four diagnostic test sets and provided oversight on statistical issues during development of the test set. TO: Participated in design of the study, manuscript preparation and editing. MP: Key participant in the statistical design of the study. Provided oversight on statistical analysis during study development and implementation. BMG: Participated in study design and conception. Co-facilitated the modified Delphi method during the expert panel&#x02019;s consensus meetings. Edited manuscript. HN: Study design and conception, manuscript preparation. TR: Performed statistical analysis to identify and select test set cases from the BCSC. AT: Key participant in study conception and design. JGE: Overall study design, conception and implementation. Key participant in manuscript writing and editing. All authors read and approved the final manuscript.</p></sec><sec><title>Pre-publication history</title><p>The pre-publication history for this paper can be accessed here:</p><p><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6874/13/3/prepub">http://www.biomedcentral.com/1472-6874/13/3/prepub</ext-link></p></sec></body><back><sec><title>Acknowledgements</title><p>This work was supported by the National Cancer Institute (R01 CA140560) and by the National Cancer Institute-funded Breast Cancer Surveillance Consortium (U01CA86082, U01CA70013, U01CA69976, HHSN261201100031C). The content is solely the responsibility of the authors and does not necessarily represent the views of the National Cancer Institute or the National Institutes of Health. The collection of cancer and vital status data used in this study was supported in part by several state public health departments and cancer registries throughout the U.S. For a full description of these sources, please see: <ext-link ext-link-type="uri" xlink:href="http://www.breastscreening.cancer.gov/work/acknowledgement.html">http://www.breastscreening.cancer.gov/work/acknowledgement.html</ext-link>. The authors sincerely thank Sara Jackson, MD at the University of Washington for her review of this manuscript. We also gratefully acknowledge Tom Morgan at the University of Washington for his role in the project management of this study.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Kottner</surname><given-names>J</given-names></name><name><surname>Audige</surname><given-names>L</given-names></name><name><surname>Brorson</surname><given-names>S</given-names></name><name><surname>Donner</surname><given-names>A</given-names></name><name><surname>Gajewski</surname><given-names>BJ</given-names></name><name><surname>Hrobjartsson</surname><given-names>A</given-names></name><name><surname>Roberts</surname><given-names>C</given-names></name><name><surname>Shoukri</surname><given-names>M</given-names></name><name><surname>Streiner</surname><given-names>DL</given-names></name><article-title>Guidelines for reporting reliability and agreement studies (GRRAS) were proposed</article-title><source>J Clin Epidemiol</source><year>2011</year><volume>64</volume><issue>1</issue><fpage>96</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2010.03.002</pub-id><pub-id pub-id-type="pmid">21130355</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Schnitt</surname><given-names>SJ</given-names></name><name><surname>Connolly</surname><given-names>JL</given-names></name><name><surname>Tavassoli</surname><given-names>FA</given-names></name><name><surname>Fechner</surname><given-names>RE</given-names></name><name><surname>Kempson</surname><given-names>RL</given-names></name><name><surname>Gelman</surname><given-names>R</given-names></name><name><surname>Page</surname><given-names>DL</given-names></name><article-title>Interobserver reproducibility in the diagnosis of ductal proliferative breast lesions using standardized criteria</article-title><source>Am J Surg Pathol</source><year>1992</year><volume>16</volume><issue>12</issue><fpage>1133</fpage><lpage>1143</lpage><pub-id pub-id-type="doi">10.1097/00000478-199212000-00001</pub-id><pub-id pub-id-type="pmid">1463092</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Rosai</surname><given-names>J</given-names></name><article-title>Borderline epithelial lesions of the breast</article-title><source>Am J Surg Pathol</source><year>1991</year><volume>15</volume><issue>3</issue><fpage>209</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1097/00000478-199103000-00001</pub-id><pub-id pub-id-type="pmid">1847606</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Petralia</surname><given-names>G</given-names></name><name><surname>Bonello</surname><given-names>L</given-names></name><name><surname>Summers</surname><given-names>P</given-names></name><name><surname>Preda</surname><given-names>L</given-names></name><name><surname>Malasevschi</surname><given-names>A</given-names></name><name><surname>Raimondi</surname><given-names>S</given-names></name><name><surname>Di Filippi</surname><given-names>R</given-names></name><name><surname>Locatelli</surname><given-names>M</given-names></name><name><surname>Curigliano</surname><given-names>G</given-names></name><name><surname>Renne</surname><given-names>G</given-names></name><article-title>Intraobserver and interobserver variability in the calculation of apparent diffusion coefficient (ADC) from diffusion-weighted magnetic resonance imaging (DW-MRI) of breast tumours</article-title><source>Radiol Med</source><year>2011</year><volume>116</volume><issue>3</issue><fpage>466</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1007/s11547-011-0616-z</pub-id><pub-id pub-id-type="pmid">21225368</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Imamura</surname><given-names>T</given-names></name><name><surname>Isomoto</surname><given-names>I</given-names></name><name><surname>Sueyoshi</surname><given-names>E</given-names></name><name><surname>Yano</surname><given-names>H</given-names></name><name><surname>Uga</surname><given-names>T</given-names></name><name><surname>Abe</surname><given-names>K</given-names></name><name><surname>Hayashi</surname><given-names>T</given-names></name><name><surname>Honda</surname><given-names>S</given-names></name><name><surname>Yamaguchi</surname><given-names>T</given-names></name><name><surname>Uetani</surname><given-names>M</given-names></name><article-title>Diagnostic performance of ADC for Non-mass-like breast lesions on MR imaging</article-title><source>Magn Reson Med Sci</source><year>2010</year><volume>9</volume><issue>4</issue><fpage>217</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.2463/mrms.9.217</pub-id><pub-id pub-id-type="pmid">21187691</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Darvishian</surname><given-names>F</given-names></name><name><surname>Singh</surname><given-names>B</given-names></name><name><surname>Simsir</surname><given-names>A</given-names></name><name><surname>Ye</surname><given-names>W</given-names></name><name><surname>Cangiarella</surname><given-names>JF</given-names></name><article-title>Atypia on breast core needle biopsies: reproducibility and significance</article-title><source>Ann Clin Lab Sci</source><year>2009</year><volume>39</volume><issue>3</issue><fpage>270</fpage><lpage>276</lpage><pub-id pub-id-type="pmid">19667411</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Haupt</surname><given-names>B</given-names></name><name><surname>Schwartz</surname><given-names>MR</given-names></name><name><surname>Xu</surname><given-names>Q</given-names></name><name><surname>Ro</surname><given-names>JY</given-names></name><article-title>Columnar cell lesions: a consensus study among pathology trainees</article-title><source>Hum Pathol</source><year>2010</year><volume>41</volume><issue>6</issue><fpage>895</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1016/j.humpath.2009.12.003</pub-id><pub-id pub-id-type="pmid">20233620</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Wells</surname><given-names>WA</given-names></name><name><surname>Carney</surname><given-names>PA</given-names></name><name><surname>Eliassen</surname><given-names>MS</given-names></name><name><surname>Tosteson</surname><given-names>AN</given-names></name><name><surname>Greenberg</surname><given-names>ER</given-names></name><article-title>Statewide study of diagnostic agreement in breast pathology</article-title><source>JNCI</source><year>1998</year><volume>90</volume><issue>2</issue><fpage>142</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1093/jnci/90.2.142</pub-id><pub-id pub-id-type="pmid">9450574</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Weaver</surname><given-names>DL</given-names></name><name><surname>Vacek</surname><given-names>PM</given-names></name><name><surname>Skelly</surname><given-names>JM</given-names></name><name><surname>Geller</surname><given-names>BM</given-names></name><article-title>Predicting biopsy outcome after mammography: what is the likelihood the patient has invasive or in situ breast cancer?</article-title><source>Ann Surg Oncol</source><year>2005</year><volume>12</volume><issue>8</issue><fpage>660</fpage><lpage>673</lpage><pub-id pub-id-type="doi">10.1245/ASO.2005.09.008</pub-id><pub-id pub-id-type="pmid">15968496</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="other"><source>Breast cancer surveillance consortium</source><year>2011</year><comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://breastscreening.cancer.gov">http://breastscreening.cancer.gov</ext-link>. Accessed June 1, 2011</comment></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Carney</surname><given-names>PA</given-names></name><name><surname>Poplack</surname><given-names>SP</given-names></name><name><surname>Wells</surname><given-names>WA</given-names></name><name><surname>Littenberg</surname><given-names>B</given-names></name><article-title>The New hampshire mammography network: the development and design of a population-based registry</article-title><source>Am J Roentgenol</source><year>1996</year><volume>167</volume><issue>2</issue><fpage>367</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.2214/ajr.167.2.8686606</pub-id><pub-id pub-id-type="pmid">8686606</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Carney</surname><given-names>PA</given-names></name><name><surname>Geller</surname><given-names>BM</given-names></name><name><surname>Moffett</surname><given-names>H</given-names></name><name><surname>Ganger</surname><given-names>M</given-names></name><name><surname>Sewell</surname><given-names>M</given-names></name><name><surname>Barlow</surname><given-names>WE</given-names></name><name><surname>Stalnaker</surname><given-names>N</given-names></name><name><surname>Taplin</surname><given-names>SH</given-names></name><name><surname>Sisk</surname><given-names>C</given-names></name><name><surname>Ernster</surname><given-names>VL</given-names></name><article-title>Current medicolegal and confidentiality issues in large, multicenter research programs</article-title><source>Am J Epidemiol</source><year>2000</year><volume>152</volume><issue>4</issue><fpage>371</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1093/aje/152.4.371</pub-id><pub-id pub-id-type="pmid">10968382</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Weaver</surname><given-names>DL</given-names></name><name><surname>Rosenberg</surname><given-names>RD</given-names></name><name><surname>Barlow</surname><given-names>WE</given-names></name><name><surname>Ichikawa</surname><given-names>L</given-names></name><name><surname>Carney</surname><given-names>PA</given-names></name><name><surname>Kerlikowske</surname><given-names>K</given-names></name><name><surname>Buist</surname><given-names>DS</given-names></name><name><surname>Geller</surname><given-names>BM</given-names></name><name><surname>Key</surname><given-names>CR</given-names></name><name><surname>Maygarden</surname><given-names>SJ</given-names></name><article-title>Pathologic findings from the breast cancer surveillance consortium: population-based outcomes in women undergoing biopsy after screening mammography</article-title><source>Cancer</source><year>2006</year><volume>106</volume><issue>4</issue><fpage>732</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1002/cncr.21652</pub-id><pub-id pub-id-type="pmid">16411214</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Collins</surname><given-names>LC</given-names></name><name><surname>Connolly</surname><given-names>JL</given-names></name><name><surname>Page</surname><given-names>DL</given-names></name><name><surname>Goulart</surname><given-names>RA</given-names></name><name><surname>Pisano</surname><given-names>ED</given-names></name><name><surname>Fajardo</surname><given-names>LL</given-names></name><name><surname>Berg</surname><given-names>WA</given-names></name><name><surname>Caudry</surname><given-names>DJ</given-names></name><name><surname>McNeil</surname><given-names>BJ</given-names></name><name><surname>Schnitt</surname><given-names>SJ</given-names></name><article-title>Diagnostic agreement in the evaluation of image-guided breast core needle biopsies: results from a randomized clinical trial</article-title><source>Amer J Surg Path</source><year>2004</year><volume>28</volume><issue>1</issue><fpage>126</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1097/00000478-200401000-00015</pub-id><pub-id pub-id-type="pmid">14707874</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Ginsburg</surname><given-names>OM</given-names></name><name><surname>Martin</surname><given-names>LJ</given-names></name><name><surname>Boyd</surname><given-names>NF</given-names></name><article-title>Mammographic density, lobular involution, and risk of breast cancer</article-title><source>Brit J Cancer</source><year>2008</year><volume>99</volume><issue>9</issue><fpage>1369</fpage><lpage>1374</lpage><pub-id pub-id-type="doi">10.1038/sj.bjc.6604635</pub-id><pub-id pub-id-type="pmid">18781174</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="other"><name><surname>Helmer-Hirschberg</surname><given-names>O</given-names></name><source>The systematic Use of expert judgment in operations research</source><year>2012</year><comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.rand.org/pubs/papers/P2795.html">http://www.rand.org/pubs/papers/P2795.html</ext-link>. Accessed August</comment></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Pocock</surname><given-names>SJ</given-names></name><name><surname>Collier</surname><given-names>TJ</given-names></name><name><surname>Dandreo</surname><given-names>KJ</given-names></name><name><surname>de Stavola</surname><given-names>BL</given-names></name><name><surname>Goldman</surname><given-names>MB</given-names></name><name><surname>Kalish</surname><given-names>LA</given-names></name><name><surname>Kasten</surname><given-names>LE</given-names></name><name><surname>McCormack</surname><given-names>VA</given-names></name><article-title>Issues in the reporting of epidemiological studies: a survey of recent practice</article-title><source>BMJ</source><year>2004</year><volume>329</volume><issue>7471</issue><fpage>883</fpage><pub-id pub-id-type="doi">10.1136/bmj.38250.571088.55</pub-id><pub-id pub-id-type="pmid">15469946</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>Honest</surname><given-names>H</given-names></name><name><surname>Khan</surname><given-names>KS</given-names></name><article-title>Reporting of measures of accuracy in systematic reviews of diagnostic literature</article-title><source>BMC Health Serv Res</source><year>2002</year><volume>2</volume><fpage>4</fpage><pub-id pub-id-type="doi">10.1186/1472-6963-2-4</pub-id><pub-id pub-id-type="pmid">11884248</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><name><surname>Smidt</surname><given-names>N</given-names></name><name><surname>Rutjes</surname><given-names>AW</given-names></name><name><surname>van der Windt</surname><given-names>DA</given-names></name><name><surname>Ostelo</surname><given-names>RW</given-names></name><name><surname>Reitsma</surname><given-names>JB</given-names></name><name><surname>Bossuyt</surname><given-names>PM</given-names></name><name><surname>Bouter</surname><given-names>LM</given-names></name><name><surname>de Vet</surname><given-names>HC</given-names></name><article-title>Quality of reporting of diagnostic accuracy studies</article-title><source>Radiology</source><year>2005</year><volume>235</volume><issue>2</issue><fpage>347</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1148/radiol.2352040507</pub-id><pub-id pub-id-type="pmid">15770041</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Smidt</surname><given-names>N</given-names></name><name><surname>Rutjes</surname><given-names>AW</given-names></name><name><surname>van der Windt</surname><given-names>DA</given-names></name><name><surname>Ostelo</surname><given-names>RW</given-names></name><name><surname>Bossuyt</surname><given-names>PM</given-names></name><name><surname>Reitsma</surname><given-names>JB</given-names></name><name><surname>Bouter</surname><given-names>LM</given-names></name><name><surname>de Vet</surname><given-names>HC</given-names></name><article-title>The quality of diagnostic accuracy studies since the STARD statement: has it improved?</article-title><source>Neurology</source><year>2006</year><volume>67</volume><issue>5</issue><fpage>792</fpage><lpage>797</lpage><pub-id pub-id-type="doi">10.1212/01.wnl.0000238386.41398.30</pub-id><pub-id pub-id-type="pmid">16966539</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="book"><collab>National Health Service Breast Screening Programme</collab><source>Quality assurance guidelines for breast pathology services</source><year>2011</year><edition>2</edition><comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.cancerscreening.nhs.uk/breastscreen/publications/nhsbsp02.pdf">http://www.cancerscreening.nhs.uk/breastscreen/publications/nhsbsp02.pdf</ext-link>. Accessed December 2012</comment></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Bossuyt</surname><given-names>PM</given-names></name><name><surname>Reitsma</surname><given-names>JB</given-names></name><name><surname>Bruns</surname><given-names>DE</given-names></name><name><surname>Gatsonis</surname><given-names>CA</given-names></name><name><surname>Glasziou</surname><given-names>PP</given-names></name><name><surname>Irwig</surname><given-names>LM</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Rennie</surname><given-names>D</given-names></name><name><surname>de Vet</surname><given-names>HC</given-names></name><name><surname>Lijmer</surname><given-names>JG</given-names></name><article-title>The STARD statement for reporting studies of diagnostic accuracy: explanation and elaboration</article-title><source>Ann Intern Med</source><year>2003</year><volume>138</volume><issue>1</issue><fpage>W1</fpage><lpage>W12</lpage><pub-id pub-id-type="pmid">12513067</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Elmore</surname><given-names>JG</given-names></name><name><surname>Wells</surname><given-names>CK</given-names></name><name><surname>Lee</surname><given-names>CH</given-names></name><name><surname>Howard</surname><given-names>DH</given-names></name><name><surname>Feinstein</surname><given-names>AR</given-names></name><article-title>Variability in radiologists&#x02019; interpretations of mammograms</article-title><source>N Engl J Med</source><year>1994</year><volume>331</volume><issue>22</issue><fpage>1493</fpage><lpage>1499</lpage><pub-id pub-id-type="doi">10.1056/NEJM199412013312206</pub-id><pub-id pub-id-type="pmid">7969300</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Sztajzel</surname><given-names>JM</given-names></name><name><surname>Picard-Kossovsky</surname><given-names>M</given-names></name><name><surname>Lerch</surname><given-names>R</given-names></name><name><surname>Vuille</surname><given-names>C</given-names></name><name><surname>Sarasin</surname><given-names>FP</given-names></name><article-title>Accuracy of cardiac auscultation in the era of doppler-echocardiography: a comparison between cardiologists and internists</article-title><source>Int J Cardiol</source><year>2010</year><volume>138</volume><issue>3</issue><fpage>308</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1016/j.ijcard.2008.06.066</pub-id><pub-id pub-id-type="pmid">18762344</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Egglin</surname><given-names>TK</given-names></name><name><surname>Feinstein</surname><given-names>AR</given-names></name><article-title>Context bias. A problem in diagnostic radiology</article-title><source>JAMA</source><year>1996</year><volume>276</volume><issue>21</issue><fpage>1752</fpage><lpage>1755</lpage><pub-id pub-id-type="doi">10.1001/jama.1996.03540210060035</pub-id><pub-id pub-id-type="pmid">8940325</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>Bankier</surname><given-names>AA</given-names></name><name><surname>Levine</surname><given-names>D</given-names></name><name><surname>Halpern</surname><given-names>EF</given-names></name><name><surname>Kressel</surname><given-names>HY</given-names></name><article-title>Consensus interpretation in imaging research: is there a better way?</article-title><source>Radiology</source><year>2010</year><volume>257</volume><issue>1</issue><fpage>14</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1148/radiol.10100252</pub-id><pub-id pub-id-type="pmid">20851935</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Gur</surname><given-names>D</given-names></name><name><surname>Bandos</surname><given-names>AI</given-names></name><name><surname>Cohen</surname><given-names>CS</given-names></name><name><surname>Hakim</surname><given-names>CM</given-names></name><name><surname>Hardesty</surname><given-names>LA</given-names></name><name><surname>Ganott</surname><given-names>MA</given-names></name><name><surname>Perrin</surname><given-names>RL</given-names></name><name><surname>Poller</surname><given-names>WR</given-names></name><name><surname>Shah</surname><given-names>R</given-names></name><name><surname>Sumkin</surname><given-names>JH</given-names></name><article-title>The &#x0201c;laboratory&#x0201d; effect: comparing radiologists&#x02019; performance and variability during prospective clinical and laboratory mammography interpretations</article-title><source>Radiology</source><year>2008</year><volume>249</volume><issue>1</issue><fpage>47</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1148/radiol.2491072025</pub-id><pub-id pub-id-type="pmid">18682584</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><name><surname>Kundel</surname><given-names>HL</given-names></name><name><surname>Polansky</surname><given-names>M</given-names></name><article-title>Measurement of observer agreement</article-title><source>Radiology</source><year>2003</year><volume>228</volume><issue>2</issue><fpage>303</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1148/radiol.2282011860</pub-id><pub-id pub-id-type="pmid">12819342</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Weller</surname><given-names>SC</given-names></name><name><surname>Mann</surname><given-names>NC</given-names></name><article-title>Assessing rater performance without a &#x0201c;gold standard&#x0201d; using consensus theory</article-title><source>Med Decis Making</source><year>1997</year><volume>17</volume><issue>1</issue><fpage>71</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1177/0272989X9701700108</pub-id><pub-id pub-id-type="pmid">8994153</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><name><surname>Ballard-Barbash</surname><given-names>R</given-names></name><name><surname>Taplin</surname><given-names>SH</given-names></name><name><surname>Yankaskas</surname><given-names>BC</given-names></name><name><surname>Ernster</surname><given-names>VL</given-names></name><name><surname>Rosenberg</surname><given-names>RD</given-names></name><name><surname>Carney</surname><given-names>PA</given-names></name><name><surname>Barlow</surname><given-names>WE</given-names></name><name><surname>Geller</surname><given-names>BM</given-names></name><name><surname>Kerlikowske</surname><given-names>K</given-names></name><name><surname>Edwards</surname><given-names>BK</given-names></name><article-title>Breast cancer surveillance consortium: a national mammography screening and outcomes database</article-title><source>Am J Roentgenol</source><year>1997</year><volume>169</volume><issue>4</issue><fpage>1001</fpage><lpage>1008</lpage><pub-id pub-id-type="doi">10.2214/ajr.169.4.9308451</pub-id><pub-id pub-id-type="pmid">9308451</pub-id></mixed-citation></ref></ref-list></back></article>