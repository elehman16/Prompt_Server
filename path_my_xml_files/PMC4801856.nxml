<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Aging Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Aging Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Aging Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Aging Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1663-4365</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27047370</article-id><article-id pub-id-type="pmc">4801856</article-id><article-id pub-id-type="doi">10.3389/fnagi.2016.00049</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Working Memory Training and Speech in Noise Comprehension in Older Adults</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wayne</surname><given-names>Rachel V.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/295786/overview"/></contrib><contrib contrib-type="author"><name><surname>Hamilton</surname><given-names>Cheryl</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Jones Huyck</surname><given-names>Julia</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/304231/overview"/></contrib><contrib contrib-type="author"><name><surname>Johnsrude</surname><given-names>Ingrid S.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/317592/overview"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Psychology, Queen's University</institution><country>Kingston, ON, Canada</country></aff><aff id="aff2"><sup>2</sup><institution>Speech Pathology and Audiology, Kent State University</institution><country>Kent, OH, USA</country></aff><aff id="aff3"><sup>3</sup><institution>Department of Psychology, School of Communication Sciences and Disorders, The Brain and Mind Institute, University of Western Ontario</institution><country>London, ON, Canada</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: P. Hemachandra Reddy, Texas Tech University, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: Anna Maria Colangelo, University of Milano-Bicocca, Italy; Annette N. Boles, Texas Tech University Health Sciences Center Garrison Institute on Aging, USA</p></fn><corresp id="fn001">*Correspondence: Rachel V. Wayne <email xlink:type="simple">rachelvwayne@gmail.com</email></corresp></author-notes><pub-date pub-type="epub"><day>22</day><month>3</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>8</volume><elocation-id>49</elocation-id><history><date date-type="received"><day>09</day><month>12</month><year>2015</year></date><date date-type="accepted"><day>22</day><month>2</month><year>2016</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2016 Wayne, Hamilton, Jones Huyck and Johnsrude.</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Wayne, Hamilton, Jones Huyck and Johnsrude</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Understanding speech in the presence of background sound can be challenging for older adults. Speech comprehension in noise appears to depend on working memory and executive-control processes (e.g., Heald and Nusbaum, <xref rid="B27" ref-type="bibr">2014</xref>), and their augmentation through training may have rehabilitative potential for age-related hearing loss. We examined the efficacy of adaptive working-memory training (Cogmed; Klingberg et al., <xref rid="B41" ref-type="bibr">2002</xref>) in 24 older adults, assessing generalization to other working-memory tasks (near-transfer) and to other cognitive domains (far-transfer) using a cognitive test battery, including the Reading Span test, sensitive to working memory (e.g., Daneman and Carpenter, <xref rid="B15" ref-type="bibr">1980</xref>). We also assessed far transfer to speech-in-noise performance, including a closed-set sentence task (Kidd et al., <xref rid="B39" ref-type="bibr">2008</xref>). To examine the effect of cognitive training on benefit obtained from semantic context, we also assessed transfer to open-set sentences; half were semantically coherent (high-context) and half were semantically anomalous (low-context). Subjects completed 25 sessions (0.5&#x02013;1 h each; 5 sessions/week) of both adaptive working memory training and placebo training over 10 weeks in a crossover design. Subjects' scores on the adaptive working-memory training tasks improved as a result of training. However, training did not transfer to other working memory tasks, nor to tasks recruiting other cognitive domains. We did not observe any training-related improvement in speech-in-noise performance. Measures of working memory correlated with the intelligibility of low-context, but not high-context, sentences, suggesting that sentence context may reduce the load on working memory. The Reading Span test significantly correlated only with a test of visual episodic memory, suggesting that the Reading Span test is not a pure-test of working memory, as is commonly assumed.</p></abstract><kwd-group><kwd>cognitive training</kwd><kwd>Cogmed</kwd><kwd>working memory training</kwd><kwd>speech-in-noise</kwd><kwd>speech perception</kwd><kwd>reading span</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">Natural Sciences and Engineering Research Council of Canada<named-content content-type="fundref-id">10.13039/501100000038</named-content></funding-source></award-group><award-group><funding-source id="cn002">Canadian Institutes of Health Research<named-content content-type="fundref-id">10.13039/501100000024</named-content></funding-source></award-group></funding-group><counts><fig-count count="4"/><table-count count="5"/><equation-count count="0"/><ref-count count="86"/><page-count count="15"/><word-count count="12535"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>Perception and comprehension of speech heard in background noise becomes more difficult with age (Plomp and Mimpen, <xref rid="B57" ref-type="bibr">1979</xref>; Van Rooij and Plomp, <xref rid="B79" ref-type="bibr">1990</xref>; Sommers, <xref rid="B70" ref-type="bibr">1997</xref>; Schneider et al., <xref rid="B65" ref-type="bibr">2002</xref>; Pichora-Fuller and Souza, <xref rid="B55" ref-type="bibr">2003</xref>). These difficulties are not fully explained by pure-tone audiometric thresholds (hearing sensitivity), and may be due in part to declining frequency selectivity and temporal coding with age (Kujawa and Liberman, <xref rid="B44" ref-type="bibr">2009</xref>; Gordon-Salant et al., <xref rid="B25" ref-type="bibr">2010</xref>; Humes and Dubno, <xref rid="B32" ref-type="bibr">2010</xref>; Plack et al., <xref rid="B56" ref-type="bibr">2014</xref>). Moreover, amplification devices (i.e., hearing aids), the most widely prescribed treatment for hearing difficulties, improve hearing sensitivity but not frequency selectivity or temporal coding, which are important for segregating speech from background sound (e.g., Perez et al., <xref rid="B54" ref-type="bibr">2014</xref>), and many individuals who have been prescribed hearing aids do not wear them (see McCormack and Fortnum, <xref rid="B48" ref-type="bibr">2013</xref> for a review). As communication difficulties are linked to depression, isolation, and decreased quality of life (Mulrow et al., <xref rid="B50" ref-type="bibr">1990</xref>; Carabellese et al., <xref rid="B11" ref-type="bibr">1993</xref>; Cacciatore et al., <xref rid="B10" ref-type="bibr">1999</xref>), rehabilitative strategies, used either in isolation or in combination with amplification, are urgently needed. Here, we focus on the utility of cognitive strategies for hearing loss rehabilitation.</p><p>Hearing loss leads to degradation of the incoming acoustic signal, and the resulting perceptual ambiguity places increased demands on executive processes that mediate knowledge-guided perceptual processes, such as use of context in order to select the contextually appropriate meaning from among competing alternatives (Rodd et al., <xref rid="B59" ref-type="bibr">2005</xref>, <xref rid="B60" ref-type="bibr">2012</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>). This requires listeners to rely more heavily on top-down information, recruiting previous experience, and linguistic knowledge to help evaluate perceptual hypotheses about the incoming signal (Kane and Engle, <xref rid="B36" ref-type="bibr">2000</xref>).</p><p>The ability to use contextual information effectively to enhance intelligibility varies widely among individuals (Davis et al., <xref rid="B17" ref-type="bibr">2011</xref>; Janse and Jesse, <xref rid="B35" ref-type="bibr">2014</xref>). This variability may be attributable, in part, to individual differences in more domain-general cognitive abilities such as processing speed, and executive functions such as working memory and inhibition (for reviews, see Wingfield and Tun, <xref rid="B81" ref-type="bibr">2007</xref>; Arlinger et al., <xref rid="B2" ref-type="bibr">2009</xref>; Schneider et al., <xref rid="B66" ref-type="bibr">2010</xref>; Heald and Nusbaum, <xref rid="B27" ref-type="bibr">2014</xref>). Executive functions allow listeners to direct attention to a particular speaker, integrate the acoustic signal with previous knowledge, and inhibit irrelevant information (e.g., Tun et al., <xref rid="B76" ref-type="bibr">2002</xref>; Woods et al., <xref rid="B83" ref-type="bibr">2013</xref>; Tamati et al., <xref rid="B74" ref-type="bibr">2013</xref>). In addition, knowledge about linguistic structure and sentence parsing may facilitate the use of contextual information to support speech understanding (Rodd et al., <xref rid="B59" ref-type="bibr">2005</xref>; Aydelott et al., <xref rid="B3" ref-type="bibr">2011</xref>; Billig et al., <xref rid="B6" ref-type="bibr">2013</xref>).</p><p>Slower processing speed is linked to difficulty understanding speech in noise (e.g., Tun and Wingfield, <xref rid="B77" ref-type="bibr">1999</xref>; Pronk et al., <xref rid="B58" ref-type="bibr">2013</xref>) and may be particularly important for understanding speech spoken at fast rates (e.g., Wingfield et al., <xref rid="B82" ref-type="bibr">1999</xref>; Gordon-Salant and Fitzgibbons, <xref rid="B24" ref-type="bibr">2001</xref>). Both processing speed (Salthouse, <xref rid="B64" ref-type="bibr">1996</xref>) and executive functions (Craik and Salthouse, <xref rid="B14" ref-type="bibr">2007</xref>) decline with age and such declines appear to contribute to listening difficulties in older adults (Humes and Dubno, <xref rid="B32" ref-type="bibr">2010</xref>).</p><p>A large body of research has linked working memory measures to speech comprehension in poor listening conditions (due to noise or pathology; e.g., Humes et al., <xref rid="B33" ref-type="bibr">2006</xref>; George et al., <xref rid="B23" ref-type="bibr">2007</xref>; Wingfield and Tun, <xref rid="B81" ref-type="bibr">2007</xref>; Akeroyd, <xref rid="B1" ref-type="bibr">2008</xref>; Rudner et al., <xref rid="B63" ref-type="bibr">2011</xref>; Sorqvist and R&#x000f6;nnberg, <xref rid="B71" ref-type="bibr">2012</xref>; Szenkovits et al., <xref rid="B73" ref-type="bibr">2012</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>; Tamati et al., <xref rid="B74" ref-type="bibr">2013</xref>; Heald and Nusbaum, <xref rid="B27" ref-type="bibr">2014</xref>; Rudner and Lunner, <xref rid="B62" ref-type="bibr">2014</xref>). The evidence to date supporting the role of working memory in speech perception has been largely correlational. However, working memory may contribute to the ability to use sentence context to guide and constrain interpretation to compensate for increased processing demands when the signal is degraded and interpretation is therefore ambiguous (Rodd et al., <xref rid="B59" ref-type="bibr">2005</xref>, <xref rid="B60" ref-type="bibr">2012</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>). Thus, individuals with greater working memory capacity may be better able to compensate for degraded listening conditions.</p><p>Research linking working memory capacity to speech comprehension has largely relied on the Reading Span test (Daneman and Carpenter, <xref rid="B15" ref-type="bibr">1980</xref>) as a measure of working memory (Tun et al., <xref rid="B78" ref-type="bibr">1991</xref>; Akeroyd, <xref rid="B1" ref-type="bibr">2008</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>; Besser et al., <xref rid="B5" ref-type="bibr">2013</xref>; Zekveld et al., <xref rid="B85" ref-type="bibr">2013</xref>; Davies-Venn and Souza, <xref rid="B16" ref-type="bibr">2014</xref>, but see Humes and Coughlin, <xref rid="B31" ref-type="bibr">2009</xref>; Schoof and Rosen, <xref rid="B67" ref-type="bibr">2014</xref>). The R&#x000f6;nnberg et al. (<xref rid="B61" ref-type="bibr">1989</xref>) version (adapted from Daneman and Carpenter, <xref rid="B15" ref-type="bibr">1980</xref>; Baddeley et al., <xref rid="B4" ref-type="bibr">1985</xref>, but see also Conway et al., <xref rid="B13" ref-type="bibr">2002</xref>; Towse et al., <xref rid="B75" ref-type="bibr">2008</xref> for alternate versions) is most widely used. These five versions differ in a number of ways (see Table <xref ref-type="table" rid="T1">1</xref>). In the canonical Daneman and Carpenter (<xref rid="B15" ref-type="bibr">1980</xref>) version (and similarly in the R&#x000f6;nnberg et al., <xref rid="B61" ref-type="bibr">1989</xref> version), participants read or hear a set of sentences, and are required to make a yes/no semantic judgment after each sentence to prevent rehearsal of items. After each set participants are asked to recall the last word from each sentence in the set in serial order. (See also Lyxell and R&#x000f6;nnberg, <xref rid="B47" ref-type="bibr">1993</xref>, in which subjects are cued whether to recall the first or last word in a set). As the test progresses, the set size increases. Although the Reading Span test is commonly referred to as a test of working memory, it also draws on other cognitive abilities, including processing speed, executive functioning (e.g., selective attention, inhibition, task switching), and reading skill: it is not a &#x0201c;pure test&#x0201d; of working memory. Thus, it is possible that a correlation between working memory and speech in noise (Humes et al., <xref rid="B33" ref-type="bibr">2006</xref>; George et al., <xref rid="B23" ref-type="bibr">2007</xref>; Wingfield and Tun, <xref rid="B81" ref-type="bibr">2007</xref>; Akeroyd, <xref rid="B1" ref-type="bibr">2008</xref>; Rudner et al., <xref rid="B63" ref-type="bibr">2011</xref>; Sorqvist and R&#x000f6;nnberg, <xref rid="B71" ref-type="bibr">2012</xref>; Szenkovits et al., <xref rid="B73" ref-type="bibr">2012</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>; Tamati et al., <xref rid="B74" ref-type="bibr">2013</xref>; Heald and Nusbaum, <xref rid="B27" ref-type="bibr">2014</xref>; Rudner and Lunner, <xref rid="B62" ref-type="bibr">2014</xref>) may, in fact, be due to other cognitive processes.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Description of different versions of the Reading Span test</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th valign="top" align="left" rowspan="1" colspan="1"><bold>Mode of Delivery</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Recall Item</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Judgment Task</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Discontinue Criteria</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Dependent Variable</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Daneman and Carpenter, <xref rid="B15" ref-type="bibr">1980</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Oral or read from card</td><td valign="top" align="left" rowspan="1" colspan="1">Final word in series</td><td valign="top" align="left" rowspan="1" colspan="1">Semantic (yes/no)</td><td valign="top" align="left" rowspan="1" colspan="1">Fail all three items in set</td><td valign="top" align="left" rowspan="1" colspan="1">Span at which items are correctly reported for 2/3 sentences in a set</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Baddeley et al., <xref rid="B4" ref-type="bibr">1985</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Oral</td><td valign="top" align="left" rowspan="1" colspan="1">Subject or object of sentence (as cued)</td><td valign="top" align="left" rowspan="1" colspan="1">Factual (true/false)</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td><td valign="top" align="left" rowspan="1" colspan="1"># of items recalled in correct serial order</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">R&#x000f6;nnberg et al., <xref rid="B61" ref-type="bibr">1989</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Read from computer</td><td valign="top" align="left" rowspan="1" colspan="1">Final word in series</td><td valign="top" align="left" rowspan="1" colspan="1">Semantic (yes/no)</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td><td valign="top" align="left" rowspan="1" colspan="1"># Correct items recalled/maximum score</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Conway et al., <xref rid="B13" ref-type="bibr">2002</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Read from computer</td><td valign="top" align="left" rowspan="1" colspan="1">Unrelated word presented at end of each sentence</td><td valign="top" align="left" rowspan="1" colspan="1">None; must score better than 50% on comprehension post-test</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td><td valign="top" align="left" rowspan="1" colspan="1"># of items recalled in correct serial order, weighted by the number of items within a series (e.g., two points per correct two-item series)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Towse et al., <xref rid="B75" ref-type="bibr">2008</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Read from computer; subjects provide a word to complete sentence</td><td valign="top" align="left" rowspan="1" colspan="1">Completion word provided by subjects (integrated word condition), or unrelated target word provided (independent word condition)</td><td valign="top" align="left" rowspan="1" colspan="1">None</td><td valign="top" align="left" rowspan="1" colspan="1">Fail all three items in set</td><td valign="top" align="left" rowspan="1" colspan="1"># of words correctly recalled</td></tr></tbody></table></table-wrap><p>One way to directly confirm the involvement of working memory processes in speech-in-noise performance is to demonstrate training-related improvement in performance on speech-in-noise tests after increasing working memory capacity through training. A growing body of research has examined the efficacy of working memory training to improve working-memory capacity (for reviews, see Hindin and Zelinski, <xref rid="B29" ref-type="bibr">2012</xref>; Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>; Karr et al., <xref rid="B38" ref-type="bibr">2014</xref>). The efficacy of working memory training, and cognitive training generally has been the subject of debate (e.g., Owen et al., <xref rid="B53" ref-type="bibr">2010</xref>; Shipstead et al., <xref rid="B69" ref-type="bibr">2012b</xref>; Jacoby and Ahissar, <xref rid="B34" ref-type="bibr">2013</xref>; Lampit et al., <xref rid="B45" ref-type="bibr">2014</xref>). However, if effective, working memory training (and cognitive training, in general), holds great promise for mitigating documented age-related declines in processing speed, episodic memory, working memory, and other domains of executive function (e.g., see Craik and Salthouse, <xref rid="B14" ref-type="bibr">2007</xref>).</p><p>We examine whether working-memory training transfers to speech perception in noise in older adults, as well as to other tests of cognitive functioning. We used Cogmed Working Memory Training (Version QM: Pearson; Klingberg et al., <xref rid="B41" ref-type="bibr">2002</xref>), an adaptive, computerized, commercial working memory-training program. We selected Cogmed since several publications have demonstrated its efficacy (Olesen et al., <xref rid="B52" ref-type="bibr">2003</xref>; Klingberg et al., <xref rid="B40" ref-type="bibr">2005</xref>; Holmes et al., <xref rid="B30" ref-type="bibr">2009</xref>; Klingberg, <xref rid="B42" ref-type="bibr">2010</xref>; Brehmer et al., <xref rid="B8" ref-type="bibr">2011</xref>, <xref rid="B7" ref-type="bibr">2012</xref>), and it includes a placebo training condition (an active control group). Improvements due to Cogmed training have been shown to generalize to related working-memory tasks (near transfer), including verbal working memory and visuo-spatial working memory, in both younger (Olesen et al., <xref rid="B52" ref-type="bibr">2003</xref>; Klingberg et al., <xref rid="B40" ref-type="bibr">2005</xref>; Holmes et al., <xref rid="B30" ref-type="bibr">2009</xref>; Klingberg, <xref rid="B42" ref-type="bibr">2010</xref>), and older (Brehmer et al., <xref rid="B8" ref-type="bibr">2011</xref>, <xref rid="B7" ref-type="bibr">2012</xref>) adults. Far transfer to other domains of intellectual functioning (verbal and non-verbal reasoning) has not been shown (Shipstead et al., <xref rid="B68" ref-type="bibr">2012a</xref>). However, in a study of deaf children with cochlear implants, Kronenberger et al. (<xref rid="B43" ref-type="bibr">2011</xref>) observed improved verbal and non-verbal working memory capacity, as well as improved sentence-repetition ability after Cogmed training, providing some evidence of transfer to real-world speech comprehension ability, indicating suitability of the use of Cogmed for our study.</p><p>We tested for transfer to perception of speech in noise with two speech tasks. The first task was a closed-set, five-word sentence matrix test (BUG; Kidd et al., <xref rid="B39" ref-type="bibr">2008</xref>), with two competing talkers (and one target speaker). The second task assessed perception in noise for sentences with and without supporting contextual information. The ability to use supporting contextual information to facilitate comprehension of degraded speech appears to depend on working memory (Janse and Jesse, <xref rid="B35" ref-type="bibr">2014</xref>) and varies markedly among individuals (Rodd et al., <xref rid="B59" ref-type="bibr">2005</xref>, <xref rid="B60" ref-type="bibr">2012</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>). It is not known, however, whether this benefit from context can be improved through working memory training.</p><p>We provided older adults with 5 weeks (25 sessions) of both adaptive and placebo Cogmed (Klingberg et al., <xref rid="B41" ref-type="bibr">2002</xref>) training in a cross-over design, and evaluated cognitive functions at three time points: prior to the start of training (T0), following the first 5 weeks of either adaptive or placebo training (T1), and following the second 5 weeks of training (T2; participants who received adaptive training in T1 received placebo training in T2 and vice versa; see Figure <xref ref-type="fig" rid="F1">1</xref>). Cognitive evaluation included tests of working memory, processing speed, fluency, and short-term memory. We also assessed speech comprehension in noise using the BUG and high-/low-context sentence tasks. Near-transfer was assessed through improvements on other working memory tasks as a function of adaptive training, whereas far-transfer was operationalized as improvements on non-trained cognitive tasks (i.e., those other than tests of working memory, including speech tasks). Note that this design is among the first randomized active control trial for working memory training in older adults that specifically assesses for transfer to speech-in-noise function (see also, Henshaw and Ferguson, <xref rid="B28" ref-type="bibr">2013</xref> for the protocol for a forthcoming trial with hearing-aid users). Importantly, this design allows us to establish a causal link between working memory training and speech in noise function, rather than relying on correlational designs, a limitation of previous research. If working memory contributes to speech in noise perception, then improvements as a result of adaptive working memory training should lead to improved performance on tests of working memory (near-transfer), as well as on tests of speech perception, above and beyond practice effects (far-transfer; see Figure <xref ref-type="fig" rid="F2">2</xref>). In order to investigate the relationship between measures of working memory and other cognitive functions, and the ability to comprehend speech in noise, we examined correlations between cognitive abilities, particularly working memory ability, and speech-in-noise performance.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Study design</bold>. Participants were split into two groups and tested at three time points: at baseline, and following each of two 25-session training blocks. The A&#x02013;P group received adaptive training followed by placebo training, whereas the P&#x02013;A group received the placebo training followed by adaptive training.</p></caption><graphic xlink:href="fnagi-08-00049-g0001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Dissociating training from practice effects</bold>. Our cross-over design allowed us to dissociate training effects from practice effects, within-subjects, by aggregating across the two 5-week blocks of training (T1-T0 and T2-T1). A&#x02013;P refers to the group receiving adaptive training after baseline testing, followed by placebo training, whereas P&#x02013;A refers to placebo training followed by adaptive training. Note that this is a hypothetical outcome.</p></caption><graphic xlink:href="fnagi-08-00049-g0002"/></fig></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec><title>Subjects</title><p>We recruited 26 subjects (13 male, 13 female) between 59 and 73 years of age (mean = 64.96 years, <italic>SD</italic> = 3.77 years) through local newspapers, flyers, and community groups. Subjects generally reported good health and they were screened for hearing loss and mild cognitive impairment (see below) before beginning the study. Informed consent was obtained from all subjects and they were compensated for their time in the laboratory at a rate of $10 per hour. Subjects completing the study also received a $50 gift card for their efforts spent training online. The study was approved by the Queen's University Research Ethics Board.</p></sec><sec><title>Screening procedure</title><p>Before commencing the study, all subjects received an audiogram (at 0.5, 1, 2, and 3 kHz), as well as the Montreal Cognitive Assessment (MoCA; Nasreddine et al., <xref rid="B51" ref-type="bibr">2005</xref>). Subjects with scores of 23 or below on the MoCA were excluded from the study, as scores of 24 and above are indicative of cognitive impairment with over 95% sensitivity and specificity (Luis et al., <xref rid="B46" ref-type="bibr">2009</xref>). We excluded two subjects (not reported here) on this basis. A total of 13 subjects were classified as having normal hearing, defined as thresholds at or below 25 dB HL at the tested frequencies. The 13 remaining subjects had some hearing loss: mild (a loss of &#x0003c; 40 dB in the better ear for at least one of the tested frequencies) in six participants; moderate (&#x0003c;55 dB in the better ear) in four; moderate-severe (&#x0003c;70 dB in the better ear) in two; and severe (&#x0003e;70 dB in the better ear) in one. These individuals were not excluded. The single participant with severe hearing loss wore hearing aids during testing, as did one participant with moderate hearing loss and one with moderate-severe hearing loss. We accounted for this heterogeneity in hearing levels by testing the effects of training in two ways: overall (collapsed across all subjects), as well as by conducting analyses for both groups separately (although this substantially reduces power).</p><p>During this initial screening session, subjects also completed portions of the Speech, Spatial, and Qualities (SSQ) of Hearing scale (Gatehouse and Noble, <xref rid="B21" ref-type="bibr">2004</xref>; the subset of questions related to spatial hearing were not administered), Raven's Progressive Matrices (a measure of non-verbal intelligence), and a demographic questionnaire. Subjects also completed the Burns Anxiety Inventory (Burns, <xref rid="B9" ref-type="bibr">1999</xref>); however, these scores did not correlate with other measures and were not used in subsequent analyses.</p></sec><sec><title>Cognitive training procedure</title><p>Subjects were instructed to train 5 days a week for 10 weeks (i.e., 25 sessions in total for both active and placebo training) using the Cogmed working memory-training program (Klingberg et al., <xref rid="B41" ref-type="bibr">2002</xref>). Twelve different training modules, involving remembering a sequence of numbers, letters, or objects for immediate recall, were used. Some exercises involved active manipulation of information, such as entering numbers in the reverse order that they appeared. Subjects worked on 8 of a possible 12 modules on each day of training; the modules that each subject had to complete on a given day were pre-determined by the online training program and were consistent across subjects. Training sessions took approximately half an hour to an hour per day to complete (with shorter times for placebo training).</p><p>In adaptive training modules, the level of difficulty was adjusted according to subjects' performance by increasing stimulus span length on the subsequent trial (conversely, span length was decreased following unsuccessful trials). In placebo training, only three items were ever presented for recall at a time. Since most individuals can easily recall three items, placebo training was not expected to improve working memory capacity (all subjects scored near 100% on placebo training). All subjects completed five blocked weeks of both adaptive and placebo training; however, the order in which the two different kinds of training (adaptive and placebo) was administered was pseudorandom and counterbalanced across subjects (see Figure <xref ref-type="fig" rid="F1">1</xref>). Two couples participated and in that case both partners were assigned to the same group at the same time, since we wanted to keep participants naive about the other condition they would perform. Subjects were told that they would be completing &#x0201c;brain training,&#x0201d; but no direct information about there being both adaptive and placebo conditions, and which condition they were completing at present, was provided.</p><p>The 25 sessions of each condition were completed on average in 33.88 days (<italic>SD</italic> = 2.86; including non-training days). The average time to completion did not differ significantly between the training groups or training type (placebo vs. adaptive) for subjects who successfully completed training. Progress was monitored remotely every week via the Cogmed Training Web to ensure training sessions were completed. Subjects received a weekly email from the experimenter (RVW; a certified Cogmed coach), who addressed training-related concerns and questions, and offered encouragement to maintain motivation.</p><p>Dependent variables from adaptive Cogmed training included the Start Index (calculated by Cogmed based on span length from training days 2 and 3), the Maximum Index (calculated by Cogmed from the two best days during training), as well as the Index-Improvement score (calculated by Cogmed as the Subtraction of Start Index from the Maximum Index).</p></sec><sec><title>Testing procedure</title><p>The cognitive and speech tests were administered before and after each block of testing in two sessions, separated by a short break. The order of the sessions was identical for each subject across all three time-points, but counterbalanced across subjects. Cognitive testing was completed in a quiet room free of distractions. All auditory tests were conducted in a sound-attenuating booth (Eckel Industries) with headphones (Grado Prestige SR225). Speech stimuli were adjusted to a comfortable listening level based on feedback from subjects (mean = 76.49 dB, <italic>SD</italic> = 6.76). Speech levels for each subject were kept constant across all three time-points<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>. Testing was usually completed in 2.5&#x02013;3.5 h (across two sessions), and at the same time of day, where possible.</p></sec><sec><title>Cognitive test battery</title><p>We administered a broad cognitive test battery in order to assess the generalization of working memory training to multiple domains of cognitive function. Tests of near-transfer included measures of spatial working memory (Spatial Working Memory, CANTAB; Spatial Span Forward and Reverse, CANTAB), and verbal working memory (WAIS-IV Letter-Number Sequencing). Far-transfer tests included assessment of episodic memory (Paired Associate Learning Test, CANTAB), semantic fluency (Category Fluency; Strauss et al., <xref rid="B72" ref-type="bibr">2006</xref>), response inhibition (Stop Signal Task, CANTAB), motor/processing speed (Reaction Time, CANTAB), and sustained visual attention (Rapid Visual Information Processing, CANTAB). We also included a computerized version of the Reading Span test (R&#x000f6;nnberg et al., <xref rid="B61" ref-type="bibr">1989</xref>) and asked subjects to report the last word of every sentence. Tests were chosen on the basis of availability of published norms for older adults, although raw scores were used for the purposes of subsequent analyses. When multiple versions of a test existed (i.e., Paired Associate Learning, Stop Signal Task, Spatial Working Memory fluency), all three versions were counterbalanced across subjects. Please see Table <xref ref-type="table" rid="T2">2</xref> for further description of these tests and the dependent variables derived from them.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Summary of cognitive tests and outcome measures</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Cognitive Test</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Domain Assessed</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Description</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Outcome Measures</bold></th></tr></thead><tbody><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1"><bold>Spatial Working Memory (SWM)</bold><xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Working memory</td><td valign="top" align="left" rowspan="1" colspan="1">Three, four, six, and eight boxes are dispersed on the screen. Subjects search for blue tokens hidden inside one of the boxes. Only one blue token is hidden at a time, without replacement (subjects must remember which boxes have produced a token).</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Between Errors</italic><xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref>&#x02014;The number of times a box in which a token has previously been found is revisited.<break/><italic>Strategy</italic><xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref>&#x02014;The number of times the subject begins a new search with a different box for six- and eight- box trials (note that this denotes an inefficient strategy).</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1"><bold>Spatial Span (SSP) (forward and reverse modes)</bold><xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Working memory</td><td valign="top" align="left" rowspan="1" colspan="1">White squares (boxes) are arranged in a variable sequence on screen. Subjects touch the boxes in the order in which they changed color. The length of the sequence begins at two and increases adaptively up to nine boxes. In reverse mode, subjects touch the boxes in the reverse order that they changed color.</td><td valign="top" align="left" rowspan="1" colspan="1">The longest sequence successfully recalled by the subject, calculated for both the forward and reverse modes.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1"><bold>WAIS-IV Letter-Number Sequencing</bold></td><td valign="top" align="left" rowspan="1" colspan="1">Working memory</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects repeat back a string of letters and numbers in numerical order, followed by alphabetical order. The number of items in a string increases from 2 to 8 letters and digits.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Total Score</italic>&#x02014;Number of items correctly reported, up to a maximum of 30.<break/><italic>Longest</italic>&#x02014;Longest string completed by a subject.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Reading Span</td><td valign="top" align="left" rowspan="1" colspan="1">Working memory (complex test)</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects read aloud a series of unconnected sentences. After each sentence, subjects indicate whether the sentence made sense or not (e.g., &#x0201c;the girl sang a song&#x0201d; vs. &#x0201c;the train sang a song&#x0201d;) to prevent rehearsal of items. At the end of a series, they recall the last word of each sentence. The span of the series begins at 3 and increases to 6.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Number of Correct Responses</italic>&#x02014;This is the sum of correct responses given for whether sentences were absurd or not. This score was used for validity purposes&#x02014;a score of 85% correct or greater was deemed acceptable (which all subjects achieved). This score was not used in subsequent analyses. <italic>Reading Span (Total)</italic>&#x02014;Total number of words correctly recalled.<break/><italic>Longest</italic>&#x02014;The longest series for which a subject was able to recall the last word of every item in the series.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Semantic/Category Fluency</td><td valign="top" align="left" rowspan="1" colspan="1">Category fluency/processing speed</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects name as many animals, fruits, or vegetables as possible within 60 s.</td><td valign="top" align="left" rowspan="1" colspan="1">Total number of correct items named.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Paired Associate Learning Test (PAL)<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Episodic memory</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects are presented with two, three, six, and eight boxes displayed on the screen that open one at a time in a randomized order to reveal a pattern. Respondents must select the box in which each pattern appeared.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Errors Adj.<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></italic>&#x02014;Total number of errors made, adjusting for each stage not attempted due to previous failure (the test discontinues if 10 consecutive errors are made at a stage).<break/><italic>Errors, 8 Shapes, Adj.<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></italic>&#x02014;Total number of errors made at 8 shapes stage, adjusted if this stage is not reached.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (SST)<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Inhibition</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects make a two-choice button response, but withhold their response of a beep is heard on a trial. The timing of the auditory stop signal is set such that the subject is able to stop successfully approximately 50% of the time.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Direction Errors on Stop/Go Trials<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></italic>&#x02014;Number of trials in which the wrong button was pressed (left button when the right arrow was shown on screen and vice versa).<break/><italic>Proportion of Successful Stops (Last Half)</italic>&#x02014;The number of times the subject stopped successfully divided by the total number of stop signals during the last half of sub-blocks. <italic>Median Correct Reaction Time on Go Trials<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></italic>&#x02014;Median reaction time for Go trials (trials without a beep), in milliseconds.<break/><italic>Stop Signal Delay (50%) (last half)<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref>&#x02014;</italic>Stop signal delay at which subject was able to stop 50% of the time.<break/><italic>Stop-Signal Reaction Time&#x02014;</italic>Time taken to respond.</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Reaction Time (RTI)<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Motor/processing speed</td><td valign="top" align="left" rowspan="1" colspan="1">Subjects respond to a yellow dot appearing on the screen. In simple reaction time, the dot appears in a circle in the center of the screen, and in five-choice reaction time, the spot appears in any one of five circles located concentrically to the center of the screen.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>Five-choice Reaction Time<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref>&#x02014;</italic>Speed at which subject releases the press pad button in response to the appearance of the yellow dot during the five-choice reaction time task (speed of cognitive function).<break/><italic>Five-choice Movement Time<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></italic>&#x02014;Time taken to touch the screen after the press pad button has been released during the five-choice reaction time task (speed of motor functions).</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Rapid Visual Information Processing (RVP)<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">Sustained visual attention</td><td valign="top" align="left" rowspan="1" colspan="1">Digits from 2 to 9 appear in a box in the center of the screen in a pseudo-random order, at the rate of 100 digits per minute. Subjects are required to make a button press response to all of three target sequences (2-4-6, 3-5-7, or 4-6-8).</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>A'&#x02014;</italic>A prime is the signal detection measure of sensitivity to the target, accounting for response bias.</td></tr></tbody></table><table-wrap-foot><p>This table lists cognitive tests repeated across the three time points, with a brief description of each test and outcome measures used. Bolded tests assess near-transfer (i.e., working memory ability), whereas the remainder of tests assess far-transfer to other cognitive domains. Tests with</p><fn id="TN1"><label>*</label><p><italic>are taken from the Cambridge Neuropsychological Test Automated battery (CANTAB)</italic>.</p></fn><p>Outcome measures with</p><fn id="TN2"><label>**</label><p><italic>are reverse coded (such that a lower value reflects a higher score)</italic>.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Speech tests</title><sec><title>Sentence-matrix test (BUG)</title><p>Stimuli for this task were taken from Kidd et al. (<xref rid="B39" ref-type="bibr">2008</xref>). The words were recorded with neutral inflection so that all possible combinations of words could be used. Although the corpus consists of both male and female speakers, only eight female voices were used for this experiment. Every sentence had the structure &#x0003c;<italic>name verb number adjective noun</italic>&#x0003e;. Sentences consisted of a string of words composed by taking one word from each of the 5 categories (e.g., &#x0201c;Bob found three green shoes&#x0201d;). Stimuli were created by combining three distinct talkers (including two distractor voices), such that no word was repeated in any category across the three speakers. Subjects were instructed to follow the voice of the talker who said the name &#x0201c;Bob&#x0201d;; one signal with the name &#x0201c;Bob&#x0201d; was present in each trial. Items were mixed at 0 dB SNR. A MATLAB script was used to present the stimuli, at +3 and +6 signal-to-noise ratios (dB SNRs) in four blocks of 25 trials. The first block was provided as practice for subjects and was subsequently removed from analyses. Following each stimulus presentation, subjects were instructed to select each of the target words from a five by eight matrix of options (i.e., eight monosyllabic words from each of five different word-type categories), but the first column was not scored (since the target name was always &#x0201c;Bob&#x0201d;). Dependent variables were percentage of words correctly reported at both +3 and +6 dB SNR.</p><p>The closed set nature of the task ensures that contextual information and the load on working memory is constant across stimuli. This task has the advantage of having excellent psychometric properties (e.g., intelligibility is not confounded by a tendency to guess), and item effects are substantially weaker than for open-set materials, reducing within-subject variability, in principle making any change over time within subjects easier to detect.</p></sec><sec><title>Context sentences</title><p>We assessed the use of context by asking subjects to report words from sentences with and without contextual information, each presented with different sentences produced by two competing (same-sex) talkers. The task comprised of 96 semantically coherent (high-context) sentences, which had supportive contextual information (e.g., &#x0201c;He always read a book before going to bed&#x0201d;), and 96 semantically anomalous (low-context) sentences, which were syntactically correct but nonsensical and were created by replacing the content words of coherent sentences with other words matched in part of speech and word frequency (e.g., &#x0201c;Her good slope was done in carrot&#x0201d;; Davis et al., <xref rid="B17" ref-type="bibr">2011</xref>). Distractor sentences consisted of common, everyday sentences (e.g., &#x0201c;the student tried to move the desk&#x0201d;).</p><p>Sentences were recorded by three individuals who were raised in southern Ontario and had an accent typical for the region (all were female; one individual recorded the target sentences and the other two recorded the distracter sentences). Sentences were divided into three sets of 64 sentences (32 at each level of context), matched across sets for average length. The order of the sentence sets was counterbalanced across participants, so that approximately equal numbers heard each set at each testing time point. Care was taken to avoid repetition of distractor sentences across sets where possible, but target sentences were never repeated (distractor sentences were never repeated within a set).</p><p>Stimulus mixing and presentation was accomplished using MATLAB. Target and distractor sentences were all normalized to have the same RMS power. The two distractor sentences for each trial were first combined and mixed at 0 dB SNR, then this result was normalized with the target and combined with the target at +3 and +6 dB. Subjects were instructed to attend to a target voice, identified as the voice to which they had listened during 10 practice sentences (no distractors were presented during practice). On each trial, subjects were instructed to type all of the words they could understand from the target sentence, in the correct order. Word report was assessed as the proportion of words correctly reported in each sentence. As in Wayne and Johnsrude (<xref rid="B80" ref-type="bibr">2012</xref>) and Davis et al. (<xref rid="B18" ref-type="bibr">2005</xref>), words were scored as correct if the written form perfectly matched the word produced in the sentence. Morphological variants were scored as incorrect, whereas homonyms and misspellings were scored as correct. Words were scored correct if they were reported in the correct order, even if intervening words were absent or incorrectly reported. All subjects correctly reported practice sentences (which included both high- and low-context sentences), indicating that word report is probably not limited by poor memory. Dependent variables were percentage of words correctly reported for both high- and low-context sentences at +3 and +6 dB SNR. Benefit from context was operationally defined as word report for high-context sentences minus word report for low-context sentences, at each SNR.</p></sec></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>Subjects in the two training groups (adaptive then placebo; and placebo then adaptive) did not significantly differ on any of the outcome measures reported in Table <xref ref-type="table" rid="T3">3</xref> at baseline (at T0). Two subjects (one couple) withdrew from the study for health reasons after completing 5 weeks of placebo training and the T1 test session; adaptive training data and T2 test data are unavailable for these subjects. Due to error, one subject completed 7 weeks of adaptive training followed by 3 weeks of placebo training. We included data from this subject, since more training may have increased the likelihood of finding any effect (which we did not observe anyway). Means and standard deviations for all outcome measures are reported in Table <xref ref-type="table" rid="T3">3</xref> (see Figures <xref ref-type="fig" rid="F3">3</xref>, <xref ref-type="fig" rid="F4">4</xref> for accuracy and word-report data for speech tests). We first established the efficacy of Cogmed Working Memory Training by examining evidence of improvement on adaptive training. Training-related changes on the measures from the cognitive and speech-in-noise tests were then assessed using repeated-measures ANOVAs (Jacoby and Ahissar, <xref rid="B34" ref-type="bibr">2013</xref>). Results are reported across all subjects, and for the normally hearing and hearing-impaired groups separately. Finally, we examine the correlations between speech tests and tests of working memory, and between working memory (including Reading Span) and other cognitive domains. Correlations were computed using Spearman's rho (unless otherwise noted) and all corrections were completed using the Benjamini-Hochberg Procedure.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p><bold>Means and standard deviations for all outcome measures</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Adaptive&#x02013;Placebo</bold></th><th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Placebo-Adaptive</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>T0</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>T1</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>T2</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>T0</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>T1</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>T2</bold></th></tr></thead><tbody><tr style="background-color:#bbbdc0"><td valign="top" align="left" colspan="7" rowspan="1"><bold>SCREENING TESTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Montreal Cognitive Assessment</td><td valign="top" align="center" rowspan="1" colspan="1">27.85 (1.77)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">27.15 (1.57)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Raven (Raw Score)</td><td valign="top" align="center" rowspan="1" colspan="1">50.92 (6.51)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">51.27 (6.02)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Speech Spatial Qualities: Speech</td><td valign="top" align="center" rowspan="1" colspan="1">8.21 (0.77)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">6.95 (1.24)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Speech Spatial Qualities: Qualities</td><td valign="top" align="center" rowspan="1" colspan="1">8.79 (0.55)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">8.04 (0.89)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr style="background-color:#bbbdc0"><td valign="top" align="left" colspan="7" rowspan="1"><bold>NEAR-TRANSFER (WORKING MEMORY) TESTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Working Memory (Between Errors)</td><td valign="top" align="center" rowspan="1" colspan="1">23.46 (15.59)</td><td valign="top" align="center" rowspan="1" colspan="1">20.46 (13.35)</td><td valign="top" align="center" rowspan="1" colspan="1">23.31 (13.79)</td><td valign="top" align="center" rowspan="1" colspan="1">22.62 (10.97)</td><td valign="top" align="center" rowspan="1" colspan="1">18.15 (13.67)</td><td valign="top" align="center" rowspan="1" colspan="1">21.82 (11.30)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Working Memory (Strategy)</td><td valign="top" align="center" rowspan="1" colspan="1">30.31 (7.47)</td><td valign="top" align="center" rowspan="1" colspan="1">30.38 (5.94)</td><td valign="top" align="center" rowspan="1" colspan="1">33.00 (5.34)</td><td valign="top" align="center" rowspan="1" colspan="1">32.23 (4.34)</td><td valign="top" align="center" rowspan="1" colspan="1">28.46 (5.17)</td><td valign="top" align="center" rowspan="1" colspan="1">32.27 (4.33)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Span (Forward)</td><td valign="top" align="center" rowspan="1" colspan="1">6.23 (1.17)</td><td valign="top" align="center" rowspan="1" colspan="1">6.85 (1.46)</td><td valign="top" align="center" rowspan="1" colspan="1">6.62 (1.12)</td><td valign="top" align="center" rowspan="1" colspan="1">5.69 (0.95)</td><td valign="top" align="center" rowspan="1" colspan="1">6.38 (1.33)</td><td valign="top" align="center" rowspan="1" colspan="1">6.64 (1.21)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Span (Reverse)</td><td valign="top" align="center" rowspan="1" colspan="1">5.62 (1.39)</td><td valign="top" align="center" rowspan="1" colspan="1">6.54 (1.20)</td><td valign="top" align="center" rowspan="1" colspan="1">6.69 (1.60)</td><td valign="top" align="center" rowspan="1" colspan="1">5.85 (0.90)</td><td valign="top" align="center" rowspan="1" colspan="1">5.70 (1.11)</td><td valign="top" align="center" rowspan="1" colspan="1">6.36 (1.43)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Letter-Number Sequencing (Raw Score)</td><td valign="top" align="center" rowspan="1" colspan="1">20.39 (2.14)</td><td valign="top" align="center" rowspan="1" colspan="1">21.23 (2.49)</td><td valign="top" align="center" rowspan="1" colspan="1">22.46 (2.93)</td><td valign="top" align="center" rowspan="1" colspan="1">20.31 (1.60)</td><td valign="top" align="center" rowspan="1" colspan="1">21.23 (2.49)</td><td valign="top" align="center" rowspan="1" colspan="1">21.00 (1.18)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Letter-Number Sequencing (Longest)</td><td valign="top" align="center" rowspan="1" colspan="1">6.00 (0.91)</td><td valign="top" align="center" rowspan="1" colspan="1">6.15 (1.14)</td><td valign="top" align="center" rowspan="1" colspan="1">6.62 (0.87)</td><td valign="top" align="center" rowspan="1" colspan="1">5.61 (0.87)</td><td valign="top" align="center" rowspan="1" colspan="1">5.85 (0.99)</td><td valign="top" align="center" rowspan="1" colspan="1">5.82 (0.60)</td></tr><tr style="background-color:#bbbdc0"><td valign="top" align="left" colspan="7" rowspan="1"><bold>FAR-TRANSFER TESTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reading Span</td><td valign="top" align="center" rowspan="1" colspan="1">21.15 (3.29)</td><td valign="top" align="center" rowspan="1" colspan="1">24.65 (5.67)</td><td valign="top" align="center" rowspan="1" colspan="1">26.69 (6.28)</td><td valign="top" align="center" rowspan="1" colspan="1">21.84 (5.51)</td><td valign="top" align="center" rowspan="1" colspan="1">24.85 (6.20)</td><td valign="top" align="center" rowspan="1" colspan="1">23.10 (6.17)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reading Span (Longest)</td><td valign="top" align="center" rowspan="1" colspan="1">1.62 (1.56)</td><td valign="top" align="center" rowspan="1" colspan="1">2.77 (1.30)</td><td valign="top" align="center" rowspan="1" colspan="1">2.69 (1.25)</td><td valign="top" align="center" rowspan="1" colspan="1">2.23 (1.59)</td><td valign="top" align="center" rowspan="1" colspan="1">2.69 (1.25)</td><td valign="top" align="center" rowspan="1" colspan="1">2.00 (1.61)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Fluency</td><td valign="top" align="center" rowspan="1" colspan="1">19.31 (3.97)</td><td valign="top" align="center" rowspan="1" colspan="1">22.00 (7.43)</td><td valign="top" align="center" rowspan="1" colspan="1">20.62 (4.27)</td><td valign="top" align="center" rowspan="1" colspan="1">16.54 (4.35)</td><td valign="top" align="center" rowspan="1" colspan="1">18.08 (3.75)</td><td valign="top" align="center" rowspan="1" colspan="1">22.73 (9.69)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Paired Associate Learning (Errors, Adj.)</td><td valign="top" align="center" rowspan="1" colspan="1">18.08 (16.98)</td><td valign="top" align="center" rowspan="1" colspan="1">14.92 (13.47)</td><td valign="top" align="center" rowspan="1" colspan="1">11.77 (8.45)</td><td valign="top" align="center" rowspan="1" colspan="1">16.54 (14.24)</td><td valign="top" align="center" rowspan="1" colspan="1">16.31 (11.24)</td><td valign="top" align="center" rowspan="1" colspan="1">16.18 (12.69)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Paired Associate Learning (Errors, 8 Shapes adj.)</td><td valign="top" align="center" rowspan="1" colspan="1">13.92 (13.09)</td><td valign="top" align="center" rowspan="1" colspan="1">11.15 (11.46)</td><td valign="top" align="center" rowspan="1" colspan="1">9.08 (6.06)</td><td valign="top" align="center" rowspan="1" colspan="1">12.00 (11.63)</td><td valign="top" align="center" rowspan="1" colspan="1">12.15 (10.38)</td><td valign="top" align="center" rowspan="1" colspan="1">10.64 (9.22)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (Direction Errors)</td><td valign="top" align="center" rowspan="1" colspan="1">5.54 (12.35)</td><td valign="top" align="center" rowspan="1" colspan="1">6.69 (10.03)</td><td valign="top" align="center" rowspan="1" colspan="1">5.00 (4.62)</td><td valign="top" align="center" rowspan="1" colspan="1">1.23 (1.96)</td><td valign="top" align="center" rowspan="1" colspan="1">2.54 (4.13)</td><td valign="top" align="center" rowspan="1" colspan="1">1.45 (1.86)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (Prop. Successful Stops)</td><td valign="top" align="center" rowspan="1" colspan="1">0.51 (0.08)</td><td valign="top" align="center" rowspan="1" colspan="1">0.51 (0.09)</td><td valign="top" align="center" rowspan="1" colspan="1">0.52 (0.10)</td><td valign="top" align="center" rowspan="1" colspan="1">0.56 (0.06)</td><td valign="top" align="center" rowspan="1" colspan="1">0.54 (0.99)</td><td valign="top" align="center" rowspan="1" colspan="1">0.55 (0.07)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (Median Correct, Go Trials)</td><td valign="top" align="center" rowspan="1" colspan="1">540.77 (133.89)</td><td valign="top" align="center" rowspan="1" colspan="1">503.85 (151.14)</td><td valign="top" align="center" rowspan="1" colspan="1">489.92 (166.21)</td><td valign="top" align="center" rowspan="1" colspan="1">568.04 (120.45)</td><td valign="top" align="center" rowspan="1" colspan="1">548.88 (124.47)</td><td valign="top" align="center" rowspan="1" colspan="1">537.41 (127.49)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (Stop Signal Delay)</td><td valign="top" align="center" rowspan="1" colspan="1">323.73 (185.57)</td><td valign="top" align="center" rowspan="1" colspan="1">284.24 (167.12)</td><td valign="top" align="center" rowspan="1" colspan="1">292.06 (180.18)</td><td valign="top" align="center" rowspan="1" colspan="1">351.58 (126.39)</td><td valign="top" align="center" rowspan="1" colspan="1">365.86 (150.60)</td><td valign="top" align="center" rowspan="1" colspan="1">372.84 (140.86)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop Signal Task (Reaction Time)</td><td valign="top" align="center" rowspan="1" colspan="1">217.03 (78.00)</td><td valign="top" align="center" rowspan="1" colspan="1">219.61 (58.69)</td><td valign="top" align="center" rowspan="1" colspan="1">197.87 (44.61)</td><td valign="top" align="center" rowspan="1" colspan="1">216.46 (55.57)</td><td valign="top" align="center" rowspan="1" colspan="1">183.02 (44.78)</td><td valign="top" align="center" rowspan="1" colspan="1">164.57 (33.75)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reaction Time (Five-Choice Movement Time)</td><td valign="top" align="center" rowspan="1" colspan="1">381.67 (96.93)</td><td valign="top" align="center" rowspan="1" colspan="1">399.09 (89.58)</td><td valign="top" align="center" rowspan="1" colspan="1">345.79 (99.88)</td><td valign="top" align="center" rowspan="1" colspan="1">462.10 (123.27)</td><td valign="top" align="center" rowspan="1" colspan="1">385.50 (98.41)</td><td valign="top" align="center" rowspan="1" colspan="1">377.20 (89.79)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reaction Time (Five-Choice Reaction Time)</td><td valign="top" align="center" rowspan="1" colspan="1">336.98 (53.97)</td><td valign="top" align="center" rowspan="1" colspan="1">334.08 (53.97)</td><td valign="top" align="center" rowspan="1" colspan="1">311.97 (42.79)</td><td valign="top" align="center" rowspan="1" colspan="1">350.85 (40.14)</td><td valign="top" align="center" rowspan="1" colspan="1">342.64 (45.41)</td><td valign="top" align="center" rowspan="1" colspan="1">309.78 (29.82)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Rapid Visual Processing (A&#x02032;)</td><td valign="top" align="center" rowspan="1" colspan="1">0.92 (0.05)</td><td valign="top" align="center" rowspan="1" colspan="1">0.93 (0.03)</td><td valign="top" align="center" rowspan="1" colspan="1">0.93 (0.04)</td><td valign="top" align="center" rowspan="1" colspan="1">0.92 (0.06)</td><td valign="top" align="center" rowspan="1" colspan="1">0.93 (0.05)</td><td valign="top" align="center" rowspan="1" colspan="1">0.93 (0.06)</td></tr><tr style="background-color:#bbbdc0"><td valign="top" align="left" colspan="7" rowspan="1"><bold>SPEECH TESTS</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">BUG % Accuracy (+3 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">38.07 (11.11)</td><td valign="top" align="center" rowspan="1" colspan="1">35.36 (9.87)</td><td valign="top" align="center" rowspan="1" colspan="1">35.90 (9.58)</td><td valign="top" align="center" rowspan="1" colspan="1">35.47 (11.71)</td><td valign="top" align="center" rowspan="1" colspan="1">36.35 (10.12)</td><td valign="top" align="center" rowspan="1" colspan="1">34.97 (10.09)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">BUG % Accuracy (+6 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">42.87 (10.11)</td><td valign="top" align="center" rowspan="1" colspan="1">41.20 (9.05)</td><td valign="top" align="center" rowspan="1" colspan="1">41.99 (9.24)</td><td valign="top" align="center" rowspan="1" colspan="1">45.59 (9.76)</td><td valign="top" align="center" rowspan="1" colspan="1">44.93 (14.28)</td><td valign="top" align="center" rowspan="1" colspan="1">44.59 (12.72)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Low-Context Sentences (+3 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">42.62 (17.01)</td><td valign="top" align="center" rowspan="1" colspan="1">38.09 (15.41)</td><td valign="top" align="center" rowspan="1" colspan="1">42.39 (13.32)</td><td valign="top" align="center" rowspan="1" colspan="1">37.33 (17.28)</td><td valign="top" align="center" rowspan="1" colspan="1">38.26 (15.48)</td><td valign="top" align="center" rowspan="1" colspan="1">39.61 (13.45)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Low-Context Sentences (+6 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">64.25 (18.56)</td><td valign="top" align="center" rowspan="1" colspan="1">60.25 (15.83)</td><td valign="top" align="center" rowspan="1" colspan="1">66.46 (15.56)</td><td valign="top" align="center" rowspan="1" colspan="1">61.46 (16.46)</td><td valign="top" align="center" rowspan="1" colspan="1">57.56 (21.65)</td><td valign="top" align="center" rowspan="1" colspan="1">59.68 (20.02)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">High-Context Sentences (+3 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">75.24 (11.26)</td><td valign="top" align="center" rowspan="1" colspan="1">65.64 (13.97)</td><td valign="top" align="center" rowspan="1" colspan="1">73.97 (16.71)</td><td valign="top" align="center" rowspan="1" colspan="1">70.16 (18.20)</td><td valign="top" align="center" rowspan="1" colspan="1">65.96 (23.65)</td><td valign="top" align="center" rowspan="1" colspan="1">68.13 (23.34)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">High-Context Sentences (+6 dB SNR)</td><td valign="top" align="center" rowspan="1" colspan="1">87.23 (7.88)</td><td valign="top" align="center" rowspan="1" colspan="1">85.11 (13.09)</td><td valign="top" align="center" rowspan="1" colspan="1">88.90 (6.11)</td><td valign="top" align="center" rowspan="1" colspan="1">82.92 (15.45)</td><td valign="top" align="center" rowspan="1" colspan="1">85.82 (17.36)</td><td valign="top" align="center" rowspan="1" colspan="1">83.33 (15.75)</td></tr></tbody></table><table-wrap-foot><p><italic>Note that reaction times are provided in milliseconds and speech scores are presented as percentage of words correctly reported (context sentences) or selected (BUG)</italic>.</p></table-wrap-foot></table-wrap><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Accuracy scores for the BUG speech task across the three study time points</bold>. Error bars reflect standard error of the mean.</p></caption><graphic xlink:href="fnagi-08-00049-g0003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Percentage word report scores for high- and low-context sentences across the three study time points</bold>. Error bars reflect standard error of the mean.</p></caption><graphic xlink:href="fnagi-08-00049-g0004"/></fig><sec><title>Improvement on cognitive training (Cogmed)</title><p>The average Start Index (performance on days 2 and 3) was 85.38 (<italic>SD</italic> = 9.84, min = 70, max = 105) and the Maximum Index (performance on the two best training days) was 108.75 (<italic>SD</italic> = 13.53, min = 89, max = 142). The Cogmed Index-Improvement score, which compares these two (Maximum vs. Start), was 23.5 (<italic>SD</italic> = 7.95, min = 12, max = 49; the normal range is 18&#x02013;42); this improvement was significant, and all subjects' scores improved over the course of adaptive training. The Index-Improvement score did not appear to depend on whether adaptive training was first or second (i.e., before or after placebo training). Crucially, the Index-Improvement score is comparable to (or larger than) those reported in studies reporting near-transfer (e.g., Gropper et al., <xref rid="B26" ref-type="bibr">2014</xref>), suggesting that training was effective.</p><p>The average Raven's score was in the 67th percentile (minimum = 21st percentile, maximum = 99th percentile). The Raven's score significantly correlated with the Start Index score (<italic>r</italic><sub><italic>s</italic></sub> = 0.64, <italic>p</italic> = 0.001, corrected), but not with the Index-Improvement score or the Maximum Index, indicating that intelligence was related to initial performance on working-memory training, but not to training gains. The average Letter-Number Sequencing (a widely accepted test of verbal working memory) scaled score at the start of the experiment (T0) was 10.68 (<italic>SD</italic> = 1.92; note that 10 is the population mean scaled score, indicating average baseline working memory ability).</p></sec><sec><title>Transfer to cognitive tests</title><p>For cognitive test outcome measures for which normative data were available (this excludes scores for Reading Span, Paired Associate Learning, 8-shapes Adjusted, Spatial Span Reverse, and the Stop Signal Task), the average <italic>Z</italic>-score across tests was 0.67 (<italic>SD</italic> = 0.19). On all tests, on average subjects performed within 1.5 standard deviations of the mean (min = &#x02212;0.72, max = 1.37), indicating that older adults participating in our study consistently performed within acceptable limits.</p><p>We analyzed the data for each cognitive test using repeated-measures ANOVAs, with Training Group (adaptive before placebo or placebo before adaptive) as a between-subjects variable, and Time as a within-subjects variable with three levels. The Group by Time interaction reflects both training and the interaction between order (placebo, then training or training, then placebo) and training (either of which indicate that training has had some effect). The main effect of time reflects both practice, as well as training (see Figure <xref ref-type="fig" rid="F2">2</xref>). The main effect of training group was non-significant for all dependent variables, suggesting that participants in the two groups were drawn from the same population.</p><p>Significant practice effects (evident as a main effect of time with increasing values over time) were obtained on Reading Span, Letter-Number Sequencing score, Stop Signal Task Stop Signal Response Time, Spatial Working Memory Strategy score, Reaction Time Five-choice Movement Time and Five-choice Reaction Time, as well as Spatial Span Forward and Reverse (see Table <xref ref-type="table" rid="T4">4</xref> for statistics). The interaction between Group and Time was non-significant for all measures drawn from all the cognitive tests listed in Table <xref ref-type="table" rid="T3">3</xref>, meaning that pre-post improvement did not differ between placebo and adaptive training, suggesting that the general improvements in performance are practice effects. Analyzing the hearing and hearing-impaired groups separately did not change the pattern of results. These results indicate no evidence for training-related cognitive improvement in older adults.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p><bold><italic><bold>F</bold></italic>-test statistics for main effect of time for all dependent variables, and (uncorrected) <italic><bold>post-hoc</bold></italic> comparisons</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Dependent Variable</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>F</italic><sub>(2, 44)</sub></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>p</italic></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>&#x003b7;<italic><sub><italic>p</italic></sub></italic><sup>2</sup></bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold><italic>Post-hoc</italic> comparisons <sup>*</sup><italic>p</italic> &#x0003c; 0.05; <sup>**</sup><italic>p</italic> &#x0003c; 0.001</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Reading Span Score</td><td valign="top" align="center" rowspan="1" colspan="1">13.26</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.001</td><td valign="top" align="center" rowspan="1" colspan="1">0.38</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>**</sup>, T1 &#x0003e; T0<sup>**</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Letter-Number Sequencing Score</td><td valign="top" align="center" rowspan="1" colspan="1">5.81</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.21</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Stop-Signal Task Stop Signal Reaction Time</td><td valign="top" align="center" rowspan="1" colspan="1">4.46</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.17</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Working Memory Strategy Score</td><td valign="top" align="center" rowspan="1" colspan="1">3.16</td><td valign="top" align="center" rowspan="1" colspan="1">0.052</td><td valign="top" align="center" rowspan="1" colspan="1">0.13</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T1<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reaction Time Five-Choice Movement Time</td><td valign="top" align="center" rowspan="1" colspan="1">6.19</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.22</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Reaction Time Five-Choice Reaction Time</td><td valign="top" align="center" rowspan="1" colspan="1">11.23</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.001</td><td valign="top" align="center" rowspan="1" colspan="1">0.34</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>**</sup>, T2 &#x0003e; T1<sup>**</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Span Forward Score</td><td valign="top" align="center" rowspan="1" colspan="1">3.94</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.15</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Spatial Span Reverse Score</td><td valign="top" align="center" rowspan="1" colspan="1">4.37</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.17</td><td valign="top" align="center" rowspan="1" colspan="1">T2 &#x0003e; T0<sup>*</sup></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">High Context Sentences +3 dB SNR</td><td valign="top" align="center" rowspan="1" colspan="1">8.61</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.001</td><td valign="top" align="center" rowspan="1" colspan="1">0.28</td><td valign="top" align="center" rowspan="1" colspan="1">T0 &#x0003e; T1<sup>*</sup></td></tr></tbody></table></table-wrap><p>We conducted additional exploratory analyses on training-related transfer, using the baseline score and training group (adaptive vs. placebo) as separate predictors in a linear regression. Data were recoded to match a between-subjects design, such that each subject contributed two data points for each of post-training performance and baseline performance, with a dummy variable coding for adaptive vs. placebo training (e.g., For the adaptive-placebo group, T0 was taken as baseline in the adaptive condition, and T1 was baseline for the placebo condition, with T1 as the post-training performance in the adaptive condition, and T2 for the placebo condition). Although this analysis was more sensitive than the repeated-measures ANOVA, we did not find any significant effect of training group, even at an uncorrected level.</p></sec><sec><title>Transfer to speech tests</title><p>Data for speech tests are presented in Figures <xref ref-type="fig" rid="F3">3</xref>, <xref ref-type="fig" rid="F4">4</xref>. As expected, the effect of SNR was significant for all three tasks, with +6 dB SNR being more intelligible than +3 dB SNR (see Table <xref ref-type="table" rid="T3">3</xref>). In addition, significantly more words were reported for high-context sentences (proportion of words reported correctly: <italic>M</italic> = 0.78, <italic>SD</italic> = 0.14, min = 0.34, max = 0.93) than for low-context sentences (<italic>M</italic> = 0.52, <italic>SD</italic> = 0.15, min = 0.17, max = 0.74; <italic>t</italic><sub>(25)</sub> = 16.81, <italic>p</italic> &#x0003c; 0.001; similar to (Davis et al., <xref rid="B17" ref-type="bibr">2011</xref>)). The average proportion of words correctly reported on the BUG at +6 dB SNR was 0.44 (<italic>SD</italic> = 0.10, min = 0.28, max = 0.70) and 0.36 (<italic>SD</italic> = 0.09, min = 0.22, max = 0.56) at +3 dB SNR. These results suggest that performance was not at ceiling or floor for either of the speech tasks. We conducted a repeated-measures ANOVA on BUG performance and on word-report scores for high- and low-context sentences separately, as well as on the context benefit (high-low) score, with training group as a between-subjects factor and time and SNR (+3 dB and +6 dB) as within-subjects factors. Speech scores did not improve as a result of training (far-transfer); the interaction between Group and Time was non-significant for all three tasks. We also analyzed high- and low-context scores together; even with increased power, there was no effect of training group. A lack of training-related transfer to speech tests is unsurprising given the lack of transfer to other cognitive tests. The main effect of Group was non-significant across all three tasks, but there was a main effect of Time for high-context sentences presented at +3 dB SNR [<italic>F</italic><sub>(2, 44)</sub> = 8.61, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<inline-formula><mml:math id="M1"><mml:msubsup><mml:mrow/><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>= 0.28], reflecting practice effects. Conducting analyses separately on hearing and hearing-impaired subjects did not change the overall pattern of results, and, similar to cognitive tests, our exploratory analyses (see previous section for details) did not reveal any significant training-related effects.</p></sec><sec><title>Correlations between speech and cognitive tests</title><p>Since scores on cognitive tests did not depend on training (as demonstrated in a previous section), participants' scores on each test were averaged across all three time points (and across the two SNRs for the BUG and high- and low-context sentence tests) to yield more reliable estimates of performance.</p><p>We computed correlations between average context-benefit scores (difference in word report for high- and low-context sentences) and tests of working memory (see Table <xref ref-type="table" rid="T5">5</xref>). None of the correlations with context benefit survived correction. Although there was a trend toward significance for Reading Span Longest score (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.42), Letter-Number Sequencing score (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.41), and Letter-Number Sequencing Longest score (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.44), the negative direction of these trends was contrary to expectations, as they appeared to be driven by a positive relationship between working memory and intelligibility of low-context sentences specifically. In fact, word report for low-context sentences significantly correlated with Letter-Number Sequencing Average score (<italic>r</italic><sub><italic>s</italic></sub> = 0.58, <italic>p</italic> &#x0003c; 0.05) and Letter-Number Sequencing Longest score (<italic>r</italic><sub><italic>s</italic></sub> = 0.48, <italic>p</italic> &#x0003c; 0.05, both corrected). There was also a trend toward significance for correlations between low-context sentence word report and Reading Span total (<italic>r</italic><sub><italic>s</italic></sub> = 0.45) and Longest scores (<italic>r</italic><sub><italic>s</italic></sub> = 0.39; these did not survive correction for multiple comparisons). There was no relationship between word-report for high-context sentences and tests of working memory, even when examined at only the more difficult +3 dB SNR to minimize ceiling effects, with the exception of a trend in the predicted direction for Spatial Working Memory Errors (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.38; the apparent negative correlation reflects the fact that low values are indicative of better performance). The difference between correlations for low- and high-context sentences was significant for both Letter-Number Sequencing Average score (Steiger's Z-test; <italic>Z</italic> = 2.48, <italic>p</italic> &#x0003c; 0.05) and Letter-Number Sequencing Longest score (<italic>Z</italic> = 2.70, <italic>p</italic> &#x0003c; 0.05).</p><table-wrap id="T5" position="float"><label>Table 5</label><caption><p><bold>Correlations between speech tests and (select) cognitive tests</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>RS</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>RS</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>LNS</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>LNS</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SWM</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SSP</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SSP</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>PAL</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SST</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Raven's</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>BUG</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>H</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>L</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>H-L</bold></th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>L</bold></th><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>L</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Errors</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Fwd</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Rev</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>(8)</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SS</bold></th><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Context</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Context</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Context</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>RS</bold></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>RS L</bold></td><td align="char" char="." rowspan="1" colspan="1">0.81<xref ref-type="table-fn" rid="TN2"><sup>**</sup></xref></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>LNS</bold></td><td align="char" char="." rowspan="1" colspan="1">0.43<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.37</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>LNS L</bold></td><td align="char" char="." rowspan="1" colspan="1">0.36</td><td align="char" char="." rowspan="1" colspan="1">0.33</td><td align="char" char="." rowspan="1" colspan="1">0.90<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>SWM (Errors)</bold></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.16</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.12</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.44<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>SSP Fwd</bold></td><td align="char" char="." rowspan="1" colspan="1">0.31</td><td align="char" char="." rowspan="1" colspan="1">0.28</td><td align="char" char="." rowspan="1" colspan="1">0.46<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.46<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.33</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>SSP Rev</bold></td><td align="char" char="." rowspan="1" colspan="1">0.37</td><td align="char" char="." rowspan="1" colspan="1">0.26</td><td align="char" char="." rowspan="1" colspan="1">0.61<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.51<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.30</td><td align="char" char="." rowspan="1" colspan="1">0.54<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>PAL (8)</bold></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.54<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.36</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.66<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.69<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.32</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.32</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.31</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>SST SS</bold></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.34</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.27</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.21</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.37</td><td align="char" char="." rowspan="1" colspan="1">0.17</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.02</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.03</td><td align="char" char="." rowspan="1" colspan="1">0.28</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Raven's</bold></td><td align="char" char="." rowspan="1" colspan="1">0.27</td><td align="char" char="." rowspan="1" colspan="1">0.14</td><td align="char" char="." rowspan="1" colspan="1">0.46<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.29</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.45<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.23</td><td align="char" char="." rowspan="1" colspan="1">0.61<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.28</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.07</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>BUG</bold></td><td align="char" char="." rowspan="1" colspan="1">0.16</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.01</td><td align="char" char="." rowspan="1" colspan="1">0.18</td><td align="char" char="." rowspan="1" colspan="1">0.09</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.12</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.07</td><td align="char" char="." rowspan="1" colspan="1">0.16</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.12</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.01</td><td align="char" char="." rowspan="1" colspan="1">0.24</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>H Context</bold></td><td align="char" char="." rowspan="1" colspan="1">0.31</td><td align="char" char="." rowspan="1" colspan="1">0.14</td><td align="char" char="." rowspan="1" colspan="1">0.26</td><td align="char" char="." rowspan="1" colspan="1">0.11</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.34</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.23</td><td align="char" char="." rowspan="1" colspan="1">0.06</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.17</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.06</td><td align="char" char="." rowspan="1" colspan="1">0.33</td><td align="char" char="." rowspan="1" colspan="1">0.55<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>L Context</bold></td><td align="char" char="." rowspan="1" colspan="1">0.45<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.39</td><td align="char" char="." rowspan="1" colspan="1">0.58<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.48<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.24</td><td align="char" char="." rowspan="1" colspan="1">0.04</td><td align="char" char="." rowspan="1" colspan="1">0.22</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.42<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.10</td><td align="char" char="." rowspan="1" colspan="1">0.27</td><td align="char" char="." rowspan="1" colspan="1">0.47<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">0.76<xref ref-type="table-fn" rid="TN4"><sup>**</sup></xref></td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>H-L Context</bold></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.20</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.42<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.41<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.44<xref ref-type="table-fn" rid="TN3"><sup>*</sup></xref></td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.13</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.19</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.13</td><td align="char" char="." rowspan="1" colspan="1">0.25</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.06</td><td align="char" char="." rowspan="1" colspan="1">0.04</td><td align="char" char="." rowspan="1" colspan="1">0.11</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.00</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;0.50</td><td rowspan="1" colspan="1"/></tr></tbody></table><table-wrap-foot><p><italic>Note that significance levels displayed here are uncorrected for multiple comparisons. RS (Reading Span), RS L (Reading Span Longest Span), LNS (Letter-Number Sequencing), LNS L (Letter-Number Sequencing, Longest Sequence) SWM (Spatial Working Memory), SSP Fwd (Spatial Span Forward), SSP Rev (Spatial Span Reverse), SST SS (Stop Signal Task, Proportion of Successful Stops), BUG (Sentence-matrix speech in noise task), H Context (High-Context sentence word report scores), L Context (Low-Context sentence word report scores), H-L Context (High &#x02013; low context sentence word report scores)</italic>.</p><fn id="TN3"><label>*</label><p>significant at p &#x0003c; 0.05;</p></fn><fn id="TN4"><label>**</label><p><italic>significant at p &#x0003c; 0.01</italic>.</p></fn></table-wrap-foot></table-wrap><p>This pattern of results suggests that working memory may facilitate intelligibility particularly when contextual information is unavailable, although this may be an artifact of the word-report intelligibility measure we used. Word report is a rather unnatural assessment of speech intelligibility. Listeners generally do not need to repeat back sentences in everyday communication, and it is possible that word report scores for low-context sentences may load more highly on working memory because they are harder to remember than high-context sentences. We evaluated this hypothesis by examining the Pearson correlation between sentence length and word-report scores, for high- and low-context sentences separately. These were then averaged, within-subjects, across test time points. A repeated-measures ANOVA, with high- vs. low-context sentences and time as within-subjects factors, and training group as a between-subjects factor revealed a main effect of level of context [<italic>F</italic><sub>(1, 22)</sub> = 30.17, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.58]: sentence length was significantly more negatively correlated with word report for low- compared to high- context sentences (low-context <italic>M</italic><sub><italic>r</italic></sub> = &#x02212;0.26, <italic>SE</italic> = 0.02; high-context <italic>M</italic><sub><italic>r</italic></sub> = &#x02212;0.08, <italic>SE</italic> = 0.03). The interaction between Context Level and Time trended toward significance (<italic>p</italic> = 0.05, sentence word report for low-context sentences was significantly more negatively correlated with sentence length at all three time points). All other main effects and interactions were non-significant. This result is consistent with low context sentences being more difficult to maintain in memory, and may account for the correlation between low-context sentences and working memory.</p><p>We did not observe any significant correlations between working memory measures and the BUG speech task scores. Interestingly, scores on the speech tasks did not significantly correlate with the Raven's nor with the SSQ Speech or SSQ Qualities measures, although there was a trend for a correlation between SSQ Speech and low-context sentence word-report scores (<italic>r</italic><sub><italic>s</italic></sub> = 0.36).</p></sec><sec><title>Correlations between reading span and cognitive measures</title><p>Correlations between Reading Span score (i.e., the total number of words recalled) and speech-in-noise performance in previous reports have generally been taken as evidence for the involvement of working memory in speech-in-noise performance (Tun et al., <xref rid="B78" ref-type="bibr">1991</xref>; Akeroyd, <xref rid="B1" ref-type="bibr">2008</xref>; Zekveld et al., <xref rid="B84" ref-type="bibr">2012</xref>; Besser et al., <xref rid="B5" ref-type="bibr">2013</xref>; Zekveld et al., <xref rid="B85" ref-type="bibr">2013</xref>; Davies-Venn and Souza, <xref rid="B16" ref-type="bibr">2014</xref>, but see Humes and Coughlin, <xref rid="B31" ref-type="bibr">2009</xref>; Schoof and Rosen, <xref rid="B67" ref-type="bibr">2014</xref>). However, the Reading Span test is a complex test that relies on other cognitive domains, in addition to working memory. We examined the cognitive architecture supporting Reading Span performance by correlating measures on this test with other measures of working memory (Letter-Number Sequencing Average score, Spatial Working Memory score, Spatial Span Forward, and Spatial Span Reverse scores), non-verbal reasoning (Raven's), processing speed (Reaction Time Five-choice Reaction Time), memory (Paired Associate Learning, 8-Shapes Corrected score) and inhibition (Stop Signal Task Proportion of Successful Stops). As seen in Table <xref ref-type="table" rid="T5">5</xref>, the Reading Span score correlated with the Paired-Associate Learning, 8-Shapes Total Errors Adjusted score (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.54, <italic>p</italic> &#x0003c; 0.05, corrected for multiple comparisons). There was a trend toward significance for the correlations between Reading Span score and Letter-Number Sequencing score (<italic>r</italic><sub><italic>s</italic></sub> = 0.43), Spatial Span Reverse (<italic>r</italic><sub><italic>s</italic></sub> = 0.37), as well as Stop Signal Task Proportion of Successful Stops (<italic>r</italic><sub><italic>s</italic></sub> = &#x02212;0.34, <italic>p</italic>&#x0003e;0.05, after correction for multiple comparisons). The lack of significance here is probably due to insufficient power, but the pattern of results indicates, not surprisingly, that the Reading Span Test loaded on tests of working memory, episodic visual memory, and inhibition.</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><sec><title>Generalizability of cognitive training</title><p>As expected, scores on the Cogmed working-memory tests increased over time in the adaptive-training sessions, and both the adaptive and placebo training groups showed practice effects on several test measures. However, we observed no evidence of transfer of working-memory training, even to tests that should tap the same cognitive domains as training (i.e., other working memory tests), and even when uncorrected for multiple comparisons. Ultimately, our results demonstrate no evidence that Cogmed cognitive training improved cognitive functioning as measured by our tests, or improved speech-in-noise comprehension in older adults.</p><p>Our results apparently contradict those documenting near- or far-transfer of working memory training, including Cogmed, to other cognitive domains in both older and younger adults (Olesen et al., <xref rid="B52" ref-type="bibr">2003</xref>; Klingberg et al., <xref rid="B40" ref-type="bibr">2005</xref>; Holmes et al., <xref rid="B30" ref-type="bibr">2009</xref>; Klingberg, <xref rid="B42" ref-type="bibr">2010</xref>; Brehmer et al., <xref rid="B8" ref-type="bibr">2011</xref>, <xref rid="B7" ref-type="bibr">2012</xref>; Kronenberger et al., <xref rid="B43" ref-type="bibr">2011</xref>; Hindin and Zelinski, <xref rid="B29" ref-type="bibr">2012</xref>; Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>; Karbach and Verhaeghen, <xref rid="B37" ref-type="bibr">2014</xref>; Karr et al., <xref rid="B38" ref-type="bibr">2014</xref>). In attempting to reconcile our null results for generalization of cognitive training with significant generalization noted elsewhere, it is important to note that effects of training may be specific to assessment measures used. Others have suggested that even in the absence of direct strategy instruction, cognitive strategies may be task specific (Dunning and Holmes, <xref rid="B19" ref-type="bibr">2014</xref>), reflecting limited generalizability of training gains. Alternatively, Cogmed training may specifically benefit those with below-average working memory ability (Zinke et al., <xref rid="B86" ref-type="bibr">2014</xref>). The vast majority of our subjects had at least average working memory ability (on Letter-Number Sequencing, all subjects had baseline scores at or above the 25th percentile (the low-average range), and our subjects performed on average, half a standard deviation better than the norm on cognitive tests).</p><p>Although a lack of motivation could in principle explain a lack of efficacy, our older participants exhibited acceptable improvement scores on training, commensurate with studies reporting evidence of transfer (Gropper et al., <xref rid="B26" ref-type="bibr">2014</xref>) and they appeared highly motivated. We did not compensate them for training time; only for the time spent in the testing sessions, and we experienced a very low rate of attrition. It is also possible that our study was underpowered. However, our study had more than the mean number of adults assessed in the studies reviewed in the meta-analysis of cognitive training studies in older adults by Karbach and Verhaeghen (<xref rid="B37" ref-type="bibr">2014</xref>; 21.34; <italic>SD</italic> = 13.98); this analysis revealed significant effects for training, although none of the studies used Cogmed (these studies also typically used a between-subjects design, a less powerful design than our within-subjects design).</p><p>Instead, our results are consistent with an emerging body of literature challenging the effectiveness and generalizability of cognitive training, including Cogmed (e.g., Shipstead et al., <xref rid="B68" ref-type="bibr">2012a</xref>,<xref rid="B69" ref-type="bibr">b</xref>; Chacko et al., <xref rid="B12" ref-type="bibr">2013</xref>; Jacoby and Ahissar, <xref rid="B34" ref-type="bibr">2013</xref>; Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>; Gathercole, <xref rid="B22" ref-type="bibr">2014</xref>; Lampit et al., <xref rid="B45" ref-type="bibr">2014</xref>). At present, the reasons for inconsistencies between these studies and those reporting evidence of generalization (e.g., Kronenberger et al., <xref rid="B43" ref-type="bibr">2011</xref>) is unclear. However, a recent meta-analysis and review of cognitive training in 5000 older adults found that home-based training was ineffective compared to group-based training, and that training more than three sessions a week was less effective than training three or fewer times per week, perhaps due to cognitive fatigue (Lampit et al., <xref rid="B45" ref-type="bibr">2014</xref>). Our subjects trained five times per week at home, which may account for our null findings. However, it is also important to note that effect sizes reported in this meta-analysis are small (Hedge's <italic>g</italic> = 0.22).</p><p>Our cross-over, within-subjects design appears to be unique in the literature; to our knowledge our design in which subjects receive <italic>both</italic> placebo and adaptive training (in a counterbalanced manner) has not been used in studies evaluating the efficacy of Cogmed Working Memory Training (Olesen et al., <xref rid="B52" ref-type="bibr">2003</xref>; Klingberg et al., <xref rid="B40" ref-type="bibr">2005</xref>; Holmes et al., <xref rid="B30" ref-type="bibr">2009</xref>; Klingberg, <xref rid="B42" ref-type="bibr">2010</xref>; Brehmer et al., <xref rid="B8" ref-type="bibr">2011</xref>, <xref rid="B7" ref-type="bibr">2012</xref>; Kronenberger et al., <xref rid="B43" ref-type="bibr">2011</xref>; Hindin and Zelinski, <xref rid="B29" ref-type="bibr">2012</xref>; Chacko et al., <xref rid="B12" ref-type="bibr">2013</xref>; Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>; Karr et al., <xref rid="B38" ref-type="bibr">2014</xref>), or any other form of cognitive training in older adults. This design is more rigorous than the traditional between-subjects approach because it controls for motivational/engagement effects resulting from training. More specifically, it is possible that motivation and engagement is higher in the training group, owing to the higher degree of effort necessitated by the training regimen, compared to even an active placebo group (since the task performed by the placebo group is usually easier). Thus, where adaptive and placebo training are not counterbalanced within subjects, the adaptive group may show training gains simply as a result of effort and engagement, rather than cognitive training (see also Jacoby and Ahissar, <xref rid="B34" ref-type="bibr">2013</xref> for a similar argument).</p><p>This view is supported by the apparent absence of significant differences between active (placebo training) and passive (no training) control groups in other studies (see Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>; Karbach and Verhaeghen, <xref rid="B37" ref-type="bibr">2014</xref> for reviews). This finding that placebo training is equivalent to no training at all suggests that the placebo condition in Cogmed is not sufficiently demanding to control for effects related to effort or engagement during training. Thus, it is possible that evidence of transfer of training to cognitive tests in studies comparing adaptive to placebo (or passive training) might reflect gains due to task engagement, rather than the content of the training regimen, suggesting that these gains might be acquired through engagement with non-specific cognitive tasks. Moreover, the relative superiority of group-based (or lab-based) training over at-home training (Lampit et al., <xref rid="B45" ref-type="bibr">2014</xref>) also suggests that task-engagement, or social interaction, may drive cognitive training gains.</p></sec><sec><title>Relationship between working memory and speech in noise</title><p>We observed that working memory measures correlated with the amount of benefit to word-report obtained through provision of greater context, but this relationship is explained by a positive correlation specifically with low-context word-report scores. The cognitive load imposed by low-context (semantically anomalous) sentences (as listeners strive fruitlessly after a coherent meaning) may limit processing resources available for accurate perception of further words in the utterance, reducing word report. The greater the cognitive capacity, the more resources are left over from this futile semantic integration process for accurate perception. Moreover, low-context sentences may place a greater strain on working memory since the lack of meaningful associations among the words in the sentences means that fewer retrieval cues for any given word are available. As word report was higher for high-context sentences compared to low-context sentences, it is also possible that low-context sentences were more effortful (as reflected by greater recruitment of working memory resources) as a result of being more difficult to maintain in memory for immediate report. This explanation is supported by our finding of a significant negative association between sentence length and word report for low-context sentences but not for high-context sentences. It is possible that correlations between working memory and word report for high-context sentences may emerge more strongly in longer streams of perceptual inputs (i.e., longer utterances) due to increased processing demands.</p></sec><sec><title>What does the reading span test measure?</title><p>Our results warrant some caution in using the commonly administered Reading Span test (R&#x000f6;nnberg et al., <xref rid="B61" ref-type="bibr">1989</xref>) as an exclusive test of working memory. The Reading Span test correlated with memory, with a trend for correlation with measures of working memory and inhibition. The pattern of results suggests that Reading Span may load on both working memory and general cognitive functioning, including episodic visual memory. Given the documented contributions of more general cognitive functioning to speech perception (e.g., Wingfield and Tun, <xref rid="B81" ref-type="bibr">2007</xref>; Arlinger et al., <xref rid="B2" ref-type="bibr">2009</xref>; Heald and Nusbaum, <xref rid="B27" ref-type="bibr">2014</xref>), as well as the high correlations between working memory and non-verbal intelligence (e.g., Engle et al., <xref rid="B20" ref-type="bibr">1999</xref>), future research should take care to parcel contributions of working memory from other cognitive processes. This can be achieved by using more domain-specific tests of working memory (e.g., WAIS Letter-Number Sequencing and other simple span tests), as well as using multiple, converging measurements of working memory. It would also be worthwhile to compare the widely-used R&#x000f6;nnberg et al. (<xref rid="B61" ref-type="bibr">1989</xref>) version of the Reading Span test with the Daneman and Carpenter (<xref rid="B15" ref-type="bibr">1980</xref>) version (as well as others) to verify whether they can justifiably be used interchangeably.</p></sec></sec><sec id="s5"><title>Summary and future directions</title><p>Commercial cognitive training software, including Cogmed Working Memory Training (Klingberg et al., <xref rid="B41" ref-type="bibr">2002</xref>), is being aggressively marketed to the general population. Our study adds to the growing body of literature suggesting that cognitive training, a multi-million dollar industry, may not be as effective as initially hoped (e.g., Shipstead et al., <xref rid="B68" ref-type="bibr">2012a</xref>; Melby-Lerv&#x000e5;g and Hulme, <xref rid="B49" ref-type="bibr">2013</xref>). Our study lends further support to the idea that working memory is important in speech comprehension. Although, our results suggest that individuals with better working memory capacity may be better able to compensate for degraded auditory input when contextual information is unavailable, this may be an artifact of our word report measure. Future studies should extend these findings to more naturalistic paradigms, such as through comparing reaction time as a function of cognitive load in dual-task paradigms for high- and low-context sentences. Our study also suggests that exclusive reliance on the Reading Span as a measure of working memory may be problematic, since in our study Reading Span correlated significantly only with a measure of episodic visual memory, but not working memory. Future research should also aim to evaluate the impact of cognitive training on everyday cognitive functioning, also controlling for levels of effort, which are typically not matched in an active, low-level task control group (including the placebo condition of Cogmed). Working memory training, if effective, would be a cornerstone of rehabilitation programs for older adults with communication difficulties, but the evidence suggests that we have not yet found the magic ingredient.</p></sec><sec id="s6"><title>Author contributions</title><p>JJH, IJ, and RW designed the study. Stimulus creation, data collection, and data analysis were conducted by CH, JJ, and RW. RW wrote the manuscript; IJ edited the manuscript and CH and JJH commented on the final version.</p></sec><sec><title>Funding</title><p>This research was funded through an NSERC Discovery Grant and CIHR Operating Grant to IJ.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. The reviewer AB and handling Editor declared their shared affiliation, and the handling Editor states that the process nevertheless met the standards of a fair and objective review.</p></sec></sec></body><back><fn-group><fn id="fn0001"><p><sup>1</sup>For eight participants, the levels were changed due to experimental error at T1 and T2. However, at T2, the average change in levels was identical between the A&#x02013;P and P&#x02013;A groups for both speech tasks. At T1, the change in levels favored the adaptive group; this biased the results in favor of improved speech comprehension performance as a result of cognitive training, which we still did not observe.</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akeroyd</surname><given-names>M. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Are individual differences in speech reception related to individual differences in cognitive ability? A survey of twenty experimental studies with normal and hearing-impaired adults</article-title>. <source>Int. J. Audiol.</source>
<volume>47</volume>(<issue>Suppl. 2</issue>), <fpage>S53</fpage>&#x02013;<lpage>S71</lpage>. <pub-id pub-id-type="doi">10.1080/14992020802301142</pub-id><pub-id pub-id-type="pmid">19012113</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arlinger</surname><given-names>S.</given-names></name><name><surname>Lunner</surname><given-names>T.</given-names></name><name><surname>Lyxell</surname><given-names>B.</given-names></name><name><surname>Pichora-Fuller</surname><given-names>M. K.</given-names></name></person-group> (<year>2009</year>). <article-title>The emergence of cognitive hearing science</article-title>. <source>Scand. J. Psychol.</source>
<volume>50</volume>, <fpage>371</fpage>&#x02013;<lpage>384</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9450.2009.00753.x</pub-id><pub-id pub-id-type="pmid">19778385</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aydelott</surname><given-names>J.</given-names></name><name><surname>Leech</surname><given-names>R.</given-names></name><name><surname>Crinion</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Normal adult aging and the contextual influences affecting speech and meaningful sound perception</article-title>. <source>Trends Amplif.</source>
<volume>14</volume>, <fpage>218</fpage>&#x02013;<lpage>232</lpage>. <pub-id pub-id-type="doi">10.1177/1084713810393751</pub-id><pub-id pub-id-type="pmid">21307006</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A.</given-names></name><name><surname>Logie</surname><given-names>R.</given-names></name><name><surname>Nimmosmith</surname><given-names>I.</given-names></name><name><surname>Brereton</surname><given-names>N.</given-names></name></person-group> (<year>1985</year>). <article-title>Components of fluent reading</article-title>. <source>J. Mem. Lang.</source>
<volume>24</volume>, <fpage>119</fpage>&#x02013;<lpage>131</lpage>. <pub-id pub-id-type="doi">10.1016/0749-596X(85)90019-1</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besser</surname><given-names>J.</given-names></name><name><surname>Koelewijn</surname><given-names>T.</given-names></name><name><surname>Zekveld</surname><given-names>A. A.</given-names></name><name><surname>Kramer</surname><given-names>S. E.</given-names></name><name><surname>Festen</surname><given-names>J. M.</given-names></name></person-group> (<year>2013</year>). <article-title>How linguistic closure and verbal working memory relate to speech recognition in noise&#x02014;a review</article-title>. <source>Trends Amplif.</source>
<volume>17</volume>, <fpage>75</fpage>&#x02013;<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1177/1084713813495459</pub-id><pub-id pub-id-type="pmid">23945955</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Billig</surname><given-names>A. J.</given-names></name><name><surname>Davis</surname><given-names>M. H.</given-names></name><name><surname>Deeks</surname><given-names>J. M.</given-names></name><name><surname>Monstrey</surname><given-names>J.</given-names></name><name><surname>Carlyon</surname><given-names>R. P.</given-names></name></person-group> (<year>2013</year>). <article-title>Lexical influences on auditory streaming</article-title>. <source>Curr Biol.</source>
<volume>23</volume>, <fpage>1585</fpage>&#x02013;<lpage>1589</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2013.06.042</pub-id><pub-id pub-id-type="pmid">23891107</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brehmer</surname><given-names>Y.</given-names></name><name><surname>Westerberg</surname><given-names>H.</given-names></name><name><surname>Backman</surname><given-names>L.</given-names></name></person-group> (<year>2012</year>). <article-title>Working-memory training in younger and older adults: training gains, transfer, and maintenance</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>6</volume>:<issue>63</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2012.00063</pub-id><pub-id pub-id-type="pmid">22470330</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brehmer</surname><given-names>Y.</given-names></name><name><surname>Rieckmann</surname><given-names>A.</given-names></name><name><surname>Bellander</surname><given-names>M.</given-names></name><name><surname>Westerberg</surname><given-names>H.</given-names></name><name><surname>Fischer</surname><given-names>H.</given-names></name><name><surname>Backman</surname><given-names>L.</given-names></name></person-group> (<year>2011</year>). <article-title>Neural correlates of training-related working-memory gains in old age</article-title>. <source>Neuroimage</source>
<volume>58</volume>, <fpage>1110</fpage>&#x02013;<lpage>1120</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.079</pub-id><pub-id pub-id-type="pmid">21757013</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Burns</surname><given-names>D. D.</given-names></name></person-group> (<year>1999</year>). <source>The Feeling Good Handbook.</source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>First Plume Printing</publisher-name>.</mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cacciatore</surname><given-names>F.</given-names></name><name><surname>Napoli</surname><given-names>C.</given-names></name><name><surname>Abete</surname><given-names>P.</given-names></name><name><surname>Marciano</surname><given-names>E.</given-names></name><name><surname>Triassi</surname><given-names>M.</given-names></name><name><surname>Rengo</surname><given-names>F.</given-names></name></person-group> (<year>1999</year>). <article-title>Quality of life determinants and hearing function in an elderly population: osservatorio Geriatrico Campano Study Group</article-title>. <source>Gerontology</source>
<volume>45</volume>, <fpage>323</fpage>&#x02013;<lpage>328</lpage>. <pub-id pub-id-type="doi">10.1159/000022113</pub-id><pub-id pub-id-type="pmid">10559650</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carabellese</surname><given-names>C. M. D.</given-names></name><name><surname>Appollonio</surname><given-names>M. D.</given-names></name><name><surname>Rozzini</surname><given-names>R.</given-names></name><name><surname>Bianchetti</surname><given-names>A.</given-names></name><name><surname>Frisoni</surname><given-names>G. B.</given-names></name><name><surname>Frattola</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>1993</year>). <article-title>Sensory impairment and quality-of-life in a community elderly population</article-title>. <source>J. Am. Geriatr. Soc.</source>
<volume>41</volume>, <fpage>401</fpage>&#x02013;<lpage>407</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.1993.tb06948.x</pub-id><pub-id pub-id-type="pmid">8463527</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chacko</surname><given-names>A.</given-names></name><name><surname>Feirsen</surname><given-names>N.</given-names></name><name><surname>Bedard</surname><given-names>A. C.</given-names></name><name><surname>Marks</surname><given-names>D.</given-names></name><name><surname>Uderman</surname><given-names>J. Z.</given-names></name><name><surname>Chimiklis</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>). <article-title>Cogmed working memory training for youth with ADHD: a closer examinaton of efficacy utilizing evidence-based criteria</article-title>. <source>J. Clin. Child Adolesc. Psychol.</source>
<volume>42</volume>, <fpage>769</fpage>&#x02013;<lpage>783</lpage>. <pub-id pub-id-type="doi">10.1080/15374416.2013.787622</pub-id><pub-id pub-id-type="pmid">23668397</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>R. A.</given-names></name><name><surname>Cowan</surname><given-names>N.</given-names></name><name><surname>Bunting</surname><given-names>M. F.</given-names></name><name><surname>Therriault</surname><given-names>D. J.</given-names></name><name><surname>Minkoff</surname><given-names>S. R. B.</given-names></name></person-group> (<year>2002</year>). <article-title>A latent variable analysis of working memory capacity, processing speed, and general fluid intelligence</article-title>. <source>Intelligence</source>
<volume>30</volume>, <fpage>163</fpage>&#x02013;<lpage>183</lpage>. <pub-id pub-id-type="doi">10.1016/S0160-2896(01)00096-4</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Craik</surname><given-names>F.</given-names></name><name><surname>Salthouse</surname><given-names>T. A.</given-names></name></person-group> (<year>2007</year>). <source>Handbook of Aging and Cognition, 3rd Edn</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Psychology Press</publisher-name>.</mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daneman</surname><given-names>M.</given-names></name><name><surname>Carpenter</surname><given-names>P. A.</given-names></name></person-group> (<year>1980</year>). <article-title>Individual-differences in working memory and reading</article-title>. <source>J. Verbal Learning Verbal Behav.</source>
<volume>19</volume>, <fpage>450</fpage>&#x02013;<lpage>466</lpage>. <pub-id pub-id-type="doi">10.1016/S0022-5371(80)90312-6</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies-Venn</surname><given-names>E.</given-names></name><name><surname>Souza</surname><given-names>P.</given-names></name></person-group> (<year>2014</year>). <article-title>The role of audibility, spectral resolution and cognition in explaining variance in susceptibility to temporal envelope distortion for listeners with mild to moderate and moderate-to-severe hearing loss</article-title>. <source>J. Am. Acad. Audiol.</source>
<volume>25</volume>, <fpage>1</fpage>&#x02013;<lpage>13</lpage>. <pub-id pub-id-type="doi">10.3766/jaaa.25.6.9</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M. H.</given-names></name><name><surname>Ford</surname><given-names>M. A.</given-names></name><name><surname>Kherif</surname><given-names>F.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Does semantic context benefit speech understanding through top-down processes? Evidence from time-resolved sparse fMRI</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>23</volume>, <fpage>3914</fpage>&#x02013;<lpage>3932</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00084</pub-id><pub-id pub-id-type="pmid">21745006</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M. H.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name><name><surname>Hervais-Adelman</surname><given-names>A.</given-names></name><name><surname>Taylor</surname><given-names>K.</given-names></name><name><surname>McGettigan</surname><given-names>C.</given-names></name></person-group> (<year>2005</year>). <article-title>Lexical information drives perceptual learning of distorted speech: evidence from the comprehension of noise-vocoded sentences</article-title>. <source>J. Exp. Psychol.</source>
<volume>134</volume>, <fpage>222</fpage>&#x02013;<lpage>241</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.134.2.222</pub-id><pub-id pub-id-type="pmid">15869347</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunning</surname><given-names>D. L.</given-names></name><name><surname>Holmes</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Does working memory training promote the use of strategies on untrained working memory tasks?</article-title>
<source>Mem. Cognit.</source>
<volume>42</volume>, <fpage>854</fpage>&#x02013;<lpage>862</lpage>. <pub-id pub-id-type="doi">10.3758/s13421-014-0410-5</pub-id><pub-id pub-id-type="pmid">24748348</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engle</surname><given-names>R. W.</given-names></name><name><surname>Tuholski</surname><given-names>S. W.</given-names></name><name><surname>Laughlin</surname><given-names>J. E.</given-names></name><name><surname>Conway</surname><given-names>A. R. A.</given-names></name></person-group> (<year>1999</year>). <article-title>Working memory, short-term memory, and general fluid intelligence: a latent-variable approach</article-title>. <source>J. Exp. Psychol.</source>
<volume>128</volume>, <fpage>309</fpage>&#x02013;<lpage>331</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.128.3.309</pub-id><pub-id pub-id-type="pmid">10513398</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S.</given-names></name><name><surname>Noble</surname><given-names>W.</given-names></name></person-group> (<year>2004</year>). <article-title>The speech, spatial, and qualities of hearing scale (SSQ)</article-title>. <source>Int. J. Audiol.</source>
<volume>43</volume>, <fpage>85</fpage>&#x02013;<lpage>99</lpage>. <pub-id pub-id-type="doi">10.1080/14992020400050014</pub-id><pub-id pub-id-type="pmid">15035561</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gathercole</surname><given-names>S. E.</given-names></name></person-group> (<year>2014</year>). <article-title>Commentary: Working memory training and ADHD: where does it potential lie? Reflections on Chacko et al., (2014)</article-title>. <source>J. Child Psychol. Psychiatry</source>
<volume>55</volume>, <fpage>256</fpage>&#x02013;<lpage>257</lpage>. <pub-id pub-id-type="doi">10.1111/jcpp.12196</pub-id><pub-id pub-id-type="pmid">24438534</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>E. L.</given-names></name><name><surname>Zekveld</surname><given-names>A. A.</given-names></name><name><surname>Kramer</surname><given-names>S. E.</given-names></name><name><surname>Goverts</surname><given-names>S. T.</given-names></name><name><surname>Festen</surname><given-names>J. M.</given-names></name><name><surname>Houtgast</surname><given-names>T.</given-names></name></person-group> (<year>2007</year>). <article-title>Auditory and nonauditory factors affecting speech reception in noise by older listeners</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>121</volume>, <fpage>2362</fpage>&#x02013;<lpage>2375</lpage>. <pub-id pub-id-type="doi">10.1121/1.2642072</pub-id><pub-id pub-id-type="pmid">17471748</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon-Salant</surname><given-names>S.</given-names></name><name><surname>Fitzgibbons</surname><given-names>P. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Sources of age-related recognition difficulty for time-compressed speech</article-title>. <source>J. Speech Lang. Hear. Res.</source>
<volume>44</volume>
<fpage>709</fpage>&#x02013;<lpage>719</lpage>. <pub-id pub-id-type="doi">10.1044/1092-4388(2001/056)</pub-id><pub-id pub-id-type="pmid">11521766</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gordon-Salant</surname><given-names>S.</given-names></name><name><surname>Frisina</surname><given-names>R. D.</given-names></name><name><surname>Popper</surname><given-names>A. N.</given-names></name><name><surname>Fay</surname><given-names>R. R.</given-names></name></person-group> (<year>2010</year>). <source>The Aging Auditory System: Perceptual Characterization and Neural Bases of Presbycusis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>.</mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gropper</surname><given-names>R. J.</given-names></name><name><surname>Gotlieb</surname><given-names>H.</given-names></name><name><surname>Kronitz</surname><given-names>R.</given-names></name><name><surname>Tannock</surname><given-names>R.</given-names></name></person-group> (<year>2014</year>). <article-title>Working memory training in colleage students with ADHD or LD</article-title>. <source>J. Atten. Disord.</source>
<volume>18</volume>, <fpage>331</fpage>&#x02013;<lpage>345</lpage>. <pub-id pub-id-type="doi">10.1177/1087054713516490</pub-id><pub-id pub-id-type="pmid">24420765</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heald</surname><given-names>S. L. M.</given-names></name><name><surname>Nusbaum</surname><given-names>H. C.</given-names></name></person-group> (<year>2014</year>). <article-title>Speech perception as an active cognitive process</article-title>. <source>Front. Syst. Neurosci.</source>
<volume>8</volume>:<issue>35</issue>. <pub-id pub-id-type="doi">10.3389/fnsys.2014.00035</pub-id><pub-id pub-id-type="pmid">24672438</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henshaw</surname><given-names>H.</given-names></name><name><surname>Ferguson</surname><given-names>M. A.</given-names></name></person-group> (<year>2013</year>). <article-title>Working memory training for adult hearing aid users: study protocol for a double-blind randomized active controlled trial</article-title>. <source>Trials</source>
<volume>14</volume>:<fpage>417</fpage>. <pub-id pub-id-type="doi">10.1186/1745-6215-14-417</pub-id><pub-id pub-id-type="pmid">24304745</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindin</surname><given-names>S. B.</given-names></name><name><surname>Zelinski</surname><given-names>E. M.</given-names></name></person-group> (<year>2012</year>). <article-title>Extended practice and aerobic exercise interventions benefit untrained cognitive outcomes in older adults: a meta-analysis</article-title>. <source>J. Am. Geriatr. Soc.</source>
<volume>60</volume>, <fpage>136</fpage>&#x02013;<lpage>141</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.2011.03761.x</pub-id><pub-id pub-id-type="pmid">22150209</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>J.</given-names></name><name><surname>Gathercole</surname><given-names>S. E.</given-names></name><name><surname>Dunning</surname><given-names>D. L.</given-names></name></person-group> (<year>2009</year>). <article-title>Adaptive training leads to sustained enhancement of poor working memory in children</article-title>. <source>Dev. Sci.</source>
<volume>12</volume>, <fpage>F9</fpage>&#x02013;<lpage>F15</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-7687.2009.00848.x</pub-id><pub-id pub-id-type="pmid">19635074</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humes</surname><given-names>L. E.</given-names></name><name><surname>Coughlin</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Aided speech-identification performance in single-talker competition by older adults with impaired hearing</article-title>. <source>Scand. J. Psychol.</source>
<volume>50</volume>, <fpage>485</fpage>&#x02013;<lpage>494</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9450.2009.00740.x</pub-id><pub-id pub-id-type="pmid">19778396</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Humes</surname><given-names>L. E.</given-names></name><name><surname>Dubno</surname><given-names>J. R.</given-names></name></person-group> (<year>2010</year>). <article-title>Factors affecting speech understanding in older adults</article-title>, in <source>The Aging Auditory System: Perceptual Characterization and Neural Bases of Presbycusis</source>, eds <person-group person-group-type="editor"><name><surname>Gordon-Salant</surname><given-names>S.</given-names></name><name><surname>Frisina</surname><given-names>R. D.</given-names></name><name><surname>Popper</surname><given-names>A. N.</given-names></name><name><surname>Fay</surname><given-names>R. R.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>), <fpage>211</fpage>&#x02013;<lpage>258</lpage>.</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Humes</surname><given-names>L. E.</given-names></name><name><surname>Lee</surname><given-names>J. H.</given-names></name><name><surname>Coughlin</surname><given-names>M. P.</given-names></name></person-group> (<year>2006</year>). <article-title>Auditory measures of selective and divided attention in young and older adults using single-talker competition</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>120</volume>, <fpage>2926</fpage>&#x02013;<lpage>2293</lpage>. <pub-id pub-id-type="doi">10.1121/1.2354070</pub-id><pub-id pub-id-type="pmid">17139749</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacoby</surname><given-names>N.</given-names></name><name><surname>Ahissar</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Chapter 5- What does it take to show that a cognitive training procedure is useful?: a critical evaluation</article-title>. <source>Progr. Brain Res.</source>
<volume>207</volume>, <fpage>121</fpage>&#x02013;<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1016/B978-0-444-63327-9.00004-7</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janse</surname><given-names>E.</given-names></name><name><surname>Jesse</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Working memory affects older adults' use of context in spoken word recognition</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>67</volume>, <fpage>1842</fpage>&#x02013;<lpage>1862</lpage>. <pub-id pub-id-type="doi">10.1080/17470218.2013.879391</pub-id><pub-id pub-id-type="pmid">24443921</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kane</surname><given-names>M. J.</given-names></name><name><surname>Engle</surname><given-names>R. W.</given-names></name></person-group> (<year>2000</year>). <article-title>Working-memory capacity, proactive interference, and divided attention: limits on long-term memory retrieval</article-title>. <source>J. Exp. Psychol.</source>
<volume>26</volume>, <fpage>336</fpage>&#x02013;<lpage>358</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.26.2.336</pub-id><pub-id pub-id-type="pmid">10764100</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karbach</surname><given-names>J.</given-names></name><name><surname>Verhaeghen</surname><given-names>P.</given-names></name></person-group> (<year>2014</year>). <article-title>Making working memory work: a meta-analysis of executive-control and working memory training in older adults</article-title>. <source>Psychol. Sci.</source>
<volume>25</volume>, <fpage>2027</fpage>&#x02013;<lpage>2037</lpage>. <pub-id pub-id-type="doi">10.1177/0956797614548725</pub-id><pub-id pub-id-type="pmid">25298292</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karr</surname><given-names>J. E.</given-names></name><name><surname>Areshenkoff</surname><given-names>C. N.</given-names></name><name><surname>Garcia-Barrera</surname><given-names>M. A.</given-names></name></person-group> (<year>2014</year>). <article-title>An empirical comparison of the therapeutic benefits of physical exercise and cognitive training on the executive functions of older adults: a meta-analysis of controlled trials</article-title>. <source>Neuropsychology</source>
<volume>28</volume>, <fpage>829</fpage>&#x02013;<lpage>845</lpage>. <pub-id pub-id-type="doi">10.1037/neu0000101</pub-id><pub-id pub-id-type="pmid">24933486</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kidd</surname><given-names>G.</given-names><suffix>Jr.</suffix></name><name><surname>Best</surname><given-names>V.</given-names></name><name><surname>Mason</surname><given-names>C. R.</given-names></name></person-group> (<year>2008</year>). <article-title>Listening to every other word: examining the strength of linkage variables in forming streams of speech</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>124</volume>, <fpage>3793</fpage>&#x02013;<lpage>3802</lpage>. <pub-id pub-id-type="doi">10.1121/1.2998980</pub-id><pub-id pub-id-type="pmid">19206805</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klingberg</surname><given-names>T.</given-names></name><name><surname>Fernell</surname><given-names>E.</given-names></name><name><surname>Olesen</surname><given-names>P. J.</given-names></name><name><surname>Johnson</surname><given-names>M.</given-names></name><name><surname>Gustafsson</surname><given-names>P.</given-names></name><name><surname>Dahlstrom</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>Computerized training of working memory in children with ADHD - A randomized, controlled trial</article-title>. <source>J. Am. Acad. Child Adolesc. Psychiatry</source>
<volume>44</volume>, <fpage>177</fpage>&#x02013;<lpage>186</lpage>. <pub-id pub-id-type="doi">10.1097/00004583-200502000-00010</pub-id><pub-id pub-id-type="pmid">15689731</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klingberg</surname><given-names>T.</given-names></name><name><surname>Forssberg</surname><given-names>H.</given-names></name><name><surname>Westerberg</surname><given-names>H.</given-names></name></person-group> (<year>2002</year>). <article-title>Training of working memory in children with ADHD</article-title>. <source>J. Clin. Exp. Neuropsychol.</source>
<volume>26</volume>, <fpage>781</fpage>&#x02013;<lpage>791</lpage>. <pub-id pub-id-type="doi">10.1076/jcen.24.6.781.8395</pub-id><pub-id pub-id-type="pmid">12424652</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klingberg</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Training and plasticity of working memory</article-title>. <source>Trends Cogn. Sci.</source>
<volume>14</volume>, <fpage>317</fpage>&#x02013;<lpage>324</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2010.05.002</pub-id><pub-id pub-id-type="pmid">20630350</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kronenberger</surname><given-names>W. G.</given-names></name><name><surname>Pisoni</surname><given-names>D. B.</given-names></name><name><surname>Henning</surname><given-names>S. C.</given-names></name><name><surname>Colson</surname><given-names>B. G.</given-names></name><name><surname>Hazzard</surname><given-names>L. M.</given-names></name></person-group> (<year>2011</year>). <article-title>Working memory training for children with cochlear implants: a pilot study</article-title>. <source>J. Speech Lang. Hear. Res.</source>
<volume>54</volume>, <fpage>1182</fpage>&#x02013;<lpage>1196</lpage>. <pub-id pub-id-type="doi">10.1044/1092-4388(2010/10-0119)</pub-id><pub-id pub-id-type="pmid">21173394</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kujawa</surname><given-names>S. G.</given-names></name><name><surname>Liberman</surname><given-names>M. C.</given-names></name></person-group> (<year>2009</year>). <article-title>Adding insult to injury: cochlear nerve degeneration after &#x0201c;temporary&#x0201d; noise-induced hearing loss</article-title>. <source>J. Neurosci.</source>
<volume>29</volume>, <fpage>14077</fpage>&#x02013;<lpage>14085</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2845-09.2009</pub-id><pub-id pub-id-type="pmid">19906956</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lampit</surname><given-names>A.</given-names></name><name><surname>Hallock</surname><given-names>H.</given-names></name><name><surname>Valenzuela</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>Computerized cognitive training in cognitively healthy older adults: a systematic review and meta-analysis of effect-modifiers</article-title>. <source>PLoS ONE</source>
<volume>11</volume>:<fpage>e1001756</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pmed.1001756</pub-id><pub-id pub-id-type="pmid">25405755</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luis</surname><given-names>C. A.</given-names></name><name><surname>Keegan</surname><given-names>A. P.</given-names></name><name><surname>Mullan</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Cross validation of the Montreal Cognitive Assessment in community dwelling older adults residing in the Southeastern US</article-title>. <source>Int. J. Geriatr. Psychiatry</source>
<volume>24</volume>, <fpage>197</fpage>&#x02013;<lpage>201</lpage>. <pub-id pub-id-type="doi">10.1002/gps.2101</pub-id><pub-id pub-id-type="pmid">18850670</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lyxell</surname><given-names>B.</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name></person-group> (<year>1993</year>). <article-title>The effects of background noise and working memory capacity on speechreading performance</article-title>. <source>Scand. J. Audiol.</source>
<volume>22</volume>, <fpage>67</fpage>&#x02013;<lpage>70</lpage>. <pub-id pub-id-type="doi">10.3109/01050399309046021</pub-id><pub-id pub-id-type="pmid">8322000</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormack</surname><given-names>A.</given-names></name><name><surname>Fortnum</surname><given-names>H.</given-names></name></person-group> (<year>2013</year>). <article-title>Why do people fitted with hearing aids not wear them?</article-title>
<source>Int. J. Audiol.</source>
<volume>52</volume>, <fpage>360</fpage>&#x02013;<lpage>368</lpage>. <pub-id pub-id-type="doi">10.3109/14992027.2013.769066</pub-id><pub-id pub-id-type="pmid">23473329</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Melby-Lerv&#x000e5;g</surname><given-names>M.</given-names></name><name><surname>Hulme</surname><given-names>C.</given-names></name></person-group> (<year>2013</year>). <article-title>Is working memory training effective? A meta-analytic review</article-title>. <source>Dev. Psychol.</source>
<volume>49</volume>, <fpage>270</fpage>&#x02013;<lpage>291</lpage>. <pub-id pub-id-type="doi">10.1037/a0028228</pub-id><pub-id pub-id-type="pmid">22612437</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulrow</surname><given-names>C. D.</given-names></name><name><surname>Aguilar</surname><given-names>C.</given-names></name><name><surname>Endicott</surname><given-names>J. E.</given-names></name><name><surname>Velez</surname><given-names>R.</given-names></name><name><surname>Tuley</surname><given-names>M. R.</given-names></name><name><surname>Charlip</surname><given-names>W. S.</given-names></name><etal/></person-group>. (<year>1990</year>). <article-title>Association between hearing impairment and the quality of life of elderly individuals</article-title>. <source>J. Am. Geriatr. Soc.</source>
<volume>38</volume>, <fpage>45</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.1990.tb01595.x</pub-id><pub-id pub-id-type="pmid">2295767</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nasreddine</surname><given-names>Z. S.</given-names></name><name><surname>Phillips</surname><given-names>N. A.</given-names></name><name><surname>B&#x000e9;dirian</surname><given-names>V.</given-names></name><name><surname>Charbonneau</surname><given-names>S.</given-names></name><name><surname>Whitehead</surname><given-names>V.</given-names></name><name><surname>Collin</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>The Montreal Cognitive Assessment, MoCA: a Brief screening tool for mild cognitive impairment</article-title>. <source>J. Am. Geriatr. Soc.</source>
<volume>53</volume>, <fpage>695</fpage>&#x02013;<lpage>699</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.2005.53221.x</pub-id><pub-id pub-id-type="pmid">15817019</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olesen</surname><given-names>P. J.</given-names></name><name><surname>Westerberg</surname><given-names>H.</given-names></name><name><surname>Klingberg</surname><given-names>T.</given-names></name></person-group> (<year>2003</year>). <article-title>Increased prefrontal and parietal activity after training of working memory</article-title>. <source>Nat. Neurosci.</source>
<volume>7</volume>, <fpage>75</fpage>&#x02013;<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1038/nn1165</pub-id><pub-id pub-id-type="pmid">14699419</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owen</surname><given-names>A. M.</given-names></name><name><surname>Hampshire</surname><given-names>A.</given-names></name><name><surname>Grahn</surname><given-names>J. A.</given-names></name><name><surname>Stenton</surname><given-names>R.</given-names></name><name><surname>Dajani</surname><given-names>S.</given-names></name><name><surname>Alistair</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Putting brain training to the test</article-title>. <source>Nature</source>
<volume>465</volume>, <fpage>775</fpage>&#x02013;<lpage>778</lpage>. <pub-id pub-id-type="doi">10.1038/nature09042</pub-id><pub-id pub-id-type="pmid">20407435</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez</surname><given-names>E.</given-names></name><name><surname>McCormack</surname><given-names>A.</given-names></name><name><surname>Edmonds</surname><given-names>B. A.</given-names></name></person-group> (<year>2014</year>). <article-title>Sensitivity to temporal fine structure and heaing-aid outcomes in older adults</article-title>. <source>Front. Neurosci.</source>
<volume>8</volume>:<issue>7</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2014.00007</pub-id><pub-id pub-id-type="pmid">24550769</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pichora-Fuller</surname><given-names>M. K.</given-names></name><name><surname>Souza</surname><given-names>P. E.</given-names></name></person-group> (<year>2003</year>). <article-title>Effects of aging on auditory processing of speech</article-title>. <source>Int. J. Audiol.</source>
<volume>42</volume>, <fpage>11</fpage>&#x02013;<lpage>16</lpage>. <pub-id pub-id-type="doi">10.3109/14992020309074638</pub-id><pub-id pub-id-type="pmid">12918623</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plack</surname><given-names>C. J.</given-names></name><name><surname>Barker</surname><given-names>D.</given-names></name><name><surname>Prendergast</surname><given-names>G.</given-names></name></person-group> (<year>2014</year>). <article-title>Perceptual consequences of &#x0201c;hidden&#x0201d; hearing loss</article-title>. <source>Trends Hear.</source>
<volume>18</volume>, <fpage>1</fpage>&#x02013;<lpage>11</lpage>
<pub-id pub-id-type="doi">10.1177/2331216514550621</pub-id><pub-id pub-id-type="pmid">25204468</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plomp</surname><given-names>R.</given-names></name><name><surname>Mimpen</surname><given-names>A. M.</given-names></name></person-group> (<year>1979</year>). <article-title>Speech-reception threshold for sentences as a function of age and noise level</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>66</volume>, <fpage>1333</fpage>&#x02013;<lpage>1342</lpage>. <pub-id pub-id-type="doi">10.1121/1.383554</pub-id><pub-id pub-id-type="pmid">500971</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pronk</surname><given-names>M.</given-names></name><name><surname>Deeg</surname><given-names>J. H. D.</given-names></name><name><surname>Festen</surname><given-names>J. M.</given-names></name><name><surname>Twisk</surname><given-names>J. W.</given-names></name><name><surname>Smits</surname><given-names>C.</given-names></name><name><surname>Comijs</surname><given-names>H. C.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Decline in older persons' ability to recognize speech in noise: the influence of demographic, health-related, environmental, and cognitive factors</article-title>. <source>Ear Hear.</source>
<volume>34</volume>, <fpage>722</fpage>&#x02013;<lpage>732</lpage>. <pub-id pub-id-type="doi">10.1097/AUD.0b013e3182994eee</pub-id><pub-id pub-id-type="pmid">24165301</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodd</surname><given-names>J. M.</given-names></name><name><surname>Davis</surname><given-names>M. H.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name></person-group> (<year>2005</year>). <article-title>The neural mechanisms of speech comprehension: fMRI studies of semantic ambiguity</article-title>. <source>Cereb. Cortex</source>
<volume>15</volume>, <fpage>1261</fpage>&#x02013;<lpage>1269</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhi009</pub-id><pub-id pub-id-type="pmid">15635062</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodd</surname><given-names>J. M.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name><name><surname>Davis</surname><given-names>M. H.</given-names></name></person-group> (<year>2012</year>). <article-title>Dissociating frontotemporal contributions to semantic ambiguity resolution in spoken sentences</article-title>. <source>Cereb. Cortex</source>
<volume>22</volume>, <fpage>1761</fpage>&#x02013;<lpage>1773</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr252</pub-id><pub-id pub-id-type="pmid">21968566</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name><name><surname>Arlinger</surname><given-names>S.</given-names></name><name><surname>Lyxell</surname><given-names>B.</given-names></name><name><surname>Kinnefors</surname><given-names>C.</given-names></name></person-group> (<year>1989</year>). <article-title>Visual evoked potentials: relations to adult speechreading and cognitive function</article-title>. <source>J. Speech Hear. Res.</source>
<volume>32</volume>, <fpage>725</fpage>&#x02013;<lpage>735</lpage>. <pub-id pub-id-type="doi">10.1044/jshr.3204.725</pub-id><pub-id pub-id-type="pmid">2601304</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudner</surname><given-names>M.</given-names></name><name><surname>Lunner</surname><given-names>T.</given-names></name></person-group> (<year>2014</year>). <article-title>Cognitive spare capacity and speech communication: a narrative overview</article-title>. <source>Biomed Res. Int.</source>
<volume>2014</volume>:<fpage>869726</fpage>
<pub-id pub-id-type="doi">10.1155/2014/869726</pub-id><pub-id pub-id-type="pmid">24971355</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudner</surname><given-names>M.</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name><name><surname>Lunner</surname><given-names>T.</given-names></name></person-group> (<year>2011</year>). <article-title>Working memory supports listening in noise for persons with hearing impairment</article-title>. <source>J. Am. Acad. Audiol.</source>
<volume>22</volume>, <fpage>156</fpage>&#x02013;<lpage>167</lpage>. <pub-id pub-id-type="doi">10.3766/jaaa.22.3.4</pub-id><pub-id pub-id-type="pmid">21545768</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>T. A.</given-names></name></person-group> (<year>1996</year>). <article-title>The processing speed theory of cognitive aging</article-title>. <source>Psychol. Rev.</source>
<volume>103</volume>, <fpage>403</fpage>&#x02013;<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.103.3.403</pub-id><pub-id pub-id-type="pmid">8759042</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>B. A.</given-names></name><name><surname>Daneman</surname><given-names>M.</given-names></name><name><surname>Pichora-Fuller</surname></name></person-group>. (<year>2002</year>). <article-title>Listening in aging adults: from discourse comprehension to psychoacoustics</article-title>. <source>Can. J. Exp. Psychol.</source>
<volume>56</volume>, <fpage>139</fpage>&#x02013;<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1037/h0087392</pub-id><pub-id pub-id-type="pmid">12271745</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>B. A.</given-names></name><name><surname>Pichora-Fuller</surname><given-names>K.</given-names></name><name><surname>Daneman</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Effects of senescent changes in audition and cognition on spoken language comprehension</article-title>, in <source>The Aging Auditory System: Perceptual Characterization and Neural Bases of Presbycusis</source>, eds <person-group person-group-type="editor"><name><surname>Gordon-Salant</surname><given-names>S.</given-names></name><name><surname>Frisina</surname><given-names>R. D.</given-names></name><name><surname>Popper</surname><given-names>A. N.</given-names></name><name><surname>Fay</surname><given-names>R. R.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>), <fpage>167</fpage>&#x02013;<lpage>210</lpage>.</mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoof</surname><given-names>T.</given-names></name><name><surname>Rosen</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>The role of auditory and cognitive factors in understanding speech in noise by normal-hearing older listeners</article-title>. <source>Front. Aging Neurosci.</source>
<volume>6</volume>:<issue>307</issue>. <pub-id pub-id-type="doi">10.3389/fnagi.2014.00307</pub-id><pub-id pub-id-type="pmid">25429266</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipstead</surname><given-names>Z.</given-names></name><name><surname>Hicks</surname><given-names>K. L.</given-names></name><name><surname>Engle</surname><given-names>R. W.</given-names></name></person-group> (<year>2012a</year>). <article-title>Cogmed working memory training: does the evidence support the claims?</article-title>
<source>J. Appl. Res. Mem. Cogn.</source>
<volume>1</volume>, <fpage>185</fpage>&#x02013;<lpage>193</lpage>. <pub-id pub-id-type="doi">10.1016/j.jarmac.2012.06.003</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipstead</surname><given-names>Z.</given-names></name><name><surname>Redick</surname><given-names>T. S.</given-names></name><name><surname>Engle</surname><given-names>R. W.</given-names></name></person-group> (<year>2012b</year>). <article-title>Is working memory training effective?</article-title>
<source>Psychol. Bull.</source>
<volume>138</volume>, <fpage>628</fpage>&#x02013;<lpage>654</lpage>. <pub-id pub-id-type="doi">10.1037/a0027473</pub-id><pub-id pub-id-type="pmid">22409508</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommers</surname><given-names>M. S.</given-names></name></person-group> (<year>1997</year>). <article-title>Speech perception in older adults: the importance of speech-specific cognitive abilities</article-title>. <source>J. Am. Geriatr. Soc.</source>
<volume>45</volume>, <fpage>633</fpage>&#x02013;<lpage>637</lpage>. <pub-id pub-id-type="doi">10.1111/j.1532-5415.1997.tb03101.x</pub-id><pub-id pub-id-type="pmid">9158590</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000f6;rqvist</surname><given-names>P.</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>Episodic long-term memory of spoken discourse masked by speech: what is the role for working memory capacity?</article-title>
<source>J. Speech Lang. Hear. Res.</source>
<volume>55</volume>, <fpage>210</fpage>&#x02013;<lpage>218</lpage>. <pub-id pub-id-type="doi">10.1044/1092-4388(2011/10-0353)</pub-id><pub-id pub-id-type="pmid">22199182</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Strauss</surname><given-names>E.</given-names></name><name><surname>Sherman</surname><given-names>E. M. S.</given-names></name><name><surname>Spreen</surname><given-names>O.</given-names></name></person-group> (<year>2006</year>). <source>A Compendium of Neuropsychological Tests: Administration, Norms, and Commentary, 3rd Edn.</source>
<publisher-loc>New York, NY</publisher-loc>
<publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szenkovits</surname><given-names>G.</given-names></name><name><surname>Peelle</surname><given-names>J. E.</given-names></name><name><surname>Norris</surname><given-names>D.</given-names></name><name><surname>Davis</surname><given-names>M. H.</given-names></name></person-group> (<year>2012</year>). <article-title>Individual differences in premotor and motor recruitment during speech perception</article-title>. <source>Neuropsychologia</source>
<volume>50</volume>, <fpage>1380</fpage>&#x02013;<lpage>1392</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2012.02.023</pub-id><pub-id pub-id-type="pmid">22521874</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamati</surname><given-names>T. N.</given-names></name><name><surname>Gilbert</surname><given-names>J. L.</given-names></name><name><surname>Pisoni</surname><given-names>D. B.</given-names></name></person-group> (<year>2013</year>). <article-title>Some factors underlying individual differences in speech recognition on PRESTO: a first report</article-title>. <source>J. Am. Acad. Audiol.</source>
<volume>24</volume>, <fpage>616</fpage>&#x02013;<lpage>634</lpage>. <pub-id pub-id-type="doi">10.3766/jaaa.24.7.10</pub-id><pub-id pub-id-type="pmid">24047949</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Towse</surname><given-names>J. N.</given-names></name><name><surname>Cowan</surname><given-names>N.</given-names></name><name><surname>Hitch</surname><given-names>G. J.</given-names></name><name><surname>Horton</surname><given-names>N. J.</given-names></name></person-group> (<year>2008</year>). <article-title>The recall of information from working memory. Insights from behavioral and chronometric perspectives</article-title>. <source>Exp. Psychol.</source>
<volume>55</volume>, <fpage>371</fpage>&#x02013;<lpage>383</lpage>. <pub-id pub-id-type="doi">10.1027/1618-3169.55.6.371</pub-id><pub-id pub-id-type="pmid">19130763</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tun</surname><given-names>P. A.</given-names></name><name><surname>O'Kane</surname><given-names>G.</given-names></name><name><surname>Wingfield</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>). <article-title>Distraction by competing speech in young and older adults</article-title>. <source>Psychol. Aging</source>
<volume>17</volume>, <fpage>453</fpage>&#x02013;<lpage>467</lpage>. <pub-id pub-id-type="doi">10.1037/0882-7974.17.3.453</pub-id><pub-id pub-id-type="pmid">12243387</pub-id></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tun</surname><given-names>P. A.</given-names></name><name><surname>Wingfield</surname><given-names>A.</given-names></name></person-group> (<year>1999</year>). <article-title>One voice too many: adult age differences in language processing with different types of distracting sounds</article-title>. <source>J. Gerontol.</source>
<volume>54B</volume>, <fpage>317</fpage>&#x02013;<lpage>327</lpage>. <pub-id pub-id-type="doi">10.1093/geronb/54B.5.P317</pub-id></mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tun</surname><given-names>P. A.</given-names></name><name><surname>Wingfield</surname><given-names>A.</given-names></name><name><surname>andStine</surname><given-names>E. A. L.</given-names></name></person-group> (<year>1991</year>). <article-title>Speech processing capacity in young and older adults: a dual-task study</article-title>. <source>Psychol. Aging</source>
<volume>6</volume>, <fpage>3</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1037/0882-7974.6.1.3</pub-id><pub-id pub-id-type="pmid">2029365</pub-id></mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Rooij</surname><given-names>J. C. G. M.</given-names></name><name><surname>Plomp</surname><given-names>R.</given-names></name></person-group> (<year>1990</year>). <article-title>Auditive and cognitive factors in speech perception by elderly listeners</article-title>. <source>Acta Otolaryngol.</source>
<volume>111</volume>, <fpage>177</fpage>&#x02013;<lpage>181</lpage>.</mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wayne</surname><given-names>R. V.</given-names></name><name><surname>Johnsrude</surname><given-names>I.</given-names></name></person-group> (<year>2012</year>). <article-title>The role of visual speech information in supporting perceptual learning of degraded speech</article-title>. <source>J. Exp. Psychol.</source>
<volume>18</volume>, <fpage>419</fpage>&#x02013;<lpage>435</lpage>. <pub-id pub-id-type="doi">10.1037/a0031042</pub-id><pub-id pub-id-type="pmid">23294284</pub-id></mixed-citation></ref><ref id="B81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wingfield</surname><given-names>A.</given-names></name><name><surname>Tun</surname><given-names>P. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Cognitive supports and cognitive constraints on comprehension of spoken language</article-title>. <source>J. Am. Acad. Audiol.</source>
<volume>18</volume>, <fpage>548</fpage>&#x02013;<lpage>558</lpage>. <pub-id pub-id-type="doi">10.3766/jaaa.18.7.3</pub-id><pub-id pub-id-type="pmid">18236643</pub-id></mixed-citation></ref><ref id="B82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wingfield</surname><given-names>A.</given-names></name><name><surname>Tun</surname><given-names>P. A.</given-names></name><name><surname>Koh</surname><given-names>C. K.</given-names></name><name><surname>Rosen</surname><given-names>M. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Regaining lost time: adult aging and the effects of time restoration on recall of time-compressed speech</article-title>. <source>Psychol. Aging</source>
<volume>14</volume>, <fpage>380</fpage>&#x02013;<lpage>389</lpage>. <pub-id pub-id-type="doi">10.1037/0882-7974.14.3.380</pub-id><pub-id pub-id-type="pmid">10509694</pub-id></mixed-citation></ref><ref id="B83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>W. S.</given-names></name><name><surname>Kalluri</surname><given-names>S.</given-names></name><name><surname>Pentony</surname><given-names>S.</given-names></name><name><surname>Nooraei</surname><given-names>N.</given-names></name></person-group> (<year>2013</year>). <article-title>Predicting the effect of hearing loss and audibility on amplified speech reception in a multi-talker listening scenario</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>133</volume>, <fpage>4268</fpage>&#x02013;<lpage>4278</lpage>. <pub-id pub-id-type="doi">10.1121/1.4803859</pub-id><pub-id pub-id-type="pmid">23742377</pub-id></mixed-citation></ref><ref id="B84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname><given-names>A. A.</given-names></name><name><surname>Rudner</surname><given-names>M.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name><name><surname>Heslenfeld</surname><given-names>D. J.</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>Behavioral and fMRI evidence that cognitive ability modulates the effect of semantic context on speech intelligibility</article-title>. <source>Brain Lang.</source>
<volume>122</volume>, <fpage>103</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1016/j.bandl.2012.05.006</pub-id><pub-id pub-id-type="pmid">22728131</pub-id></mixed-citation></ref><ref id="B85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname><given-names>A. A.</given-names></name><name><surname>Rudner</surname><given-names>M.</given-names></name><name><surname>Johnsrude</surname><given-names>I. S.</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>The effects of working memory capacity and semantic cues on the intelligibility of speech in noise</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>134</volume>, <fpage>2225</fpage>&#x02013;<lpage>2234</lpage>. <pub-id pub-id-type="doi">10.1121/1.4817926</pub-id><pub-id pub-id-type="pmid">23967952</pub-id></mixed-citation></ref><ref id="B86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zinke</surname><given-names>K.</given-names></name><name><surname>Zeintl</surname><given-names>M.</given-names></name><name><surname>Rose</surname><given-names>N. S.</given-names></name><name><surname>Putzmann</surname><given-names>J.</given-names></name><name><surname>Pydde</surname><given-names>A.</given-names></name><name><surname>Kliegel</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>Working memory training and transfer in older adults: effects of age, baseline performance, and training gains</article-title>. <source>Dev. Psychol.</source>
<volume>50</volume>, <fpage>304</fpage>&#x02013;<lpage>315</lpage>. <pub-id pub-id-type="doi">10.1037/a0032982</pub-id><pub-id pub-id-type="pmid">23688173</pub-id></mixed-citation></ref></ref-list></back></article>