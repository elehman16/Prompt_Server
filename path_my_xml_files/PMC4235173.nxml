<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Trials</journal-id><journal-id journal-id-type="iso-abbrev">Trials</journal-id><journal-title-group><journal-title>Trials</journal-title></journal-title-group><issn pub-type="epub">1745-6215</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24304745</article-id><article-id pub-id-type="pmc">4235173</article-id><article-id pub-id-type="publisher-id">1745-6215-14-417</article-id><article-id pub-id-type="doi">10.1186/1745-6215-14-417</article-id><article-categories><subj-group subj-group-type="heading"><subject>Study Protocol</subject></subj-group></article-categories><title-group><article-title>Working memory training for adult hearing aid users: study protocol for a double-blind randomized active controlled trial</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Henshaw</surname><given-names>Helen</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>helen.henshaw@nottingham.ac.uk</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Ferguson</surname><given-names>Melanie A</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>melanie.ferguson@nottingham.ac.uk</email></contrib></contrib-group><aff id="I1"><label>1</label>NIHR Nottingham Hearing Biomedical Research Unit, School of Medicine, University of Nottingham, Ropewalk House, 113 The Ropewalk, Nottingham, UK</aff><aff id="I2"><label>2</label>NIHR Nottingham Hearing Biomedical Research Unit, Nottingham University Hospitals NHS Trust, Ropewalk House, 113 The Ropewalk, Nottingham, UK</aff><pub-date pub-type="collection"><year>2013</year></pub-date><pub-date pub-type="epub"><day>5</day><month>12</month><year>2013</year></pub-date><volume>14</volume><fpage>417</fpage><lpage>417</lpage><history><date date-type="received"><day>4</day><month>9</month><year>2013</year></date><date date-type="accepted"><day>18</day><month>11</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2013 Henshaw and Ferguson; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2013</copyright-year><copyright-holder>Henshaw and Ferguson; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.trialsjournal.com/content/14/1/417"/><abstract><sec><title>Background</title><p>One in ten people aged between 55 to 74&#x000a0;years have a significant hearing impairment in their better hearing ear (as defined by audiometric hearing thresholds). However, it is becoming increasingly clear that the challenges faced by older listeners cannot be explained by the audiogram alone. The ability for people with hearing loss to use cognition to support speech perception allows for compensation of the degraded auditory input. This in turn offers promise for new cognitive-based rehabilitative interventions. Working memory is known to be highly associated with language comprehension and recent evidence has shown significant generalization of learning from trained working memory tasks to improvements in sentence-repetition skills of children with severe to profound hearing loss. This evidence offers support for further investigation into the potential benefits of working memory training to improve speech perception abilities in other hearing impaired populations.</p></sec><sec><title>Methods/Design</title><p>This is a double-blind randomized active controlled trial aiming to assess whether a program of working memory training results in improvements in untrained measures of cognition, speech perception and self-reported hearing abilities in adult hearing aid users (aged 50 to 74 years) with mild-to-moderate hearing loss, compared with an active control group who receive a placebo version of the working memory training program.</p></sec><sec><title>Discussion</title><p>The present study aims to generate high-quality preliminary evidence for the efficacy of working memory training for adults with mild-to-moderate sensorineural hearing loss who are existing hearing aid users. This trial addresses a number of gaps in the published literature assessing training interventions for people with hearing loss, and in the general literature surrounding working memory training, such as the inclusion of an active control group, participant and tester blinding, and increased transparency in reporting.</p></sec><sec><title>Trial registration</title><p>ClinicalTrials.gov identifier: <ext-link ext-link-type="uri" xlink:href="http://www.clinicaltrials.gov/ct2/show/NCT01892007">NCT01892007</ext-link>. Date of registration: 27 June 2013.</p></sec></abstract><kwd-group><kwd>Hearing loss</kwd><kwd>Hearing aid</kwd><kwd>Speech intelligibility</kwd><kwd>Speech perception</kwd><kwd>Cognition</kwd><kwd>Cognitive training</kwd><kwd>Working memory</kwd><kwd>Working memory training</kwd></kwd-group></article-meta></front><body><sec><title>Background</title><p>More than one in ten people aged between 55 to 74&#x000a0;years have a significant hearing impairment (greater than 25&#x000a0;dB hearing loss (dB HL) averaged across 0.5 to 4&#x000a0;k&#x000a0;Hz) in their better hearing ear [<xref ref-type="bibr" rid="B1">1</xref>]. Although a relationship between auditory and cognitive processing has been recognized for decades [<xref ref-type="bibr" rid="B2">2</xref>], it has become clear in recent years that the challenges faced by older listeners cannot be explained by the audiogram alone [<xref ref-type="bibr" rid="B3">3</xref>]. Difficulties faced by adults with hearing loss, particularly in complex and noisy environments, have led to a recent resurgence in interest in the link between audition and cognition [<xref ref-type="bibr" rid="B4">4</xref>-<xref ref-type="bibr" rid="B6">6</xref>].</p><p>Auditory training has been used for many years as a rehabilitative intervention for people with hearing loss. It can be defined as a process that involves teaching the brain to listen through active engagement with sound. Auditory training has been shown to result in improved performance for the trained task, for example, frequency discrimination in normally hearing adults and children [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. However, for auditory training to be an effective intervention for those with hearing loss, any improvements shown for trained tasks need to generalize to functional benefits to real-world listening [<xref ref-type="bibr" rid="B9">9</xref>]. It has previously been suggested that for language and listening abilities, the development of cognitive skills may be equally, or perhaps even more important, than the refinement of sensory processing [<xref ref-type="bibr" rid="B10">10</xref>]. A recent study of auditory-cognitive training for older adults with hearing loss showed generalized improvements in neural timing, memory, speed of processing and speech-in-noise perception [<xref ref-type="bibr" rid="B11">11</xref>]. Research from our own laboratory suggests that auditory training using phonemic contrasts results in significant improvements in untrained measures of divided attention and working memory. Participants also reported post-training improvements in self-reported hearing abilities, specifically for a complex listening condition, &#x02018;having a conversation with several people in a group&#x02019; [<xref ref-type="bibr" rid="B12">12</xref>]. Thus, training interventions that aim to improve cognitive performance may offer benefits to the listening abilities of people with hearing loss.</p><p>Working memory has been defined in many ways. Engle and Kane [<xref ref-type="bibr" rid="B13">13</xref>] emphasize the role of inhibition, suppressing interference from irrelevant sources of information. Barrouillet <italic>et al</italic>. [<xref ref-type="bibr" rid="B14">14</xref>] focus on resource sharing and the capacity to divide or switch attention. Miyake <italic>et al</italic>. [<xref ref-type="bibr" rid="B15">15</xref>] state that working memory offers a means to update and maintain information. In a review of a number of different models, Miyake and Shah concluded that working memory could be generally defined as those &#x02018;mechanisms or processes that are involved in the control, regulation, and active maintenance of task-relevant information in the service of complex cognition, including novel as well as familiar, skilled tasks&#x02019; [<xref ref-type="bibr" rid="B16">16</xref>]. Working memory is known to be highly associated with language comprehension [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>] and the neural processing of sound [<xref ref-type="bibr" rid="B19">19</xref>]. Working memory has also been recognized as an important predictor of an individual&#x02019;s success with hearing aids [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B21">21</xref>]. Difficulties in hearing may be exacerbated by, or &#x02018;masquerade as&#x02019;&#x02009;, reductions in cognitive performance, for example, problems in remembering or comprehending spoken language [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>]. It has been suggested that the ability for people with hearing loss to use cognitive abilities (such as attention and working memory) to support context in speech perception allows for compensation of a degraded auditory input, which in turn offers promise for new cognitive-based rehabilitative interventions [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B25">25</xref>]. However, a recent systematic review of studies assessing the efficacy of <italic>auditory</italic> training for adults with hearing loss suggests a number of methodological and reporting inadequacies in published research, resulting in very-low to moderate quality evidence [<xref ref-type="bibr" rid="B9">9</xref>]. Thus, to draw adequate conclusions about the efficacy of training interventions (auditory or cognitive) for people with hearing loss, any future investigations should offer a high level of evidence using well-designed randomized controlled trials with ample transparency in reporting.</p><p>Cogmed RM is a training software product for children or adults that aims to improve working memory, comprising verbal and visuospatial working memory and memory storage tasks. Brehmer <italic>et al</italic>. [<xref ref-type="bibr" rid="B26">26</xref>] demonstrated significant improvements in performance for trained Cogmed tasks in younger (20 to 30&#x000a0;years old) and older (60 to 70&#x000a0;years old) adults. In addition, generalization of on-task learning was shown to improvements in untrained measures of sustained attention and self-reported cognitive function, and these improvements were maintained across a 3-month follow-up interval. A pilot study of Cogmed as an intervention for hearing loss [<xref ref-type="bibr" rid="B27">27</xref>] showed significant generalization of on-task learning to improvements in sentence-repetition skills of children with severe to profound hearing loss who were cochlear implant users.</p><p>There are currently 10 million people in the UK with a significant hearing impairment [<xref ref-type="bibr" rid="B28">28</xref>], the majority of whom have mild and moderate hearing loss. The most common management strategy for those individuals is the provision of hearing aids to amplify sound. However, additional support and interventions can improve outcomes for aided hearing impaired listeners [<xref ref-type="bibr" rid="B24">24</xref>]. This preliminary evidence [<xref ref-type="bibr" rid="B27">27</xref>] offers support for further investigation into the potential benefits of working memory training to improve listening and speech perception abilities for adult hearing aid users with mild to moderate hearing loss.</p><p>The present study protocol presents novel independent research funded by the National Institute for Health Research (NIHR) and has been reported in accordance with the SPIRIT (&#x02018;Standard Protocol Items: Recommendations for Intervention Trials&#x02019;) 2013 guidance for content of a clinical trial protocol [<xref ref-type="bibr" rid="B29">29</xref>].</p><sec><title>Research objective</title><p>Does working memory training result in improvements in cognition, speech perception and self-reported hearing abilities in adults with mild-to-moderate hearing loss who are existing hearing aid users, compared with an active control group (non-adaptive, placebo training)?</p></sec><sec><title>Specific research hypotheses</title><p>We <bold>hypothesise</bold> that:</p><p>1. Compared with the active control group, hearing aid users in the experimental group (adaptive working memory training) will have significant generalized improvements in untrained measures of cognition, speech perception and self-reported hearing abilities. Furthermore, these improvements will be significantly greater than for hearing aid users in the active control group who receive non-adaptive training.</p></sec></sec><sec><title>Methods/Design</title><p>The study is a single-center, phase II, double-blind, randomized, active controlled trial, with minimized allocation of participants to one of two groups (Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>). One group (experimental) will receive adaptive working memory training, where task difficulty adjusts according to individual participant performance. The second group (active control) will receive non-adaptive training, fixed at low-difficulty practice level (3 to-be-remembered items). The use of an active control group for comparison will help account for any placebo effects, thus increasing confidence in the estimation of effect in the adaptively trained group that improvements in outcomes result from the development of working memory ability (as trained using an adaptive training program), rather than simply the provision of a the training program <italic>per se</italic>. The research edition of Cogmed RM working memory training will be used as this has been designed for double-blind randomized active controlled trials and provides no indication to either participants or testers of which training group (experimental or active control) a participant has been allocated.</p><p>One initial assessment and two baseline sessions, conducted a maximum of 1&#x000a0;week apart (T1 and T2), will be completed prior to allocation of training. The two baseline sessions will help account for any improvements in outcomes as a result of test-retest effects (procedural learning) prior to the intervention, thus increasing our confidence in the estimation of subsequent intervention-specific effects.</p><p>Working memory training will be delivered in participants&#x02019; homes via an online training portal. Participants will complete a total of 25 sessions (5 sessions per week for 5&#x000a0;weeks). Improvements for trained tasks will be assessed using the Cogmed &#x02018;index of improvement&#x02019;. Following training, participants will return for a post-intervention outcome assessment at T3. Participants in the active control group who receive the non-adaptive training will be unblinded following their T3 assessment and offered the adaptive training. Participants in the experimental group will remain blinded at T3 and will be invited to return for a 6-month follow-up assessment at T4 (31&#x000a0;weeks) to assess retention of any post-training improvements in outcomes (Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Study design.</p></caption><graphic xlink:href="1745-6215-14-417-1"/></fig><p>The study has obtained approval from the Nottingham University Hospitals NHS Trust Research and Innovation Department, the trial sponsor (study reference 08ET002-01), and full ethical approval from Nottingham 2 NHS Research Ethics Committee (reference 08/H0408/172).</p><sec><title>Participant sample</title><p>Existing hearing aid users between the ages of 50 to 74&#x000a0;years with mild to moderate hearing loss, as defined by an audiometric air-conduction pure-tone averaged (averaged instead of average) (PTA) across octave frequencies between 0.25 to 4&#x000a0;kHz of 20 to 70&#x000a0;dB HL [<xref ref-type="bibr" rid="B30">30</xref>] in the better hearing ear, will be recruited from the NIHR Nottingham Hearing Biomedical Research Unit database of research volunteers in the UK.</p><sec><title>Inclusion criteria</title><p>Inclusion criteria are: (1) aged 50 to 74&#x000a0;years; (2) existing (3+ months) hearing aid(s) user; (3) mild to moderate (PTA<sub>0.25-4k Hz</sub> 21 to 69&#x000a0;dB HL) sensorineural hearing loss (SNHL; air bone gap average across 0.5, 1 and 2&#x000a0;kHz&#x02009;&#x02264;&#x02009;15&#x000a0;dB HL) in the better hearing ear; and (4) internet access at home.</p></sec><sec><title>Exclusion criteria</title><p>Exclusion criteria are: (1) having previously taken part in a training intervention study; (2) first language other than English (all speech outcome measure are presented in English); (3) unable to use a desktop or laptop computer (as working memory training is delivered via the internet using a desktop or laptop computer); and (4) mild cognitive impairment as defined (as a score of less than 26/30 on the Montreal Cognitive Assessment [<xref ref-type="bibr" rid="B31">31</xref>]).</p></sec></sec><sec><title>Outcome measures and power analysis</title><sec><title>Primary outcome measure</title><p>Change in performance in an untrained measure of verbal working memory (Visual Letter Monitoring Task) will be the primary measure of efficacy in the present study. The Visual Letter Monitoring Task [<xref ref-type="bibr" rid="B32">32</xref>] is a visual measure of verbal working memory updating that is not trained within the Cogmed package. There are 10 consonant-vowel-consonant (CVC) words embedded in an 80-letter sequence. Two sequences will be presented to participants at each visit in counterbalanced order. Individual letters are displayed sequentially on a computer screen at a rate of 2&#x000a0;s per letter (first list) and 1&#x000a0;s per letter (second list). Participants will be asked to press the keyboard &#x02018;space bar&#x02019; (hit) when three consecutive letters formed a recognized CVC word (for example, M-A-T). The test provides two measures, total number of hits (maximum score of ten per list) and d&#x02019; (d prime).</p></sec><sec><title>Secondary outcome measures</title><p>Secondary outcome measures assess multiple aspects of speech perception, cognition and communication abilities.</p></sec></sec><sec><title>Speech perception</title><sec><title>Phoneme discrimination</title><p>The phoneme discrimination task assesses an individual&#x02019;s ability to distinguish differences between phonemes presented on a continuum. Delivered using the Medical Research Council (MRC) Institute of Hearing Research System for Testing Auditory Responses (IHR-STAR) platform. Participants will be presented with three discrete phonemes from a continuum per trial and asked to identify the odd one out. Phoneme continua /a/ /e/ (easy) and /d/ /g/ (difficult) will be presented for a block of 35 trials in sequential blocks, with a 3-trial demonstration of continuum /a/ /e/ prior to the 2 blocks. The task will be adaptive based on participant performance using a three-phase adaptive staircase procedure (see [<xref ref-type="bibr" rid="B33">33</xref>] for further information), with auditory and visual feedback provided to participants after each trial (correct/incorrect response). Threshold will be calculated as the average of the last 2 reversals in a block of 35 trials.</p></sec><sec><title>Context</title><p>High-predictability and low-predictability (context) sentences [<xref ref-type="bibr" rid="B34">34</xref>], based on the Revised Speech Perception in Noise Test [<xref ref-type="bibr" rid="B35">35</xref>], are produced by a British English native speaker. Lists of 22 sentences (11 high predictability and 11 low predictability) are presented in the free field in a background of multi-talker babble at a fixed signal-to-noise ratio (SNR) of -1&#x000a0;dB. Two practice sentences (one high and one low predictability) are presented to participants at a slightly more favorable (2&#x000a0;dB) SNR prior to commencing the main test. Participants are asked to listen to each sentence and repeat the last word aloud. The test is scored as the percentage of last words correctly repeated for both high-predictability and low-predictability lists.</p></sec><sec><title>Competing speech</title><p>The Modified Coordinate Response Measure (MCRM) is a measure of speech perception ability in the presence of different maskers at an adaptive signal-to-noise ratio. The basic task is described by Hazan and colleagues [<xref ref-type="bibr" rid="B36">36</xref>], and is based on the Coordinate Response Measure [<xref ref-type="bibr" rid="B37">37</xref>]. Participants will be presented with sentences in the form of &#x02018;show the [animal] where the [color] [number] is&#x02019;. There are six possible monosyllabic animals (cat, cow, dog, duck, pig and sheep), six colors (black, blue, green, pink, red and white) and eight numbers (one to nine, excluding multisyllabic seven). Two sentences are presented concurrently, one by a female speaker (target) and one by a male speaker (distracter). Participants will be asked to listen for the color and number spoken by the female speaker (&#x02018;dog&#x02019; is always the animal target) while ignoring the male speaker, and respond by pressing the corresponding target color number on a computer touchscreen. The test uses an adaptive 1-up 1-down staircase method with an initial step size of 10&#x000a0;dB until the first reversal, reducing to 7&#x000a0;dB at reversal 2 and 4&#x000a0;dB at reversal 3. The test continues until a total of eight reversals are achieved and the test is completed twice by each participant. Speech reception thresholds are calculated in this study using the average of the last two reversals, averaged across the two runs.</p></sec></sec><sec><title>Cognition</title><sec><title>Simple-span working memory</title><p>The digit span (backwards) subtest from the Wechsler Adult Intelligence Scale, Third Edition (WAIS-III) [<xref ref-type="bibr" rid="B38">38</xref>] is measure of simple-span working memory that involves listening to a list of numbers of increasing length and repeating them in reverse order. Digits are presented at each list length twice and lists increase in length by one digit if participants correctly recall one of the two lists at each length correctly, otherwise the test is discontinued. The performance is scored as the total number of lists correctly repeated in reverse order. A version of the digit span (backwards) forms one of the trained tasks in the Cogmed RM program.</p></sec><sec><title>Auditory attention</title><p>The MRC Institute of Hearing Research Test of Attention in Listening (TAIL) is a measure of auditory attention [<xref ref-type="bibr" rid="B39">39</xref>] using tones that vary in both frequency and spatial location. Primary tasks include both frequency and location discrimination and participants are asked to respond as to whether two tones are the &#x02018;same&#x02019; or &#x02018;different&#x02019; frequency or location using a button box response. Tones are presented in the free field at participants&#x02019; most comfortable loudness (MCL) level [<xref ref-type="bibr" rid="B40">40</xref>] via two speakers situated at 90&#x000b0; to the left and 90&#x000b0; to the right of the participant. TAIL measures the ability to focus selectively on a task relevant dimension (either frequency or location) and ignore information from task irrelevant dimensions, using reaction time (RT) as the primary performance measure. The task is scored using measures of involuntary orientation (the impact of the task irrelevant dimension on RTs for the task relevant dimension, quantified as the difference in RTs between &#x02018;same&#x02019; and &#x02018;different&#x02019; trials) and conflict resolution (the frequency by location interaction, quantified as the difference between congruent (same or different in both dimensions) and incongruent (same in one dimension, different in the other) trials).</p></sec><sec><title>Single and divided attention</title><p>The Test of Everyday Attention (TEA) subtests 6 (telephone search) and 7 (telephone search while counting) will be used to assess participants single (visual) attention and dual (auditory and visual) attention [<xref ref-type="bibr" rid="B41">41</xref>]. In subtest 6, participants are asked to search a telephone directory for matching symbols. In subtest 7, participants are asked to search a telephone directory for matching symbols while counting strings of beeps in varying lengths (2 to 12) that are presented in the free field. The task is scored using time (in seconds) per correctly identified symbol for subtests 6 and 7, and weighted in subtest 7 by the proportion of correctly counted beep strings. A dual task decrement can be calculated, which provides the difference in time (in seconds) per correctly identified symbol where two simultaneous tasks are being completed, compared with that for a single task (subtest 7 minus subtest 6).</p></sec><sec><title>Working memory and inhibition</title><p>The Size Comparison Span (SICSPAN) is a measure of working memory capacity including inhibition of semantic confusions [<xref ref-type="bibr" rid="B42">42</xref>]. Participants view lists of size comparisons (for example, &#x02018;tree is larger than acorn&#x02019; to which they must respond &#x02018;yes&#x02019; or &#x02018;no&#x02019; using a button box response. Participants are then provided with to-be-remembered words from the same semantic category (for example, &#x02018;leaf&#x02019;). At the end of the list, participants are required to recall the to-be-remembered words while inhibiting words included in the size comparison judgments. The task begins with lists of two size comparison judgments and to-be-remembered words, increasing to list lengths of three, four, five and six. There are two trials at each list length. The task continues until all list lengths have been presented, with no discontinuation rule.</p></sec><sec><title>Dual task of listening and memory</title><p>The dual task is a measure of listening and memory designed to assess listening effort [<xref ref-type="bibr" rid="B43">43</xref>]. Participants are presented with a five-digit memory task that flanks a speech in noise comprehension task. A string of five digits are displayed visually on a computer screen for 5&#x000a0;s. Participants are asked to retain the digits in memory for later recall. Participants are then presented with a list of five AB isophonemic monosyllabic words [<xref ref-type="bibr" rid="B44">44</xref>] presented in a background of multi-talker babble, and are asked to repeat each word immediately after presentation. After each list of five words, participants are asked to recall the previously presented five digits. There are 4 word lists, resulting in a maximum possible score of 20 correctly repeated words and 20 correctly recalled digits. A dual-task score is calculated by adding together the scores for the word and digit tasks, resulting in a maximum possible dual-task score of 40.</p></sec></sec><sec><title>Self-reported communication</title><p>The Glasgow Hearing Aid Benefit Profile [<xref ref-type="bibr" rid="B45">45</xref>] is used to assess self-reported hearing disability (activity limitation), hearing handicap (participation restriction), and hearing aid use, benefit, and satisfaction. This questionnaire will be administered via interview and completed electronically. Participants will be presented with series of four listening scenarios (listening to the television, having a conversation with one other person in a quiet room, having a conversation in a busy street or shop, talking to several people in a group) and are asked to rate the amount difficulty they have in the situation while wearing their hearing aids (initial disability/activity limitation, 1&#x02009;=&#x02009;no difficulty to 5&#x02009;=&#x02009;cannot manage at all) and how much any difficulty worries, annoys or upsets them (handicap/participation limitation, 1&#x02009;=&#x02009;not at all to 5&#x02009;=&#x02009;very much indeed). Participants then rate their hearing aid use (1&#x02009;=&#x02009;never to 5&#x02009;=&#x02009;all the time), benefit (1&#x02009;=&#x02009;no use at all to 5&#x02009;=&#x02009;hearing is perfect with aid) and satisfaction with their hearing aids (1&#x02009;=&#x02009;not satisfied at all to 5&#x02009;=&#x02009;delighted with aid). The mean of all four scenarios in each measure (Initial Disability, Handicap, Hearing Aid Use, Hearing Aid Benefit and Hearing Aid Satisfaction) are converted to a percentage (0% to 100%).</p><p>The Hearing Handicap Inventory for the Elderly [<xref ref-type="bibr" rid="B46">46</xref>] is a self-report questionnaire that quantifies the emotional and social/situational effects of self-perceived hearing impairment. Participants are asked to complete the 25-item paper questionnaire answering statements such as &#x02018;Does a hearing problem cause you to be nervous&#x02019; with either &#x02018;yes&#x02019; (4 points), &#x02018;no&#x02019; (0 points) or &#x02018;sometimes&#x02019; (2 points). The questionnaire is scored as total points for all items (maximum 100 points). Subtotal scores can also be calculated for emotional (12 items, maximum 48 points) and situational items (13 items, maximum 52 points).</p></sec><sec><title>Power analysis</title><p>In order to detect a minimum improvement of 1.5 words (15%) in the primary outcome measure (Visual Letter Monitoring Task) based on 80% power, a 1-sided type I error rate of 5%, using a pooled standard deviation of 2.118 to derive the effect sizes, a total of 27 participants are required in each training group. We anticipate a participant attrition rate of no more than 15%, and therefore will recruit a total of 31 participants per group.</p></sec><sec><title>Test procedure</title><p>Participants will be sent a study information sheet at least 24&#x000a0;h before their first test session. At the first test session, participants will provide signed informed consent. All testing will be carried out at the NIHR Nottingham Hearing Biomedical Research Unit. Audiometric testing will be performed in double walled sound attenuating booth. Speech perception and cognitive testing will take place in a quiet, purpose-designed test room. Auditory stimuli will be presented in the free field via a single speaker (Genelec Inc., MA) situated directly in front of the participant at their most comfortable loudness (MCL) level [<xref ref-type="bibr" rid="B40">40</xref>].</p><p>Cogmed RM working memory training will be delivered via the internet at the participant&#x02019;s home, using either their home PC or a laptop loaned by the NIHR Nottingham Hearing Biomedical Research Unit. Auditory elements will be presented in the free field using built-in or portable speakers at participants&#x02019; MCL. Training will be home-based with telephone monitoring once per week to ensure progress is maintained and to monitor for any practical or technical issues with training. Participants will be supported throughout their at-home training by a training aide, typically their spouse, who will offer support and guidance in accordance with Cogmed guidelines. Training aides will be instructed on their role by a qualified training coach at the NIHR Nottingham Hearing Biomedical Research Unit.</p></sec><sec><title>Randomization and blinding</title><sec><title>Allocation to training groups</title><p>Participants will be allocated either an &#x02018;experimental&#x02019; or an &#x02018;active control&#x02019; user ID to access the training URL by the chief investigator (HH) using Minim, a method of minimization [<xref ref-type="bibr" rid="B47">47</xref>]. Minimization will ensure balanced allocation to the experimental and active control groups based on participants&#x02019; age (younger&#x02009;=&#x02009;50 to 62&#x000a0;years vs older&#x02009;=&#x02009;63 to 74&#x000a0;years), sex (male, female), hearing amplification type (unilateral vs bilateral hearing aids) and low versus high working memory capacity (backwards digit span score &#x0003c;7 vs &#x02265;7) at baseline. Participant group allocation details will be documented and stored securely by the chief investigator in a password protected file.</p></sec><sec><title>Blinding of participants</title><p>Participants will be blind to group allocation and it will not be possible for participants to tell from the online training interface which group they have been assigned to.</p></sec><sec><title>Blinding of tester</title><p>The researcher responsible for testing participants at baseline and post-intervention outcome assessments will not be involved in the allocation of participant IDs and will be blind to participants&#x02019; group allocation.</p></sec></sec><sec><title>Intervention</title><p>Cogmed RM working memory training (Figure&#x000a0;<xref ref-type="fig" rid="F2">2</xref>) consists of 11 different sequence-based verbal and visuospatial working memory and memory storage games (Table&#x000a0;<xref ref-type="table" rid="T1">1</xref>). Participants are required to complete 25 sessions over 5&#x000a0;weeks (5 sessions per week), actively training for 35 to 45&#x000a0;minutes a day.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>User home screen for working memory training.</p></caption><graphic xlink:href="1745-6215-14-417-2"/></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Working memory training tasks</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th align="left"><bold>Training tasks</bold></th><th align="left"><bold>Task type</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom">Asteroid, sorter, 3D cube, rotating data link<hr/></td><td align="left" valign="bottom">Visuospatial working memory<hr/></td></tr><tr><td align="left" valign="bottom">Input module with lid<hr/></td><td align="left" valign="bottom">Verbal working memory<hr/></td></tr><tr><td align="left" valign="bottom">Input module, stabilizer<hr/></td><td align="left" valign="bottom">Visuospatial and verbal working memory<hr/></td></tr><tr><td align="left" valign="bottom">Data room, visual data link, space whack<hr/></td><td align="left" valign="bottom">Visuospatial storage<hr/></td></tr><tr><td align="left">Decoder</td><td align="left">Verbal storage</td></tr></tbody></table></table-wrap><sec><title>Adaptive training</title><p>For the experimental group, training task difficulty (number of to-be-remembered items) is adaptive, based on individual performance, to maintain average daily performance levels of approximately 60% of trials correct.</p></sec><sec><title>Non-adaptive training</title><p>For the active control group, non-adaptive training tasks are fixed at a low-difficulty practice level (three to-be-remembered items) and task difficulty will not increase for the duration of the training.</p></sec></sec><sec><title>Data management</title><p>The chief investigator is the data custodian. This study will abide by the Caldicott principles. Data will be stored in accordance with NHS guidelines.</p><p>Data collected on paper will be entered onto a database accessible only by the research team and stored alongside electronic data. The database will be password protected and held on the NIHR Nottingham Hearing Biomedical Research Unit network, which is also protected with a password that is changed every 12&#x000a0;months. Paper files will be stored in filing cabinets in a locked room. All identifiable files will be stored separately from data. Data will carry a unique (non-identifiable) study number. Electronic data is backed up daily, with backup files stored off site in a fireproof cabinet. Only the primary investigator, chief investigator, and the unit statistician will have access to the final data set.</p></sec><sec><title>Data analysis and statistical methods</title><p>Analyses will be performed to include those of the 62 recruited participants who meet the study criteria and complete the trial. Any participant leaving the study before its completion will not be replaced. Missing data will be accounted for using a method of multiple imputation (replaced with plausible values based on Monte Carlo-simulated data points from the data set). Effect sizes will be calculated using Cohen&#x02019;s <italic>d</italic>, using the pooled standard deviation of the two groups.</p></sec><sec><title>Baseline characteristics</title><p>Baseline characteristics (including but not limited to; age, sex, hearing loss, working memory capacity, hearing aid use, hearing disability, hearing handicap, speech perception) will be described for each group.</p></sec><sec><title>Efficacy analyses</title><p>The primary endpoint and first analysis of group data will take place at the end of the 7-week randomized controlled trial (week 7). Repeated measures analysis of variance (ANOVA) will be used to assess any main effects of time and training group (experimental vs. active control) on the primary and secondary outcome measures. In addition, exploration of any significant interaction effects will enable the identification of whether Cogmed (adaptive) training for participants in the experimental group results in significantly different outcome performance than Cogmed (fixed) training for participants in the active control group. The mean difference in the primary outcome measure (Visual Letter Monitoring Task) for the main intervention assessment comparison (T2-T3) will be presented as a mean difference and 95% confidence interval (CI) for each of the two groups. Within-group and between-group comparisons for the primary and secondary outcome measures will be conducted using paired and independent t tests (or non-parametric equivalents). Pearson&#x02019;s product moment (or Spearman&#x02019;s rho correlations) will be used to identify relationships between improvements in behavioral performance of speech perception and cognition and improvements in self-reported hearing ability, to help inform clinically significant benefits for people with hearing loss.</p><p>The second endpoint and planned analysis will take place at the end of T4 (week 31), for the experimental group only, to examine the retention of any post-training improvements in the primary and secondary outcomes at a 6-month follow-up assessment. Repeated measures ANOVA will be used to assess any main effects of time the primary and secondary outcome measures for participants in the experimental group. The mean difference in the primary outcome measure (Visual Letter Monitoring Task) for the main retention assessment comparison (T3-T4) will be presented as a mean difference and 95% confidence interval (CI). Within-group comparisons for the primary and secondary outcome measures will be conducted using paired and independent t tests (or non-parametric equivalents).</p></sec><sec><title>Subgroup analyses</title><p>Repeated measures ANOVA, paired t tests and independent t tests (or their non-parametric equivalents) will be performed where appropriate to assess intervention efficacy in subgroups of participants who are bilateral and unilateral hearing aid users, and those with high and low baseline working memory capacity. Analyses will identify whether there are any differences in pre-intervention to post-intervention outcome performance (week 7), and for the retention of any training-related improvements (week 31), across different participant subgroups.</p></sec><sec><title>Adverse events</title><p>It is not anticipated that there will be any adverse events in this trial. However, should any adverse events be identified, these will be recorded and reported according to the trial sponsor&#x02019;s (Nottingham University Hospitals NHS Trust) Standard Operating Procedures.</p></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>Auditory training is currently used for the clinical management of people with hearing loss despite a lack of published high-quality evidence assessing its efficacy and mechanisms of benefit [<xref ref-type="bibr" rid="B9">9</xref>]. Benefits of auditory training to speech perception abilities of people with hearing loss may lie in bottom-up sensory refinement, top-down cognitive control, or a combination of the bottom-up and top-down improvements [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>]. Although preliminary evidence exists regarding the efficacy of working memory training to improve sentence repetition skills for children with severe to profound hearing loss [<xref ref-type="bibr" rid="B27">27</xref>], this is yet to be examined in other hearing impaired populations.</p><p>The present study aims to generate high-quality preliminary evidence for the efficacy of working memory training to improve cognition, speech perception and self-reported hearing abilities in adults with mild-to-moderate sensorineural hearing loss who are existing hearing aid users. This randomized active controlled trial addresses a number of gaps in the current published literature [<xref ref-type="bibr" rid="B9">9</xref>], offering high-level evidence for the benefits to people with hearing loss that may be offered by a program of working memory training.</p></sec><sec><title>Trial status</title><p>The trial is currently in the recruitment phase. It is expected that recruitment into the study will be complete by 31 January 2014.</p></sec><sec><title>Abbreviations</title><p>dB: Decibel; GHABP: Glasgow hearing aid benefit profile; HHIE: Hearing handicap inventory for the elderly; HL: Hearing loss; MCRM: Modified coordinate response measure; MoCA: Montreal cognitive assessment; PTA: Pure tone average; SICSPAN: Size comparison span; STAR: MRC Institute of Hearing research System for Testing Auditory Responses; TAIL: Test of attention in Listening; TEA: Test of everyday attention.</p></sec><sec><title>Competing interests</title><p>The authors declare they have no competing interests. Manuscripts reporting study results will be reviewed by Cogmed representatives 30&#x000a0;days prior to submission to a peer-reviewed journal. However, the NIHR Nottingham Hearing Biomedical Research Unit has the right to publish all statistical analyses regardless of positive or negative results.</p></sec><sec><title>Authors&#x02019; contributions</title><p>HH and MAF developed the protocol. HH drafted the manuscript. Both authors contributed to editing and approved the final manuscript. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, or the Department of Health.</p></sec></body><back><sec><title>Acknowledgments</title><p>The independent research presented in this article is funded by the National Institute for Health Research (NIHR) Biomedical Research Unit funding program. We would like to thank Deborah Hall and Derek Hoare for comments on an earlier version of this study protocol. Cogmed and Cogmed Working Memory Training are trademarks, in the US and/or other countries, of Pearson Education, Inc. or its affiliate(s).</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Davis</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>P</given-names></name><name><surname>Ferguson</surname><given-names>M</given-names></name><name><surname>Stephens</surname><given-names>D</given-names></name><name><surname>Gianopoulos</surname><given-names>I</given-names></name><article-title>Acceptability, benefit and costs of early screening for hearing disability: a study of potential screening tests and models</article-title><source>Health Technol Assess</source><year>2007</year><volume>11</volume></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Cherry</surname><given-names>EC</given-names></name><article-title>Some experiments on the recognition of speech, with one and with two ears</article-title><source>J Acoust Soc Am</source><year>1953</year><volume>25</volume><fpage>975</fpage><lpage>979</lpage><pub-id pub-id-type="doi">10.1121/1.1907229</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Kiessling</surname><given-names>J</given-names></name><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><name><surname>Gatehouse</surname><given-names>S</given-names></name><name><surname>Stephens</surname><given-names>D</given-names></name><name><surname>Arlinger</surname><given-names>S</given-names></name><name><surname>Chisolm</surname><given-names>T</given-names></name><name><surname>Davis</surname><given-names>AC</given-names></name><name><surname>Erber</surname><given-names>NP</given-names></name><name><surname>Hickson</surname><given-names>L</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name><name><surname>Rosenhall</surname><given-names>U</given-names></name><name><surname>von Wedel</surname><given-names>H</given-names></name><article-title>Candidature for and delivery of audiological services: special needs of older people</article-title><source>Int J Audiol</source><year>2003</year><volume>42</volume><fpage>S92</fpage><lpage>S101</lpage><pub-id pub-id-type="doi">10.3109/14992020309074650</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><article-title>Cognitive aging and auditory information processing</article-title><source>Int J Audiol</source><year>2003</year><volume>42</volume><fpage>2S26</fpage><lpage>2S32</lpage><pub-id pub-id-type="pmid">12918626</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><name><surname>Singh</surname><given-names>G</given-names></name><article-title>Effects of age on auditory and cognitive processing: implications for hearing aid fitting and audiologic rehabilitation</article-title><source>Trends Amplif</source><year>2006</year><volume>10</volume><fpage>29</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1177/108471380601000103</pub-id><pub-id pub-id-type="pmid">16528429</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Edwards</surname><given-names>B</given-names></name><article-title>The future of hearing aid technology</article-title><source>Trends Amplif</source><year>2007</year><volume>11</volume><fpage>31</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1177/1084713806298004</pub-id><pub-id pub-id-type="pmid">17301336</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Amitay</surname><given-names>S</given-names></name><name><surname>Hawkey</surname><given-names>DJC</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name><article-title>Auditory frequency discrimination learning is affected by stimulus variability</article-title><source>Percept Psychophys</source><year>2005</year><volume>67</volume><fpage>691</fpage><lpage>698</lpage><pub-id pub-id-type="doi">10.3758/BF03193525</pub-id><pub-id pub-id-type="pmid">16134462</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Halliday</surname><given-names>LF</given-names></name><name><surname>Taylor</surname><given-names>JL</given-names></name><name><surname>Edmondson-Jones</surname><given-names>AM</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name><article-title>Frequency discrimination learning in children</article-title><source>J Acoust Soc Am</source><year>2008</year><volume>123</volume><fpage>4393</fpage><lpage>4402</lpage><pub-id pub-id-type="doi">10.1121/1.2890749</pub-id><pub-id pub-id-type="pmid">18537390</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Henshaw</surname><given-names>H</given-names></name><name><surname>Ferguson</surname><given-names>MA</given-names></name><article-title>Efficacy of individual computer-based auditory training for people with hearing loss: a systematic review of the evidence</article-title><source>PLoS One</source><year>2013</year><volume>8</volume><fpage>e62836</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0062836</pub-id><pub-id pub-id-type="pmid">23675431</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Moore</surname><given-names>DR</given-names></name><name><surname>Halliday</surname><given-names>L</given-names></name><name><surname>Amitay</surname><given-names>S</given-names></name><article-title>Use of auditory learning to manage listening problems in children</article-title><source>Philosophical Trans Roy Soc B: Biol Sci</source><year>2009</year><volume>364</volume><fpage>409</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0187</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>S</given-names></name><name><surname>White-Schwoch</surname><given-names>T</given-names></name><name><surname>Parbery-Clark</surname><given-names>A</given-names></name><name><surname>Kraus</surname><given-names>N</given-names></name><article-title>Reversal of age-related neural timing delays with training</article-title><source>Proc Natl Acad Sci</source><year>2013</year><volume>110</volume><fpage>4357</fpage><lpage>4362</lpage><pub-id pub-id-type="doi">10.1073/pnas.1213555110</pub-id><pub-id pub-id-type="pmid">23401541</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="other"><name><surname>Ferguson</surname><given-names>M</given-names></name><name><surname>Henshaw</surname><given-names>H</given-names></name><name><surname>Clark</surname><given-names>D</given-names></name><name><surname>Moore</surname><given-names>D</given-names></name><article-title>Benefits of phoneme discrimination training in a randomized controlled trial of 50&#x02013;74 year olds with mild hearing loss</article-title><source>Ear Hear</source><comment>In press</comment></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="book"><name><surname>Engle</surname><given-names>RW</given-names></name><name><surname>Kane</surname><given-names>MJ</given-names></name><article-title>Executive attention, working memory capacity, and a two-factor theory of cognitive control</article-title><source>Psychology of Learning and Motivation, Volume 44</source><year>2003</year><publisher-name>Waltham, MA: Academic Press</publisher-name><fpage>145</fpage><lpage>199</lpage></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Barrouillet</surname><given-names>P</given-names></name><name><surname>Bernardin</surname><given-names>S</given-names></name><name><surname>Camos</surname><given-names>V</given-names></name><article-title>Time constraints and resource sharing in adults&#x02019; working memory spans</article-title><source>J Exp Psychol Gen</source><year>2004</year><volume>133</volume><fpage>83</fpage><lpage>100</lpage><pub-id pub-id-type="pmid">14979753</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Miyake</surname><given-names>A</given-names></name><name><surname>Friedman</surname><given-names>NP</given-names></name><name><surname>Emerson</surname><given-names>MJ</given-names></name><name><surname>Witzki</surname><given-names>AH</given-names></name><name><surname>Howerter</surname><given-names>A</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><article-title>The unity and diversity of executive functions and their contributions to complex &#x0201c;Frontal Lobe&#x0201d; tasks: a latent variable analysis</article-title><source>Cogn Psychol</source><year>2000</year><volume>41</volume><fpage>49</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1006/cogp.1999.0734</pub-id><pub-id pub-id-type="pmid">10945922</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><name><surname>Miyake</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>P</given-names></name><source>Models of Working Memory: Mechanisms of Active Maintenance and Executive Control</source><year>1999</year><publisher-name>Cambridge, UK: Cambridge University Press</publisher-name></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Akeroyd</surname><given-names>MA</given-names></name><article-title>Are individual differences in speech reception related to individual differences in cognitive ability? A survey of twenty experimental studies with normal and hearing-impaired adults</article-title><source>Int J Audiol</source><year>2008</year><volume>47</volume><fpage>53</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1080/14992020802301142</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>R&#x000f6;nnberg</surname><given-names>J</given-names></name><name><surname>Rudner</surname><given-names>M</given-names></name><name><surname>Foo</surname><given-names>C</given-names></name><name><surname>Lunner</surname><given-names>T</given-names></name><article-title>Cognition counts: a working memory system for ease of language understanding (ELU)</article-title><source>Int J Audiol</source><year>2008</year><volume>47</volume><fpage>S99</fpage><lpage>S105</lpage><pub-id pub-id-type="doi">10.1080/14992020802301167</pub-id><pub-id pub-id-type="pmid">19012117</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><name><surname>Kraus</surname><given-names>N</given-names></name><article-title>Biological impact of music and software-based auditory training</article-title><source>J Commun Disord</source><year>2012</year><volume>45</volume><fpage>403</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1016/j.jcomdis.2012.06.005</pub-id><pub-id pub-id-type="pmid">22789822</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="book"><name><surname>Edwards</surname><given-names>B</given-names></name><source>The Effect of Hearing Loss and Hearing Aids on Cognition</source><year>2008</year><publisher-name>Charlotte, NC: American Academy of Audiology Convention, April 2&#x02013;4</publisher-name></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Lunner</surname><given-names>T</given-names></name><name><surname>Rudner</surname><given-names>M</given-names></name><name><surname>R&#x000f6;nnberg</surname><given-names>J</given-names></name><article-title>Cognition and hearing aids</article-title><source>Scand J Psychol</source><year>2009</year><volume>50</volume><fpage>395</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9450.2009.00742.x</pub-id><pub-id pub-id-type="pmid">19778387</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><name><surname>Schneider</surname><given-names>BA</given-names></name><name><surname>Daneman</surname><given-names>M</given-names></name><article-title>How young and old adults listen to and remember speech in noise</article-title><source>J Acoust Soc Am</source><year>1995</year><volume>97</volume><fpage>593</fpage><lpage>608</lpage><pub-id pub-id-type="doi">10.1121/1.412282</pub-id><pub-id pub-id-type="pmid">7860836</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Schneider</surname><given-names>BA</given-names></name><name><surname>Daneman</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>DR</given-names></name><name><surname>Kwong-See</surname><given-names>S</given-names></name><article-title>Listening to discourse in distracting settings: the effects of gaining</article-title><source>Psychol Aging</source><year>2000</year><volume>15</volume><fpage>110</fpage><lpage>125</lpage><pub-id pub-id-type="pmid">10755294</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Kricos</surname><given-names>PB</given-names></name><article-title>Audiological management of older adults with hearing loss and compromised cognitive/psychoacoustic auditory processing capabiliites</article-title><source>Trends Amplif</source><year>2006</year><volume>10</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1177/108471380601000102</pub-id><pub-id pub-id-type="pmid">16528428</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><article-title>Audition and cognition. Where lab meets clinic</article-title><source>ASHA Leader</source><year>2008</year><volume>13</volume><fpage>14</fpage><lpage>17</lpage></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>Brehmer</surname><given-names>Y</given-names></name><name><surname>Westerberg</surname><given-names>H</given-names></name><name><surname>Backman</surname><given-names>L</given-names></name><article-title>Working-memory training in younger and older adults: training gains, transfer, and maintenance</article-title><source>Front Hum Neurosci</source><year>2012</year><volume>6</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="pmid">22279433</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Kronenberger</surname><given-names>WG</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name><name><surname>Henning</surname><given-names>SC</given-names></name><name><surname>Colson</surname><given-names>BG</given-names></name><name><surname>Hazzard</surname><given-names>LM</given-names></name><article-title>Working memory training for children with cochlear implants: a pilot study</article-title><source>J Speech Lang Hear Res</source><year>2010</year><volume>54</volume><fpage>1182</fpage><lpage>1196</lpage><pub-id pub-id-type="pmid">21173394</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="other"><collab>Action on Hearing Loss</collab><article-title>Statistics about deafness and hearing</article-title><comment><ext-link ext-link-type="uri" xlink:href="http://www.actiononhearingloss.org.uk/your-hearing/about-deafness-and-hearing-loss/statistics.aspx">http://www.actiononhearingloss.org.uk/your-hearing/about-deafness-and-hearing-loss/statistics.aspx</ext-link></comment></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Chan</surname><given-names>AW</given-names></name><name><surname>Tetzlaff</surname><given-names>JM</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name><name><surname>Laupacis</surname><given-names>A</given-names></name><name><surname>G&#x000f8;tzsche</surname><given-names>PC</given-names></name><name><surname>Krle&#x0017e;a-Jeri&#x00107;</surname><given-names>K</given-names></name><name><surname>Hr&#x000f3;bjartsson</surname><given-names>A</given-names></name><name><surname>Mann</surname><given-names>H</given-names></name><name><surname>Dickersin</surname><given-names>K</given-names></name><name><surname>Berlin</surname><given-names>JA</given-names></name><name><surname>Dor&#x000e9;</surname><given-names>CJ</given-names></name><name><surname>Parulekar</surname><given-names>WR</given-names></name><name><surname>Summerskill</surname><given-names>WS</given-names></name><name><surname>Groves</surname><given-names>T</given-names></name><name><surname>Schulz</surname><given-names>KF</given-names></name><name><surname>Sox</surname><given-names>HC</given-names></name><name><surname>Rockhold</surname><given-names>FW</given-names></name><name><surname>Rennie</surname><given-names>D</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><article-title>SPIRIT 2013 statement: defining standard protocol items for clinical trials</article-title><source>Ann Intern Med</source><year>2013</year><volume>158</volume><fpage>200</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.7326/0003-4819-158-3-201302050-00583</pub-id><pub-id pub-id-type="pmid">23295957</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="other"><collab>British Society of Audiology</collab><article-title>Pure-tone air- and bone-conduction threshold audiometry with and without masking</article-title><comment><ext-link ext-link-type="uri" xlink:href="http://www.thebsa.org.uk/docs/Guidelines/BSA_RP_PTA_FINAL_24Sept11.pdf">http://www.thebsa.org.uk/docs/Guidelines/BSA_RP_PTA_FINAL_24Sept11.pdf</ext-link></comment></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><name><surname>Nasreddine</surname><given-names>ZS</given-names></name><name><surname>Phillips</surname><given-names>NS</given-names></name><name><surname>B&#x000e9;dirian</surname><given-names>V</given-names></name><name><surname>Charbonneau</surname><given-names>S</given-names></name><name><surname>Whitehead</surname><given-names>V</given-names></name><name><surname>Collin</surname><given-names>I</given-names></name><name><surname>Cummings</surname><given-names>JL</given-names></name><name><surname>Chertkow</surname><given-names>H</given-names></name><article-title>The Montreal Cognitive Assessment, MoCA: a brief screening tool for mild cognitive impairment</article-title><source>J Am Geriatr Soc</source><year>2005</year><volume>53</volume><fpage>695</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1111/j.1532-5415.2005.53221.x</pub-id><pub-id pub-id-type="pmid">15817019</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Gatehouse</surname><given-names>S</given-names></name><name><surname>Naylor</surname><given-names>G</given-names></name><name><surname>Elberling</surname><given-names>C</given-names></name><article-title>Linear and nonlinear hearing aid fittings&#x02013;1. Patterns of benefit</article-title><source>Int J Audiol</source><year>2006</year><volume>45</volume><fpage>130</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1080/14992020500429518</pub-id><pub-id pub-id-type="pmid">16579490</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><name><surname>Moore</surname><given-names>DR</given-names></name><name><surname>Rosenberg</surname><given-names>JF</given-names></name><name><surname>Coleman</surname><given-names>JS</given-names></name><article-title>Discrimination training of phonemic contrasts enhances phonological processing in mainstream school children</article-title><source>Brain Lang</source><year>2005</year><volume>94</volume><fpage>72</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2004.11.009</pub-id><pub-id pub-id-type="pmid">15896385</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="book"><name><surname>Heinrich</surname><given-names>A</given-names></name><name><surname>Bruhn</surname><given-names>K</given-names></name><name><surname>Hawkins</surname><given-names>S</given-names></name><person-group person-group-type="editor">Algom D, Zakay D, Chajut E, Shaki S, Mama Y, Shakuf V</person-group><article-title>Young and old listeners&#x02019; perceptions of speech in a background of English- and foreign-accented babble</article-title><source>Proceedings of the 27th Annual Meeting of the International Society for Psychophysics</source><year>2011</year><publisher-name>Raanana, Israel</publisher-name></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><name><surname>Bilger</surname><given-names>RC</given-names></name><name><surname>Nuetzel</surname><given-names>JM</given-names></name><name><surname>Rabinowitz</surname><given-names>WM</given-names></name><name><surname>Rezeczkowski</surname><given-names>C</given-names></name><article-title>Standardization of a test of speech perception in noise</article-title><source>J Speech Hear Res</source><year>1984</year><volume>27</volume><fpage>32</fpage><lpage>48</lpage><pub-id pub-id-type="pmid">6717005</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><name><surname>Hazan</surname><given-names>V</given-names></name><name><surname>Messaoud-Galusi</surname><given-names>S</given-names></name><name><surname>Rosen</surname><given-names>S</given-names></name><name><surname>Nouwens</surname><given-names>S</given-names></name><name><surname>Shakespeare</surname><given-names>B</given-names></name><article-title>Speech perception abilities of adults with dyslexia: is there any evidence for a true defecit?</article-title><source>J Speech Lang Hear Res</source><year>2009</year><volume>52</volume><fpage>1510</fpage><lpage>1529</lpage><pub-id pub-id-type="doi">10.1044/1092-4388(2009/08-0220)</pub-id><pub-id pub-id-type="pmid">19635940</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><name><surname>Bolia</surname><given-names>RS</given-names></name><name><surname>Nelson</surname><given-names>WT</given-names></name><name><surname>Ericson</surname><given-names>MA</given-names></name><name><surname>Simpson</surname><given-names>BD</given-names></name><article-title>A speech corpus for multitalker communications research</article-title><source>J Acoust Soc Am</source><year>2000</year><volume>107</volume><fpage>1065</fpage><lpage>1066</lpage><pub-id pub-id-type="doi">10.1121/1.428288</pub-id><pub-id pub-id-type="pmid">10687719</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><name><surname>Wechsler</surname><given-names>D</given-names></name><source>Wechsler Adult Intelligence Scale</source><year>1997</year><edition>3</edition><publisher-name>San Antonio, TX: The Psychological Corporation</publisher-name></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>YX</given-names></name><name><surname>Barry</surname><given-names>JG</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name><name><surname>Amitay</surname><given-names>S</given-names></name><article-title>A new test of attention in listening (TAIL) predicts auditory performance</article-title><source>PLoS One</source><year>2012</year><volume>7</volume><fpage>1</fpage><lpage>12</lpage></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><name><surname>Ventry</surname><given-names>IM</given-names></name><name><surname>Woods</surname><given-names>RW</given-names></name><name><surname>Rubin</surname><given-names>M</given-names></name><name><surname>Hill</surname><given-names>W</given-names></name><article-title>Most comfortable loudness for pure tones, noise, and speech</article-title><source>J Acoust Soc Am</source><year>1971</year><volume>49</volume><fpage>1805</fpage><lpage>1813</lpage><pub-id pub-id-type="doi">10.1121/1.1912585</pub-id><pub-id pub-id-type="pmid">5125727</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Ward</surname><given-names>T</given-names></name><name><surname>Ridgeway</surname><given-names>V</given-names></name><name><surname>Nimmo-Smith</surname><given-names>I</given-names></name><source>The Test of Everyday Attention</source><year>1994</year><publisher-name>Thames Valley Test Company: Bury St, Edmunds, UK</publisher-name></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><name><surname>Sorqvist</surname><given-names>P</given-names></name><name><surname>Ljungberg</surname><given-names>JK</given-names></name><name><surname>Ljung</surname><given-names>R</given-names></name><article-title>A sub-process view of working memory capacity: evidence from effects of speech on prose memory</article-title><source>Memory</source><year>2010</year><volume>18</volume><fpage>310</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1080/09658211003601530</pub-id><pub-id pub-id-type="pmid">20182946</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><name><surname>Howard</surname><given-names>CS</given-names></name><name><surname>Munro</surname><given-names>KJ</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name><article-title>Listening effort at signal-to-noise ratios that are typical of the school classroom</article-title><source>Int J Audiol</source><year>2010</year><volume>49</volume><fpage>928</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.3109/14992027.2010.520036</pub-id><pub-id pub-id-type="pmid">21047295</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><name><surname>Boothroyd</surname><given-names>A</given-names></name><article-title>Developments in speech audiometry</article-title><source>Br J Audiol</source><year>1968</year><volume>2</volume><fpage>3</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3109/00381796809075436</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><name><surname>Gatehouse</surname><given-names>S</given-names></name><article-title>Glasgow hearing aid benefit profile: derivation and validation of client-centred outcome measures for hearing aid services</article-title><source>J Am Acad Audiol</source><year>1999</year><volume>10</volume><fpage>80</fpage><lpage>103</lpage></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><name><surname>Newman</surname><given-names>CW</given-names></name><name><surname>Weinstein</surname><given-names>BE</given-names></name><article-title>The hearing handicap inventory for the elderly as a measure of hearing aid benefit</article-title><source>Amplification Aural Rehabil</source><year>1988</year><volume>9</volume><fpage>81</fpage><lpage>85</lpage></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="book"><name><surname>Altman</surname><given-names>D</given-names></name><source>Practical Statistics for Medical Research</source><year>1991</year><publisher-name>London, UK: Chapman &#x00026; Hall</publisher-name></mixed-citation></ref></ref-list></back></article>