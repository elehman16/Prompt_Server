<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PeerJ</journal-id><journal-id journal-id-type="iso-abbrev">PeerJ</journal-id><journal-id journal-id-type="pmc">PeerJ</journal-id><journal-id journal-id-type="publisher-id">PeerJ</journal-id><journal-title-group><journal-title>PeerJ</journal-title></journal-title-group><issn pub-type="epub">2167-8359</issn><publisher><publisher-name>PeerJ Inc.</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25337457</article-id><article-id pub-id-type="pmc">4203023</article-id><article-id pub-id-type="publisher-id">589</article-id><article-id pub-id-type="doi">10.7717/peerj.589</article-id><article-categories><subj-group subj-group-type="heading"><subject>Epidemiology</subject></subj-group><subj-group subj-group-type="heading"><subject>Science and Medical Education</subject></subj-group><subj-group subj-group-type="heading"><subject>Science Policy</subject></subj-group><subj-group subj-group-type="heading"><subject>Statistics</subject></subj-group><subj-group subj-group-type="heading"><subject>Human&#x02013;Computer Interaction</subject></subj-group></article-categories><title-group><article-title>A randomized trial in a massive online open course shows people don&#x02019;t know what a statistically significant relationship looks like, but they can learn</article-title></title-group><contrib-group><contrib id="author-1" contrib-type="author"><name><surname>Fisher</surname><given-names>Aaron</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib><contrib id="author-2" contrib-type="author"><name><surname>Anderson</surname><given-names>G. Brooke</given-names></name><xref ref-type="aff" rid="aff-2">2</xref></contrib><contrib id="author-3" contrib-type="author"><name><surname>Peng</surname><given-names>Roger</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib><contrib id="author-4" contrib-type="author" corresp="yes"><name><surname>Leek</surname><given-names>Jeff</given-names></name><xref ref-type="aff" rid="aff-1">1</xref><email>jleek@jhsph.edu</email></contrib><aff id="aff-1"><label>1</label><institution>Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health</institution>, <addr-line>Baltimore, MD</addr-line>, <country>USA</country></aff><aff id="aff-2"><label>2</label><institution>Department of Environmental &#x00026; Radiological Health Sciences, Colorado State University</institution>, <addr-line>Fort Collins, CO</addr-line>, <country>USA</country></aff></contrib-group><contrib-group><contrib id="editor-1" contrib-type="editor"><name><surname>Engelhardt</surname><given-names>Barbara</given-names></name></contrib></contrib-group><pub-date pub-type="epub" date-type="pub" iso-8601-date="2014-10-16"><day>16</day><month>10</month><year iso-8601-date="2014">2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>2</volume><elocation-id>e589</elocation-id><history><date date-type="received" iso-8601-date="2014-06-13"><day>13</day><month>6</month><year iso-8601-date="2014">2014</year></date><date date-type="accepted" iso-8601-date="2014-09-01"><day>1</day><month>9</month><year iso-8601-date="2014">2014</year></date></history><permissions><copyright-statement>&#x000a9; 2014 Fisher et al.</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Fisher et al.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p></license></permissions><self-uri xlink:href="https://peerj.com/articles/589"/><abstract><p>Scatterplots are the most common way for statisticians, scientists, and the public to visually detect relationships between measured variables. At the same time, and despite widely publicized controversy, <italic>P</italic>-values remain the most commonly used measure to statistically justify relationships identified between variables. Here we measure the ability to detect statistically significant relationships from scatterplots in a randomized trial of 2,039 students in a statistics massive open online course (MOOC). Each subject was shown a random set of scatterplots and asked to visually determine if the underlying relationships were statistically significant at the <italic>P</italic> &#x0003c; 0.05 level. Subjects correctly classified only 47.4% (95% CI [45.1%&#x02013;49.7%]) of statistically significant relationships, and 74.6% (95% CI [72.5%&#x02013;76.6%]) of non-significant relationships. Adding visual aids such as a best fit line or scatterplot smooth increased the probability a relationship was called significant, regardless of whether the relationship was actually significant. Classification of statistically significant relationships improved on repeat attempts of the survey, although classification of non-significant relationships did not. Our results suggest: (1) that evidence-based data analysis can be used to identify weaknesses in theoretical procedures in the hands of average users, (2) data analysts can be trained to improve detection of statistically significant results with practice, but (3) data analysts have incorrect intuition about what statistically significant relationships look like, particularly for small effects. We have built a web tool for people to compare scatterplots with their corresponding <italic>p</italic>-values which is available here: <uri xlink:href="http://glimmer.rstudio.com/afisher/EDA/">http://glimmer.rstudio.com/afisher/EDA/</uri>.</p></abstract><kwd-group kwd-group-type="author"><kwd>Evidenced based data analysis</kwd><kwd>Statistics</kwd><kwd><italic>p</italic>-values</kwd><kwd>MOOC</kwd><kwd>Randomized trial</kwd><kwd>Statistical significance</kwd><kwd>Data visualization</kwd><kwd>Education</kwd></kwd-group><funding-group><award-group id="fund-1"><funding-source>National Institute of Environmental Health Sciences</funding-source><award-id>T32ES012871</award-id></award-group><funding-statement>This research was partially supported by the National Institute of Environmental Health Sciences (grant number T32ES012871). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>Over the last two decades there has been a dramatic increase in the amount and variety of data available to scientists, physicians, and business leaders in nearly every area of application. Statistical literacy is now critical for anyone consuming data analysis reports, including scientific papers, newspaper reports (<xref rid="ref-3" ref-type="bibr">Beyth-Marom, Fidler &#x00026; Cumming, 2008</xref>), legal cases (<xref rid="ref-8" ref-type="bibr">Gastwirth, 1988</xref>), and medical test results (<xref rid="ref-18" ref-type="bibr">Schwartz et al., 1997</xref>; <xref rid="ref-19" ref-type="bibr">Sheridan, Pignone &#x00026; Lewis, 2003</xref>). A lack of sufficient training in statistics and data analysis has been responsible for the retraction of high-profile papers (<xref rid="ref-11" ref-type="bibr">Ledford, 2011</xref>), the cancellation of clinical trials (<xref rid="ref-16" ref-type="bibr">Pelley, 2012</xref>), and mistakes in papers used to justify major economic policy initiatives (<xref rid="ref-4" ref-type="bibr">Cassidy, 2013</xref>).</p><p>Despite the critical importance of statistics and data analysis in modern life, we have relatively little empirical evidence about how statistical tools work in the hands of typical analysts and consumers. The most well-studied statistical tool is the visual display of quantitative information. Previous studies have shown that humans have difficulty interpreting linear measures of correlation (<xref rid="ref-5" ref-type="bibr">Cleveland, 1982</xref>), are better at judging relative positions than relative angles (<xref rid="ref-9" ref-type="bibr">Heer &#x00026; Bostock, 2010</xref>; <xref rid="ref-6" ref-type="bibr">Cleveland &#x00026; McGill, 1985</xref>), and view correlations differently when plotted on different scales (<xref rid="ref-5" ref-type="bibr">Cleveland, 1982</xref>). These studies show that mathematically correct statistical procedures may have unintended consequences in the hands of users. The real effect of a statistical procedure depends, to a large extent, on psychology and cognitive function.</p><p>Here we perform a large-scale study of the ability of average data analysts to detect statistically significant relationships from scatterplots. Our study compares two of the most common data analysis tasks, making scatterplots and calculating <italic>P</italic>-values. It has been estimated that as many as 80% of the plots published across all scientific disciplines are scatterplots (<xref rid="ref-20" ref-type="bibr">Tufte &#x00026; Graves-Morris, 1983</xref>). At the same time, and despite widely publicized controversy over their use (<xref rid="ref-15" ref-type="bibr">Nuzzo, 2014</xref>), <italic>P</italic>-values remain the most common choice for reporting a statistical summary of the relationship between two variables in the scientific literature. In the decade 2000&#x02013;2010, 15,653 <italic>P</italic>-values were reported in the abstracts of the <italic>The Lancet</italic>, <italic>The Journal of the American Medical Association</italic>, <italic>The New England Journal of Medicine</italic>, <italic>The British Medical Journal</italic>, and <italic>The American Journal of Epidemiology</italic> (<xref rid="ref-10" ref-type="bibr">Jager &#x00026; Leek, 2007</xref>).</p><p>Data analysts frequently use exploratory scatterplots for model selection and building. Selecting which variables to include in a model can be viewed as visual hypothesis testing where the test statistic is the plot and the measure of significance is human judgement. However, it is not well known how accurately humans can visually classify significance when looking at graphs of raw data. This classification task depends on both understanding what combinations of sample size and effect size constitute significant relationships, and being able to visually distinguish these effect sizes. We performed a set of experiments to (1) estimate the baseline accuracy with which subjects could visually determine if two variables showed a statistically significant relationship; (2) test whether accuracy in visually classifying significance was changed by the number of data points in the plot or the way the plot was presented; and (3) test whether accuracy in visually classifying significance improved with practice. Our intuition is that potential improvements with practice would be better explained by an improved cognitive understanding of statistical significance, rather than an improved perceptive ability to distinguish effect sizes.</p></sec><sec sec-type="methods"><title>Methods and Results</title><p>Our study was conducted within the infrastructure of a statistics massive online open course (MOOC). While MOOCs have previously been used to study MOOCs (<xref rid="ref-7" ref-type="bibr">Do et al., 2013</xref>; <xref rid="ref-13" ref-type="bibr">Mak, Williams &#x00026; Mackness, 2010</xref>; <xref rid="ref-12" ref-type="bibr">Liyanagunawardena, Adams &#x00026; Williams, 2013</xref>), to our knowledge this is the first example of a MOOC being used to study the practice of science. Specifically, our survey was conducted as an ungraded, voluntary exercise within the Spring 2013 Data Analysis Coursera class. This class was 8 weeks long, and consisted of lecture content, readings, and a weekly quiz. Although 121,257 students registered for the course, only 5,306 completed the final weekly quiz. The survey was made available to all students in the class, and 2,039 students responded&#x02014;approximately 38% relative to the number of active users. In one of the weekly quizzes preceding the survey, students were asked two questions relating to the concept of <italic>P</italic>-values (see <xref ref-type="supplementary-material" rid="supp-1">Supplemental Information</xref> for specific question text). Students had two attempts at each question and their accuracies were: 73.5% (1st attempt, 1st question), 96.1% (2nd attempt, 1st question), 73.1% (1st attempt, 2nd question), and 95.4% (2nd attempt, 2nd question). These questions were not identical to the questions in our survey but suggest that students understand the concepts behind a <italic>P</italic>-value, assuming that almost all students completed the graded quizzes before submitting responses to the optional exercises that followed.</p><p>Each student who participated in the survey was shown a set of bi-variate scatterplots (examples shown in <xref ref-type="fig" rid="fig-1">Fig. 1</xref>). The set of plots included eight plots from seven different categories (<xref ref-type="table" rid="table-1">Table 1</xref>), with two plots from the reference category (of which one was significant and one was not) and one plot from each of the other categories (each randomly chosen to be either significant or non-significant). These plot categories (<xref ref-type="table" rid="table-1">Table 1</xref>) were selected to allow analysis of whether students&#x02019; accuracy in visually classifying significance changed based on the number of data points in the plot, or the plot&#x02019;s presentation style. Each set of plots shown to a user was randomly selected from a library containing 10 plots from each category (see <xref ref-type="supplementary-material" rid="supp-1">Supplemental Information</xref> for full library and generating code), of which half were statistically significant (<italic>P</italic>-values from testing the slope coefficient in a linear regression relating <italic>X</italic> and <italic>Y</italic> were between 0.023 and 0.025; e.g., <xref ref-type="fig" rid="fig-1">Fig. 1A</xref>) and half were not statistically significant (<italic>P</italic>-values between 0.33 and 0.35; e.g., <xref ref-type="fig" rid="fig-1">Fig. 1B</xref>).</p><fig id="fig-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.589/fig-1</object-id><label>Figure 1</label><caption><title>Examples of plots shown to users.</title></caption><graphic xlink:href="peerj-02-589-g001"/></fig><table-wrap id="table-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.589/table-1</object-id><label>Table 1</label><caption><title>Plot categories shown to users.</title></caption><alternatives><graphic xlink:href="peerj-02-589-g004"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col align="justify" span="1"/></colgroup><tbody><tr><td rowspan="1" colspan="1">Reference</td><td style="text-align:left;" rowspan="1" colspan="1">100 data points (e.g., <xref ref-type="fig" rid="fig-1">Fig. 1</xref>)</td></tr><tr><td rowspan="1" colspan="1">Smaller <italic>n</italic></td><td style="text-align:left;" rowspan="1" colspan="1">35 data points</td></tr><tr><td rowspan="1" colspan="1">Larger <italic>n</italic></td><td style="text-align:left;" rowspan="1" colspan="1">200 data points</td></tr><tr><td rowspan="1" colspan="1">Best-fit line</td><td style="text-align:left;" rowspan="1" colspan="1">100 data points, with best fit line added</td></tr><tr><td rowspan="1" colspan="1">Lowess</td><td style="text-align:left;" rowspan="1" colspan="1">100 data points, with smooth lowess curve added (using R &#x0201c;lowess&#x0201d; function)</td></tr><tr><td rowspan="1" colspan="1">Axis Scale</td><td style="text-align:left;" rowspan="1" colspan="1">100 data points, with the axis range increased to 1.5 standard deviations outside <italic>X</italic> and <italic>Y</italic> variable ranges<break/>(e.g., &#x0201c;zoomed out&#x0201d;) (<xref rid="ref-5" ref-type="bibr">Cleveland, 1982</xref>)</td></tr><tr><td rowspan="1" colspan="1">Axis Label</td><td style="text-align:left;" rowspan="1" colspan="1">100 data points, with fictional <italic>X</italic>- and <italic>Y</italic>-axis labels added corresponding to activation in a brain region<break/>(e.g., &#x0201c;Cranial Electrode 33 (Standardized)&#x0201d; versus &#x0201c;Cranial Electrode 92 (Standardized)&#x0201d;)</td></tr></tbody></table></alternatives></table-wrap><p>For each plot, students were asked to visually determine whether the bi-variate relationship shown was statistically significant at the 0.05 level (in the example plots shown in <xref ref-type="fig" rid="fig-1">Fig. 1</xref>, the correct answer would have been &#x0201c;statistically significant&#x0201d; for <xref ref-type="fig" rid="fig-1">Fig. 1A</xref> for which the <italic>P</italic>-value of a linear relationship between the <italic>X</italic> and <italic>Y</italic> variables is 0.024, and &#x0201c;not statistically significant&#x0201d; for <xref ref-type="fig" rid="fig-1">Fig. 1B</xref> for which the <italic>P</italic>-value is 0.341). All eight plots were shown at the same time and students submitted responses for all plots in a single submission. Students were also able to submit a partial response by leaving some of the survey questions blank. 94.4% of users completed their first attempt of the survey. After submitting their responses, students were shown the correct answers and given the opportunity to retake the survey with a new set of plots. Students were not told any information about the structure of the survey and so were not able to use the structure of the survey (e.g., the fact that one of the &#x0201c;Reference&#x0201d; plots was significant and one was not) to improve their accuracy.</p><p>To analyze responses, we created separate models for the probability of correctly visually classifying significance in: (1) graphs that showed two variables with a statistically significant relationship (e.g., <xref ref-type="fig" rid="fig-1">Fig. 1A</xref>) and (2) graphs that showed two variables with a statistically non-significant relationship (e.g., <xref ref-type="fig" rid="fig-1">Fig. 1B</xref>). These two types of visual classification correspond to the separate accuracy metrics: human sensitivity to significance (accuracy in giving a positive result in cases where a condition is true) and human specificity to non-significance (accuracy in giving a negative result in cases where a condition is false). In this framework, the hypothetical baseline case where humans have no ability to classify significance corresponds to the sensitivity rate being equal to one minus the specificity rate, which means that the probability of visually classifying a plot as significant is unaffected by the actual significance level of the plot. Accuracy in both metrics was modeled by logistic regressions with person-specific random intercept terms, using the &#x0201c;lme4&#x0201d; package in R (see <xref ref-type="supplementary-material" rid="supp-1">Supplemental Information</xref>).</p><fig id="fig-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.589/fig-2</object-id><label>Figure 2</label><caption><title>Accuracy of significance classifications under different conditions.</title><p>Point estimates and confidence intervals for classification accuracy for each presentation style (<xref ref-type="table" rid="table-1">Table 1</xref>). Accuracy rates for plots with truly significant underlying relationships (sensitivity) are shown in blue, and accuracy rates for plots with non-significant underlying relationships (specificity) are shown in red.</p></caption><graphic xlink:href="peerj-02-589-g002"/></fig><p>We found that, overall, subjects tended to be conservative in their classifications of significance. In the reference category (100 data points; <xref ref-type="table" rid="table-1">Table 1</xref>, examples in <xref ref-type="fig" rid="fig-1">Fig. 1</xref>), students accurately classified graphs of significant relationships as significant only 47.4% (95% CI [45.1%&#x02013;49.7%]) of the time (i.e., 47.4% sensitivity) and accurately classified graphs of non-significant relationships as non-significant 74.6% (95% CI [72.5%&#x02013;76.6%]) of the time (i.e., 74.6% specificity) (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>). Specificity exceeded sensitivity across all of the plot categories presented (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>).</p><p>When comparing the reference plot category of 100 data points to other plot categories (<xref ref-type="table" rid="table-1">Table 1</xref>), sensitivity and specificity were in some cases significantly changed by the number of points displayed in the graph or the style of graph presentation (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>). Changes to the plots that increased sensitivity correlated with changes that decreased specificity. For example, reducing the number of data points shown (&#x0201c;Smaller <italic>n</italic>&#x0201d; plot category) significantly decreased sensitivity (Odds Ratio (OR) = 0.454, 95% CI [0.385&#x02013;0.535]) and increased specificity (OR = 1.67, 95% CI [1.39&#x02013;2.04]). Adding visual aids (best-fit line, lowess curve) significantly improved sensitivity (OR = 1.62 and 1.26 respectively, with 95% CIs [1.38&#x02013;1.89] and 1.08&#x02013;1.47), but significantly reduced specificity (OR = 0.600 and 0.699 respectively, with 95% CIs [0.508&#x02013;0.709] and 0.590&#x02013;0.829). Changing the scale of the axes also increased sensitivity (OR = 1.32, 95% CI [1.13&#x02013;1.55]), but decreased specificity (OR = 0.670, 95% CI [0.567&#x02013;0.792]). Finally, changing the axes label had no significant effect on sensitivity (OR = 1.02, 95% CI [0.871&#x02013;1.19]) and only a marginally significant effect on specificity (OR = 0.811, 95% CI [0.682&#x02013;0.965]). Because any gain in either specificity or sensitivity tended to come at the cost of the other, none of these plot categories represented a uniform increase in accuracy across all true significance levels of the data underlying the plots.</p><p>The exception to this counter-balancing trend came in &#x0201c;Larger <italic>n</italic>&#x0201d; plots of 200 data points, where students showed a significant drop in specificity (OR = 0.320, 95% CI [0.271&#x02013;0.377]), and no significant change in sensitivity (OR = 0.891, 95% CI [0.763&#x02013;1.04]). For plots in this category, the probability that users would classify a relationship as significant was fairly similar across truly significant plots and nonsignificant plots. One possible explanation for this is that larger samples require a lower correlation to attain the same significance level. If the correlation becomes imperceptibly small, then the probability that an observer classifies a relationship as significant might be less affected by the true significance level of the plot.</p><p>To test if accuracy in visually classifying significance improved with practice, we selected only the students who submitted the quiz multiple times (101 students) and compared accuracy rates between these students&#x02019; first and second attempts. Of these students, 92% completed their first attempt of the survey, and 99% completed their second attempt of the survey. Because these students self-selected to take the survey twice, they may not form a representative sample of the broader population. However, they may still be representative of motivated students who wish to improve their statistical skills.</p><fig id="fig-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.589/fig-3</object-id><label>Figure 3</label><caption><title>Classification accuracy on repeat attempts of the survey.</title><p>Each plot shows point estimates and confidence intervals for accuracy rates of human visual classifications of statistical significance on the first and second attempt of the survey. For the truly significant underlying <italic>P</italic>-values, users showed a significant increase in accuracy (sensitivity) on the second attempt of the survey for the &#x0201c;Reference,&#x0201d; &#x0201c;Smaller <italic>n</italic>,&#x0201d; and &#x0201c;Best Fit&#x0201d; presentation styles. For non-significant underlying <italic>P</italic>-values, accuracy (specificity) decreased significantly for the &#x0201c;Smaller <italic>n</italic>&#x0201d; category. Because these accuracy rates were estimated only based on the data from students who submitted more than one response to the survey, the confidence intervals here are wider than those in <xref ref-type="fig" rid="fig-2">Fig. 2</xref>.</p></caption><graphic xlink:href="peerj-02-589-g003"/></fig><p>We found that, for the &#x0201c;Reference&#x0201d;, &#x0201c;Best Fit&#x0201d;, and &#x0201c;Smaller <italic>n</italic>&#x0201d; categories, sensitivity improved significantly on the second attempt of the survey (OR = 5.27, 2.98, and 4.51, with 95% CIs [2.69&#x02013;10.33], [1.28&#x02013;6.92], and [1.79&#x02013;11.37]; <xref ref-type="fig" rid="fig-3">Fig. 3</xref>). For the &#x0201c;Reference&#x0201d; and &#x0201c;Best Fit&#x0201d; categories, the sensitivity improvements were not associated with significant changes in specificity, indicating an improvement in overall accuracy in the visual classification of significance. In the &#x0201c;Smaller <italic>n</italic>&#x0201d; plot category however, the increased sensitivity came at the cost of a significant decrease in specificity (OR = 0.163, 95% CI [0.059&#x02013;0.447]). For plots in this &#x0201c;Smaller <italic>n</italic>&#x0201d; category, practice did not necessarily improve overall accuracy in visually classifying significance, but rather increased a student&#x02019;s odds of classifying any graph as &#x0201c;significant&#x0201d;, regardless of whether the relationship it displayed was truly significant. It is possible that this was due to students over-correcting for their conservatism on their first attempts of the survey. For remaining plot categories (&#x0201c;Larger <italic>n</italic>&#x0201d;, &#x0201c;Axis Label&#x0201d;, &#x0201c;Lowess&#x0201d;, &#x0201c;Axis Scale&#x0201d;), there were no statistically significant changes in sensitivity or specificity between first and second attempts.</p></sec><sec sec-type="discussion"><title>Discussion</title><p>Our research focuses on the question of how accurately statistical significance can be visually perceived in scatterplots of raw data. This work is a logical extension of previous studies on the visual perception of correlation in raw data scatterplots (<xref rid="ref-5" ref-type="bibr">Cleveland, 1982</xref>; <xref rid="ref-14" ref-type="bibr">Meyer &#x00026; Shinar, 1992</xref>; <xref rid="ref-17" ref-type="bibr">Rensink &#x00026; Baldridge, 2010</xref>), and on the visual perception of plotted confidence intervals in the absence of raw data (<xref rid="ref-1" ref-type="bibr">Belia et al., 2005</xref>). The results of this trial are not only relevant towards anyone who wishes to more intuitively understand <italic>P</italic>-values in scientific literature, but also towards designers and observers of scatterplots. Designers of plots should keep in mind that adding trend lines to a plot tends to make viewers more likely to perceive the underlying relationship as significant, regardless of the relationship&#x02019;s actual significance level, so that they can prevent their plots from misleading viewers. Similarly, viewers of scatterplots may want to slightly discount their perception of statistical significance when trend lines are shown.</p><p>Our results also suggest that, on average, readers can improve their ability to visually perceive statistical significance through practice. Our intuition is that this improvement is better explained by an improved understanding of what effect sizes constitute significant relationships, rather than an improved ability to visually distinguish these effect sizes. It would follow that the apparent baseline poor accuracy in visually detecting significance is largely due to a false intuition for what constitutes significant relationships. A broad movement towards practicing the task of visually classifying significance could improve this intuition, and better the efficiency and clarity of communication in science. To help readers train their sense for <italic>P</italic>-values, we&#x02019;ve created an interactive online application where users can explore the connection between the significance level of a bi-variate relationship and how the data for that relationship appears in a scatterplot (<uri xlink:href="http://glimmer.rstudio.com/afisher/EDA/">http://glimmer.rstudio.com/afisher/EDA/</uri>). Users can see the visual effect of changing sample size while holding the <italic>P</italic>-value constant. They can also add lowess curves and best-fit lines to the scatterplot.</p><p>This work is also relevant to debate over the misuse of EDA. It has been argued that when EDA and formal hypothesis testing are applied to the same dataset, the &#x0201c;data snooping&#x0201d; committed through EDA process can increase the Type I error rates of the formal hypothesis tests (<xref rid="ref-2" ref-type="bibr">Berk, Brown &#x00026; Zhao, 2010</xref>). However, the apparently low sensitivity with which humans can detect statistically significant relationships in scatterplots implies that both the costs of EDA misuse, as well as the benefits of responsibly conducted EDA, may be smaller than expected.</p><p>Data analysis involves the application of statistical methods. Our study highlights that even when the theoretical properties of a statistic are well understood, the actual behavior in the hands of data analysts may not be known. Our study highlights the need for placing the practice of data analysis on a firm scientific footing through experimentation. We call this idea of evidence based data analysis, as it closely parallels the idea of evidence based medicine, the term for scientifically studying the impact of clinical practice. Evidence based data analysis studies the practical efficacy of a broad range of statistical methods when used, sometimes imperfectly, by analysts with different levels of statistical training. Further research in evidence based data analysis may be one way to reduce the well-documented problems with reproducibility and replicability of complicated data analyses.</p></sec><sec sec-type="supplementary-material" id="supplemental-information"><title>Supplemental Information</title><supplementary-material content-type="local-data" id="supp-1"><object-id pub-id-type="doi">10.7717/peerj.589/supp-1</object-id><label>Supplemental Information</label><caption><title>Supplementary Text Revision</title></caption><media xlink:href="peerj-02-589-s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><sec sec-type="additional-information"><title>Additional Information and Declarations</title><fn-group content-type="competing-interests"><title>Competing Interests</title><fn id="conflict-1" fn-type="con"><p>The authors declare there are no competing interests.</p></fn></fn-group><fn-group content-type="author-contributions"><title>Author Contributions</title><fn id="contribution-1" fn-type="con"><p><xref ref-type="contrib" rid="author-1">Aaron Fisher</xref> conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, reviewed drafts of the paper.</p></fn><fn id="contribution-2" fn-type="con"><p><xref ref-type="contrib" rid="author-2">G. Brooke Anderson</xref> and <xref ref-type="contrib" rid="author-4">Jeff Leek</xref> conceived and designed the experiments, performed the experiments, contributed reagents/materials/analysis tools, wrote the paper, reviewed drafts of the paper.</p></fn><fn id="contribution-3" fn-type="con"><p><xref ref-type="contrib" rid="author-3">Roger Peng</xref> conceived and designed the study and helped write the paper.</p></fn></fn-group><fn-group content-type="other"><title>Human Ethics</title><fn id="addinfo-1" fn-type="other"><p>The following information was supplied relating to ethical approvals (i.e., approving body and any reference numbers):</p><p>Johns Hopkins Bloomberg School of Public Health IRB Approval number: IRB00005072, 45 CFR 46.101(b)(4).</p></fn></fn-group><fn-group content-type="other"><title>Data Deposition</title><fn id="addinfo-2" fn-type="other"><p>The following information was supplied regarding the deposition of related data:</p><p><uri xlink:href="https://github.com/aaronjfisher/visual_pvalue/tree/master">https://github.com/aaronjfisher/visual_pvalue/tree/master</uri>.</p></fn></fn-group></sec><ref-list content-type="authoryear"><title>References</title><ref id="ref-1"><label>Belia et al. (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belia</surname><given-names>S</given-names></name><name><surname>Fidler</surname><given-names>F</given-names></name><name><surname>Williams</surname><given-names>J</given-names></name><name><surname>Cumming</surname><given-names>G</given-names></name></person-group><article-title>Researchers misunderstand confidence intervals and standard error bars</article-title><source>Psychological Methods</source><year>2005</year><volume>10</volume><fpage>389</fpage><lpage>396</lpage><pub-id pub-id-type="doi">10.1037/1082-989X.10.4.389</pub-id><pub-id pub-id-type="pmid">16392994</pub-id></element-citation></ref><ref id="ref-2"><label>Berk, Brown &#x00026; Zhao (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berk</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>L</given-names></name><name><surname>Zhao</surname><given-names>L</given-names></name></person-group><article-title>Statistical inference after model selection</article-title><source>Journal of Quantitative Criminology</source><year>2010</year><volume>26</volume><fpage>217</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1007/s10940-009-9077-7</pub-id></element-citation></ref><ref id="ref-3"><label>Beyth-Marom, Fidler &#x00026; Cumming (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beyth-Marom</surname><given-names>R</given-names></name><name><surname>Fidler</surname><given-names>F</given-names></name><name><surname>Cumming</surname><given-names>G</given-names></name></person-group><article-title>Statistical cognition: towards evidence-based practice in statistics and statistics education</article-title><source>Statistics Education Research Journal</source><year>2008</year><volume>7</volume><fpage>20</fpage><lpage>39</lpage></element-citation></ref><ref id="ref-4"><label>Cassidy (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cassidy</surname><given-names>J</given-names></name></person-group><article-title>The reinhart and rogoff controversy: a summing up</article-title><source>The New Yorker</source><year>2013</year><comment><italic>Available at <uri xlink:href="http://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up">http://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up</uri></italic> (accessed 21 August 2014)</comment></element-citation></ref><ref id="ref-5"><label>Cleveland (1982)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleveland</surname><given-names>WS</given-names></name><name><surname>Diaconis</surname><given-names>P</given-names></name><name><surname>McGill</surname><given-names>R</given-names></name></person-group><article-title>Variables on scatterplots look more highly correlated when the scales are increased</article-title><source>Science</source><year>1982</year><volume>216</volume><fpage>1138</fpage><lpage>1141</lpage><pub-id pub-id-type="doi">10.1126/science.216.4550.1138</pub-id><pub-id pub-id-type="pmid">17808503</pub-id></element-citation></ref><ref id="ref-6"><label>Cleveland &#x00026; McGill (1985)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cleveland</surname><given-names>WS</given-names></name><name><surname>McGill</surname><given-names>R</given-names></name></person-group><article-title>Graphical perception and graphical methods for analyzing scientific data</article-title><source>Science</source><year>1985</year><volume>229</volume><fpage>828</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1126/science.229.4716.828</pub-id><pub-id pub-id-type="pmid">17777913</pub-id></element-citation></ref><ref id="ref-7"><label>Do et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Do</surname><given-names>CB</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Brandman</surname><given-names>R</given-names></name><name><surname>Koller</surname><given-names>D</given-names></name></person-group><article-title>Self-driven mastery in massive open online courses</article-title><source>MOOCs Forum</source><year>2013</year><volume>1</volume><fpage>14</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1089/mooc.2013.0003</pub-id></element-citation></ref><ref id="ref-8"><label>Gastwirth (1988)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gastwirth</surname><given-names>JL</given-names></name></person-group><source>Statistical reasoning in law and public policy: volume 2: Tort law, evidence and health</source><year>1988</year><publisher-loc>San Diego, CA</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="ref-9"><label>Heer &#x00026; Bostock (2010)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Heer</surname><given-names>J</given-names></name><name><surname>Bostock</surname><given-names>M</given-names></name></person-group><article-title>Crowdsourcing graphical perception: using mechanical turk to assess visualization design</article-title><conf-name>ACM human factors in computing systems (CHI)</conf-name><year>2010</year><fpage>203</fpage><lpage>212</lpage></element-citation></ref><ref id="ref-10"><label>Jager &#x00026; Leek (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jager</surname><given-names>LR</given-names></name><name><surname>Leek</surname><given-names>JT</given-names></name></person-group><article-title>Empirical estimates suggest most published medical research is true</article-title><source>PLoS Medicine</source><year>2007</year><volume>4</volume><elocation-id>e589</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pmed.0040168</pub-id></element-citation></ref><ref id="ref-11"><label>Ledford (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ledford</surname><given-names>H</given-names></name></person-group><article-title>Paper on genetics of longevity retracted</article-title><source>Nature</source><year>2011</year><comment><italic>Available at <uri xlink:href="http://www.nature.com/news/2011/110721/full/news.2011.429.html">http://www.nature.com/news/2011/110721/full/news.2011.429.html</uri></italic> (accessed 21 August 2014)</comment></element-citation></ref><ref id="ref-12"><label>Liyanagunawardena, Adams &#x00026; Williams (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liyanagunawardena</surname><given-names>TR</given-names></name><name><surname>Adams</surname><given-names>AA</given-names></name><name><surname>Williams</surname><given-names>SA</given-names></name></person-group><article-title>MOOCs: a systematic study of the published literature 2008&#x02013;2012</article-title><source>The International Review of Research in Open and Distance Learning</source><year>2013</year><volume>14</volume><fpage>202</fpage><lpage>227</lpage></element-citation></ref><ref id="ref-13"><label>Mak, Williams &#x00026; Mackness (2010)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mak</surname><given-names>S</given-names></name><name><surname>Fai</surname><given-names>J</given-names></name><name><surname>Williams</surname><given-names>R</given-names></name><name><surname>Mackness</surname><given-names>J</given-names></name></person-group><article-title>Blogs and forums as communication and learning tools in a MOOC</article-title><conf-name>Networked learning conference</conf-name><year>2010</year><conf-loc>Aarlborg</conf-loc><fpage>275</fpage><lpage>284</lpage><comment><italic>Available at <uri xlink:href="http://www.lancs.ac.uk/fss/organisations/netlc/past/nlc2010/abstracts/Mak.html">http://www.lancs.ac.uk/fss/organisations/netlc/past/nlc2010/abstracts/Mak.html</uri></italic></comment></element-citation></ref><ref id="ref-14"><label>Meyer &#x00026; Shinar (1992)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>J</given-names></name><name><surname>Shinar</surname><given-names>D</given-names></name></person-group><article-title>Estimating correlations from scatterplots</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><year>1992</year><volume>34</volume><fpage>335</fpage><lpage>349</lpage></element-citation></ref><ref id="ref-15"><label>Nuzzo (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nuzzo</surname><given-names>R</given-names></name></person-group><article-title>Scientific method: statistical errors</article-title><source>Nature</source><year>2014</year><volume>506</volume><fpage>150</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1038/506150a</pub-id><pub-id pub-id-type="pmid">24522584</pub-id></element-citation></ref><ref id="ref-16"><label>Pelley (2012)</label><element-citation publication-type="other"><person-group><name><surname>Pelley</surname><given-names>S</given-names></name></person-group><year>2012</year><comment>Deception at Duke: fraud in cancer care? <italic>CBS - 60 Minutes</italic>. <italic>Available at <uri xlink:href="http://www.cbsnews.com/news/deception-at-duke-fraud-in-cancer-care">http://www.cbsnews.com/news/deception-at-duke-fraud-in-cancer-care</uri></italic> (accessed 21 August 2014)</comment></element-citation></ref><ref id="ref-17"><label>Rensink &#x00026; Baldridge (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rensink</surname><given-names>RA</given-names></name><name><surname>Baldridge</surname><given-names>G</given-names></name></person-group><article-title>The perception of correlation in scatterplots</article-title><source>Computer Graphics Forum</source><year>2010</year><volume>29</volume><fpage>1203</fpage><lpage>1210</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8659.2009.01694.x</pub-id></element-citation></ref><ref id="ref-18"><label>Schwartz et al. (1997)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>LM</given-names></name><name><surname>Woloshin</surname><given-names>S</given-names></name><name><surname>Black</surname><given-names>WC</given-names></name><name><surname>Welch</surname><given-names>HG</given-names></name></person-group><article-title>The role of numeracy in understanding the benefit of screening mammography</article-title><source>Annals of Internal Medicine</source><year>1997</year><volume>127</volume><fpage>966</fpage><lpage>972</lpage><pub-id pub-id-type="doi">10.7326/0003-4819-127-11-199712010-00003</pub-id><pub-id pub-id-type="pmid">9412301</pub-id></element-citation></ref><ref id="ref-19"><label>Sheridan, Pignone &#x00026; Lewis (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheridan</surname><given-names>SL</given-names></name><name><surname>Pignone</surname><given-names>MP</given-names></name><name><surname>Lewis</surname><given-names>CL</given-names></name></person-group><article-title>A randomized comparison of patients&#x02019; understanding of number needed to treat and other common risk reduction formats</article-title><source>Journal of General Internal Medicine</source><year>2003</year><volume>18</volume><fpage>884</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1046/j.1525-1497.2003.21102.x</pub-id><pub-id pub-id-type="pmid">14687273</pub-id></element-citation></ref><ref id="ref-20"><label>Tufte &#x00026; Graves-Morris (1983)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tufte</surname><given-names>ER</given-names></name><name><surname>Graves-Morris</surname><given-names>P</given-names></name></person-group><source>The visual display of quantitative information</source><volume>Vol. 2</volume><year>1983</year><publisher-loc>Cheshire, CT</publisher-loc><publisher-name>Graphics press</publisher-name></element-citation></ref></ref-list></back></article>