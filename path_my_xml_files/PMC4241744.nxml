<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25505435</article-id><article-id pub-id-type="pmc">4241744</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2014.01323</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Nonverbal synchrony and affect in dyadic interactions</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tschacher</surname><given-names>Wolfgang</given-names></name><xref ref-type="author-notes" rid="fn002"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/52628"/></contrib><contrib contrib-type="author"><name><surname>Rees</surname><given-names>Georg M.</given-names></name><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/184284"/></contrib><contrib contrib-type="author"><name><surname>Ramseyer</surname><given-names>Fabian</given-names></name><uri xlink:type="simple" xlink:href="http://community.frontiersin.org/people/u/109955"/></contrib></contrib-group><aff id="aff1"><institution>Abteilung f&#x000fc;r Psychotherapie, Universit&#x000e4;tsklinik f&#x000fc;r Psychiatrie und Psychotherapie, Universit&#x000e4;t Bern</institution><country>Bern, Switzerland</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: <italic>Michael W. Kraus, University of Illinois at Urbana-Champaign, USA</italic></p></fn><fn fn-type="edited-by"><p>Reviewed by: <italic>John F. Rauthmann, Humboldt-Universit&#x000e4;t zu Berlin, Germany; Katja Schlegel, University of Geneva, Switzerland</italic></p></fn><corresp id="fn002">*Correspondence: <italic>Wolfgang Tschacher, Abteilung f&#x000fc;r Psychotherapie, Universit&#x000e4;tsklinik f&#x000fc;r Psychiatrie und Psychotherapie, Universit&#x000e4;t Bern, Laupenstrasse 49, Bern 3010, Switzerland e-mail: <email xlink:type="simple">tschacher@spk.unibe.ch</email></italic></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Personality and Social Psychology, a section of the journal Frontiers in Psychology.</p></fn></author-notes><pub-date pub-type="epub"><day>24</day><month>11</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>5</volume><elocation-id>1323</elocation-id><history><date date-type="received"><day>05</day><month>9</month><year>2014</year></date><date date-type="accepted"><day>31</day><month>10</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Tschacher, Rees and Ramseyer.</copyright-statement><copyright-year>2014</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p> This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>In an experiment on dyadic social interaction, we invited participants to verbal interactions in cooperative, competitive, and &#x02018;fun task&#x02019; conditions. We focused on the link between interactants&#x02019; affectivity and their nonverbal synchrony, and explored which further variables contributed to affectivity: interactants&#x02019; personality traits, sex, and the prescribed interaction tasks. Nonverbal synchrony was quantified by the coordination of interactants&#x02019; body movement, using an automated video-analysis algorithm (motion energy analysis). Traits were assessed with standard questionnaires of personality, attachment, interactional style, psychopathology, and interpersonal reactivity. We included 168 previously unacquainted individuals who were randomly allocated to same-sex dyads (84 females, 84 males, mean age 27.8 years). Dyads discussed four topics of general interest drawn from an urn of eight topics, and finally engaged in a fun interaction. Each interaction lasted 5 min. In between interactions, participants repeatedly assessed their affect. Using hierarchical linear modeling, we found moderate to strong effect sizes for synchrony to occur, especially in competitive and fun task conditions. Positive affect was associated positively with synchrony, negative affect was associated negatively. As for causal direction, data supported the interpretation that synchrony entailed affect rather than vice versa. The link between nonverbal synchrony and affect was strongest in female dyads. The findings extend previous reports of synchrony and mimicry associated with emotion in relationships and suggest a possible mechanism of the synchrony-affect correlation.</p></abstract><kwd-group><kwd>nonverbal synchrony</kwd><kwd>mimicry</kwd><kwd>imitation</kwd><kwd>embodiment</kwd><kwd>coordinated body-movement</kwd><kwd>motion energy analysis (MEA)</kwd><kwd>body movement</kwd></kwd-group><counts><fig-count count="2"/><table-count count="4"/><equation-count count="0"/><ref-count count="75"/><page-count count="13"/><word-count count="0"/></counts></article-meta></front><body><sec><title>INTRODUCTION</title><p>When people are affectively moved, they tend to move accordingly &#x02013; the close and bidirectional link between emotion and bodily movement (<xref rid="B8" ref-type="bibr">Blake and Shiffrar, 2007</xref>; <xref rid="B36" ref-type="bibr">Hatfield et al., 2009</xref>) constitutes the core premise of the present empirical project. This assumed link is consistent with the concept <italic>embodiment</italic>, which has recently received support from research in psychology and cognitive science (<xref rid="B27" ref-type="bibr">Gallese, 2005</xref>; <xref rid="B70" ref-type="bibr">Tschacher and Bergomi, 2011</xref>). Embodiment denotes the theoretical perspective that mental processes must not be viewed isolated from bodily processes; the essence of cognition is recognized in sensorimotor couplings rather than in abstract information processing. A similar focus, a &#x02018;corporeal turn,&#x02019; is currently observed in the humanities and in philosophy (<xref rid="B25" ref-type="bibr">Fuchs and Jaegher, 2009</xref>; <xref rid="B1" ref-type="bibr">Alloa et al., 2012</xref>; <xref rid="B26" ref-type="bibr">Fuchs and Koch, 2014</xref>). Thus, psychology is becoming increasingly sensitized to investigate the close association between mental and bodily parameters such as body motion, gesture, or facial expression.</p><p>In a dynamical systems view, <italic>synchronization</italic> is a pervasive concept relevant to a large number of physical (<xref rid="B50" ref-type="bibr">Nicolis and Prigogine, 1977</xref>), biological (<xref rid="B61" ref-type="bibr">Rodriguez et al., 1999</xref>; <xref rid="B40" ref-type="bibr">Iacoboni, 2009</xref>), and social (<xref rid="B63" ref-type="bibr">Salvatore and Tschacher, 2012</xref>; <xref rid="B65" ref-type="bibr">Schmidt et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Chartrand and Lakin, 2013</xref>) systems. Synchronization means that previously independent variables of a system can become entrained, i.e., increasingly correlated, thereby reducing the degrees of freedom of the system. Synchronization events are typically found in complex systems undergoing transitions from disordered states to states of higher order and coherence. Non-linear systems science describes and models the laws that underlie such pattern formation and self-organization in systems across disciplines (<xref rid="B32" ref-type="bibr">Haken, 1977</xref>). In the present empirical study, we focused on the combination of both, embodiment and synchronization, in investigating the aspect of coordinated body-movement of individuals interacting in dyads.</p><p>This coordinated body-movement will be termed nonverbal synchrony. We were interested whether nonverbal synchrony is a manifestation of the affective states of the individuals in interaction and how synchrony and affect relate to each other, in different types of verbal interaction.</p><p>In the context of psychotherapy dyads, synchrony was previously found associated with positive affectivity reflected by better rapport and a positive quality of the therapeutic relationship (<xref rid="B57" ref-type="bibr">Ramseyer and Tschacher, 2011</xref>, <xref rid="B58" ref-type="bibr">2014</xref>). Rapport was conceptualized according to <xref rid="B69" ref-type="bibr">Tickle-Degnen and Rosenthal (1990)</xref>, who identified three aspects: Mutual attentiveness, positivity, and coordination. Our present operationalization of nonverbal synchrony covers their aspect of coordination, and the affective component inherent to positivity was measured by self-report questionnaire data.</p><p>In the domain of social psychology, synchrony has been studied as behavioral imitation (chameleon effect: <xref rid="B13" ref-type="bibr">Chartrand and Bargh, 1999</xref>), and numerous investigations were concerned with mutual adaptation during social exchange (interpersonal adaptation: <xref rid="B11" ref-type="bibr">Burgoon et al., 1995</xref>), and movement entrainment (<xref rid="B60" ref-type="bibr">Richardson et al., 2008</xref>). Again, there is a link to emotion regulation (emotional contagion: <xref rid="B35" ref-type="bibr">Hatfield et al., 1994</xref>). The majority of empirical studies concerned with nonverbal synchrony have been conducted in affiliative contexts, i.e., within interactional affordances that encouraged rapport between interactants (e.g., <xref rid="B49" ref-type="bibr">Nelson et al., 2014</xref>). To our knowledge, direct comparisons of cooperative versus competitive interaction settings and their associations to nonverbal synchrony have almost never been systematically investigated (<xref rid="B5" ref-type="bibr">Bernieri et al., 1996</xref>). A rare exception is <xref rid="B52" ref-type="bibr">Paxton and Dale (2013a)</xref>, who explicitly addressed the impact of conflict on nonverbal synchrony and found that it was disrupted in comparison to cooperative interactions. This scarcity of research on nonverbal behavior in the two opposing settings of cooperation and competition is rather surprising because the relevance of these aspects for negotiation or debate has long been discussed in social psychology (e.g., <xref rid="B68" ref-type="bibr">Thompson, 1990</xref>; <xref rid="B31" ref-type="bibr">Graziano et al., 1996</xref>; <xref rid="B20" ref-type="bibr">De Dreu et al., 2000</xref>; <xref rid="B66" ref-type="bibr">Seiter et al., 2009</xref>; <xref rid="B23" ref-type="bibr">Dunbar and Abra, 2010</xref>). Much research on interpersonal conflict was conducted in the clinical field of marital interaction, specifically in marital conflict resolution and its association with marital satisfaction and divorce (e.g., <xref rid="B28" ref-type="bibr">Gottman and Notarius, 2000</xref>). In our study, we sought to directly compare the effects of cooperative and competitive settings on nonverbal synchrony in two kinds of verbal debates.</p><p><xref rid="B14" ref-type="bibr">Chartrand and Lakin (2013)</xref> report that, in various settings, people synchronize and &#x02018;mimic&#x02019; more whenever they perceive or wish a positive relationship. For example, the frequency of mimicry behaviors is predicted by attachment traits of adults (<xref rid="B34" ref-type="bibr">Hall et al., 2012</xref>). Vice versa, synchrony entailed liking, cooperative behavior, and further prosocial effects. Thus, synchrony was found to be both a consequence and antecedent of prosocial behavior and positive emotions.</p><p>Several explanations were proposed for this linkage between nonverbal synchrony and affect. Synchrony between interactants may support (or result from) empathic understanding (<xref rid="B3" ref-type="bibr">Bavelas et al., 1987</xref>; <xref rid="B21" ref-type="bibr">de Waal, 2007</xref>). Synchrony may also have a communicative function, creating a shared perspective of a situation (<xref rid="B64" ref-type="bibr">Scheflen, 1964</xref>; <xref rid="B73" ref-type="bibr">Wallbott, 1996</xref>). A number of studies investigating the chameleon effect have shown that imitation has beneficial effects on relationship quality and rapport (e.g., <xref rid="B67" ref-type="bibr">Stel and Vonk, 2010</xref>). Studies have demonstrated that synchronized motor activity increases both cooperation and affiliation (<xref rid="B39" ref-type="bibr">Hove and Risen, 2009</xref>; <xref rid="B74" ref-type="bibr">Wiltermuth and Heath, 2009</xref>). Even simple body-movements, such as walking, are more synchronized in dyads with positive relationships (<xref rid="B47" ref-type="bibr">Miles et al., 2010</xref>). Most of the studies referenced above explored the effects of synchrony that occurred outside of participants&#x02019; conscious awareness. Similar findings for the case of deliberate (instructed) synchronous motor activity have been reported, demonstrating increases in, e.g., self-esteem and affiliation to interaction partners (<xref rid="B46" ref-type="bibr">Lumsden et al., 2014</xref>).</p><p>Many areas of human social interaction generate synchronized behavior (<xref rid="B72" ref-type="bibr">Vallacher and Nowak, 2009</xref>): the list includes religious settings (chorusing, dancing), sporting events (&#x02018;Mexican waves&#x02019; in the stadium), and the military (marching). These behavioral examples describe ritual processes where belongingness is negotiated and positive affect is desired. Research on interactional synchrony has likewise been conducted in diverse contexts (<xref rid="B18" ref-type="bibr">Davis, 1982</xref>; <xref rid="B7" ref-type="bibr">Bernieri and Rosenthal, 1991</xref>; <xref rid="B11" ref-type="bibr">Burgoon et al., 1995</xref>). We derived the interactional setting for the present experimental study from previous research on nonverbal synchrony between patient and therapist: Using the above mentioned conceptualization of synchrony, we found evidence for the association between synchrony and positive aspects of the current state of a relationship (measured at the level of single sessions of psychotherapy, i.e., micro-outcome) as well as at the level of relationship development and maintenance (measured at termination of all therapy sessions, i.e., macro-outcome). We therefore sought to extend these findings from the psychotherapy setting (<xref rid="B57" ref-type="bibr">Ramseyer and Tschacher, 2011</xref>) to an experimental context of dyadic verbal interactions. We created an interactional setting that provided analogous instructions for both the cooperative as well as the competitive conditions. This was achieved by instructing participants to engage in verbal discussions with the aim to either convince the other fellow participant (=competition) or with the aim to defend a shared argumentational position against a third party (=cooperation). &#x02018;Micro-outcome&#x02019; in the present, more general context was assessed by repeated ratings of participants&#x02019; affectivity directly after interactions.</p><p>The hypotheses of the present study were fourfold. As our specific methodology was not before applied outside of clinical settings, we hypothesized that nonverbal synchrony was significantly present also in dyads of unacquainted individuals who engage in prescribed conversations (hypothesis 1, one-sided). We expected that synchrony would be associated positively to positive affect and negatively to negative affect resulting from these conversations (hypothesis 2, two-sided). We wished to assess temporal sequences, a potential indicator of the direction of causality between synchrony and affect: Is nonverbal synchrony better explained by affect ratings prior to, or subsequent to, the respective interactions where synchrony occurs (hypothesis 3, two-sided)? Finally, in an exploratory approach, we wished to model the dependence of positive and negative affect on synchrony together with interaction type, sex, age, and personality traits of the interactants; additionally, possible differential effects of synchrony in combination with sex or interaction type were tested (hypothesis 4, exploratory).</p></sec><sec sec-type="materials|methods" id="s1"><title>MATERIALS AND METHODS</title><sec><title>SETTING</title><p>The project consisted of staged dyadic interactions between previously unacquainted persons of the same sex. Each dyad had five interactions; four concerned social or political topics of common interest, which were randomly drawn from an urn (without replacement); the fifth interaction was a fun task. For the initial four interactions, eight different topics were prepared, such as &#x02018;do tuition fees at university make sense?,&#x02019; &#x02018;media influences on child development,&#x02019; &#x02018;voluntary army or conscript army?&#x02019; and similar. These topics provided the basis for verbal debates between members of each dyad. Participants of a dyad were provided with one of two different and opposing written lists of specific arguments fitting these topics, which they could read in a 2-min preparation period prior to the interaction. The dyads were given instructions for the respective interaction; two instructions encouraged cooperation and two instructions encouraged competition. Cooperation instruction 1 was to develop a shared position with the strongest arguments from the lists; the other cooperation instruction (2) additionally invoked an imagined third party against which the dyad was asked to discuss the best shared argumentation strategy. The competition instruction 1 was to argue, on the basis of each participant&#x02019;s list of arguments, as convincingly as possible against the position of the interaction partner; the second competition instruction was asymmetrical, where one participant received a longer list of five strong arguments, and the other a list of two weaker arguments. The fifth interaction was a &#x02018;fun task&#x02019; with the instruction, &#x0201c;Please design a five-course meal composed of dishes and drinks that both you and your interaction partner dislike.&#x0201d; The fun task was adapted from <xref rid="B15" ref-type="bibr">Chovil (1991)</xref>. Our motivation for including the fun task was to investigate the relationship between affect and synchrony not only in themed discussions, but also in the engaging and humorous atmosphere reliably created by it; this assumption had been supported in the pilot phase of the present experiment. The fun-task type of cooperation was also more similar to previous work employing cooperative and competitive interactions (e.g., <xref rid="B4" ref-type="bibr">Bernieri et al., 1994</xref>). Given that the fun task deviated from the previous four, more highly structured, topical interactions, we always included it at the end of the experiment outside of the randomization scheme. The sequence of instructions was randomized and balanced, with 50% of dyads receiving cooperation 1 &#x02013; cooperation 2 &#x02013; competition 1 &#x02013; competition 2 &#x02013; fun task, and 50% receiving competition 1 &#x02013; competition 2 &#x02013; cooperation 1 &#x02013; cooperation 2 &#x02013; fun task.</p><p>All five interactions (duration 5 min each) of a dyad were recorded using two cameras joined into a split-screen image. Prior to the experiment, it was ascertained that participants did not know each other, were fluent speakers of German, and had no current or previous psychiatric diagnosis. Participants were unaware of the specific hypotheses of the study, especially of the fact that the synchrony of movement was a variable of interest. Thus, the goals of the experiment were not disclosed in detail until the end of the experiment. Instead, participants were informed that the experiment sought to analyze processes taking place in verbal negotiations between unacquainted persons. The filming and audio recording of interactions was explained as being a prerequisite for subsequent evaluation of discussion performance. The interactions were conducted in a studio-like setting with standardized seating arrangements (<bold>Figure <xref ref-type="fig" rid="F1">1</xref></bold>). The audio&#x02013;visual recording of interactions was openly declared in the recruitment description and participants gave informed consent complying with Swiss ethical regulation policies. When participants arrived at the lab, a research assistant introduced them to each other and explained the sequence of events. Each person individually completed a battery of psychological measures prior to the interaction sequences.</p><fig id="F1" position="float"><label>FIGURE 1</label><caption><p><bold>Depiction of the experimental setup.</bold> Top left and right, digital video cameras.</p></caption><graphic xlink:href="fpsyg-05-01323-g001"/></fig></sec><sec><title>PARTICIPANTS</title><p>Participants (<italic>N</italic> = 168) were 84 women and 84 men (mean age 27.8 years, SD = 4.8), with men on average 3.37 years older [<italic>t</italic>(166) = 4.81; <italic>p</italic> &#x0003c; 0.0001). Participants were predominantly students or university graduates, and further persons recruited by the investigators. Fluency in German was an inclusion criterion; 87% were Swiss citizens, other participants were from Germany (9%) and other European countries; all participants were Caucasian. Participants were assigned to dyads randomly from the pool of available persons, with the rule that interactants in a dyad had the same sex and the same linguistic background, since the Swiss, German, and Austrian variants of spoken German vary considerably. Participants&#x02019; education levels were generally high, 82% had high-school levels (&#x0201c;Matura&#x0201d; degree in the Swiss schooling system), and 57% had received higher education degrees (technical or pedagogic college 12%, university graduation 45%). Participants were paid 30 Swiss francs for their time.</p></sec><sec><title>MOTION ENERGY ANALYSIS (MEA) AND MEASUREMENT OF NONVERBAL SYNCHRONY</title><p>The idea of interactional synchrony was originally introduced by <xref rid="B16" ref-type="bibr">Condon and Ogston (1966)</xref>, who manually coded movement changes occurring between consecutive frames of film recordings. Other methods have relied on trained judges&#x02019; evaluations (<xref rid="B7" ref-type="bibr">Bernieri and Rosenthal, 1991</xref>). Technical advances in digital video processing have since greatly facilitated quantification of movement based on video recordings (<xref rid="B29" ref-type="bibr">Grammer et al., 1997</xref>; <xref rid="B30" ref-type="bibr">Grammer et al., 1999</xref>; <xref rid="B55" ref-type="bibr">Ramseyer and Tschacher, 2006</xref>, <xref rid="B57" ref-type="bibr">2011</xref>; <xref rid="B48" ref-type="bibr">Nagaoka and Komori, 2008</xref>; <xref rid="B44" ref-type="bibr">Kupper et al., 2010</xref>; <xref rid="B2" ref-type="bibr">Altmann, 2011</xref>; <xref rid="B52" ref-type="bibr">Paxton and Dale, 2013a</xref>,<xref rid="B53" ref-type="bibr">b</xref>). Motion energy analysis (MEA), an objective method to determine changes in movement, relies on the same principle of frame-by-frame change introduced almost five decades ago. Yet, MEA provides a cost- and time-efficient alternative to manual observer ratings because it is automated to continuously monitor the amount of change occurring in pre-defined regions of interest (<bold>Figure <xref ref-type="fig" rid="F2">2</xref></bold>). The technical prerequisites for the recordings are a static camera position and stable light conditions with constant shutter-speed and aperture. Regions of interest should not overlap, and people should not occlude one another.</p><fig id="F2" position="float"><label>FIGURE 2</label><caption><p><bold>Motion energy analysis (MEA).</bold> (<bold>A</bold>; top row), consecutive frames 1, 2, and 3 of split-screen video recordings. (<bold>A</bold>; bottom row), corresponding images of motion energy 1*, 2*, and 3*. <bold>(B)</bold> time series of individual motion energies (ordinate: smoothed, <italic>z</italic>-standardized and threshold-adjusted motion energy values; abszissa: time in 1/10 s). The regions of interest (ROI) are shown as boxes in image 1 and 1*. In images 1* and 2*, episodes of nonverbal synchrony occur.</p></caption><graphic xlink:href="fpsyg-05-01323-g002"/></fig><p>Motion energy analysis involves several processing steps: Digitized sequences (10 frames/s) of dyadic interactions were analyzed with commercial video-analysis software (&#x02018;softVNS&#x02019; <xref rid="B62" ref-type="bibr">Rokeby, 2006</xref>; &#x02018;MaxMsp&#x02019; cycling &#x02019;74, 2006) that was customized for MEA (<xref rid="B54" ref-type="bibr">Ramseyer, 2008</xref>; see <ext-link ext-link-type="uri" xlink:href="http://www.psync.ch">www.psync.ch</ext-link> for details). Motion energy was defined as differences in gray-scale pixels between consecutive video-frames (<xref rid="B30" ref-type="bibr">Grammer et al., 1999</xref>), with differences indicating body motion of the respective participant. One region of interest (ROI) was adapted to each participant, covering the entire body including the head and legs (see <bold>Figure <xref ref-type="fig" rid="F2">2A</xref></bold>). Time-series of these raw pixel-changes in each ROI were then smoothed with a moving average of 0.5 s, which reduces fluctuations due to signal-distortion present in most videos. In order to account for different size regions of interest, data were z-transformed and a threshold for minimal movement was individually calculated for each interaction and each participant. Data filtered and corrected in this manner were submitted for quantification of nonverbal synchrony (see below). The objectivity of this kind of automatic movement analysis is high, i.e., MEA is observer-independent once the procedure is established. MEA provides objective and unobtrusive quantitative measures of movement dynamics.</p><p>The quantification of nonverbal synchrony was based on cross-correlations of participants&#x02019; movement time-series. In every 5-min interaction, motion energies of both participants were cross-correlated (<xref rid="B9" ref-type="bibr">Boker et al., 2002</xref>) in window segments of 30 s duration. In contrast to previous work with MEA in psychotherapy dyads (<xref rid="B57" ref-type="bibr">Ramseyer and Tschacher, 2011</xref>), the window size of 30 s was chosen to account for the relatively more dynamic and shorter turn-taking latencies in argumentative interaction compared to a psychotherapy setting. Segmentation into windows was chosen in order to take into consideration the non-stationary nature of movement behaviors. Cross-correlations for positive and negative time-lags up to 5 s in steps of 0.1 s were computed by step-wise shifting one time-series in relation to the other (50 steps in each direction, i.e., positive and negative lags). Cross-correlations were then standardized (Fisher&#x02019;s Z) and their absolute values were aggregated over the entire 5-min interval of an interaction, yielding one global value of nonverbal synchrony for each of the five interactions of each dyad. The use of absolute values means that both positive and negative cross-correlations contributed positively to the 5-min synchrony measure. This strategy yields synchrony values representative of the movement coordination of an interacting dyad. These values were used as the synchrony variable in testing hypotheses 2, 3, and 4.</p><p>In order to evaluate the significance of synchrony values (hypothesis 1), a control for coincidental synchrony is needed. <xref rid="B6" ref-type="bibr">Bernieri et al. (1988)</xref> worked with so-called pseudointeractions &#x0201c;... by isolating the video image of each interactant and then pairing them with the video images of other interactants recorded in other interactions&#x0201d; (p. 245). <xref rid="B6" ref-type="bibr">Bernieri et al. (1988)</xref> were able to show significantly higher synchrony in genuine mother&#x02013;child interactions than in pseudointeractions. We implemented a similar technique and generated pseudointeractions using automated surrogate algorithms (<xref rid="B56" ref-type="bibr">Ramseyer and Tschacher, 2010</xref>). Surrogate datasets (<italic>n</italic>= 100 out of each genuine dataset) were produced by segment-wise (30 s segments) shu&#x0fb04;ing of the original data of interactants X and Y of a dyad, then aligning movement segments of X with movement segments of Y that never actually occurred at the same time. This procedure kept the window-wise, individual progressive time structure of the real data intact but permuted the temporal location of window segments. Synchrony in pseudointeractions (i.e., pseudosynchrony) was finally calculated identically to the synchrony of the original data as described above. For the statistical comparison of synchrony versus pseudosynchrony, the synchrony values of all 100 surrogate datasets of a dyad were computed in each of the five interaction types, yielding a distribution of pseudosynchronies. Each dyad&#x02019;s five genuine synchrony values were expressed as z values on the basis of the respective distribution of pseudosynchronies.</p></sec><sec><title>PROCESS MEASURE OF AFFECT</title><p>Prior to and subsequent to each of the five interaction tasks, all participants rated their own momentary affective state using the <italic>Positive and Negative Affect Scale</italic>, PANAS (<xref rid="B43" ref-type="bibr">Krohne et al., 1996</xref>). The PANAS is a short standard instrument for the self-assessment of emotional states. It consists of twenty emotion adjectives (e.g., &#x02018;active,&#x02019; &#x02018;interested,&#x02019; &#x02018;upset,&#x02019; &#x02018;afraid&#x02019;) that are rated on five-point scales ranging from &#x02018;very slightly or not at all&#x02019; to &#x02018;extremely.&#x02019; The 20 items load on two factors, positive affect and negative affect. Internal consistencies of the factors are usually found to be high, exceeding 0.80. The PANAS is a change-sensitive instrument and thus has low test-retest reliability. The positive and negative affect factors were used in hypotheses 2, 3, and 4.</p></sec><sec><title>MEASURES OF PERSONALITY TRAITS</title><p>All participants filled out questionnaires covering different areas such as interactional style, interpersonal problems, personality traits, and psychological symptoms, to be used as predictors in hypothesis 4. All instruments were based on participants&#x02019; self-reports. These questionnaires were given at baseline, prior to the interactions.</p><p>The <italic>Five Factor Personality Inventory</italic> (NEO-FFI, <xref rid="B10" ref-type="bibr">Borkenau and Ostendorf, 1991</xref>; <xref rid="B17" ref-type="bibr">Costa and McCrae, 1992</xref>) is a multidimensional questionnaire for the self-assessment of the fundamental dimensions of personality (the postulated &#x0201c;Big Five&#x0201d; are neuroticism, extraversion, openness for new experience, agreeableness, conscientiousness). The five dimensions are measured on the basis of 60 items with five-point scales. Cronbach&#x02019;s alpha of the dimensions in the German version ranged between 0.71 (openness) and 0.85, and test&#x02013;retest reliabilities are commonly reported as adequate.</p><p>The <italic>Inventory of Interpersonal Problems</italic> (IIP, <xref rid="B37" ref-type="bibr">Horowitz et al., 1988</xref>, <xref rid="B38" ref-type="bibr">1994</xref>) is a measure of current difficulties in interpersonal functioning. Apart from a total score indicative of the overall level of interpersonal problems, eight subscales pertaining to the circumplex model of interpersonal behavior are assessed using a five-point Likert scale (64 items ranging from 0 to 4). <xref rid="B38" ref-type="bibr">Horowitz et al. (1994)</xref> reported an internal consistency ranging from 0.82 to 0.94 with a 10-week test&#x02013;retest reliability of 0.80 to 0.90.</p><p>The patients&#x02019; adult attachment style was measured with the <italic>Measure of Attachment Qualities</italic> (MAQ, <xref rid="B12" ref-type="bibr">Carver, 1997</xref>). The 14 items are scored on a four-point Likert scale ranging from 1 to 4. The measure provides four scales of attachment types: security, avoidance, ambivalence-worry, and ambivalence-merger. <xref rid="B12" ref-type="bibr">Carver (1997)</xref> reported internal consistencies of 0.69 to 0.76 and a test&#x02013;retest reliability of 0.61 to 0.80 over a 6-week period.</p><p>The SCL-K-9 is a short version of the <italic>Symptom Checklist</italic> SCL-90-R, composed of the nine items correlating highest with the global severity index of the SCL (<xref rid="B24" ref-type="bibr">Franke, 1994</xref>; <xref rid="B42" ref-type="bibr">Klaghofer and Br&#x000e4;hler, 2001</xref>), a measure used to assess general symptom distress, such as worries, emotional instability, being nervous. Using a five-point Likert scale, participants indicate to what extent they experienced each of nine distress symptoms in the past week. We used the mean of the items as an assessment of overall current symptomatology. For the original scales, internal consistencies between 0.63 and 0.85 with a test&#x02013;retest reliability between 0.73 and 0.92 over a 1-week period were reported.</p><p>The Saarbr&#x000fc;cker Pers&#x000f6;nlichkeitsfragebogen SPF (Saarbr&#x000fc;cken personality questionnaire) is a reworked German version of the <italic>Interpersonal Reactivity Index</italic> (IRI: <xref rid="B19" ref-type="bibr">Davis, 1983</xref>), a questionnaire for the measurement of empathy. The SPF has four scales, perspective taking, fantasy, empathic concern, and personal distress. <xref rid="B51" ref-type="bibr">Paulus (2009)</xref> reported internal consistencies of 0.66 to 0.71 and good test&#x02013;retest reliability.</p><p>In the present study, factor analysis was used to construct factors that represent these personality-based and clinical trait measures. The intention was to define strictly orthogonal factors that were suited as predictors in later regression analyses (hypothesis 4), thereby avoiding collinearity of predictors. The small number of factors also reduces the problem of alpha inflation of statistical modeling, since the complete set of trait data comprised 22 subscales of the available instruments (five subscales of the NEO-FFI, eight subscales of the IIP, four of the MAQ, one SCL-K-9 scale, four subscales of the SPF). Factor analysis with Maximum likelihood estimation (JMP Pro 10 statistical software) yielded six factors with an Eigenvalue &#x0003e; 1. Using Varimax rotation, six orthogonal factors were obtained by the linear composites of the subscales. These factors explained 57.4% of total variance. Factor loadings are given in <bold>Table <xref ref-type="table" rid="T1">1</xref></bold>. The factors (with explained variances) can be described as follows:</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Factor loadings after factor analysis with Varimax rotation of 22 questionnaire scales.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Scale</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 1 selfish-domineering</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 2 non-assertive-accommodating</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 3 cold-avoidant</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 4 ambivalent-troubled</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 5 introverted-distressed</th><th valign="top" align="left" rowspan="1" colspan="1">Factor 6 open-empathic</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">NEO neuroticism</td><td valign="top" align="left" rowspan="1" colspan="1">0.32</td><td valign="top" align="left" rowspan="1" colspan="1">0.15</td><td valign="top" align="left" rowspan="1" colspan="1">0.04</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.52</bold></td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.56</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">NEO extraversion</td><td valign="top" align="left" rowspan="1" colspan="1">-0.01</td><td valign="top" align="left" rowspan="1" colspan="1">0.02</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>-0.49</bold></td><td valign="top" align="left" rowspan="1" colspan="1">-0.07</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>-0.52</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.15</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">NEO openness</td><td valign="top" align="left" rowspan="1" colspan="1">-0.06</td><td valign="top" align="left" rowspan="1" colspan="1">-0.07</td><td valign="top" align="left" rowspan="1" colspan="1">0.00</td><td valign="top" align="left" rowspan="1" colspan="1">-0.19</td><td valign="top" align="left" rowspan="1" colspan="1">-0.05</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.61</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">NEO agreeableness</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>-0.60</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.25</td><td valign="top" align="left" rowspan="1" colspan="1">-0.33</td><td valign="top" align="left" rowspan="1" colspan="1">-0.09</td><td valign="top" align="left" rowspan="1" colspan="1">0.03</td><td valign="top" align="left" rowspan="1" colspan="1">0.10</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">NEO conscientiousness</td><td valign="top" align="left" rowspan="1" colspan="1">-0.36</td><td valign="top" align="left" rowspan="1" colspan="1">-0.07</td><td valign="top" align="left" rowspan="1" colspan="1">0.02</td><td valign="top" align="left" rowspan="1" colspan="1">0.03</td><td valign="top" align="left" rowspan="1" colspan="1">-0.11</td><td valign="top" align="left" rowspan="1" colspan="1">-0.05</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">MAQ security</td><td valign="top" align="left" rowspan="1" colspan="1">-0.04</td><td valign="top" align="left" rowspan="1" colspan="1">0.05</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>-0.49</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td><td valign="top" align="left" rowspan="1" colspan="1">0.05</td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">MAQ avoidance</td><td valign="top" align="left" rowspan="1" colspan="1">0.10</td><td valign="top" align="left" rowspan="1" colspan="1">0.13</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.69</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.06</td><td valign="top" align="left" rowspan="1" colspan="1">0.09</td><td valign="top" align="left" rowspan="1" colspan="1">-0.03</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">MAQ ambivalence-worry</td><td valign="top" align="left" rowspan="1" colspan="1">0.01</td><td valign="top" align="left" rowspan="1" colspan="1">0.08</td><td valign="top" align="left" rowspan="1" colspan="1">0.08</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.77</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.10</td><td valign="top" align="left" rowspan="1" colspan="1">-0.01</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">MAQ ambivalence-merger</td><td valign="top" align="left" rowspan="1" colspan="1">0.09</td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td><td valign="top" align="left" rowspan="1" colspan="1">0.04</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.50</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.09</td><td valign="top" align="left" rowspan="1" colspan="1">-0.08</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP domineering/controlling</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.77</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.13</td><td valign="top" align="left" rowspan="1" colspan="1">0.21</td><td valign="top" align="left" rowspan="1" colspan="1">0.16</td><td valign="top" align="left" rowspan="1" colspan="1">0.03</td><td valign="top" align="left" rowspan="1" colspan="1">0.03</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP vindictive/self-centered</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.73</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.04</td><td valign="top" align="left" rowspan="1" colspan="1">0.31</td><td valign="top" align="left" rowspan="1" colspan="1">0.16</td><td valign="top" align="left" rowspan="1" colspan="1">0.20</td><td valign="top" align="left" rowspan="1" colspan="1">-0.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP cold/distant</td><td valign="top" align="left" rowspan="1" colspan="1">0.34</td><td valign="top" align="left" rowspan="1" colspan="1">0.19</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.71</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.20</td><td valign="top" align="left" rowspan="1" colspan="1">0.12</td><td valign="top" align="left" rowspan="1" colspan="1">0.01</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP socially inhibited</td><td valign="top" align="left" rowspan="1" colspan="1">0.17</td><td valign="top" align="left" rowspan="1" colspan="1">0.30</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.60</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.23</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.47</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.02</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP non-assertive</td><td valign="top" align="left" rowspan="1" colspan="1">0.02</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.55</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.32</td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.59</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP overly accommodating</td><td valign="top" align="left" rowspan="1" colspan="1">0.00</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.88</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.12</td><td valign="top" align="left" rowspan="1" colspan="1">0.08</td><td valign="top" align="left" rowspan="1" colspan="1">0.21</td><td valign="top" align="left" rowspan="1" colspan="1">0.01</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP self-sacrificing</td><td valign="top" align="left" rowspan="1" colspan="1">0.19</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.77</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.08</td><td valign="top" align="left" rowspan="1" colspan="1">0.28</td><td valign="top" align="left" rowspan="1" colspan="1">0.05</td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">IIP intrusive/needy</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.65</bold></td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.45</bold></td><td valign="top" align="left" rowspan="1" colspan="1">-0.01</td><td valign="top" align="left" rowspan="1" colspan="1">0.32</td><td valign="top" align="left" rowspan="1" colspan="1">-0.06</td><td valign="top" align="left" rowspan="1" colspan="1">0.16</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPF perspective taking</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>-0.43</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.13</td><td valign="top" align="left" rowspan="1" colspan="1">0.11</td><td valign="top" align="left" rowspan="1" colspan="1">0.00</td><td valign="top" align="left" rowspan="1" colspan="1">-0.17</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.50</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPF fantasy</td><td valign="top" align="left" rowspan="1" colspan="1">0.16</td><td valign="top" align="left" rowspan="1" colspan="1">0.03</td><td valign="top" align="left" rowspan="1" colspan="1">-0.13</td><td valign="top" align="left" rowspan="1" colspan="1">0.05</td><td valign="top" align="left" rowspan="1" colspan="1">0.20</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.64</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPF empathic concern</td><td valign="top" align="left" rowspan="1" colspan="1">0.04</td><td valign="top" align="left" rowspan="1" colspan="1">0.23</td><td valign="top" align="left" rowspan="1" colspan="1">-0.21</td><td valign="top" align="left" rowspan="1" colspan="1">0.21</td><td valign="top" align="left" rowspan="1" colspan="1">0.06</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.56</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SPF personal distress</td><td valign="top" align="left" rowspan="1" colspan="1">0.25</td><td valign="top" align="left" rowspan="1" colspan="1">0.19</td><td valign="top" align="left" rowspan="1" colspan="1">0.00</td><td valign="top" align="left" rowspan="1" colspan="1">0.33</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.58</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.12</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SCL-9 global</td><td valign="top" align="left" rowspan="1" colspan="1">0.31</td><td valign="top" align="left" rowspan="1" colspan="1">0.26</td><td valign="top" align="left" rowspan="1" colspan="1">-0.05</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>0.48</bold></td><td valign="top" align="left" rowspan="1" colspan="1">0.33</td><td valign="top" align="left" rowspan="1" colspan="1">0.24</td></tr></tbody></table><table-wrap-foot><attrib><italic>Factor loadings exceeding 0.40 are in boldface. NEO, Five Factor Personality Inventory; MAQ, Measure of Attachment Qualities; IIP, Inventory of Interpersonal Problems; SPF, Saarbr&#x000fc;cker Pers&#x000f6;nlichkeitsfragebogen; SCL-9, Symptom Checklist short version</italic>.</attrib></table-wrap-foot></table-wrap><p>Factor 1 selfish-domineering (12.4%): This factor describes domineering, vindictive, and intrusive IIP styles with negative NEO agreeableness and SPF perspective taking.</p><p>Factor 2 non-assertive-accommodating (10.6%): High loadings on several IIP scales, especially on overly accommodating, self-sacrificing, non-assertive, and intrusive/needy.</p><p>Factor 3 cold-avoidant (10.4%): This factor loads on IIP scales cold/distant and socially inhibited, with MAQ avoidant and insecure attachment. Lower loadings are on NEO extraversion (negative).</p><p>Factor 4 ambivalent-troubled (8.7%): This factor loads highest on MAQ ambivalent-worried and ambivalent-merging attachment, with loadings on NEO neuroticism and SCL-K-9 symptoms of psychopathology.</p><p>Factor 5 introverted-distressed (8.3%): This factor loads on IIP non-assertive and socially inhibited, SPF personal distress, NEO neuroticism and, negatively, NEO extraversion.</p><p>Factor 6 open-empathic (7.1%): This factor loads on SPF fantasy, NEO openness, and SPF empathic concern and perspective taking.</p></sec><sec><title>HIERARCHICAL LINEAR MODELING</title><p>For the sake of testing hypothesis 3, we construed a two-level model with interactions (Level 1) nested within dyads (Level 2). The dependent variable was nonverbal synchrony of dyads, and the two predictors of synchrony were PANAS-defined affect of interactants in a dyad, either measured before the interaction or after the interaction. The direction of causality was estimated on the basis of temporal sequence, using the significance of these predictors. Thus, we were testing competing models of temporal relationships between synchrony and affect: If affect prior to the interaction was significant whereas affect after the interaction was not, this would speak for Granger-causality &#x02018;affect causing synchrony.&#x02019; If affect prior to the interaction was insignificant whereas affect after the interaction was significant, this would speak for Granger-causality &#x02018;synchrony causing affect.&#x02019;</p><p>For hypotheses 2 and 4, we modeled interactions (Level 1) as nested within participants (Level 2) and nested within dyads (Level 3). The dependent variables were participants&#x02019; positive (negative) affect as measured by the PANAS. <italic>n</italic> = 840 measurements were planned (168 participants &#x000d7; 5 interactions), with three PANAS measurements missing due to data loss (hence, <italic>n</italic> = 837 in <bold>Tables <xref ref-type="table" rid="T2">2</xref></bold> and <bold><xref ref-type="table" rid="T3">3</xref></bold>). For the exploratory assessments of hypothesis 4 we tested different explanatory variables as predictors of affect in a systematic modeling procedure, separately for participants&#x02019; positive and negative affect. We used a step-up procedure, exploring different combinations of predictors (i.e., models). We evaluated all models in terms of Akaike&#x02019;s information criterion (AIC) to select the best model; we used the software package JMP Pro 10 (SAS Institute Inc, Cary, NC, USA) for computation of the corrected AIC (AICc) and for all further statistical analyses. We applied mixed-effects analysis to explain the variance of the dependent variable &#x02018;positive (negative) affect&#x02019; by the following fixed effects (i.e., predictors): &#x02018;Synchrony,&#x02019; &#x02018;Interaction type,&#x02019; &#x02018;Interaction type &#x000d7; Synchrony,&#x02019; &#x02018;Age,&#x02019; &#x02018;Sex,&#x02019; &#x02018;Sex &#x000d7; Synchrony,&#x02019; &#x02018;Factor 1, 2,..., 6.&#x02019; In all models, &#x02018;Participant&#x02019; and &#x02018;Dyad&#x02019; were entered as random effects, which defined the dependency structure inherent to this hierarchical dataset (<xref rid="B59" ref-type="bibr">Raudenbush and Bryk, 2002</xref>). The best-fitting and most parsimonious model was selected with the following procedure: We incrementally entered the predictors (fixed effects) in the sequence of the list above. Statistical significance (<italic>p</italic> &#x0003c; 0.05) of the entered predictor was applied as a criterion to either keep the current predictor and add the following predictor, or skip the current predictor and enter the following predictor. In this manner, nine models were computed for the dependent variable &#x02018;Positive affect&#x02019; and the same number for &#x02018;Negative affect.&#x02019; Finally, AIC was used, a common approximation to model evidence. The AIC includes both an accuracy and complexity term, in other words, it identifies the most accurate model that can also provide a parsimonious explanation for observed data. Smaller AIC indicates the better model. The respective AIC-optimal models are printed bold in the resulting tables below.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Mixed effects models of <italic>N</italic>168 participants interacting in 84 dyads. Dependent variable, PANAS positive affect.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"/><th valign="top" align="left" rowspan="1" colspan="1">Model 1 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 2 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 3 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 4 (<italic>n</italic> = 837</th><th valign="top" align="left" rowspan="1" colspan="1">Model 5 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 6 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 7 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 8 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 9 (<italic>n</italic> = 837)</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Fixed Effects</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.65***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.29**</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.52***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.51***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.47***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.73***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.75***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.71***</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Interaction type</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 10.3****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 13.3****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 13.3****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 13.3****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 14.1****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 14.1****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 14.1****</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Interaction type &#x000d7; Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.86**</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.86**</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.88**</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.41*</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.48*</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 4.47*</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Age</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.18</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Sex[male]</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.72</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.72</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.89</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.28</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Sex[male] &#x000d7; Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -3.62***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -3.56***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -3.60***</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 1 selfish-domineering</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = .71</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 2 non-assertive-accommodating</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -.99</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 3 cold-avoidant</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -1.63</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 4 ambivalent-troubled</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -.95</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 5 introverted-distressed</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -2.42*</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -2.84**</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 6 open-empathic</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.57</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Random Effects</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Participant [Dyad] (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">48.85</td><td valign="top" align="left" rowspan="1" colspan="1">49.41</td><td valign="top" align="left" rowspan="1" colspan="1">50.04</td><td valign="top" align="left" rowspan="1" colspan="1">50.58</td><td valign="top" align="left" rowspan="1" colspan="1">50.89</td><td valign="top" align="left" rowspan="1" colspan="1">51.11</td><td valign="top" align="left" rowspan="1" colspan="1">51.63</td><td valign="top" align="left" rowspan="1" colspan="1">51.63</td><td valign="top" align="left" rowspan="1" colspan="1">51.68</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Dyad (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">16.27</td><td valign="top" align="left" rowspan="1" colspan="1">15.95</td><td valign="top" align="left" rowspan="1" colspan="1">16.06</td><td valign="top" align="left" rowspan="1" colspan="1">15.54</td><td valign="top" align="left" rowspan="1" colspan="1">15.33</td><td valign="top" align="left" rowspan="1" colspan="1">14.65</td><td valign="top" align="left" rowspan="1" colspan="1">14.67</td><td valign="top" align="left" rowspan="1" colspan="1">14.47</td><td valign="top" align="left" rowspan="1" colspan="1">13.28</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Whole model variance (%)</td><td valign="top" align="left" rowspan="1" colspan="1">71.23</td><td valign="top" align="left" rowspan="1" colspan="1">71.76</td><td valign="top" align="left" rowspan="1" colspan="1">72.64</td><td valign="top" align="left" rowspan="1" colspan="1">72.98</td><td valign="top" align="left" rowspan="1" colspan="1">72.99</td><td valign="top" align="left" rowspan="1" colspan="1">72.98</td><td valign="top" align="left" rowspan="1" colspan="1">73.49</td><td valign="top" align="left" rowspan="1" colspan="1">73.49</td><td valign="top" align="left" rowspan="1" colspan="1">73.47</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AIC</td><td valign="top" align="left" rowspan="1" colspan="1">1385.4</td><td valign="top" align="left" rowspan="1" colspan="1">1373.6</td><td valign="top" align="left" rowspan="1" colspan="1">1369.1</td><td valign="top" align="left" rowspan="1" colspan="1">1361.0</td><td valign="top" align="left" rowspan="1" colspan="1">1370.3</td><td valign="top" align="left" rowspan="1" colspan="1">1364.2</td><td valign="top" align="left" rowspan="1" colspan="1">1352.6</td><td valign="top" align="left" rowspan="1" colspan="1">1374.0</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>1350.6</bold></td></tr></tbody></table><table-wrap-foot><attrib><italic>Factor, orthogonal factors of participants&#x02019; traits; AIC, Akaike&#x02019;s Information Criterion. PANAS, Positive and Negative Affect Scale. AIC minimum printed in boldface. For each model, fixed effects estimates, random effects estimates, whole model variance and AIC are listed (top to bottom). *<italic>p</italic>&#x0003c; 0.05; **<italic>p</italic>&#x0003c; 0.01; ***<italic>p</italic>&#x0003c; 0.001; ****<italic>p</italic>&#x0003c; 0.0001</italic>.</attrib></table-wrap-foot></table-wrap><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Mixed effects models of <italic>N</italic> = 168 participants interacting in 84 dyads. Dependent variable, PANAS negative affect.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"/><th valign="top" align="left" rowspan="1" colspan="1">Model 1 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 2 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 3 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 4 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 5 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 6 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 7 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 8 (<italic>n</italic> = 837)</th><th valign="top" align="left" rowspan="1" colspan="1">Model 9 (<italic>n</italic> = 837)</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Fixed Effects</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -2.28*</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.62</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.60</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.61</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.62</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.57</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Interaction type</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 50.9****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 46.6****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 50.9****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 50.9****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 51.1****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 53.73****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 53.70****</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Interaction type &#x000d7; Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>F</italic> = 0.46</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Age</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.66</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Sex[male]</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.17</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.16</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Sex[male] &#x000d7; Synchrony</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.65</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 1 selfish-domineering</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 2.56*</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 2.61*</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 2 non-assertive-accommodating</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.79***</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 3.96***</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 3 cold-avoidant</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.00</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 4 ambivalent-troubled</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 4.13****</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 4.37****</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 5 introverted-distressed</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.14</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Factor 6 open-empathic</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 1.58</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Random Effects</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Participant [Dyad] (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">39.99</td><td valign="top" align="left" rowspan="1" colspan="1">40.28</td><td valign="top" align="left" rowspan="1" colspan="1">44.28</td><td valign="top" align="left" rowspan="1" colspan="1">44.22</td><td valign="top" align="left" rowspan="1" colspan="1">44.61</td><td valign="top" align="left" rowspan="1" colspan="1">44.12</td><td valign="top" align="left" rowspan="1" colspan="1">44.06</td><td valign="top" align="left" rowspan="1" colspan="1">33.00</td><td valign="top" align="left" rowspan="1" colspan="1">31.83</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Dyad (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">3.13</td><td valign="top" align="left" rowspan="1" colspan="1">2.79</td><td valign="top" align="left" rowspan="1" colspan="1">3.26</td><td valign="top" align="left" rowspan="1" colspan="1">3.30</td><td valign="top" align="left" rowspan="1" colspan="1">2.98</td><td valign="top" align="left" rowspan="1" colspan="1">3.61</td><td valign="top" align="left" rowspan="1" colspan="1">3.73</td><td valign="top" align="left" rowspan="1" colspan="1">7.92</td><td valign="top" align="left" rowspan="1" colspan="1">9.40</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Whole model (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">52.03</td><td valign="top" align="left" rowspan="1" colspan="1">52.32</td><td valign="top" align="left" rowspan="1" colspan="1">58.95</td><td valign="top" align="left" rowspan="1" colspan="1">59.00</td><td valign="top" align="left" rowspan="1" colspan="1">58.97</td><td valign="top" align="left" rowspan="1" colspan="1">58.97</td><td valign="top" align="left" rowspan="1" colspan="1">59.02</td><td valign="top" align="left" rowspan="1" colspan="1">58.57</td><td valign="top" align="left" rowspan="1" colspan="1">58.53</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AIC</td><td valign="top" align="left" rowspan="1" colspan="1">385.9</td><td valign="top" align="left" rowspan="1" colspan="1">383.1</td><td valign="top" align="left" rowspan="1" colspan="1">306.3</td><td valign="top" align="left" rowspan="1" colspan="1">309.3</td><td valign="top" align="left" rowspan="1" colspan="1">316.9</td><td valign="top" align="left" rowspan="1" colspan="1">314.3</td><td valign="top" align="left" rowspan="1" colspan="1">316.5</td><td valign="top" align="left" rowspan="1" colspan="1">308.5</td><td valign="top" align="left" rowspan="1" colspan="1"><bold>288.3</bold></td></tr></tbody></table><table-wrap-foot><attrib><italic>Factor, orthogonal factors of participants&#x02019; traits; AIC, Akaike&#x02019;s Information Criterion; PANAS, Positive and Negative Affect Scale. AIC minimum printed in boldface. For each model, fixed effects estimates, random effects estimates, whole model variance and AIC are listed (top to bottom). *<italic>p</italic>&#x0003c; 0.05; **<italic>p</italic>&#x0003c; 0.01; ***<italic>p</italic>&#x0003c; 0.001; ****<italic>p</italic>&#x0003c; 0.0001</italic>.</attrib></table-wrap-foot></table-wrap></sec></sec><sec><title>RESULTS</title><p>Nonverbal synchrony did not vary significantly across the four debate conditions that realized cooperation or competition [<italic>F</italic>(1,83) = 0.082; <italic>p</italic> = 0.775], but it significantly increased across all five interactions [it was higher in the final interaction, the fun task; <italic>F</italic>(1,83) = 17.993; <italic>p</italic> &#x0003c; 0.0001]. Within the 5-minute tasks, there was no effect of time on synchrony across all 30-second windows [<italic>F</italic>(9,3986) = 0.933; <italic>p</italic> = 0.495].</p><sec><title>HYPOTHESIS 1</title><p>The comparison of synchrony with pseudosynchronies derived from shu&#x0fb04;ed data demonstrated that nonverbal synchrony was significantly present at an above-chance level in this sample of 84 dyads and in all of the five interaction conditions. The mean <italic>z</italic> values for genuine synchrony were 0.41 (cooperation 1), 0.71 (cooperation 2), 0.74 (competition 1), 0.78 (competition 2), and 1.11 (fun task). These mean <italic>z</italic> values are identical to effect sizes (Cohen&#x02019;s <italic>d</italic>), i.e., they demonstrate moderate to strong effects. When the five interaction conditions are collapsed in three conditions, mean <italic>z</italic> values were 0.56 (cooperation), 0.76 (competition), and 1.11 (fun task). The fun task showed a significantly higher synchrony than both competition (<italic>p</italic> &#x0003c; 0.05; <italic>d</italic> = 0.30 for the difference) and cooperation (<italic>p</italic> &#x0003c; 0.001; <italic>d</italic> = 0.49).</p><p>The mean genuine synchrony values were 0.168 (cooperation 1), 0.170 (cooperation 2), 0.174 (competition 1), 0.178 (competition 2), and 0.195 (fun task). In three categories, genuine synchrony ranged from 0.169 (cooperation), to 0.176 (competition), and 0.195 (fun task); the three categories of genuine synchrony were all significantly different from each other (<italic>p</italic> &#x0003c; 0.0001; <italic>d</italic> = 0.63 and 0.86). There was no general increase or decrease of synchrony over time in the initial four interactions whose sequence was randomized.</p></sec><sec><title>HYPOTHESIS 2</title><p>Hierarchical linear models were computed for positive affect (<bold>Table <xref ref-type="table" rid="T2">2</xref></bold>) and negative affect (<bold>Table <xref ref-type="table" rid="T3">3</xref></bold>). Individual affect ratings were used. In both tables, model 2 refers to the modulation of affect by the dyad&#x02019;s synchrony alone. As expected, it was found that nonverbal synchrony positively predicted positive affect (<italic>t</italic> = 3.65, <italic>p</italic> &#x0003c; 0.001) and predicted reduced negative affect (<italic>t</italic> = -2.28, <italic>p</italic> &#x0003c; 0.05).</p></sec><sec><title>HYPOTHESIS 3</title><p>Hierarchical linear models were computed for nonverbal synchrony (dependent variable) explained by positive affect prior to the respective interaction and by positive affect after this interaction; affect ratings were the averages of the two dyad members in the interaction (<bold>Table <xref ref-type="table" rid="T4">4</xref></bold>, Model a). The procedure was repeated with negative affect prior to, and after, an interaction (<bold>Table <xref ref-type="table" rid="T4">4</xref></bold>, Model b). We found that positive affect after the interactions was a significant effect in the model (<italic>t</italic> = 2.52, <italic>p</italic> &#x0003c; 0.05) whereas positive affect prior to the interactions was not (<italic>t</italic> = -0.16, <italic>p</italic> = 0.87). Negative affect after the interactions was likewise significant in Model b (<italic>t</italic> = -1.98, <italic>p</italic> &#x0003c; 0.05) whereas negative affect prior to the interactions was not predictive (<italic>t</italic> = 0.08, <italic>p</italic> = 0.93). This supported the assumption that, in the present sample, positive or negative affect may have been caused by synchrony rather than that affect caused synchrony.</p><table-wrap id="T4" position="float"><label>Table 4</label><caption><p>Mixed effects models of <italic>N</italic> = 84 dyads in five interaction conditions. Dependent variable, nonverbal synchrony.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><td valign="top" align="left" rowspan="1" colspan="1"/><th valign="top" align="left" rowspan="1" colspan="1">Model a (<italic>n</italic> = 420)</th><th valign="top" align="left" rowspan="1" colspan="1">Model b (<italic>n</italic> = 420)</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Fixed Effects</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">PANAS positive before</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -0.16</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">PANAS positive after</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 2.52*</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">PANAS negative before</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = 0.08</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">PANAS negative after</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"><italic>t</italic> = -1.98*</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><bold>Random Effect</bold></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Dyad (% variance)</td><td valign="top" align="left" rowspan="1" colspan="1">6.30</td><td valign="top" align="left" rowspan="1" colspan="1">5.72</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Whole model variance (%)</td><td valign="top" align="left" rowspan="1" colspan="1">12.66</td><td valign="top" align="left" rowspan="1" colspan="1">11.15</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">AIC</td><td valign="top" align="left" rowspan="1" colspan="1">-1705.9</td><td valign="top" align="left" rowspan="1" colspan="1">-1705.3</td></tr></tbody></table><table-wrap-foot><attrib><italic>For both models, fixed effects estimates, the random effect estimate, whole model variance, and AIC are listed (top to bottom). AIC, Akaike&#x02019;s Information Criterion; PANAS, Positive and Negative Affect Scale. *<italic>p</italic>&#x0003c; 0.05</italic>.</attrib></table-wrap-foot></table-wrap></sec><sec><title>HYPOTHESIS 4</title><p>The preferred direction of causality suggested by the test of hypothesis 3 advised to treat positive and negative affect as the dependent variables in further explorations. As in the test of hypothesis 2, individual affect ratings were used. Hierarchical linear models with all predictors entered in a sequential fashion are shown in <bold>Tables <xref ref-type="table" rid="T2">2</xref></bold> and <bold><xref ref-type="table" rid="T3">3</xref></bold> (to simplify the tables, <italic>F</italic> values are given for the categorical predictor &#x02018;Interaction type,&#x02019; for the specific <italic>t</italic> values see the following text).</p><p>Participants&#x02019; positive affect was best explained by Model 9 of <bold>Table <xref ref-type="table" rid="T2">2</xref></bold>, by the predictors &#x02018;Synchrony,&#x02019; &#x02018;Interaction type&#x02019; and, negatively, the personality factor 5 &#x02018;introverted-distressed.&#x02019; As for &#x02018;Interaction type,&#x02019; the competition condition produced significantly higher positive affect (<italic>t</italic> = 4.97, <italic>p</italic> &#x0003c; 0.0001), and the cooperation condition significantly lower positive affect (<italic>t</italic> = -2.79, <italic>p</italic> &#x0003c; 0.01), both relative to the fun task. Additionally, the interactions &#x02018;Interaction type &#x000d7; Synchrony&#x02019; and &#x02018;Sex &#x000d7; Synchrony&#x02019; were significant predictors: The single tests of the former interaction showed that in the cooperation condition, synchrony was linked less with positive affect as compared to the fun task condition (<italic>t</italic> = -2.94, <italic>p</italic> &#x0003c; 0.01), whereas competition and fun task resulted in similar linkages of synchrony and positive affect (<italic>t</italic> = 0.61, <italic>p</italic> = 0.55). The latter interaction &#x02018;Sex &#x000d7; Synchrony&#x02019; means that in male dyads, synchrony was less closely linked with positive affect than in female dyads (<italic>t</italic> = -3.60, <italic>p</italic> &#x0003c; 0.001, see <bold>Table <xref ref-type="table" rid="T2">2</xref></bold>).</p><p>Negative affect of interactants was predicted by a different combination of independent variables (Model 9 in <bold>Table <xref ref-type="table" rid="T3">3</xref></bold>): Again, interaction type was a significant predictor. Interaction type fully mediated the influence of synchrony on negative affect, since synchrony was (negatively) predictive in Model 2, but lost significance as soon as interaction type was also entered. The competition condition of &#x02018;Interaction type&#x02019; was associated with significantly higher negative affect than the fun task (<italic>t</italic> = 10.05, <italic>p</italic> &#x0003c; 0.0001), the cooperation condition and the fun task were not statistically different (<italic>t</italic> = -0.49, <italic>p</italic> = 0.62). Three trait factors contributed to negative affect: Factor 1 (selfish-domineering), Factor 2 (non-assertive-accommodating) and Factor 4 (ambivalent-troubled). In addition to the predictive value of interaction type, we found a significant decrease of negative affect over the course of the experiment.</p></sec></sec><sec><title>DISCUSSION</title><p>In the present study, we explored nonverbal synchrony in same-sex dyads that engaged in discussions of prescribed topics. The method used was motion energy analysis (MEA), an objective and automatized movement analysis of video recordings. MEA has been previously applied only to clinical samples (movement deficits in schizophrenia: <xref rid="B44" ref-type="bibr">Kupper et al., 2010</xref>; patient&#x02013;therapist synchrony in psychotherapy sessions: <xref rid="B57" ref-type="bibr">Ramseyer and Tschacher, 2011</xref>). Here, we implemented the same measure with a different design and context, the first prospective application of MEA in healthy adults. Based on the analogous methodological setup, we showed here that nonverbal synchrony was present to an even higher extent than in the psychotherapy sample, with most effect sizes exceeding the moderate range. Effect sizes (Cohen&#x02019;s <italic>d</italic>) between <italic>d</italic> = 0.50 and 0.59 were reported in psychotherapy dyads (<xref rid="B57" ref-type="bibr">Ramseyer and Tschacher, 2011</xref>). The effect sizes in the present sample were between 0.56 for interactions in the cooperation condition, to 0.76 in competitive discussions, and 1.11 in a fun task. Hence it was found that, other than might have been expected (<xref rid="B4" ref-type="bibr">Bernieri et al., 1994</xref>; <xref rid="B53" ref-type="bibr">Paxton and Dale, 2013b</xref>), (mildly) competitive conversations were more synchronized than conversations with cooperation instructions. However, the comparison with previous studies assessing both cooperative and competitive interactions should be made with caution: In our experiment, the instructions for cooperative and competitive debates were of a similar nature: The activity in both conditions was identical, only the focus (&#x0201c;convince your partner&#x0201d; versus &#x0201c;convince a third party&#x0201d;) was modified by our instructions. The available eight topics in our study were used for both cooperative and competitive discussions. This kind of similarity is clearly different from <xref rid="B4" ref-type="bibr">Bernieri et al.&#x02019;s (1994)</xref> vacation-trip planning (cooperative) versus debate (competitive) instructions, or from <xref rid="B53" ref-type="bibr">Paxton and Dale&#x02019;s (2013b)</xref> affiliative (&#x0201c;find and discuss media that both enjoy&#x0201d;) and argumentative (&#x0201c;try to convince each other of your opinion&#x0201d;) instructions.</p><p>Competition realized in the present project was linked with the highest ratings for both positive and negative affect, thus competition was affectively arousing and not perceived entirely negative. On the other hand, cooperation realized in this project was linked with the lowest ratings for positive affect (<italic>d</italic> = -0.22 in comparison to competition), which could be interpreted as a sign that our implementation of a cooperative debate was less prone to elicit arousal in participants. Our fun task was more similar to the trip-planning and media-discussion activities implemented in <xref rid="B4" ref-type="bibr">Bernieri et al.&#x02019;s (1994)</xref> and <xref rid="B53" ref-type="bibr">Paxton and Dale&#x02019;s (2013b)</xref> experiments: In line with their findings, our fun task ranked highest in synchrony and lowest in negative affect (<italic>d</italic> = -0.66 in comparison to competition). These differences suggest that task affordances were a driving force for synchrony and also influenced affect in this experiment.</p><p>In general, we found objective evidence of nonverbal synchrony in dyadic interactions among healthy individuals previously unknown to each other, and were able to quantify the (considerable) magnitude of synchrony using effect sizes. Nonverbal synchrony in this project was obtained inconspicuously, i.e., participants were blind to our focus on the social synchronization of their body movement. This finding was possible on the basis of MEA methodology. It is a merit of this and similar frame-differencing approaches (e.g., <xref rid="B22" ref-type="bibr">Delaherche et al., 2012</xref>) that they are independent of ratings by researchers, and can be applied in settings where participants may move without restrictions. Hence, the use of computerized video analysis offers a tool to improve the reproducibility of social psychology findings (<xref rid="B75" ref-type="bibr">Yong, 2012</xref>; <xref rid="B49" ref-type="bibr">Nelson et al., 2014</xref>).</p><p>Affect was associated with nonverbal synchrony in the expected way: more synchronous interactions were entailed by higher positive affect and lower negative affect. Comparing the association between synchrony and affect directly before and affect directly after a conversation, we found that the present data favored an interpretation that synchrony entailed affect and not vice versa. This may indicate the predominant direction of causality between synchrony and affect in the present sample. Synchrony was not merely an expression of participants&#x02019; affective states. Instead, our findings are rather consistent with the interpretation that synchrony caused affect, with a moderate to large effect size. To our knowledge, this is the first project where the two directions of causality were compared within the same dataset. Albeit not resulting from an experimental design, this finding provides new information on the generative mechanisms responsible for the synchrony-affect correlation.</p><p>Nonverbal synchrony measured by MEA has the great advantage of being objective, reproducible, and independent of the (supposed) meanings of nonverbal gestures and postures &#x02013; we created a content-independent measure in the spirit of non-linear systems theory. As psychologists, however, we wished to assess what the measurements &#x02018;mean&#x02019;: The exploratory analyses (hypothesis 4) corroborated the strong link between synchrony and positive affect in dyadic interactions (hypothesis 2) when, importantly, all participants are unaware of the measurement of nonverbal synchrony. This indicates that the embodiment of dyadic interactions, as represented by correlated body movement, is an important contributor to positive affect originating from these interactions, and hence to the emotional quality of the dyadic relationship. We showed that the direct link between bodily variables and positive affect was not explained by personality traits, sex, or age of the interacting individuals. The influence of synchrony was partially moderated by sex of participants and the type of the interactions, because the connection between synchrony and positive affect was especially enhanced in female dyads, as well as in competitive and humorous/affiliative conversations. Yet none of the various explored predictors and interactions of predictors reduced the direct linkage between synchrony and positive affect.</p><sec><title>LIMITATIONS</title><p>As described in the Section &#x0201c;Materials and Methods,&#x0201d; MEA does not assess the qualitative aspects of nonverbal behavior, which means that MEA does not take into account qualitative features such as participants&#x02019; facial expression (e.g., smiling) or posture (e.g., approaching vs. disengaging postures). Future analyses based on observer codings will shed more light on the association of these qualitative features of nonverbal behavior and their relation to synchrony and affect. Further analytic avenues could be opened up by using Actor-Partner-Interdependence Models (APIM; <xref rid="B41" ref-type="bibr">Kenny et al., 2006</xref>). The present study has limitations in the causality assessment (hypothesis 3) since its design rests on temporal, not experimental, inference (i.e., causality inferred from temporal sequence). We interpreted that nonverbal synchrony Granger-caused positive and inhibited negative affect, yet in principle third variables such as the motivational valence of the tasks and topics may have influenced the association between synchrony and affect. Nevertheless, Granger causality constitutes the only design that allows checking both causal directions in the same dataset, which appears preferable to conventional designs such as comparing two experimental groups. The included sample has certain additional limitations as we recruited an academically advanced sample not representative of the general population. Also, we formed only same-sex dyads owing to statistical power considerations and to previous research indicating erratic findings in opposite-sex dyads &#x02013; sex complicates interaction. The restriction to same-sex dyads obviously narrows the generalizability of the findings. Finally, we did not fully randomize the temporal sequence of interaction type in the experimental design because we expected the fun task to have extremely divergent implications when positioned as first versus final task. <italic>Post hoc</italic> analyses, however, showed that negative affect may have significantly dwindled over time. Thus, the predictors &#x02018;temporal sequence&#x02019; and &#x02018;interaction type&#x02019; were not fully disentangled, and in the modeling of negative affect the temporal sequence would probably be an important fixed effect. A minor problem was the inclusion of somewhat older male than female participants, since age was explicitly controlled for and found to be an insignificant predictor in all models. The experimental context in the project implied that the monetary compensation was given irrespective of a participant&#x02019;s performance in the interactions. Thus, competitive and cooperative behavior was not specifically rewarded, which probably affected the fidelity of these two interaction types, and may in part explain the unexpected synchrony we found in competitive conversations.</p></sec></sec><sec><title>CONCLUSIONS</title><p>Concerning conceptualization of the main construct of this study, &#x02018;synchrony&#x02019; is an appropriate and neutral concept, and in our opinion preferable to concepts such as &#x02018;mimicry&#x02019; or &#x02018;imitation&#x02019;: Like in the present study, synchrony is commonly found to occur unintentionally, without the awareness of interactants, hence quite unlike what a &#x02018;mime&#x02019; in &#x02018;mimicking&#x02019; or &#x02018;imitating&#x02019; would do. As stated in the introduction, we believe that a tendency toward synchronization may be derived from general assumptions and even laws concerning the self-organization of complex systems (<xref rid="B71" ref-type="bibr">Tschacher and Haken, 2007</xref>; <xref rid="B33" ref-type="bibr">Haken and Tschacher, 2010</xref>). Synchrony emerges independent of interactants&#x02019; intentions or imitation goals. This notion is supported by the fact that synchrony in social contexts occurs spontaneously and usually unnoticed by interactants. Based on theoretical considerations of complex systems theory applied to psychology (<xref rid="B45" ref-type="bibr">Kyselo and Tschacher, 2014</xref>), we would theorize that it is the individually varying affordance, or motivational valence, of the respective discussion topics that may account for the not further explicated variance components of the random effect &#x02018;participant&#x02019; (cf. <bold>Tables <xref ref-type="table" rid="T2">2</xref></bold> and <bold><xref ref-type="table" rid="T3">3</xref></bold>). Future research should therefore increasingly incorporate qualitative and even narrative analyses of nonverbal behavior and its associations with the context and content of conversations.</p><p>In both practical and scientific applications, we believe that MEA methodology is suitable for the exploration of a wide range of social encounters where coordinative processes such as nonverbal synchrony occur. It offers objective measures for analyzing individual movement as well as for assessing synchrony in dyads or more complex social aggregates. Given today&#x02019;s high availability of video recordings, MEA greatly facilitates research into nonverbally embodied aspects of emotion and communication.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><p>This study was conducted in the context of the European Cooperation in Science and Technology, COST action 2102, and funded by the Swiss Federal Department of Home Affairs (project number C07.0036). We thank Eric Keller for important support, Yvonne Delevoye Turrell for methodological suggestions, and Christine Adamus for help in preparing the manuscript.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alloa</surname><given-names>E.</given-names></name><name><surname>Bedorf</surname><given-names>T.</given-names></name><name><surname>Gr&#x000fc;ny</surname><given-names>C.</given-names></name><name><surname>Klass</surname><given-names>T. N.</given-names></name></person-group>
<comment>(eds)</comment> (<year>2012</year>). <source><italic>Leiblichkeit. Geschichte und Aktualit&#x000e4;t eines Konzepts</italic></source> [Corporeality: History and actuality of a concept]. T&#x000fc;bingen: Mohr-Siebeck.</mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Altmann</surname><given-names>U.</given-names></name></person-group> (<year>2011</year>). <article-title>&#x0201c;Investigation of movement synchrony using windowed cross-lagged regression,&#x0201d; in</article-title>
<source><italic>Analysis of Verbal and Nonverbal Communication and Enactment. Lecture Notes in Computer Science,</italic></source>
<volume>Vol. 6800</volume>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Esposito</surname><given-names>A.</given-names></name><name><surname>Vinciarelli</surname><given-names>A.</given-names></name><name><surname>Vicsi</surname><given-names>K.</given-names></name><name><surname>Pelachaud</surname><given-names>C.</given-names></name><name><surname>Nijholt</surname><given-names>A.</given-names></name></person-group> (<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>), <fpage>335</fpage>&#x02013;<lpage>345</lpage>
<pub-id pub-id-type="doi">10.1007/978-3-642-25775-9-31</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bavelas</surname><given-names>J. B.</given-names></name><name><surname>Black</surname><given-names>A.</given-names></name><name><surname>Lemery</surname><given-names>C. R.</given-names></name><name><surname>Mullett</surname><given-names>J.</given-names></name><name><surname>Eisenberg</surname><given-names>N.</given-names></name></person-group> (<year>1987</year>). <article-title>&#x0201c;Motor mimicry as primitive empathy,&#x0201d; in</article-title>
<source><italic>Empathy and its Development</italic></source>
<role>ed.</role>
<person-group person-group-type="editor"><name><surname>Strayer</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>) <fpage>317</fpage>&#x02013;<lpage>338</lpage>.</mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernieri</surname><given-names>F. J.</given-names></name><name><surname>Davis</surname><given-names>J. M.</given-names></name><name><surname>Rosenthal</surname><given-names>R.</given-names></name><name><surname>Knee</surname><given-names>C. R.</given-names></name></person-group> (<year>1994</year>). <article-title>Interactional synchrony and rapport: measuring synchrony in displays devoid of sound and facial affect.</article-title>
<source><italic>Pers. Soc. Psychol. Bull.</italic></source>
<volume>20</volume>
<fpage>303</fpage>&#x02013;<lpage>311</lpage>
<pub-id pub-id-type="doi">10.1177/0146167294203008</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernieri</surname><given-names>F. J.</given-names></name><name><surname>Gillis</surname><given-names>J. S.</given-names></name><name><surname>Davis</surname><given-names>J. M.</given-names></name><name><surname>Grahe</surname><given-names>J. E.</given-names></name></person-group> (<year>1996</year>). <article-title>Dyad rapport and the accuracy of its judgment across situations: a lens model analysis.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>71</volume>
<fpage>110</fpage>&#x02013;<lpage>129</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.71.1.110</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernieri</surname><given-names>F. J.</given-names></name><name><surname>Reznick</surname><given-names>S.</given-names></name><name><surname>Rosenthal</surname><given-names>R.</given-names></name></person-group> (<year>1988</year>). <article-title>Synchrony, pseudosynchrony, and dissynchrony: measuring the entrainment process in mother-infant interactions.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>54</volume>
<fpage>243</fpage>&#x02013;<lpage>253</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.54.2.243</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bernieri</surname><given-names>F. J.</given-names></name><name><surname>Rosenthal</surname><given-names>R.</given-names></name></person-group> (<year>1991</year>). <article-title>&#x0201c;Interpersonal coordination: behavior matching and interactional synchrony,&#x0201d; in</article-title>
<source><italic>Fundamentals of Nonverbal Behavior. Studies in Emotion and Social Interaction</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Feldman</surname><given-names>R. S.</given-names></name><name><surname>Rime</surname><given-names>B.</given-names></name></person-group> (<publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>), <fpage>401</fpage>&#x02013;<lpage>432</lpage>.</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blake</surname><given-names>R.</given-names></name><name><surname>Shiffrar</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Perception of human motion.</article-title>
<source><italic>Annu. Rev. Psychol.</italic></source>
<volume>58</volume>
<fpage>47</fpage>&#x02013;<lpage>73</lpage>
<pub-id pub-id-type="doi">10.1146/annurev.psych.57.102904.19015</pub-id><pub-id pub-id-type="pmid">16903802</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boker</surname><given-names>S. M.</given-names></name><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Rotondo</surname><given-names>J. L.</given-names></name><name><surname>King</surname><given-names>K.</given-names></name></person-group> (<year>2002</year>). <article-title>Windowed cross-correlation and peak picking for the analysis of variability in the association between behavioral time series.</article-title>
<source><italic>Psychol. Methods</italic></source>
<volume>7</volume>
<fpage>338</fpage>&#x02013;<lpage>355</lpage>
<pub-id pub-id-type="doi">10.1037//1082-989X.7.3.338</pub-id><pub-id pub-id-type="pmid">12243305</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borkenau</surname><given-names>P.</given-names></name><name><surname>Ostendorf</surname><given-names>F.</given-names></name></person-group> (<year>1991</year>). <article-title>Ein Fragebogen zur Erfassung f&#x000fc;nf robuster Pers&#x000f6;nlichkeitsfaktoren [A questionnaire to assess five robust personality factors].</article-title>
<source><italic>Diagnostica</italic></source>
<volume>37</volume>
<fpage>29</fpage>&#x02013;<lpage>41</lpage>.</mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Burgoon</surname><given-names>J. K.</given-names></name><name><surname>Stern</surname><given-names>L. A.</given-names></name><name><surname>Dillman</surname><given-names>L.</given-names></name></person-group> (<year>1995</year>). <source><italic>Interpersonal Adaptation: Dyadic Interaction Patterns</italic>.</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>
<pub-id pub-id-type="doi">10.1017/CBO9780511720314</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carver</surname><given-names>C. S.</given-names></name></person-group> (<year>1997</year>). <article-title>Adult attachment and personality: converging evidence and a new measure.</article-title>
<source><italic>Pers. Soc. Psychol. Bull.</italic></source>
<volume>23</volume>
<fpage>865</fpage>&#x02013;<lpage>883</lpage>
<pub-id pub-id-type="doi">10.1177/0146167297238007</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chartrand</surname><given-names>T. L.</given-names></name><name><surname>Bargh</surname><given-names>J. A.</given-names></name></person-group> (<year>1999</year>). <article-title>The chameleon effect: the perception-behavior link and social interaction.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>76</volume>
<fpage>893</fpage>&#x02013;<lpage>910</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.76.6.893</pub-id><pub-id pub-id-type="pmid">10402679</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chartrand</surname><given-names>T. L.</given-names></name><name><surname>Lakin</surname><given-names>J. L.</given-names></name></person-group> (<year>2013</year>). <article-title>The antecedents and consequences of human behavioral mimicry.</article-title>
<source><italic>Annu. Rev. Psychol.</italic></source>
<volume>64</volume>
<fpage>285</fpage>&#x02013;<lpage>308</lpage>
<pub-id pub-id-type="doi">10.1146/annurev-psych-113011-143754</pub-id><pub-id pub-id-type="pmid">23020640</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chovil</surname><given-names>N.</given-names></name></person-group> (<year>1991</year>). <article-title>Discourse-oriented facial displays in conversation.</article-title>
<source><italic>Res. Lang. Soc. Interact.</italic></source>
<volume>25</volume>
<fpage>163</fpage>&#x02013;<lpage>194</lpage>
<pub-id pub-id-type="doi">10.1080/08351819109389361</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Condon</surname><given-names>W. S.</given-names></name><name><surname>Ogston</surname><given-names>W. D.</given-names></name></person-group> (<year>1966</year>). <article-title>Sound film analysis of normal and pathological behavior patterns.</article-title>
<source><italic>J. Nerv. Ment. Dis.</italic></source>
<volume>143</volume>
<fpage>338</fpage>&#x02013;<lpage>457</lpage>
<pub-id pub-id-type="doi">10.1097/00005053-196610000-00005</pub-id><pub-id pub-id-type="pmid">5958766</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>P. T.</given-names></name><name><surname>McCrae</surname><given-names>R. R.</given-names></name></person-group> (<year>1992</year>). <source><italic>Revised NEO Personality Inventory (NEO PI-R) and NEO Five Factor Inventory. Professional Manual</italic>.</source>
<publisher-loc>Odessa, FL</publisher-loc>: <publisher-name>Psychological Assessment Resources</publisher-name>.</mixed-citation></ref><ref id="B18"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M.</given-names></name></person-group> (<role>ed.</role>). (<year>1982</year>). <source><italic>Interaction Rhythms. Periodicity in Communicative Behavior.</italic></source>
<publisher-loc>New York</publisher-loc>: <publisher-name>Human Sciences Press</publisher-name>.</mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M.</given-names></name></person-group> (<year>1983</year>). <article-title>Measuring individual differences in empathy: evidence for a multidimensional approach.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>44</volume>
<fpage>113</fpage>&#x02013;<lpage>126</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.44.1.113</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Dreu</surname><given-names>C. K.</given-names></name><name><surname>Weingart</surname><given-names>L. R.</given-names></name><name><surname>Kwon</surname><given-names>S.</given-names></name></person-group> (<year>2000</year>). <article-title>Influence of social motives on integrative negotiation: a meta-analytic review and test of two theories.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>78</volume>
<fpage>889</fpage>&#x02013;<lpage>905</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.78.5.889</pub-id><pub-id pub-id-type="pmid">10821196</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>de Waal</surname><given-names>F. B.</given-names></name></person-group> (<year>2007</year>). <article-title>&#x0201c;The &#x0201c;Russian doll&#x0201d; model of empathy and imitation,&#x0201d; in</article-title>
<source><italic>On Being Moved: From Mirror Neurons to Empathy</italic></source>
<role>ed.</role>
<person-group person-group-type="editor"><name><surname>Braten</surname><given-names>S.</given-names></name></person-group> (<publisher-loc>Amsterdam</publisher-loc>: <publisher-name>John Benjamins Publishing Company</publisher-name>) <fpage>49</fpage>&#x02013;<lpage>69</lpage>.</mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delaherche</surname><given-names>E.</given-names></name><name><surname>Chetouani</surname><given-names>M.</given-names></name><name><surname>Mahdaoui</surname><given-names>A.</given-names></name><name><surname>Saint-Georges</surname><given-names>C.</given-names></name><name><surname>Viaux</surname><given-names>S.</given-names></name><name><surname>Cohen</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>). <article-title>Interpersonal synchrony: a survey of evaluation methods across disciplines.</article-title>
<source><italic>IEEE Trans. Affect. Comput.</italic></source>
<volume>3</volume>
<fpage>349</fpage>&#x02013;<lpage>365</lpage>
<pub-id pub-id-type="doi">10.1109/T-AFFC.2012.1</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunbar</surname><given-names>N. E.</given-names></name><name><surname>Abra</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>). <article-title>Observations of dyadic power in interpersonal interaction.</article-title>
<source><italic>Commu. Monogr.</italic></source>
<volume>77</volume>
<fpage>657</fpage>&#x02013;<lpage>684</lpage>
<pub-id pub-id-type="doi">10.1080/03637751.2010.520018</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Franke</surname><given-names>G.</given-names></name></person-group> (<year>1994</year>). <source><italic>SCL-90-R. Die Symptom-Checkliste von Derogatis, deutsche Version</italic>.</source>
<publisher-loc>Weinheim</publisher-loc>: <publisher-name>Beltz</publisher-name>.</mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname><given-names>T.</given-names></name><name><surname>Jaegher</surname><given-names>H.</given-names></name></person-group> (<year>2009</year>). <article-title>Enactive intersubjectivity: participatory sense-making and mutual incorporation.</article-title>
<source><italic>Phenomenol. Cogn. Sci.</italic></source>
<volume>8</volume>
<fpage>465</fpage>&#x02013;<lpage>486</lpage>
<pub-id pub-id-type="doi">10.1007/s11097-009-9136-4</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname><given-names>T.</given-names></name><name><surname>Koch</surname><given-names>S. C.</given-names></name></person-group> (<year>2014</year>). <article-title>Embodied affectivity: on moving and being moved.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>5</volume>:<issue>508</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2014.00508</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallese</surname><given-names>V.</given-names></name></person-group> (<year>2005</year>). <article-title>Embodied simulation: from neurons to phenomenal experience.</article-title>
<source><italic>Phenomenol. Cogn. Sci.</italic></source>
<volume>4</volume>
<fpage>23</fpage>&#x02013;<lpage>48</lpage>
<pub-id pub-id-type="doi">10.1007/s11097-005-4737-z</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gottman</surname><given-names>J. M.</given-names></name><name><surname>Notarius</surname><given-names>C. I.</given-names></name></person-group> (<year>2000</year>). <article-title>Decade review: observing marital interaction.</article-title>
<source><italic>J. Marriage Fam.</italic></source>
<volume>62</volume>
<fpage>927</fpage>&#x02013;<lpage>947</lpage>
<pub-id pub-id-type="doi">10.1111/j.1741-3737.2000.00927.x</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grammer</surname><given-names>K.</given-names></name><name><surname>Filova</surname><given-names>V.</given-names></name><name><surname>Fieder</surname><given-names>M.</given-names></name></person-group> (<year>1997</year>). <article-title>&#x0201c;The communication paradox and possible solutions,&#x0201d; in</article-title>
<source><italic>New Aspects of Human Ethology</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Schmitt</surname><given-names>A.</given-names></name><name><surname>Atzwanger</surname><given-names>K.</given-names></name><name><surname>Grammer</surname><given-names>K.</given-names></name><name><surname>Schaefer</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>London</publisher-loc>: <publisher-name>Plenum Press</publisher-name>), <fpage>91</fpage>&#x02013;<lpage>120</lpage>
<pub-id pub-id-type="doi">10.1007/978-0-585-34289-4_6</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grammer</surname><given-names>K.</given-names></name><name><surname>Honda</surname><given-names>R.</given-names></name><name><surname>Schmitt</surname><given-names>A.</given-names></name><name><surname>J&#x000fc;tte</surname><given-names>A.</given-names></name></person-group> (<year>1999</year>). <article-title>Fuzziness of nonverbal courtship communication unblurred by motion energy detection.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>77</volume>
<fpage>487</fpage>&#x02013;<lpage>508</lpage>
<pub-id pub-id-type="doi">10.1037/0022-3514.77.3.487</pub-id><pub-id pub-id-type="pmid">10510505</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname><given-names>W. G.</given-names></name><name><surname>Jensen-Campbell</surname><given-names>L. A.</given-names></name><name><surname>Hair</surname><given-names>E. C.</given-names></name></person-group> (<year>1996</year>). <article-title>Perceiving interpersonal conflict and reacting to it: the case for agreeableness.</article-title>
<source><italic>J. Pers. Soc. Psychol.</italic></source>
<volume>70</volume>
<issue>820</issue>
<pub-id pub-id-type="doi">10.1037/0022-3514.70.4.820</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Haken</surname><given-names>H.</given-names></name></person-group> (<year>1977</year>). <source><italic>Synergetics&#x02013;An Introduction. Nonequilibrium Phase-Transitions and Self-Organization in Physics, Chemistry and Biology</italic>.</source>
<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haken</surname><given-names>H.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>A theoretical model of intentionality with an application to neural dynamics.</article-title>
<source><italic>Mind and Matter</italic></source>
<volume>8</volume>
<fpage>7</fpage>&#x02013;<lpage>18</lpage>.</mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>N. R.</given-names></name><name><surname>Millings</surname><given-names>A.</given-names></name><name><surname>Boucas</surname><given-names>S. B.</given-names></name></person-group> (<year>2012</year>). <article-title>Adult attachment orientation and implicit behavioral mimicry.</article-title>
<source><italic>J. Nonverbal Behav.</italic></source>
<volume>36</volume>
<fpage>235</fpage>&#x02013;<lpage>247</lpage>
<pub-id pub-id-type="doi">10.1007/s10919-012-0136-7</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatfield</surname><given-names>E.</given-names></name><name><surname>Cacioppo</surname><given-names>J. T.</given-names></name><name><surname>Rapson</surname><given-names>R. L.</given-names></name></person-group> (<year>1994</year>). <source><italic>Emotional Contagion.</italic></source> (Cambridge, MA: Cambridge University Press).</mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hatfield</surname><given-names>E.</given-names></name><name><surname>Rapson</surname><given-names>R. L.</given-names></name><name><surname>Le</surname><given-names>Y. C. L.</given-names></name></person-group> (<year>2009</year>). <article-title>&#x0201c;Emotional contagion and empathy,&#x0201d; in</article-title>
<source><italic>The Social Neuroscience of Empathy</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Decety</surname><given-names>J.</given-names></name><name><surname>Ickes</surname><given-names>W.</given-names></name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>19</fpage>&#x02013;<lpage>30</lpage>
<pub-id pub-id-type="doi">10.7551/mitpress/9780262012973.003.0003</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horowitz</surname><given-names>L. M.</given-names></name><name><surname>Rosenberg</surname><given-names>S. E.</given-names></name><name><surname>Baer</surname><given-names>B. A.</given-names></name><name><surname>Ure&#x000f1;o</surname><given-names>G.</given-names></name><name><surname>Villase&#x000f1;or</surname><given-names>V. S.</given-names></name></person-group> (<year>1988</year>). <article-title>Inventory of interpersonal problems: psychometric properties and clinical applications.</article-title>
<source><italic>J. Consult. Clin. Psychol.</italic></source>
<volume>56</volume>
<fpage>885</fpage>&#x02013;<lpage>892</lpage>
<pub-id pub-id-type="doi">10.1037/0022-006X.56.6.885</pub-id><pub-id pub-id-type="pmid">3204198</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Horowitz</surname><given-names>L. M.</given-names></name><name><surname>Strauss</surname><given-names>B.</given-names></name><name><surname>Kordy</surname><given-names>H.</given-names></name></person-group> (<year>1994</year>). <source><italic>IIP-D. Inventar zur Erfassung Interpersonaler Probleme. Deutsche Version.</italic></source>
<publisher-loc>Weinheim</publisher-loc>: <publisher-name>Beltz</publisher-name>.</mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hove</surname><given-names>M. J.</given-names></name><name><surname>Risen</surname><given-names>J. L.</given-names></name></person-group> (<year>2009</year>). <article-title>It&#x02019;s all in the timing: interpersonal synchrony increases affiliation.</article-title>
<source><italic>Soc. Cogn.</italic></source>
<volume>27</volume>
<fpage>949</fpage>&#x02013;<lpage>960</lpage>
<pub-id pub-id-type="doi">10.1521/soco.2009.27.6.949</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacoboni</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Imitation, empathy, and mirror neurons.</article-title>
<source><italic>Annu. Rev. Psychol.</italic></source>
<volume>60</volume>
<fpage>653</fpage>&#x02013;<lpage>670</lpage>
<pub-id pub-id-type="doi">10.1017/s0140525x07003123</pub-id><pub-id pub-id-type="pmid">18793090</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kenny</surname><given-names>D. A.</given-names></name><name><surname>Kashy</surname><given-names>D. A.</given-names></name><name><surname>Cook</surname><given-names>W. L.</given-names></name></person-group> (<year>2006</year>). <source><italic>Dyadic Data Analysis.</italic></source>
<publisher-loc>New York</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klaghofer</surname><given-names>R.</given-names></name><name><surname>Br&#x000e4;hler</surname><given-names>E.</given-names></name></person-group> (<year>2001</year>). <article-title>Konstruktion und teststatistische Pr&#x000fc;fung einer Kurzform der SCL-90&#x02013;R [Construction and test statistical evaluation of a short version of the SCL-90&#x02013;R].</article-title>
<source><italic>Z. Klin. Psychol. Psychiatr. Psychother.</italic></source>
<volume>49</volume>
<fpage>115</fpage>&#x02013;<lpage>124</lpage>.</mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krohne</surname><given-names>H. W.</given-names></name><name><surname>Egloff</surname><given-names>B.</given-names></name><name><surname>Kohlmann</surname><given-names>C.-W.</given-names></name><name><surname>Tausch</surname><given-names>A.</given-names></name></person-group> (<year>1996</year>). <article-title>Untersuchungen mit einer deutschen Version der &#x0201c;Positive and Negative Affect Schedule&#x0201d; (PANAS).</article-title>
<source><italic>Diagnostica</italic></source>
<volume>42</volume>
<fpage>139</fpage>&#x02013;<lpage>156</lpage>.</mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kupper</surname><given-names>Z.</given-names></name><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Hoffmann</surname><given-names>H.</given-names></name><name><surname>Kalbermatten</surname><given-names>S.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>Video-based quantification of body movement during social interaction indicates the severity of negative symptoms in patients with schizophrenia.</article-title>
<source><italic>Schizophr. Res.</italic></source>
<volume>121</volume>
<fpage>90</fpage>&#x02013;<lpage>100</lpage>
<pub-id pub-id-type="doi">10.1016/j.schres.2010.03.032</pub-id><pub-id pub-id-type="pmid">20434313</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kyselo</surname><given-names>M.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2014</year>). <article-title>An enactive and dynamical systems theory account of dyadic relationships.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>5</volume>:<issue>452</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2014.00452</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lumsden</surname><given-names>J.</given-names></name><name><surname>Miles</surname><given-names>L. K.</given-names></name><name><surname>Macrae</surname><given-names>C. N.</given-names></name></person-group> (<year>2014</year>). <article-title>Sync or sink? Interpersonal synchrony impacts self-esteem.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>5</volume>:<issue>1064</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2014.01064</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miles</surname><given-names>L. K.</given-names></name><name><surname>Griffiths</surname><given-names>J. L.</given-names></name><name><surname>Richardson</surname><given-names>M. J.</given-names></name><name><surname>Macrae</surname><given-names>C. N.</given-names></name></person-group> (<year>2010</year>). <article-title>Too late to coordinate: contextual influences on behavioral synchrony.</article-title>
<source><italic>Eur. J. Soc. Psychol.</italic></source>
<volume>40</volume>
<fpage>52</fpage>&#x02013;<lpage>60</lpage>
<pub-id pub-id-type="doi">10.1002/ejsp.721</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagaoka</surname><given-names>C.</given-names></name><name><surname>Komori</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Body movement synchrony in psychotherapeutic counseling: a study using the video-based quantification method.</article-title>
<source><italic>IEICE Trans. Inform. Syst.</italic></source>
<volume>E91</volume>
<fpage>1634</fpage>&#x02013;<lpage>1640</lpage>
<pub-id pub-id-type="doi">10.1093/ietisy/e91-d.6.1634</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>A.</given-names></name><name><surname>Grahe</surname><given-names>J.</given-names></name><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Serier</surname><given-names>K.</given-names></name></person-group> (<year>2014</year>). <article-title>Psychological data from an exploration of the rapport / synchroy interplay using motion energy analysis.</article-title>
<source><italic>J. Open Psychol. Data</italic></source>
<volume>2</volume> e5. <pub-id pub-id-type="doi">10.5334/jopd.ae</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nicolis</surname><given-names>G.</given-names></name><name><surname>Prigogine</surname><given-names>I.</given-names></name></person-group> (<year>1977</year>). <source><italic>Self-Organization in Nonequilibrium Systems: From Dissipative Structures to Order through Fluctuations</italic>.</source>
<publisher-loc>New York</publisher-loc>: <publisher-name>Wiley-Interscience</publisher-name>.</mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulus</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <source><italic>Der Saarbr&#x000fc;cker Pers&#x000f6;nlichkeitsfragebogen</italic>.</source>
<comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://psydok.sulb.uni-saarland.de/volltexte/2009/2363/pdf/SPF_Artikel.pdf">http://psydok.sulb.uni-saarland.de/volltexte/2009/2363/pdf/SPF_Artikel.pdf</ext-link></comment></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paxton</surname><given-names>A.</given-names></name><name><surname>Dale</surname><given-names>R.</given-names></name></person-group> (<year>2013a</year>). <article-title>Argument disrupts interpersonal synchrony.</article-title>
<source><italic>Q. J. Exp. Psychol.</italic></source>
<volume>66</volume>
<fpage>2092</fpage>&#x02013;<lpage>2102</lpage>
<pub-id pub-id-type="doi">10.1080/17470218.2013.85308</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paxton</surname><given-names>A.</given-names></name><name><surname>Dale</surname><given-names>R.</given-names></name></person-group> (<year>2013b</year>). <article-title>Frame-differencing methods for measuring bodily synchrony in conversation.</article-title>
<source><italic>Behav. Res. Methods</italic></source>
<volume>45</volume>
<fpage>329</fpage>&#x02013;<lpage>343</lpage>
<pub-id pub-id-type="doi">10.3758/s13428-012-0249-2</pub-id><pub-id pub-id-type="pmid">23055158</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramseyer</surname><given-names>F.</given-names></name></person-group> (<year>2008</year>). <source><italic>Synchronisation nonverbaler Interaktion in der Psychotherapie. [Synchrony of Nonverbal Interaction in Psychotherapy].</italic></source>
<publisher-name>Doctoral Dissertation, Institute of Psychology, Bern</publisher-name>
<comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.psync.ch">www.psync.ch</ext-link></comment></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2006</year>). <article-title>Synchrony: a core concept for a constructivist approach to psychotherapy.</article-title>
<source><italic>Constructivism Hum. Sci.</italic></source>
<volume>11</volume>
<fpage>150</fpage>&#x02013;<lpage>171</lpage>.</mixed-citation></ref><ref id="B56"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>&#x0201c;Nonverbal synchrony or random coincidence? How to tell the difference,&#x0201d; in</article-title>
<source><italic>Development of Multimodal Interfaces: Active Listening and Synchrony</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Esposito</surname><given-names>A.</given-names></name><name><surname>Campbell</surname><given-names>N.</given-names></name><name><surname>Vogel</surname><given-names>C.</given-names></name><name><surname>Hussain</surname><given-names>A.</given-names></name><name><surname>Nijholt</surname><given-names>A.</given-names></name></person-group> (<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>182</fpage>&#x02013;<lpage>196</lpage>.</mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2011</year>). <article-title>Nonverbal synchrony in psychotherapy: coordinated body-movement reflects relationship quality and outcome.</article-title>
<source><italic>J. Consult. Clin. Psychol.</italic></source>
<volume>79</volume>
<fpage>284</fpage>&#x02013;<lpage>295</lpage>
<pub-id pub-id-type="doi">10.1037/a0023419</pub-id><pub-id pub-id-type="pmid">21639608</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramseyer</surname><given-names>F.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2014</year>). <article-title>Nonverbal synchrony of head- and body-movement in psychotherapy: different signals have different associations with outcome.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>5</volume>:<issue>979</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2014.00979</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Raudenbush</surname><given-names>W.</given-names></name><name><surname>Bryk</surname><given-names>A. S.</given-names></name></person-group> (<year>2002</year>). <source><italic>Hierarchical Linear Models. Applications and Data Analysis Methods.</italic></source>
<publisher-loc>London</publisher-loc>: <publisher-name>Sage</publisher-name>.</mixed-citation></ref><ref id="B60"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>D.</given-names></name><name><surname>Dale</surname><given-names>R.</given-names></name><name><surname>Shockley</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>&#x0201c;Synchrony and swing in conversation: coordination, temporal dynamics, and communication,&#x0201d; in</article-title>
<source><italic>Embodied Communication in Humans and Machines</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Wachsmuth</surname><given-names>I.</given-names></name><name><surname>Lenzen</surname><given-names>M.</given-names></name><name><surname>Knoblich</surname><given-names>G.</given-names></name></person-group> (<publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Pres</publisher-name>), <fpage>75</fpage>&#x02013;<lpage>94</lpage>.</mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodriguez</surname><given-names>E.</given-names></name><name><surname>George</surname><given-names>N.</given-names></name><name><surname>Lachaux</surname><given-names>J. P.</given-names></name><name><surname>Martinerie</surname><given-names>J.</given-names></name><name><surname>Renault</surname><given-names>B.</given-names></name><name><surname>Varela</surname><given-names>F. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Perception&#x02019;s shadow: long-distance synchronization of human brain activity.</article-title>
<source><italic>Nature</italic></source>
<volume>397</volume>
<fpage>430</fpage>&#x02013;<lpage>433</lpage>
<pub-id pub-id-type="doi">10.1038/17120</pub-id><pub-id pub-id-type="pmid">9989408</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rokeby</surname><given-names>D.</given-names></name></person-group> (<year>2006</year>). <source><italic>softVNS 2.17</italic></source> [Computer Software (<ext-link ext-link-type="uri" xlink:href="http://www.softVNS.com">www.softVNS.com</ext-link>)]. <publisher-loc>Toronto, Canada</publisher-loc>.</mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salvatore</surname><given-names>S.</given-names></name><name><surname>Tschacher</surname><given-names>W.</given-names></name></person-group> (<year>2012</year>). <article-title>Time dependency of psychotherapeutic exchanges: the contribution of the theory of dynamic systems in analyzing process.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>3</volume>:<issue>253</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2012.00253</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheflen</surname><given-names>A. E.</given-names></name></person-group> (<year>1964</year>). <article-title>The significance of posture in communication systems.</article-title>
<source><italic>Psychiatry</italic></source>
<volume>27</volume>
<fpage>316</fpage>&#x02013;<lpage>331</lpage>.<pub-id pub-id-type="pmid">14216879</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>R. C.</given-names></name><name><surname>Morr</surname><given-names>S.</given-names></name><name><surname>Fitzpatrick</surname><given-names>P.</given-names></name><name><surname>Richardson</surname><given-names>M. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Measuring the dynamics of interactional synchrony.</article-title>
<source><italic>J. Nonverbal Behav.</italic></source>
<volume>36</volume>
<fpage>263</fpage>&#x02013;<lpage>279</lpage>
<pub-id pub-id-type="doi">10.1007/s10919-012-0138-5</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seiter</surname><given-names>J. S.</given-names></name><name><surname>Weger</surname><given-names>H.</given-names></name><name><surname>Kinzer</surname><given-names>H. J.</given-names></name><name><surname>Jensen</surname><given-names>A. S.</given-names></name></person-group> (<year>2009</year>). <article-title>Impression management in televised debates: the effect of background nonverbal behavior on audience perceptions of debaters&#x02019; likeability.</article-title>
<source><italic>Commu. Res. Rep.</italic></source>
<volume>26</volume>
<fpage>1</fpage>&#x02013;<lpage>11</lpage>
<pub-id pub-id-type="doi">10.1080/08824090802636959</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stel</surname><given-names>M.</given-names></name><name><surname>Vonk</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Mimicry in social interaction: benefits for mimickers, mimickees, and their interaction.</article-title>
<source><italic>Br. J. Psychol.</italic></source>
<volume>101</volume>
<fpage>311</fpage>&#x02013;<lpage>323</lpage>
<pub-id pub-id-type="doi">10.1348/000712609X46542</pub-id><pub-id pub-id-type="pmid">19646328</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>L.</given-names></name></person-group> (<year>1990</year>). <article-title>Negotiation behavior and outcomes: empirical evidence and theoretical issues.</article-title>
<source><italic>Psychol. Bull.</italic></source>
<volume>108</volume>
<fpage>515</fpage>&#x02013;<lpage>532</lpage>
<pub-id pub-id-type="doi">10.1037/0033-2909.108.3.515</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tickle-Degnen</surname><given-names>L.</given-names></name><name><surname>Rosenthal</surname><given-names>R.</given-names></name></person-group> (<year>1990</year>). <article-title>The nature of rapport and its nonverbal correlates.</article-title>
<source><italic>Psychol. Inquiry</italic></source>
<volume>1</volume>
<fpage>285</fpage>&#x02013;<lpage>293</lpage>
<pub-id pub-id-type="doi">10.1207/s15327965pli0104-1</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tschacher</surname><given-names>W.</given-names></name><name><surname>Bergomi</surname><given-names>C.</given-names></name></person-group>
<comment>(eds)</comment> (<year>2011</year>). <source><italic>The Implications of Embodiment: Cognition and Communication</italic>.</source>
<publisher-loc>Exeter</publisher-loc>: <publisher-name>Imprint Academic</publisher-name>.</mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tschacher</surname><given-names>W.</given-names></name><name><surname>Haken</surname><given-names>H.</given-names></name></person-group> (<year>2007</year>). <article-title>Intentionality in non-equilibrium systems? The functional aspects of self-organized pattern formation.</article-title>
<source><italic>New Ideas Psychol.</italic></source>
<volume>25</volume>
<fpage>1</fpage>&#x02013;<lpage>15</lpage>
<pub-id pub-id-type="doi">10.1016/j.newideapsych.2006.09.002</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vallacher</surname><given-names>R. R.</given-names></name><name><surname>Nowak</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>&#x0201c;The dynamics of human experience: fundamentals of dynamical social psychology,&#x0201d; in</article-title>
<source><italic>Chaos and Complexity in Psychology: The Theory of Nonlinear Dynamical Systems,</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Guastello</surname><given-names>S. J.</given-names></name><name><surname>Koopmans</surname><given-names>M.</given-names></name><name><surname>Pincus</surname><given-names>D.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>), <fpage>370</fpage>&#x02013;<lpage>401</lpage>.</mixed-citation></ref><ref id="B73"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wallbott</surname><given-names>H. G.</given-names></name></person-group> (<year>1996</year>). <article-title>&#x0201c;Congruence, contagion, and motor mimicry: mutualities in nonverbal exchange,&#x0201d; in</article-title>
<source><italic>Mutualities in Dialogue,</italic></source>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Markova</surname><given-names>I.</given-names></name><name><surname>Grauman</surname><given-names>C. F.</given-names></name><name><surname>Foppa</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>), <fpage>82</fpage>&#x02013;<lpage>98</lpage>.</mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltermuth</surname><given-names>S. S.</given-names></name><name><surname>Heath</surname><given-names>C.</given-names></name></person-group> (<year>2009</year>). <article-title>Synchrony and cooperation.</article-title>
<source><italic>Psychol. Sci.</italic></source>
<volume>20</volume>
<fpage>1</fpage>&#x02013;<lpage>5</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02253.x</pub-id><pub-id pub-id-type="pmid">19152536</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yong</surname><given-names>E.</given-names></name></person-group> (<year>2012</year>). <article-title>Replication studies: bad copy.</article-title>
<source><italic>Nature</italic></source>
<volume>485</volume>
<fpage>298</fpage>&#x02013;<lpage>300</lpage>
<pub-id pub-id-type="doi">10.1038/485298a</pub-id><pub-id pub-id-type="pmid">22596136</pub-id></mixed-citation></ref></ref-list></back></article>