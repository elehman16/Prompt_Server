<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28487662</article-id><article-id pub-id-type="pmc">5403894</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2017.00513</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Eye of the Beholder: Stage Entrance Behavior and Facial Expression Affect Continuous Quality Ratings in Music Performance</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Waddell</surname><given-names>George</given-names></name><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/162280/overview"/></contrib><contrib contrib-type="author"><name><surname>Williamon</surname><given-names>Aaron</given-names></name><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/24612/overview"/></contrib></contrib-group><aff><institution>Centre for Performance Science, Royal College of Music</institution><country>London, UK</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Olga Luc&#x000ed;a Gamboa Arana, Goethe University Frankfurt, Germany</p></fn><fn fn-type="edited-by"><p>Reviewed by: Reinhard Kopiez, Hanover University of Music Drama and Media, Germany; Friedrich Platz, State University of Music and Performing Arts Stuttgart, Germany</p></fn><corresp id="fn001">*Correspondence: Aaron Williamon <email xlink:type="simple">aaron.williamon@rcm.ac.uk</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Cognitive Science, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>25</day><month>4</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>8</volume><elocation-id>513</elocation-id><history><date date-type="received"><day>23</day><month>12</month><year>2016</year></date><date date-type="accepted"><day>20</day><month>3</month><year>2017</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2017 Waddell and Williamon.</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Waddell and Williamon</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Judgments of music performance quality are commonly employed in music practice, education, and research. However, previous studies have demonstrated the limited reliability of such judgments, and there is now evidence that extraneous visual, social, and other &#x0201c;non-musical&#x0201d; features can unduly influence them. The present study employed continuous measurement techniques to examine how the process of forming a music quality judgment is affected by the manipulation of temporally specific visual cues. Video footage comprising an appropriate stage entrance and error-free performance served as the standard condition (Video <xref ref-type="supplementary-material" rid="SM2">1</xref>). This footage was manipulated to provide four additional conditions, each identical save for a single variation: an inappropriate stage entrance (Video <xref ref-type="supplementary-material" rid="SM3">2</xref>); the presence of an aural performance error midway through the piece (Video <xref ref-type="supplementary-material" rid="SM4">3</xref>); the same error accompanied by a negative facial reaction by the performer (Video <xref ref-type="supplementary-material" rid="SM5">4</xref>); the facial reaction with no corresponding aural error (Video <xref ref-type="supplementary-material" rid="SM6">5</xref>). The participants were 53 musicians and 52 non-musicians (<italic>N</italic> = 105) who individually assessed the performance quality of one of the five randomly assigned videos via a digital continuous measurement interface and headphones. The results showed that participants viewing the &#x0201c;inappropriate&#x0201d; stage entrance made judgments significantly more quickly than those viewing the &#x0201c;appropriate&#x0201d; entrance, and while the poor entrance caused significantly lower initial scores among those with musical training, the effect did not persist long into the performance. The aural error caused an immediate drop in quality judgments that persisted to a lower final score only when accompanied by the frustrated facial expression from the pianist; the performance error alone caused a temporary drop only in the musicians' ratings, and the negative facial reaction alone caused no reaction regardless of participants' musical experience. These findings demonstrate the importance of visual information in forming evaluative and aesthetic judgments in musical contexts and highlight how visual cues dynamically influence those judgments over time.</p></abstract><kwd-group><kwd>performance</kwd><kwd>decision making</kwd><kwd>evaluation</kwd><kwd>multi-modal</kwd><kwd>continuous measurement</kwd></kwd-group><counts><fig-count count="8"/><table-count count="1"/><equation-count count="0"/><ref-count count="68"/><page-count count="14"/><word-count count="11041"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>The evaluation of performance quality is a fixture of musical practice. In educational and professional contexts, quality judgments are used to assess a performer's ability, to diagnose performance problems, to provide summaries of achievement, to determine competition rankings, and to award positions of employment (Goolsby, <xref rid="B14" ref-type="bibr">1999</xref>). Reliable assessment tools are also vital to music research, used to determine the influence of factors such as self-efficacy (Ritchie and Williamon, <xref rid="B37" ref-type="bibr">2011</xref>), practice quality and quantity (Williamon and Valentine, <xref rid="B65" ref-type="bibr">2000</xref>), and the presence of an audience (Shoda and Adachi, <xref rid="B44" ref-type="bibr">2014</xref>) on performance outcomes. These judgments are commonly provided by experts who are assumed to be able to provide consistent and objective indicators of quality. A growing body of research has examined this assumption, calling into question the reliability of expert judges' ratings (Wapnick et al., <xref rid="B60" ref-type="bibr">1993</xref>, <xref rid="B63" ref-type="bibr">2005</xref>), the consistency of interjudge agreement and rating severity (Wesolowski et al., <xref rid="B64" ref-type="bibr">2015</xref>), the validity of the criteria used (Thompson and Williamon, <xref rid="B48" ref-type="bibr">2003</xref>), raters' preexisting knowledge and impressions of the performer (Duerksen, <xref rid="B8" ref-type="bibr">1972</xref>; Kroger and Margulis, <xref rid="B24" ref-type="bibr">2017</xref>), and the influence of factors considered extraneous to traditional music performance quality judgment (for reviews, see McPherson and Schubert, <xref rid="B29" ref-type="bibr">2004</xref>; Waddell and Williamon, <xref rid="B57" ref-type="bibr">2017</xref>).</p><p>As live music performance often incorporates a visual element, many studies have explored the influence of visual cues on the perception of musical quality. Davidson (<xref rid="B6" ref-type="bibr">1993</xref>) showed that performers' body movements are not only indicative of their ability and expressive intentions but that participants are better able to differentiate such intentions when presented with the video alone, as opposed to those paired with audio or the audio alone. Further research has found visual performance cues to alter perception of violin vibrato (Gillespie, <xref rid="B12" ref-type="bibr">1997</xref>), tone duration (Schutz and Lipscomb, <xref rid="B43" ref-type="bibr">2007</xref>), and overall ratings of performance quality (Huang and Krumhansl, <xref rid="B20" ref-type="bibr">2011</xref>; Lehmann and Kopiez, <xref rid="B25" ref-type="bibr">2013</xref>; Morrison et al., <xref rid="B31" ref-type="bibr">2014</xref>), including ratings of such predominantly aural concepts as phrasing, dynamics, and rubato (Juchniewicz, <xref rid="B22" ref-type="bibr">2008</xref>). Quality evaluations have also been shown to be affected by otherwise unrelated visual features including race (e.g., Elliott, <xref rid="B10" ref-type="bibr">1995</xref>; Davidson and Edgar, <xref rid="B7" ref-type="bibr">2003</xref>; VanWeelden, <xref rid="B55" ref-type="bibr">2004</xref>), dress (Griffiths, <xref rid="B16" ref-type="bibr">2008</xref>, <xref rid="B17" ref-type="bibr">2010</xref>, <xref rid="B18" ref-type="bibr">2011</xref>), attractiveness (Wapnick et al., <xref rid="B59" ref-type="bibr">1997</xref>, <xref rid="B61" ref-type="bibr">1998</xref>, <xref rid="B62" ref-type="bibr">2000</xref>; Ryan and Costa-Giomi, <xref rid="B38" ref-type="bibr">2004</xref>; Ryan et al., <xref rid="B39" ref-type="bibr">2006</xref>), and sex (Davidson and Edgar, <xref rid="B7" ref-type="bibr">2003</xref>), while the introduction of the blind orchestral audition since the 1970s has been linked to a rebalancing of such biases, including a marked increase in the hiring of female performers (Goldin and Rouse, <xref rid="B13" ref-type="bibr">2000</xref>).</p><p>These studies are supported by a meta-analysis that has demonstrated a global effect (<italic>d</italic> = 0.51 SDs) of visual information on performance quality, expressiveness, and appreciation ratings (Platz and Kopiez, <xref rid="B33" ref-type="bibr">2012</xref>). Tsay (<xref rid="B53" ref-type="bibr">2013</xref>) provided a dramatic summation of this phenomenon. She gave participants 6-s clips of the three finalists in international piano competitions and asked them to identify the jury's top performer in each case. When provided with either audiovisual or audio-only information, the participants did no better than chance at selecting the winner, irrespective of musical training. However, those who were provided silent video clips identified the winner at a rate significantly higher than chance, a finding that was replicated with a second study using orchestral performances (Tsay, <xref rid="B54" ref-type="bibr">2014</xref>). A key feature of Tsay's research was the use of very brief excerpts, forcing participants to form snap judgments of the recorded performances. The question remains as to whether the immediate influence of these visual features will persist over the course of an entire performance. This has been examined with the use of excerpts of varying lengths, although not with full performances and with conflicting findings. In supplementary studies, Tsay (<xref rid="B53" ref-type="bibr">2013</xref>) replicated her primary results using excerpts ranging from 1 to 60 s in length, suggesting that the effects may not be time-dependent. Research by Wapnick et al. (<xref rid="B58" ref-type="bibr">2009</xref>), however, found that the effects on ratings of some extra-musical visual attributes (attractiveness, dress, and stage behavior) varied as a function of excerpt duration (25, 55, and 115 s), although results were inconsistent between attributes and performers' sex. For example, high attractiveness significantly increased ratings for women only and only in the 25-s excerpts, while dress affected ratings for men only in the 25- and 115-s (but not the 55-s) excerpts.</p><p>One method of examining the long-term effect of visual information is by examining cues that are specific to one point in the performance, thus allowing for a residual effect to be studied after the cue is presented. The stage entrance provides such an opportunity, marking the time from when the performer emerges into the audience's field of view to the production of the first note, often incorporating a bow, acknowledgement of applause, and a brief preparation of the instrument (e.g., tuning, adjusting the seat). No music is being produced, thus any effect on evaluation of the subsequent musical material can be linked entirely to visual features. Platz and Kopiez (<xref rid="B34" ref-type="bibr">2013</xref>) compiled an inventory of 141 stage-entrance features drawn from previous studies, interviews with a small concert audience, and transcriptions of an acting tutor's commentary on select entrance videos. As stimuli, 27 videos of stage entrances were extracted from an international violin competition and manipulated to ensure consistent ambient audience noise (including applause) across conditions. Through appropriateness ratings of each video's entrance behavior on a 5-point scale by 435 participants across two preliminary studies, the corpus of 141 features was reduced to 56 and then to 10 salient behaviors via probabilistic test theory and item response theory models. In the final study, 1,002 participants rated the appropriateness of these 10 items while viewing 12 of the videos of entrance behavior and then indicated whether they would like to continue watching the ensuing performance. Of the 10 behaviors, six were found to be the most salient to judging the appropriateness of a stage entrance: nodding, direction of gaze, touching oneself, stance width, step size, and making a resolute impression. High-scoring entrances correlated positively with the viewer's motivation to continue watching. This suggests that the process of performance evaluation had already begun with the stage entrance and may have influenced perception of the musical content itself, although as the videos were stopped before the first note sounded, the effect on musical perception was not explicitly examined.</p><p>Musicians' facial reactions to specific performance events can also provide dramatic visual markers. The role of facial expression in music performance has been given greatest attention among singers, where studies have found their expressions to aid in lyric comprehension (Jesse and Massaro, <xref rid="B21" ref-type="bibr">2010</xref>), to alter pitch perception (Thompson et al., <xref rid="B50" ref-type="bibr">2005</xref>, <xref rid="B51" ref-type="bibr">2010</xref>), to indicate musical phrasing (Ceaser et al., <xref rid="B5" ref-type="bibr">2009</xref>) and to enhance emotional expression (Thompson et al., <xref rid="B52" ref-type="bibr">2008</xref>; Quinto et al., <xref rid="B35" ref-type="bibr">2014</xref>; Livingstone et al., <xref rid="B26" ref-type="bibr">2015</xref>). However, facial expression has been experimentally examined far less in instrumentalists. Thompson et al. (<xref rid="B50" ref-type="bibr">2005</xref>) demonstrated that body and facial movements by blues guitarist B.B. King increased ratings of perceived aural dissonance by participants. In the context of the musical genre (the blues), this dissonance is expected, if not desired, thus the expression enhanced its effect. How then might facial expression influence the perception of inappropriate and unintended aural dissonance, such as when an explicit performance error has been made? Errors of pitch and timing are not considered trivial in the classical music tradition, although Repp (<xref rid="B36" ref-type="bibr">1996</xref>) found that only a relatively small percentage of errors in pianists' performances were noticed, even among highly trained listeners. This is to the performer's advantage; the goal should be to avoid drawing attention to a misplaced note or, if it has been detected, not to emphasize its importance. The role that facial expression plays in this process has not been systematically investigated.</p><p>In the present study, we tested the influence of visual cues on participants' quality ratings of music performances. We first examined stage entrance behavior, following the work of Platz and Kopiez (<xref rid="B34" ref-type="bibr">2013</xref>), to determine whether &#x0201c;appropriate&#x0201d; and &#x0201c;inappropriate&#x0201d; entrances indeed affect the perception of the musical content that immediately follows and whether such an effect lasts throughout the performance. We then examined the presence of facial reactions to a severe performance error. Performances were evaluated by representative samples of musicians and non-musicians, differentiated only by their level of musical experience. From these experimental manipulations and the existing literature, the following hypotheses were posited:</p><p>1A. The presence of an &#x0201c;inappropriate&#x0201d; stage entrance would cause a lower initial rating when compared with the same performance with an &#x0201c;appropriate&#x0201d; entrance. This first rating would also be made sooner, as a result of the performers' deviation from expected stage entrance behavior.</p><p>1B. As musically trained evaluators would have a stronger heuristic for &#x0201c;appropriate&#x0201d; stage entrances based on their extensive experience, they would show a shorter time to first decision and lower initial rating than the non-musician group.</p><p>2A. The addition of a severe performance error would cause an immediate decrease in performance ratings, measured from pre-determined points before and after the inserted error and the effect on the final rating when compared with a control performance. A corresponding negative facial reaction would intensify this response.</p><p>2B. As with hypothesis 1B, musicians' reactions to the error would be more severe than non-musicians' as a result of stronger expectations.</p><p>Testing these hypotheses required the measurement of participants' reactions to the performances as they unfolded, thus participants provided continuous responses in real-time using bespoke software in addition to completing overall, <italic>post hoc</italic> quality ratings. In order to maximize ecological validity, full performances were used that, despite experimental manipulations, gave the impression of live, undoctored performances.</p></sec><sec sec-type="materials and methods" id="s2"><title>Materials and methods</title><sec><title>Participants</title><p>Participants (<italic>N</italic> = 105) with and without musical training were recruited via email and in person from conservatoires, universities, and public music and science festivals held in southeast England. Musicians (<italic>n</italic> = 53: 28 men, 25 women, mean age = 27.38, SD &#x000b1; 12.16 years) were defined as participants currently undertaking undergraduate music training (<italic>n</italic> = 27), those completing or holding postgraduate music training (<italic>n</italic> = 23), and/or practicing professional musicians (<italic>n</italic> = 18). Participants not meeting these criteria were classified as non-musicians (<italic>n</italic> = 52: 31 men, 21 women, mean age = 30.82, SD &#x000b1; 16.23 years), which included amateurs without specialist training (<italic>n</italic> = 30), participants who had undertaken some undergraduate training in music but did not currently practice (<italic>n</italic> = 6), and those who did not play an instrument or sing (<italic>n</italic> = 16), thus representing a variety of musical engagement. Primary instrument families represented across groups were piano (<italic>n</italic> = 30), string (<italic>n</italic> = 16), guitar (<italic>n</italic> = 11), woodwind (<italic>n</italic> = 11), voice (<italic>n</italic> = 7), brass (<italic>n</italic> = 6), and other (<italic>n</italic> = 6). The musician group had greater exposure to visually presented (live or recorded) classical performances, with 81% viewing at least monthly, in contrast to just 31% of non-musicians (13% of non-musicians reported never seeing performances). This study was conducted according to ethical guidelines of the British Psychological Society following internal Royal College of Music (RCM) approval on behalf of the Conservatoires UK Research Ethics Committee. Informed consent was obtained from all participants, and no payment was given in exchange for participation.</p></sec><sec><title>Research design</title><p>Participants were randomly assigned to one of five conditions, each of which comprised viewing one of five videos of a manipulated piano performance while providing a continuous quality rating on custom software (see Figures <xref ref-type="fig" rid="F1">1</xref> and <xref ref-type="fig" rid="F2">2</xref>). This was followed by a hardcopy questionnaire. Details of the stimuli, measures, and analyses are provided below.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Screenshot of the custom continuous measurement interface</bold>. As the video plays the user can move the slider across the screen via the trackpad. Here, the user has already clicked to register the first judgment, turning the slider blue.</p></caption><graphic xlink:href="fpsyg-08-00513-g0001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>The study design</bold>. One hundred and five participants were each randomly assigned one video condition to view. From their continuous data, the time to first decision (T<sub>1</sub>), time to final rating (T<sub>2</sub>), first rating (R<sub>1</sub>), and final rating (R<sub>2</sub>) were calculated. The overall rating (R<sub>3</sub>) came from a written score completed after the video and continuous measurement were finished, followed by a questionnaire. Shading: yellow = inappropriate stage entrance, orange = aural performance error, blue = negative facial reaction.</p></caption><graphic xlink:href="fpsyg-08-00513-g0002"/></fig></sec><sec><title>Stimuli</title><p>To maximize the ecological validly of the stimuli, recordings were created that would give the impression of a genuine live performance. Chopin's <italic>Aeolian Harp</italic> Etude (Op. 25, No. 1) was chosen as the work to be performed due to its short length (~3 min), its familiarity to Western classical audiences, and its homogenous structure: the composition features a perpetual-motion texture that is maintained throughout. Therefore, a brief break and resumption of that texture would be easily perceived by non-musicians as a severe unintentional error, similar in effect to a layperson with no knowledge of figure skating technique recognizing the severity of rare but occasional cases of professional skaters falling to the ice. A postgraduate pianist at the RCM performed the work in the RCM's Concert Hall on a grand piano. The lighting, staging, and performer's dress reflected a live concert experience. Audio was recorded via two Schoeps MK41 microphones hung above the stage, and video was recorded through two remotely controlled Panasonic AW-HE50 cameras.</p><p>Musicians have been shown to be highly sensitive to audiovisual asynchronies when viewing recordings of musicians with their hands in frame, particularly of their own instrument type (Bishop and Goebl, <xref rid="B2" ref-type="bibr">2014</xref>). Therefore, footage of genuinely synchronized audiovisual information with the hands in view was cut with views wherein the hands were occluded during asynchronous moments. Camera 1 was positioned at the back of the hall and captured a lateral view showing the entire pianist and instrument including a clear view of the hands on the keyboard. Camera 2 was positioned at stage left, looking across the body of the piano with a clear frontal and tightly framed view of the performer's face and upper body, obscuring the hands. Behne and W&#x000f6;llner (<xref rid="B1" ref-type="bibr">2011</xref>) demonstrated that such manipulations can give the impression of undoctored performances even among participants with high levels of musical training and knowledge of audiovisual and experimental manipulation techniques.</p><p>The pianist was instructed to perform the complete work from memory at a high, but not necessarily &#x0201c;perfect&#x0201d; standard, achieved by recording the work shortly before the performer considered it to be concert-ready. This resulted in several minor inconsistencies in the performance (e.g., a wrong note at ~128 s) maintained throughout each condition to increase the validly of such a performance containing a catastrophic error in the relevant conditions. Following the performance, the pianist bowed and walked off stage. The pianist was also recorded making two stage entrances: one appropriate and one inappropriate. These were based on the criteria outlined by Platz and Kopiez (<xref rid="B34" ref-type="bibr">2013</xref>), in which the appropriate entrance displayed a confident stride, repeated eye contact with the audience, a deep bow, and nods of appreciation for the applause, while the inappropriate entrance featured a narrow gate, limited eye contact, hands in pockets, and an abbreviated bow. Additionally, a performance error as described above was recorded in which the pianist was instructed to begin playing approximately two-thirds of the way into the piece (bar 27), and then make a critical error in which the performance stops for several seconds, he struggles momentarily to find his place, then continues onward. He was also given the explicit instruction to convey intense frustration at having committed the error through his facial expression. Finally, a wide shot was filmed displaying the set stage without the pianist present with the first several rows of audience seats visible. Previously recorded pre-concert activity in the same venue was then superimposed over the bottom section of the screen, along with corresponding audio, giving the impression of a live audience present for the performance. Audience applause (taken from existing footage from the venue to ensure acoustic validity) was added to the stage entrances and to the final bow. With the resulting footage, five conditions were constructed using Final Cut Pro 7, each exactly 3 min in length plus an additional 4 s in the two videos (<xref ref-type="supplementary-material" rid="SM4">3</xref> and <xref ref-type="supplementary-material" rid="SM5">4</xref>) containing an aural performance error (see Table <xref ref-type="table" rid="T1">1</xref> and Figure <xref ref-type="fig" rid="F2">2</xref> for summaries and Videos <xref ref-type="supplementary-material" rid="SM2">1</xref>&#x02013;<xref ref-type="supplementary-material" rid="SM6">5</xref> in the Supplementary Material).</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Properties of the five videos used in the study</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Condition</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Description</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Stage entrance</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Length (s)</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Error at 100 s</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Video <xref ref-type="supplementary-material" rid="SM2">1</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Standard</td><td valign="top" align="left" rowspan="1" colspan="1">Appropriate</td><td valign="top" align="center" rowspan="1" colspan="1">180</td><td valign="top" align="left" rowspan="1" colspan="1">None</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Video <xref ref-type="supplementary-material" rid="SM3">2</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Inappropriate stage entrance</td><td valign="top" align="left" rowspan="1" colspan="1">Inappropriate</td><td valign="top" align="center" rowspan="1" colspan="1">180</td><td valign="top" align="left" rowspan="1" colspan="1">None</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Video <xref ref-type="supplementary-material" rid="SM4">3</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Aural error with facial reaction</td><td valign="top" align="left" rowspan="1" colspan="1">Appropriate</td><td valign="top" align="center" rowspan="1" colspan="1">184</td><td valign="top" align="left" rowspan="1" colspan="1">Aural/facial</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Video <xref ref-type="supplementary-material" rid="SM5">4</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Aural error only</td><td valign="top" align="left" rowspan="1" colspan="1">Appropriate</td><td valign="top" align="center" rowspan="1" colspan="1">184</td><td valign="top" align="left" rowspan="1" colspan="1">Aural only</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Video <xref ref-type="supplementary-material" rid="SM6">5</xref></td><td valign="top" align="left" rowspan="1" colspan="1">Facial reaction only</td><td valign="top" align="left" rowspan="1" colspan="1">Appropriate</td><td valign="top" align="center" rowspan="1" colspan="1">180</td><td valign="top" align="left" rowspan="1" colspan="1">Facial only</td></tr></tbody></table><table-wrap-foot><p><italic>Each video was formed of manipulations of the same recording of Chopin's Aeolian Harp Etude. Videos <xref ref-type="supplementary-material" rid="SM2">1</xref>&#x02013;<xref ref-type="supplementary-material" rid="SM6">5</xref> are available in the Supplementary Material</italic>.</p></table-wrap-foot></table-wrap></sec><sec><title>Continuous measurement</title><p>Continuous measurements, in which participants provide real-time feedback through a dial, slider, or software, have been used extensively in studies of music perception in relation to musical stimuli as they change over time, including listeners' genre preferences (Brittin and Sheldon, <xref rid="B3" ref-type="bibr">1995</xref>), perception of loudness (Geringer, <xref rid="B11" ref-type="bibr">1995</xref>), focus of attention (Madsen and Geringer, <xref rid="B28" ref-type="bibr">1999</xref>; Williams et al., <xref rid="B66" ref-type="bibr">2011</xref>), perception of musical intensity (Brittin and Duke, <xref rid="B4" ref-type="bibr">1997</xref>), perceived tension (Madsen, <xref rid="B27" ref-type="bibr">1998</xref>; Vines et al., <xref rid="B56" ref-type="bibr">2006</xref>; Williams et al., <xref rid="B66" ref-type="bibr">2011</xref>), perceived expressivity (Silveira and Diaz, <xref rid="B46" ref-type="bibr">2014</xref>), and emotional responses (Madsen, <xref rid="B27" ref-type="bibr">1998</xref>; Schubert, <xref rid="B40" ref-type="bibr">1999</xref>, <xref rid="B41" ref-type="bibr">2004</xref>; Nagel et al., <xref rid="B32" ref-type="bibr">2007</xref>; Egermann et al., <xref rid="B9" ref-type="bibr">2009</xref>). Such measures, however, have had relatively limited use in studies of performance evaluation. Himonides (<xref rid="B19" ref-type="bibr">2011</xref>) conducted a pilot study examining continuous quality ratings of sung vocal performances, and Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>) established baseline values of time to first- and final-decisions and relationships between continuous and static ratings in judgments of short, audio-only piano performances. No research to date has examined whether such outcomes are affected by visual performance features as examined here. Thus, a bespoke tool was created using the software package <italic>Presentation</italic> (Neurobehavioral Software, v. 17.2) in order to deliver the video stimuli while simultaneously collecting synchronized continuous responses. After displaying an initial screen with instructions to &#x0201c;rate the quality of the following performance from &#x02018;Poor&#x02019; to &#x02018;Excellent,&#x02019; &#x0201d; the software presented the video across the top of the screen. Underneath, a horizontal gray bar was presented alongside a rating scale ranging from 1 (poor) to 7 (excellent), following the scale used by Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>). Horizontal movement on the laptop trackpad corresponded with a red bar moving across the gray space, which also recorded the position from 1 to 70 at 2 Hz in a separate file for analysis (also in line with Thompson et al., <xref rid="B49" ref-type="bibr">2007</xref>). The red bar began at the midpoint (35 out of 70), and clicking the trackpad recorded a timestamp and turned the red bar to blue to confirm a first decision had been entered. Figure <xref ref-type="fig" rid="F1">1</xref> displays a screenshot of the continuous measurement interface.</p></sec><sec><title>Procedure</title><p>After providing informed consent, participants were told that they would be evaluating a recording of a classical pianist. They were instructed to base their ratings &#x0201c;not on how much you enjoy the performance, but by how &#x02018;good&#x02019; you feel the performance is, as if you were a competition judge.&#x0201d; This differentiation was emphasized because the constructs of performance enjoyment and quality ratings, while correlated (Thompson, <xref rid="B47" ref-type="bibr">2007</xref>), are assumed to be mutually exclusive in the act of professional performance evaluation (Thompson and Williamon, <xref rid="B48" ref-type="bibr">2003</xref>). They were then able to try the continuous measurement software using a brief recording of a violinist playing unaccompanied Bach, with the instructions that:
<list list-type="bullet"><list-item><p>as soon as they had an opinion of the quality of the performance they should move the slider to the appropriate point and click (the click served to mark a first decision in the few cases where the slider's midpoint already indicated the participant's first rating), and</p></list-item><list-item><p>they should feel free to move the slider at any point (without needing to click) if their opinion changed over the course of the performance.</p></list-item></list></p><p>They then initiated, watched, and rated one of the five videos (randomly assigned). Following the video, they completed a questionnaire on which they rated the performance's quality and typicality, their familiarity with the work, their enjoyment of the performance, and the appropriateness of the performer's on-stage behavior on 7-point Likert-type scales. They were also free to provide open comments on the performance. The questionnaire also collected basic background information including age and musical training.</p></sec><sec><title>Data preparation and analyses</title><p>Data were first treated to several operations, primarily following Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>), resulting in five general indicators of time to and score of first and final ratings. As a preliminary check, a visual examination of the data revealed one obvious erroneous spike in one participant's data caused by an accidental touch of the trackpad (i.e., a quick movement to an extreme score followed by an immediate return to the original score); this was removed and replaced with the score indicated immediately before and after the spike. Following this, five discreet variables were extracted from the full continuous data (see Figure <xref ref-type="fig" rid="F2">2</xref>):
<list list-type="bullet"><list-item><p>Time to first decision, <bold>T</bold><sub>1</sub>: As a brief amount of time was necessary to move the slider to the desired first rating point, the time of first movement (or the first click in the 3 of 105 cases where there was no initial first movement) was noted as the initial decision time, T<sub>1</sub>. The continuous measurement ratings were taken from the beginning of the video, yet the first note was not played until 25 s; therefore, 25 s were subtracted from each score, giving initial ratings made prior to the first note a negative time value. Two outliers wherein a first decision was not registered until after two-thirds of the performance had elapsed were removed, based on an admission from one participant that she had forgotten to indicate any judgment until late into the trial.</p></list-item><list-item><p>First rating, <bold>R</bold><sub>1</sub>: The first point at which the participant maintained a stable rating of at least 2 s was taken as the first rating.</p></list-item><list-item><p>Final rating, <bold>R</bold><sub>2</sub>: The final score reported in the continuous data.</p></list-item><list-item><p>Time to final rating, <bold>T</bold><sub>2</sub>: Participants' continuous data tended toward brief, direct movements between stable plateaus. Thus, the time of final rating, T<sub>2</sub>, was recorded as the point at which the movement leading to the final rating (R<sub>2</sub>) was started. As with T<sub>1</sub>, 25 s were subtracted from each score to account for the stage entrance.</p></list-item><list-item><p>Overall rating, <bold>R</bold><sub>3</sub>: The overall written score provided in the questionnaire on a scale of 1&#x02013;7. For a direct comparison with the final continuous rating, R<sub>2</sub> was also converted from 70-point to 7-point values following Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>).</p></list-item></list></p><p>Preliminary analyses using a series of <italic>t</italic>-tests showed no significant differences between men and women on the group T and R scores; subsequently, sex was discounted as a between-groups variable. Differences in R and T scores between conditions (Videos <xref ref-type="supplementary-material" rid="SM2">1</xref>&#x02013;<xref ref-type="supplementary-material" rid="SM6">5</xref>) and experience groups (musicians vs. non-musicians) were analyzed using 5 &#x000d7; 2 factorial ANOVA models. Planned contrasts were run specifically for the hypotheses being tested. In examining the effect of the stage entrance on T<sub>1</sub> and R<sub>1</sub> (i.e., hypothesis 1A), only Video <xref ref-type="supplementary-material" rid="SM3">2</xref> with the &#x0201c;inappropriate&#x0201d; entrance differed in opening material that could affect these measurements. Therefore, a Helmert contrast was employed as this allows a condition to be compared with the sum mean of the following conditions (i.e., Video <xref ref-type="supplementary-material" rid="SM3">2</xref> vs. <xref ref-type="supplementary-material" rid="SM2">1</xref>, <xref ref-type="supplementary-material" rid="SM4">3</xref>, <xref ref-type="supplementary-material" rid="SM5">4</xref>, &#x00026; <xref ref-type="supplementary-material" rid="SM6">5</xref>; Video <xref ref-type="supplementary-material" rid="SM2">1</xref> vs. <xref ref-type="supplementary-material" rid="SM4">3</xref>, <xref ref-type="supplementary-material" rid="SM5">4</xref>, &#x00026; <xref ref-type="supplementary-material" rid="SM6">5</xref>; Video <xref ref-type="supplementary-material" rid="SM4">3</xref> vs. <xref ref-type="supplementary-material" rid="SM5">4</xref> &#x00026; <xref ref-type="supplementary-material" rid="SM6">5</xref>; Video <xref ref-type="supplementary-material" rid="SM5">4</xref> vs. <xref ref-type="supplementary-material" rid="SM6">5</xref>). Simple contrasts, in which each video was compared with the <italic>standard</italic> control, were used for the remaining tests (i.e., hypothesis 2A). <italic>T</italic>-tests were used for direct comparisons of experience level in hypotheses 1B and 2B. As R<sub>1</sub> and R<sub>2</sub> were commensurable, they were tested using a mixed 2 &#x000d7; 5 &#x000d7; 2 ANOVA to examine changes between first and final ratings. To analyze moment-by-moment changes within each group resulting from the stage entrance behavior, performance errors, and facial reactions, repeated measures ANOVAs were calculated using mean scores at 10-s increments from the beginning of the video. This followed the method reported by Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>), who used 15-s increments; the value was reduced to 10 to provide greater precision around the performance error.</p></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>Analyses in the first two sections below examine between-group differences (i.e., conditions 1&#x02013;5 and musicians vs. non-musicians) and within-group comparisons of time to first decision (T<sub>1</sub>), time to final decision (T<sub>2</sub>), and first (R<sub>1</sub>), final (R<sub>2</sub>), and overall written (R<sub>3</sub>) ratings. A complete set of means and SDs are provided in Supplementary Table <xref ref-type="supplementary-material" rid="SM1">1</xref>. The following two sections focus on repeated measures analyses of the continuous effects of the stage entrance and aural/facial errors. The final section examines relationships between general features of the participants' attitude toward the work, such as familiarity with and likeability of the piece.</p><sec><title>Effects of stage entrance on time to first decision (T<sub>1</sub>) and first rating (R<sub>1</sub>)</title><p>Four of the five conditions used the same opening material: that of the appropriate, confident stage entrance by the performer. Only the condition featuring the inappropriate stage entrance (Video <xref ref-type="supplementary-material" rid="SM3">2</xref>) varied from the others in its opening material, thus we investigated whether participants responded differently to the altered stage entrance in both the time to and result of their first ratings: T<sub>1</sub> and R<sub>1</sub> (hypothesis 1A). To test this, ANOVAs comparing condition (&#x000d7;5) and musical experience (&#x000d7;2) with T<sub>1</sub> and R<sub>1</sub> as dependent variables were each followed by a Helmert contrast.</p><p>For T<sub>1</sub>, while the ANOVA showed no overall differences between conditions, experience groups, or any interaction, the Helmert contrast showed a significantly lower time to first decision [<italic>t</italic><sub>(93)</sub> = &#x02212;10.42, <italic>p</italic> &#x0003c; 0.05, <italic>r</italic> = 0.73] while watching the inappropriate stage entrance (<italic>M</italic> = 8.00, SD &#x000b1; 17.00 s) vs. the combined effect of the remaining four (<italic>M</italic> = 18.52, SD &#x000b1; 20.64 s; see Figure <xref ref-type="fig" rid="F3">3</xref>). Level 2 of the contrast, in which the <italic>standard</italic> condition was compared with the remaining three, showed no significant difference, demonstrating consistent decision times across groups viewing videos with identical opening material. Furthermore, 6 of the 21 <italic>entrance</italic> raters (29%) recorded a first decision before the performer had played his first note, compared with 6 of the remaining 84 participants (14%) that viewed one of the other four conditions.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>The combined mean time to first judgment (T<sub>1</sub>) in seconds measured from the first note played</bold>. The inappropriate <italic>entrance</italic> condition resulted in a significantly lower time to first decision compared with the other four conditions. Error bars show 95% CI. <sup>*</sup><italic>p</italic> &#x0003c; 0.05, as tested using a Helmert contrast in which the <italic>entrance</italic> condition was compared with the mean of all subsequent conditions.</p></caption><graphic xlink:href="fpsyg-08-00513-g0003"/></fig><p>For R<sub>1</sub>, the ANOVA showed a significant overall effect of condition [<italic>F</italic><sub>(4, 95)</sub> = 4.94, <italic>p</italic> &#x0003c; 0.005, &#x003b7;<sup>2</sup> = 0.16], with no overall effect of or interaction with experience group. The Helmert contrast mirrored that of T<sub>1</sub>, showing a significantly lower score reported [<italic>t</italic><sub>(95)</sub> = &#x02212;7.78, <italic>p</italic> &#x0003c; 0.005, <italic>r</italic> = 0.62; see Figure <xref ref-type="fig" rid="F4">4</xref>] by those watching the inappropriate stage entrance vs. the remaining conditions. Also as with T<sub>1</sub>, no significant effect was seen at the second contrast level comparing the <italic>standard</italic> and remaining videos. The hypothesis that musicians would more harshly penalize an inappropriate stage entrance (hypothesis 1B) was confirmed with a comparison [<italic>t</italic><sub>(19)</sub> = &#x02212;2.00, <italic>p</italic> &#x0003c; 0.05, <italic>r</italic> = 0.42; one-tailed] wherein musicians gave an average initial rating of 34.91 (SD &#x000b1; 17.18) and non-musicians a rating of 47.30 (SD &#x000b1; 9.66), on par with first ratings across the other conditions. No significant difference in time to first decision (T<sub>1</sub>) was found between musicians and non-musicians in a similar comparison. Thus, the manipulated stage entrance was indeed found to have an effect on continuous quality evaluations. Musicians gave significantly lower initial ratings when viewing the inappropriate stage entrance, and both musicians and non-musicians delivered their first ratings of this condition in a significantly shorter length of time.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>First continuous ratings (R<sub>1</sub>) of musicians (blue) and non-musicians (green) on a scale from 1 to 70</bold>. The inappropriate <italic>entrance</italic> condition resulted in a significantly lower first rating compared with the other four conditions. A direct comparison revealed that this difference was due to a significantly lower first rating among musicians as compared with non-musicians. Error bars show 95% CI. <sup>*</sup><italic>p</italic> &#x0003c; 0.005, as tested using a Helmert contrast in which the <italic>entrance</italic> condition was compared with the mean of all subsequent conditions. <sup>**</sup><italic>p</italic> &#x0003c; 0.05 in a comparison between musicians and non-musicians within the <italic>entrance</italic> condition.</p></caption><graphic xlink:href="fpsyg-08-00513-g0004"/></fig></sec><sec><title>Effects of condition on final decision (T<sub>2</sub>) and final rating (R<sub>2</sub> and R<sub>3</sub>)</title><p>The mean time to a final, stable rating (T<sub>2</sub>) across conditions was 128.31 s (SD &#x000b1; 24.51) of the total 180 s of the entire performance (or 184 s for Videos <xref ref-type="supplementary-material" rid="SM4">3</xref> and <xref ref-type="supplementary-material" rid="SM5">4</xref>, in which the aural error incorporated an extra 4 s of musical material). The ANOVA revealed no significant difference in final decision times based on condition or experience, and a Helmert contrast with the <italic>entrance</italic> condition in the first position and <italic>standard</italic> in the second showed no effect of condition at any level (see Figure <xref ref-type="fig" rid="F5">5</xref>). Thus, while the inappropriate stage entrance caused raters to make their first judgments more quickly (hypothesis 1A), it showed no significant effect on how long they took to come to a final decision about the performance.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>The combined mean time to final judgment (T<sub>2</sub>) in seconds measured from the first note played</bold>. No significant difference was found between conditions. Error bars show 95% CI.</p></caption><graphic xlink:href="fpsyg-08-00513-g0005"/></fig><p>The mixed 2 &#x000d7; 5 &#x000d7; 2 ANOVA comparing the first (R<sub>1</sub>) and final (R<sub>2</sub>) continuous scores showed that, overall, the groups' initial mean ratings did not differ significantly from their final ratings. However, a significant interaction of rating and condition was shown [<italic>F</italic><sub>(4, 95)</sub> = 5.56, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.18], and a planned simple contrast comparing each condition with the <italic>standard</italic> showed that the <italic>aural/facial</italic> condition followed a different overall profile [<italic>t</italic><sub>(95)</sub> = &#x02212;7.55, <italic>p</italic> &#x0003c; 0.01, <italic>r</italic> = 0.61]. As the ANOVA examining R<sub>1</sub> showed no significant difference in the first score for this condition, it followed that a significantly lower final score would instead be the cause of the significant interaction effect. A 5 &#x000d7; 2 ANOVA examining R<sub>2</sub> confirmed this with a significant effect of condition [<italic>F</italic><sub>(4, 95)</sub> = 5.56, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.19] with no effect of or interaction with experience. Again, a planned simple contrast was conducted comparing each condition with the <italic>standard</italic>. Only the <italic>aural</italic>/<italic>facial</italic> condition (<italic>M</italic> = 36.00, SD &#x000b1; 13.37) was found to have received a final continuous rating significantly lower than the <italic>standard</italic> [<italic>M</italic> = 46.82, SD &#x000b1; 11.55; <italic>t</italic><sub>(95)</sub> = &#x02212;10.80, <italic>p</italic> &#x0003c; 0.005, <italic>r</italic> = 0.74; hypothesis 2A; see Figure <xref ref-type="fig" rid="F6">6</xref>].</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Final continuous ratings (R<sub>2</sub>) of musicians (blue) and non-musicians (green) on a scale from 1 to 70</bold>. The <italic>aural/facial</italic> condition, comprising a performance error with corresponding negative facial reaction, resulted in the only significantly lower performance rating. Error bars show 95% CI. <sup>*</sup><italic>p</italic> &#x0003c; 0.005, wherein a simple contrast compared each condition with the <italic>standard</italic>, with no interaction with experience group.</p></caption><graphic xlink:href="fpsyg-08-00513-g0006"/></fig><p>An analysis of the final written scores (R<sub>3</sub>) showed similar findings, with a main effect of condition [<italic>F</italic><sub>(4, 95)</sub> = 4.87, <italic>p</italic> &#x0003c; 0.005, &#x003b7;<sup>2</sup> = 0.17] and contrasts revealing that only the <italic>aural/facial</italic> score (<italic>M</italic> = 3.90; SD &#x000b1; 0.97) was significantly lower than the <italic>standard</italic> on the 7-point scale [<italic>M</italic> = 4.86, SD &#x000b1; 1.32; <italic>t</italic><sub>(95)</sub> = &#x02212;0.96, <italic>p</italic> &#x0003c; 0.005, <italic>r</italic> = 0.10; see Figure <xref ref-type="fig" rid="F7">7</xref>]. A direct overall comparison of R<sub>2</sub> and R<sub>3</sub> with a repeated measures ANOVA (following a conversion of R<sub>2</sub> from a 70-point to a comparable 7-point scale, as described in the &#x0201c;Data Preparation and Analyses&#x0201d; section) with experience and condition as between-subjects variables also showed no main effect of rating type on the reported scores. R<sub>2</sub> and R<sub>3</sub> also showed a strong correlation (<italic>r</italic><sub>&#x003c4;</sub> = 0.70, <italic>p</italic> &#x0003c; 0.001). This suggests that the final continuous ratings accurately reflected the opinions given by the more routinely used written scores, thus confirming the validity of continuous rating as a proxy for evaluation scores given in standard summative procedures (Thompson et al., <xref rid="B49" ref-type="bibr">2007</xref>). R<sub>2</sub> and R<sub>3</sub> both showed small correlations with R<sub>1</sub> (<italic>r</italic><sub>&#x003c4;</sub> = 0.23, <italic>p</italic> &#x0003c; 0.005 and <italic>r</italic><sub>&#x003c4;</sub> = 0.23, <italic>p</italic> &#x0003c; 0.001, respectively).</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Final written ratings (R<sub>3</sub>) of musicians (blue) and non-musicians (green) on a scale from 1 to 7</bold>. As with R<sub>2</sub>, the <italic>aural/facial</italic> condition, comprising a performance error with corresponding negative facial reaction, resulted in the only significantly lower performance rating. Error bars show 95% CI. <sup>*</sup><italic>p</italic> &#x0003c; 0.005, wherein a simple contrast compared each condition with the <italic>standard</italic>, with no interaction with experience group.</p></caption><graphic xlink:href="fpsyg-08-00513-g0007"/></fig><p>These analyses found that the inappropriate stage entrance did not have a lasting effect on the final ratings (R<sub>2</sub> and R<sub>3</sub>) given by either musicians or non-musicians. As this contrasts with the lower initial ratings (R<sub>1</sub>) given by musicians as reported in the previous section, the following section examines the point at which this difference in rating converged with the <italic>standard</italic> condition. Regarding the performance errors, only the <italic>aural/facial</italic> condition had a significant effect, lowering the final ratings (R<sub>2</sub> and R<sub>3</sub>) of both experience groups. No overall effects of the <italic>facial</italic> or <italic>aural</italic> errors alone were found on the final ratings. Again, repeated measures analyses of the continuous measures data were then employed to examine the effect of the errors at the point of occurrence, as reported below.</p></sec><sec><title>Continuous effects of the stage entrance</title><p>As the above analyses of the final and overall ratings (R<sub>2</sub> and R<sub>3</sub>) showed that those viewing the inappropriate stage entrance condition did not yield significantly lower scores than those in the <italic>standard</italic> condition, the lower R<sub>1</sub> scores reported by the musicians seem to have rebounded by the end of the performance. To identify how soon after the initial stage entrance this was accomplished, average ratings at 10-s intervals from the beginning of the video were extracted and analyzed using a repeated-measures ANOVA with planned contrasts of each interval to the final score. When conducted from the 50-s mark (25 s from the first note played), where 8 of the 10 musicians in this subsection were already reporting a mean score of 50.13 (SD &#x000b1; 7.08), no significant difference from the final score was found in the remaining 12 levels. Thus, any negative impression caused by the inappropriate entrance, reflected in the quicker first rating among both experience groups and lower initial rating by musicians, was not reflected in the rating after 25 s of musical performance. Direct repeated-measures analyses prior to the 25-s point were not possible using this method due to the number of missing pairwise data sets resulting from participants who had not yet recorded their first rating. These results should be considered in light of the non-significant difference between the <italic>entrance</italic> and <italic>standard</italic> conditions in their change of R<sub>1</sub> to R<sub>2</sub>, as shown by the 2 &#x000d7; 5 &#x000d7; 2 mixed ANOVA contrasts described above, where the difference in this subgroup did not emerge as significant when examined in conjunction with the other four conditions. Thus, any effect of the stage entrance on initial ratings among musicians did not persist when the pianist began playing, despite having formed their initial, more negative impressions significantly earlier.</p></sec><sec><title>Continuous effects of the performance errors</title><p>Three conditions related to performance errors: <italic>aural/facial</italic> (Video <xref ref-type="supplementary-material" rid="SM4">3</xref>), in which a performance error with corresponding negative facial reaction was spliced into the <italic>standard</italic> recording (Video <xref ref-type="supplementary-material" rid="SM2">1</xref>); <italic>aural</italic> (Video <xref ref-type="supplementary-material" rid="SM5">4</xref>), in which audio from the same performance error was superimposed with the visual recording of the <italic>standard</italic> condition; and <italic>facial</italic> (Video <xref ref-type="supplementary-material" rid="SM6">5</xref>), in which the visual reaction to the mistake was superimposed over the correct playing. As reported above, only the <italic>aural/facial</italic> condition triggered a significantly lower overall rating than the <italic>standard</italic>, reported by both musicians and non-musicians. Visual examination of the data revealed that this stemmed from a dramatic, immediate drop in continuous ratings immediately following the error by respondents when compared with the <italic>standard</italic> (see Figure <xref ref-type="fig" rid="F8">8</xref>).</p><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>Mean participant ratings of musicians (blue; gray error bars) and non-musicians (red; black error bars) across the <italic>standard, aural/facial, aural</italic>, and <italic>facial</italic> conditions at 10-s intervals</bold>. Time in seconds from video opening&#x02014;the first note was played at 25 s and the error occurred at 100 s. Axes begin at <italic>t</italic> = 40 s to reflect the point at which most participants were supplying data, allowing for consistent representation of mean and error. A larger drop can be seen at the point of the error in the <italic>aural/facial</italic> condition, with a smaller drop in the <italic>aural</italic> condition by musicians only and no significant movement in the <italic>standard</italic> and <italic>facial</italic> conditions. Error bars show 95% CI adjusted for repeated-measures data.</p></caption><graphic xlink:href="fpsyg-08-00513-g0008"/></fig><p>To determine the individual and combined effects of the aural and visual (i.e., <italic>facial</italic>) components on musicians and non-musicians, average continuous ratings at 10-s intervals were again extracted and plotted. To determine when the final <italic>aural/facial</italic> score was finalized, a mixed ANOVA was conducted with 12 time intervals from the 70-s mark as a repeated-measures factor (30 s prior to the error, where 19 of the 20 participants across both experience groups had begun registering their continuous responses) and experience as a between-group variable. Planned contrasts comparing each point with the final score were used to isolate when the final decision was reached. A significant effect of rating over time was found [<italic>F</italic><sub>(11, 187)</sub> = 20.20, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.53] with no main effect of or interaction with experience, and contrasts were significant (<italic>p</italic> &#x0003c; 0.05, <italic>r</italic> = 0.32&#x02013;0.62) until the 120-s point (20 s following the error) which followed a slight increase from the 110-s point following the error-invoked drop. To examine musicians' and non-musicians' specific reaction to the error, difference scores were calculated between ratings immediately before (100 s) and after (110 s) its presentation for the <italic>standard, aural/facial, aural</italic>, and <italic>facial</italic> conditions. The ANOVA revealed a significant effect of condition [<italic>F</italic><sub>(3, 80)</sub> = 14.85, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.28] with contrasts revealing that both the <italic>aural/facial</italic> condition [<italic>t</italic><sub>(80)</sub> = &#x02212;19.02, <italic>p</italic> &#x0003c; 0.001, <italic>r</italic> = 0.90] and the <italic>aural</italic> condition [<italic>t</italic><sub>(80)</sub> = &#x02212;7.25, <italic>p</italic> &#x0003c; 0.05, <italic>r</italic> = 0.63] showed significant drops in comparison with the <italic>standard</italic> (<italic>M</italic> = &#x02212;19.20, SD &#x000b1; 13.87; <italic>M</italic> = &#x02212;7.43, SD &#x000b1; 7.24; and <italic>M</italic> = &#x02212;0.18, SD &#x000b1; 8.07, respectively), but no such movement was seen in the <italic>facial</italic> condition (<italic>M</italic> = &#x02212;0.90, SD &#x000b1; 7.24; see Figure <xref ref-type="fig" rid="F8">8</xref>).</p><p>Hypothesis 2B posited that musicians would react to the performance error more severely than non-musicians. A comparison confirmed this in the <italic>aural</italic> condition where musicians made a significantly larger drop [<italic>t</italic><sub>(19)</sub> = &#x02212;2.12, <italic>p</italic> &#x0003c; 0.05, <italic>r</italic> = 0.44] during that period, with musicians lowering their score by a mean 12.00 points (SD &#x000b1; 12.69) and non-musicians by 2.40 points (SD &#x000b1; 6.81) out of the total 70 over that 10-s period (see Figure <xref ref-type="fig" rid="F8">8</xref>). However, as shown by the R<sub>2</sub> and R<sub>3</sub> scores in the section above (see &#x0201c;Effects of Condition on Final Decision and Final Rating&#x0201d;), this penalization by musicians was not reflected in their overall ratings. No such difference was found in a similar comparison of the <italic>aural/facial</italic> condition.</p><p>To summarize, when the <italic>aural</italic> error was presented alone, the musicians reacted with a significantly lower immediate decrease in scores to the non-musicians, though this penalization was not reflected in the final scores. When the <italic>facial</italic> error was presented alone, no immediate or overall effect was shown, regardless of experience. When the two errors were juxtaposed in the <italic>aural/facial</italic> condition, however, both experience groups showed an immediate drop in continuous quality rating that was reflected in the final (R<sub>2</sub> and R<sub>3</sub>) ratings.</p></sec><sec><title>Work familiarity, likeability, and typicality</title><p>Participants' ratings of how much they liked and knew the composition (likeability and familiarity), how typical the performance was, and the appropriateness of the performer's behavior were tested for correlations (Kendal's tau, due to the large proportion of tied ranks within the 7-point scales) with T<sub>1</sub>, T<sub>2</sub>, R<sub>1</sub>, R<sub>2</sub>, and R<sub>3</sub>. After controlling for multiple comparisons, no significant relationships with the time to form their decisions (T<sub>1</sub> or T<sub>2</sub>) were found, and only the appropriateness of the performer's behavior significantly correlated with the overall rating, R<sub>3</sub> (<italic>r</italic><sub>&#x003c4;</sub> = 0.28, <italic>p</italic> &#x0003c; 0.05), although its correlation with R<sub>2</sub> was not significant and therefore should be interpreted with caution. A significant correlation between participants' familiarity with and liking of a composition was found (<italic>r</italic><sub>&#x003c4;</sub> = 0.37, <italic>p</italic> &#x0003c; 0.01).</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>Music quality judgments, like the performances they seek to quantify, take place over time. The present study sought to examine this temporal nature of musical assessment, employing continuous measures methodologies to reveal previously unexamined immediate and overall effects on the decision-making process of extra-musical variables that could be defined by their having occurred prior to (i.e., the stage entrance) or at a specific point during (i.e., the error) a performance.</p><p>To achieve this, we manipulated a recorded performance of Chopin's <italic>Aeolian Harp</italic> etude to vary in appropriateness of the stage entrance or in the incidence of an aural performance error and/or corresponding negative facial reaction. We also examined the effect of experience by comparing response differences in musicians and non-musicians. The continuous ratings were able to show effects of these variations that the standard <italic>post hoc</italic> measurements would not have revealed. Where the inappropriate stage entrance did not have an overall effect on final ratings, the continuous data showed a significantly shorter time to first decision across experience groups and a lower initial rating by musicians that quickly recovered, confirming both hypotheses 1A and 1B. Regarding the errors, overall written scores showed that only the performance error with corresponding facial reaction (i.e., the <italic>aural/facial</italic> condition) led to a lower rating (hypothesis 2A), but the continuous measures data again demonstrated a more complex process at work. Musicians penalized then forgave a performance error on its own, only providing an overall score when the error was paired with a negative facial reaction. Non-musicians were significantly less harsh in their initial judgment of the aural error alone (hypothesis 2B), though behaved just as their more musically experienced counterparts when the facial reaction was juxtaposed. Neither group reacted to the negative facial reaction on its own.</p><p>In the discussion of their results, Thompson et al. (<xref rid="B49" ref-type="bibr">2007</xref>) questioned the generalizability of their finding that initial decisions were made within an average of 15 s following the first note, particularly in situations outside of their audio-only condition. The present research not only supports those findings, in that initial ratings across the four groups without the inappropriate stage entrance were made in approximately 18 s, but suggests that the presence of visual information relating to the performance, including the performer's behavior as they take the stage, does not alter this process to a great degree so long as the entrance is deemed &#x0201c;appropriate.&#x0201d; When stage entrances betrayed the expectations of their audience that decision was made earlier, and occasionally before the first note was played as was hypothesized by Thompson and colleagues. This study also found that experience did not play a role in the speed at which the judgment was formed, implying that the heightened expectations and knowledge of the material to be performed neither increased nor hindered the rate at which judges could form their decisions (or, at least, were willing or able consciously to record their first decision). However, experience did play a small role in the height of the first rating, where musicians reported a significantly lower initial score than non-musicians for the inappropriate entrance. Here, their greater experience with, and thus expectations of, the protocols of stage entrance behavior in the Western classical tradition may have caused them to penalize the performer more harshly. However, this judgment did not last long. When Platz and Kopiez (<xref rid="B34" ref-type="bibr">2013</xref>) demonstrated that the appropriateness of a violinist's entrance correlated positively with their anticipation of the performance's start, they wondered how sustainable the positive motivational effect might be were the performance to continue. While it is unclear what the specific effect of a <italic>positive</italic> impression might be in the current study, due to the finding that the average group ratings did not significantly differ from final ratings in the <italic>standard</italic> condition, it was shown that the <italic>negative</italic> impressions recorded by the musicians in the <italic>entrance</italic> scenario had dissipated (i.e., ratings had returned to the baseline of the <italic>standard</italic> rating) within 25 s of the first note. This aligns with the findings of Wapnick et al. (<xref rid="B58" ref-type="bibr">2009</xref>) where the visual effect of heightened attractiveness on higher quality ratings for female performers appeared in 25-s excerpts but not in longer ones. It is perhaps promising news for musicians; while the standard finding from the general evaluation literature is that negative first impressions are more resistant to change than positive impressions (e.g., Ybarra, <xref rid="B67" ref-type="bibr">2001</xref>), in this case a negative first impression was quickly forgiven based on the quality of the performance that immediately followed. While stage entrance behavior made an impression on performance quality ratings, the impression of the musical content itself took precedence once it began. Future studies might examine the effect of an appropriate stage entrance on an initially poor musical performance, or whether a poor musical start can be as easily forgiven as the inappropriate stage entrance was here.</p><p>The negative impression of performance error on musicians was also temporary, with no indication in their final ratings that the error made a lasting impression. The lack of response from the non-musicians may indicate that they simply did not perceive that an error had occurred, though the severity of the mistake makes this situation unlikely. In the optional comments section, several non-musicians rating the aural condition indicated that they were aware of the error, where one wrote that she &#x0201c;perceived a mistake at about two-thirds of the way through.&#x0201d; Furthermore, the fact that non-musicians behaved in the same manner as the musicians in the <italic>aural/facial</italic> and <italic>facial</italic> conditions (i.e., reacting strongly to a performance error with negative facial response but having no reaction to the facial response on its own) indicates that they indeed perceived the aural difference. The question then remains why the facial reaction caused the error to be perceived as that much more detrimental to the performance, as when the negative expression was presented in isolation it caused no measured effect in either group. Put another way, it was not the behavior inherent to the expression that was penalized; it was how the expression altered the impression of the performance error itself. The ecological model of <italic>emotion face overgeneralization</italic> may account for this, wherein those interpreting a facial expression infer information not only concerning affective state but also of generalized traits (Zebrowitz and Montepare, <xref rid="B68" ref-type="bibr">2008</xref>). Participants have rated people displaying sad faces as lower in trait dominance, while happy or surprised faces resulted in higher dominance and affiliation ratings (Montepare and Dobish, <xref rid="B30" ref-type="bibr">2003</xref>). Thus, it could be expected that a musician's expression of frustration and anger at the committal of a performance error might result in the viewer regarding a trait tendency displaying general lack of control, instead of simply a performer who has, in that moment, lost control. Rather than being a musician momentarily making a mistake, they are perceived as musician <italic>that makes mistakes</italic>. This especially as the goal of music performance quality evaluations is often not only to rate the quality of the performance but, by extension, the performers themselves.</p><p>Both of these findings point to the interaction between aural and visual information, with the former taking some precedence. Tsay (<xref rid="B53" ref-type="bibr">2013</xref>, <xref rid="B54" ref-type="bibr">2014</xref>) found that presenting visual information alone led to more accurate predictions of competition results than audio-only or audiovisual condition, though, crucially, participants were given extremely brief clips in which an immediate impression had to be formed. Here, a visually specific stage entrance caused an immediate reaction that was tempered after a period of aurally specific musical content, once participants were given time to process it. A visually specific facial reaction had no effect unless it supported an aurally presented musical error. While the visual element of performance still played a role, particularly in triggering immediate reactions, the aural information was dominant over time.</p><p>Generalizability of the present study is limited by the nature of the experimental condition. While the use of genuine performance recordings and video manipulation to give the impression of a live performance was undertaken to maximize ecological validity, participants nonetheless made their judgments in artificial situations, wearing headphones while observing the performances on a laptop screen. While many music quality judgments indeed take place in this environment, whether in private listening to a recording or professional evaluation of a recorded competition submission, whether the processes of evaluation here examined are maintained <italic>in situ</italic> during live performances, surrounded by fellow audience or panel members, remains unstudied. Furthermore, the use of multiple camera angles (necessary to hide the obvious asynchrony between the hands and music in the manipulations) maximized raters' view of the pianist's face at the point of the manipulated error in the relevant conditions. This provided ideal conditions for the effects of facial expression to manifest. While this framing is common in performance broadcasts, it is less likely to be viewable in single-camera or live performance settings and further study is required to determine whether the effects of facial expression are maintained in less ideal viewing conditions. It should also be noted that the presentation of inappropriate stage entrances or performance errors were inserted into a performance of particularly high (although not perfect) overall quality. This juxtaposition was intentional in order to provide a clear experimental framework, though further study will be required to determine whether an audience's tendency to &#x0201c;forgive&#x0201d; certain forms of performance error is maintained when the quality difference between those errors and the surrounding performance is not so stark. This also relates to the extreme severity of the performance error itself, where the performance momentary stopped. While common at amateur levels, this event is increasingly rare (but not unheard of) at such high ability levels. The current study demonstrates the effects of such a catastrophic mistake; further work could employ the same design with errors of varying nature and increasing subtlety. Finally, it could be argued that use of the continuous software interfered with participants' natural processes of performance evaluation, causing an increase in cognitive load that distracted from the final rating. Promisingly, when participants were asked following the experiment whether using the software consciously affected their ability to deliver a quality judgment, only 11% reported that it made the process more difficult; 46% reported that the software made no difference, and 42% reported that it made judgments easier. Schubert (<xref rid="B42" ref-type="bibr">2013</xref>) found a test-retest reliability of approximately 80% when using a continuous interface to record perceptions of musical emotion. A significant amount of unreliability stemmed from the opening of the performance, during which participants oriented themselves to the rating paradigm. The current methodology minimizes this issue in that participants were asked not to begin recording until they had decided on their first response. Overall, this suggests that familiarity with such devices in musical experiments does not significantly affect participants' ability to focus on the task.</p><p>Overall, the present study has demonstrated a temporally dynamic process of music performance quality evaluation that can be measured to determine the effects of temporally specific musical and extra-musical factors. Visual information in particular plays a key role in the decision-making process, but in a more nuanced relationship with the aurally based musical content than previous research has been able to demonstrate. In particular, the pre-performance rituals of Western classical performance made a difference on quality ratings, both in terms of impression formation and perhaps in determining performer traits. Whether or not it has been a focus of study, the role of personal expression on musical impression formation has been acknowledged for some time in practice. George Grove, the first director of the Royal College of Music and author of the eponymous Grove Dictionary of Music, was struck by such an effect when he saw the pianist Franz Liszt perform in 1886. He wrote that he &#x0201c;was delighted (1) by his playing, so calm, clear, correct, refined&#x02013;so entirely unlike the style of the so-called &#x02018;Liszt School&#x02019;&#x02013;(2) by his face. Directly he sat down he [sic] dismissed that very artificial smile, which he always wears, and his face assumed the most beautiful serene look with enormous power and repose in it. It was quite a wonderful sight&#x0201d; (Graves, <xref rid="B15" ref-type="bibr">1903</xref>, p. 311). Grove was taken not only by the great pianist's performance, but the impression of Liszt's character; an impression that centered on the emotive capabilities of the face. Whether or not the visual aspect of Western classical performance has indeed been ignored in explicit practice and research, recent studies have moved it sharply into focus (e.g., Platz and Kopiez, <xref rid="B33" ref-type="bibr">2012</xref>; Tsay, <xref rid="B53" ref-type="bibr">2013</xref>, <xref rid="B54" ref-type="bibr">2014</xref>; Silveira, <xref rid="B45" ref-type="bibr">2014</xref>; Krah&#x000e9; et al., <xref rid="B23" ref-type="bibr">2015</xref>). Continued study of these extra-musical variables and their effects on evaluation can now tease apart the relation between and weighting of their myriad aspects, the points in time at which each is most influential, and the lasting effects they may have as musical decision-making unfolds.</p></sec><sec id="s5"><title>Author contributions</title><p>All authors listed have made substantial, direct, and intellectual contribution to the work and approved it for publication.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>We would like to thank Elisabeth Cook, Bex Gibson, Eugene Marshall, Matt Parkin, Rosie Perkins, David Rees, Sogol Shirazi, and our pianist for their help on the project.</p></ack><sec sec-type="supplementary-material" id="s6"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00513/full#supplementary-material">http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00513/full#supplementary-material</ext-link></p><supplementary-material content-type="local-data" id="SM1"><media xlink:href="Table1.DOCX"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM2"><media xlink:href="Video1.MP4"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM3"><media xlink:href="Video2.MP4"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM4"><media xlink:href="Video3.MP4"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM5"><media xlink:href="Video4.MP4"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="SM6"><media xlink:href="Video5.MP4"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behne</surname><given-names>K.-E.</given-names></name><name><surname>W&#x000f6;llner</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>Seeing or hearing the pianists? A synopsis of an early audiovisual perception experiment and a replication</article-title>. <source>Musicae Sci.</source>
<volume>15</volume>, <fpage>324</fpage>&#x02013;<lpage>342</lpage>. <pub-id pub-id-type="doi">10.1177/1029864911410955</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>L.</given-names></name><name><surname>Goebl</surname><given-names>W.</given-names></name></person-group> (<year>2014</year>). <article-title>Context-specific effects of musical expertise on audiovisual integration</article-title>. <source>Front. Psychol.</source>
<volume>5</volume>:<fpage>1123</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.01123</pub-id><pub-id pub-id-type="pmid">25324819</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brittin</surname><given-names>R. V.</given-names></name><name><surname>Sheldon</surname><given-names>D. A.</given-names></name></person-group> (<year>1995</year>). <article-title>Comparing continuous versus static measurements in music listeners' preferences</article-title>. <source>J. Res. Music Educ.</source>
<volume>43</volume>, <fpage>36</fpage>&#x02013;<lpage>46</lpage>. <pub-id pub-id-type="doi">10.2307/3345790</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brittin</surname><given-names>R. V.</given-names></name><name><surname>Duke</surname><given-names>R. A.</given-names></name></person-group> (<year>1997</year>). <article-title>Continuous versus summative evaluations of musical intensity: a comparison of two methods for measuring overall effect</article-title>. <source>J. Res. Music Educ.</source>
<volume>45</volume>, <fpage>245</fpage>&#x02013;<lpage>258</lpage>. <pub-id pub-id-type="doi">10.2307/3345584</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceaser</surname><given-names>D. K.</given-names></name><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Russo</surname><given-names>F.</given-names></name></person-group> (<year>2009</year>). <article-title>Expressing tonal closure in music performance: auditory and visual cues</article-title>. <source>Can. Acoust.</source>
<volume>37</volume>, <fpage>29</fpage>&#x02013;<lpage>34</lpage>.</mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>J. W.</given-names></name></person-group> (<year>1993</year>). <article-title>Visual perception of performance manner in the movements of solo musicians</article-title>. <source>Psychol. Music</source>
<volume>21</volume>, <fpage>103</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1177/030573569302100201</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>J. W.</given-names></name><name><surname>Edgar</surname><given-names>R.</given-names></name></person-group> (<year>2003</year>). <article-title>Gender and race bias in the judgement of Western Art music performance</article-title>. <source>Music Educ. Res.</source>
<volume>5</volume>, <fpage>169</fpage>&#x02013;<lpage>181</lpage>. <pub-id pub-id-type="doi">10.1080/1461380032000085540</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duerksen</surname><given-names>G. L.</given-names></name></person-group> (<year>1972</year>). <article-title>Some effects of expectation on evaluation of recorded musical performance</article-title>. <source>J. Res. Music Educ.</source>
<volume>20</volume>, <fpage>268</fpage>&#x02013;<lpage>272</lpage>. <pub-id pub-id-type="doi">10.2307/3344093</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egermann</surname><given-names>H.</given-names></name><name><surname>Grewe</surname><given-names>O.</given-names></name><name><surname>Kopiez</surname><given-names>R.</given-names></name><name><surname>Altenm&#x000fc;ller</surname><given-names>E.</given-names></name></person-group> (<year>2009</year>). <article-title>Social feedback influences musically induced emotions</article-title>. <source>Ann. N. Y. Acad. Sci.</source>
<volume>1169</volume>, <fpage>346</fpage>&#x02013;<lpage>350</lpage>. <pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.04789.x</pub-id><pub-id pub-id-type="pmid">19673805</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>C. A.</given-names></name></person-group> (<year>1995</year>). <article-title>Race and gender as factors in judgments of musical performance</article-title>. <source>Bull. Counc. Res. Music Educ.</source>
<volume>127</volume>, <fpage>50</fpage>&#x02013;<lpage>56</lpage>.</mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geringer</surname><given-names>J. M.</given-names></name></person-group> (<year>1995</year>). <article-title>Continuous loudness judgments of dynamics in recorded music excerpts</article-title>. <source>J. Res. Music Educ.</source>
<volume>43</volume>, <fpage>22</fpage>&#x02013;<lpage>35</lpage>. <pub-id pub-id-type="doi">10.2307/3345789</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillespie</surname><given-names>R.</given-names></name></person-group> (<year>1997</year>). <article-title>Ratings of violin and viola vibrato performance in audio-only and audiovisual presentations</article-title>. <source>J. Res. Music Educ.</source>
<volume>45</volume>, <fpage>212</fpage>&#x02013;<lpage>220</lpage>. <pub-id pub-id-type="doi">10.2307/3345581</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldin</surname><given-names>C.</given-names></name><name><surname>Rouse</surname><given-names>C.</given-names></name></person-group> (<year>2000</year>). <article-title>Orchestrating impartiality: the impact of &#x0201c;blind&#x0201d; auditions on female musicians</article-title>. <source>Am. Econ. Rev.</source>
<volume>90</volume>, <fpage>715</fpage>&#x02013;<lpage>741</lpage>. <pub-id pub-id-type="doi">10.1257/aer.90.4.715</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goolsby</surname><given-names>T. W.</given-names></name></person-group> (<year>1999</year>). <article-title>Assessment in instrumental music</article-title>. <source>Music Educ. J.</source>
<volume>86</volume>, <fpage>31</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.2307/3399587</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>C. L.</given-names></name></person-group> (<year>1903</year>). <source>The Life &#x00026; Letters of Sir George Grove</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Macmillan</publisher-name>.</mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>N. K.</given-names></name></person-group> (<year>2008</year>). <article-title>The effects of concert dress and physical appearance on perceptions of female solo performers</article-title>. <source>Musicae Sci.</source>
<volume>12</volume>, <fpage>273</fpage>&#x02013;<lpage>290</lpage>. <pub-id pub-id-type="doi">10.1177/102986490801200205</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>N. K.</given-names></name></person-group> (<year>2010</year>). <article-title>&#x02018;Posh music should equal posh dress&#x02019;: an investigation into the concert dress and physical appearance of female soloists</article-title>. <source>Psychol. Music</source>
<volume>38</volume>, <fpage>159</fpage>&#x02013;<lpage>177</lpage>. <pub-id pub-id-type="doi">10.1177/0305735608100372</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>N. K.</given-names></name></person-group> (<year>2011</year>). <article-title>The fabric of performance: values and social practices of classical music expressed through concert dress choice</article-title>. <source>Music Perform. Res.</source>
<volume>4</volume>, <fpage>30</fpage>&#x02013;<lpage>48</lpage>.</mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Himonides</surname><given-names>E.</given-names></name></person-group> (<year>2011</year>). <article-title>Mapping a beautiful voice: the continuous response measurement apparatus (CReMA)</article-title>. <source>J. Music Technol. Educ.</source>
<volume>4</volume>, <fpage>5</fpage>&#x02013;<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1386/jmte.4.1.5_1</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Krumhansl</surname><given-names>C. L.</given-names></name></person-group> (<year>2011</year>). <article-title>What does seeing the performer add? It depends on musical style, amount of stage behavior, and audience expertise</article-title>. <source>Musicae Sci.</source>
<volume>15</volume>, <fpage>343</fpage>&#x02013;<lpage>364</lpage>. <pub-id pub-id-type="doi">10.1177/1029864911414172</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jesse</surname><given-names>A.</given-names></name><name><surname>Massaro</surname><given-names>D. W.</given-names></name></person-group> (<year>2010</year>). <article-title>Seeing a singer helps comprehension of the song's lyrics</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>17</volume>, <fpage>323</fpage>&#x02013;<lpage>328</lpage>. <pub-id pub-id-type="doi">10.3758/PBR.17.3.323</pub-id><pub-id pub-id-type="pmid">20551353</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juchniewicz</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>The influence of physical movement on the perception of musical performance</article-title>. <source>Psychol. Music</source>
<volume>36</volume>, <fpage>417</fpage>&#x02013;<lpage>427</lpage>. <pub-id pub-id-type="doi">10.1177/0305735607086046</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krah&#x000e9;</surname><given-names>C.</given-names></name><name><surname>Hahn</surname><given-names>U.</given-names></name><name><surname>Whitney</surname><given-names>K.</given-names></name></person-group> (<year>2015</year>). <article-title>Is seeing (musical) believing? The eye versus the ear in emotional responses to music</article-title>. <source>Psychol. Music</source>
<volume>43</volume>, <fpage>140</fpage>&#x02013;<lpage>148</lpage>. <pub-id pub-id-type="doi">10.1177/0305735613498920</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kroger</surname><given-names>C.</given-names></name><name><surname>Margulis</surname><given-names>E. H.</given-names></name></person-group> (<year>2017</year>). <article-title>&#x0201c;But they told me it was professional&#x0201d;: extrinsic factors in the evaluation of musical performance</article-title>. <source>Psychol. Music</source>
<volume>45</volume>, <fpage>49</fpage>&#x02013;<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1177/0305735616642543</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehmann</surname><given-names>M.</given-names></name><name><surname>Kopiez</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <article-title>The influence of on-stage behavior on the subjective evaluation of rock guitar performances</article-title>. <source>Musicae Sci.</source>
<volume>17</volume>, <fpage>472</fpage>&#x02013;<lpage>494</lpage>. <pub-id pub-id-type="doi">10.1177/1029864913493922</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Livingstone</surname><given-names>S. R.</given-names></name><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Wanderley</surname><given-names>M. M.</given-names></name><name><surname>Palmer</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>). <article-title>Common cues to emotion in the dynamic facial expressions of speech and song</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>68</volume>, <fpage>952</fpage>&#x02013;<lpage>970</lpage>. <pub-id pub-id-type="doi">10.1080/17470218.2014.971034</pub-id><pub-id pub-id-type="pmid">25424388</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madsen</surname><given-names>C. K.</given-names></name></person-group> (<year>1998</year>). <article-title>Emotion versus tension in Haydn's Symphony no. 104 as measured by the two-dimensional continuous response digital interface</article-title>. <source>J. Res. Music Educ.</source>
<volume>46</volume>, <fpage>546</fpage>&#x02013;<lpage>554</lpage>.</mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madsen</surname><given-names>C. K.</given-names></name><name><surname>Geringer</surname><given-names>J. M.</given-names></name></person-group> (<year>1999</year>). <article-title>Comparison of good versus bad tone quality/intonation of vocal and string performances: issues concerning measurement and reliability of the continuous response digital interface</article-title>. <source>Bull. Counc. Res. Music Educ.</source>
<volume>141</volume>, <fpage>86</fpage>&#x02013;<lpage>92</lpage>.</mixed-citation></ref><ref id="B29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McPherson</surname><given-names>G. E.</given-names></name><name><surname>Schubert</surname><given-names>E.</given-names></name></person-group> (<year>2004</year>). <article-title>Measuring performance enhancement in music</article-title>, in <source>Musical Excellence: Strategies and Techniques to Enhance Performance</source>, ed <person-group person-group-type="editor"><name><surname>Williamon</surname><given-names>A.</given-names></name></person-group>(<publisher-loc>Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>), <fpage>61</fpage>&#x02013;<lpage>82</lpage>.</mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montepare</surname><given-names>J. M.</given-names></name><name><surname>Dobish</surname><given-names>H.</given-names></name></person-group> (<year>2003</year>). <article-title>The contribution of emotion perceptions and their overgeneralizations to trait impressions</article-title>. <source>J. Nonverbal Behav.</source>
<volume>27</volume>, <fpage>237</fpage>&#x02013;<lpage>254</lpage>. <pub-id pub-id-type="doi">10.1023/A:1027332800296</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>S. J.</given-names></name><name><surname>Price</surname><given-names>H. E.</given-names></name><name><surname>Smedley</surname><given-names>E. M.</given-names></name><name><surname>Meals</surname><given-names>C. D.</given-names></name></person-group> (<year>2014</year>). <article-title>Conductor gestures influence evaluations of ensemble performance</article-title>. <source>Front. Psycholol.</source>
<volume>5</volume>:<fpage>806</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.00806</pub-id><pub-id pub-id-type="pmid">25104944</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagel</surname><given-names>F.</given-names></name><name><surname>Kopiez</surname><given-names>R.</given-names></name><name><surname>Grewe</surname><given-names>O.</given-names></name><name><surname>Altenm&#x000fc;ller</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>EMuJoy: software for continuous measurement of perceived emotions in music</article-title>. <source>Behav. Res. Methods</source>
<volume>39</volume>, <fpage>283</fpage>&#x02013;<lpage>290</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193159</pub-id><pub-id pub-id-type="pmid">17695356</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platz</surname><given-names>F.</given-names></name><name><surname>Kopiez</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>When the eye listens: a meta-analysis of how audio-visual presentation enhances the appreciation of music performance</article-title>. <source>Music Percept.</source>
<volume>30</volume>, <fpage>71</fpage>&#x02013;<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1525/mp.2012.30.1.71</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platz</surname><given-names>F.</given-names></name><name><surname>Kopiez</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <article-title>When the first impression counts: music performers, audience and the evaluation of stage entrance behaviour</article-title>. <source>Musicae Sci.</source>
<volume>17</volume>, <fpage>167</fpage>&#x02013;<lpage>197</lpage>. <pub-id pub-id-type="doi">10.1177/1029864913486369</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinto</surname><given-names>L. R.</given-names></name><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Kroos</surname><given-names>C.</given-names></name><name><surname>Palmer</surname><given-names>C.</given-names></name></person-group> (<year>2014</year>). <article-title>Singing emotionally: a study of pre-production, production, and post-production facial expressions</article-title>. <source>Front. Psychol.</source>
<volume>5</volume>:<fpage>262</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.00262</pub-id><pub-id pub-id-type="pmid">24808868</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repp</surname><given-names>B. H.</given-names></name></person-group> (<year>1996</year>). <article-title>The art of inaccuracy: why pianists' errors are difficult to hear</article-title>. <source>Music Percept.</source>
<volume>14</volume>, <fpage>161</fpage>&#x02013;<lpage>183</lpage>. <pub-id pub-id-type="doi">10.2307/40285716</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchie</surname><given-names>L.</given-names></name><name><surname>Williamon</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Measuring distinct types of musical self-efficacy</article-title>. <source>Psychol. Music Psychol. Music</source>
<volume>39</volume>, <fpage>328</fpage>&#x02013;<lpage>344</lpage>. <pub-id pub-id-type="doi">10.1177/0305735610374895</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname><given-names>C.</given-names></name><name><surname>Costa-Giomi</surname><given-names>E.</given-names></name></person-group> (<year>2004</year>). <article-title>Attractiveness bias in the evaluation of young pianists' performances</article-title>. <source>J. Res. Music Educ.</source>
<volume>52</volume>, <fpage>141</fpage>&#x02013;<lpage>154</lpage>. <pub-id pub-id-type="doi">10.2307/3345436</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname><given-names>C.</given-names></name><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Lacaille</surname><given-names>N.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name></person-group> (<year>2006</year>). <article-title>The effects of various physical characteristics of high-level performers on adjudicators' performance ratings</article-title>. <source>Psychol. Music</source>
<volume>34</volume>, <fpage>559</fpage>&#x02013;<lpage>572</lpage>. <pub-id pub-id-type="doi">10.1177/0305735606068106</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>E.</given-names></name></person-group> (<year>1999</year>). <article-title>Measuring emotion continuously: validity and reliability of the two-dimensional emotion-space</article-title>. <source>Aust. J. Psychol.</source>
<volume>51</volume>, <fpage>154</fpage>&#x02013;<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1080/00049539908255353</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>E.</given-names></name></person-group> (<year>2004</year>). <article-title>Modeling perceived emotion with continuous musical features</article-title>. <source>Music Percept.</source>
<volume>21</volume>, <fpage>561</fpage>&#x02013;<lpage>585</lpage>. <pub-id pub-id-type="doi">10.1525/mp.2004.21.4.561</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>E.</given-names></name></person-group> (<year>2013</year>). <article-title>Reliability issues regarding the beginning, middle and end of continuous emotion ratings to music</article-title>. <source>Psychol. Music</source>
<volume>41</volume>, <fpage>350</fpage>&#x02013;<lpage>371</lpage>. <pub-id pub-id-type="doi">10.1177/0305735611430079</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schutz</surname><given-names>M.</given-names></name><name><surname>Lipscomb</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Hearing gestures, seeing music: vision influences perceived tone duration</article-title>. <source>Perception</source>
<volume>36</volume>, <fpage>888</fpage>&#x02013;<lpage>897</lpage>. <pub-id pub-id-type="doi">10.1068/p5635</pub-id><pub-id pub-id-type="pmid">17718367</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shoda</surname><given-names>H.</given-names></name><name><surname>Adachi</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>Why live recording sounds better: a case study of Schumann's Traumerei</article-title>. <source>Front. Psychol.</source>
<volume>5</volume>:<fpage>1564</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.01564</pub-id><pub-id pub-id-type="pmid">25620948</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silveira</surname><given-names>J. M.</given-names></name></person-group> (<year>2014</year>). <article-title>The effect of body movement on listeners' perceptions of musicality in trombone quartet performance</article-title>. <source>Int. J. Music Educ.</source>
<volume>32</volume>, <fpage>311</fpage>&#x02013;<lpage>323</lpage>. <pub-id pub-id-type="doi">10.1177/0255761413491210</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silveira</surname><given-names>J. M.</given-names></name><name><surname>Diaz</surname><given-names>F. M.</given-names></name></person-group> (<year>2014</year>). <article-title>The effect of subtitles on listeners' perceptions of expressivity</article-title>. <source>Psychol. Music</source>
<volume>42</volume>, <fpage>233</fpage>&#x02013;<lpage>250</lpage>. <pub-id pub-id-type="doi">10.1177/0305735612463951</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Determinants of listeners' enjoyment of a performance</article-title>. <source>Psychol. Music</source>
<volume>35</volume>, <fpage>20</fpage>&#x02013;<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1177/0305735607068886</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>S.</given-names></name><name><surname>Williamon</surname><given-names>A.</given-names></name></person-group> (<year>2003</year>). <article-title>Evaluating evaluation: musical performance assessment as a research tool</article-title>. <source>Music Percept.</source>
<volume>21</volume>, <fpage>21</fpage>&#x02013;<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1525/mp.2003.21.1.21</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>S.</given-names></name><name><surname>Williamon</surname><given-names>A.</given-names></name><name><surname>Valentine</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Time-dependent characteristics of performance evaluation</article-title>. <source>Music Percept.</source>
<volume>25</volume>, <fpage>13</fpage>&#x02013;<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1525/mp.2007.25.1.13</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Graham</surname><given-names>P.</given-names></name><name><surname>Russo</surname><given-names>F. A.</given-names></name></person-group> (<year>2005</year>). <article-title>Seeing music performance: visual influences on perception and experience</article-title>. <source>Semiotica</source>
<volume>2005</volume>, <fpage>203</fpage>&#x02013;<lpage>227</lpage>. <pub-id pub-id-type="doi">10.1515/semi.2005.2005.156.203</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Russo</surname><given-names>F. A.</given-names></name><name><surname>Livingstone</surname><given-names>S. R.</given-names></name></person-group> (<year>2010</year>). <article-title>Facial expressions of singers influence perceived pitch relations</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>17</volume>, <fpage>317</fpage>&#x02013;<lpage>322</lpage>. <pub-id pub-id-type="doi">10.3758/PBR.17.3.317</pub-id><pub-id pub-id-type="pmid">20551352</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>W. F.</given-names></name><name><surname>Russo</surname><given-names>F. A.</given-names></name><name><surname>Quinto</surname><given-names>L.</given-names></name></person-group> (<year>2008</year>). <article-title>Audio-visual integration of emotional cues in song</article-title>. <source>Cogn. Emotion</source>
<volume>22</volume>, <fpage>1457</fpage>&#x02013;<lpage>1470</lpage>. <pub-id pub-id-type="doi">10.1080/02699930701813974</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsay</surname><given-names>C.-J.</given-names></name></person-group> (<year>2013</year>). <article-title>Sight over sound in the judgment of music performance</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>110</volume>, <fpage>14580</fpage>&#x02013;<lpage>14585</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1221454110</pub-id><pub-id pub-id-type="pmid">23959902</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsay</surname><given-names>C.-J.</given-names></name></person-group> (<year>2014</year>). <article-title>The vision heuristic: judging music ensembles by sight alone</article-title>. <source>Organ. Behav. Hum. Decis. Process.</source>
<volume>124</volume>, <fpage>24</fpage>&#x02013;<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1016/j.obhdp.2013.10.003</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanWeelden</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>Racially stereotyped music and conductor race: perceptions of performance</article-title>. <source>Bull. Counc. Res. Music Educ.</source>
<volume>160</volume>, <fpage>38</fpage>&#x02013;<lpage>48</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/40319217">http://www.jstor.org/stable/40319217</ext-link></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vines</surname><given-names>B. W.</given-names></name><name><surname>Krumhansl</surname><given-names>C. L.</given-names></name><name><surname>Wanderley</surname><given-names>M. M.</given-names></name><name><surname>Levitin</surname><given-names>D. J.</given-names></name></person-group> (<year>2006</year>). <article-title>Cross-modal interactions in the perception of musical performance</article-title>. <source>Cognition</source>
<volume>101</volume>, <fpage>80</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2005.09.003</pub-id><pub-id pub-id-type="pmid">16289067</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Waddell</surname><given-names>G.</given-names></name><name><surname>Williamon</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Measuring the audience</article-title>, in <source>Scholarly Research for Musicians</source>, ed <person-group person-group-type="editor"><name><surname>Lee</surname><given-names>S.</given-names></name></person-group>(<publisher-loc>Abingdon</publisher-loc>: <publisher-name>Routledge</publisher-name>), <fpage>148</fpage>&#x02013;<lpage>155</lpage>.</mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Campbell</surname><given-names>L.</given-names></name><name><surname>Siddell-Strebel</surname><given-names>J.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name></person-group> (<year>2009</year>). <article-title>Effects of non-musical attributes and excerpt duration on ratings of high-level piano performances</article-title>. <source>Musicae Sci.</source>
<volume>13</volume>, <fpage>35</fpage>&#x02013;<lpage>54</lpage>. <pub-id pub-id-type="doi">10.1177/1029864909013001002</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name><name><surname>Kovacs</surname><given-names>J.</given-names></name><name><surname>Dalrymple</surname><given-names>L.</given-names></name></person-group> (<year>1997</year>). <article-title>Effects of physical attractiveness on evaluation of vocal performance</article-title>. <source>J. Res. Music Educ.</source>
<volume>45</volume>, <fpage>470</fpage>&#x02013;<lpage>479</lpage>. <pub-id pub-id-type="doi">10.2307/3345540</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Flowers</surname><given-names>P.</given-names></name><name><surname>Alegant</surname><given-names>M.</given-names></name><name><surname>Jasinskas</surname><given-names>L.</given-names></name></person-group> (<year>1993</year>). <article-title>Consistency in piano performance evaluation</article-title>. <source>J. Res. Music Educ.</source>
<volume>41</volume>, <fpage>282</fpage>&#x02013;<lpage>292</lpage>. <pub-id pub-id-type="doi">10.2307/3345504</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Mazza</surname><given-names>J. K.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name></person-group> (<year>1998</year>). <article-title>Effects of performer attractiveness, stage behavior, and dress on violin performance evaluation</article-title>. <source>J. Res. Music Educ.</source>
<volume>46</volume>, <fpage>510</fpage>&#x02013;<lpage>521</lpage>. <pub-id pub-id-type="doi">10.2307/3345347</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Mazza</surname><given-names>J. K.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name></person-group> (<year>2000</year>). <article-title>Effects of performer attractiveness, stage behavior, and dress on evaluation of children's piano performances</article-title>. <source>J. Res. Music Educ.</source>
<volume>48</volume>, <fpage>323</fpage>&#x02013;<lpage>335</lpage>. <pub-id pub-id-type="doi">10.2307/3345367</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wapnick</surname><given-names>J.</given-names></name><name><surname>Ryan</surname><given-names>C.</given-names></name><name><surname>Campbell</surname><given-names>L.</given-names></name><name><surname>Deek</surname><given-names>P.</given-names></name><name><surname>Lemire</surname><given-names>R.</given-names></name><name><surname>Darrow</surname><given-names>A.-A.</given-names></name></person-group> (<year>2005</year>). <article-title>Effects of excerpt tempo and duration on musicians' ratings of high-level piano performances</article-title>. <source>J. Res. Music Educ.</source>
<volume>53</volume>, <fpage>162</fpage>&#x02013;<lpage>176</lpage>. <pub-id pub-id-type="doi">10.1177/002242940505300206</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wesolowski</surname><given-names>B. C.</given-names></name><name><surname>Wind</surname><given-names>S. A.</given-names></name><name><surname>Engelhard</surname><given-names>G.</given-names></name></person-group> (<year>2015</year>). <article-title>Rater fairness in music performance assessment: evaluating model-data fit and differential rater functioning</article-title>. <source>Musicae Sci.</source>
<volume>19</volume>, <fpage>147</fpage>&#x02013;<lpage>170</lpage>. <pub-id pub-id-type="doi">10.1177/1029864915589014</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williamon</surname><given-names>A.</given-names></name><name><surname>Valentine</surname><given-names>E.</given-names></name></person-group> (<year>2000</year>). <article-title>Quantity and quality of musical practice as predictors of performance quality</article-title>. <source>Br. J. Psychol.</source>
<volume>91</volume>, <fpage>353</fpage>&#x02013;<lpage>376</lpage>. <pub-id pub-id-type="doi">10.1348/000712600161871</pub-id><pub-id pub-id-type="pmid">10958579</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>L. R.</given-names></name><name><surname>Fredrickson</surname><given-names>W. E.</given-names></name><name><surname>Atkinson</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). <article-title>Focus of attention to melody or harmony and perception of music tension: an exploratory study</article-title>. <source>Int. J. Music Educ.</source>
<volume>29</volume>, <fpage>72</fpage>&#x02013;<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1177/0255761410372725</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ybarra</surname><given-names>O.</given-names></name></person-group> (<year>2001</year>). <article-title>When first impressions don't last: the role of isolation and adaptation processes in the revision of evaluative impressions</article-title>. <source>Soc. Cogn.</source>
<volume>19</volume>, <fpage>491</fpage>&#x02013;<lpage>520</lpage>. <pub-id pub-id-type="doi">10.1521/soco.19.5.491.19910</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zebrowitz</surname><given-names>L. A.</given-names></name><name><surname>Montepare</surname><given-names>J. M.</given-names></name></person-group> (<year>2008</year>). <article-title>Social psychological face perception: why appearance matters</article-title>. <source>Soc. Personal. Psychol. Compass</source>
<volume>2</volume>:<fpage>1497</fpage>. <pub-id pub-id-type="doi">10.1111/j.1751-9004.2008.00109.x</pub-id><pub-id pub-id-type="pmid">20107613</pub-id></mixed-citation></ref></ref-list></back></article>