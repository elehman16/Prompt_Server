<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29694384</article-id><article-id pub-id-type="pmc">5919050</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0196176</article-id><article-id pub-id-type="publisher-id">PONE-D-17-29381</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject><subj-group><subject>Psychoacoustics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject><subj-group><subject>Psychoacoustics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject><subj-group><subject>Psychoacoustics</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject><subj-group><subject>Psychoacoustics</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Psychophysics</subject><subj-group><subject>Psychoacoustics</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Music Cognition</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Music Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Bioassays and Physiological Analysis</subject><subj-group><subject>Electrophysiological Techniques</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain Mapping</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Clinical Medicine</subject><subj-group><subject>Clinical Neurophysiology</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Bioassays and Physiological Analysis</subject><subj-group><subject>Electrophysiological Techniques</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Brain Electrophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain Mapping</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Clinical Medicine</subject><subj-group><subject>Clinical Neurophysiology</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Electroencephalography</subject><subj-group><subject>Event-Related Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Neurolinguistics</subject><subj-group><subject>Mismatch Negativity</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurolinguistics</subject><subj-group><subject>Mismatch Negativity</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject><subj-group><subject>Bioacoustics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Bioacoustics</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Signal Processing</subject><subj-group><subject>Signal Filtering</subject><subj-group><subject>Bandpass Filters</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Mismatch negativity reflects asymmetric pre-attentive harmonic interval discrimination</article-title><alt-title alt-title-type="running-head">MMN reflect interval discrimination</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4643-2832</contrib-id><name><surname>Wagner</surname><given-names>Luise</given-names></name><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="corresp" rid="cor001">*</xref><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Rahne</surname><given-names>Torsten</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Plontke</surname><given-names>Stefan K.</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Heidekr&#x000fc;ger</surname><given-names>Nico</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><xref ref-type="aff" rid="aff001"/></contrib></contrib-group><aff id="aff001"><addr-line>University Hospital Halle (Saale), Department of Otorhinolaryngology, Head and Neck Surgery, Martin Luther University Halle-Wittenberg, Halle (Saale), Germany</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Malmierca</surname><given-names>Manuel S.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Universidad de Salamanca, SPAIN</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>luise.wagner@uk-halle.de</email></corresp></author-notes><pub-date pub-type="epub"><day>25</day><month>4</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>13</volume><issue>4</issue><elocation-id>e0196176</elocation-id><history><date date-type="received"><day>8</day><month>8</month><year>2017</year></date><date date-type="accepted"><day>6</day><month>4</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; 2018 Wagner et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Wagner et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0196176.pdf"/><abstract><sec id="sec001"><title>Objective</title><p>Western music is based on intervals; thus, interval discrimination is important for distinguishing the character of melodies or tracking melodies in polyphonic music. In this study the encoding of intervals in simultaneously presented sound is studied.</p></sec><sec id="sec002"><title>Study design</title><p>In an electrophysiological experiment in 15 normal-hearing non-musicians, major thirds or fifths were presented in a controlled oddball paradigm. Harmonic intervals were created by simultaneously presented sinusoidals with randomized root frequency. Mismatch negativity (MMN) responses were measured with an EEG recording. The discrimination index was calculated in a psychoacoustic experiment.</p></sec><sec id="sec003"><title>Results</title><p>A clear MMN response was found for the major third but not for the fifth. The neural generators were located within the auditory cortices. Psychoacoustically, no evidence was found that the subjects were able to detect the deviants.</p></sec><sec id="sec004"><title>Conclusions</title><p>We conclude that pre-attentive discrimination of harmonic interval size is, in principle, possible in listeners without musical training although simultaneous presentation makes it harder to distinguish compared to non-overlapping intervals. Furthermore we see a difference in the response to infrequent dissonant stimuli in consonant standard stimuli compared to the opposite, rare consonant stimuli in dissonant standard stimuli.</p></sec></abstract><funding-group><funding-statement>The authors received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="3"/><table-count count="0"/><page-count count="9"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper and its Supporting Information files.</p></notes></front><body><sec sec-type="intro" id="sec005"><title>Introduction</title><p>Music perception in human beings is based on the detection of elements such as pitch, rhythm, dynamics, and timbre. In Western classical polyphonic music, synchronously sounding tones form so-called harmonic (or vertical) intervals. Physically, harmonic intervals can be described as ratios of the frequencies of two tones. The interval size between two notes of a diatonic scale can be considered as a multiple of semitones [<xref rid="pone.0196176.ref001" ref-type="bibr">1</xref>]. The interval is roughly the same at equal distances to the respective root note along the frequency axis [<xref rid="pone.0196176.ref002" ref-type="bibr">2</xref>,<xref rid="pone.0196176.ref003" ref-type="bibr">3</xref>]. The sound of a harmonic interval is rated as consonant if the frequency ratio is an integer value. Dissonance increases with decreasing frequency ratios; e.g., a minor second (16:15) is more dissonant than a major second (9:8), a major third (5:4), or a perfect fifth (3:2).</p><p>Cortical processing of musical sounds is influenced by musical training [<xref rid="pone.0196176.ref004" ref-type="bibr">4</xref>&#x02013;<xref rid="pone.0196176.ref008" ref-type="bibr">8</xref>] and voluntary or involuntary attention [<xref rid="pone.0196176.ref009" ref-type="bibr">9</xref>]. Involuntary attention and pre-attentive cortical processing can be investigated with the mismatch negativity (MMN) event-related potential [<xref rid="pone.0196176.ref010" ref-type="bibr">10</xref>], which reflects the brain response to unexpected events and is usually studied using oddball paradigms. Therefore, a deviating stimulus is rarely presented in a series of repeated standard stimuli. Auditory MMN has successfully been recorded for deviances in pitch, duration, intensity, location, order, and other parameters of the stimuli [<xref rid="pone.0196176.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0196176.ref012" ref-type="bibr">12</xref>]. MMN is also elicited by abstract changes in auditory stimulation, such as language grammar and musical syntax violations (for a review, see [<xref rid="pone.0196176.ref011" ref-type="bibr">11</xref>]).</p><p>The so-called feature-detector model predicts asymmetric MMN amplitudes depending on the exclusion or inclusion of extra features in the deviant [<xref rid="pone.0196176.ref013" ref-type="bibr">13</xref>]. Larger amplitudes are observed if extra features are included in the deviant stimulus. If we would increase dissonance in the deviant interval, this model would predict larger MMN amplitudes than vice versa.</p><p>MMN studies have also focused on musical processing and perception [<xref rid="pone.0196176.ref014" ref-type="bibr">14</xref>]. Vuust et al. [<xref rid="pone.0196176.ref015" ref-type="bibr">15</xref>] elicited MMN using pitch mistuning, intensity, timbre, sound-source location, and rhythm cues. Harmonic intervals processing was assessed by K&#x000f6;lsch et al. [<xref rid="pone.0196176.ref016" ref-type="bibr">16</xref>] using major chords of three tones as standard stimuli. A marginally mistuned middle tone evoked an MMN as an indicator for pre-attentive processing of chords. Brattico et al. [<xref rid="pone.0196176.ref017" ref-type="bibr">17</xref>] examined the processing of minor, major chords and uncommon mistuned chords by musicians and non-musicians with MEG and found a more efficient discrimination for chords varying from conventional tonal music. In a controlled case study in a patient with acquired deafness to dissonance, Brattico et al. [<xref rid="pone.0196176.ref018" ref-type="bibr">18</xref>] found that there was a larger MMN amplitude to an infrequent dissonant interval (the major seventh) in a context of repeated consonant intervals (the major sixth) than there was to an infrequent consonant interval in a consonant context (e.g., the perfect octave replacing the major sixth). In the present study we investigated whether this asymmetry can also be found in normal hearing non-musicians.</p><p>Since these studies did not report a randomization of the absolute frequencies, no conclusions can be made about pre-attentive processing of interval size deviations independently of the absolute tone frequencies. Interval sequences based on root notes with constant frequency could also evoke an integration of those tones in auditory streams. The observed MMN would then have been evoked by a pitch deviation within a certain stream and not by the different interval size. Virtala et al. [<xref rid="pone.0196176.ref019" ref-type="bibr">19</xref>] avoided such a misleading observation by investigating major and minor dissonant and consonant chords and by varying the pitch of the standard major chords. Deviating minor, dissonant, or soft chords elicited a MMN. In the recent study the root notes are randomized.</p><p>The audiotory system seems to be sensitive to step direction as investigated by recording MMN [<xref rid="pone.0196176.ref020" ref-type="bibr">20</xref>]. Generally, it was later found that the auditory system has a preference for upward steps over downward steps, which can be seen in smaller psychoacoustic thresholds and larger MMN amplitudes for upward steps [<xref rid="pone.0196176.ref021" ref-type="bibr">21</xref>]. This asymmetry might also be expected regarding interval size processing, so that, e.g., infrequently presented fifths would evoke different MMN amplitudes than major thirds dependent on the frequently presented interval size.</p><p>The intent of this study was to objectively assess the pre-attentive processing of harmonic intervals in normal hearing subjects. We used harmonic intervals made of two sinusoidal tones with varying root frequencies and compared the elicited event-related potentials (ERPs) using an oddball paradigm. If deviations in interval size evoked a MMN, we hypothesized that harmonic interval discrimination is processed pre-attentively. To check if it is an MMN response dipoles are constructed and the location is checked according to [<xref rid="pone.0196176.ref022" ref-type="bibr">22</xref>].</p></sec><sec sec-type="materials|methods" id="sec006"><title>Materials and methods</title><sec id="sec007"><title>Subjects</title><p>Fifteen normal hearing (4PTA<sub>0.5&#x02013;4 kHz</sub> &#x0003c; 20 dB HL) listeners were recruited to participate in a prospective, controlled experimental study. All participants were between age 18 and 65 years and had no formal musical training. Written informed consent was obtained from all participants. The experimental procedures were in accordance with the guidelines in the Declaration of Helsinki and were approved by the ethics committee of the Martin Luther University Halle-Wittenberg. Every subject received monetary compensation for taking part in the study.</p></sec><sec id="sec008"><title>Stimuli</title><p>Two simultaneously played sinusoidal tones were generated as wave files by MATLAB software (MathWorks Inc., Natick, MN, USA) applying a sample rate of 16 kHz. The frequency of the lower tone, i.e., the root note, was randomized and was set to either 300 Hz, 350 Hz, 400 Hz, 450 Hz, or 500 Hz. The frequency of the higher tone was adapted to the root note, forming either a major third with a frequency ratio of 5:4 or a perfect fifth with a frequency ratio of 3:2. The stimuli had a length of 100 ms including Hanning window-shaped ramps of 20 ms at the beginning and the end.</p><p>In an oddball paradigm, either the major third or the perfect fifth intervals were played infrequently as deviants, with a probability of 12.5%. If the fifths were used as deviants, then the major thirds were presented as standards, and vice versa. Each condition was presented in three consecutive blocks, with one block lasting about three minutes. In total, for each condition, 2000 standard and 250 deviant intervals were presented with a stimulus onset asynchrony of 400 ms in a passive listening task. Each deviant was followed by at least three standard intervals.</p><p>The stimuli were bilaterally presented through ER-3A insert earphones (Etymotic Research, Elk grove Village, Il, USA) with a sound pressure level of 70 dB. The stimulation process was implemented on a personal computer using STIM2 software (Compumedics, Singen, Germany).</p></sec><sec id="sec009"><title>Data recording</title><sec id="sec010"><title>Electrophysiological recordings</title><p>In the electrophysiological part of the study, the subjects were comfortably seated in a sound-attenuated room, where they watched a subtitled movie without sound and received instructions to disregard the presented auditory stimuli. They were not informed about the stimuli and the attendant features.</p><p>The subjects&#x02019; EEGs were continuously recorded with a Neuroscan SynAmps RT (Compumedics, Singen, Germany) AC coupled amplifier (sampling rate: 1000 Hz), using a 128-channel-electrode Standard BrainCap (EASYCAP GmbH, Herrsching, Germany) arranged on the scalp according to the extended International 10&#x02013;20 system ("Report of the committee on methods of clinical examination in electroencephalography," 1958). A nose electrode was used as reference. The vertical electro-oculogram (EOG) was recorded with a bipolar electrode configuration on the left eye using additional electrodes. The EOG was later used for artifact reduction and to ensure that the participants were reading the subtitles of the movie. The electrode impedances were controlled before and after the measurement. Electrode impedances were kept below 20&#x02013;30 kOhm.</p></sec><sec id="sec011"><title>Psychoacoustical measurements</title><p>Ten of the included fifteen subjects were available to participate in the psychoacoustic portion of the study. The same acoustical stimulation as in the electrophysiological portion was provided to the participants. The features of the interval stimuli were explained to them. After a training run, each subject&#x02019;s task was to identify the major third or the fifth by pressing a button on a response key. The <italic>fifth</italic> and <italic>major third</italic> conditions were presented in an alternating order. The responses were recorded with Curry Neuroscan Software. The presentation of the respective blocks was made by an alternate sequence. A response was considered as &#x0201c;hit&#x0201d; if it occurred between 100 ms and 1000 ms after the target stimulus.</p></sec></sec><sec id="sec012"><title>Data analysis</title><p>The data analysis was conducted off-line with Curry Neuroscan Software. All data were baseline corrected before being off-line filtered using a 1 Hz to 20 Hz Butterworth bandpass filter (24 dB/octave) and a 50 Hz notch filter. Bad blocks due to muscular activity were removed manually. The EOG channels were inspected automatically for artifacts, and if the sample amplitudes were not between -150 &#x003bc;V and 150 &#x003bc;V, all channels were corrected using principal component analysis. For those participants with few blinking artifacts, the correction range was changed to between -100 &#x003bc;V and 100 &#x003bc;V. The first PCA component was always identified as blinking and then removed. Depending on the length of the blinking, the interval was 100 ms or 200 ms before and 200 ms or 300 ms after the detected artifact was corrected.</p><p>The preprocessed EEG data were segmented into epochs of 500 ms, with a 100 ms pre-stimulus beginning. Standard and deviant epochs were identified for both conditions and separately averaged. The two standard epochs recorded after a deviant and the last standard before a deviant were excluded. Epochs with a noise level larger than 1.6 times the average noise level were excluded.</p><p>The remaining epochs were further analyzed with MATLAB 2015 software, including the eeglab 13_6_5b toolbox. The nose electrode was used as reference. The base line correction was made with a 100 ms pre-stimulus interval. Bad channels with high impedances were excluded. The group mean waveforms were calculated for every electrode out of the averaged individual standard and deviant epochs for each subject. Difference waveforms for the <italic>fifth</italic> condition were calculated by subtracting the standard epochs of the <italic>major third</italic> condition (i.e., the responses to the fifths as standards) from the deviant epochs of the <italic>fifth</italic> condition; the difference waveforms for the <italic>major third</italic> condition were calculated by subtracting the standard epochs of the <italic>fifth</italic> condition (i.e., the responses to the major thirds as standards) from the deviant epochs of the <italic>major third</italic> condition. The latency of the MMN response was measured at the minimum of the group mean waveform at electrode Fz in a time window from 0 to 350 ms after stimulus onset. For each subject, the individual MMN amplitude was calculated as the mean voltage in a 40 ms time interval centered on the MMN peak latency of the group average waveform. The noise floor for statistical comparisons was calculated as mean amplitudes in a time interval with the same length as the interval around the MMN peak from 70 ms to 30 ms before stimulus onset.</p><p>The statistical analysis of the amplitudes was performed with SPSS20 software (IBM, Ehningen, Germany). The assumption of amplitude normality for both the MMN and the noise floor distributions was tested by the Kolmogorov-Smirnov test. The significance of the MMN amplitudes was tested with <italic>t</italic>-tests for paired samples, comparing the amplitude of the individual MMN in both conditions with the respective noise floor. The level of significance was reduced by the Bonferroni correction for multiple comparisons.</p><p>Source reconstruction was performed with BESA Research 6.1 software. One pair of symmetric dipoles and one dipole with free orientation were assumed and fitted on a 4-shell ellipsoidal with the LORETA algorithm. Sources were reconstructed for significant MMN amplitudes and also to compare the group average N1 response of the <italic>major third</italic> condition. The MMN source reconstruction used the interval from 100 to 200 ms after stimulus onset. Based on the zero crossings of the Cz potential of the major third condition, the interval for reconstructing the N1 sources was selected as 95 to 135 ms after stimulus onset (in a 40 ms time window around the minimum of the group average).</p><p>For the psychoacoustical part, the individual hit rates and false alarm rates were calculated for the two target intervals using Curry Software. The sensivity index d&#x02019; was calculated.</p></sec></sec><sec sec-type="results" id="sec013"><title>Results</title><p>Fifteen normal hearing listeners (age range 20&#x02013;65 years; mean age 31.2 years, 7 females and 8 males) participated in the experiment. All of them had no special musical training except for ordinary musical lessons in school. One EEG data set had to be excluded due to unexplainable technical artifacts.</p><p><xref ref-type="fig" rid="pone.0196176.g001">Fig 1</xref> shows the group averages of the deviant and standard epochs as well as the difference curves. A clear MMN was observed only for the major third. The topoplots of the difference curves show a fronto-central localization of the MMN activity for the <italic>major third</italic> and no focused localization for the <italic>fifth</italic> condition.</p><fig id="pone.0196176.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0196176.g001</object-id><label>Fig 1</label><caption><p><bold>Grand average ERP waveforms as elicited by &#x02018;standard&#x02019; (light gray line) and &#x02018;deviant&#x02019; (dark gray line) <italic>major third</italic> (left) or <italic>fifth</italic> (right) intervals at Fz.</bold> The black lines show the difference waveforms between the &#x02018;deviant&#x02019; and &#x02018;standard&#x02019; waveforms. The contour maps show the distribution of response polarities on an average scalp at the latency of the MMN. Clear fronto-central negativity is only evoked by the major third deviants.</p></caption><graphic xlink:href="pone.0196176.g001"/></fig><p>The Kolmogorov-Smirnov test revealed a normal distribution of MMN amplitudes (p &#x0003e; 0.05) for all participants at the latency of maximal negativity in the group average. Also, the amplitudes of the noise floor were normally distributed. Thus, parametric tests were applied in further analyses.</p><p>For the <italic>major third</italic> condition, the paired <italic>t</italic>-test showed significant MMN amplitudes, -0.34 &#x003bc;V &#x000b1; 0.32 &#x003bc;V at a mean latency of 173 ms, compared to the amplitudes 50 ms before stimulus onset (-0.01 &#x003bc;V &#x000b1; 0.08 &#x003bc;V; <italic>p</italic> = 0.003). For the <italic>fifth</italic> condition, a paired <italic>t</italic>-test showed no significant MMN amplitudes at a latency of 167 ms (-0.02 &#x003bc;V &#x000b1; 0.44 &#x003bc;V) compared to the potential 50 ms before stimulus onset (0.00 &#x003bc;V &#x000b1; 0.09 &#x003bc;V; <italic>p</italic> = 0.83). A comparison between fifth and major third revealed no significant difference between the corresponding MMN amplitudes (<italic>p</italic> = 0.273).</p><p><xref ref-type="fig" rid="pone.0196176.g002">Fig 2</xref> shows the source reconstruction results for the <italic>major third</italic> condition. The dipoles of the MMN were located within the auditory cortices, which have locations comparable to that of the N1 response.</p><fig id="pone.0196176.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0196176.g002</object-id><label>Fig 2</label><caption><p><bold>Source reconstruction of the MMN (left) and N100 responses (right) for the <italic>major third</italic> condition using a standard head model.</bold> Dipoles are located in the auditory cortices.</p></caption><graphic xlink:href="pone.0196176.g002"/></fig><p><xref ref-type="fig" rid="pone.0196176.g003">Fig 3A</xref> shows the results of the psychoacoustic portion of the experiment. Three participants (30%) reached a discrimination score &#x0003e;1.5 for the fifth detection, and four participants (40%) reached that score for the major third detection. The mean discrimination indexes for the major third and fifth with its standard deviations were 1.66 &#x000b1; 1.01 and 1.93 &#x000b1; 1.51, respectively. This difference was not significant (p &#x0003e; 0.05). <xref ref-type="fig" rid="pone.0196176.g003">Fig 3B</xref> shows the MMN amplitudes at Fz as a function of the discrimination index. It is seen that the elicitation of a MMN response for the major third is independent of the individual psychoacoustic discrimination index and the amplitude does not increase with growing d&#x02019; (r = -0.48).</p><fig id="pone.0196176.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0196176.g003</object-id><label>Fig 3</label><caption><p>(A) Discrimination index as boxplots for the major third (white) and the fifth (gray). The difference is not significant (p &#x0003e; 0.05). (B) Individual MMN amplitude at Fz for the major third (white circle) and the fifth (black squares) as functions of the individual discrimination index d&#x02019;.</p></caption><graphic xlink:href="pone.0196176.g003"/></fig></sec><sec sec-type="conclusions" id="sec014"><title>Discussion</title><p>The results show that size differences in harmonic intervals evoke an MMN. If the interval size was infrequently reduced to a major third in a stream of fifths (<italic>major third</italic> condition), a clear response was evoked with a clear fronto-central distribution of negative response polarity and source dipoles within the auditory cortex. The response pattern and dipole sources are typical for a MMN response [<xref rid="pone.0196176.ref022" ref-type="bibr">22</xref>]. Thus, pre-attentive discrimination of harmonic interval differences is possible, in principle. Since an increase in interval size did not evoke significant MMN amplitudes (<italic>fifth</italic> condition) this automatic interval discrimination is asymmetrically.</p><p>This asymmetry is a little in contrast to the postulated preference of the auditory system towards upward steps as described in the introduction. Maybe the different root notes used in the present paradigm have masked the step directions. The asymmetry may also have been caused by the psychophysical feature of &#x02018;disharmony&#x02019; since disharmony was increased by the major third more than it was by the fifth. As consonance is directly correlated to disharmony and is more important for the elicitation of the MMN than interval width [<xref rid="pone.0196176.ref023" ref-type="bibr">23</xref>], asymmetric MMN responses as observed in our study confirmed asymmetric pre-attentive discrimination of intervals. Another explanation for the asymmetry might be the different likelihoods of integrating intervals depending on their degree of consonance in one stream [<xref rid="pone.0196176.ref024" ref-type="bibr">24</xref>]. Also, different likelihoods of segregating low- and high-pitch streams would occur for fifths and major thirds [<xref rid="pone.0196176.ref024" ref-type="bibr">24</xref>]. A rare major third would evoke a gap in the high-frequency stream and, additionally, information in the root note stream. Thus, it is more likely to evoke an MMN with a major third than with a rare fifth causing reduced information within one single stream.</p><p>Psychoacoustically, the detection rate d&#x02019; of both interval size differences was with no significant difference between the conditions. However some participants surprisingly reported an easier detection of the fifths and some others for the thirds. The psychoacoustical results, however, do not reflect the individual interval discrimination skills, as this control experiment was not designed to measure those skills. For psychoacoustical measurements, longer stimuli and complex tones should be used rather than short sinusoidals [<xref rid="pone.0196176.ref025" ref-type="bibr">25</xref>].</p><p>Also, the root note frequency should be kept constant. Since a dissociation between MMN amplitudes and behavioral discrimination measures is prevalent in may paradigms (e.g. [<xref rid="pone.0196176.ref026" ref-type="bibr">26</xref>, <xref rid="pone.0196176.ref027" ref-type="bibr">27</xref>]), our results emphasize the usefulness of objective measures to study cortical discrimination tasks.</p><p>None of the participants was musically trained. Although they could not detect the deviant intervals psychoacoustically in the presentation, pre-attentive detection was indicated by a significant MMN response.</p><p>We conclude that pre-attentive discrimination of harmonic interval size is, in principle, possible in listeners who lack musical training. Even if the target tones cannot be detected psychoacoustically, a MMN response is elicited.</p></sec><sec sec-type="supplementary-material" id="sec015"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0196176.s001"><label>S1 Table</label><caption><title>The table shows the individual amplitudes of the subjects for the condition with major thirds or fifth as deviant at the latency of the MMN and the amplitudes of the noise floor before stimulus onset.</title><p>(XLSX)</p></caption><media xlink:href="pone.0196176.s001.xlsx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0196176.s002"><label>S2 Table</label><caption><title>The table shows the individual d&#x02018; of each subjet for detecting the fifth or the major third.</title><p>(XLSX)</p></caption><media xlink:href="pone.0196176.s002.xlsx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank all participants for their patience.</p></ack><ref-list><title>References</title><ref id="pone.0196176.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Russo</surname><given-names>FA</given-names></name>, <name><surname>Thompson</surname><given-names>WF</given-names></name> (<year>2005</year>) <article-title>The subjective size of melodic intervals over a two-octave range</article-title>. <source>Psychonomic bulletin &#x00026; review</source> 12 (<issue>6</issue>): <fpage>1068</fpage>&#x02013;<lpage>1075</lpage>.<pub-id pub-id-type="pmid">16615330</pub-id></mixed-citation></ref><ref id="pone.0196176.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Attneave</surname><given-names>F</given-names></name>, <name><surname>Olson</surname><given-names>RK</given-names></name> (<year>1971</year>) <article-title>Pitch as a medium: a new approach to psychophysical scaling</article-title>. <source>Am. J. Psychol</source>. 84 (<issue>2</issue>): <fpage>147</fpage>&#x02013;<lpage>166</lpage>. <pub-id pub-id-type="pmid">5566581</pub-id></mixed-citation></ref><ref id="pone.0196176.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>X</given-names></name>, <name><surname>Masterson</surname><given-names>ME</given-names></name>, <name><surname>Wu</surname><given-names>C-C</given-names></name> (<year>2014</year>) <article-title>Melodic interval perception by normal-hearing listeners and cochlear implant users</article-title>. <source>J. Acoust. Soc. Am</source>. 136 (<issue>4</issue>): <fpage>1831</fpage>&#x02013;<lpage>1844</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.4894738">10.1121/1.4894738</ext-link></comment>
<pub-id pub-id-type="pmid">25324084</pub-id></mixed-citation></ref><ref id="pone.0196176.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Gfeller</surname><given-names>K</given-names></name> (<year>2016</year>) <article-title>Music-based training for pediatric CI recipients: A systematic analysis of published studies</article-title>. <source>Eur. Ann. Otorhinolaryngol. Head Neck Dis</source>. 133: <fpage>S50</fpage>&#x02013;<lpage>S56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.anorl.2016.01.010">10.1016/j.anorl.2016.01.010</ext-link></comment>
<pub-id pub-id-type="pmid">27246744</pub-id></mixed-citation></ref><ref id="pone.0196176.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Lappe</surname><given-names>C</given-names></name>, <name><surname>Trainor</surname><given-names>LJ</given-names></name>, <name><surname>Herholz</surname><given-names>SC</given-names></name>, <name><surname>Pantev</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>Cortical Plasticity Induced by Short-Term Multimodal Musical Rhythm Training</article-title>. <source>PLoS ONE</source> 6 (<issue>6</issue>).</mixed-citation></ref><ref id="pone.0196176.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Looi</surname><given-names>V</given-names></name>, <name><surname>Gfeller</surname><given-names>K</given-names></name>, <name><surname>Driscoll</surname><given-names>V</given-names></name> (<year>2012</year>) <article-title>Music appreciation and training for cochlear implant recipients: a review</article-title>. <source>Seminars in hearing</source> 33 (<issue>4</issue>): <fpage>307</fpage>&#x02013;<lpage>334</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1055/s-0032-1329222">10.1055/s-0032-1329222</ext-link></comment>
<pub-id pub-id-type="pmid">23459244</pub-id></mixed-citation></ref><ref id="pone.0196176.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Putkinen</surname><given-names>V</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name>, <name><surname>Saarikivi</surname><given-names>K</given-names></name>, <name><surname>Vent</surname><given-names>N de</given-names></name>, <name><surname>Huotilainen</surname><given-names>M</given-names></name> (<year>2014</year>) <article-title>Investigating the effects of musical training on functional brain development with a novel Melodic MMN paradigm</article-title>. <source>Neurobiology of learning and memory</source> 110: <fpage>8</fpage>&#x02013;<lpage>15</lpage>.</mixed-citation></ref><ref id="pone.0196176.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Fujioka</surname><given-names>T</given-names></name>, <name><surname>Trainor</surname><given-names>LJ</given-names></name>, <name><surname>Ross</surname><given-names>B</given-names></name>, <name><surname>Kakigi</surname><given-names>R</given-names></name>, <name><surname>Pantev</surname><given-names>C</given-names></name> (<year>2004</year>) <article-title>Musical training enhances automatic encoding of melodic contour and interval structure</article-title>. <source>J. Cogn. Neurosci</source>. 16 (<issue>6</issue>): <fpage>1010</fpage>&#x02013;<lpage>1021</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/0898929041502706">10.1162/0898929041502706</ext-link></comment>
<pub-id pub-id-type="pmid">15298788</pub-id></mixed-citation></ref><ref id="pone.0196176.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Gaillard</surname><given-names>AW</given-names></name>, <name><surname>M&#x000e4;ntysalo</surname><given-names>S</given-names></name> (<year>1980</year>) <article-title>Brain potential correlates of voluntary and involuntary attention</article-title>. <source>Prog. Brain Res</source>. 54: <fpage>343</fpage>&#x02013;<lpage>348</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0079-6123(08)61645-3">10.1016/S0079-6123(08)61645-3</ext-link></comment>
<pub-id pub-id-type="pmid">7220937</pub-id></mixed-citation></ref><ref id="pone.0196176.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Gaillard</surname><given-names>A</given-names></name>, <name><surname>M&#x000e4;ntysalo</surname><given-names>S</given-names></name> (<year>1978</year>) <article-title>Early selective-attention effect on evoked potential reinterpreted</article-title>. <source>Acta Psychol</source>. 42 (<issue>4</issue>): <fpage>313</fpage>&#x02013;<lpage>329</lpage>.</mixed-citation></ref><ref id="pone.0196176.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Rinne</surname><given-names>T</given-names></name>, <name><surname>Alho</surname><given-names>K</given-names></name> (<year>2007</year>) <article-title>The mismatch negativity (MMN) in basic research of central auditory processing. A review</article-title>. <source>Clin. Neurophysiol</source>. 118 (<issue>12</issue>): <fpage>2544</fpage>&#x02013;<lpage>2590</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.clinph.2007.04.026">10.1016/j.clinph.2007.04.026</ext-link></comment>
<pub-id pub-id-type="pmid">17931964</pub-id></mixed-citation></ref><ref id="pone.0196176.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Paavilainen</surname><given-names>P</given-names></name> (<year>2013</year>) <article-title>The mismatch-negativity (MMN) component of the auditory event-related potential to violations of abstract regularities: a review</article-title>. <source>Int. J. Psychophysiol</source>. 88 (<issue>2</issue>): <fpage>109</fpage>&#x02013;<lpage>123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ijpsycho.2013.03.015">10.1016/j.ijpsycho.2013.03.015</ext-link></comment>
<pub-id pub-id-type="pmid">23542165</pub-id></mixed-citation></ref><ref id="pone.0196176.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Timm</surname><given-names>J</given-names></name>, <name><surname>Weise</surname><given-names>A</given-names></name>, <name><surname>Grimm</surname><given-names>S</given-names></name>, <name><surname>Schr&#x000f6;ger</surname><given-names>E</given-names></name> (<year>2011</year>) <article-title>An Asymmetry in the Automatic Detection of the Presence or Absence of a Frequency Modulation within a Tone: A Mismatch Negativity Study</article-title>. <source>Front. Psychol</source>. 2: <fpage>189</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2011.00189">10.3389/fpsyg.2011.00189</ext-link></comment>
<pub-id pub-id-type="pmid">21852979</pub-id></mixed-citation></ref><ref id="pone.0196176.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Yu</surname><given-names>X</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>, <name><surname>Gao</surname><given-names>D</given-names></name> (<year>2015</year>) <article-title>The Mismatch Negativity: An Indicator of Perception of Regularities in Music. Behav</article-title>. <source>Neurol</source>. 2015: <fpage>469508</fpage>.</mixed-citation></ref><ref id="pone.0196176.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Vuust</surname><given-names>P</given-names></name>, <name><surname>Brattico</surname><given-names>E</given-names></name>, <name><surname>Glerean</surname><given-names>E</given-names></name>, <name><surname>Seppanen</surname><given-names>M</given-names></name>, <name><surname>Pakarinen</surname><given-names>S</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name>
<etal>et al</etal> (<year>2011</year>) <article-title>New fast mismatch negativity paradigm for determining the neural prerequisites for musical ability</article-title>. <source>Cortex</source> 47 (<issue>9</issue>): <fpage>1091</fpage>&#x02013;<lpage>1098</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2011.04.026">10.1016/j.cortex.2011.04.026</ext-link></comment>
<pub-id pub-id-type="pmid">21621766</pub-id></mixed-citation></ref><ref id="pone.0196176.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Koelsch</surname><given-names>S</given-names></name>, <name><surname>Schroger</surname><given-names>E</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name> (<year>1999</year>) <article-title>Superior pre-attentive auditory processing in musicians</article-title>. <source>Neuroreport</source> 10 (<issue>6</issue>): <fpage>1309</fpage>&#x02013;<lpage>1313</lpage>. <pub-id pub-id-type="pmid">10363945</pub-id></mixed-citation></ref><ref id="pone.0196176.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Brattico</surname><given-names>E</given-names></name>, <name><surname>Pallesen</surname><given-names>KJ</given-names></name>, <name><surname>Varyagina</surname><given-names>O</given-names></name>, <name><surname>Bailey</surname><given-names>C</given-names></name>, <name><surname>Anourova</surname><given-names>I</given-names></name>, <name><surname>J&#x000e4;rvenp&#x000e4;&#x000e4;</surname><given-names>M</given-names></name>
<etal>et al</etal> (<year>2009</year>) <article-title>Neural Discrimination of Nonprototypical Chords in Music Experts and Laymen: An MEG Study</article-title>. <source>J. Cogn. Neurosci</source>. 21 (<issue>11</issue>): <fpage>2230</fpage>&#x02013;<lpage>2244</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2008.21144">10.1162/jocn.2008.21144</ext-link></comment>
<pub-id pub-id-type="pmid">18855547</pub-id></mixed-citation></ref><ref id="pone.0196176.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Brattico</surname><given-names>E</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name>, <name><surname>Valimaki</surname><given-names>V</given-names></name>, <name><surname>van Zuijen</surname><given-names>T</given-names></name>, <name><surname>Peretz</surname><given-names>I</given-names></name> (<year>2003</year>) <article-title>Cortical correlates of acquired deafness to dissonance</article-title>. <source>Ann. N. Y. Acad. Sci</source>. 999: <fpage>158</fpage>&#x02013;<lpage>160</lpage>.</mixed-citation></ref><ref id="pone.0196176.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Virtala</surname><given-names>P</given-names></name>, <name><surname>Berg</surname><given-names>V</given-names></name>, <name><surname>Kivioja</surname><given-names>M</given-names></name>, <name><surname>Purhonen</surname><given-names>J</given-names></name>, <name><surname>Salmenkivi</surname><given-names>M</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>
<etal>et al</etal> (<year>2011</year>) <article-title>The preattentive processing of major vs. minor chords in the human brain: An event-related potential study</article-title>. <source>Neurosci. Lett</source>. 487 (<issue>3</issue>): <fpage>406</fpage>&#x02013;<lpage>410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neulet.2010.10.066">10.1016/j.neulet.2010.10.066</ext-link></comment>
<pub-id pub-id-type="pmid">21055444</pub-id></mixed-citation></ref><ref id="pone.0196176.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Saarinen</surname><given-names>J</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Sch&#x000f6;ger</surname><given-names>E</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name>, <name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name> (<year>1992</year>) <article-title>Representation of abstract attributes of auditory stimuli in the human brain</article-title>. <source>Neuroreport</source> 3 (<issue>12</issue>): <fpage>1149</fpage>&#x02013;<lpage>1151</lpage>. <pub-id pub-id-type="pmid">1493229</pub-id></mixed-citation></ref><ref id="pone.0196176.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Ruusuvirta</surname><given-names>TT</given-names></name>, <name><surname>Astikainen</surname><given-names>P</given-names></name> (<year>2012</year>) <article-title>Mismatch negativity of higher amplitude for melodic ascendance than descendance</article-title>. <source>Neuroreport</source> 23 (<issue>4</issue>): <fpage>220</fpage>&#x02013;<lpage>223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1097/WNR.0b013e32834fe71d">10.1097/WNR.0b013e32834fe71d</ext-link></comment>
<pub-id pub-id-type="pmid">22246244</pub-id></mixed-citation></ref><ref id="pone.0196176.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Rinne</surname><given-names>T</given-names></name>, <name><surname>Alho</surname><given-names>K</given-names></name> (<year>2007</year>) <article-title>The mismatch negativity (MMN) in basic research of central auditory processing: a review</article-title>. <source>Clin. Neurophysiol</source>. 118(<issue>12</issue>):<fpage>2544</fpage>&#x02013;<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.clinph.2007.04.026">10.1016/j.clinph.2007.04.026</ext-link></comment>
<pub-id pub-id-type="pmid">17931964</pub-id></mixed-citation></ref><ref id="pone.0196176.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Schellenberg</surname><given-names>EG</given-names></name>, <name><surname>Trainor</surname><given-names>LJ</given-names></name> (<year>1996</year>) <article-title>Sensory consonance and the perceptual similarity of complex-tone harmonic intervals: Tests of adult and infant listeners</article-title>. <source>J. Acoust. Soc. Am</source>. 100 (<issue>5</issue>): <fpage>3321</fpage>&#x02013;<lpage>3328</lpage>. <pub-id pub-id-type="pmid">8914313</pub-id></mixed-citation></ref><ref id="pone.0196176.ref024"><label>24</label><mixed-citation publication-type="book"><name><surname>Deutsch</surname><given-names>D</given-names></name> (<year>2013</year>) <source>The Psychology of Music</source>, <edition>3<sup>rd</sup> edition</edition>
<publisher-name>Academic Press</publisher-name> ISBN: 9780123814609</mixed-citation></ref><ref id="pone.0196176.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Micheyl</surname><given-names>C</given-names></name>, <name><surname>Delhommeau</surname><given-names>K</given-names></name>, <name><surname>Perrot</surname><given-names>X</given-names></name>, <name><surname>Oxenham</surname><given-names>AJ</given-names></name> (<year>2006</year>) <article-title>Influence of musical and psychoacoustical training on pitch discrimination</article-title>. <source>Hear. Res</source>. 219 (<issue>1&#x02013;2</issue>): <fpage>36</fpage>&#x02013;<lpage>47</lpage>.</mixed-citation></ref><ref id="pone.0196176.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>van Zuijen</surname><given-names>TL</given-names></name>, <name><surname>Simoens</surname><given-names>VL</given-names></name>, <name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name>, <name><surname>Tervaniemi</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Implicit, intuitive, and explicit knowledge of abstract regularities in a sound sequence: an event-related brain potential study</article-title>. <source>J. Cogn. Neurosci</source>. 18 (<issue>8</issue>): <fpage>1292</fpage>&#x02013;<lpage>1303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2006.18.8.1292">10.1162/jocn.2006.18.8.1292</ext-link></comment>
<pub-id pub-id-type="pmid">16859415</pub-id></mixed-citation></ref><ref id="pone.0196176.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Paavilainen</surname><given-names>P</given-names></name>, <name><surname>Arajarvi</surname><given-names>P</given-names></name>, <name><surname>Takegata</surname><given-names>R</given-names></name> (<year>2007</year>) <article-title>Preattentive detection of nonsalient contingencies between auditory features</article-title>. <source>Neuroreport</source> 18 (<issue>2</issue>): <fpage>159</fpage>&#x02013;<lpage>163</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1097/WNR.0b013e328010e2ac">10.1097/WNR.0b013e328010e2ac</ext-link></comment>
<pub-id pub-id-type="pmid">17301682</pub-id></mixed-citation></ref></ref-list></back></article>