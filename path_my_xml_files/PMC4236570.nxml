<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Res Methodol</journal-id><journal-id journal-id-type="iso-abbrev">BMC Med Res Methodol</journal-id><journal-title-group><journal-title>BMC Medical Research Methodology</journal-title></journal-title-group><issn pub-type="epub">1471-2288</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25204467</article-id><article-id pub-id-type="pmc">4236570</article-id><article-id pub-id-type="publisher-id">1471-2288-14-104</article-id><article-id pub-id-type="doi">10.1186/1471-2288-14-104</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>The effect of an internet option and single-sided printing format to increase the response rate to a population-based study: a randomized controlled trial</article-title></title-group><contrib-group><contrib contrib-type="author" id="A1"><name><surname>Fl&#x000fc;&#x000df;</surname><given-names>Elisa</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>elisa.fluess@abdn.ac.uk</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Bond</surname><given-names>Christine M</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>c.m.bond@abdn.ac.uk</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Jones</surname><given-names>Gareth T</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>gareth.jones@abdn.ac.uk</email></contrib><contrib contrib-type="author" corresp="yes" id="A4"><name><surname>Macfarlane</surname><given-names>Gary J</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>g.j.macfarlane@abdn.ac.uk</email></contrib></contrib-group><aff id="I1"><label>1</label>Epidemiology Group, University of Aberdeen, Polwarth Building, Foresterhill, Aberdeen AB25 2ZD, UK</aff><aff id="I2"><label>2</label>Centre for Academic Primary Care, University of Aberdeen, Polwarth Building, Foresterhill, Aberdeen AB25 2ZD, UK</aff><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>9</day><month>9</month><year>2014</year></pub-date><volume>14</volume><fpage>104</fpage><lpage>104</lpage><history><date date-type="received"><day>21</day><month>5</month><year>2014</year></date><date date-type="accepted"><day>12</day><month>8</month><year>2014</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2014 Fl&#x000fc;&#x000df; et al.; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Fl&#x000fc;&#x000df; et al.; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><self-uri xlink:href="http://www.biomedcentral.com/1471-2288/14/104"/><abstract><sec><title>Background</title><p>Paper questionnaires are a common means to collect self-reported information in population-based epidemiological studies. Over the past decades, the response rates to epidemiological studies have been decreasing which can affect the selection process of eligible subjects and lead to non-response bias. Hence, research into strategies to increase questionnaire response rates is crucial. The aim of this study was therefore to explore the effectiveness of single-sided questionnaires and an internet option for response in increasing response rates to a population-based study.</p></sec><sec><title>Methods</title><p>A 2&#x000d7;2 factorial experiment was embedded within a large population-based study of pain and pain management. Persons in the study sample were 4600 residents in Grampian (north of Scotland) aged 25&#x000a0;years and over who were randomly selected from health board records. Sampled persons were randomly assigned to either receive a single-sided or double-sided questionnaire with or without an internet option to respond. The study questionnaire was distributed via post.</p></sec><sec><title>Results</title><p>The overall study response rate was 36.3%. When compared to the reference group that received no intervention (response rate&#x02009;=&#x02009;35.5%), the response rate changed only marginally when single-sided questionnaires were distributed (35.8%) or when an option to reply via the internet was provided (34.3%). A somewhat higher increase in response rates was achieved when both strategies were employed (39.6%). Overall, no significant effect on response rate was determined for each strategy or their interaction.</p></sec><sec><title>Conclusions</title><p>Evidence from this study suggests that neither single-sided questionnaires nor the option to reply via the internet resulted in a significant increase in response rates to population-based studies.</p></sec></abstract><kwd-group><kwd>Response rate</kwd><kwd>Randomized controlled trial</kwd><kwd>Postal questionnaires</kwd><kwd>Health surveys</kwd><kwd>Data collection</kwd><kwd>Internet</kwd></kwd-group></article-meta></front><body><sec><title>Background</title><p>Questionnaires to collect self-reported information are one of the key elements in population-based studies. A common means to conduct these studies is the use of postally distributed questionnaires which are a convenient way to reach a large number of people in a short period of time [<xref ref-type="bibr" rid="B1">1</xref>]. While population studies are less prone to selection bias, low study response rates and selective participation can result in non-response bias which can threaten a study&#x02019;s validity [<xref ref-type="bibr" rid="B2">2</xref>].</p><p>It has been widely observed that response rates to epidemiological studies have been decreasing over the past decades [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B4">4</xref>]. A retrospective review to investigate the change in study participation over time, reported that between 1970 and 2003 the response rates to cohort and cross-sectional studies decreased by &#x02212;0.54% (95 CI: &#x02212;1.33, 0.24) and &#x02212;0.67% (95% CI: &#x02212;1.91, 0.56) per year, respectively [<xref ref-type="bibr" rid="B4">4</xref>]. According to current predictions, response rates are likely to decline further in the future [<xref ref-type="bibr" rid="B3">3</xref>]. While statistical methods, like weighting or imputation, are useful to substitute missing responses, it remains questionable whether they are applicable to studies in which respondents only represent a small fraction of the sample population. It is therefore crucial to explore methods that improve questionnaire response rates to population studies.</p><p>Much research has already been done to explore methods to improve response rates to postal questionnaires [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B6">6</xref>]. To date, the most effective strategies are known to be incentives, the use of special or certified delivery services or shorter questionnaires [<xref ref-type="bibr" rid="B5">5</xref>]. Pre-notification of receiving a questionnaire, reminder mailings and personalization methods can also increase questionnaire response rates significantly. However there are limitations to the existing literature on response rates. It is not clear to what extent methods that have proven to be effective for specific groups, for example, physicians or students are effective for general populations. Secondly, evidence collected previously for approaches based on newer technologies such as the internet may no longer be valid due to the wider use of those technologies within society. Finally the cost-effectiveness of different methods should also be assessed to allow researchers to choose the most appropriate overall approach.</p><p>A method that can easily be applied in population-based studies is to change the printing format of the questionnaire. As yet, four randomized controlled trials (RCTs) have examined the effect on response rates when questionnaires were printed single-sided versus double-sided [<xref ref-type="bibr" rid="B5">5</xref>]. Their findings suggest that the distribution of single-sided questionnaires leads to a small but significant effect on response rates (OR&#x02009;=&#x02009;1.22; 95% CI: 1.01, 1.47). This may seem counter-intuitive since shorter questionnaires have shown to increase response rates. However, it may be speculated that questionnaire respondents felt more encouraged to complete the instrument after noticing that only the first side of the questionnaire pages was printed. They may have believed that its completion would not take up too much of their time after all, hence filled it in and returned it. None of the four trials were conducted within a general population sample. It would therefore be interesting to test this strategy in a population-based study.</p><p>The provision of an internet option to respond to a paper questionnaire may be another potential method to increase the response rate to population-based studies if prospective respondents prefer one administration mode over the other. The effect on response rates when participants received an option to reply via the internet was summarized in a recent meta-analysis [<xref ref-type="bibr" rid="B7">7</xref>]. Only four out of twelve peer-reviewed studies were RCTs that were conducted within general population samples [<xref ref-type="bibr" rid="B8">8</xref>-<xref ref-type="bibr" rid="B11">11</xref>]. The pooled Odds Ratio suggests that an additional web option does not improve response rates to population-based studies (OR&#x02009;=&#x02009;0.90; 0.73, 1.11). Two out of the four trials were carried out more than five years ago. In the context of rapidly growing internet penetration rates (in Scotland: 62.7% in 2007 and 77.4% in 2012; [<xref ref-type="bibr" rid="B12">12</xref>]), it is possible that an additional response option could become more acceptable and in this way increase questionnaire response rates.</p><p>The aims of the current study were to explore the effectiveness of printing the questionnaires single-sided and providing an internet option to respond and to assess the cost-effectiveness of both methods in a population-based study. It was hypothesized that the distribution of single-sided questionnaires and the provision of an internet option have an independent effect on questionnaire response rates, while no interaction effect between methods was expected. A secondary aim was to use additional data collected in this study to update an earlier meta-analysis of the evidence on the effect of an internet option in population studies [<xref ref-type="bibr" rid="B7">7</xref>].</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Study design</title><p>A 2&#x000d7;2 factorial experiment was embedded within a cross-sectional population-based study of pain and pain management in 2012/2013. Using an electronic randomization program, persons in the study sample were randomly allocated to either receive (1) a single-sided or double-sided questionnaire and (2) an option or no option to reply via the internet.</p></sec><sec><title>Study procedure</title><p>A random sample of 4600 residents in Grampian (north of Scotland, UK) aged 25&#x000a0;years and over was selected from health board records. Upon randomization, selected persons were sent a notification letter that they had been selected for the study. One week later they were sent a survey pack comprising an invitation letter, an information sheet, the questionnaire and a pre-paid reply envelope. Potential participants were advised to read the information sheet and to complete and return the questionnaire if they wished to take part. The invitation letter for those in the web option groups contained, in addition, the URL link to the electronic questionnaire and their individual ID number and password for its access. Non-respondents were sent a second survey pack appropriate to their randomization group, three weeks after the first contact (i.e. two weeks after the questionnaire distribution) (Figure&#x000a0;<xref ref-type="fig" rid="F1">1</xref>).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>Flowchart of the study procedure.</p></caption><graphic xlink:href="1471-2288-14-104-1"/></fig></sec><sec><title>Study questionnaire</title><p>The 20-page study questionnaire included questions on participants&#x02019; demographic characteristics (gender, age, and educational background), their health, pain and pain management. Validated standard questionnaires were used to collect information on participants&#x02019; health (SF-36 [<xref ref-type="bibr" rid="B13">13</xref>]) and pain status (set of pain questions with manikins and Chronic Pain Grade [<xref ref-type="bibr" rid="B14">14</xref>]). The questionnaire to collect pain management information was validated within a small population sample before the conduct of the study (Results to be published). Depending on their randomization, persons in the study sample either received a 10-sheet (double-sided) or a 20-sheet (single-sided) questionnaire.</p></sec><sec><title>Statistical analysis</title><p>The main outcome of interest was questionnaire response rate; defined as the percentage of completed and partially completed questionnaires returned after excluding from the denominator those which were invalid (e.g. change of address or death). With questionnaire response as the dependent variable, logistic regression models were performed in order to determine predictors for questionnaire response. Odds Ratios and 95% Confidence Intervals were calculated in order to quantify the effect of the strategies on the questionnaire response rate. A meta-analysis was performed to summarize the current evidence on the effectiveness of an internet option in increasing response rates to population-based studies. Additionally, the cost-effectiveness of single-sided questionnaires and an internet option was investigated by determining the cost per additional response.</p></sec><sec><title>Ethical approval</title><p>The study was approved by the North of Scotland National Health Service Research Ethics Committee (REC reference: 12/NS/0079).</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Response rate</title><p>The response rate before the reminder surveys were distributed to non-respondents was 21.4%. At the end of data collection, 183 questionnaires were found invalid (for example, due to an invited participant being deceased or no longer resident at the given address) and 1604 completed questionnaires were returned giving an overall study response rate of 36.3% (1604/4417). Out of the respondents who were offered an internet option, 60 completed the electronic questionnaire (7.3%).</p></sec><sec><title>Time to respond</title><p>Completed study questionnaires were returned a median of 10&#x000a0;days (Interquartile range (IQR): 7, 20) after their distribution. Electronic questionnaires were received earlier than paper questionnaires (median, web: 7&#x000a0;days; median, paper: 10&#x000a0;days; Mann&#x02013;Whitney test: p&#x02009;&#x0003c;&#x02009;0.001).</p></sec><sec><title>Respondents&#x02019; demographic characteristics</title><p>Females represented 55.3% of respondents. The median age was 55&#x000a0;years (IQR: 44, 65) with the oldest respondent aged 94&#x000a0;years. The majority of respondents reported secondary school (29.6%), a vocational qualification (20.0%) or a professional qualification (16.7%) as their highest level of education. When compared to non-respondents, respondents were significantly more likely to be female and of older age (Chi-square test: p&#x02009;&#x0003c;&#x02009;0.001, both tests). There was a significant interaction between gender and age, showing that the positive effect of female gender on response reduces with older age. Electronic respondents (n&#x02009;=&#x02009;60) were significantly more likely to be younger and more educated when compared to paper respondents (Chi-square test: p&#x02009;&#x0003c;&#x02009;0.001, both tests).</p></sec><sec><title>Response rate by study group</title><p>There were small differences in response rates between the four study groups. The reference group achieved a response rate of 35.5%. When sampled persons were provided with an internet option, this dropped to 34.3%. In contrast, the response rate increased to 35.8% when participants were sent a single-sided questionnaire with no option to respond via the internet. A greater increase in response rate of 4.1% was determined when participants received both interventions (39.6%).</p></sec><sec><title>The effectiveness of the strategies in increasing response rates</title><p>From the logistic model there was no &#x0201c;main&#x0201d; effect on response rates when an internet option was provided (OR&#x02009;=&#x02009;0.95, 95% CI&#x02009;=&#x02009;0.80, 1.13) or when single-sided questionnaires were distributed (OR&#x02009;=&#x02009;1.01, 95% CI&#x02009;=&#x02009;0.85, 1.20). Moreover, the interaction between both strategies led to a larger, albeit not statistically significant, effect (OR&#x02009;=&#x02009;1.24, 95% CI&#x02009;=&#x02009;0.97, 1.59, Table&#x000a0;<xref ref-type="table" rid="T1">1</xref>).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>The effect of the strategies on response rates</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="center"/><col align="center"/></colgroup><thead valign="top"><tr><th align="center" valign="middle"><bold>Logistic Regression, Model term</bold></th><th align="center" valign="middle"><bold>Crude OR (95% CI)</bold></th></tr></thead><tbody valign="top"><tr><td align="center" valign="bottom">No intervention<hr/></td><td align="center" valign="bottom">1.00<hr/></td></tr><tr><td align="center" valign="bottom">Web (main effect)<hr/></td><td align="center" valign="bottom">0.95 (0.80, 1.13)<hr/></td></tr><tr><td align="center" valign="bottom">Single-sided (main effect)<hr/></td><td align="center" valign="bottom">1.01 (0.85, 1.20)<hr/></td></tr><tr><td align="center">Web&#x02009;+&#x02009;Single-sided (interaction term)</td><td align="center">1.24 (0.97, 1.59)</td></tr></tbody></table></table-wrap><p>When comparing the response rates of those who were randomized to receive an internet option and those who were not, the strategy of providing an internet option increased the response rate non-significantly by 1.3% (OR&#x02009;=&#x02009;1.06; 95% CI: 0.94, 1.20). A somewhat larger, yet non-significant effect was determined when the response rates of those who were allocated to receive a single-sided questionnaire and those who were allocated to be sent a double-sided questionnaire were compared: the response rate increased by 2.8% when participants received a single-sided questionnaire (OR&#x02009;=&#x02009;1.13; 95% CI: 0.998, 1.28).</p></sec><sec><title>Internet option &#x02013; summary of evidence</title><p>When the results of the current study were added to those reported in previous population studies (Figure&#x000a0;<xref ref-type="fig" rid="F2">2</xref>), there no effect on response rates when an internet option versus no internet option was provided for participants (OR&#x02009;=&#x02009;0.95; 0.83, 1.10). There was no obvious pattern of an improvement in the effectiveness of an internet option over time. There was significant heterogeneity between studies.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p>Comparison of an internet option vs. no internet option to increase response to population studies.</p></caption><graphic xlink:href="1471-2288-14-104-2"/></fig></sec><sec><title>Cost-effectiveness</title><p>The employment of the strategies to increase response rates was associated with additional cost. The use of single-sided questionnaires led to increased cost for printing (since the required number of pages doubled) and postage (because the survey packs were heavier). The implementation of an electronic version of the study questionnaire resulted in extra costs due to programming time and set up cost. Due to the low uptake rate of the internet option, differences in data entry costs were minimal. It was therefore decided not to include the data entry costs in the cost-effectiveness analysis. As outlined in Table&#x000a0;<xref ref-type="table" rid="T2">2</xref>, the cost per response was the lowest in the reference group that did not receive either intervention (&#x000a3;6.64). An additional cost of at least &#x000a3;1.02 per response was spent for the employment of the interventions. The internet option resulted in lower response at greater cost when double-sided questionnaires were distributed. The use of single-sided rather than double-sided questionnaires cost &#x000a3;119.19 per additional response. The combination of both methods was more cost-effective: Distributing single-sided questionnaire with an option to reply via the internet cost &#x000a3;25.20 per extra response.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Strategies to improve questionnaire response: Cost-effectiveness</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="center"/><col align="center"/><col align="center"/><col align="center"/><col align="center"/></colgroup><thead valign="top"><tr><th align="center" valign="middle">&#x000a0;</th><th align="center" valign="middle"><bold>No internet option &#x00026; Double-sided</bold></th><th align="center" valign="middle"><bold>Internet option &#x00026; Double-sided</bold></th><th align="center" valign="middle"><bold>No internet option &#x00026; Single-sided</bold></th><th align="center" valign="middle"><bold>Internet option &#x00026; Single-sided</bold></th></tr></thead><tbody valign="top"><tr><td align="center" valign="bottom"><bold>Response rate (in %)</bold><hr/></td><td align="center" valign="bottom">35.5<hr/></td><td align="center" valign="bottom">34.3<hr/></td><td align="center" valign="bottom">35.8<hr/></td><td align="center" valign="bottom">39.4<hr/></td></tr><tr><td align="center" valign="bottom"><bold>Nr. of respondents</bold><hr/></td><td align="center" valign="bottom">393<hr/></td><td align="center" valign="bottom">382<hr/></td><td align="center" valign="bottom">387<hr/></td><td align="center" valign="bottom">442<hr/></td></tr><tr><td align="center" valign="bottom"><bold>Nr. of eligible participants</bold><hr/></td><td align="center" valign="bottom">1106<hr/></td><td align="center" valign="bottom">1082<hr/></td><td align="center" valign="bottom">1113<hr/></td><td align="center" valign="bottom">1116<hr/></td></tr><tr><td align="center" valign="bottom"><bold>Cost per response (&#x000a3;)</bold><hr/></td><td align="center" valign="bottom">6.64<hr/></td><td align="center" valign="bottom">8.59<hr/></td><td align="center" valign="bottom">7.67<hr/></td><td align="center" valign="bottom">8.36<hr/></td></tr><tr><td align="center"><bold>Cost per additional response (&#x000a3;)</bold></td><td align="center">--</td><td align="center">--</td><td align="center">119.19</td><td align="center">25.20</td></tr></tbody></table></table-wrap></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Main findings</title><p>Overall, neither the use of single-sided questionnaires nor the provision to reply via the internet significantly improved the questionnaire response rate in the current study. A small but non-significant interaction effect was determined when both strategies were used in combination.</p><p>The current study was the first study that explored the effectiveness of single-sided questionnaires in a population-based sample. We found no effect on response rates when questionnaires were printed single-sided (OR&#x02009;=&#x02009;1.13; 95% CI: 0.998, 1.28). Likewise, no effect on response rates was determined when an internet option was provided for the sampled persons (OR&#x02009;=&#x02009;1.06; 95% CI: 0.94, 1.20). An updated meta-analysis confirmed that based on the current evidence of five studies, an option to reply via the internet does not improve response rates to a population study (OR&#x02009;=&#x02009;0.95; 0.83, 1.10).</p></sec><sec><title>Strengths and limitations</title><p>The current study had several strengths. Firstly, we used a randomized controlled study design. Secondly, the use of a two by two factorial design enabled us to test the independent and the combined effect of two different methods to increase questionnaire response rates. Thirdly, we conducted a subsequent cost-effectiveness analysis which provided insight into the expenses that were associated with the respective strategies under investigation.</p><p>A limitation of the study was that it was a sub-study within a large cross-sectional study. The study sample size was therefore powered on the main outcome variables and not on the difference in questionnaire response rates. Nevertheless, the main effects of both strategies on questionnaire response rates were very small and insufficient power to detect a meaningful difference is unlikely to have been a reason for observed lack of effect. It is probable however, that there was a lack of power to detect a significant interaction effect between both studies. Secondly, due to a small number of electronic responses the interpretation of some results was limited. It was determined that electronic respondents were significantly younger and more highly educated when compared to paper respondents. While a higher proportion of electronic respondents were male and living in an urban area (information provided by the sampling frame), these differences were not statistically significant &#x02013; most probably due to a lack of power.</p></sec><sec><title>Findings in relation to previous studies</title><p>Out of the 824 respondents who were randomized to the internet option groups, only 60 (7.3%) used the electronic version to respond to the questionnaire. The low uptake rate of the internet option was similar to that observed in the population study by Ziegenfuss et al. [<xref ref-type="bibr" rid="B9">9</xref>], in which only 8.0% of the web option respondents used the electronic questionnaire. While a lack of internet coverage was not a concern in the current study, it is likely that the initial mode of contact caused the low internet uptake rate. Since all prospective respondents were sent a paper questionnaire, they may have been more inclined to complete and return the paper version.</p><p>A couple of hypotheses have been discussed in the literature to explain why an internet option is ineffective in increasing response rates [<xref ref-type="bibr" rid="B7">7</xref>]. Firstly, when approached by mail, the completion of an electronic questionnaire requires additional effort for participants since they have to &#x02018;switch task mode&#x02019;. It can be hypothesized that a number of people may initially have decided to use the electronic questionnaire but never actually logged on to complete and submit. Secondly, long and complicated URLs (e.g. those containing numbers and case sensitive letters) may make it more difficult for participants to access the online questionnaire and appear off-putting. As a result, fewer participants may consider completing the online version. Nevertheless, the URL in the current study was reasonably short and only contained lowercase letters). Thirdly, people may be less likely to respond when provided with an internet option because they are required to make a choice at the very beginning. According to Schwartz [<xref ref-type="bibr" rid="B15">15</xref>], offering choices has negative effects on people&#x02019;s decision-making. Since every choice is associated with opportunity costs, one must consider the trade-offs concerned with each option they are offered. This, in turn, makes it less appealing to choose either one. It remains uncertain why the use of single-sided questionnaires was ineffective in the current study. The questionnaire in the current study consisted of 20 pages and appeared very bulky when printed single-sided. It can be assumed that people might have felt discouraged when they received the questionnaire. Surprisingly, we established that although not statistically significant, there was an effect on questionnaire response rate that laid in the interaction of both strategies (OR&#x02009;=&#x02009;1.24, 95% CI&#x02009;=&#x02009;0.97, 1.59). It remains questionable why the response rates were only increased when sampled persons received both interventions. It can be speculated that fewer people considered using the internet option when they were sent a single-sided questionnaire. People may have believed that its completion would take up less of their time using the printed version and hence, were more likely to complete and return it straight away.</p><p>We added our findings to the results of previous population studies that were summarized in a recent meta-analysis by Medway and Fulton [<xref ref-type="bibr" rid="B7">7</xref>]. In order to account for any studies that were published after 2011, we conducted a comprehensive literature search. However, no additional papers were identified.</p></sec></sec><sec sec-type="conclusions"><title>Conclusions</title><p>Taken as a whole, neither an option to reply via the internet nor the use of single-sided questionnaires were effective methods to significantly increase the response rates to a population-based sample. The results derived from the web option comparison were in agreement with the pooled effect size of the current evidence. Furthermore, it has been demonstrated that the cost per additional response was high, even when both methods were combined. As result of the current findings, researchers should be aware that neither method is effective in increasing response rates to future population studies. Besides, researchers should be alerted to select the methods to increase questionnaire response rates in consideration of their effectiveness and the costs concerned. Due to the current trend of decreasing response rates, further research into strategies to increase those remains important. Future studies should always provide sufficient information on the cost-effectiveness of each employed strategy in order to allow an appropriate assessment of these.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors&#x02019; contributions</title><p>This study was conceived by GJM, GTJ and CMB. It was planned by all the authors and EF conducted the study. EF drafted the manuscript and all other authors critically reviewed the manuscript and provided important intellectual content. All authors read and approved the final manuscript.</p></sec><sec><title>Pre-publication history</title><p>The pre-publication history for this paper can be accessed here:</p><p><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2288/14/104/prepub">http://www.biomedcentral.com/1471-2288/14/104/prepub</ext-link></p></sec></body><back><sec><title>Acknowledgements</title><p>We would like to thank the Institute of Applied Health Sciences (IAHS) at the University of Aberdeen for funding the PhD studentship of EF. Furthermore, we would like to thank everyone who was involved in the study, including Professor Sir Lewis Ritchie (Director of Public Health, NHS Grampian), John Lemon (University of Aberdeen), Dr. Fiona Garton (University of Aberdeen) and the Aberdeen Service User Group. Lastly, we would like to acknowledge all data entry clerks (Maxx Livingstone, Rory Macfarlane, Georgia Mannion-Krase and Hazel Reilly) and participants of the study.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="book"><name><surname>Silman</surname><given-names>AJ</given-names></name><name><surname>Macfarlane</surname><given-names>GJ</given-names></name><source>Epidemiological studies. A practical Guide</source><year>2005</year><edition>2</edition><publisher-name>Cambridge: Cambridge University Press</publisher-name></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Galea</surname><given-names>S</given-names></name><name><surname>Tracy</surname><given-names>M</given-names></name><article-title>Participation rates in epidemiologic studies</article-title><source>Ann Epidemiol</source><year>2007</year><volume>17</volume><issue>9</issue><fpage>643</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1016/j.annepidem.2007.03.013</pub-id><pub-id pub-id-type="pmid">17553702</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Galea</surname><given-names>S</given-names></name><article-title>Participation rates in epidemiologic studies</article-title><source>Ann Epidemiol</source><year>2007</year><volume>17</volume><issue>9</issue><fpage>643</fpage><pub-id pub-id-type="doi">10.1016/j.annepidem.2007.03.013</pub-id><pub-id pub-id-type="pmid">17553702</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Morton</surname><given-names>LM</given-names></name><article-title>Reporting participation in epidemiologic studies: a survey of practice</article-title><source>Am J Epidemiol</source><year>2006</year><volume>163</volume><issue>3</issue><fpage>197</fpage><pub-id pub-id-type="pmid">16339049</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Edwards</surname><given-names>PJ</given-names></name><name><surname>Roberts</surname><given-names>I</given-names></name><name><surname>Clarke</surname><given-names>MJ</given-names></name><name><surname>Diguiseppi</surname><given-names>C</given-names></name><name><surname>Wentz</surname><given-names>R</given-names></name><name><surname>Kwan</surname><given-names>I</given-names></name><name><surname>Cooper</surname><given-names>R</given-names></name><name><surname>Felix</surname><given-names>LM</given-names></name><name><surname>Pratap</surname><given-names>S</given-names></name><article-title>Methods to increase response to postal and electronic questionnaires</article-title><source>Cochrane Database Syst Rev</source><year>2009</year><volume>3</volume><comment>MR000008</comment></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Nakash</surname><given-names>R</given-names></name><article-title>Maximising response to postal questionnaires&#x02013;a systematic review of randomised trials in health research</article-title><source>BMC Med Res Methodol</source><year>2006</year><volume>6</volume><issue>1</issue><fpage>5</fpage><pub-id pub-id-type="doi">10.1186/1471-2288-6-5</pub-id><pub-id pub-id-type="pmid">16504090</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Medway</surname><given-names>RL</given-names></name><name><surname>Fulton</surname><given-names>J</given-names></name><article-title>When more gets you less: a meta-analysis of the effect of concurrent web options on mail survey response rates</article-title><source>Public Opin Q</source><year>2012</year><volume>76</volume><issue>4</issue><fpage>733</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1093/poq/nfs047</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Brogger</surname><given-names>J</given-names></name><name><surname>Nystad</surname><given-names>W</given-names></name><name><surname>Cappelen</surname><given-names>I</given-names></name><name><surname>Bakke</surname><given-names>P</given-names></name><article-title>No increase in response rate by adding a web response option to a postal population survey: a randomized trial</article-title><source>J Med Internet Res</source><year>2007</year><volume>9</volume><issue>5</issue><fpage>e40</fpage><pub-id pub-id-type="doi">10.2196/jmir.9.5.e40</pub-id><pub-id pub-id-type="pmid">18174120</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Ziegenfuss</surname><given-names>JY</given-names></name><name><surname>Beebe</surname><given-names>TJ</given-names></name><name><surname>Rey</surname><given-names>E</given-names></name><name><surname>Schleck</surname><given-names>C</given-names></name><name><surname>Locke</surname><given-names>GR</given-names></name><name><surname>Talley</surname><given-names>NJ</given-names></name><article-title>Internet option in a mail survey: More harm than good?</article-title><source>Epidemiology</source><year>2010</year><volume>21</volume><issue>4</issue><fpage>585</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1097/EDE.0b013e3181e09657</pub-id><pub-id pub-id-type="pmid">20539115</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Schneider</surname><given-names>SJ</given-names></name><name><surname>Cantor</surname><given-names>D</given-names></name><name><surname>Malakhoff</surname><given-names>L</given-names></name><name><surname>Arieira</surname><given-names>C</given-names></name><name><surname>Segel</surname><given-names>P</given-names></name><name><surname>Nguyen</surname><given-names>K</given-names></name><name><surname>Tancreto</surname><given-names>JG</given-names></name><article-title>Telephone, internet, and paper data collection modes for the Census 2000 short form</article-title><source>J Official Stat</source><year>2005</year><volume>21</volume><issue>1</issue><fpage>89</fpage><lpage>101</lpage></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Smyth</surname><given-names>JD</given-names></name><name><surname>Dillman</surname><given-names>DA</given-names></name><name><surname>Christian</surname><given-names>LM</given-names></name><name><surname>O'Neill</surname><given-names>AC</given-names></name><article-title>Using the internet to survey small towns and communities: limitations and possibilities in the early 21st century</article-title><source>Am Behav Sci</source><year>2010</year><volume>53</volume><issue>9</issue><fpage>1423</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1177/0002764210361695</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="other"><source>Widen use of the internet</source><comment><ext-link ext-link-type="uri" xlink:href="http://www.scotland.gov.uk/About/Performance/scotPerforms/indicator/internet">http://www.scotland.gov.uk/About/Performance/scotPerforms/indicator/internet</ext-link></comment></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Ware</surname><given-names>JE</given-names><suffix>Jr</suffix></name><name><surname>Sherbourne</surname><given-names>CD</given-names></name><article-title>The MOS 36-item short-form health survey (SF-36): I. Conceptual framework and item selection</article-title><source>Med Care</source><year>1992</year><volume>30</volume><issue>6</issue><fpage>473</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1097/00005650-199206000-00002</pub-id><pub-id pub-id-type="pmid">1593914</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Von Korff</surname><given-names>M</given-names></name><name><surname>Dworkin</surname><given-names>SF</given-names></name><name><surname>Le Resche</surname><given-names>L</given-names></name><article-title>Graded chronic pain status: an epidemiologic evaluation</article-title><source>Pain</source><year>1990</year><volume>40</volume><issue>3</issue><fpage>279</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1016/0304-3959(90)91125-3</pub-id><pub-id pub-id-type="pmid">2326094</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="other"><name><surname>Schwartz</surname><given-names>B</given-names></name><source>The paradox of choice. New York: Harper Perennial</source><year>2004</year></mixed-citation></ref></ref-list></back></article>