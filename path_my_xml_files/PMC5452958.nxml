<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PeerJ</journal-id><journal-id journal-id-type="iso-abbrev">PeerJ</journal-id><journal-id journal-id-type="pmc">PeerJ</journal-id><journal-id journal-id-type="publisher-id">PeerJ</journal-id><journal-title-group><journal-title>PeerJ</journal-title></journal-title-group><issn pub-type="epub">2167-8359</issn><publisher><publisher-name>PeerJ Inc.</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28584698</article-id><article-id pub-id-type="pmc">5452958</article-id><article-id pub-id-type="publisher-id">3209</article-id><article-id pub-id-type="doi">10.7717/peerj.3209</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychiatry and Psychology</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational Science</subject></subj-group></article-categories><title-group><article-title>High or low? Comparing high and low-variability phonetic training in adult and child second language learners</article-title></title-group><contrib-group><contrib id="author-1" contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0698-1121</contrib-id><name><surname>Giannakopoulou</surname><given-names>Anastasia</given-names></name><xref ref-type="aff" rid="aff-1">1</xref></contrib><contrib id="author-2" contrib-type="author"><name><surname>Brown</surname><given-names>Helen</given-names></name><xref ref-type="aff" rid="aff-2">2</xref></contrib><contrib id="author-3" contrib-type="author"><name><surname>Clayards</surname><given-names>Meghan</given-names></name><xref ref-type="aff" rid="aff-3">3</xref></contrib><contrib id="author-4" contrib-type="author" corresp="yes"><name><surname>Wonnacott</surname><given-names>Elizabeth</given-names></name><xref ref-type="aff" rid="aff-4">4</xref><email>e.wonnacott@ucl.ac.uk</email></contrib><aff id="aff-1"><label>1</label><institution>School of Psychology, University of Bedfordshire</institution>, <addr-line>Luton</addr-line>, <country>UK</country></aff><aff id="aff-2"><label>2</label><institution>Department of Psychology, University of Warwick</institution>, <addr-line>Coventry</addr-line>, <country>UK</country></aff><aff id="aff-3"><label>3</label><institution>Department of Linguistics, School of Communications Sciences and Disorders, McGill University</institution>, <addr-line>Montreal, QC</addr-line>, <country>Canada</country></aff><aff id="aff-4"><label>4</label><institution>Psychology and Language Sciences, University College London, University of London</institution>, <addr-line>London</addr-line>, <country>UK</country></aff></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Brock</surname><given-names>Jon</given-names></name></contrib></contrib-group><pub-date pub-type="epub" date-type="pub" iso-8601-date="2017-05-30"><day>30</day><month>5</month><year iso-8601-date="2017">2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>5</volume><elocation-id>e3209</elocation-id><history><date date-type="received" iso-8601-date="2016-11-07"><day>7</day><month>11</month><year iso-8601-date="2016">2016</year></date><date date-type="accepted" iso-8601-date="2017-03-21"><day>21</day><month>3</month><year iso-8601-date="2017">2017</year></date></history><permissions><copyright-statement>&#x000a9; 2017 Giannakopoulou et al.</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Giannakopoulou et al.</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p></license></permissions><self-uri xlink:href="https://peerj.com/articles/3209"/><abstract><sec><title>Background</title><p>High talker variability (i.e., multiple voices in the input) has been found effective in training nonnative phonetic contrasts in adults. A small number of studies suggest that children also benefit from high-variability phonetic training with some evidence that they show greater learning (more plasticity) than adults given matched input, although results are mixed. However, no study has directly compared the effectiveness of high versus low talker variability in children.</p></sec><sec><title>Methods</title><p>Native Greek-speaking eight-year-olds (<italic>N</italic> = 52), and adults (<italic>N</italic> = 41) were exposed to the English /i/-/&#x0026a;/ contrast in 10 training sessions through a computerized word-learning game. Pre- and post-training tests examined discrimination of the contrast as well as lexical learning. Participants were randomly assigned to high (four talkers) or low (one talker) variability training conditions.</p></sec><sec><title>Results</title><p>Both age groups improved during training, and both improved more while trained with a single talker. Results of a three-interval oddity discrimination test did not show the predicted benefit of high-variability training in either age group. Instead, children showed an effect in the <italic>reverse</italic> direction&#x02014;i.e., reliably greater improvements in discrimination following single talker training, even for untrained generalization items, although the result is qualified by (accidental) differences between participant groups at pre-test. Adults showed a numeric advantage for high-variability but were inconsistent with respect to voice and word novelty. In addition, no effect of variability was found for lexical learning. There was no evidence of greater plasticity for phonetic learning in child learners.</p></sec><sec><title>Discussion</title><p>This paper adds to the handful of studies demonstrating that, like adults, child learners can improve their discrimination of a phonetic contrast via computerized training. There was no evidence of a benefit of training with multiple talkers, either for discrimination or word learning. The results also do not support the findings of greater plasticity in child learners found in a previous paper (<xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2013a</xref>). We discuss these results in terms of various differences between training and test tasks used in the current work compared with previous literature.</p></sec></abstract><kwd-group kwd-group-type="author"><kwd>High-variability perceptual training</kwd><kwd>Child second language learning</kwd><kwd>L2 phonetic contrasts</kwd></kwd-group><funding-group><award-group id="fund-1"><funding-source>British Academy Small Grant</funding-source><award-id>SG111965</award-id></award-group><award-group id="fund-2"><funding-source>Economic and Social Research Council</funding-source><award-id>ES/K013637/2</award-id></award-group><funding-statement>The work was supported by the British Academy Small Grant, a grant awarded to EW and MC (SG111965), a grant awarded to EW and HB from the Economic and Social Research Council (ES/K013637/2), and by a grant awarded to AG by the Research Centre for Applied Psychology, University of Bedfordshire. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><sec><title>Phonetic training studies in adults</title><p>One of the most challenging aspects of learning a second language (L2) is learning to accurately perceive novel phonetic categories. This is particularly difficult when the mapping between phonetic properties and phonological categories is mismatched between the first language (L1) and L2 (<xref rid="ref-11" ref-type="bibr">Best, 1995</xref>; <xref rid="ref-17" ref-type="bibr">Flege, 1995</xref>; <xref rid="ref-19" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2011</xref>). A substantial body of literature has demonstrated that adult learners can improve their discrimination and identification of nonnative speech sounds through phonetic training, but that effective generalization may depend upon encountering sufficiently varied stimuli during training. For example, in an early attempt to train a nonnative contrast, <xref rid="ref-54" ref-type="bibr">Strange &#x00026; Dittmann (1984)</xref> trained native Japanese speakers on the English /r/-/l/ contrast using a discrimination task in which participants made same&#x02013;different judgments about stimuli from a synthetic <italic>rock-lock</italic> continuum, receiving immediate trial by trial feedback. Variability was present in the form of the ambiguous intermediate stimuli along the continuum, however, there was a single phonetic context and a single (synthesized) talker. Participants were given a variety of discrimination and identification tasks pre- and post-training. These revealed improvements in discrimination and identification for stimuli on the synthesized <italic>rock-lock</italic> continuum, and for novel items on a synthesized <italic>rake-lake</italic> continuum, but <italic>not</italic> for naturally produced minimal pair items that had not been encountered in training. Later experiments suggested that this limited generalization was due to the low-variability present in the stimuli used in the training intervention (i.e., a single phonetic context and single talker).</p><p><xref rid="ref-32" ref-type="bibr">Logan, Lively &#x00026; Pisoni (1991)</xref> also trained Japanese speakers on the English /r/-/l/ contrast, but used <italic>high-variability</italic> training stimuli that included multiple natural exemplars (67 minimal pairs, where the target speech sounds appeared in different phonetic contexts) and multiple talkers (four males and two females). They employed a minimal pair identification task in which participants identified the correct member from a (written) minimal pair, receiving trial by trial feedback. Comparison of performance on tests administered pre- and post-training revealed improvements in tasks that involved both trained stimuli <italic>and</italic> untrained stimuli produced by a new talker. <xref rid="ref-30" ref-type="bibr">Lively, Logan &#x00026; Pisoni (1993)</xref> replicated this finding of generalization after high-variability training and, in a follow up experiment using the same training paradigm but with training stimuli produced by a single (natural) talker (although still exemplifying the contrast in multiple phonetic environments), they found improvements between pre- and post-test for the trained talker, but <italic>not</italic> for an untrained talker, suggesting a specific role for talker variability in high-variability training.</p><p>Following the work of <xref rid="ref-32" ref-type="bibr">Logan, Lively &#x00026; Pisoni (1991)</xref>, high-variability phonetic training has become a standard methodology in the field. The effectiveness of this type of training has been demonstrated for various phonetic contrasts and in studies which have also found benefits for long-term retention and in production tasks (<xref rid="ref-14" ref-type="bibr">Bradlow et al., 1997</xref>, <xref rid="ref-13" ref-type="bibr">1999</xref>; <xref rid="ref-31" ref-type="bibr">Lively et al., 1994</xref>).</p></sec><sec><title>Phonetic training studies with children</title><p>To date, studies of L2 phonetic training have primarily been conducted in adults. There is reason to predict that child L2 learners might outperform adults in these tasks, due to enhanced brain plasticity. A large body of research reports declines in language learning capacities with age (<xref rid="ref-26" ref-type="bibr">Johnson &#x00026; Newport, 1989</xref>; <xref rid="ref-29" ref-type="bibr">Lenneberg, 1967</xref>; <xref rid="ref-36" ref-type="bibr">Newport, 1990</xref>, also see <xref rid="ref-28" ref-type="bibr">Kuhl, 2004</xref>, for review), with various theories proposed to account for this including changes to developing cognitive mechanisms (<xref rid="ref-36" ref-type="bibr">Newport, 1990</xref>) and increased neural commitment to structures necessary for the L1 (<xref rid="ref-28" ref-type="bibr">Kuhl, 2004</xref>). For phonetic learning specifically, there is some naturalistic support for a benefit of age in L2 speech sound discrimination coming from longitudinal studies comparing child and adult L2 learners in immersion situations. These studies show better L2 speech sound discrimination in children compared to adults (<xref rid="ref-2" ref-type="bibr">Aoyama et al., 2004</xref>; <xref rid="ref-56" ref-type="bibr">Tsukada et al., 2005</xref>), although studies comparing adults and children after periods of immersion less than one year, do not always find clear perception advantages for children (e.g., <xref rid="ref-6" ref-type="bibr">Baker et al., 2008</xref>; <xref rid="ref-50" ref-type="bibr">Snow &#x00026; Hoefnagel-H&#x000f6;hle, 1978</xref>). However, a limitation to these naturalistic studies is that, while they control for length of residence in the L2-speaking country, the actual input received by the learners was not controlled. As <xref rid="ref-56" ref-type="bibr">Tsukada et al. (2005)</xref> point out, it is possible that children may be immersed in a more L2-rich environment than adults, making it difficult to pull apart age effects from differences in input.</p><p>Turning to training studies, only a handful of experiments have compared children and adults. These have all used high-variability phonetic training but have produced mixed results with regards to the role of age. <xref rid="ref-57" ref-type="bibr">Wang &#x00026; Kuhl (2003)</xref> conducted a two-week computer-based Mandarin tone training study in which native English-speaking adults and children (three age groups: 6, 10, and 14-year-olds), with no previous experience of Mandarin, were trained to associate tones with symbols (i.e., a picture of an animal for each of the four trained tones). Training stimuli exhibited high-variability (648 stimuli produced by six native speakers of Mandarin). Overall, older participants outperformed younger participants (adults &#x0003e;14 years &#x0003e;10 years &#x0003e;6 years) at both the pre- and post-training tests. However, although all participant groups improved as a result of training, the amount of improvement was approximately the same across all age groups. This result thus does not support an account in which younger learners demonstrate greater plasticity.</p><p><xref rid="ref-57" ref-type="bibr">Wang &#x00026; Kuhl (2003)</xref> suggest that one possible explanation for the fact that they did not see plasticity differences for children and adults is that, for tones, English speakers do not have pre-existing comparable categories. This means that the &#x0201c;mental map&#x0201d; for tone is equally open for children and adults, so that age effects due to previous L1 experience are not expected. This would predict that plasticity effects should be more likely in segmental phonology. However, a similar result was found by <xref rid="ref-22" ref-type="bibr">Heeren &#x00026; Schouten (2008</xref>, <xref rid="ref-23" ref-type="bibr">2010</xref>), who trained adults and 12-year-old native Dutch speakers, with no previous Finnish experience, to discriminate the Finnish length contrast /t/-/t:/. This was a five-day study with a pre-test and post-test on the first and last days and three days of training. Training consisted of an identification paradigm (participants identified stimuli as &#x0201c;short t&#x0201d; or &#x0201c;long t&#x0201d; and received feedback). Stimuli were seven-step continua created from recordings of five talkers. Pre- and post-tests included identification and discrimination within and across category boundaries. Although adults again out performed children overall, both age groups showed reliable increases in sensitivity in the newly trained category boundaries and, critically, there were again similar levels of improvement in both age groups. This result might appear to corroborate that of <xref rid="ref-57" ref-type="bibr">Wang &#x00026; Kuhl (2003)</xref>, however, the lack of age effects may be due to a different reason, specifically, the amount of training provided (three training sessions) may be insufficient in order for children to outperform adults (c.f., <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2013a</xref>, discussed below).</p><p>In contrast to the studies discussed above, two further studies <italic>have</italic> found evidence of greater learning in children than adults for high-variability phonetic training. <xref rid="ref-46" ref-type="bibr">Shinohara &#x00026; Iverson (2013</xref>, <xref rid="ref-47" ref-type="bibr">2015</xref>; also <xref rid="ref-45" ref-type="bibr">Shinohara, 2014)</xref> compared learning of the English /r/-/l/ contrast in native Japanese adults (25&#x02013;59 years), adolescents (15&#x02013;18 years) and older and younger children (8&#x02013;12 and 6&#x02013;8 years). Training stimuli exhibited high-variability (100 word-initial minimal pairs from five talkers) and involved ten days of minimal pair identification (with written stimuli) and discrimination tasks (all with feedback). There were pre- and post-test identification tasks with new talkers in both trained (word-initial) position and untrained positions. In both identification accuracy and category discrimination abilities, all groups showed evidence of learning and generalization to new speakers and phonetic contexts. However, adolescents and older children improved more than either 6&#x02013;8 year-olds or adults. <xref rid="ref-46" ref-type="bibr">Shinohara &#x00026; Iverson (2013</xref>, <xref rid="ref-47" ref-type="bibr">2015</xref>) interpret the increased learning in older children and adolescents compared with adults as being due to their less fossilized brain plasticity and lesser interference from developed L1 phonetic units. Lesser learning in the 6&#x02013;8 year-olds, which was unpredicted in a plasticity account, was explained as being a result of difficulties with the tasks due to an immaturity of phonemic awareness.</p><p>One difference between the paradigms used by <xref rid="ref-22" ref-type="bibr">Heeren &#x00026; Schouten (2008</xref>, <xref rid="ref-23" ref-type="bibr">2010</xref>) and <xref rid="ref-46" ref-type="bibr">Shinohara &#x00026; Iverson (2013</xref>, <xref rid="ref-47" ref-type="bibr">2015</xref>) is the length of training: Heeren &#x00026; Schouten used three training sessions whilst Shinohara &#x00026; Iverson used 10. If children&#x02019;s early learning is slower than that of adults (<xref rid="ref-50" ref-type="bibr">Snow &#x00026; Hoefnagel-H&#x000f6;hle, 1978</xref>), this could potentially account for why Shinohara &#x00026; Iverson saw a plasticity benefit (at least for older children compared to adults), whilst Heeren &#x00026; Schouten did not. Some evidence for this comes from a final study by <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>, who also found a plasticity benefit (greater learning in 7&#x02013;8 year-olds than in adults), but also found evidence that this maturational difference only emerged after several sessions of exposure. This study used high-variability phonetic training to train the tense-lax English vowel contrast /i/ versus /&#x0026a;/ (e.g., <italic>bean-bin</italic>) with child (7&#x02013;8 years) and adult (20&#x02013;30 years) native Greek learners of L2 English. The study explored both age effects and cue weightings, through the use of natural and modified duration stimuli (whereby duration cues were equalized and not relevant, or were reliable cues). A pre-test, training, post-test paradigm was used, with training consisting of 10 sessions using an identification task (identifying the correct member of a minimal pair given written stimuli) with high-variability stimuli (45 minimal pairs produced by two male and two female speakers). Half of the participants in each age group were trained with modified stimuli (no duration cues) and half with natural stimuli. Participants were given the option to replay any given stimulus and feedback was provided in the form of a video game style animation. Although Greek adults, who started with more years of L2 education, generally performed better than Greek children at pre-test, high-variability perceptual training improved performance for both groups (child and adult) across all tasks (perceptual identification and discrimination for both natural and modified stimuli conditions). However, critically, children improved more than adults. Importantly, the results from <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>&#x02019;s training task, which were recorded each day, suggested that children&#x02019;s identification performance only overtook that of adults by Session 7 (see <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2013a</xref>, Figs. 11&#x02013;14). This suggests that plasticity benefits, which are seen in this study and in that of Shinohara &#x00026; Iverson, but not in <xref rid="ref-22" ref-type="bibr">Heeren &#x00026; Schouten (2008</xref>, <xref rid="ref-23" ref-type="bibr">2010</xref>) studies could rely on more lengthy exposure. However, this cannot account for why Giannakopoulou, Uther &#x00026; Ylinen saw this benefit for 7&#x02013;8 year-olds compared with adults while this was <italic>not</italic> seen for 6&#x02013;8 year-olds compared with adults in the Shinohara &#x00026; Iverson study (only for older children compared with adults). If Shinohara &#x00026; Iverson are right that their youngest children had greater difficulty with the learning task due to less well developed phonemic awareness, one possibility is that the /i/ versus /&#x0026a;/ contrast is somehow more salient for Greek speakers than the /l/ versus /r/ contrast is for Japanese speakers, even for younger children. This may be partially due to the length cue present in these stimuli: the difference between children and adults was more marked for the natural stimuli compared with the modified stimuli, suggesting that the children may have been particularly relying on durational cues during training. This is in line with research showing that nonnative listeners from many different language backgrounds tend to rely heavily on the duration cue when discriminating English tense-lax vowel pairs (unlike native listeners who rely more on formant frequency, e.g., <xref rid="ref-18" ref-type="bibr">Flege, Bohn &#x00026; Jang, 1997</xref>). The reliance on durational cues may also have been exacerbated by the use of written stimuli during training since English spelling provides an additional analogue length cue (two letters such as <italic>ee</italic> and <italic>ea</italic> are often used to represent the longer vowel /i/ while a single letter such as <italic>i</italic> is more often used to represent the shorter vowel /&#x0026a;/), which may aid learning (see also <xref rid="ref-21" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2013b</xref>, for evidence on the role of orthography in learning this contrast). We return to this point in the General Discussion.</p><p>In sum, the results of a handful of phonetic training studies give mixed results with respect to whether younger learners show stronger learning given matched input (i.e., plasticity effects). It has been suggested that that the presence (or lack) of pre-existing comparable categories in the L1, the length of exposure, and the salience of the contrast could all influence children&#x02019;s learning and contribute to differences across experiments. In the current study, we build on the paradigm established in <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>&#x02014;where plasticity benefits were clearly seen&#x02014;comparing Greek 7&#x02013;8 year-olds and adults trained on the English /i/ versus /&#x0026a;/ contrast (though we modify the paradigm to remove orthographic cues to learning). We use this paradigm to explore the effect of variability in training with different age groups.</p></sec><sec><title>Comparison of high and low-variability training</title><p>As discussed above, work by <xref rid="ref-30" ref-type="bibr">Lively, Logan &#x00026; Pisoni (1993)</xref> suggested a benefit for high-variability input over low-variability input in phonetic training for adult learners. The finding that encountering varied training instances boosts generalization is intuitively sensible: experience of variation allows the formation of generalized representations that include only phonetically relevant cues and exclude irrelevant talker identity cues. Since the seminal experiments of <xref rid="ref-30" ref-type="bibr">Lively, Logan &#x00026; Pisoni (1993)</xref>, many phonetic training studies have continued to use high-variability input, however, surprisingly few have actually tested the benefit of high-variability directly. One study which did find a high-variability benefit was conducted by <xref rid="ref-15" ref-type="bibr">Clopper &#x00026; Pisoni (2004)</xref>, although this focused on dialect categorization rather than L2 phonetic learning. They tested participants&#x02019; ability to categorize dialects following exposure to high-variability training (three talkers per dialect) compared with low-variability training (one talker per dialect), finding better generalization after high-variability training.</p><p>However, two studies looking at lexical tone learning also compared variable (multispeaker) training with less variable training, but did <italic>not</italic> find an overall benefit of high-variability input (<xref rid="ref-38" ref-type="bibr">Peracchione et al., 2007</xref>; <xref rid="ref-44" ref-type="bibr">Sadakata &#x00026; McQueen, 2014</xref>). Instead, these studies found an interaction with aptitude (i.e., baseline perceptual ability for detecting pitch) whereby only high aptitude participants benefitted from high-variability input whilst those of low aptitude did better with low-variability training. However, since these studies did not use segmental phonetic contrasts it is currently unclear the extent to which they would generalize to phonetic training. Finally, one recent training study did specifically compare high- and low-variability in L2 phonetic learning at the segmental level: <xref rid="ref-43" ref-type="bibr">Sadakata &#x00026; McQueen (2013)</xref>, tested native Dutch speakers&#x02019; ability to identify geminate and singleton variants of the Japanese fricative /s/, comparing low and high-variability training (here manipulated in terms of item variability). They found that more variable input did lead to greater improvements with generalization but no interaction with aptitude.</p><p>To the best of our knowledge the studies reviewed above are the only ones to directly compare low- and high-variability training for phonetic contrasts. Moving beyond the phonetic learning literature, a separate literature on L2 word learning has also explored the benefits of input variability (<xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers, 2005</xref>, <xref rid="ref-8" ref-type="bibr">2014</xref>; <xref rid="ref-51" ref-type="bibr">Sommers &#x00026; Barcroft, 2007</xref>, <xref rid="ref-52" ref-type="bibr">2011</xref>). A general finding from this literature is that vocabulary learning, as tested both in production and reception tests, is stronger when exposure is more varied, with benefits both of multiple talkers and multiple voice quality types. Further experiments rule out explanations in terms of a benefit of greater cognitive effort (<xref rid="ref-52" ref-type="bibr">Sommers &#x00026; Barcroft, 2011</xref>). <xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers (2005</xref>, <xref rid="ref-8" ref-type="bibr">2014</xref>) explain this general benefit of acoustic variability in terms of an exemplar-based framework whereby indexical information from all encountered examples is retained in the early stages. This means that when words are encountered from multiple talkers/voice types, learners incorporate a wider variety of cues into their representations, allowing them to form more &#x0201c;associative hooks&#x0201d; and robust representations for the target words. Note that this explanation is subtly different from the standard explanation as to why high-variability input benefits phonetic learning, which is assumed to stem from learning to ignore phonemically irrelevant information and thus is specifically important for generalization (whereas the benefit for word-learning tasks should hold for both trained and novel talkers at test).</p><p>Turning to children, no study has specifically explored whether high-variability input is more effective than low-variability input for L2 phonetic training in children. However, there is some research into word learning in L1 which suggests a role for high-variability in infants. This research has been conducted with infants in the early stages of word learning (around 14 months). A surprising finding with this age group is that even if they have mastered a particular L1 phoneme contrast (i.e., they discriminate between relevant phoneme contrasts and fail to discriminate nonnative contrasts) they may have difficulties learning new words that differ by this contrast. For example, <xref rid="ref-53" ref-type="bibr">Stager &#x00026; Werker (1997)</xref> found that when 14-month-olds were exposed to two novel words which formed a minimal pair (/b&#x0026a;/ and /d&#x0026a;/) paired with two novel objects, they did not later differentiate between trials in which the word-object pairing was identical versus opposite to that previously seen in habituation (the so-called &#x0201c;switch task&#x0201d;). This is despite the fact that children of this age were shown to be able to discriminate /b/ and/d/ outside of the context of a word-learning task. This effect has been demonstrated many times (see <xref rid="ref-58" ref-type="bibr">Werker &#x00026; Curtin, 2005</xref>, for a review), critically, however, <xref rid="ref-41" ref-type="bibr">Rost &#x00026; McMurray (2009)</xref> demonstrated that it is affected by the variability of the exposure set. Using a similar switch task to <xref rid="ref-53" ref-type="bibr">Stager &#x00026; Werker (1997)</xref>, they replicated the null effect when the novel words (/buk/ and /puk/ in their study) were produced by a single talker, but showed that infants of the same age <italic>did</italic> differentiate between the minimal-pair novel words when exposed to the novel words spoken by multiple talkers. <xref rid="ref-42" ref-type="bibr">Rost &#x00026; McMurray (2010)</xref> further probed what aspect of the variability in the input was beneficial for word learning. They considered the possibility that, although infants could discriminate the phonetic contrast in question (/b/-/p/) their phonetic categories might still be developing. In this case, the critical aspect of variability might be the presence of a bimodal distribution of the most relevant cue for differentiating the contrast (see also <xref rid="ref-35" ref-type="bibr">Maye, Werker &#x00026; Gerken, 2002</xref>&#x02014;in this case voice onset time (VOT)). <xref rid="ref-42" ref-type="bibr">Rost &#x00026; McMurray (2010)</xref> tested this by varying VOT in a clear bimodal distribution while holding talker constant. Surprisingly, infants were <italic>not</italic> able to differentiate the minimal pair after exposure to these stimuli, nor were they able to do so when exposed to the items spoken by a single talker but with variation in multiple acoustic cues to the contrast (VOT, F0 transition, and burst amplitude). In contrast, infants <italic>were</italic> able to discriminate between the minimal pairs when exposed to the items spoken by multiple talkers but with a fixed VOT across talkers. This unexpected finding suggests that what is critical is variability arising from talker differences but on <italic>irrelevant</italic> dimensions to the contrast in question. <xref rid="ref-3" ref-type="bibr">Apfelbaum &#x00026; McMurray (2011)</xref> provide an account of this in terms of associative learning. Via computational simulation, they show that the experimental results are predicted if word learning involves associating all available acoustic cues with objects, including both relevant (e.g., place of articulation/voicing) and irrelevant (e.g., talker) cues. The intuition behind the model is that associative learning will pick up on any <italic>consistent</italic> relationships across instances, meaning that both relevant and irrelevant acoustic cues will become associated with an object if they are highly consistent, as is the case when tokens all come from the same talker and thus are highly similar. The association of these irrelevant talker cues reduces the contrast established by the phonetic cues since they are shared across the words and provide evidence that they are the same. Note that a similarity between this explanation and that of <xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers (2005</xref>, <xref rid="ref-8" ref-type="bibr">2014</xref>) is that they both assume that irrelevant cues are initially incorporated into lexical representations. There is some independent evidence of this in L1 learning (<xref rid="ref-48" ref-type="bibr">Singh, Morgan &#x00026; White, 2004</xref>; <xref rid="ref-49" ref-type="bibr">Singh, White &#x00026; Morgan, 2008</xref>).</p><p>In sum, there is a long-standing assumption that more variable input is more beneficial in L2 phonetic training, although very few published studies have actually directly tested this in adults, and none have done so in children. There is also evidence that variable input is beneficial in adult L2 and infant L1 vocabulary learning, which has been interpreted in terms of the formation of robust, speaker independent representations.</p></sec><sec><title>Current study</title><p>The current experiment adds to the small literature exploring phonetic training in both adults and children. We build on the work of <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> and focus on learning of the nonnative English /i/-/&#x0026a;/ contrast by adult and 7&#x02013;8 year-old native Greek speakers. Our central research question was whether variability would benefit learning. Although variability can be manipulated along a number of dimensions, we chose to manipulate talker variability since this type of variability has been explored across both the phonetic and word learning literatures. To this end we compared learning from high-variability (four talkers) versus low-variability (one talker) input, with overall exposure matched across conditions. We embedded the phonetic training task in a word-learning task, whereby training involved pairing minimal pairs with picture representations of the two words (e.g., hear <italic>sheep</italic>, choose between pictures of a <italic>sheep</italic> and a <italic>ship</italic>), conducted in a child friendly computerized training environment. This choice allowed us to investigate the effect of variability on learning at both the phonetic and lexical levels. In addition, using pictures allowed us to avoid using orthography in training, addressing the concern that learners in <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> may have relied on length cues in English spelling (e.g., <italic>sh<underline>ee</underline>p versus sh<underline>i</underline>p</italic>) as an aid to learning. We matched other aspects of the training to that in <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>, to allow reasonably direct comparison between the studies. For example the number and duration of the training sessions were approximately the same, training used an animation to provide feedback and a &#x0201c;replay&#x0201d; button allowed participants to repeat stimuli if necessary.</p><p>However, our test of phonetic learning was a three-interval oddity discrimination task, rather than an identification task, in order to avoid using orthography but still be able to test both trained and untrained items. The inclusion of untrained items was important since high-variability is specifically predicted to benefit generalization&#x02014;i.e., exposure to multiple talkers should aid the ability to ignore phonetically irrelevant information. Voice novelty and word novelty were manipulated separately (since it is possible that exposure to multiple speakers might specifically benefit generalization across talkers, rather than generalization more broadly).</p><p>Our primary measure was the extent to which training strengthened lexical representations, since we assumed that our participants would begin the study with some knowledge of the words. We chose to focus on the links between the forms and their meanings and used a primed auditory lexical decision task to tap semantic representations in the L2 via cross-language priming (i.e., semantic priming from L2 to L1). This was adapted from a task previously used to test vocabulary development in an artificial language learning experiment (<xref rid="ref-55" ref-type="bibr">Tamminen &#x00026; Gaskell, 2012</xref>). Comparison of pre- and post-training performance tested whether this aspect of participants&#x02019; representations was changed by the training process, and whether the extent of change was modulated by input variability. We also included a more direct measure of vocabulary learning at both pre- and post-test. Participants heard Greek L1 words and matched these to the correct translation from one of four English L2 words, all taken from the training set (no minimal pairs included). This task served multiple purposes. First, it allowed us to determine which words a participant was familiar with prior to the study. Second, it allowed us to measure vocabulary learning between pre-and post-test, and finally, it ensured that all participants began the training task with some knowledge of the word meanings.</p><p>Our main prediction was that, for both measures of phonetic learning and word learning, there should be greater improvements from pre- to post-test for the high-variability condition compared to the low-variability condition. This was based both on the theoretical benefits of boosting generalization discussed above, and on the existing empirical literature (although as has been seen, there are some substantial gaps in this literature, particularly for phonetic learning and particularly in children).</p><p>A second prediction following <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> was that in the phonetic learning tasks (i.e., in the training and three-interval oddity discrimination tasks), children would show stronger learning effects than adults.</p></sec></sec><sec sec-type="materials|methods"><title>Materials and Methods</title><sec><title>Ethics statement</title><p>This project received ethical consent by the ethical committee of the University of Warwick (Ethical Application Ref: 80/12-13), abiding to the ethical standards of the Declaration of Helsinki. For children, written informed consent was obtained from their parents prior to the first session. Adults provided written consent at the beginning of the first session. Participants received a certificate and small gift at the end of the experiment.</p></sec><sec><title>Participants</title><p>Child (<italic>M</italic> = 8.4; SD = 0.6; range = 7;8 &#x02013; 9;8 years) and adult (<italic>M</italic> = 24.3; SD = 4.3; range = 18;3 &#x02013; 32;3 years) native Greek-speaking learners of English were recruited from primary schools and higher education colleges in Athens. Participants were tested in school/college by researchers or class teachers who were provided with instructions for running the experiment. The final sample consisted of 52 children and 41 adults. Participants were randomly assigned to each of two counterbalanced versions of the two experimental conditions (high-variability version1/version2 versus low-variability version1/version2). Although we had planned for participants to be spread equally across conditions and versions, our final sample was uneven. Additional participants were tested but we were unable to use their datasets due to their dropping out of the experiment, recording errors, and other errors in testing due to difficulties of testing on multiple computers in a busy school environment, and that some of our testing was done by school staff. We retained participant&#x02019;s datasets where there was data for the discrimination and lexical decision tasks (pre- and post-test), and where at least 60% of their training data had been recorded. Note that statistical analyses which allow for an uneven balance across conditions and versions were used. Details of participants in each condition are given in <xref ref-type="table" rid="table-1">Table 1</xref>.</p><table-wrap id="table-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/table-1</object-id><label>Table 1</label><caption><title>Participant details.</title></caption><alternatives><graphic xlink:href="peerj-05-3209-g006"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"><italic>N</italic></th><th rowspan="1" colspan="1">Gender</th><th rowspan="1" colspan="1">Mean age</th><th rowspan="1" colspan="1">SD age</th></tr></thead><tbody><tr><td rowspan="4" colspan="1">Adults</td><td rowspan="1" colspan="1">High-variability</td><td rowspan="1" colspan="1">(Version 1)</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">2M, 9F</td><td rowspan="1" colspan="1">25:1</td><td rowspan="1" colspan="1">5:0</td></tr><tr><td rowspan="1" colspan="1">High-variability</td><td rowspan="1" colspan="1">(Version 2)</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">3M, 8F</td><td rowspan="1" colspan="1">24:4</td><td rowspan="1" colspan="1">3:1</td></tr><tr><td rowspan="1" colspan="1">Low-variability</td><td rowspan="1" colspan="1">(Version 1)</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">1M, 9F</td><td rowspan="1" colspan="1">24:9</td><td rowspan="1" colspan="1">3:9</td></tr><tr><td rowspan="1" colspan="1">Low-variability</td><td rowspan="1" colspan="1">(Version 2)</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">4M, 5F</td><td rowspan="1" colspan="1">22:8</td><td rowspan="1" colspan="1">5:1</td></tr><tr><td rowspan="4" colspan="1">Children</td><td rowspan="1" colspan="1">High-variability</td><td rowspan="1" colspan="1">(Version 1)</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">7M, 7F</td><td rowspan="1" colspan="1">8:7</td><td rowspan="1" colspan="1">0:7</td></tr><tr><td rowspan="1" colspan="1">High-variability</td><td rowspan="1" colspan="1">(Version 2)</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">7M, 7F</td><td rowspan="1" colspan="1">8:10</td><td rowspan="1" colspan="1">0:5</td></tr><tr><td rowspan="1" colspan="1">Low-variability</td><td rowspan="1" colspan="1">(Version 1)</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">6M, 5F</td><td rowspan="1" colspan="1">8:10</td><td rowspan="1" colspan="1">0:6</td></tr><tr><td rowspan="1" colspan="1">Low-variability</td><td rowspan="1" colspan="1">(Version 2)</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">5M, 8F</td><td rowspan="1" colspan="1">8:8</td><td rowspan="1" colspan="1">0:5</td></tr></tbody></table></alternatives></table-wrap><p>Participants lived in Greece and were students of L2 English. All participants had normal or corrected-to-normal vision and nonimpaired hearing, and none reported having a language or learning disorder. Child participants&#x02019; level of proficiency was basic (L2 English education, <italic>M</italic> = 1.96 years, range = 1&#x02013;2 years). Adult participants&#x02019; level of proficiency was advanced (L2 English education, <italic>M</italic> = 10.98 years, range = 9&#x02013;13 years). All participants had spent less than two weeks in an English-speaking environment.</p></sec><sec><title>Stimuli</title><p>The experimental stimuli consisted of 20 real-word minimal pairs (e.g., <italic>ship-sheep</italic>) and 20 nonword minimal pairs (e.g., <italic>stin-steen</italic>) containing the English tense-lax vowel distinction (nonword minimal pairs were created so that they matched the real-word minimal pairs as closely as possible in their final syllables; see <xref ref-type="supplementary-material" rid="supp-1">Table S1</xref> for a list of all stimuli). Participants learned the real-word minimal pairs in the training task, but were tested on both these real-word items from training and nonword minimal pairs not included in training. This allowed us to test both trained and novel items.</p><p>All minimal pairs were recorded by five native English speakers (three female, two male) with Southern British English pronunciation using a micro track 24/96 digital recorder. Words were edited into separate sound files, and peak amplitude was normalized using <xref rid="ref-4" ref-type="bibr">Audacity&#x000ae; (2012)</xref>. All other natural variation between recordings was kept. Clipart pictures of the 40 English words were selected from free online databases.</p><p>In addition to the main experimental stimuli, a second set of stimuli were developed for a primed auditory lexical decision task. In this task, primes could be either English words or Greek words, and targets were either semantically related to the prime, semantically unrelated to the prime or nonwords (see <xref ref-type="table" rid="table-2">Table 2</xref> for example and <xref ref-type="supplementary-material" rid="supp-2">Table S2</xref> for a full list of these stimuli).</p><table-wrap id="table-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/table-2</object-id><label>Table 2</label><caption><title>Examples of the different trial types in the primed auditory lexical decision task.</title></caption><alternatives><graphic xlink:href="peerj-05-3209-g007"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Trial type</th><th rowspan="1" colspan="1">English prime</th><th rowspan="1" colspan="1">Greek prime</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Semantically related target</td><td rowspan="1" colspan="1"><italic>sheep&#x02014;&#x003c0;&#x003c1;&#x003cc;&#x003b2;&#x003b1;&#x003c4;&#x003bf; (sheep)</italic></td><td rowspan="1" colspan="1"><italic>&#x003c3;&#x003ba;&#x003cd;&#x003bb;&#x003bf;&#x003c2; (dog)&#x02014;&#x003b3;&#x003ac;&#x003c4;&#x003b1; (cat)</italic></td></tr><tr><td rowspan="1" colspan="1">Semantically unrelated target</td><td rowspan="1" colspan="1"><italic>sheep&#x02014;&#x003b3;&#x003cc;&#x003bd;&#x003b1;&#x003c4;&#x003bf; (knee)</italic></td><td rowspan="1" colspan="1"><italic>&#x003c3;&#x003ba;&#x003cd;&#x003bb;&#x003bf;&#x003c2; (dog)&#x02014;&#x003b4;&#x003ad;&#x003bc;&#x003b1; (parcel)</italic></td></tr><tr><td rowspan="1" colspan="1">Nonword target</td><td rowspan="1" colspan="1"><italic>sheep&#x02014;&#x003b3;&#x003c1;&#x003b1;&#x003bc;&#x003cc;&#x003bb;&#x003b9;</italic></td><td rowspan="1" colspan="1"><italic>&#x003c3;&#x003ba;&#x003cd;&#x003bb;&#x003bf;&#x003c2; (dog)&#x02014;&#x003b4;&#x003bf;&#x003cd;&#x003bc;&#x003b1;</italic></td></tr></tbody></table></alternatives></table-wrap><p>For the English primes, one word from each real-word minimal pair was selected (12 /i/ items, eight /&#x0026a;/ items). Originally, we had selected 10 /i:/ and 10 /&#x0026a;/ items, but as two of the /&#x0026a;/ items had Greek translations that were phonologically very similar to the English word (gin, dip) these items were replaced with their /i:/ counterpart (gene, deep) since the primed auditory lexical decision task aimed to examine semantic (not phonological) priming. For the Greek primes, 20 words that matched the English primes as closely as possible in frequency were selected. English word frequency was taken from the MRC Psycholinguistic Database (<xref rid="ref-59" ref-type="bibr">Wilson, 1988</xref>). Greek word frequency was obtained from the GreekLex database (<xref rid="ref-27" ref-type="bibr">Ktori, van Heuven &#x00026; Pitchford, 2008</xref>). An independent-samples <italic>t</italic>-test confirmed that the two lists of prime words did not differ significantly in frequency, <italic>t</italic>(38) = &#x02212;1.12, <italic>p</italic> = .27. In addition, the number of nouns, verbs, and adjectives were identical in both lists.</p><p>The semantically related target word for the English primes was the Greek translation. For the Greek primes, the semantically related word was selected by asking 15 native Greek speakers to write down the first word that came to mind for each Greek prime word. For both types of prime word, semantically unrelated words were words which were unrelated in meaning with the target words which were matched as closely as possible in frequency and length to the semantically related words (frequency, <italic>t</italic>(78) = &#x02212;0.13, <italic>p</italic> = 0.90; N phonemes, <italic>t</italic>(78) = 0.13, <italic>p</italic> = 0.89; N syllables, <italic>t</italic>(78) = 0.00, <italic>p</italic> = 1.0). Nonwords targets for both English and Greek prime words were generated by changing one and two syllables of real Greek words, preserving the number of consonants and vowels, and were matched as closely as possible in length to the word targets (N phonemes, <italic>t</italic>(158) = 0.98, <italic>p</italic> = 0.33; N syllables, <italic>t</italic>(158) = 0.99, <italic>p</italic> = 0.33). Primes and targets were never cohorts or rhymes.</p><p>All Greek word and nonword stimuli for the lexical decision task were recorded by a native Greek speaker, and were edited as above.</p></sec><sec><title>Design</title><p>Each participant completed 10 sessions over approximately two weeks (one session per day over a minimum of 12 and maximum of 15 days). The experiment involved three stages: pre-test, training, and post-test. The pre- and post-tests were identical, and contained five tasks (see <xref ref-type="fig" rid="fig-1">Fig. 1</xref>). Session 1 began with the pre-test, followed by a block of training. Sessions 2&#x02013;9 consisted of training only. Session 10 consisted of training, followed by the post-test.</p><fig id="fig-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/fig-1</object-id><label>Figure 1</label><caption><title>Tasks completed in each of the 10 experimental sessions.</title></caption><graphic xlink:href="peerj-05-3209-g001"/></fig><p>There were two experimental conditions that differed only during training&#x02014;high-variability versus low-variability. In the high-variability training, English minimal-pair words were spoken by four different talkers (two female, two male). In the low-variability training, English minimal-pair words were spoken by a single talker (always female). Pre- and post-tests were identical for the two conditions (although old/new talker was counterbalanced across participants in the discrimination task, resulting in four counterbalancing conditions; <xref ref-type="table" rid="table-3">Table 3</xref>).</p><table-wrap id="table-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/table-3</object-id><label>Table 3</label><caption><title>Counterbalancing of the English talkers in each task.</title></caption><alternatives><graphic xlink:href="peerj-05-3209-g008"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Task</th><th rowspan="1" colspan="1">High-variability 1</th><th rowspan="1" colspan="1">High-variability 2</th><th rowspan="1" colspan="1">Low-variability 1</th><th rowspan="1" colspan="1">Low-variability 2</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">English introduction</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td></tr><tr><td rowspan="2" colspan="1">Three-interval oddity discrimination</td><td rowspan="1" colspan="1">Female 1 (old)</td><td rowspan="1" colspan="1">Female 1 (new)</td><td rowspan="1" colspan="1">Female 1 (old)</td><td rowspan="1" colspan="1">Female 1 (new)</td></tr><tr><td rowspan="1" colspan="1">Female 2 (new)</td><td rowspan="1" colspan="1">Female 2 (old)</td><td rowspan="1" colspan="1">Female 2 (new)</td><td rowspan="1" colspan="1">Female 2 (old)</td></tr><tr><td rowspan="1" colspan="1">Primed auditory lexical decision</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td></tr><tr><td rowspan="4" colspan="1">Training</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td><td rowspan="1" colspan="1">Female 1</td><td rowspan="1" colspan="1">Female 2</td></tr><tr><td rowspan="1" colspan="1">Female 3</td><td rowspan="1" colspan="1">Female 3</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Male 1</td><td rowspan="1" colspan="1">Male 1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Male 2</td><td rowspan="1" colspan="1">Male 2</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr></tbody></table></alternatives></table-wrap></sec><sec><title>Procedure</title><p>All tasks were run using Exbuilder (a custom built software package developed at the University of Rochester) on laptop or desktop computers in quiet classrooms. Multiple participants were tested simultaneously on separate computers. Stimuli were presented binaurally over headphones at a comfortable listening level.</p><sec><title>Greek introduction</title><p>In this task, a picture of one of the minimal-pair words was presented centrally on the screen, and participants heard the corresponding Greek word (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). Each minimal-pair word was presented once each in a random order. This task was included to ensure that participants accessed the correct meaning for each picture since not all items were concrete nouns (e.g., <italic>leap, slip,</italic> etc.). No data were recorded from this task.</p><fig id="fig-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/fig-2</object-id><label>Figure 2</label><caption><title>Overview of the five experimental tasks.</title></caption><graphic xlink:href="peerj-05-3209-g002"/></fig></sec><sec><title>English introduction</title><p>In this task, participants saw a picture of one of the minimal-pair words, presented centrally at the top of the screen. Participants could click on this picture to hear the corresponding Greek word if required. Participants subsequently clicked on another button in the middle of the screen to hear four possible English words which were each &#x0201c;spoken&#x0201d; by one of four frogs which appeared at the bottom of the screen (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). If the participant selected the correct English word, they received positive feedback [Greek translation of <italic>correct</italic> (&#x0201c;<italic>&#x003c3;&#x003c9;&#x003c3;&#x003c4;&#x003cc;</italic>&#x0201d;)] and the English word was replayed. If the wrong word was selected participants listened to the four options again and had another go. This continued until the correct word was chosen. The three distracter words for each trial were randomly selected (but identical for all participants) with the following constraints; (a) no minimal pairs were heard together (e.g., if <italic>ship</italic> was the target, <italic>sheep</italic> was not a distracter); (b) no rhyming items were heard together (e.g., if <italic>ship</italic> was the target, <italic>chip</italic> was not a distracter); (c) each word was heard once as a target, and three times as a distracter. Trials were presented in a random order. Accuracy on the first attempt was recorded. Accuracy in Session 1 provided a baseline measure of English vocabulary knowledge, whilst the change in accuracy between Sessions 1 and 10 provided a measure of vocabulary learning.</p></sec><sec><title>Three-interval oddity discrimination test</title><p>In this test, participants heard three words (played with ISIs of 200 ms) spoken by a single talker. Two words were different tokens of the same word (e.g., <italic>sheep, sheep</italic>), and one the other minimal pair item (e.g., <italic>ship</italic>). Each word was &#x0201c;spoken&#x0201d; by one of three frogs which appeared on the screen and participants clicked on a frog to indicate which word was the odd one out (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). A response could not be made until the third sound file had finished playing. Instructions emphasized accuracy and no feedback was provided. All 20 real word and 20 nonword minimal pairs were heard once each. Half of the trials contained an /&#x0026a;/ target (e.g., <italic>sheep, sheep,</italic>
<bold><italic>ship</italic></bold>), and half contained an /i/ target (e.g., <italic>chip, chip,</italic>
<bold><italic>cheap</italic></bold>). To minimize the influence of duration cues (i.e., /i/ is a longer vowel than /&#x0026a;/, so <italic>sheep</italic> is likely to have a longer acoustic duration than <italic>ship</italic>) all sound files were normalized in length by adding silence at the end, up to the length of the longest item. Thus, all trials were matched in length from the onset of the first sound file until the moment when participants could respond.</p><p>Nonword trials tested whether participants could generalize their training to new untrained items. We also tested whether participants could generalize to a new talker. To do this, 10 of the 20 real-word minimal pairs were presented in a familiar voice, and the remaining 10 in a new voice, and likewise for the 20 nonword minimal pairs. The two talkers used as the familiar/new voices were counterbalanced across participants (<xref ref-type="table" rid="table-3">Table 3</xref>).</p></sec><sec><title>Primed auditory lexical decision test</title><p>A primed auditory lexical decision task investigated the status of the semantic representations for English words and determined whether this was altered following training. On each trial participants heard two words (a prime and a target). The prime could be a trained English word or a Greek word. Each prime was repeated four times, once with a semantically related word target, once with a semantically unrelated word target, and twice with a nonword target. If the trained English words have become integrated with Greek lexical knowledge then faster response times should be observed when the English prime is followed by a semantically related, compared to semantically unrelated Greek word. The inclusion of Greek primes enabled comparison of the magnitude of semantic priming effects between English and Greek. Although priming studies do not typically repeat the primes (more commonly repeating the target words with different types of primes), using the English words as primes four times in the current study increased the number of observations and thus the statistical power without the need to train participants on a very large number of English words (see <xref rid="ref-55" ref-type="bibr">Tamminen &#x00026; Gaskell, 2012</xref>, for a similar design using an artificial language). The target word was unique on each trial. Examples of each trial type are provided in <xref ref-type="table" rid="table-2">Table 2</xref> and a screenshot of the task is provided in <xref ref-type="fig" rid="fig-2">Fig. 2</xref>.</p><p>The task began with eight practice trials with feedback, followed by 160 experimental trials without feedback. Participants were instructed to make a word/nonword judgment for the second word as quickly as possible. Responses were made using the left (nonword) and right (word) arrows on the computer keyboard. Response times were measured from the onset of the second word.</p></sec><sec><title>Training</title><p>On each trial participants heard an English word and selected one of two pictures (from the same minimal pair) displayed on the computer screen (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). Following <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>, participants could replay the English word an unlimited amount of times before making a decision. If the correct picture was selected, the incorrect picture disappeared, the English word was replayed, and a short video of a &#x0201c;happy&#x0201d; bunny jumping up and down was played. A picture of a coin also appeared in a box on the left-hand side of the screen, with the aim of motivating participants to try to earn more coins during each subsequent training session. If the incorrect picture was identified both pictures were removed from the screen and a short video of a &#x0201c;sad&#x0201d; bunny was played. The two pictures then reappeared and the English word was played again. Once the participant clicked on the correct picture feedback was provided as in correct trials but no coin was awarded. A training block consisted of the 40 English minimal-pair words each heard eight times, resulting in 320 trials, presented in a random order. In the low-variability condition, all items were spoken by the same talker. In the high-variability condition participants heard each word spoken twice by each of the four talkers (two female, two male). We aimed that participants would undertake one training block (320 trials) in each of their 10 sessions, however, due to time constraints associated with testing in schools, some children were only able to complete 180 training trials in Sessions 1 and 10. In these cases, children completed the remaining 180 trials (to make a full training block of 320 trials) in Sessions 2 and 9, respectively. Data were coded such that the first 320 trials and last 320 trials completed were coded as Sessions 1 and 10 training blocks, respectively.</p></sec></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Analyses and statistical approach</title><p>Data were primarily analyzed using linear mixed effects models (<xref rid="ref-5" ref-type="bibr">Baayen, Davidson &#x00026; Bates, 2008</xref>; <xref rid="ref-25" ref-type="bibr">Jaeger, 2008</xref>; <xref rid="ref-40" ref-type="bibr">Quen&#x000e9; &#x00026; van den Bergh, 2008</xref>) using the package <italic>lme4</italic> (<xref rid="ref-10" ref-type="bibr">Bates, Maechler &#x00026; Bolker, 2013</xref>) for the R computing environment (<xref rid="ref-60" ref-type="bibr">R Core Team, 2016</xref>). Since adults and children generally had very different starting points at pre-test, the data from each age group were analyzed separately for each task. However, since we were specifically interested in age differences for phonetic discrimination, we also included additional analyses comparing the age groups for the training and three-interval oddity discrimination tasks.</p><p>Linear mixed effects models allow binary data to be analyzed with logistic models rather than as proportions, as recommended by <xref rid="ref-25" ref-type="bibr">Jaeger (2008)</xref>. Our approach was to automatically include all the relevant experimentally manipulated variables for each task, and all the interactions between those variables, as fixed factors in a model, regardless of whether they contributed significantly to the model (i.e., we did not use stepwise model comparison). Since preliminary analysis suggested that the extent to which children had used the &#x0201c;replay&#x0201d; button during training was positively correlated with their increase in performance from pre- to post-test in the three-interval oddity discrimination task (<italic>r</italic> = 0.38, <italic>df</italic> = 0.91, <italic>p</italic> &#x0003c; 0.01), we also included each participant&#x02019;s <italic>mean-replay-usage</italic> as a fixed factor in the models for that task (note that although the correlation did not hold for adults (<italic>r</italic> = 0.17, <italic>df</italic> = 0.39, <italic>p</italic> = 0.27), the factor was nevertheless included in both models for consistency). In addition, preliminary analyses revealed that one of the two talkers used in the test stimuli (i.e., as the trained/untrained voice; see <xref ref-type="table" rid="table-3">Table 3</xref>) was more intelligible than the other, affecting discrimination. In order to ensure that key effects were not carried by a specific <italic>talker,</italic> we included both <italic>talker</italic> and all the interactions with <italic>talker</italic> as a fixed factor.<xref ref-type="fn" rid="fn-1"><sup>1</sup></xref><fn id="fn-1"><label>1</label><p>There was just one model reported in the text where it was not possible to include the interactions with the control variable due to nonconvergence: the model predicting children&#x02019;s training data using <italic>training-session</italic> as a continuous predictor. However, equivalent interactions were included in the follow up model which is also reported, where the training-session variable was replaced by the binary predictor <italic>test-half.</italic></p></fn> Finally, in all models, predicting variables (including discrete factor codings) were centered to reduce the effects of collinearity between main effects and interactions, and in order that main effects were evaluated as the average effects over all levels of the other predictors (rather than at a specified reference level for each factor). We do not report full statistical models. For the experimental factors, we report statistics for main effects and interactions where there are predictions. For example, we did not inspect the model for a main effect of <italic>voice-novelty</italic> (trained versus untrained talker), since this effect is not interpretable for both levels of <italic>test-session</italic> (i.e., novelty is only relevant after training). We also inspected each model to see if there was a main effect of the control variable <italic>talker,</italic> and in addition, wherever we found a reliable main effect or interaction for the experimental factors we looked to see if it was qualified by a higher-level interaction with <italic>talker.</italic> For clarity of exposition, the results with the control variable are <italic>not</italic> reported in the main text (see <xref ref-type="supplementary-material" rid="supp-3">Table S3</xref>), with the exception of places where we found a reliable interaction between an effect of interest and the control variable <italic>talker,</italic> and this broke down to suggest that there was an effect only for one of the talkers.</p><p>The lme4 package provided <italic>p</italic>-values automatically for logistic mixed effects models but not for linear mixed effect models. For models with a continuous outcome variable (i.e., RTs in the lexical decision task) <italic>p</italic>-values were calculated using the lmerTest package using Kenward&#x02013;Roger approximation for denominator degrees of freedom. We included <italic>participant</italic> as a random effect and used a full random slope structure (i.e., by-subject slopes for all within-subject factors (although not the control variables) and their interactions, as recommended by <xref rid="ref-9" ref-type="bibr">Barr et al. (2013)</xref>). In some cases, the full model did not converge and here we removed the correlations between slopes (<xref rid="ref-9" ref-type="bibr">Barr et al., 2013</xref>). All of the models reported converged with bound optimization by quadratic approximation (BOBYQA optimization; <xref rid="ref-39" ref-type="bibr">Powell, 2009</xref>). The analyses scripts and output can be viewed here: <uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>. Data files and scripts are also available on the Open Science Framework: <uri xlink:href="https://osf.io/8anzk/">https://osf.io/8anzk/</uri>.</p></sec><sec><title>Training</title><p>Participants&#x02019; accuracy in selecting the correct picture from its minimal pair on the first attempt was recorded, though with some data loss (adults = 2%; children = 6%). Recall that high-variability training comprised four talkers; for half of the participants in this condition, these were talkers Female 1, Female 3, Male 1, and Male 2, for the other participants these were talkers Female 2, Female 3, Male 1, and Male 2. In the low-variability training, half of the participants were trained with Female 1 only and half with Female 2 only (where Female 1/Female 2 were not used in training, they were used as the novel voice in testing&#x02014;see <xref ref-type="table" rid="table-3">Table 3</xref>). This design meant that high-variability included three talkers that were never included in the low-variability training. It is possible that stimuli produced by these talkers could be easier or harder to identify than stimuli produced by the two talkers used in both training conditions. To ensure a fair comparison across conditions, we only consider trials in the <italic>high-variability</italic> condition where the stimuli were produced by one of the two talkers who were also used in the <italic>low-variability</italic> condition (i.e., trials with Female 3, Male 1, and Male 2 were excluded; see <xref ref-type="table" rid="table-3">Table 3</xref>). The proportion of correct responses in each session is shown in <xref ref-type="fig" rid="fig-3">Fig. 3</xref>. For our primary analyses, the data were analyzed in two logistic mixed effects models predicting whether a correct response was given (1/0) on each trial. Experimental factors in the model were <italic>training-session</italic> (1&#x02192;10) and <italic>condition</italic> (high-variability, low-variability), and the interaction between them. We were also interested in the contrast between age-groups, however, as can be seen in <xref ref-type="fig" rid="fig-3">Fig. 3</xref>, by the final session, adult participants were at ceiling in the low-variability condition. We, therefore, restricted our analyses comparing age-groups to data from the adults and children in the high-variability condition only. Here, we used a logistic mixed effects model predicting response accuracy with fixed effects of <italic>training-session, age-group</italic> and <italic>talker,</italic> and all of the interactions between them, although we only report the effect of age and interactions with age.</p><fig id="fig-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/fig-3</object-id><label>Figure 3</label><caption><title>(A) Adult and (B) child performance during training (error bars show standard error).</title><p>For the high-variability condition, trials with the three additional talkers are excluded (note: for all of the plots within this paper, means are corrected to control for imbalance in counterbalancing of talkers).</p></caption><graphic xlink:href="peerj-05-3209-g003"/></fig><sec><title>Adults</title><p>There were main effects of <italic>training-session</italic> (<italic>&#x003b2;</italic> = 0.35, SE = 0.03, <italic>z</italic> = 11.21, <italic>p</italic> &#x0003c; 0.001) and <italic>condition</italic> (<italic>&#x003b2;</italic> = 1.63, SE = 0.25, <italic>z</italic> = 6.41, <italic>p</italic> &#x0003c; 0.001) and a reliable interaction between <italic>condition</italic> and <italic>training-session</italic> (<italic>&#x003b2;</italic> = 0.21, SE = 0.05, <italic>z</italic> = 3.86, <italic>p</italic> &#x0003c; 0.001). This reflects improvement across sessions and an overall better performance in the low-variability condition which increases with training.</p></sec><sec><title>Children</title><p>There was a reliable main effect of <italic>training-session</italic> (<italic>&#x003b2;</italic> = 0.22, SE = 0.03, <italic>z</italic> = 7.06, <italic>p</italic> &#x0003c; 0.001), reflecting improved performance across sessions, but no reliable main effect of <italic>condition</italic> (<italic>&#x003b2;</italic> = 0.37, SE = 0.24, <italic>z</italic> = 1.56, <italic>p</italic> = 0.12). There was also a near reliable interaction between <italic>training-session</italic> and <italic>condition</italic> (<italic>&#x003b2;</italic> = 0.10, SE = 0.05, <italic>z</italic> = 1.92, <italic>p</italic> = 0.054). Inspecting the graphs, this seems to reflect the fact that the difference between conditions emerges only in the second half of training. As a follow up, we explored whether the effect of variability changed from the first half of the experiment (Sessions 1 to 5) to the second half of the experiment (Sessions 6 to 10) in an identical statistical model where <italic>training-session</italic> was replaced by the binary factor <italic>test-half</italic> (Sessions 1 to 5 versus 6 to 10). In this model, there was a reliable effect of <italic>test-half</italic> (<italic>&#x003b2;</italic> = 1.05, SE = 0.14, <italic>z</italic> = 7.51, <italic>p</italic> &#x0003c; 0.001), which broke down to show no reliable effect of variability in the first five sessions (<italic>&#x003b2;</italic> = 0.08, SE = 0.24, <italic>z</italic> = 0.32, <italic>p</italic> = 0.75) but a reliable effect of variability (benefitting low-variability) in last five sessions (<italic>&#x003b2;</italic> = 0.56, SE = 0.23, <italic>z</italic> = 2.44, <italic>p</italic> = 0.015).</p><p>Although, we were not able to include the interactions with talker in the original model (with <italic>training-session</italic> as a continuous variable), in the follow up model (with <italic>test-half</italic> replacing <italic>training-session</italic>) the interaction between <italic>test-half</italic> and <italic>condition</italic> was qualified by a reliable effect of talker (<italic>talker</italic> by <italic>test-half</italic> by <italic>condition</italic>: <italic>&#x003b2;</italic> = 0.73, SE = 0.34, <italic>z</italic> = 2.16, <italic>p</italic> = 0.031). Breaking this down, there was a reliable effect of variability only for <italic>female 2</italic> (the more intelligible talker) in the second half of training (<bold>Female 1, first half:</bold>
<italic>&#x003b2;</italic> = &#x02212;0.05, SE = 0.31, <italic>z</italic> = &#x02212;0.16, <italic>p</italic> = 0.88; <bold>Female 1, second half:</bold>
<italic>&#x003b2;</italic> = 0.09, SE = 0.33, <italic>z</italic> = 0.27, <italic>p</italic> = 0.79; <bold>Female 2, first half</bold>: <italic>&#x003b2;</italic> = 0.22, SE = 0.29, <italic>z</italic> = 0.756, <italic>p</italic> = 0.45; <bold>Female 2, second half:</bold>
<italic>&#x003b2;</italic> = 1.09, SE = 0.29, <italic>z</italic> = 3.83, <italic>p</italic> &#x0003c; 0.001).</p></sec><sec><title>Age group comparisons</title><p>Adults in the low-variability condition hit ceiling by the final training sessions, making statistical comparisons with children inappropriate. Restricting analysis to the high-variability conditions (and returning to a model with <italic>training-session</italic> as a continuous variable): there was a main effect of <italic>age-group</italic> (<italic>&#x003b2;</italic> = &#x02212;1.01, SE = 0.22, <italic>z</italic> = &#x02212;4.64, <italic>p</italic> &#x0003c; 0.001) reflecting the overall higher performance of adults, however, critically, there was no reliable interaction between <italic>age-group</italic> and <italic>training-session</italic> (<italic>&#x003b2;</italic> = &#x02212;0.05, SE = 0.05, <italic>z</italic> = &#x02212;1.02, <italic>p</italic> = 0.31). Thus, there was no reliable evidence of faster learning in children than in adults.</p></sec><sec><title>Summary of training data</title><p>All participants improved overall in the training task over time. For adults, there was a benefit of <italic>low-variability</italic>; observable throughout training and an interaction with session suggesting that this benefit increased throughout training. For children, there was no overall benefit of low-variability; however, there was marginal evidence of greater improvement in the <italic>low-</italic> rather than <italic>high-variability</italic> training. This seems to emerge in the second half of training and to be only true for the more intelligible speaker. In contrast to <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>, there was no evidence of a &#x0201c;plasticity&#x0201d; benefit whereby children showed larger benefits of training. Instead, in the low-variability condition, adults (but not children) were at ceiling by the end of training, and in the high-variability condition there was no reliable difference in the improvement shown by adults and children.</p></sec></sec><sec><title>English Introduction</title><p>The English introduction task was included primarily to check whether participants knew the meanings of any of the English words prior to the experiment. However, we were also able to use this test to explore whether knowledge of word meanings improved following training. Accuracy in selecting the correct word (from a choice of three foils) on the first attempt was coded as 1/0. <xref ref-type="table" rid="table-4">Table 4</xref> shows the percentage of correct trials for adults and children in each condition pre- and post-training. Both groups appear to improve with training, although adults outperform children and are close to ceiling (above 80% correct, even at pre-test, with many participants having perfect scores). Given ceiling effects, in the adult data, we restricted our statistical analyses to the data collected from children. A logistic mixed effects model was run over the child data predicting their accuracy (1/0) with fixed factors of <italic>test-session</italic> (pre-test, post-test), <italic>condition</italic> and <italic>test-session</italic> by <italic>condition</italic>, as well as the control factor of <italic>talker</italic> and all of the interactions. This revealed a reliable main effect of <italic>test-session</italic> (<italic>&#x003b2;</italic> = 3.19, SE = 0.26, <italic>z</italic> = &#x02212;12.23, <italic>p</italic> &#x0003c; 0.001) and a marginal interaction between <italic>test-session</italic> and <italic>condition</italic> indicating perhaps more learning in the low-variability condition (<italic>&#x003b2;</italic> = &#x02212;0.95, SE = 0.51, <italic>z</italic> = &#x02212;1.87, <italic>p</italic> = 0.061).</p><table-wrap id="table-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/table-4</object-id><label>Table 4</label><caption><title>Performance in the English introduction task: adult and children&#x02019;s knowledge of word meanings at pre- and post-test (standard error in parentheses).</title></caption><alternatives><graphic xlink:href="peerj-05-3209-g009"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Pre-test</th><th rowspan="1" colspan="1">Post-test</th></tr></thead><tbody><tr><td rowspan="2" colspan="1">Adults</td><td rowspan="1" colspan="1">High-variability condition</td><td rowspan="1" colspan="1">81% (2%)</td><td rowspan="1" colspan="1">98% (2%)</td></tr><tr><td rowspan="1" colspan="1">Low-variability condition</td><td rowspan="1" colspan="1">82% (2%)</td><td rowspan="1" colspan="1">100% (2%)</td></tr><tr><td rowspan="2" colspan="1">Children</td><td rowspan="1" colspan="1">High-variability condition</td><td rowspan="1" colspan="1">50% (3%)</td><td rowspan="1" colspan="1">88% (3%)</td></tr><tr><td rowspan="1" colspan="1">Low-variability condition</td><td rowspan="1" colspan="1">47% (2%)</td><td rowspan="1" colspan="1">92% (2%)</td></tr></tbody></table></alternatives></table-wrap><p>In summary, both adults and children showed a pattern of improved knowledge of the word meanings from pre- to post-test with no differences between the high-variability and low-variability conditions, although it was only possible to statistically verify these patterns for children due to ceiling effects in adults.</p></sec><sec><title>Primed auditory lexical decision</title><p>Trials with nonword targets were excluded. We conducted separate analyses for trials with Greek and English primes (targets were always Greek words). The Greek-primes analyses allowed us to determine whether standard semantic priming occurs within the native language, and thus served as a check on our experimental set up. (Note that, in addition to the means supplied within the text and in <xref ref-type="fig" rid="fig-4">Fig. 4</xref>, a full break down of means by condition can be seen in the R script at <uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>).</p><fig id="fig-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/fig-4</object-id><label>Figure 4</label><caption><title>(A) Adult and (B) child performance in the primed auditory lexical decision task collapsing across condition.</title><p>Mean RTs for Greek target words with related and un-related English primes pre- and post-test. Error bars show standard error (note: for all of the plots within this paper, means are corrected to control for imbalance in counterbalancing of talkers).</p></caption><graphic xlink:href="peerj-05-3209-g004"/></fig><p>For the Greek-primes analyses, trials on which targets were incorrectly identified as nonwords were removed (adults = 5%; children = 10%), as were trials with RTs &#x0003c;200 ms or &#x0003e;2.5 SD above the mean for each participant in each test-session (i.e., a further 3% of data for adults, 3% for children). The remaining data were analyzed in a linear mixed effects model predicting RT with fixed factors of <italic>prime-target relationship</italic> (related, unrelated), <italic>test-session</italic> (pre-, post-test) and the interaction between them.</p><p>For English-primes analyses, we analyzed both RTs (for children and adults), and accuracy (children only). For the RT analyses, data were filtered as described above (incorrect trials: adult = 6%, children = 16%; additional data removed due to &#x0003c;200 ms or &#x0003e;2.5 SD filter: adults = 4%, children = 4%). The remaining data were analyzed in a linear mixed effects model predicting RT with fixed factors of <italic>prime-target relationship</italic> (related, unrelated), <italic>test-session</italic> (pre-, post-test) and <italic>condition</italic> (high-variability, low-variability), the control variable <italic>talker</italic> and all of the interactions between these factors. For the accuracy analyses, all English-prime trials with real word targets were included and the data were analyzed using a logistic linear mixed effects model predicting accuracy of response (i.e., whether the target was correctly identified as a real word&#x02014;coded as 1/0) with the same predictors as the RT data.</p><sec><title>Adults</title><p>For <italic>Greek primes,</italic> there was a significant main effect of <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = 101.33, SE = 13.52, <italic>t</italic> = 7.40, <italic>p</italic> &#x0003c; 0.001, related = 1,014 ms, unrelated = 1,114 ms), reflecting a standard priming effect for semantically related words within the native language. There was no overall effect of <italic>test-session</italic> (<italic>&#x003b2;</italic> = 37.90, SE = 39.45, <italic>t</italic> = 0.95, <italic>p</italic> = 0.35) and no interaction between <italic>test-session</italic> and <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = 17.71, SE = 26.41, <italic>t</italic> = 0.67, <italic>p</italic> = 0.507).</p><p>For <italic>English primes</italic>, there was a significant main effect of <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = 83.62, SE = 20.13, <italic>t</italic> = 4.04, <italic>p</italic> &#x0003c; 0.001; related = 1,153 ms, unrelated = 1,238 ms), reflecting semantic priming across the two languages. There was no overall effect of <italic>test-session</italic> (<italic>&#x003b2;</italic> = 42.18, SE = 48.64, <italic>t</italic> = 0.82, <italic>p</italic> = 0.41), suggesting no change in RTs in the post-test. Of critical interest is whether there was an interaction between <italic>test-session</italic> and <italic>prime-target relationship</italic>, since this could indicate an effect of training on priming. No such effect was found (<italic>&#x003b2;</italic> = &#x02212;37.26, SE = 41.76, <italic>t</italic> = &#x02212;0.85, <italic>p</italic> = 0.40) and there was no three-way interaction between <italic>test-session, prime-target relationship</italic> and <italic>condition</italic> (<italic>&#x003b2;</italic> = 95.90, SE = 83.81, <italic>t</italic> = 1.10, <italic>p</italic> = 0.28). Thus, there was no evidence that across language semantic priming was affected by the training (see <xref ref-type="fig" rid="fig-4">Fig. 4</xref>).</p></sec><sec><title>Children</title><p>For <italic>Greek primes</italic> there was a significant main effect of <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = 72.34, SE = 29.21, <italic>t</italic> = 2.47, <italic>p</italic> = 0.017, related = 1,487 ms, unrelated = 1,549 ms), reflecting a standard priming effect for related words within the native language. There was a marginal overall effect of <italic>test-session</italic> (<italic>&#x003b2;</italic> = 136.08, SE = 69.21, <italic>t</italic> = 1.95, <italic>p</italic> = 0.057), reflecting a slight reduction in RT length from pre (1,563 ms) to post (1,469 ms) test for children. There was no interaction between <italic>test-session</italic> and <italic>prime-target-relationship</italic> (<italic>&#x003b2;</italic> = &#x02212;25.25, SE = 67.97, <italic>t</italic> = &#x02212;0.37, <italic>p</italic> = 0.71).</p><p>For <italic>English primes</italic> (RT data) there was a marginal main effect of <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = 65.17, SE = 33.39, <italic>t</italic> = 1.95, <italic>p</italic> = 0.058, related = 1,620 ms, unrelated = 1,664 ms), reflecting across language semantic priming. There was an overall effect of <italic>test-session</italic> (<italic>&#x003b2;</italic> = 181.88, SE = 74.46, <italic>t</italic> = 2.34, <italic>p</italic> = 0.023) indicating decreasing RTs from pre (1,704 ms) to post (1,580 ms) test. However, there was no interaction between <italic>test-session</italic> and <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = &#x02212;52.67, SE = 66.60, <italic>t</italic> = &#x02212;0.79, <italic>p</italic> = 0.43) and no three-way interaction between <italic>test-session, prime-target relationship</italic> and <italic>condition</italic> (<italic>&#x003b2;</italic> = &#x02212;7.55, SE = 133.81, <italic>t</italic> = &#x02212;0.06, <italic>p</italic> = 0.96), suggesting that across language priming was not affected by the training (see <xref ref-type="fig" rid="fig-4">Fig. 4</xref>).</p><p>Given the large amount of data excluded from the previous analyses of <italic>English primes</italic> (i.e., 16% of words inaccurately identified as nonwords), we also analyzed the accuracy data for children. Similar results were obtained. There was a significant main effect of <italic>prime-target relationship</italic> (<italic>&#x003b2;</italic> = &#x02212;0.71, SE = 0.13, <italic>z</italic> = &#x02212;5.60, <italic>p</italic> &#x0003c; 0.001, related: 87%, unrelated 81%), reflecting across language semantic priming. However, there was no interaction between <italic>test-session</italic> and <italic>target-relationship</italic> (<italic>&#x003b2;</italic> = 0.26, SE = 0.23, <italic>z</italic> = 1.12, <italic>p</italic> = 0.26), and no three-way interaction between <italic>test-session, semantic priming</italic> and <italic>condition</italic> (<italic>&#x003b2;</italic> = 0.01, SE = 0.40, <italic>z</italic> = 0.03, <italic>p</italic> = 0.98).</p></sec><sec><title>Summary of primed auditory lexical decision data</title><p>Analyses of Greek-prime trials established that both adults and children showed standard semantic priming effects within their native language (i.e., shorter RTs for targets preceded by related compared to unrelated primes), which held steady across the two test-sessions. Analyses of English-prime trials demonstrated that both adults and children showed evidence of across language priming (for adults, reliably shorter RTs, for children marginally shorter RTs and reliably more accurate responses). However, for both age groups, there was no evidence of an increase in the degree of semantic priming following training.</p></sec></sec><sec><title>Three-interval oddity discrimination test</title><p>We first ran separate logistic mixed effects models for each age-group, predicting whether a participant gave a correct response (i.e., picked the correct word as different out of a choice of three, coded as 1/0) on each trial. The fixed factors were <italic>test-session</italic> (pre-test, post-test), <italic>voice-novelty</italic> (trained voice, untrained voice), <italic>word-novelty</italic> (trained word, untrained nonword), <italic>condition</italic> (high-variability, low-variability) and all the interactions between these experimental factors. The factor <italic>talker</italic> and all of the interactions between <italic>talker</italic> and the experimental factors were included as control factors. We also included the continuous variable <italic>mean-replay-usage</italic> as an additional control factor. We ran a further model over the combined data from children and adults which included the same factors as before as well as the fixed effects of <italic>age-group</italic> (adult, child) and all of the interactions with this factor. This model was specifically inspected to look for the effects of <italic>age-group</italic>. (Note that, in addition to the means supplied within the text and the difference scores in <xref ref-type="fig" rid="fig-5">Fig. 5</xref>, a full break down of means at pre and post-test by condition can be seen in the R script at <uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>).</p><fig id="fig-5" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.3209/fig-5</object-id><label>Figure 5</label><caption><title>(A) Adult and (B) child discrimination data.</title><p>Mean increase in percent correct responses from pre- to post-test (error bars show standard error). Note: for all of the plots within this paper, means are corrected to control for imbalance in counterbalancing of talkers.</p></caption><graphic xlink:href="peerj-05-3209-g005"/></fig><sec><title>Adults</title><p>There was no reliable main effect of <italic>word-novelty</italic> (<italic>&#x003b2;</italic> = &#x02212;0.15, SE = 0.12, <italic>z</italic> = &#x02212;1.23, <italic>p</italic> = 0.22), suggesting no difference in discrimination for real English words compared to nonwords. There was a reliable effect of <italic>test-session,</italic> indicating an effect of training (<italic>&#x003b2;</italic> = &#x02212;0.52, SE = 0.15, <italic>z</italic> = &#x02212;3.44, <italic>p</italic> = 0.001). This was qualified by a reliable interaction with talker (<italic>&#x003b2;</italic> = &#x02212;0.59, SE = 0.23, <italic>z</italic> = &#x02212;2.53, <italic>p</italic> = 0.01), which broke down to show that though there was numerical improvement from pre- to post-test for both talkers, this was only reliable for the more intelligible talker (Female 2: <italic>&#x003b2;</italic> = &#x02212;0.82, SE = 0.23, <italic>z</italic> = &#x02212;3.61, <italic>p</italic> &#x0003c; 0.001; 87% &#x02192; 93%; Female 1, <italic>&#x003b2;</italic> = &#x02212;0.23, SE = 0.15, <italic>z</italic> = &#x02212;1.51, <italic>p</italic> = 0.13: 66% &#x02192; 70%) (note that there were no significant higher level interactions involving <italic>talker</italic>&#x02014;see <xref ref-type="supplementary-material" rid="supp-3">Table S3</xref>).</p><p>Of critical interest is how participants&#x02019; improvement from pre- to post-training was affected by input condition and the novelty manipulations. This is depicted in terms of difference scores in <xref ref-type="fig" rid="fig-5">Fig. 5</xref>. There were no reliable interactions of <italic>test-session</italic> by <italic>word-novelty</italic> (<italic>&#x003b2;</italic> = 0.07, SE = 0.25, <italic>z</italic> = 0.29 <italic>p</italic> = 0.77), <italic>test-session</italic> by <italic>voice-novelty</italic> (<italic>&#x003b2;</italic> = 0.19, SE = 0.25, <italic>z</italic> = 0.76, <italic>p</italic> = 0.45), or <italic>test-session</italic> by <italic>word-novelty</italic> by <italic>voice-novelty</italic> (<italic>&#x003b2;</italic> = &#x02212;0.82, SE = 0.50, <italic>z</italic> = &#x02212;1.67, <italic>p</italic> = 0.10). Contrary to predictions, adults did not show reliably greater improvement in the <italic>high-variability</italic> than <italic>low-variability</italic> conditions (<italic>test-session</italic> by <italic>condition</italic>, <italic>&#x003b2;</italic> = 0.07, SE = 0.29, <italic>z</italic> = 0.22, <italic>p</italic> = 0.82). There was also no <italic>word-novelty</italic> by <italic>test-session</italic> by <italic>condition</italic> interaction (<italic>&#x003b2;</italic> = 0.23, SE = 0.46, <italic>z</italic> = 0.50, <italic>p</italic> = 0.62). However, there was a reliable three-way <italic>voice-novelty</italic> by <italic>test-session</italic> by <italic>condition</italic> interaction (<italic>&#x003b2;</italic> = &#x02212;0.91, SE = 0.46, <italic>z</italic> = &#x02212;1.99, <italic>p</italic> = 0.046), which was qualified by a four-way <italic>voice-novelty</italic> by <italic>word-novelty</italic> by <italic>test-session</italic> by <italic>condition</italic> (<italic>&#x003b2;</italic> = 1.94, SE = 0.92, <italic>z</italic> = 2.11, <italic>p</italic> = 0.035). Breaking down the four-way interaction, <italic>voice-novelty</italic> by <italic>test-session</italic> by <italic>condition</italic> interaction was not reliable for trained words (<italic>&#x003b2;</italic> = 0.06, SE = 0.62, <italic>z</italic> = 0.10, <italic>p</italic> = 0.93) but was for untrained words (<italic>&#x003b2;</italic> = &#x02212;1.88, SE = 0.67, <italic>z</italic> = &#x02212;2.79, <italic>p</italic> = 0.005). Breaking down the three-way interaction for untrained words, there was a marginal <italic>condition</italic> by <italic>session</italic> interaction for the untrained voice which went in the predicted direction (i.e., more benefit of high-variability for the untrained voice; <italic>&#x003b2;</italic> = 0.89, SE = 0.50, <italic>z</italic> = 1.76, <italic>p</italic> = 0.078) but also a marginal interaction in the opposite direction for the trained voice (<italic>&#x003b2;</italic> = &#x02212;0.99, SE = 0.52, <italic>z</italic> = &#x02212;1.91, <italic>p</italic> = 0.056). In other words, the interaction rests both on a trend towards a greater benefit of <italic>high-variability</italic> input compared with <italic>low-variability</italic> input for untrained words-untrained voice items (which is predicted since novelty should aid generalization) and a trend towards a greater benefit of <italic>low-variability</italic> for <italic>untrained words-trained voice</italic> items (which is not predicted).</p></sec><sec><title>Children</title><p>There was no reliable main effect of <italic>word-novelty</italic> (<italic>&#x003b2;</italic> = &#x02212;0.03, SE = 0.07, <italic>z</italic> = &#x02212;0.38, <italic>p</italic> = 0.71), suggesting no difference in discrimination for real English words as opposed to nonwords. There was a reliable effect of <italic>test-session</italic>, indicating an effect of training (<italic>&#x003b2;</italic> = &#x02212;0.67, SE = 0.10, <italic>z</italic> = &#x02212;6.77, <italic>p</italic> &#x0003c; 0.001, pre-test = 62%, post-test = 74%). Again improvement from pre- to post-test is of critical interest and the relevant difference scores are shown in <xref ref-type="fig" rid="fig-5">Fig. 5</xref>. There was a marginal interaction between <italic>word-novelty</italic> and <italic>test-session</italic> (<italic>&#x003b2;</italic> = &#x02212;0.25, SE = 0.15, <italic>z</italic> = &#x02212;1.73, <italic>p</italic> = 0.084), reflecting a slightly larger improvement for the trained words (60% &#x02192; 75%) than the untrained nonwords (63% &#x02192; 74%). In contrast to adults, there was a reliable interaction between <italic>test-session</italic> and <italic>condition</italic> (<italic>&#x003b2;</italic> = &#x02212;0.49, SE = 0.20, <italic>z</italic> = &#x02212;2.48, <italic>p</italic> = 0.013), with children showing a <italic>reversed</italic> effect to that predicted&#x02014;i.e., reliably greater improvement in the <italic>low-variability</italic> condition (18%) than the <italic>high-variability</italic> condition (8%). However, participants in the low-variability condition were (by chance) lower at pre-test (<italic>&#x003b2;</italic> = &#x02212;0.49, SE = 0.18, <italic>z</italic> = &#x02212;2.68, <italic>p</italic> = 0.007; low-variability = 56%, high-variability = 66%) and in fact have not overtaken by post-test (<italic>&#x003b2;</italic> = 0.00, SE = 0.19, <italic>z</italic> = &#x02212;0.02, <italic>p</italic> = 0.99; low-variability = 74%, high-variability = 74%). The <italic>test-session</italic> by <italic>condition</italic> interaction was not qualified by an interaction with <italic>word-novelty</italic> (<italic>&#x003b2;</italic> = 0.07, SE = 0.29, <italic>z</italic> = 0.25, <italic>p</italic> = 0.80) <italic>voice-novelty</italic> (<italic>&#x003b2;</italic> = &#x02212;0.02, SE = 0.31, <italic>z</italic> = &#x02212;0.06, <italic>p</italic> = 0.95) or <italic>word-novelty</italic> by <italic>voice-novelty</italic> (<italic>&#x003b2;</italic> = 0.09, SE = 0.29, <italic>z</italic> = 0.29, <italic>p</italic> = 0.77).</p></sec><sec><title>Age-group comparison</title><p>There was a main effect of <italic>age-group</italic>, reflecting overall higher performance in adults than children across pre- and post-test (<italic>&#x003b2;</italic> = &#x02212;0.81, SE = 0.13, <italic>z</italic> = &#x02212;6.43, <italic>p</italic> &#x0003c; 0.001, adults = 79%, children = 68%). Critically, although numerically children improved more from pre- to post-test (see <xref ref-type="fig" rid="fig-5">Fig. 5</xref>) there was no reliable interaction between <italic>age-group</italic> and <italic>test-session</italic> (<italic>&#x003b2;</italic> = &#x02212;0.17, SE = 0.17, <italic>z</italic> = &#x02212;1.02, <italic>p</italic> = 0.31). The <italic>age-group</italic> by <italic>test-session</italic> interaction was not involved in any reliable higher level interactions with any combination of <italic>condition, word-novelty</italic> or <italic>voice-novelty</italic> (<italic>p</italic>&#x02019;s &#x0003e; 0.1) although there was a near reliable five-way interaction of <italic>condition</italic> by <italic>word-novelty</italic> by <italic>voice-novelty</italic> by <italic>age-group</italic> by <italic>test-session</italic> (<italic>&#x003b2;</italic> = &#x02212;2.00, SE = 1.04, <italic>z</italic> = &#x02212;1.92, <italic>p</italic> = 0.055), reflecting the different effects of these factors in the adult and child models reported above.</p></sec><sec><title>Summary of discrimination data</title><p>Adult participants improved in their discrimination performance from pre- to post-test, suggesting an effect of training. Although, numerically, adults showed greater improvement in the high- compared to the low-variability condition, the difference was not reliable (or near reliable). There was some tentative evidence of an interaction between variability and novelty, with the greatest effect of variability evident for maximally novel items. However, the key interaction rested both on a predicted benefit of high-variability training for items with untrained words and voices <italic>and</italic> an unpredicted benefit of low-variability training for items with untrained words and the trained voice, making it difficult to interpret. Child participants also showed a benefit of training in improvement from pre- to post-test. In contrast to adults, children <italic>did</italic> show an overall effect of variability, although this was in the opposite direction to that predicted, with greater improvement in the <italic>low-</italic> compared to <italic>high-variability</italic> condition, with no evidence that this was affected by the <italic>novelty</italic> of either word or voice used in the test items or by the <italic>talker</italic> used as the new or old voice. However, this interaction was driven by (chance) differences between conditions at pre-test, rather than differences at post-test, and should thus be treated with some caution. In contrast to the previous study by <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>, children did not show reliably greater improvement from pre- to post-tests than adults, i.e., we did not replicate the &#x0201c;plasticity&#x0201d; effect seen in that study.</p></sec></sec></sec><sec><title>General Discussion</title><p>The current study compared the effects of talker variability in phonetic training in eight-year-olds and adults. Native Greek learners of English were trained to discriminate the nonnative English /i/-/&#x0026a;/ contrast in ten training sessions using a picture identification task in which they heard a target word (e.g., <italic>sheep</italic>) and chose between pictures of the target (<italic>sheep</italic>) and its minimal pair counterpart (<italic>ship</italic>). Critically, half of the participants heard a single talker during training (low-variability input) whilst the other half heard four talkers (high-variability input), with items and frequencies matched across conditions. Training performance was recorded and we administered pre- and post-tests, including a three-interval oddity discrimination test, which tapped participants&#x02019; ability to discriminate the /i/-/&#x0026a;/ contrast, and tests tapping knowledge of the trained vocabulary. We predicted greater increases in performance following <italic>high-variability</italic> training, given the literature on benefits of high-variability training in both phonetic learning (<xref rid="ref-12" ref-type="bibr">Bradlow &#x00026; Bent, 2008</xref>; <xref rid="ref-15" ref-type="bibr">Clopper &#x00026; Pisoni, 2004</xref>; <xref rid="ref-30" ref-type="bibr">Lively, Logan &#x00026; Pisoni, 1993</xref>) and vocabulary learning (<xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers, 2005</xref>, <xref rid="ref-8" ref-type="bibr">2014</xref>; <xref rid="ref-51" ref-type="bibr">Sommers &#x00026; Barcroft, 2007</xref>, <xref rid="ref-52" ref-type="bibr">2011</xref>). Data did not support this prediction. We also expected that children would show greater increases in performance than adults, at least in the training and discrimination tasks, given the findings of <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>. Again, this was not seen in the data. In this discussion, we first consider the findings from each task, focusing on the contrast between <italic>high-</italic> and <italic>low-variability</italic> input. We then turn to age-related differences, considering why we do not see the same benefit for child learners seen in previous studies, and the implications for theories of plasticity and maturation.</p><sec><title>Training task</title><p>All groups showed improvement across training sessions. Both adults and children showed consistently stronger performance following low- rather than high-variability input. However, for children a benefit for low-variability training only emerged in the second half of training, and only with the more intelligible speaker.</p><p>From the perspective of phonetic discrimination, greater performance following low-variability training is perhaps unsurprising. First, repeated exposure to the same items produced by the same talker potentially allows participants to attune to idiosyncratic cues associated with that talker (<xref rid="ref-15" ref-type="bibr">Clopper &#x00026; Pisoni, 2004</xref>). In addition, the fact that our talkers varied on a trial by trial basis meant that trial by trial adaptation to talker was required in the high-variability condition, possibly imposing a burden on learners in that condition (see <xref rid="ref-34" ref-type="bibr">Martin et al., 1989</xref>; <xref rid="ref-37" ref-type="bibr">Nusbaum &#x00026; Morin, 1992</xref> for evidence that multitalker stimuli are difficult even for L1 processing). Given this, it is perhaps surprising that children did <italic>not</italic> show a reliable benefit of low-variability until the second half of training since we might actually expect that their lower working memory capacity would increase the benefit for low-variability (<xref rid="ref-37" ref-type="bibr">Nusbaum &#x00026; Morin, 1992</xref>; see below for further discussion of this in relation to the discrimination data). However, one confounding factor here is the evidence from the pre-training discrimination test which indicates that the low-variability children started out, by chance, somewhat lower in their ability to discriminate these contrasts, making it hard to evaluate differences in the first half of training.</p><p>Given that our task can also be viewed as a word-learning task, it is worth considering how this result fits with that of <xref rid="ref-41" ref-type="bibr">Rost &#x00026; McMurray (2009)</xref>, who found that 14-month-olds, who are developing their knowledge of L1 phonetic contrasts, only learn two minimal pair object labels when those words were spoken by multiple talkers, <italic>not</italic> when they were spoken by a single talker. This was despite the fact that test items did not probe generalization, testing with a voice familiar from exposure. Similarly, <xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers (2005)</xref> found benefits of multiple-talker training for adults learning novel words from a foreign language, and their tests included L2 to L1 translation where the test items used talkers familiar from training. One possibility is that in our training task, any potential benefit of variability may have been attenuated by the necessity of continuously adapting to a new speaker on a trial by trial basis, as discussed above.</p></sec><sec><title>Three-interval oddity discrimination test</title><p>In the three-interval oddity discrimination test, participants identified the odd man out from a choice of three words (e.g., <italic>sheep, sheep, ship</italic>). We were interested in the extent of improvement from pre- to post-test, and whether this was affected by training condition and novelty (of either words or talkers). If high-variability is specifically useful in supporting generalization (as argued in the phonetic training literature), we predict that high-variability training should benefit generalization items. Results from adult participants were, to some extent, in line with this prediction, with numerically greater improvement in the high-variability condition, however, this difference was not statistically reliable. The lack of a reliable difference between conditions may be due to the overall high performance of adult participants in this test. There was some evidence of an interaction between novelty and the benefit of variability. However, although a greater benefit of high-variability for more novel items is predicted (i.e., because it allows the formation of generalized representations that include only phonetically relevant cues and exclude irrelevant talker identity cues), the interaction relied in part on a benefit for the <italic>low-</italic>variability group for novel items with the familiar talker, which was not predicted. This makes the result difficult to interpret. It is notable that the strongest evidence for the benefit of high-variability training has come from studies using identity tests (<xref rid="ref-30" ref-type="bibr">Lively, Logan &#x00026; Pisoni, 1993</xref>; <xref rid="ref-43" ref-type="bibr">Sadakata &#x00026; McQueen, 2013</xref>). This type of test was <italic>not</italic> possible in the current context, where we did not use orthography, but if high-variability is specifically useful in the formation of category level representations, it may be that an identity test is more useful for testing this type of learning.</p><p>As for children, surprisingly, there was reliably greater improvement following low- rather than high-variability training. This held regardless of the novelty of test items. One concern in interpreting this result is that our low-variability group (by chance) began with lower scores at pre-test. Our analyses focus on changes from pre- to post-test (i.e., we examine interactions with test session); however, it is possible that the pre-test difference could be biasing since the high-variability group have less space for improvement (although it is worth noting that our statistical analyses were not done over proportions, but using logistic regression via mixed models which should be less susceptible to this problem). One interpretation of this result is that, for children, the four speaker input may contain too many varying cues which serve to obfuscate the critical cues needed for distinguishing the /i/-/&#x0026a;/ contrast. This is in line with the Active Control Hypothesis (<xref rid="ref-33" ref-type="bibr">Magnuson &#x00026; Nusbaum, 2007</xref>), which views speech perception as an active processes of balancing bottom-up and top-down expectations and constraints. According to this hypothesis, continuous adaption to a new speaker may usurp working memory capacity. This is supported by experimental evidence suggesting that L1 speech recognition may be slowed when listeners are placed under working memory load (remembering visually presented numbers), but only if there were multiple talkers (<xref rid="ref-37" ref-type="bibr">Nusbaum &#x00026; Morin, 1992</xref>). Since children are known to have lesser phonological working memory than adults, the burden placed by high-variability input may leave them relatively fewer resources for phonetic learning. However, replication with samples which are deliberately matched at pre-test is important (cf., <xref rid="ref-1" ref-type="bibr">Antoniou &#x00026; Wong, 2016</xref>) since this benefit of low-variability is unexpected, particularly for new items where it is difficult to see how more limited exposure could actually benefit generalization.</p></sec><sec><title>English introduction test</title><p>In the English introduction task, participants matched the meaning of a Greek word to its English counterpart given a choice of four words. One purpose of this task, which included feedback, was to ensure that all participants began the experiment with knowledge of the meanings of the words before beginning training. However, it was administered pre- and post-test and thus also provides a measure of participants improved knowledge of the words. Performance even at pre-test was very high, and all adults were at ceiling at post-test making analysis of their data inappropriate. However, children&#x02019;s data were not at ceiling and were analyzed. This revealed an improved knowledge of word meanings from pre- to post-test, but no effect of variability condition. This contrasts with the results of <xref rid="ref-7" ref-type="bibr">Barcroft &#x00026; Sommers (2005)</xref> who found a benefit of multiple talker input for adult vocabulary learning. Given the lack of appropriate comparison data from adults in the current study (i.e., due to the ceiling effects), further work is needed to establish whether the difference we see here is due to the children&#x02019;s age or to one or more of the many differences in our paradigm such as: (i) the fact that our learners are not novices but begin with some knowledge of the words (ii) the fact that we have multiple (10) learning sessions (iii) the focus on discriminating a nonnative speech-sound during training (i.e., via the minimal pairs task) rather than simple exposure to objects and phonological labels as generally occurs in their tasks.</p></sec><sec><title>Primed auditory lexical decision test of semantic priming</title><p>The aim of the auditory lexical decision task was to see if semantic representations were affected by the training, and whether the greater &#x0201c;robustness&#x0201d; of lexical representations reported for high-variability training in previous work would extend to semantic representations. Specifically, we looked for increases in semantic priming from pre- to post-test and tested whether this was greater in the high-variability condition. Analyses revealed that, while both adults and children showed reliable across language semantic priming (revealed in faster RT&#x02019;s for adults and greater accuracy for children), this was present even before training and there was no evidence of an increase in priming after the training in either condition for either group. This was contrary to our expectation that repeated exposure to the words with their picture depictions would <italic>increase</italic> the robustness of those representations and thus increase semantic priming. This does not appear to occur, or at least not sufficiently to be detected by this test. Given that there is no evidence of changes to semantic representations in <italic>either</italic> condition, it is not possible to interpret the lack of evidence for a difference in talker variability for this measure. Future work could consider whether different types of training (e.g., using multiple pictures to represent each word during training, or presenting words in richer contexts such as meaningful sentences) are more effective in this respect.</p></sec><sec><title>Maturational differences</title><p>In the current study adults generally outperformed children both at pre- and post-test. This result is not surprising from the perspective of word learning, where adults typically outperform children in recognition and recall of new words (<xref rid="ref-24" ref-type="bibr">Henderson et al., 2013</xref>). However, <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> found that children of a similar age to those in the current study, showed greater learning of the /i/-/&#x0026a;/ distinction than adults, as shown both in training (where adults initially out-performed children but were overtaken by the final training session) and in the three-interval oddity discrimination test (where children showed reliably greater improvements from pre- to post-test than adult participants). In contrast, in our training data children did <italic>not</italic> overtake adults, instead, it was adults who reached ceiling in the low-variability, while in the high-variability condition (most similar to the training in <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen, 2013a</xref>) our analyses found no evidence that children improve more from pre- to post-test than do adults. Given that we focus on the same phonetic contrasts, and use similar methods and tests, the reasons for these differences are unclear. First, we acknowledge the importance of not over-interpreting a null effect&#x02014;we have no evidence of an age effect, rather than evidence of a <italic>lack</italic> of an age effect. We may simply not have sufficient power. The different findings could also be due to differences in our participant samples. We note that the average age of the children in the current study is slightly higher than in the previous study (current study: 8;9 years; Giannakopoulou, Uther &#x00026; Ylinen: 7;11 years). There are also differences in the extent of participants&#x02019; previous English experience, which was greater in the current study for both age groups (current study: children average of 1.96 years, adult average of 10.98 years; previous study: children average of 1.4 years; adult average of 8.7 years). Note that previous English experience is a confounding factor with age in <italic>both</italic> the current study and <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>&#x02014;adults have substantially more experience in both cases&#x02014;however, the greater extent of experience for both groups in the current study could potentially limit the opportunity to see maturational differences. Speaking against this, we note that at pre-test our adults and children performed quite similarly in the three-interval oddity discrimination tests to those in the previous study; our adults: 76%, our children: 62%; <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>: adults 92%, children 76%.</p><p>Another possibility is that there is a different role for age in the two studies, due to differences in the training and testing tasks. One key difference in training is the use of picture rather than orthographic stimuli. As noted in the introduction, for this specific contrast, English orthography provides an analogue cue to the perceptual length difference between the two vowels&#x02014;the shorter vowel is generally transcribed with a single letter (<italic>i</italic>) and the longer vowel with a digraph (<italic>ee</italic>/<italic>ea</italic>). Recall that <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> found that children&#x02019;s greater improvement over adults was particularly marked in the condition where natural auditory stimuli were used in training, compared with a condition where the stimuli had been modified to remove length cues. One possibility is that children may make particular usage of the match between the length of the auditory and visual stimuli, leading to their lesser success in the current experiment where this cue was not provided. An additional benefit of orthography is that it provides consistent cues <italic>across trials</italic> as to vowel category&#x02014;i.e., there are letters/pairs of letters which occur across different items with the same vowel (i.e., <italic>i in chip</italic>, <italic>bid</italic> and <italic>lick</italic>, versus <italic>ea</italic> in <italic>cheap</italic>, <italic>bead</italic> and <italic>leak</italic>). Thus when orthography is present, learners can focus on more general mappings between the orthographic units and the vowels, potentially ignoring the rest of the lexical item, whereas in the current study they have to learn how each vowel maps to each picture on an idiosyncratic basis. It is possible that this is particularly challenging for children compared with adults. However, it is worth recalling that there are other phonetic training studies that have also not found a benefit for younger learners, and these <italic>did</italic> provide consistent cross-trial cues [e.g., <xref rid="ref-57" ref-type="bibr">Wang &#x00026; Kuhl (2003)</xref>, asked participants to choose consistent symbols for each of the four tones; <xref rid="ref-22" ref-type="bibr">Heeren &#x00026; Schouten (2008</xref>, <xref rid="ref-23" ref-type="bibr">2010</xref>), asked them to match to &#x0201c;long t&#x0201d;]. However, as discussed above, other factors may contribute to the lack of benefit to child learners in these cases.</p><p>Furthermore, research is needed to pull apart the reasons that a benefit in children is seen in <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref> but not in the current study, and more broadly to establish which factors are important in child and adult learning. However, it is clear that the current results do not support a clear story in which children&#x02019;s greater plasticity leads them to benefit more from phonetic training and it seems likely that there are interactions with task complexity.</p></sec></sec><sec><title>Conclusions and Future Directions</title><p>The current experiment adds to the literature demonstrating that L2 learners can improve their discrimination of a phonetic contrast via computerized phonetic training. In particular, we add to the handful of studies demonstrating that is true for child L2 learners.</p><p>In contrast to previous literature, although performance of both adults and children improved across training, and discrimination scores improved from pre- to post-training, we did not find evidence of greater improvements for learners trained on input produced by multiple talkers compared with a single talker. Instead, both age groups showed benefits of hearing a <italic>single</italic> talker within the training task and there was some evidence that children showed this same benefit in the discrimination test. We also did not see any benefit of high-variability in terms of word learning, either in the semantic priming test or the basic vocabulary test. In the above discussion, we have considered possible explanations for the discrepancy between these results and the previous literature showing a high-variability benefit. There are various differences between both the training and testing tasks which could account for the differences and future work must tease these apart. In particular, in the current work, since we were not using orthography, we did not include a pre- and post-test &#x0201c;identity&#x0201d; test, but this makes the result harder to compare, and we are developing methods for testing this in future work. Future work will also address whether &#x0201c;blocking&#x0201d; the input by speaker in the high-variability condition is necessary in order to see the benefits of this type of exposure. We also intend to include a word production test in future work. This will both serve to explore the extent to which comprehension training is generalized to production and also provide a vocabulary test more akin to that used in the relevant word learning literature.</p><p>Our results also do not support the findings of greater plasticity in child learning found by <xref rid="ref-20" ref-type="bibr">Giannakopoulou, Uther &#x00026; Ylinen (2013a)</xref>. Additional work is necessary to pull apart the benefits of directly representing phonemes during training using orthography (or some other categorical representation system) and whether this is particularly important for child learners.</p><p>A final point of interest in our data is that, despite the fact that we used semantic representations (pictures) when training the words, there was no evidence that training increased the robustness of the semantic representations, at least as captured by the semantic priming task. This raises the important question of the extent to which the type of minimal pairs training employed here, and elsewhere, actually changes learners&#x02019; L2 lexical representations. We consider this to be a key question for future research.</p></sec><sec sec-type="supplementary-material" id="supplemental-information"><title>Supplemental Information</title><supplementary-material content-type="local-data" id="supp-1"><object-id pub-id-type="doi">10.7717/peerj.3209/supp-1</object-id><label>Supplemental Information 1</label><caption><title>Table S1. Minimal Pair Stimuli.</title></caption><media xlink:href="peerj-05-3209-s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="supp-2"><object-id pub-id-type="doi">10.7717/peerj.3209/supp-2</object-id><label>Supplemental Information 2</label><caption><title>Table S2. Stimuli for the Primed Lexical Decision Task.</title></caption><media xlink:href="peerj-05-3209-s002.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="supp-3"><object-id pub-id-type="doi">10.7717/peerj.3209/supp-3</object-id><label>Supplemental Information 3</label><caption><title>Table S3. Analyses with the Control Variable &#x0201c;Talker&#x0201d;.</title></caption><media xlink:href="peerj-05-3209-s003.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank staff and students at the Mediterranean College, Agios Pavlos School, and Donna&#x02019;s English School who participated in this experiment.</p></ack><sec sec-type="additional-information"><title>Additional Information and Declarations</title><fn-group content-type="competing-interests"><title>Competing Interests</title><fn fn-type="COI-statement" id="conflict-1"><p>The authors declare that they have no competing interests.</p></fn></fn-group><fn-group content-type="author-contributions"><title>Author Contributions</title><fn fn-type="con" id="contribution-1"><p><xref ref-type="contrib" rid="author-1">Anastasia Giannakopoulou</xref> conceived and designed the experiments, performed the experiments, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, and reviewed drafts of the paper.</p></fn><fn fn-type="con" id="contribution-2"><p><xref ref-type="contrib" rid="author-2">Helen Brown</xref> conceived and designed the experiments, performed the experiments, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, and reviewed drafts of the paper.</p></fn><fn fn-type="con" id="contribution-3"><p><xref ref-type="contrib" rid="author-3">Meghan Clayards</xref> conceived and designed the experiments, consulted on the analyses, and reviewed drafts of the paper.</p></fn><fn fn-type="con" id="contribution-4"><p><xref ref-type="contrib" rid="author-4">Elizabeth Wonnacott</xref> conceived and designed the experiments, analyzed the data, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, and reviewed drafts of the paper.</p></fn></fn-group><fn-group content-type="other"><title>Human Ethics</title><fn id="addinfo-1"><p>The following information was supplied relating to ethical approvals (i.e., approving body and any reference numbers):</p><p>This project received ethical consent by the ethical committee of the University of Warwick (Ethical Application Ref: 80/12-13), abiding to the ethical standards of the Declaration of Helsinki. For children, written informed consent was obtained from their parents prior to the first session. Adults provided written consent at the beginning of the first session. Participants received a certificate and small gift at the end of the experiment.</p></fn></fn-group><fn-group content-type="other"><title>Data Availability</title><fn id="addinfo-2"><p>The following information was supplied regarding data availability:</p><p>The analyses scripts and output can be viewed here:</p><p><uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>.</p><p>For data files and scripts, see the Open Science Framework:</p><p><uri xlink:href="https://osf.io/8anzk/">https://osf.io/8anzk/</uri>.</p><p>For a full breakdown of means by condition, please refer to the accompanying R script, available at: <uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>.</p><p>For a full breakdown of means at pre- and post-test by condition, please refer to the accompanying R script, available at: <uri xlink:href="http://rpubs.com/ewonnacott/247911">http://rpubs.com/ewonnacott/247911</uri>.</p></fn></fn-group></sec><ref-list content-type="authoryear"><title>References</title><ref id="ref-1"><label>Antoniou &#x00026; Wong (2016)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antoniou</surname><given-names>M</given-names></name><name><surname>Wong</surname><given-names>PCM</given-names></name></person-group><article-title>Varying irrelevant phonetic features hinders learning of the feature being trained</article-title><source>Journal of the Acoustical Society of America</source><year>2016</year><volume>139</volume><issue>1</issue><fpage>271</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1121/1.4939736</pub-id><pub-id pub-id-type="pmid">26827023</pub-id></element-citation></ref><ref id="ref-2"><label>Aoyama et al. (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aoyama</surname><given-names>K</given-names></name><name><surname>Flege</surname><given-names>JE</given-names></name><name><surname>Guion</surname><given-names>SG</given-names></name><name><surname>Akahane-Yamada</surname><given-names>R</given-names></name><name><surname>Yamada</surname><given-names>T</given-names></name></person-group><article-title>Perceived phonetic dissimilarity and L2 speech learning: the case of Japanese /r/ and English /l/ and /r/</article-title><source>Journal of Phonetics</source><year>2004</year><volume>32</volume><fpage>233</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/S0095-4470(03)00036-6</pub-id></element-citation></ref><ref id="ref-3"><label>Apfelbaum &#x00026; McMurray (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apfelbaum</surname><given-names>KS</given-names></name><name><surname>McMurray</surname><given-names>B</given-names></name></person-group><article-title>Using variability to guide dimensional weighting: associative mechanisms in early word learning</article-title><source>Cognitive Science</source><year>2011</year><volume>35</volume><fpage>1105</fpage><lpage>1138</lpage><pub-id pub-id-type="doi">10.1111/j.1551-6709.2011.01181.x</pub-id><pub-id pub-id-type="pmid">21609356</pub-id></element-citation></ref><ref id="ref-4"><label>Audacity&#x000ae; (2012)</label><element-citation publication-type="software"><person-group person-group-type="author"><collab><institution>Audacity&#x000ae;</institution></collab></person-group><data-title>Audio editor and recorder</data-title><year>2012</year><version designator="2.0.0">Version 2.0.0</version><uri xlink:href="http://audacity.sourceforge.net/">http://audacity.sourceforge.net/</uri></element-citation></ref><ref id="ref-5"><label>Baayen, Davidson &#x00026; Bates (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baayen</surname><given-names>RH</given-names></name><name><surname>Davidson</surname><given-names>DJ</given-names></name><name><surname>Bates</surname><given-names>DM</given-names></name></person-group><article-title>Mixed-effects modelling with crossed random effects for subjects and items</article-title><source>Journal of Memory and Language</source><year>2008</year><volume>59</volume><fpage>390</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2007.12.005</pub-id></element-citation></ref><ref id="ref-6"><label>Baker et al. (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>W</given-names></name><name><surname>Trofimovich</surname><given-names>P</given-names></name><name><surname>Flege</surname><given-names>JE</given-names></name><name><surname>Mack</surname><given-names>M</given-names></name><name><surname>Halter</surname><given-names>R</given-names></name></person-group><article-title>Child&#x02013;adult differences in second-language phonological learning: the role of cross-language similarity</article-title><source>Language and Speech</source><year>2008</year><volume>51</volume><issue>4</issue><fpage>317</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1177/0023830908099068</pub-id><pub-id pub-id-type="pmid">19348154</pub-id></element-citation></ref><ref id="ref-7"><label>Barcroft &#x00026; Sommers (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barcroft</surname><given-names>J</given-names></name><name><surname>Sommers</surname><given-names>MS</given-names></name></person-group><article-title>Effects of acoustic variability on second language vocabulary learning</article-title><source>Studies in Second Language Acquisition</source><year>2005</year><volume>27</volume><fpage>387</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1017/s0272263105050175</pub-id></element-citation></ref><ref id="ref-8"><label>Barcroft &#x00026; Sommers (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barcroft</surname><given-names>J</given-names></name><name><surname>Sommers</surname><given-names>MS</given-names></name></person-group><article-title>Effects of variability in fundamental frequency on L2 vocabulary learning</article-title><source>Studies in Second Language Acquisition</source><year>2014</year><volume>36</volume><fpage>423</fpage><lpage>449</lpage><pub-id pub-id-type="doi">10.1017/S0272263113000582</pub-id></element-citation></ref><ref id="ref-9"><label>Barr et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barr</surname><given-names>DJ</given-names></name><name><surname>Levy</surname><given-names>R</given-names></name><name><surname>Scheepers</surname><given-names>C</given-names></name><name><surname>Tily</surname><given-names>HJ</given-names></name></person-group><article-title>Random effects structure for confirmatory hypothesis testing: keep it maximal</article-title><source>Journal of Memory and Language</source><year>2013</year><volume>68</volume><fpage>255</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2012.11.001</pub-id></element-citation></ref><ref id="ref-10"><label>Bates, Maechler &#x00026; Bolker (2013)</label><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Maechler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name></person-group><data-title>lme4: Linear mixed-effects models using S4 classes. R package</data-title><year>2013</year><version designator="0.999999-0">Version 0.999999-0</version><uri xlink:href="http://CRAN.R-project.org/package=lme4">http://CRAN.R-project.org/package=lme4</uri></element-citation></ref><ref id="ref-11"><label>Best (1995)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Best</surname><given-names>CT</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Strange</surname><given-names>W</given-names></name></person-group><article-title>A direct realist view of cross-language speech perception</article-title><source>Speech Perception and Linguistic Experience: Issues in Cross Language Research</source><year>1995</year><publisher-loc>Baltimore</publisher-loc><publisher-name>York Press</publisher-name><fpage>171</fpage><lpage>204</lpage></element-citation></ref><ref id="ref-12"><label>Bradlow &#x00026; Bent (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradlow</surname><given-names>AR</given-names></name><name><surname>Bent</surname><given-names>T</given-names></name></person-group><article-title>Perceptual adaptation to non-native speech</article-title><source>Cognition</source><year>2008</year><volume>106</volume><fpage>707</fpage><lpage>729</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2007.04.005</pub-id><pub-id pub-id-type="pmid">17532315</pub-id></element-citation></ref><ref id="ref-13"><label>Bradlow et al. (1999)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradlow</surname><given-names>AR</given-names></name><name><surname>Akahane-Yamada</surname><given-names>RA</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name><name><surname>Tohkura</surname><given-names>Y</given-names></name></person-group><article-title>Training Japanese listeners to identify English /r/and /l/: long-term retention of learning in perception and production</article-title><source>Perception &#x00026; Psychophysics</source><year>1999</year><volume>61</volume><fpage>977</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.3758/BF03206911</pub-id><pub-id pub-id-type="pmid">10499009</pub-id></element-citation></ref><ref id="ref-14"><label>Bradlow et al. (1997)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradlow</surname><given-names>AR</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name><name><surname>Akahane-Yamada</surname><given-names>R</given-names></name><name><surname>Tohkura</surname><given-names>Y</given-names></name></person-group><article-title>Training Japanese listeners to identify English /r/ and /l/: IV. Some effects of perceptual learning on speech production</article-title><source>Journal of the Acoustical Society of America</source><year>1997</year><volume>101</volume><fpage>2299</fpage><lpage>2310</lpage><pub-id pub-id-type="doi">10.1121/1.418276</pub-id><pub-id pub-id-type="pmid">9104031</pub-id></element-citation></ref><ref id="ref-15"><label>Clopper &#x00026; Pisoni (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopper</surname><given-names>CG</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name></person-group><article-title>Effects of talker variability on perceptual learning of dialects</article-title><source>Language and Speech</source><year>2004</year><volume>47</volume><fpage>207</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1177/00238309040470030101</pub-id><pub-id pub-id-type="pmid">15697151</pub-id></element-citation></ref><ref id="ref-17"><label>Flege (1995)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Flege</surname><given-names>JE</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Strange</surname><given-names>W</given-names></name></person-group><article-title>Second language speech learning theory, findings and problems</article-title><source>Speech Perception and Linguistic Experience: Issues in Cross-Language Research</source><year>1995</year><publisher-loc>Baltimore, MD</publisher-loc><publisher-name>York Press</publisher-name><fpage>233</fpage><lpage>277</lpage></element-citation></ref><ref id="ref-18"><label>Flege, Bohn &#x00026; Jang (1997)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flege</surname><given-names>JE</given-names></name><name><surname>Bohn</surname><given-names>O-S</given-names></name><name><surname>Jang</surname><given-names>S</given-names></name></person-group><article-title>Effects of experience on non-native speakers&#x02019; production and perception of English vowels</article-title><source>Journal of Phonetics</source><year>1997</year><volume>25</volume><issue>4</issue><fpage>437</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1006/jpho.1997.0052</pub-id></element-citation></ref><ref id="ref-19"><label>Giannakopoulou, Uther &#x00026; Ylinen (2011)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Giannakopoulou</surname><given-names>A</given-names></name><name><surname>Uther</surname><given-names>M</given-names></name><name><surname>Ylinen</surname><given-names>S</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Wrembel</surname><given-names>Magdalena</given-names></name><name><surname>Kul</surname><given-names>Malgorzata</given-names></name><name><surname>Dziubalska-Kolaczyk</surname><given-names>Katarzyna</given-names></name></person-group><article-title>Phonetic cue-weighting in the acquisition of a second language (L2): evidence from Greek speakers of English</article-title><source>Achievements and Perspectives in SLA of Speech: New Sounds 2010</source><year>2011</year><publisher-loc>Frankfurt am Main</publisher-loc><publisher-name>Peter Lang Verlag</publisher-name><fpage>91</fpage><lpage>102</lpage></element-citation></ref><ref id="ref-20"><label>Giannakopoulou, Uther &#x00026; Ylinen (2013a)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giannakopoulou</surname><given-names>A</given-names></name><name><surname>Uther</surname><given-names>M</given-names></name><name><surname>Ylinen</surname><given-names>S</given-names></name></person-group><article-title>Enhanced plasticity in spoken language acquisition for child learners: evidence from phonetic training studies in child and adult learners of English</article-title><source>Child Language Teaching and Therapy</source><year>2013a</year><volume>29</volume><fpage>201</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1177/0265659012467473</pub-id></element-citation></ref><ref id="ref-21"><label>Giannakopoulou, Uther &#x00026; Ylinen (2013b)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giannakopoulou</surname><given-names>A</given-names></name><name><surname>Uther</surname><given-names>M</given-names></name><name><surname>Ylinen</surname><given-names>S</given-names></name></person-group><article-title>Phonetic and orthographic cues are weighted in speech sound perception by second language speakers: evidence from Greek speakers of English</article-title><source>Journal of the Acoustical Society of America</source><year>2013b</year><volume>134</volume><fpage>40</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1121/1.4830717</pub-id><pub-id pub-id-type="pmid">23862783</pub-id></element-citation></ref><ref id="ref-22"><label>Heeren &#x00026; Schouten (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeren</surname><given-names>WFL</given-names></name><name><surname>Schouten</surname><given-names>MEH</given-names></name></person-group><article-title>Perceptual development of phoneme contrasts: how sensitivity changes along acoustic dimensions that contrast phoneme categories</article-title><source>Journal of the Acoustical Society of America</source><year>2008</year><volume>124</volume><fpage>2291</fpage><lpage>2302</lpage><pub-id pub-id-type="doi">10.1121/1.2967472</pub-id><pub-id pub-id-type="pmid">19062867</pub-id></element-citation></ref><ref id="ref-23"><label>Heeren &#x00026; Schouten (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeren</surname><given-names>WFL</given-names></name><name><surname>Schouten</surname><given-names>MEH</given-names></name></person-group><article-title>Perceptual development of the Finnish /t-t&#x002d0;/ distinction in Dutch 12-year-old children: a training study</article-title><source>Journal of Phonetics</source><year>2010</year><volume>38</volume><fpage>594</fpage><lpage>603</lpage><pub-id pub-id-type="doi">10.1016/j.wocn.2010.08.005</pub-id></element-citation></ref><ref id="ref-24"><label>Henderson et al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>LM</given-names></name><name><surname>Weighall</surname><given-names>A</given-names></name><name><surname>Brown</surname><given-names>H</given-names></name><name><surname>Gaskell</surname><given-names>MG</given-names></name></person-group><article-title>On-line lexical competition during spoken word recognition and word learning in children and adults</article-title><source>Child Development</source><year>2013</year><volume>84</volume><issue>5</issue><fpage>1668</fpage><lpage>1685</lpage><pub-id pub-id-type="doi">10.1111/cdev.12067</pub-id><pub-id pub-id-type="pmid">23432734</pub-id></element-citation></ref><ref id="ref-25"><label>Jaeger (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaeger</surname><given-names>TF</given-names></name></person-group><article-title>Categorical data analysis: away from ANOVAs (transformation or not) and towards logit mixed models</article-title><source>Journal of Memory and Language</source><year>2008</year><volume>59</volume><fpage>434</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2007.11.007</pub-id><pub-id pub-id-type="pmid">19884961</pub-id></element-citation></ref><ref id="ref-26"><label>Johnson &#x00026; Newport (1989)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>JS</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><article-title>Critical period effects in second language learning: the influence of maturational state on the acquisition of English as a second language</article-title><source>Cognitive Psychology</source><year>1989</year><volume>21</volume><fpage>60</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(89)90003-0</pub-id><pub-id pub-id-type="pmid">2920538</pub-id></element-citation></ref><ref id="ref-27"><label>Ktori, van Heuven &#x00026; Pitchford (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ktori</surname><given-names>M</given-names></name><name><surname>van Heuven</surname><given-names>WJB</given-names></name><name><surname>Pitchford</surname><given-names>NJ</given-names></name></person-group><article-title>GreekLex: a lexical database of Modern Greek</article-title><source>Behavioral Research Methods</source><year>2008</year><volume>40</volume><fpage>773</fpage><lpage>783</lpage><pub-id pub-id-type="doi">10.3758/BRM.40.3.773</pub-id></element-citation></ref><ref id="ref-28"><label>Kuhl (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname><given-names>PK</given-names></name></person-group><article-title>Early language acquisition: cracking the speech code</article-title><source>Nature Reviews, Neuroscience</source><year>2004</year><volume>5</volume><fpage>831</fpage><lpage>843</lpage><pub-id pub-id-type="doi">10.1038/nrn1533</pub-id><pub-id pub-id-type="pmid">15496861</pub-id></element-citation></ref><ref id="ref-29"><label>Lenneberg (1967)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lenneberg</surname><given-names>EH</given-names></name></person-group><source>Biological Foundations of Language</source><year>1967</year><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="ref-30"><label>Lively, Logan &#x00026; Pisoni (1993)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lively</surname><given-names>SE</given-names></name><name><surname>Logan</surname><given-names>JS</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name></person-group><article-title>Training Japanese listeners to identify English /r/ and /l/. II: the role of phonetic environment and talker variability in learning new perceptual categories</article-title><source>Journal of the Acoustical Society of America</source><year>1993</year><volume>94</volume><fpage>1242</fpage><lpage>1255</lpage><pub-id pub-id-type="doi">10.1121/1.408177</pub-id><pub-id pub-id-type="pmid">8408964</pub-id></element-citation></ref><ref id="ref-31"><label>Lively et al. (1994)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lively</surname><given-names>SE</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name><name><surname>Yamada</surname><given-names>RA</given-names></name><name><surname>Tohkura</surname><given-names>Y</given-names></name><name><surname>Yamada</surname><given-names>T</given-names></name></person-group><article-title>Training Japanese listeners to identify English /r/ and /l/: III. Long-term retention of new phonetic categories</article-title><source>Journal of the Acoustical Society of America</source><year>1994</year><volume>96</volume><fpage>2076</fpage><lpage>2087</lpage><pub-id pub-id-type="doi">10.1121/1.410149</pub-id><pub-id pub-id-type="pmid">7963022</pub-id></element-citation></ref><ref id="ref-32"><label>Logan, Lively &#x00026; Pisoni (1991)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logan</surname><given-names>JD</given-names></name><name><surname>Lively</surname><given-names>SE</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name></person-group><article-title>Training Japanese listeners to identify English /r/ and /l/: a first report</article-title><source>Journal of the Acoustical Society of America</source><year>1991</year><volume>89</volume><fpage>874</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1121/1.1894649</pub-id><pub-id pub-id-type="pmid">2016438</pub-id></element-citation></ref><ref id="ref-33"><label>Magnuson &#x00026; Nusbaum (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magnuson</surname><given-names>JS</given-names></name><name><surname>Nusbaum</surname><given-names>HC</given-names></name></person-group><article-title>Acoustic differences, listener expectations, and the perceptual accommodation of talker variability</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2007</year><volume>33</volume><fpage>391</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.33.2.391</pub-id><pub-id pub-id-type="pmid">17469975</pub-id></element-citation></ref><ref id="ref-34"><label>Martin et al. (1989)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>CS</given-names></name><name><surname>Mullennix</surname><given-names>JW</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name><name><surname>Summers</surname><given-names>WV</given-names></name></person-group><article-title>Effects of talker variability on recall of spoken word lists</article-title><source>Journal of Experimental Psychology: Learning, Memory and Cognition</source><year>1989</year><volume>15</volume><issue>4</issue><fpage>676</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.15.4.676</pub-id></element-citation></ref><ref id="ref-35"><label>Maye, Werker &#x00026; Gerken (2002)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maye</surname><given-names>J</given-names></name><name><surname>Werker</surname><given-names>JF</given-names></name><name><surname>Gerken</surname><given-names>L</given-names></name></person-group><article-title>Infant sensitivity to distributional information can affect phonetic discrimination</article-title><source>Cognition</source><year>2002</year><volume>82</volume><fpage>B101</fpage><lpage>B111</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(01)00157-3</pub-id><pub-id pub-id-type="pmid">11747867</pub-id></element-citation></ref><ref id="ref-36"><label>Newport (1990)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><article-title>Maturational constraints on language learning</article-title><source>Cognitive Science</source><year>1990</year><volume>14</volume><fpage>11</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog1401_2</pub-id></element-citation></ref><ref id="ref-37"><label>Nusbaum &#x00026; Morin (1992)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nusbaum</surname><given-names>HC</given-names></name><name><surname>Morin</surname><given-names>TM</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Tohkura</surname><given-names>Y</given-names></name><name><surname>Sagisaka</surname><given-names>Y</given-names></name><name><surname>Varikiotis-Bateson</surname><given-names>E</given-names></name></person-group><article-title>Paying attention to differences among talkers</article-title><source>Speech Perception, Speech Production, and Linguistic Structure</source><year>1992</year><publisher-loc>Tokyo</publisher-loc><publisher-name>OHM</publisher-name><fpage>113</fpage><lpage>134</lpage></element-citation></ref><ref id="ref-38"><label>Peracchione et al. (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peracchione</surname><given-names>TK</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Ha</surname><given-names>LY</given-names></name><name><surname>Wong</surname><given-names>PC</given-names></name></person-group><article-title>Learning a novel phonological contrast depends on interactions between individual differences and training paradigm design</article-title><source>Journal of the Acoustical Society of America</source><year>2007</year><volume>130</volume><fpage>461</fpage><lpage>472</lpage><pub-id pub-id-type="doi">10.1121/1.3593366</pub-id></element-citation></ref><ref id="ref-39"><label>Powell (2009)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Powell</surname><given-names>MJD</given-names></name></person-group><article-title>The BOBYQA algorithm for bound constrained optimization without derivatives</article-title><source>Technical Report DAMTP 2009/NA06</source><year>2009</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Centre for Mathematical Sciences, University of Cambridge</publisher-name><uri xlink:href="http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf">http://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf</uri></element-citation></ref><ref id="ref-40"><label>Quen&#x000e9; &#x00026; van den Bergh (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quen&#x000e9;</surname><given-names>H</given-names></name><name><surname>van den Bergh</surname><given-names>H</given-names></name></person-group><article-title>Examples of mixed-effects modelling with crossed random effects and with binomial data</article-title><source>Journal of Memory and Language</source><year>2008</year><volume>59</volume><fpage>413</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2008.02.002</pub-id></element-citation></ref><ref id="ref-60"><label>R Core Team (2016)</label><element-citation publication-type="book"><person-group person-group-type="author"><collab><institution>R Core Team</institution></collab></person-group><source>R: A Language and Environment for Statistical Computing</source><year>2016</year><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><uri xlink:href="https://www.R-project.org/">https://www.R-project.org/</uri></element-citation></ref><ref id="ref-41"><label>Rost &#x00026; McMurray (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>GC</given-names></name><name><surname>McMurray</surname><given-names>B</given-names></name></person-group><article-title>Speaker variability augments phonological processing in early word learning</article-title><source>Developmental Science</source><year>2009</year><volume>12</volume><fpage>339</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2008.00786.x</pub-id><pub-id pub-id-type="pmid">19143806</pub-id></element-citation></ref><ref id="ref-42"><label>Rost &#x00026; McMurray (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>GC</given-names></name><name><surname>McMurray</surname><given-names>B</given-names></name></person-group><article-title>Finding the signal by adding noise: the role of noncontrastive phonetic variability in early word learning</article-title><source>Infancy</source><year>2010</year><volume>15</volume><fpage>608</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1111/j.1532-7078.2010.00033.x</pub-id></element-citation></ref><ref id="ref-43"><label>Sadakata &#x00026; McQueen (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadakata</surname><given-names>M</given-names></name><name><surname>McQueen</surname><given-names>J</given-names></name></person-group><article-title>High stimulus variability in non-native speech learning supports formation of abstract categories: evidence from Japanese geminates</article-title><source>Journal of Acoustical Society of America</source><year>2013</year><volume>134</volume><fpage>1324</fpage><lpage>1335</lpage><pub-id pub-id-type="doi">10.1121/1.4812767</pub-id></element-citation></ref><ref id="ref-44"><label>Sadakata &#x00026; McQueen (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadakata</surname><given-names>M</given-names></name><name><surname>McQueen</surname><given-names>J</given-names></name></person-group><article-title>Individual aptitude in Mandarin lexical tone learning predicts effectiveness of high-variability training</article-title><source>Frontiers in Psychology</source><year>2014</year><volume>5</volume><fpage>13</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.3389/fpsyg.2014.01318</pub-id><pub-id pub-id-type="pmid">24478744</pub-id></element-citation></ref><ref id="ref-45"><label>Shinohara (2014)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shinohara</surname><given-names>Y</given-names></name></person-group><article-title>Perceptual training of English /r/ and /l/ for Japanese adults, adolescents and children</article-title><comment>Doctoral thesis</comment><year>2014</year><publisher-loc>United Kingdom</publisher-loc><publisher-name>University College London</publisher-name><uri xlink:href="http://discovery.ucl.ac.uk/1421176/">http://discovery.ucl.ac.uk/1421176/</uri></element-citation></ref><ref id="ref-46"><label>Shinohara &#x00026; Iverson (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinohara</surname><given-names>Y</given-names></name><name><surname>Iverson</surname><given-names>P</given-names></name></person-group><article-title>Computer-based English /r/-/l/ perceptual training for Japanese children</article-title><source>Proceedings of Meetings on Acoustics</source><year>2013</year><volume>19</volume><issue>1</issue><fpage>060049</fpage><pub-id pub-id-type="doi">10.1121/1.4800136</pub-id></element-citation></ref><ref id="ref-47"><label>Shinohara &#x00026; Iverson (2015)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Shinohara</surname><given-names>Y</given-names></name><name><surname>Iverson</surname><given-names>P</given-names></name></person-group><person-group person-group-type="editor"><collab><institution>The Scottish Consortium for ICPhS 2015</institution></collab></person-group><article-title>Effects of English /r/-/l/ perceptual training on Japanese children&#x02019;s production</article-title><conf-name>Proceedings of the 18th International Congress of Phonetic Sciences</conf-name><year>2015</year><publisher-loc>Glasgow</publisher-loc><publisher-name>University of Glasgow</publisher-name><uri xlink:href="http://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2015/Papers/ICPHS0540.pdf">http://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2015/Papers/ICPHS0540.pdf</uri></element-citation></ref><ref id="ref-48"><label>Singh, Morgan &#x00026; White (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>L</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name><name><surname>White</surname><given-names>KS</given-names></name></person-group><article-title>Preference and processing: the role of speech affect in early spoken word recognition</article-title><source>Journal of Memory and Language</source><year>2004</year><volume>51</volume><fpage>173</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2004.04.004</pub-id></element-citation></ref><ref id="ref-49"><label>Singh, White &#x00026; Morgan (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>L</given-names></name><name><surname>White</surname><given-names>KS</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name></person-group><article-title>Building a word-form lexicon in the face of variable input: influences of pitch and amplitude on early spoken word recognition</article-title><source>Language Learning and Development</source><year>2008</year><volume>4</volume><fpage>157</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1080/15475440801922131</pub-id></element-citation></ref><ref id="ref-50"><label>Snow &#x00026; Hoefnagel-H&#x000f6;hle (1978)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snow</surname><given-names>CE</given-names></name><name><surname>Hoefnagel-H&#x000f6;hle</surname><given-names>M</given-names></name></person-group><article-title>The critical period for language acquisition: evidence from second language learning</article-title><source>Child Development</source><year>1978</year><volume>49</volume><issue>4</issue><fpage>1114</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.2307/1128751</pub-id></element-citation></ref><ref id="ref-51"><label>Sommers &#x00026; Barcroft (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommers</surname><given-names>MS</given-names></name><name><surname>Barcroft</surname><given-names>J</given-names></name></person-group><article-title>An integrated account of the effects of acoustic variability in first language and second language: evidence from amplitude, fundamental frequency, and speaking rate variability</article-title><source>Applied Psycholinguistics</source><year>2007</year><volume>28</volume><fpage>231</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1017/S0142716407070129</pub-id></element-citation></ref><ref id="ref-52"><label>Sommers &#x00026; Barcroft (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommers</surname><given-names>MS</given-names></name><name><surname>Barcroft</surname><given-names>J</given-names></name></person-group><article-title>Indexical information, encoding difficulty, and second language vocabulary learning</article-title><source>Applied Psycholinguistics</source><year>2011</year><volume>32</volume><fpage>417</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1017/S0142716410000469</pub-id></element-citation></ref><ref id="ref-53"><label>Stager &#x00026; Werker (1997)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stager</surname><given-names>CL</given-names></name><name><surname>Werker</surname><given-names>JF</given-names></name></person-group><article-title>Infants listen for more phonetic detail in speech perception than in word-learning tasks</article-title><source>Nature</source><year>1997</year><volume>388</volume><fpage>381</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/41102</pub-id><pub-id pub-id-type="pmid">9237755</pub-id></element-citation></ref><ref id="ref-54"><label>Strange &#x00026; Dittmann (1984)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>W</given-names></name><name><surname>Dittmann</surname><given-names>S</given-names></name></person-group><article-title>Effects of discrimination training on the perception of /r-l/ by Japanese adults learning English</article-title><source>Perception and Psychophysics</source><year>1984</year><volume>36</volume><fpage>131</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.3758/BF03202673</pub-id><pub-id pub-id-type="pmid">6514522</pub-id></element-citation></ref><ref id="ref-55"><label>Tamminen &#x00026; Gaskell (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamminen</surname><given-names>J</given-names></name><name><surname>Gaskell</surname><given-names>MG</given-names></name></person-group><article-title>Novel word integration in the mental lexicon: evidence from unmasked and masked semantic priming</article-title><source>Quarterly Journal of Experimental Psychology</source><year>2012</year><volume>66</volume><fpage>1001</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1080/17470218.2012.724694</pub-id></element-citation></ref><ref id="ref-56"><label>Tsukada et al. (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsukada</surname><given-names>K</given-names></name><name><surname>Birdsong</surname><given-names>D</given-names></name><name><surname>Bialystok</surname><given-names>E</given-names></name><name><surname>Mack</surname><given-names>M</given-names></name><name><surname>Sung</surname><given-names>H</given-names></name><name><surname>Flege</surname><given-names>J</given-names></name></person-group><article-title>A developmental study of English vowel production and perception by native Korean adults and children</article-title><source>Journal of Phonetics</source><year>2005</year><volume>33</volume><fpage>263</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1016/j.wocn.2004.10.002</pub-id></element-citation></ref><ref id="ref-57"><label>Wang &#x00026; Kuhl (2003)</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Kuhl</surname><given-names>PK</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Sol&#x000e9;</surname><given-names>M-J</given-names></name><name><surname>Recasens</surname><given-names>D</given-names></name><name><surname>Romero</surname><given-names>J</given-names></name></person-group><article-title>Evaluating the &#x0201c;critical period&#x0201d; hypothesis: perceptual learning of Mandarin tones in American adults and American children at 6, 10 and 14 years of age</article-title><year>2003</year><conf-name>Proceedings of the 15th International Congress on Phonetic Sciences</conf-name><publisher-loc>Adelaide, Australia</publisher-loc><publisher-name>Causal Productions</publisher-name><fpage>1537</fpage><lpage>1540</lpage><uri xlink:href="https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2003/papers/p15_1537.pdf">https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2003/papers/p15_1537.pdf</uri></element-citation></ref><ref id="ref-58"><label>Werker &#x00026; Curtin (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werker</surname><given-names>JF</given-names></name><name><surname>Curtin</surname><given-names>S</given-names></name></person-group><article-title>PRIMIR: a developmental framework of infant speech processing</article-title><source>Language Learning and Development</source><year>2005</year><volume>1</volume><fpage>197</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1080/15475441.2005.9684216</pub-id></element-citation></ref><ref id="ref-59"><label>Wilson (1988)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MD</given-names></name></person-group><article-title>The MRC Psycholinguistic Database: machine-readable dictionary, version 2</article-title><source>Behavior Research Methods, Instruments and Computers</source><year>1988</year><volume>20</volume><issue>1</issue><fpage>6</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3758/bf03202594</pub-id></element-citation></ref></ref-list></back></article>