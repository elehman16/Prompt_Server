<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Implement Sci</journal-id><journal-title-group><journal-title>Implementation Science : IS</journal-title></journal-title-group><issn pub-type="epub">1748-5908</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">21619621</article-id><article-id pub-id-type="pmc">3123565</article-id><article-id pub-id-type="publisher-id">1748-5908-6-51</article-id><article-id pub-id-type="doi">10.1186/1748-5908-6-51</article-id><article-categories><subj-group subj-group-type="heading"><subject>Study Protocol</subject></subj-group></article-categories><title-group><article-title>Effects of an evidence service on health-system policy makers' use of research evidence: A protocol for a randomised controlled trial</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Lavis</surname><given-names>John N</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I3">3</xref><xref ref-type="aff" rid="I4">4</xref><email>lavisj@mcmaster.ca</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Wilson</surname><given-names>Michael G</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I5">5</xref><email>wilsom2@mcmaster.ca</email></contrib><contrib contrib-type="author" id="A3"><name><surname>Grimshaw</surname><given-names>Jeremy M</given-names></name><xref ref-type="aff" rid="I6">6</xref><xref ref-type="aff" rid="I7">7</xref><xref ref-type="aff" rid="I8">8</xref><email>jgrimshaw@ohri.ca</email></contrib><contrib contrib-type="author" id="A4"><name><surname>Haynes</surname><given-names>R Brian</given-names></name><xref ref-type="aff" rid="I3">3</xref><xref ref-type="aff" rid="I9">9</xref><email>bhaynes@mcmaster.ca</email></contrib><contrib contrib-type="author" id="A5"><name><surname>Hanna</surname><given-names>Steven</given-names></name><xref ref-type="aff" rid="I3">3</xref><xref ref-type="aff" rid="I5">5</xref><xref ref-type="aff" rid="I10">10</xref><xref ref-type="aff" rid="I11">11</xref><email>hannas@mcmaster.ca</email></contrib><contrib contrib-type="author" id="A6"><name><surname>Raina</surname><given-names>Parminder</given-names></name><xref ref-type="aff" rid="I3">3</xref><xref ref-type="aff" rid="I12">12</xref><email>praina@mcmaster.ca</email></contrib><contrib contrib-type="author" id="A7"><name><surname>Gruen</surname><given-names>Russell</given-names></name><xref ref-type="aff" rid="I13">13</xref><xref ref-type="aff" rid="I14">14</xref><email>r.gruen@alfred.org.au</email></contrib><contrib contrib-type="author" id="A8"><name><surname>Ouimet</surname><given-names>Mathieu</given-names></name><xref ref-type="aff" rid="I15">15</xref><xref ref-type="aff" rid="I16">16</xref><email>mathieu.ouimet@pol.ulaval.ca</email></contrib></contrib-group><aff id="I1"><label>1</label>McMaster Health Forum, Hamilton, Canada</aff><aff id="I2"><label>2</label>Centre for Health Economics and Policy Analysis, McMaster University, Hamilton, Canada</aff><aff id="I3"><label>3</label>Department of Clinical Epidemiology and Biostatistics, McMaster University, Hamilton, Canada</aff><aff id="I4"><label>4</label>Department of Political Science, McMaster University, Hamilton, Canada</aff><aff id="I5"><label>5</label>Health Research Methodology Program, McMaster University, Hamilton, Canada</aff><aff id="I6"><label>6</label>Clinical Epidemiology Program, Ottawa Hospital Research Institute, Ottawa, Canada</aff><aff id="I7"><label>7</label>Department of Medicine, University of Ottawa, Ottawa, Canada</aff><aff id="I8"><label>8</label>Institute of Population Health, University of Ottawa, Ottawa, Canada</aff><aff id="I9"><label>9</label>Health Information Research Unit, McMaster University, Hamilton, Canada</aff><aff id="I10"><label>10</label>School of Rehabilitation Science, McMaster University, Hamilton, Canada</aff><aff id="I11"><label>11</label>CanChild Centre for Childhood Disability Research, McMaster University, Hamilton, Canada</aff><aff id="I12"><label>12</label>Evidence-based Practice Centre, McMaster University, Hamilton, Canada</aff><aff id="I13"><label>13</label>The National Trauma Research Institute, Alfred Hospital, Melbourne, Australia</aff><aff id="I14"><label>14</label>Departments of Surgery &#x00026; Public Health, Monash University, Melbourne, Australia</aff><aff id="I15"><label>15</label>Department of Political Science, Universit&#x000e9; Laval, Qu&#x000e9;bec, Canada</aff><aff id="I16"><label>16</label>Centre de Recherche du Centre Hospitalier Universitaire de Qu&#x000e9;bec, Qu&#x000e9;bec, Canada</aff><pub-date pub-type="collection"><year>2011</year></pub-date><pub-date pub-type="epub"><day>27</day><month>5</month><year>2011</year></pub-date><volume>6</volume><fpage>51</fpage><lpage>51</lpage><history><date date-type="received"><day>26</day><month>11</month><year>2010</year></date><date date-type="accepted"><day>27</day><month>5</month><year>2011</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2011 Lavis et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2011</copyright-year><copyright-holder>Lavis et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.implementationscience.com/content/6/1/51"/><abstract><sec><title>Background</title><p>Health-system policy makers need timely access to synthesised research evidence to inform the policy-making process. No efforts to address this need have been evaluated using an experimental quantitative design. We developed an evidence service that draws inputs from Health Systems Evidence, which is a database of policy-relevant systematic reviews. The reviews have been (a) categorised by topic and type of review; (b) coded by the last year searches for studies were conducted and by the countries in which included studies were conducted; (c) rated for quality; and (d) linked to available user-friendly summaries, scientific abstracts, and full-text reports. Our goal is to evaluate whether a "full-serve" evidence service increases the use of synthesized research evidence by policy analysts and advisors in the Ontario Ministry of Health and Long-Term Care (MOHLTC) as compared to a "self-serve" evidence service.</p></sec><sec><title>Methods/design</title><p>We will conduct a two-arm randomized controlled trial (RCT), along with a follow-up qualitative process study in order to explore the findings in greater depth. For the RCT, all policy analysts and policy advisors (n = 168) in a single division of the MOHLTC will be invited to participate. Using a stratified randomized design, participants will be randomized to receive either the "full-serve" evidence service (database access, monthly e-mail alerts, and full-text article availability) or the "self-serve" evidence service (database access only). The trial duration will be ten months (two-month baseline period, six-month intervention period, and two month cross-over period). The primary outcome will be the mean number of site visits/month/user between baseline and the end of the intervention period. The secondary outcome will be participants' intention to use research evidence. For the qualitative study, 15 participants from each trial arm (n = 30) will be purposively sampled. One-on-one semi-structured interviews will be conducted by telephone on their views about and their experiences with the evidence service they received, how helpful it was in their work, why it was helpful (or not helpful), what aspects were most and least helpful and why, and recommendations for next steps.</p></sec><sec><title>Discussion</title><p>To our knowledge, this will be the first RCT to evaluate the effects of an evidence service specifically designed to support health-system policy makers in finding and using research evidence.</p></sec><sec><title>Trial registration</title><p>ClinicalTrials.gov: <ext-link ext-link-type="uri" xlink:href="http://www.clinicaltrials.gov/ct2/show/NCT01307228">NCT01307228</ext-link></p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Health-system policy makers make important decisions every day about the governance, financial, and delivery arrangements within which programs, services, and drugs are provided and about implementation strategies [<xref ref-type="bibr" rid="B1">1</xref>]. The nature of their decisions will vary according to the setting in which they work (<italic>e.g.</italic>, federal, provincial, or local government) and the role they play (<italic>e.g.</italic>, political staff, policy analyst, senior policy advisor, Assistant Deputy Minister, or elected official), among other factors. Systematic reviews are increasingly seen as a key source of information to inform these decisions [<xref ref-type="bibr" rid="B1">1</xref>]. Reduced bias and increased precision comprise the main advantages of systematic reviews that address questions about the effects of interventions [<xref ref-type="bibr" rid="B2">2</xref>]. Drawing on a systematic review that addresses <italic>any </italic>question constitutes a more efficient use of time for busy policy makers because the research literature has already been identified, selected, appraised, and synthesised in a systematic and transparent way. Additionally, a systematic review makes possible more constructive policy debates because stakeholders can focus on the synthesis and its local applicability rather than on which single study has greater credibility [<xref ref-type="bibr" rid="B3">3</xref>].</p><p>In order to make informed decisions, health-system policy makers need timely access to systematic reviews that can be easily retrieved using terminology that is understandable to them and that are presented in ways that facilitate rapid scanning for relevance, recency of searches for potentially relevant studies, the settings of studies included in the review, and quality of the review [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B4">4</xref>]. A systematic review of the factors that influence the use of research in policy making identified timing/timeliness as one of two factors that increased the prospects for research use among health-system policy makers [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B5">5</xref>]. However, when attempting to retrieve systematic reviews in a timely fashion, health-system policy makers typically cannot search all of the potential sources of systematic reviews. Moreover, policy makers typically cannot search most sources of systematic reviews, like The Cochrane Library, using terms with which they are familiar. The number and searchability of existing sources of systematic reviews become particularly frustrating when policy makers know there is likely to be a review available on a topical issue. Moreover, search results typically do not highlight the types of decision-relevant information that health-system policy makers are seeking [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B4">4</xref>].</p><p>One response to the similar types of issues faced by clinical decision makers has been the development of evidence services that provide regular email alerts about newly identified research products and a searchable database of these products[<xref ref-type="bibr" rid="B6">6</xref>]. However, no 'full-serve' evidence service currently exists to meet the needs of health-system policy makers. Existing evidence services that include health-system policy makers among their target audiences, such as E-watch (<ext-link ext-link-type="uri" xlink:href="http://kuuc.chair.ulaval.ca/english/index.php">http://kuuc.chair.ulaval.ca/english/index.php</ext-link>) and CHAIN Canada (<ext-link ext-link-type="uri" xlink:href="http://www.epoc.uottawa.ca/CHAINCanada/">http://www.epoc.uottawa.ca/CHAINCanada/</ext-link>), do not focus on systematic reviews. Existing evidence services that focus on high-quality studies (not just systematic reviews), such as Evidence Updates (<ext-link ext-link-type="uri" xlink:href="http://plus.mcmaster.ca/EvidenceUpdates/">http://plus.mcmaster.ca/EvidenceUpdates/</ext-link>), do not target health-system policy makers[<xref ref-type="bibr" rid="B6">6</xref>].</p><p>To address this gap, we developed a full-serve evidence service for health-system policy makers. First, we developed Health Systems Evidence, which contains over 1,400 syntheses about governance, financial, and delivery arrangements within health systems and about implementation strategies relevant to health systems. By syntheses we mean both systematic reviews and two types of review-derived products, namely, policy briefs and overviews of systematic reviews [<xref ref-type="bibr" rid="B7">7</xref>]. A policy brief summarises how the findings from a number of systematic reviews pertain to a pressing problem, select options for addressing the problem, and key implementation considerations, whereas an overview provides a 'map' of all available systematic reviews on a broad health-system topic. The reviews have been (a) categorised by topic (<italic>i.e.</italic>, by health-system arrangement or implementation strategy), type of review (<italic>i.e.</italic>, policy brief, overview of reviews, Cochrane systematic review, systematic review, or systematic review protocol), and type of question addressed (<italic>i.e.</italic>, effectiveness, not effectiveness, and 'many'); (b) coded by the last year in which searches for studies were conducted and by the countries in which included studies were conducted; (c) rated for quality using the AMSTAR (A MeaSurement Tool for the 'Assessment of multiple systematic Reviews') instrument [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B9">9</xref>]; and (d) linked to available user-friendly summaries, scientific abstracts, and full-text reviews that are available free online [<xref ref-type="bibr" rid="B10">10</xref>].</p><p>Second, we identified systematic reviews in Health Systems Evidence that are neither available free online nor available through subscriptions held by the Ontario Ministry of Health and Long-Term Care (MOHLTC) and developed a mechanism to reimburse publishers for full-text downloads of these reviews.</p><p>Third, we developed the format for monthly email alerts, which (in tabular format) identifies new additions to Health Systems Evidence and describes the type of review, type of question addressed, health-system arrangement or implementation strategy addressed, and title of the review. A hypertext link for each review enables policy makers to view the availability of (and links to) user-friendly summaries, scientific abstracts, and the full-text review. A hypertext link to the online Health Systems Evidence webpage enables policy makers to view additional information about these same recent database additions, including the last year searched, quality rating, the countries in which included studies were conducted, and the complete citation. (Electronic newsletter width restrictions precluded having all fields presented in the monthly email alerts.)</p><p>Our goal is to evaluate whether (and how and why) a full-serve evidence service increases the use of synthesised research evidence by policy analysts and advisors in the MOHLTC as compared to a 'self-serve' evidence service. The full-serve evidence service comprises database access (an effort to facilitate policy makers' efforts to 'pull' in research when they need it), monthly email alerts about new additions to the database (a 'push' effort), and full-text article availability (an additional effort to facilitate pull). A systematic review found that simply providing information (in the form of clinical-practice guidelines) can change clinical behaviour,[<xref ref-type="bibr" rid="B11">11</xref>] which leaves us reasonably confident that we have the potential to achieve an increase in evidence use among health-system policy makers. Moreover, the results of a cluster randomised trial indicate that a full-serve evidence service increased practicing clinicians' utilisation of evidence-based information from a digital library [<xref ref-type="bibr" rid="B12">12</xref>].</p></sec><sec><title>Methods/design</title><p>We will conduct this trial using a sequential explanatory mixed-methods design, [<xref ref-type="bibr" rid="B13">13</xref>] beginning with the randomised controlled trial (RCT) and then following up with a qualitative process study to explore the RCT findings in greater depth. For an initial two-month baseline period, all participants will receive the self-serve evidence service. For the following six-month period, the intervention group will receive the full-serve evidence service and the control group will continue to receive the self-serve evidence service. For a final two-month period, both groups will receive the full-serve evidence service. This protocol received ethics approval from the Hamilton Health Sciences/Faculty of Health Sciences Research Ethics Board at McMaster University (project number 10-267).</p></sec><sec><title>RCT methods/design</title><sec><title>Study population and recruitment</title><p>To recruit participants who deal with health-systems issues on a regular basis, we will invite all policy analysts and policy advisors from one purposively selected division of the MOHLTC to participate in the RCT. All division staff members similarly face a relatively new expectation about obtaining training in finding and using research evidence (in the form of an indicator in annual performance reviews), as well as a new mandate for using the Ministry's 'Research Evidence Tool' for submissions that support decision making at the Ministry Management Committee and cabinet levels. Moreover, a trial endorsement letter will be signed by the Assistant Deputy Ministry responsible for this division. These contextual developments precede the launch of the trial and help to create a favourable climate for the use of research evidence among all potential trial participants.</p><p>Based on estimates provided to us in June 2009 by the MOHLTC, there are approximately 49 policy analysts (four are junior program and policy analysts) and 99 senior policy analysts in the division (n = 148). We do not yet have an accurate estimate of the number of policy advisors in the division; however, this group is likely to include roughly 20 people and all of them are likely to be senior policy advisors. By including all three levels of policy analysts and (if applicable) both levels of policy advisors, we will gather evidence from a diverse group that plays different roles in the policy-making process. For example, a policy analyst might conduct the initial, extensive 'workup' of an issue, whereas a senior policy advisor might write a short briefing note for the Minister.</p><p>Selecting this sample of policy analysts and advisors raises two applicability/generalisabilty issues. First, these RCT participants will differ in whether and when they received training on finding and using research evidence. Two of us (JNL and MGW) delivered a series of five one-day workshops for policy analysts and advisors at the MOHLTC between July 2008 and March 2009 (<italic>i.e.</italic>, 14 to 22 months before the trial will begin). We delivered five additional one-day workshops, one half-day workshop, and one half-day webinar for policy analysts and policy advisors, as well as one 1.5-hour workshop for more senior MOHLTC executives who set expectations for these staff, between January and March 2010 (<italic>i.e.</italic>, two to four months before the trial will begin). Given the division's expectation about training, we can assume that most RCT participants will have received the training. However, newly hired policy analysts and advisors may not have received the training, and others may not have been able to participate due to scheduling conflicts; those that have received the training will differ in the recency of the training. Second, these RCT participants will differ in their experience, which is somewhat related to their position (<italic>i.e.</italic>, level of policy analyst and level of policy advisor). To address each of these applicability/generalisability issues, we will stratify the randomisation based on past training and current position (see below).</p></sec><sec><title>Intervention and control arms</title><p>We will conduct a two-arm RCT with a full-serve evidence service as the intervention arm and a self-serve version as the control arm. Participants allocated to the full-serve evidence service will receive the following:</p><p>&#x02022; database (Health Systems Evidence) access (facilitating pull)</p><p>&#x02022; monthly email alerts (push)</p><p>&#x02022; full-text article availability (facilitating pull)</p><p>Participants allocated to the self-serve evidence service will receive only database access, which is already publicly available at <ext-link ext-link-type="uri" xlink:href="http://www.healthsystemsevidence.org">http://www.healthsystemsevidence.org</ext-link>.</p></sec><sec><title>Randomisation</title><p>Participants will be randomised using a stratified design. After completing the baseline questionnaire during the two-month baseline period, participants will be allocated to strata based on past workshop attendance (yes or no) and their position (policy analyst, senior policy analyst, or policy advisor). This two-layer stratification will produce six strata. Participants will be randomised after all those who consent to participate in the trial have completed the baseline questionnaire. We will assign a unique participant ID number to each participant and then provide the list of IDs to a biostatistician external to the research team who will conduct the randomisation and keep a log to provide a clear audit trail. The biostatistician will then communicate directly with a knowledge broker external to the research team who will be generating the email alerts and with the website server administrator at McMaster University who will be establishing which participants get access to which evidence service. The participants and investigators will be blinded to group assignment.</p></sec><sec><title>Outcomes</title><p>Measuring the impact of knowledge transfer and exchange (KTE) interventions, such as the evidence service proposed here, poses significant challenges [<xref ref-type="bibr" rid="B14">14</xref>]. The ultimate goal of KTE interventions is typically to improve health. However, there is a long chain of potential causal relationships between an evidence service and improved health. For instance, the evidence service may influence the use of research evidence in different stages of the policy-making process, which in turn may influence decisions made by patients and healthcare providers (<italic>e.g.</italic>, healthcare professionals, teams, and institutions), which may in turn influence whether cost-effective programs, services, and drugs get to the patients who need them and have their desired impacts, and which in turn may translate into improved health [<xref ref-type="bibr" rid="B15">15</xref>]. Moreover, even the first relationship in this long chain is complicated by the competing influences on the policy-making process, such as institutional constraints within a political system, stakeholder pressure campaigns, values and beliefs held by key decision makers, and external factors such as the state of the economy [<xref ref-type="bibr" rid="B16">16</xref>-<xref ref-type="bibr" rid="B18">18</xref>]. Similar challenges arise when assessing the impact of KTE interventions, such as guideline-dissemination strategies, on clinical practice and on health [<xref ref-type="bibr" rid="B19">19</xref>-<xref ref-type="bibr" rid="B21">21</xref>].</p><p>Given these challenges, our primary and secondary outcomes for the trial are proxy measures for the use of research evidence in policy making. The primary outcome will be a measure of utilisation that is similar to the one used in a trial of the McMaster Premium Literature Updating Service (PLUS) [<xref ref-type="bibr" rid="B12">12</xref>]. Specifically, we will track the mean number of site visits/month/participant across trial groups during each period, that is, the baseline period, intervention period, and crossover period. We will also provide related descriptive measures such as the proportion of users per month in each of the full-serve and self-serve groups; the frequency with which the full monthly update page, systematic review records, and the more detailed documentation for each review (<italic>e.g.</italic>, user-friendly summaries, scientific abstracts, and full-text reports) are accessed; the mean number of minutes per month that participants use the database (with a 'time out' set at 60 minutes); and the number of times the monthly email alerts are forwarded.</p><p>Health Systems Evidence will be hosted on a secure server at McMaster University and will require a user login that will be used to accurately track their usage of the database. A user login is necessary because individuals from the MOHLTC do not have a consistent IP address when accessing external websites, which would preclude the collection of utilisation data if the site were hosted without requiring users to login. In addition, requiring user login will partially protect against contamination of the control group. However, we cannot rule out the possibility that individuals in the intervention arm of the study will forward monthly email alerts and full-text systematic reviews that are available only by subscription to individuals in the control arm; however, we will collect data about alert forwarding.</p><p>For the secondary outcome, we will use a survey based upon the theory of planned behaviour to measure participants' intention to use research evidence. The theory of planned behaviour is a model of how human action is guided [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>], and it consists of three variables--attitudes (<italic>i.e.</italic>, beliefs and judgments), subjective norms (<italic>i.e.</italic>, normative beliefs and judgments about those beliefs), and perceived behavioural control (<italic>i.e.</italic>, the perceived ability to enact the behaviour)--that shape the behaviour intentions of people, which is in turn a strong predictor of future behaviour [<xref ref-type="bibr" rid="B23">23</xref>-<xref ref-type="bibr" rid="B25">25</xref>]. In Figure <xref ref-type="fig" rid="F1">1</xref>, we outline linkages among the intervention, contextual developments (described above), and theory of planned behaviour constructs and measures.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Linkages among the intervention, contextual developments, and theory of planned behaviour constructs</bold>.</p></caption><graphic xlink:href="1748-5908-6-51-1"/></fig><p>The theory of planned behaviour has been extensively used and tested in the fields of psychology and healthcare. Systematic reviews conducted in the psychology field have demonstrated that the theory explains about 39% of the variance in intention and about 27% of the variance in behaviour [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B25">25</xref>]. A number of studies have demonstrated the feasibility of producing valid and reliable measures of key theory of planned behaviour constructs for use with healthcare professionals [<xref ref-type="bibr" rid="B26">26</xref>-<xref ref-type="bibr" rid="B28">28</xref>]. A systematic review suggests that the proportion of the variance in healthcare professionals' behaviour explained by intention was similar in magnitude to that found in the broader literature [<xref ref-type="bibr" rid="B29">29</xref>]. This successful transfer of the theory from individuals (as studied by psychologists) to healthcare professionals involved in an agency relationship with their patients (as studied by health-services researchers) bodes well for its further transfer to policy analysts and advisors involved in an agency relationship with Ministers and other senior officials.</p><p>Using a manual to support health researchers who want to construct measures based on the theory [<xref ref-type="bibr" rid="B23">23</xref>], we developed and sought preliminary feedback on a data collection instrument by first assessing face validity through interviews with key informants and then pilot testing it with 28 policy makers and researchers from 20 low-middle income countries who completed it after participating in a KTE intervention [<xref ref-type="bibr" rid="B30">30</xref>]. In addition, Boyko <italic>et al. </italic>(2010) found moderate test-retest reliability of the instrument using generalisability theory (<italic>G </italic>= 0.50) [<xref ref-type="bibr" rid="B31">31</xref>] when scores from a sample of 37 health-system policy makers, managers, professionals, citizens/consumers, and researchers participating in stakeholder dialogues convened by the McMaster Health Forum were generalised across a single administration, and even stronger reliability (<italic>G </italic>= 0.9) when scores were generalised across the average of two administrations of the tool [<xref ref-type="bibr" rid="B30">30</xref>]. In the reliability assessment by Boyko <italic>et al. </italic>(2010), the first administration of the tool immediately followed a McMaster Health Forum stakeholder dialogue, which may have promoted enthusiasm for using research evidence among participants. This likely produced higher measures of intention on the first administration of the tool as compared to the second, resulting in the lower <italic>G </italic>score. Given that we won't be administering the tool in a similar atmosphere of enthusiasm for using research evidence, we are confident in the level of reliability of the tool without two administrations at both baseline and follow-up. We modified the instrument by adding a question to measure the perceived usefulness of the intervention, as well as questions about participant characteristics.</p><p>We will administer the instrument during the baseline period, as well as at the end of the six-month intervention period, through a brief online survey that takes approximately 10 minutes to complete. We will use unique identifiers for each participant to ensure their responses to the previous survey are linked for calculations of before-and-after changes in their intention to use research evidence. We will follow up with participants who do not complete the survey once per week for three weeks to minimise the number of participants lost to follow-up.</p></sec><sec><title>Data management and analysis</title><p>Data will be entered into SPSS 16.0 (IBM Corporation, Somers, NY) after all data collection has been completed. Analyses will be conducted by two members of the research team (SH and MGW), and during the analysis, neither they nor other study investigators will have access to the key linking the participants to their unique identifiers.</p><p>We will treat both outcome measures as continuous variables and analyse the change in these measures over time using a two-way mixed-effects linear repeated-measures analysis of variance (ANOVA), with the interaction of intervention by time as the main feature of interest. In addition, we will control for four variables--past workshop attendance, position (policy analyst, senior policy analyst, or senior policy advisor), branch within the division (of which there are six), and number of years working at the MOHLTC--using analysis of covariance. Given the likelihood that the distribution of the outcomes will be skewed, we will transform the data where necessary and possible, which may include adjusting the time period for which we calculate the mean number of site visits/participant (<italic>e.g.</italic>, calculating the mean over two months) if there are insufficient data for analysis. Moreover, as part of a secondary analysis, we will assess whether there is an interaction between each of these variables (entered as a fixed factor) and the outcome measures. We will also qualitatively compare the number of participants in the intervention and control groups that do not complete the follow-up survey and assess whether their baseline characteristics can help to explain their loss to follow-up.</p><p>For all analyses, we will use the intention-to-treat principle and report 95% confidence intervals; <italic>p </italic>values equal to or less than .05 (two-tailed) will be considered significant. For the primary outcome measure (mean number of site visits/month/participant), missing data are irrelevant because it is a naturalistic measure. For the secondary outcome measure (obtained through the survey), missing data can be taken into account through the use of a mixed-effects model.</p></sec><sec><title>Statistical precision</title><p>Given a fixed sample size of at least 148 policy analysts and advisors in the division, a sample-size calculation is not relevant. Instead, we have calculated the level of statistical precision that we can expect given our fixed sample size. We had no mechanism to estimate the intraclass correlation coefficient (ICC) for measurements of the primary outcome for individuals over time. Therefore, we calculated estimates of statistical precision for ICCs of .2, .3, .5, .7, and .8 based on a six-month trial period with 80% power; an estimated standard deviation of 1.0; significance of .05; and 74 participants per study group (total n = 148, which does not include the as yet undefined number of senior policy advisors). Assuming the primary outcome data will be collected from all 148 participants at baseline and at six follow-up points (one per month), the time-averaged detectable difference (in standard deviation units) between the two groups is at best 0.27 (ICC = .2), which increases with successively greater ICCs to 0.30 (ICC = .3), 0.35 (ICC = .5), 0.40 (ICC = .7), and 0.42 (ICC = .8).</p></sec></sec><sec><title>Qualitative study methods/design</title><p>Given that this is the first RCT evaluating a KTE intervention for health-system policy makers (at least to our knowledge) and given the inherent limitations associated with measuring research use as an outcome, we will conduct a qualitative process study after the completion of the trial to explore the RCT findings in greater depth. The qualitative study will explore how and why the evidence service worked (or didn't work), including the role of past workshop attendance and position and the degree of contamination between the intervention and control groups.</p><sec><title>Sample</title><p>We will use a mixed-method sequential nested sampling procedure, whereby a larger sample is analysed in one study (RCT) and a subset of the larger sample is selected for further inquiry in the second study [<xref ref-type="bibr" rid="B32">32</xref>]. Specifically, 15 participants from each trial arm (n = 30) will be purposively sampled [<xref ref-type="bibr" rid="B33">33</xref>,<xref ref-type="bibr" rid="B34">34</xref>]. Our sampling criteria include RCT arm (<italic>i.e.</italic>, full-serve or self-serve evidence service), outcomes, past workshop attendance, position, branch within the division, and number of years working at the MOHLTC. We have assumed a 70% response rate (in keeping with our past experience with conducting qualitative studies involving health-system policy makers), which means that we should sample approximately 40 policy analysts and advisors in order to achieve a sample size of 30.</p></sec><sec><title>Data collection</title><p>One-on-one semistructured interviews will be conducted either by telephone or in person (where possible) on participants' views about and experiences with the evidence service, including whether and how they used it (and the degree of 'contamination' between the two arms of the RCT, if any) and why, whether and how it was helpful in their work and why, what aspects were most and least helpful and why, and recommendations for next steps. Potential explanatory factors (for which we will probe) include past workshop attendance, position, branch within the division, and number of years working at the MOHLTC.</p></sec><sec><title>Data management and analysis</title><p>We will tape and transcribe all interviews, use NVivo 8 (QSR International, Cambridge, MA) for data management, and use a constant comparative method for analysis [<xref ref-type="bibr" rid="B35">35</xref>-<xref ref-type="bibr" rid="B37">37</xref>]. Specifically, two reviewers will identify themes emerging from each successive wave of four to five interviews and iteratively refine the interview guide and emerging themes until we reach data saturation. This strategy will allow the reviewers to develop and refine codes and broader themes in NVivo 8 that reflect the emerging and increasing levels of nuance that result from the continuous checks that are involved in the constant comparative method [<xref ref-type="bibr" rid="B35">35</xref>,<xref ref-type="bibr" rid="B37">37</xref>]. The same reviewers will then apply the final analytic framework to all of the interview transcripts and conduct member checking once analysis is completed (<italic>i.e.</italic>, we will send a brief, structured summary of what we learned from the interviews and invite comment on it).</p></sec></sec><sec><title>Discussion</title><p>To our knowledge, this will be the first RCT to evaluate the effects of an evidence service specifically designed to support health-system policy makers in finding and using research evidence. While there have been a number of strategies developed to both support the production of policy-relevant research evidence and the identification and use of research evidence by health-system policy makers [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B38">38</xref>], rigorous evaluations of the effects of these strategies remains a critical gap in the KTE literature [<xref ref-type="bibr" rid="B38">38</xref>,<xref ref-type="bibr" rid="B39">39</xref>]. This study will begin to address this gap by providing a rigorous evaluation of the effects of a KTE intervention for policy makers and by examining how and why the intervention succeeds or fails. In addition, this trial will contribute to an emerging evidence base about similarities and differences in 'what works' in KTE across different target audiences [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B40">40</xref>].</p><p>The main potential limitation of the RCT is that it will be conducted within one division of the MOHLTC, and hence, there is the potential for contamination of study groups despite the use of a user-specific login. Given that many of the policy analysts and advisors work collaboratively, resources from the full-serve evidence service may be shared with those who had been allocated to the self-serve arm. Unfortunately, there is no mechanism to protect against this fully. However, we will adjust for variables (such as the branch in which the policy analyst is based) that may be correlated with degree of collaboration, and hence likelihood of contamination; we will measure the number of times that monthly email alerts are forwarded; and we will ask about contamination in the qualitative process study. Furthermore, if we find a significant amount of contamination through the qualitative study, it suggests that the full-serve evidence service is perceived as highly useful by those not allocated to receive it.</p></sec><sec><title>Competing interests</title><p>Three of the authors (JNL, MGW, and JMG) were involved in the development, and remain involved in the continuous updating, of Health Systems Evidence, which is the intervention being tested in the trial.</p></sec><sec><title>Authors' contributions</title><p>JNL conceived of the study, participated in its design, led its planning, and helped to draft the protocol. MGW participated in the design and planning of the study and drafted the protocol. JMG and RBH participated in the design of the study and provided feedback on drafts of the protocol. SH participated in the design of the study, supported the sample-size calculations, and provided feedback on drafts of the protocol. PR, RG, and MO provided feedback on drafts of the protocol. All authors read and approved the final manuscript.</p></sec></body><back><sec><title>Acknowledgements</title><p>The authors thank Adalsteinn Brown, Alison Paprica, and Sarah Caldwell, MOHLTC, for supporting the study and identifying ways to allow for its operationalisation. The authors also thank the MOHLTC for supporting the study financially through its grant to the Centre for Health Economics and Policy Analysis at McMaster University.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><article-title>How can we support the use of systematic reviews in policymaking?</article-title><source>PLoS Medicine</source><year>2009</year><volume>6</volume></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><name><surname>Egger</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>GD</given-names></name><name><surname>O'Rourke</surname><given-names>K</given-names></name><person-group person-group-type="editor">Egger M, Smith GD, Altman DG</person-group><article-title>Rationale, potentials, and promise of systematic reviews</article-title><source>Systematic Reviews in Health Care: Meta-Analysis in Context</source><year>2001</year><edition>Second</edition><publisher-name>London: BMJ Books</publisher-name><fpage>3</fpage><lpage>19</lpage></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Davies</surname><given-names>HTO</given-names></name><name><surname>Oxman</surname><given-names>AD</given-names></name><name><surname>Denis</surname><given-names>J-L</given-names></name><name><surname>Golden-Biddle</surname><given-names>K</given-names></name><name><surname>Ferlie</surname><given-names>E</given-names></name><article-title>Towards systematic reviews that inform health care management and policy-making</article-title><source>Journal of Health Services Research and Policy</source><year>2005</year><volume>10</volume><fpage>S1:35</fpage><lpage>S1:48</lpage></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Davies</surname><given-names>HTO</given-names></name><name><surname>Gruen</surname><given-names>RL</given-names></name><article-title>Working within and beyond the Cochrane Collaboration to make systematic reviews more useful to healthcare managers and policy makers</article-title><source>Healthcare Policy</source><year>2006</year><volume>1</volume><fpage>21</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">19305650</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Innvaer</surname><given-names>S</given-names></name><name><surname>Vist</surname><given-names>GE</given-names></name><name><surname>Trommald</surname><given-names>M</given-names></name><name><surname>Oxman</surname><given-names>AD</given-names></name><article-title>Health policy-makers' perceptions of their use of evidence: A systematic review</article-title><source>Journal of Health Services Research and Policy</source><year>2002</year><volume>7</volume><fpage>239</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1258/135581902320432778</pub-id><pub-id pub-id-type="pmid">12425783</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Haynes</surname><given-names>RB</given-names></name><name><surname>Cotoi</surname><given-names>C</given-names></name><name><surname>Holland</surname><given-names>J</given-names></name><name><surname>Walters</surname><given-names>L</given-names></name><name><surname>Wilczynski</surname><given-names>N</given-names></name><name><surname>Jedraszewski</surname><given-names>D</given-names></name><name><surname>McKinlay</surname><given-names>J</given-names></name><name><surname>Parrish</surname><given-names>R</given-names></name><name><surname>McKibbon</surname><given-names>KA</given-names></name><collab>the McMaster Premium Literature Service (PLUS) Project</collab><article-title>Second-Order Peer Review of the Medical Literature for Clinical Practitioners</article-title><source>JAMA</source><year>2006</year><volume>295</volume><fpage>1801</fpage><lpage>1808</lpage><pub-id pub-id-type="doi">10.1001/jama.295.15.1801</pub-id><pub-id pub-id-type="pmid">16622142</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Permanand</surname><given-names>G</given-names></name><name><surname>Oxman</surname><given-names>AD</given-names></name><name><surname>Lewin</surname><given-names>SA</given-names></name><name><surname>Fretheim</surname><given-names>A</given-names></name><article-title>SUPPORT Tools for evidence-informed health Policymaking (STP) 13: Preparing and using policy briefs to support evidence-informed policymaking</article-title><source>Health Research Policy and Systems</source><year>2009</year><volume>7</volume></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Oxman</surname><given-names>A</given-names></name><name><surname>Schunemann</surname><given-names>H</given-names></name><name><surname>Fretheim</surname><given-names>A</given-names></name><article-title>Improving the use of research evidence in guideline development: 8. Synthesis and presentation of evidence</article-title><source>Health Research Policy and Systems</source><year>2006</year><volume>4</volume><fpage>20</fpage><pub-id pub-id-type="doi">10.1186/1478-4505-4-20</pub-id><pub-id pub-id-type="pmid">17147809</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Shea</surname><given-names>BJ</given-names></name><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Wells</surname><given-names>GA</given-names></name><name><surname>Boers</surname><given-names>M</given-names></name><name><surname>Andersson</surname><given-names>N</given-names></name><name><surname>Hamel</surname><given-names>C</given-names></name><name><surname>Porter</surname><given-names>AC</given-names></name><name><surname>Tugwell</surname><given-names>P</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Bouter</surname><given-names>LM</given-names></name><article-title>Development of AMSTAR: A measurement tool to assess the methodological quality of systematic reviews</article-title><source>BMC Medical Research Methodology</source><year>2007</year><volume>7</volume></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="book"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Wilson</surname><given-names>MG</given-names></name><name><surname>Hammill</surname><given-names>AC</given-names></name><name><surname>Boyko</surname><given-names>JA</given-names></name><name><surname>Grimshaw</surname><given-names>J</given-names></name><name><surname>Oxman</surname><given-names>A</given-names></name><name><surname>Flottorp</surname><given-names>S</given-names></name><source>Enhancing the retrieval of systematic reviews that can inform health system management and policymaking</source><year>2009</year><publisher-name>Hamilton, Canada: Program in Policy Decision-Making</publisher-name></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Thomas</surname><given-names>RE</given-names></name><name><surname>MacLennan</surname><given-names>G</given-names></name><name><surname>Fraser</surname><given-names>C</given-names></name><name><surname>Ramsay</surname><given-names>CR</given-names></name><name><surname>Vale</surname><given-names>L</given-names></name><name><surname>Whitty</surname><given-names>P</given-names></name><name><surname>Eccles</surname><given-names>MP</given-names></name><name><surname>Matowe</surname><given-names>L</given-names></name><name><surname>Shirran</surname><given-names>L</given-names></name><etal/><article-title>Effectiveness and efficiency of guideline dissemination and implementation strategies</article-title><source>Health Technology Assessment</source><year>2004</year><volume>8</volume></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Haynes</surname><given-names>RB</given-names></name><name><surname>Holland</surname><given-names>J</given-names></name><name><surname>Cotoi</surname><given-names>C</given-names></name><name><surname>McKinlay</surname><given-names>RJ</given-names></name><name><surname>Wilczynski</surname><given-names>NL</given-names></name><name><surname>Walters</surname><given-names>LA</given-names></name><name><surname>Jedras</surname><given-names>D</given-names></name><name><surname>Parrish</surname><given-names>R</given-names></name><name><surname>McKibbon</surname><given-names>KA</given-names></name><name><surname>Garg</surname><given-names>A</given-names></name><etal/><article-title>McMaster PLUS: A cluster randomized clinical trial of an intervention to accelerate clinical use of evidence-based information from digital libraries</article-title><source>Journal of the American Medical Informatics Association</source><year>2006</year><volume>13</volume><fpage>593</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1197/jamia.M2158</pub-id><pub-id pub-id-type="pmid">16929034</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="book"><name><surname>Creswell</surname><given-names>JW</given-names></name><name><surname>Plano Clark</surname><given-names>VL</given-names></name><source>Designing and Conducting Mixed Methods Research</source><year>2007</year><publisher-name>Thousand Oaks, California: Sage</publisher-name></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Ross</surname><given-names>SE</given-names></name><name><surname>McLeod</surname><given-names>CB</given-names></name><name><surname>Gildiner</surname><given-names>A</given-names></name><article-title>Measuring the impact of health research</article-title><source>Journal of Health Services Research and Policy</source><year>2003</year><volume>8</volume><fpage>165</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1258/135581903322029520</pub-id><pub-id pub-id-type="pmid">12869343</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><article-title>Ideas at the margin or marginalized ideas? Nonmedical determinants of health in Canada</article-title><source>Health Affairs</source><year>2002</year><volume>21</volume><fpage>107</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1377/hlthaff.21.2.107</pub-id><pub-id pub-id-type="pmid">11900150</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Ross</surname><given-names>SE</given-names></name><name><surname>Hurley</surname><given-names>JE</given-names></name><name><surname>Hohenadel</surname><given-names>JM</given-names></name><name><surname>Stoddart</surname><given-names>GL</given-names></name><name><surname>Woodward</surname><given-names>CA</given-names></name><name><surname>Abelson</surname><given-names>J</given-names></name><article-title>Examining the role of health services research in public policymaking</article-title><source>Milbank Quarterly</source><year>2002</year><volume>80</volume><fpage>125</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1111/1468-0009.00005</pub-id><pub-id pub-id-type="pmid">11933791</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><name><surname>Lavis</surname><given-names>JN</given-names></name><person-group person-group-type="editor">Lemieux-Charles L, Champagne F</person-group><article-title>A political science perspective on evidence-based decision-making</article-title><source>Using knowledge and evidence in health care: Multidisciplinary perspectives</source><year>2004</year><publisher-name>Toronto, Canada: University of Toronto Press</publisher-name><fpage>70</fpage><lpage>85</lpage></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><article-title>Research, public policymaking, and knowledge-translation processes: Canadian efforts to build bridges</article-title><source>The Journal of Continuing Education in the Health Professions</source><year>2006</year><volume>26</volume><fpage>37</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1002/chp.49</pub-id><pub-id pub-id-type="pmid">16557509</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><name><surname>Foy</surname><given-names>R</given-names></name><name><surname>MacLennan</surname><given-names>G</given-names></name><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Penney</surname><given-names>G</given-names></name><name><surname>Campbell</surname><given-names>M</given-names></name><name><surname>Grol</surname><given-names>RP</given-names></name><article-title>Attributes of clinical recommendations that influence change in practice following audit and feedback</article-title><source>Journal of Clinical Epidemiology</source><year>2002</year><volume>55</volume><fpage>17</fpage><lpage>22</lpage></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Grilli</surname><given-names>R</given-names></name><name><surname>Lomas</surname><given-names>J</given-names></name><article-title>Evaluating the message: The relationship between compliance rate and the subject of a practice guideline</article-title><source>Medical Care</source><year>1994</year><volume>32</volume><fpage>202</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1097/00005650-199403000-00002</pub-id><pub-id pub-id-type="pmid">8145598</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Grol</surname><given-names>R</given-names></name><name><surname>Dalhuijsen</surname><given-names>J</given-names></name><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Veld</surname><given-names>C</given-names></name><name><surname>Rutten</surname><given-names>G</given-names></name><name><surname>Mokkink</surname><given-names>H</given-names></name><article-title>Attributes of clinical guidelines that influence use of guidelines in general practice: Observational study</article-title><source>British Medical Journal</source><year>1998</year><volume>317</volume><fpage>858</fpage><lpage>861</lpage><pub-id pub-id-type="pmid">9748183</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Ajzen</surname><given-names>I</given-names></name><article-title>The theory of planned behaviour</article-title><source>Organizational Behavior and Human Decision Processes</source><year>1991</year><volume>50</volume><fpage>179</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/0749-5978(91)90020-T</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="book"><name><surname>Francis</surname><given-names>JJ</given-names></name><name><surname>Eccles</surname><given-names>MP</given-names></name><name><surname>Johnston</surname><given-names>M</given-names></name><name><surname>Walker</surname><given-names>A</given-names></name><name><surname>Grimshaw</surname><given-names>J</given-names></name><name><surname>Foy</surname><given-names>R</given-names></name><name><surname>Kaner</surname><given-names>EFS</given-names></name><name><surname>Smith</surname><given-names>L</given-names></name><name><surname>Bonetti</surname><given-names>D</given-names></name><source>Constructing Questionnaires Based on the Theory of Planned Behaviour: A Manual for Health Services Researchers</source><year>2004</year><publisher-name>Newcastle upon Tyne, England: Centre for Health Services Research, University of Newcastle</publisher-name></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Armitage</surname><given-names>CJ</given-names></name><name><surname>Conner</surname><given-names>M</given-names></name><article-title>Efficacy of the theory of planned behaviour: A meta-analytic review</article-title><source>British Journal of Social Psychology</source><year>2001</year><volume>40</volume><fpage>471</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.1348/014466601164939</pub-id><pub-id pub-id-type="pmid">11795063</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><name><surname>Sheeran</surname><given-names>P</given-names></name><person-group person-group-type="editor">Strobe W, Hewscone M</person-group><article-title>Intention-behavior relations: A conceptual and empirical review</article-title><source>European Review of Social Psychology</source><year>2002</year><publisher-name>Chichester, England: John Wiley &#x00026; Sons, Ltd</publisher-name><fpage>1</fpage><lpage>36</lpage></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>Bonetti</surname><given-names>D</given-names></name><name><surname>Pitts</surname><given-names>NB</given-names></name><name><surname>Eccles</surname><given-names>M</given-names></name><name><surname>Grimshaw</surname><given-names>J</given-names></name><name><surname>Johnston</surname><given-names>M</given-names></name><name><surname>Steen</surname><given-names>N</given-names></name><name><surname>Glidewell</surname><given-names>L</given-names></name><name><surname>Thomas</surname><given-names>R</given-names></name><name><surname>MacLennan</surname><given-names>G</given-names></name><name><surname>Clarkson</surname><given-names>JE</given-names></name><etal/><article-title>Applying psychological theory to evidence-based clinical practice: Identifying factors predictive of taking intra-oral radiographs</article-title><source>Soc Sci Med</source><year>2006</year><volume>63</volume><fpage>1889</fpage><lpage>1899</lpage><pub-id pub-id-type="doi">10.1016/j.socscimed.2006.04.005</pub-id><pub-id pub-id-type="pmid">16843579</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Walker</surname><given-names>A</given-names></name><name><surname>Watson</surname><given-names>M</given-names></name><name><surname>Grimshaw</surname><given-names>J</given-names></name><name><surname>Bond</surname><given-names>C</given-names></name><article-title>Applying the theory of planned behaviour to pharmacists' beliefs and intentions about the treatment of vaginal candidiasis with non-prescription medicines</article-title><source>Family Practice</source><year>2004</year><volume>21</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1093/fampra/cmh101</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><name><surname>Walker</surname><given-names>AE</given-names></name><name><surname>Grimshaw</surname><given-names>JM</given-names></name><name><surname>Armstrong</surname><given-names>EM</given-names></name><article-title>Salient beliefs and intentions to prescribe antibiotics for patients with a sore throat</article-title><source>British Journal of Health Psychology</source><year>2001</year><volume>6</volume><fpage>347</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1348/135910701169250</pub-id><pub-id pub-id-type="pmid">12614509</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Eccles</surname><given-names>MP</given-names></name><name><surname>Hrisos</surname><given-names>S</given-names></name><name><surname>Francis</surname><given-names>J</given-names></name><name><surname>kaner</surname><given-names>EF</given-names></name><name><surname>Dickinson</surname><given-names>HO</given-names></name><name><surname>Beyer</surname><given-names>F</given-names></name><name><surname>Johnston</surname><given-names>M</given-names></name><article-title>Do self-reported intentions predict clinicians' behaviour: A systematic review</article-title><source>Implementation Science</source><year>2006</year><volume>1</volume><fpage>28</fpage><pub-id pub-id-type="doi">10.1186/1748-5908-1-28</pub-id><pub-id pub-id-type="pmid">17118180</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book"><name><surname>Boyko</surname><given-names>JA</given-names></name><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Souza</surname><given-names>NM</given-names></name><source>Reliability of a Tool for Measuring Theory of Planned Behaviour Constructs for use in Evaluating Research Use in Policymaking</source><year>2010</year><publisher-name>Hamilton, Canada: McMaster University</publisher-name></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="book"><name><surname>Streiner</surname><given-names>DL</given-names></name><name><surname>Norman</surname><given-names>G</given-names></name><source>Health Measurement Scales: A Practical Guide to their Development and Use</source><year>2008</year><publisher-name>New York, USA: Oxford University Press</publisher-name></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Collins</surname><given-names>KMT</given-names></name><name><surname>Onwuegbuzie</surname><given-names>AJ</given-names></name><name><surname>Jiao</surname><given-names>QG</given-names></name><article-title>A mixed methods investigation of mixed methods sampling designs in social and health science research</article-title><source>Journal of Mixed Methods Research</source><year>2007</year><volume>1</volume><fpage>267</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1177/1558689807299526</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="book"><name><surname>Patton</surname><given-names>M</given-names></name><source>Qualitative Evaluation and Research Methods</source><year>1990</year><publisher-name>Beverly Hills, USA: Sage</publisher-name></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><name><surname>Sandelowski</surname><given-names>M</given-names></name><article-title>Combining qualitative and quantitative sampling, data collection, and analysis techniques in mixed-method studies</article-title><source>Research in Nursing &#x00026; Health</source><year>2000</year><volume>23</volume><fpage>246</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1002/1098-240X(200006)23:3&#x0003c;246::AID-NUR9&#x0003e;3.0.CO;2-H</pub-id><pub-id pub-id-type="pmid">10871540</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><name><surname>Boeije</surname><given-names>H</given-names></name><article-title>A purposeful approach to the constant comparative methods in the analysis of qualitative interviews</article-title><source>Quality &#x00026; Quantity</source><year>2002</year><volume>36</volume><fpage>391</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1023/A:1020909529486</pub-id><pub-id pub-id-type="pmid">21623610</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><name><surname>Creswell</surname><given-names>JW</given-names></name><source>Qualitative Inquiry and Research Design: Choosing Among Five Traditions</source><year>1998</year><publisher-name>London, England: Sage Publications</publisher-name></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><name><surname>Pope</surname><given-names>C</given-names></name><name><surname>Ziebland</surname><given-names>S</given-names></name><name><surname>Mays</surname><given-names>N</given-names></name><article-title>Qualitative research in health care: Analysing qualitative data</article-title><source>BMJ</source><year>2000</year><volume>320</volume><fpage>114</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1136/bmj.320.7227.114</pub-id><pub-id pub-id-type="pmid">10625273</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><name><surname>Lavis</surname><given-names>JN</given-names></name><name><surname>Lomas</surname><given-names>J</given-names></name><name><surname>Hamid</surname><given-names>M</given-names></name><name><surname>Sewankambo</surname><given-names>NK</given-names></name><article-title>Assessing country-level efforts to link research to action</article-title><source>Bulletin of the World Health Organization</source><year>2006</year><volume>84</volume><fpage>620</fpage><lpage>628</lpage><pub-id pub-id-type="doi">10.2471/BLT.06.030312</pub-id><pub-id pub-id-type="pmid">16917649</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><name><surname>Mitton</surname><given-names>C</given-names></name><name><surname>Adair</surname><given-names>CE</given-names></name><name><surname>McKenzie</surname><given-names>E</given-names></name><name><surname>Patten</surname><given-names>SB</given-names></name><name><surname>Wayne Perry</surname><given-names>B</given-names></name><article-title>Knowledge transfer and exchange: Review and synthesis of the literature</article-title><source>Milbank Quarterly</source><year>2007</year><volume>85</volume><fpage>729</fpage><lpage>768</lpage><pub-id pub-id-type="doi">10.1111/j.1468-0009.2007.00506.x</pub-id><pub-id pub-id-type="pmid">18070335</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><name><surname>Dobbins</surname><given-names>M</given-names></name><name><surname>Robeson</surname><given-names>P</given-names></name><name><surname>Ciliska</surname><given-names>D</given-names></name><name><surname>Hanna</surname><given-names>S</given-names></name><name><surname>Cameron</surname><given-names>R</given-names></name><name><surname>O'Mara</surname><given-names>L</given-names></name><name><surname>DeCorby</surname><given-names>K</given-names></name><name><surname>Mercer</surname><given-names>S</given-names></name><article-title>A description of a knowledge broker role implemented as part of a randomized controlled trial evaluating three knowledge translation strategies</article-title><source>Implementation Science</source><year>2009</year><volume>4</volume><fpage>23</fpage><pub-id pub-id-type="doi">10.1186/1748-5908-4-23</pub-id><pub-id pub-id-type="pmid">19397820</pub-id></mixed-citation></ref></ref-list></back></article>