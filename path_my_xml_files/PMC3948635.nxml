<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMJ Open</journal-id><journal-id journal-id-type="iso-abbrev">BMJ Open</journal-id><journal-id journal-id-type="hwp">bmjopen</journal-id><journal-id journal-id-type="publisher-id">bmjopen</journal-id><journal-title-group><journal-title>BMJ Open</journal-title></journal-title-group><issn pub-type="epub">2044-6055</issn><publisher><publisher-name>BMJ Publishing Group</publisher-name><publisher-loc>BMA House, Tavistock Square, London, WC1H 9JR</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">24604483</article-id><article-id pub-id-type="pmc">3948635</article-id><article-id pub-id-type="publisher-id">bmjopen-2013-004339</article-id><article-id pub-id-type="doi">10.1136/bmjopen-2013-004339</article-id><article-categories><subj-group subj-group-type="heading"><subject>Medical Education and Training</subject><subj-group><subject>Research</subject></subj-group></subj-group><subj-group subj-group-type="hwp-journal-coll"><subject>1506</subject><subject>1709</subject><subject>1696</subject><subject>1704</subject><subject>1722</subject></subj-group></article-categories><title-group><article-title>Assessing communication quality of consultations in primary care: initial reliability of the Global Consultation Rating Scale, based on the Calgary-Cambridge Guide to the Medical Interview</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Burt</surname><given-names>Jenni</given-names></name><xref ref-type="aff" rid="af1">1</xref><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0037-274X</contrib-id></contrib><contrib contrib-type="author"><name><surname>Abel</surname><given-names>Gary</given-names></name><xref ref-type="aff" rid="af1">1</xref></contrib><contrib contrib-type="author"><name><surname>Elmore</surname><given-names>Natasha</given-names></name><xref ref-type="aff" rid="af1">1</xref></contrib><contrib contrib-type="author"><name><surname>Campbell</surname><given-names>John</given-names></name><xref ref-type="aff" rid="af2">2</xref></contrib><contrib contrib-type="author"><name><surname>Roland</surname><given-names>Martin</given-names></name><xref ref-type="aff" rid="af1">1</xref></contrib><contrib contrib-type="author"><name><surname>Benson</surname><given-names>John</given-names></name><xref ref-type="aff" rid="af3">3</xref></contrib><contrib contrib-type="author"><name><surname>Silverman</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="af4">4</xref></contrib></contrib-group><aff id="af1"><label>1</label><institution>Cambridge Centre for Health Services Research, University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>UK</country></aff><aff id="af2"><label>2</label><institution>University of Exeter Medical School, University of Exeter</institution>, <addr-line>Exeter</addr-line>, <country>UK</country></aff><aff id="af3"><label>3</label><addr-line>Primary Care Unit</addr-line>, <institution>University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>UK</country></aff><aff id="af4"><label>4</label><institution>School of Clinical Medicine</institution>, <institution>University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>UK</country></aff><author-notes><corresp><label>Correspondence to</label> Dr Jenni Burt; <email>jab35@medschl.cam.ac.uk</email></corresp></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>6</day><month>3</month><year>2014</year></pub-date><volume>4</volume><issue>3</issue><elocation-id>e004339</elocation-id><history><date date-type="received"><day>25</day><month>10</month><year>2013</year></date><date date-type="rev-recd"><day>29</day><month>1</month><year>2014</year></date><date date-type="accepted"><day>13</day><month>2</month><year>2014</year></date></history><permissions><copyright-statement>Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions</copyright-statement><copyright-year>2014</copyright-year><license license-type="open-access"><license-p>This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 3.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link></license-p></license></permissions><self-uri xlink:title="pdf" xlink:type="simple" xlink:href="bmjopen-2013-004339.pdf"/><self-uri content-type="draft-revisions-pdf" xlink:type="simple" xlink:href="bmjopen-2013-004339.draft_revisions.pdf"/><self-uri content-type="reviewers-comments-pdf" xlink:type="simple" xlink:href="bmjopen-2013-004339.reviewer_comments.pdf"/><abstract><sec><title>Objectives</title><p>To investigate initial reliability of the Global Consultation Rating Scale (GCRS: an instrument to assess the effectiveness of communication across an entire doctor&#x02013;patient consultation, based on the Calgary-Cambridge guide to the medical interview), in simulated patient consultations.</p></sec><sec><title>Design</title><p>Multiple ratings of simulated general practitioner (GP)&#x02013;patient consultations by trained GP evaluators.</p></sec><sec><title>Setting</title><p>UK primary care.</p></sec><sec><title>Participants</title><p>21 GPs and six trained GP evaluators.</p></sec><sec><title>Outcome measures</title><p>GCRS score.</p></sec><sec><title>Methods</title><p>6 GP raters used GCRS to rate randomly assigned video recordings of GP consultations with simulated patients. Each of the 42 consultations was rated separately by four raters. We considered whether a fixed difference between scores had the same meaning at all levels of performance. We then examined the reliability of GCRS using mixed linear regression models. We augmented our regression model to also examine whether there were systematic biases between the scores given by different raters and to look for possible order effects.</p></sec><sec><title>Results</title><p>Assessing the communication quality of individual consultations, GCRS achieved a reliability of 0.73 (95% CI 0.44 to 0.79) for two raters, 0.80 (0.54 to 0.85) for three and 0.85 (0.61 to 0.88) for four. We found an average difference of 1.65 (on a 0&#x02013;10 scale) in the scores given by the least and most generous raters: adjusting for this evaluator bias increased reliability to 0.78 (0.53 to 0.83) for two raters; 0.85 (0.63 to 0.88) for three and 0.88 (0.69 to 0.91) for four. There were considerable order effects, with later consultations (after 15&#x02013;20 ratings) receiving, on average, scores more than one point higher on a 0&#x02013;10 scale.</p></sec><sec><title>Conclusions</title><p>GCRS shows good reliability with three raters assessing each consultation. We are currently developing the scale further by assessing a large sample of real-world consultations.</p></sec></abstract><kwd-group><kwd>Statistics &#x00026; Research Methods</kwd><kwd>Medical Education &#x00026; Training</kwd></kwd-group></article-meta></front><body><boxed-text position="float"><caption><title>Strengths and limitations of this study</title></caption><list list-type="bullet"><list-item><p>The Global Consultation Rating Scale (GCRS) is based on the widely used Calgary-Cambridge guide to the medical interview, and is designed to evaluate a practitioner's communication skills across an entire consultation, linking the identification of potential training needs to an established approach to teaching communication skills.</p></list-item><list-item><p>We considered evaluator bias and order effects to obtain a more robust assessment of the reliability of GCRS to evaluate communication competence within a particular consultation.</p></list-item><list-item><p>A particular limitation is that our findings are based on the use of simulated patient consultations. This had an impact on our ability to assess the performance of GCRS to evaluate communication competence of individual doctors, rather than particular consultations. A full evaluation of the performance of GCRS requires the assessment of real-world consultations and we are undertaking this at present.</p></list-item></list></boxed-text><sec id="s1"><title>Introduction</title><p>During the past 30&#x02005;years, an extensive research literature has defined the skills that enhance communication between doctor and patient. This evidence demonstrates the essential role that communication plays in high-quality healthcare by enabling more accurate, efficient and supportive interviews, by enhancing patient and professional experience and by improving health outcomes for patients. The use of specific communication skills has been shown to lead to improvements in symptom relief, in clinical outcomes and possibly in medicine adherence.<xref rid="R1" ref-type="bibr">1&#x02013;6</xref> In light of these findings, there has been increasing pressure from professional medical bodies to improve the training and evaluation of doctors in communication.<xref rid="R7" ref-type="bibr">7&#x02013;13</xref></p><p>In order to evaluate doctors&#x02019; communication skills effectively, tools with solid theoretical grounding and good psychometric properties are required. Various rating scales exist to assess doctor&#x02013;patient consultations, which vary widely in their setting, approach and in the published details of their psychometric properties.<xref rid="R14" ref-type="bibr">14</xref>
<xref rid="R15" ref-type="bibr">15</xref> Perhaps for these reasons, none have become standard to use within the National Health Service (NHS), in spite of National Institute for Health and Care Excellence (NICE) standards which require that &#x0201c;Patients experience effective interactions with staff who have demonstrated competency in relevant communication skills.&#x0201d;<xref rid="R16" ref-type="bibr">16</xref> Recently, there has been a move towards domain, or global, marking schemes (awarding overall marks to groupings of items) rather than itemised checklists, the suggestion being that checklists may reward thoroughness rather than competence and work better for novices than for experts.<xref rid="R17" ref-type="bibr">17</xref> Global marking schemes may be more useful in postgraduate assessments, improving professional authenticity. We have, therefore, developed the Global Consultation Rating Scale (GCRS), based on the Calgary-Cambridge guide to the medical interview, to evaluate the communication effectiveness of an entire doctor&#x02013;patient consultation, using the domain marking approach.</p><p>At present, there is a dearth of assessment tools that robustly measure the overall communication skills of an individual general practitioner (GP) in real-world practice. While a number of existing tools may be used to assess doctor&#x02013;patient communication, their suitability to assess a doctor's overall communication skills in day-to-day practice irrespective of the content of the consultation is limited and they do not link specifically to educational material commonly used in the UK for subsequent communication skills development. GCRS differs from some alternative instruments, such as the MAAS-Global, in its aim of measuring communication skills only, irrespective of clinical content, to provide an assessment of doctors&#x02019; generic communication skills and to thereby enable targeted communication teaching. For example, 4 of the 17 items in the MAAS-Global specifically assess medical content related to history, examination, diagnosis and management and other communication items are highly specific to particular content areas.<xref rid="R18" ref-type="bibr">18</xref> In comparison, the 12 global areas of GCRS include only communication process skills without content. Following the approach of the Calgary-Cambridge guide from which it is derived, GCRS takes the standpoint that, although the context of the interaction changes and the content of the communication varies, the process skills themselves remain the same and can be evaluated independently. This, together with domain rather than individual skill marking, enables the assessment of communication skills across a wide variety of consultations, especially helpful in real-world consultations where communication checklists cannot be specific and tailored for each case.</p><p>The Calgary-Cambridge guide to the medical interview<xref rid="R1" ref-type="bibr">1</xref>
<xref rid="R19" ref-type="bibr">19&#x02013;21</xref> was developed by Silverman, Kurtz and Draper to delineate effective physician&#x02013;patient communication skills and to provide an evidence-based structure for their analysis and teaching. Within the UK, over half of UK medical schools now use the Calgary-Cambridge approach in their communication skills programmes.<xref rid="R22" ref-type="bibr">22</xref> It has been widely translated and is used in the USA, Canada and Europe. It has been used to teach communication in general practice and specialist environments, at undergraduate and postgraduate levels.</p><p>Specific tools have been developed from the guide for the assessment of medical students, practising paediatricians, dentists, pharmacists and veterinary practitioners, as well as for specific components of the consultation such as explanation and planning in OSCE style examinations.<xref rid="R23" ref-type="bibr">23&#x02013;25</xref> Before now however, there has been no validated method of using the Calgary-Cambridge consultation guide to assess complete consultations between qualified doctors and patients. This type of assessment is particularly important in postgraduate and continuing medical education in which the observation of whole consultations from real practice provides increased validity. In addition, for personal development and annual appraisal, a reliable validated assessment tool which also enables a specific link to targeted teaching of communication skills is particularly relevant. Our intention with GCRS is to develop an instrument capable of credibly evaluating a doctor's communication competence, identifying potential areas for improvement which could then be addressed directly with linked, tailored education, using the Calgary-Cambridge guide.</p><p>The aim of this study was to investigate the initial reliability of GCRS in simulated patient consultations such as those which might be used in training, as a precursor to its use with real patient consultations where GPs are assessed on their performance. To assess reliability, we asked five specific questions. These are detailed below, together with the reasons for their investigation:
<list list-type="alpha-upper"><list-item><p>Does a fixed difference between scores in GCRS have the same meaning at all levels of performance? If it does not, GCRS scores may not be useful for distinguishing between performance uniformly at all levels of performance, and could require transformation prior to analysis.</p></list-item><list-item><p>What is the reliability of GCRS in assessing individual consultations (with different numbers of raters per consultation)? One of two core questions: how consistently does GCRS perform in evaluating communication skills within a particular consultation, and how many raters are required to obtain performance estimates we are confident distinguish better from worse consultations?</p></list-item><list-item><p>What is the reliability of GCRS in assessing individual doctors&#x02019; performance across a number of consultations (with different numbers of raters and consultations per doctor)? The second core question: how many consultations, and how many raters, do we need to evaluate a particular doctors&#x02019; consultation skills such that we can differentiate them from their peers?</p></list-item><list-item><p>Are some raters more generous than others in their assessments of consultations? Wide variation between the scores assigned by raters can lead to reduced reliability. Understanding whether systematic biases are present helps to inform whether to adjust reliability estimates for these or not.</p></list-item><list-item><p>Does the order in which a consultation is rated affect the score? Psychological experiments have shown that the order in which information is presented can influence the way in which that information is processed.<xref rid="R26" ref-type="bibr">26</xref> Sequential order biases may present themselves either as an overall increase or decrease in scores throughout a judging period; or as observable effects of implicit comparisons being made between the previous and current items being judged.<xref rid="R27" ref-type="bibr">27</xref>
<xref rid="R28" ref-type="bibr">28</xref> Thus, a GCRS rater may use norm-based rather than criterion-based referencing when assigning scores as they proceed through the consultations being evaluated.</p></list-item></list></p></sec><sec sec-type="methods" id="s2"><title>Methods</title><p>Trained GP raters watched video recordings of consultations between volunteer GPs and simulated patients and completed GCRS for each. We used videos from a previous study investigating the way in which GPs discussed taking statins to prevent cardiovascular disease with simulated patients trained to play one of two roles. The two roles differed in the extent of the actor's assertiveness in asking questions about proposed management. Both roles displayed sufficient cardiovascular risk to be eligible for statins according to current NICE recommendations. Actors were experienced in playing the role of simulated patients. They were provided with a detailed written role description, including notes on their intended style of response to questions. Actors rehearsed their roles before undertaking videotaped simulations with participant GPs. GPs (n=23) selected for recruitment to the original study varied in age, gender, length of time since qualification and nature of practice (location, size and involvement with dispensing or training). They were recruited from four primary care trusts across the East of England (Cambridge, Luton, Bedford and Peterborough). Each GP conducted two consultations in their practice (one with each simulated patient), furnished with the results of appropriate medical investigations for the simulated patient. The purpose of the consultation was, from the perspective of GP and patient, to discuss the possibility of starting statin medication. This generated a total of 46 recorded consultations. For this study, we excluded videos from two GPs: one had since become a trained GP GCRS evaluator, while the videos for the second were damaged (see online supplementary appendix 1 figure S1). This left 42 videoed consultations for assessment. All GPs gave their written consent for the re-use of their videos.</p><sec id="s2a"><title>Global Consultation Rating Scale</title><p>The GCRS covers 12 domains from &#x02018;initiating the session&#x02019; to &#x02018;closure&#x02019; (see online supplementary appendix 3 for the full scale). Guidance is given within the text of the scale as to the nature of the skills that are assessed within each individual domain, which is given a score as follows: Not applicable (not scored)
<list list-type="bullet"><list-item><p>Not done/poor</p></list-item><list-item><p>Adequate</p></list-item><list-item><p>Good</p></list-item></list></p><p>The use of a three-point scale, while narrow, (1) enables a clear focus on identifying the likely need for targeted training in that area and (2) reflects the need for a simple and easy-to-use scale suitable for use while observing a consultation. A total consultation score between 0 and 24 is obtained by summing the scores from the 12 domains. In the case where a domain is considered to be not applicable, scores are renormalised to be out of 24, for example, a score of 12 out of 22 would become a score of 13.1 (=12&#x000d7;24/22) out of 24 (NB: this was not required in this study).</p></sec><sec id="s2b"><title>GP raters</title><p>We recruited six GP raters experienced in teaching and assessing communication skills using the Calgary-Cambridge consultation guide within the School of Clinical Medicine, University of Cambridge. All attended a 2&#x02005;h training session on the use of GCRS with JS, which included a specially created training video of consultations for evaluation. In training, particular attention was paid to the differences between &#x02018;good&#x02019;, &#x02018;adequate&#x02019; and &#x02018;poor&#x02019; communication behaviours, guided by the criterion referenced norms established by the Calgary-Cambridge guide. The aim was to establish a shared understanding of expected standards of behaviour across each domain.<xref rid="R29" ref-type="bibr">29</xref> Following training, each evaluator rated 28 videos. These were randomly assigned and provided in a random order for rating. Randomisation was performed with maximum cross over between raters to allow study of possible order effects (see online supplementary appendix for further details).</p><p>GP raters were requested to complete evaluations within 1&#x02005;month of collecting the videos and were paid for their time. On receipt of ratings some missing domain scores were noted (19 of 2184, 0.87%). The five raters who had missed scores watched the corresponding videos again and filled in the missing sections only. Double data entry was conducted (NE, GA) for all ratings. For the four scores (0.20%), in which there was inconsistency, the original score sheets were consulted to obtain the correct score.</p></sec><sec id="s2c"><title>Statistical analysis</title><p>The overall aim of this work was to estimate the statistical reliability of GCRS as a tool to assess consultations or doctors. Statistical reliability is an index of how well better performance can be distinguished from worse performance, and estimates how much of the variation in scores is due to true variation in performance rather than to noise due to different raters rating the same consultation differently. A reliability of 1 indicates that all the variation in measured scores is due to true variation in performance, that is, that scores are perfectly reliable. A reliability of 0 indicates that all the variation in measured scores is due to statistical noise. Between these two extremes, a reliability of 0.8 is generally considered the minimum required for most applications.<xref rid="R30" ref-type="bibr">30</xref></p><sec id="s2c1"><title>Does a fixed difference between scores in GCRS have the same meaning at all levels of performance?</title><p>One of the key assumptions made when calculating reliability is that measurement errors are independent of the true values. When this is not true a single reliability value cannot apply to all scores. Another way of thinking of this is that we require a fixed difference between two scores (eg, a two point difference) to have the same distinguishing quality across the full range of scores. For this to be true, the variability in raters&#x02019; scores of the same consultation must be the same at all levels of performance. We checked this by plotting the SD of ratings for each consultation against the mean score for that consultation (a variation on the standard Bland-Altman plot, allowing for more than two ratings per consultation). We found that the variance was not the same across all mean scores, implying that, for raw scores, a fixed difference does not have the same meaning at all levels of performance. We, therefore, sought a transformation to stabilise the variance across all mean scores. The transformed data were used for all further analysis.</p></sec><sec id="s2c2"><title>What is the reliability of GCRS for assessing single consultations?</title><p>Our experimental setup allowed us to distinguish between three different sources of variance:
<list list-type="order"><list-item><p>differing performance between doctors</p></list-item><list-item><p>differing performance of the same doctor between consultations, and</p></list-item><list-item><p>differing evaluator scores of the same consultation</p></list-item></list></p><p>In order to calculate the crude reliability, we fitted a three-level linear regression model to reflect this, with no fixed effects and with random intercepts for consultation and doctor (ie, rating nested within consultation further nested within doctor). From such a model we can estimate the reliability that would be achieved for assessing single consultations with different numbers of raters (see online supplementary appendix). The same analysis was performed on the scores for each of the individual domain of GCRS.</p></sec><sec id="s2c3"><title>What is the reliability of GCRS in assessing individual doctors&#x02019; performance across a number of consultations?</title><p>Using the same approach, we can also estimate the reliability of GCRS for assessing doctor's performance using different numbers of raters to assess each doctor, and using different numbers of consultations per doctor (see online supplementary appendix).</p></sec><sec id="s2c4"><title>Are some raters more generous than others in their assessments of consultations?</title><p>In order to establish whether there were systematic biases between the scores given by different raters, we augmented the model described above with fixed effects for raters. If present, biases between raters will increase the variation in scores, and in turn reduce the reliability of scores. The systematic biases between raters could be accounted for, and we estimated adjusted reliabilities after doing so.</p></sec><sec id="s2c5"><title>Does the order in which a consultation is rated affect the score?</title><p>Finally, to investigate possible order effects we included the order of rating in the above model. To account for non-linear effects we used a restricted cubic spline with three knots. We excluded data from one evaluator in this analysis because they had not rated the consultations in the order requested.</p><p>CIs on all estimates were calculated using bias corrected bootstrapping with 1000 repetitions and resampling at the doctor level.</p><p>The approach outlined above falls somewhere between classical reliability studies in which only one source of variance is identified (eg, inter-rater reliability) and a generalisability theory approach.<xref rid="R31" ref-type="bibr">31</xref> However, due to the limited data available we feel the approach taken is the most appropriate, and further it allows a more nuanced investigation of order effects considering non-linear functions.</p><p>Statistical analysis was conducted using Stata V.11.2.</p></sec></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>The distribution of mean scores for the 42 consultations assessed (untransformed on a 0&#x02013;24 scale) is shown in <xref ref-type="fig" rid="BMJOPEN2013004339F1">figure 1</xref>A. The highest mean consultation score was 16.25 of 24 and the lowest 1.5.</p><fig id="BMJOPEN2013004339F1" position="float"><label>Figure&#x000a0;1</label><caption><p>Histograms showing the distribution of mean consultation scores on the native (possible values 0 to 24) scale (A) and transformed (possible values 0 to 10) scale (B). Bland-Altman plot of consultation ratings shown on the native scale (C) and transformed scale (D).</p></caption><graphic xlink:href="bmjopen2013004339f01"/></fig><sec id="s3a"><title/><sec id="s3a1"><title>Does a fixed difference in GCRS have the same meaning at all levels of performance?</title><p><xref ref-type="fig" rid="BMJOPEN2013004339F1">Figure&#x000a0;1</xref>C shows the Bland-Altman type plot for the untransformed data. There was a clear trend of increasing SD of scores for each consultation with increasing mean score. This implies that there was a higher degree of agreement between raters at low scores than at the moderate scores (10&#x02013;14) which form the upper end of our data set. We found that a transformation based on the logit function performed reasonably well at stabilising the variance (see online supplementary appendix for details and lookup table). The transformation has been constructed such that the transformed scores lie between 0 and 10. The distribution of the transformed scores is shown in <xref ref-type="fig" rid="BMJOPEN2013004339F1">figure 1</xref>B.</p><p>The resulting Bland-Altman plot of transformed data is shown in <xref ref-type="fig" rid="BMJOPEN2013004339F1">figure 1</xref>D in which there is little indication of a trend (note that the increase in spread of SDs is due to the possible values available and is not considered to be a major issue). All further results relate to the transformed data.</p></sec><sec id="s3a2"><title>What is the reliability of GCRS in assessing single consultations, and in assessing individual doctors&#x02019; performance?</title><p>The SDs for the three sources of variation estimated from the crude mixed model (with no adjustment for rater bias) are shown in <xref ref-type="table" rid="BMJOPEN2013004339TB1">table 1</xref>. The largest SD was that for between doctors, implying that this is where the largest variation is seen. The SD of scores of the same consultation by different raters was slightly smaller than that attributed to between doctors&#x02019; performance. Finally, the estimates suggested that variation at the consultation level within individual doctors was essentially zero (SD=1.03&#x000d7;10<sup>&#x02212;9</sup>). This finding is likely to be a function of our dataset. We do not present any reliability estimates for rating doctors here, and outline the reasons for this in the discussion. The reliability estimates for rating consultations for different numbers of raters are shown in <xref ref-type="table" rid="BMJOPEN2013004339TB2">table 2</xref>. In the crude model, the commonly used reliability thresholds of 0.7 (modest), 0.8 (acceptable) and 0.9 (excellent) were achieved using two, three and seven raters, respectively.<xref rid="R30" ref-type="bibr">30</xref> With four raters, as used in this study, we achieved a reliability of 0.85 (95% CI 0.61 to 0.88). Details of the distribution of scores and the reliabilities of individual domains are available in online supplementary appendix figure S2 and online supplementary appendix table S2. These indicate that four raters would be sufficient to provide a broad indication of domains where a doctor may have some performance issues.</p><table-wrap id="BMJOPEN2013004339TB1" position="float"><label>Table&#x000a0;1</label><caption><p>SDs estimated for the three sources of variation from a crude model and one adjusting for systematic bias between raters</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="char" char="." span="1"/><col align="char" char="." span="1"/></colgroup><thead valign="bottom"><tr><th rowspan="1" colspan="1"/><th align="left" colspan="2" rowspan="1">SD<hr/></th></tr><tr><th align="left" rowspan="1" colspan="1">Source of variation</th><th align="left" rowspan="1" colspan="1">Crude model</th><th align="left" rowspan="1" colspan="1">Model adjusted for evaluator bias</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Between doctors</td><td rowspan="1" colspan="1">1.21 (0.87, 1.38)</td><td rowspan="1" colspan="1">1.18 (0.87, 1.33)</td></tr><tr><td rowspan="1" colspan="1">Within doctors and between consultations</td><td rowspan="1" colspan="1">1.03&#x000d7;10<sup>&#x02212;9</sup> (7.25&#x000d7;10<sup>&#x02212;13</sup>, 1.95&#x000d7;10<sup>&#x02212;9</sup>)</td><td rowspan="1" colspan="1">0.14 (0.00, 0.15)</td></tr><tr><td rowspan="1" colspan="1">Within consultations and between raters</td><td rowspan="1" colspan="1">1.03 (0.96, 1.16)</td><td rowspan="1" colspan="1">0.88 (0.82, 1.01)</td></tr></tbody></table></table-wrap><table-wrap id="BMJOPEN2013004339TB2" position="float"><label>Table&#x000a0;2</label><caption><p>Crude and adjusted reliability for evaluating consultations for different numbers of raters using GCRS (transformed 0&#x02013;10 data)</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="char" char="(" span="1"/><col align="char" char="(" span="1"/></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">Number of raters</th><th align="left" rowspan="1" colspan="1">Crude reliability* (95% CI)</th><th align="left" rowspan="1" colspan="1">Reliability adjusted for evaluator bias* (95% CI)</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">0.58 (0.28 to 0.66)</td><td rowspan="1" colspan="1">0.65 (0.36 to 0.71)</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">0.73 (0.44 to 0.79)</td><td rowspan="1" colspan="1">0.78 (0.53 to 0.83)</td></tr><tr><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">0.80 (0.54 to 0.85)</td><td rowspan="1" colspan="1">0.85 (0.63 to 0.88)</td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">0.85 (0.61 to 0.88)</td><td rowspan="1" colspan="1">0.88 (0.69 to 0.91)</td></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">0.87 (0.66 to 0.91)</td><td rowspan="1" colspan="1">0.90 (0.74 to 0.93)</td></tr><tr><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">0.89 (0.70 to 0.92)</td><td rowspan="1" colspan="1">0.92 (0.77 to 0.94)</td></tr><tr><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">0.91 (0.73 to 0.93)</td><td rowspan="1" colspan="1">0.93 (0.80 to 0.95)</td></tr><tr><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">0.92 (0.76 to 0.94)</td><td rowspan="1" colspan="1">0.94 (0.82 to 0.95)</td></tr><tr><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">0.93 (0.78 to 0.95)</td><td rowspan="1" colspan="1">0.94 (0.84 to 0.96)</td></tr><tr><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">0.93 (0.80 to 0.95)</td><td rowspan="1" colspan="1">0.95 (0.85 to 0.96)</td></tr></tbody></table><table-wrap-foot><fn><p>*Calculated from the estimated SDs shown in <xref ref-type="table" rid="BMJOPEN2013004339TB1">table 1</xref>.</p></fn><fn><p>GCRS, Global Consultation Rating Scale.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3a3"><title>Are some raters more generous than others in their assessments of consultations?</title><p>When we allowed for systematic bias between raters in our model we found that such bias was present (<xref ref-type="table" rid="BMJOPEN2013004339TB3">table 3</xref>). On an average, a difference of 1.65 (on the 0&#x02013;10 scale for transformed data) was seen between the least and most generous raters. By adjusting for evaluator bias we increased reliability somewhat (<xref ref-type="table" rid="BMJOPEN2013004339TB2">table 2</xref>), and the number of raters needed to reach the 0.7, 0.8 and 0.9 thresholds became two, three and five, respectively.</p><table-wrap id="BMJOPEN2013004339TB3" position="float"><label>Table&#x000a0;3</label><caption><p>Estimated biases between raters using GCRS (transformed 0&#x02013;10 data)</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="char" char="." span="1"/></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">Evaluator</th><th align="left" rowspan="1" colspan="1">Mean difference (95% CI)</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">Reference</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">&#x02212;0.25 (&#x02212;0.57 to 0.13)</td></tr><tr><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">&#x02212;0.68 (&#x02212;1.20 to &#x02212;0.18)</td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">0.97 (0.66 to 1.33)</td></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">&#x02212;0.25 (&#x02212;0.76 to 0.31)</td></tr><tr><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">0.49 (0.04 to 0.96)</td></tr></tbody></table><table-wrap-foot><fn><p>GCRS, Global Consultation Rating Scale.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3a4"><title>Does the order in which a consultation is rated affect the score?</title><p>Finally, we found evidence of considerable order effects, with raters giving higher scores, on average, as they progressed through the rating of consultations (<xref ref-type="fig" rid="BMJOPEN2013004339F2">figure 2</xref>). It appears that raters&#x02019; scoring levelled out after performing around 15&#x02013;20 ratings. Later consultations received, on average, scores more than one point higher on the 0&#x02013;10 scale.</p><fig id="BMJOPEN2013004339F2" position="float"><label>Figure&#x000a0;2</label><caption><p>The effect of order of rating on transformed scores compared with the first rating performed. Dots indicate point estimates and bars show 95% CIs.</p></caption><graphic xlink:href="bmjopen2013004339f02"/></fig></sec></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>GCRS shows good reliability (&#x0003e;0.8) with three raters assessing each consultation, and modest reliability (&#x0003e;0.7) with two raters. Overall, consultations received low-to-moderate scores. This reflects previous findings with simulated patients, where it has been seen that participating doctors only attain about 40&#x02013;60% of the guidelines or standards used for evaluation.<xref rid="R32" ref-type="bibr">32</xref> GCRS is designed to assess overall communication effectiveness of the entire doctor&#x02013;patient consultation, encapsulating the quality of the interaction from the opening moments, through the gathering of information, provision of information, achieving shared understanding and shared decision-making, through to closure. It is a performance-based assessment (assessing what doctors actually do in professional practice) rather than a competence-based assessment (assessing what doctors can do in controlled representations of professional practice).<xref rid="R33" ref-type="bibr">33</xref> It is additionally a criterion-referenced measure; GCRS training course highlights the importance of assessing performance against the &#x02018;gold standard&#x02019; outlined in the Calgary-Cambridge guide.</p><p>While GCRS was devised as a global assessment, doctors may be interested in knowing their performance in particular domains in order to most efficiently target training. For individual GCRS domains, reliability was broadly acceptable with four raters. Low reliability for two particular domains&#x02014;non-verbal communication and closure&#x02014;may be attributable to small between-consultation variance rather than to raters disagreeing with each other on these areas. There are two possible explanations: either that raters find it difficult to distinguish differences in doctors&#x02019; behaviours on these items (reflecting inadequate training for raters in how to assess these domains, or challenges in capturing, eg, non-verbal behaviour) or that doctors perform comparably across consultations and compared with each other on these two domains, prompting raters to award consistently similar scores.</p><p>We found that a fixed difference between scores in GCRS did not have the same meaning at all levels of performance: untransformed scores (on a scale of 0 to 24) showed a higher degree of agreement between raters at low scores than at moderate scores. For this reason, analyses were performed on transformed scores. This has implications for the most suitable score to feedback to participants if, for example, GCRS is to be used in a training situation. Transformed scores may be intuitively more difficult for participants to understand, and we need to undertake further work on the acceptability of using transformed scores in assessments of an individual doctors&#x02019; performance, and how best to calculate and present transformed scores for doctors and trainers.</p><p>While we found good reliability of GCRS in assessing the communication quality of individual consultations, comparison with existing instruments is difficult due to limited published psychometric data on assessing consultation (rather than doctor) quality. Interconsultation doctor reliability has been evaluated using the Four Habits Coding Scheme over 13 consultations (reliability of 0.72 with two raters),<xref rid="R34" ref-type="bibr">34</xref> and using the Liv-MAAS over nine consultations (reliability of 0.78 with three raters).<xref rid="R35" ref-type="bibr">35</xref> Evaluating the reliability of GCRS for assessing performance of individual doctors using different numbers of consultations will require more consultations per doctor, probably with greater subject variety, than we had in our dataset. We hope that further work on GCRS will enable us to estimate this in future.</p><p>We found consistent differences in scores assigned to consultations by the most and least generous raters. The Hawk/Dove phenomenon is well&#x000a0;documented across a wide range of performance assessments, and can be addressed through training, through the use of more than one rater and through the use of post hoc statistical techniques.<xref rid="R36" ref-type="bibr">36</xref> All of these were employed in this study, and our finding of such variation highlights the importance of using pre-evaluation and postevaluation approaches in monitoring and acting upon differences between raters.<xref rid="R37" ref-type="bibr">37</xref></p><p>We found evidence of considerable order effects. The use of multiple raters rating consultations in random order will tend to reduce order effects: sometimes a consultation will be rated early by an evaluator, and sometimes late; thus different orders for different raters average out. We have not been able to find other examples of the examination of this in GP consultation evaluation, but as previously stated, the influence of the sequential presentation of information on subsequent assessments of this information is a well-known phenomenon in the psychological literature.<xref rid="R26" ref-type="bibr">26</xref> Again, this is something which requires further work to assess how GCRS will perform in training situations.</p><p>The current study has a number of limitations. We included only a small number of GPs whose consultations had been recorded, derived from an earlier study, and only two similar scenarios per GP. These standardised scenarios do not reflect real-world consultations of variable nature and content, and we believe these are the reasons why we find little variation between consultations of the same doctor. We could not, therefore, assess how raters responded to different contexts: this is the focus of our next stage of work.</p><p>There are various sources of possible bias we did not examine due to sample size limitations. For example, contrast effect bias may be important in influencing rater behaviour, where, for example, viewing a good consultation after a series of poor consultations may lead to a substantial leap in scores assigned due to the contrast between them.</p><p>Feedback from raters showed that the assessment of consultations required significant concentration. Average consultation length was around 15&#x02005;min: viewing each consultation and completing the rating scale means each evaluation can take around 20&#x02005;min.</p></sec><sec sec-type="conclusions" id="s5"><title>Conclusions</title><p>GCRS has good reliability (&#x0003e;0.8) for rating consultations if three raters are used. Systematic differences were observed between raters: adjusting for these further improves reliability of the scale. We are currently developing the scale further by assessing a large sample of consultations in a real-world setting. This will enable a more detailed examination of the ability of the scale to assess performance between consultations of the same doctor. Once further psychometric evaluation is completed, we envisage that GCRS has the capacity to provide a robust yet practical assessment tool for the evaluation of communication skills in everyday practice, linked to the Calgary-Cambridge training approach to target identified areas for improvement.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="d35e213" content-type="local-data"><caption><title>Author's manuscript</title></caption><media mimetype="application" mime-subtype="pdf" xlink:href="bmjopen-2013-004339.draft_revisions.pdf"/></supplementary-material><supplementary-material id="d35e214" content-type="local-data"><caption><title>Reviewer comments</title></caption><media mimetype="application" mime-subtype="pdf" xlink:href="bmjopen-2013-004339.reviewer_comments.pdf"/></supplementary-material></sec></body><back><ack><p>The authors would like to thank all participating general practitioners (GPs) and GP evaluators for their assistance with this work. The authors also thank the two reviewers whose thoughtful feedback greatly improved this article.</p></ack><fn-group><fn><p><bold>Contributors:</bold> JBu designed the study, contributed to the analysis and interpretation of data and drafted the article. GA designed the study, undertook the analysis and contributed to the interpretation of data and drafting of the final version of the article. NE undertook data collection, and contributed to the analysis, the interpretation of data and drafting of the final version of the article. JC and MR designed the study, contributed to the interpretation of data and critically revised the article. JBe designed the study, supervised data collection and contributed to the interpretation of data and drafting of the final version of the article. JS designed the study, contributed to the interpretation of data, critically revised the article and devised the Global Consultation Rating Scale. All authors conceived the study and approved the final version of the article.</p></fn><fn><p><bold>Funding:</bold> This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.</p></fn><fn><p><bold>Competing interests:</bold> None.</p></fn><fn><p><bold>Ethics approval:</bold> Bromley Research Ethics Committee (REC ref: 12/LO/0421).</p></fn><fn><p><bold>Provenance and peer review:</bold> Not commissioned; externally peer reviewed.</p></fn><fn><p><bold>Data sharing statement:</bold> No additional data are available.</p></fn></fn-group><ref-list><title>References</title><ref id="R1"><label>1</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Silverman</surname><given-names>J</given-names></name><name><surname>Kurtz</surname><given-names>S</given-names></name><name><surname>Draper</surname><given-names>J</given-names></name></person-group>
<source>Skills for communicating with patients</source>. <edition>3rd edn</edition>
<publisher-loc>Oxford</publisher-loc>: <publisher-name>Radcliffe</publisher-name>, <year>2013</year></mixed-citation></ref><ref id="R2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makoul</surname><given-names>G</given-names></name></person-group>
<article-title>The interplay between education and research about patient-provider communication</article-title>. <source>Patient Educ Couns</source>
<year>2003</year>;<volume>50</volume>:<fpage>79</fpage>&#x02013;<lpage>84</lpage><pub-id pub-id-type="pmid">12767590</pub-id></mixed-citation></ref><ref id="R3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simpson</surname><given-names>M</given-names></name><name><surname>Buckman</surname><given-names>R</given-names></name><name><surname>Stewart</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>Doctor-patient communication: the Toronto consensus statement</article-title>. <source>BMJ</source>
<year>1991</year>;<volume>303</volume>:<fpage>1385</fpage>&#x02013;<lpage>7</lpage><pub-id pub-id-type="pmid">1760608</pub-id></mixed-citation></ref><ref id="R4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname><given-names>M</given-names></name><name><surname>Brown</surname><given-names>JB</given-names></name><name><surname>Boon</surname><given-names>H</given-names></name><etal/></person-group>
<article-title>Evidence on patient-doctor communication</article-title>. <source>Cancer Prev Control</source>
<year>1999</year>;<volume>3</volume>:<fpage>25</fpage>&#x02013;<lpage>30</lpage><pub-id pub-id-type="pmid">10474749</pub-id></mixed-citation></ref><ref id="R5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suchman</surname><given-names>AL</given-names></name></person-group>
<article-title>Research on patient-clinician relationships: celebrating success and identifying the next scope of work</article-title>. <source>J Gen Intern Med</source>
<year>2003</year>;<volume>18</volume>:<fpage>677</fpage>&#x02013;<lpage>8</lpage><pub-id pub-id-type="pmid">12911653</pub-id></mixed-citation></ref><ref id="R6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Fragstein</surname><given-names>M</given-names></name><name><surname>Silverman</surname><given-names>J</given-names></name><name><surname>Cushing</surname><given-names>A</given-names></name><etal/></person-group>
<article-title>UK consensus statement on the content of communication curricula in undergraduate medical education</article-title>. <source>Med Educ</source>
<year>2008</year>;<volume>42</volume>:<fpage>1100</fpage>&#x02013;<lpage>7</lpage><pub-id pub-id-type="pmid">18761615</pub-id></mixed-citation></ref><ref id="R7"><label>7</label><mixed-citation publication-type="book"><collab>Association of American Medical Colleges</collab>
<article-title>Report 3: Contemporary Issues in Medicine: Communication in Medicine</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>AAMC</publisher-name>, <year>1999</year></mixed-citation></ref><ref id="R8"><label>8</label><mixed-citation publication-type="book"><collab>BMA</collab>
<source>Communication skills education for doctors: a discussion document</source>. <publisher-loc>London</publisher-loc>: <publisher-name>BMJ</publisher-name>, <year>2003</year></mixed-citation></ref><ref id="R9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>DH</given-names></name><name><surname>Laidlaw</surname><given-names>JC</given-names></name></person-group>
<article-title>Improvement of teaching and assessment of doctor-patient communication in Canadian medical schools</article-title>. <source>J Cancer Educ</source>
<year>1993</year>;<volume>8</volume>:<fpage>109</fpage>&#x02013;<lpage>17</lpage><pub-id pub-id-type="pmid">8363936</pub-id></mixed-citation></ref><ref id="R10"><label>10</label><mixed-citation publication-type="book"><collab>Department of Health</collab>
<source>Medical schools: delivering the doctors of the future</source>. <publisher-loc>London: Department of Health</publisher-loc>, <year>2004</year></mixed-citation></ref><ref id="R11"><label>11</label><mixed-citation publication-type="book"><collab>General Medical Council</collab>
<source>Tomorrow's doctors: recommendations on undergraduate medical education</source>. <publisher-loc>London</publisher-loc>: <publisher-name>GMC</publisher-name>, <year>2009</year></mixed-citation></ref><ref id="R12"><label>12</label><mixed-citation publication-type="other"><collab>The Royal College of Physicians and Surgeons of Canada</collab>
<article-title>Canadian Medical Education Directions for Specialists 2000 Project: Skills for the New Millennium: Report of the Societal Needs Working Group</article-title>, <year>1996</year></mixed-citation></ref><ref id="R13"><label>13</label><mixed-citation publication-type="journal"><collab>Workshop Planning Committee</collab>
<article-title>Consensus statement from the workshop on teaching and assessment of communication in Canadian medical schools</article-title>. <source>CMAJ</source>
<year>1992</year>;<volume>147</volume>:<fpage>1149</fpage>&#x02013;<lpage>50</lpage><pub-id pub-id-type="pmid">1393928</pub-id></mixed-citation></ref><ref id="R14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boon</surname><given-names>H</given-names></name><name><surname>Stewart</surname><given-names>M</given-names></name></person-group>
<article-title>Patient-physician communication assessment instruments: 1986 to 1996 in review</article-title>. <source>Patient Educ Couns</source>
<year>1998</year>;<volume>35</volume>:<fpage>161</fpage>&#x02013;<lpage>76</lpage><pub-id pub-id-type="pmid">9887849</pub-id></mixed-citation></ref><ref id="R15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schirmer</surname><given-names>JM</given-names></name><name><surname>Mauksch</surname><given-names>L</given-names></name><name><surname>Lang</surname><given-names>F</given-names></name><etal/></person-group>
<article-title>Assessing communication competence: a review of current tools</article-title>. <source>Fam Med</source>
<year>2005</year>;<volume>37</volume>:<fpage>184</fpage>&#x02013;<lpage>92</lpage><pub-id pub-id-type="pmid">15739134</pub-id></mixed-citation></ref><ref id="R16"><label>16</label><mixed-citation publication-type="other"><collab>NICE</collab>
<article-title>Patient experience in adult NHS services</article-title>. <comment>Quality Standards, QS15</comment>
<year>2012</year></mixed-citation></ref><ref id="R17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Vleuten</surname><given-names>CP</given-names></name><name><surname>Schuwirth</surname><given-names>LW</given-names></name><name><surname>Scheele</surname><given-names>F</given-names></name><etal/></person-group>
<article-title>The assessment of professional competence: building blocks for theory development</article-title>. <source>Best Pract Res Clin Obstet Gynaecol</source>
<year>2010</year>;<volume>24</volume>:<fpage>703</fpage>&#x02013;<lpage>19</lpage><pub-id pub-id-type="pmid">20510653</pub-id></mixed-citation></ref><ref id="R18"><label>18</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Thiel</surname><given-names>J</given-names></name><name><surname>Ram</surname><given-names>P</given-names></name><name><surname>van Dalen</surname><given-names>J</given-names></name></person-group>
<source>MAAS-Global manual</source>. <publisher-loc>Maastricht, Netherlands: University of Maastrich</publisher-loc>, <year>2000</year></mixed-citation></ref><ref id="R19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtz</surname><given-names>S</given-names></name><name><surname>Silverman</surname><given-names>J</given-names></name><name><surname>Benson</surname><given-names>J</given-names></name><etal/></person-group>
<article-title>Marrying content and process in clinical method teaching: enhancing the Calgary-Cambridge guides</article-title>. <source>Acad Med</source>
<year>2003</year>;<volume>78</volume>:<fpage>802</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="pmid">12915371</pub-id></mixed-citation></ref><ref id="R20"><label>20</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kurtz</surname><given-names>SM</given-names></name><name><surname>Silverman</surname><given-names>J</given-names></name><name><surname>Draper</surname><given-names>J</given-names></name></person-group>
<source>Teaching and learning communication skills in medicine</source>. <edition>2nd edn</edition>
<publisher-loc>Oxford, San Francisco</publisher-loc>: <publisher-name>Radcliffe Medical</publisher-name>, <year>2005</year></mixed-citation></ref><ref id="R21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurtz</surname><given-names>SM</given-names></name><name><surname>Silverman</surname><given-names>JD</given-names></name></person-group>
<article-title>The Calgary-Cambridge referenced observation guides: an aid to defining the curriculum and organizing the teaching in communication training programmes</article-title>. <source>Med Educ</source>
<year>1996</year>;<volume>30</volume>:<fpage>83</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="pmid">8736242</pub-id></mixed-citation></ref><ref id="R22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillard</surname><given-names>S</given-names></name><name><surname>Benson</surname><given-names>J</given-names></name><name><surname>Silverman</surname><given-names>J</given-names></name></person-group>
<article-title>Teaching and assessment of explanation and planning in medical schools in the United Kingdom: cross sectional questionnaire survey</article-title>. <source>Med Teach</source>
<year>2009</year>;<volume>31</volume>:<fpage>328</fpage>&#x02013;<lpage>31</lpage><pub-id pub-id-type="pmid">19142799</pub-id></mixed-citation></ref><ref id="R23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howells</surname><given-names>RJ</given-names></name><name><surname>Davies</surname><given-names>HA</given-names></name><name><surname>Silverman</surname><given-names>JD</given-names></name><etal/></person-group>
<article-title>Assessment of doctors&#x02019; consultation skills in the paediatric setting: the Paediatric Consultation Assessment Tool</article-title>. <source>Arch Dis Child</source>
<year>2010</year>;<volume>95</volume>:<fpage>323</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="pmid">19019880</pub-id></mixed-citation></ref><ref id="R24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radford</surname><given-names>A</given-names></name><name><surname>Stockley</surname><given-names>P</given-names></name><name><surname>Silverman</surname><given-names>J</given-names></name><etal/></person-group>
<article-title>Development, teaching, and evaluation of a consultation structure model for use in veterinary education</article-title>. <source>J Vet Med Educ</source>
<year>2006</year>;<volume>33</volume>:<fpage>38</fpage>&#x02013;<lpage>44</lpage><pub-id pub-id-type="pmid">16767636</pub-id></mixed-citation></ref><ref id="R25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silverman</surname><given-names>J</given-names></name><name><surname>Archer</surname><given-names>J</given-names></name><name><surname>Gillard</surname><given-names>S</given-names></name><etal/></person-group>
<article-title>Initial evaluation of EPSCALE, a rating scale that assesses the process of explanation and planning in the medical interview</article-title>. <source>Patient Educ Couns</source>
<year>2011</year>;<volume>82</volume>:<fpage>89</fpage>&#x02013;<lpage>93</lpage><pub-id pub-id-type="pmid">20338713</pub-id></mixed-citation></ref><ref id="R26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mussweiler</surname><given-names>T</given-names></name></person-group>
<article-title>Comparison processes in social judgments: mechanisms and consequences</article-title>. <source>Psychol Rev</source>
<year>2003</year>;<volume>110</volume>:<fpage>472</fpage>&#x02013;<lpage>89</lpage><pub-id pub-id-type="pmid">12885111</pub-id></mixed-citation></ref><ref id="R27"><label>27</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Page</surname><given-names>L</given-names></name><name><surname>Page</surname><given-names>K</given-names></name></person-group>
<article-title>Last shall be first: a field study of biases in sequential performance evaluation on the idol series</article-title>. <source>J Econ Behav Organ</source>
<year>2010</year>;<volume>73</volume>:<fpage>186</fpage></mixed-citation></ref><ref id="R28"><label>28</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Rotthoff</surname><given-names>KW</given-names></name></person-group>
<comment>(Not Finding a) Sequential Order Bias in Elite Level Gymnastics</comment>, <year>2013</year></mixed-citation></ref><ref id="R29"><label>29</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>RG</given-names></name><name><surname>Klamen</surname><given-names>DA</given-names></name><name><surname>McGaghie</surname><given-names>WC</given-names></name></person-group>
<article-title>Cognitive, social and environmental sources of bias in clinical performance ratings</article-title>. <source>Teach Learn Med</source>
<year>2003</year>;<volume>15</volume>:<fpage>270</fpage>&#x02013;<lpage>92</lpage><pub-id pub-id-type="pmid">14612262</pub-id></mixed-citation></ref><ref id="R30"><label>30</label><mixed-citation publication-type="book"><collab>Postgraduate Medical Education and Training Board</collab>
<source>Developing and maintaining an assessment system&#x02014;a PMETB guide to good practice</source>. <publisher-loc>London: GMC</publisher-loc>, <year>2007</year></mixed-citation></ref><ref id="R31"><label>31</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname><given-names>RL</given-names></name></person-group>
<article-title>Generalizability Theory</article-title>. <source>Educ Meas Issues Pract</source>
<year>1992</year>;<volume>11</volume>:<fpage>27</fpage>&#x02013;<lpage>34</lpage></mixed-citation></ref><ref id="R32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rethans</surname><given-names>JJ</given-names></name><name><surname>Sturmans</surname><given-names>F</given-names></name><name><surname>Drop</surname><given-names>R</given-names></name><etal/></person-group>
<article-title>Assessment of the performance of general practitioners by the use of standardized (simulated) patients</article-title>. <source>Br J Gen Pract</source>
<year>1991</year>;<volume>41</volume>:<fpage>97</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="pmid">2031767</pub-id></mixed-citation></ref><ref id="R33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rethans</surname><given-names>JJ</given-names></name><name><surname>Norcini</surname><given-names>JJ</given-names></name><name><surname>Baron-Maldonado</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>The relationship between competence and performance: implications for assessing practice performance</article-title>. <source>Med Educ</source>
<year>2002</year>;<volume>36</volume>:<fpage>901</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="pmid">12390456</pub-id></mixed-citation></ref><ref id="R34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupat</surname><given-names>E</given-names></name><name><surname>Frankel</surname><given-names>R</given-names></name><name><surname>Stein</surname><given-names>T</given-names></name><etal/></person-group>
<article-title>The Four Habits Coding Scheme: validation of an instrument to assess clinicians&#x02019; communication behavior</article-title>. <source>Patient Educ Couns</source>
<year>2006</year>;<volume>62</volume>:<fpage>38</fpage>&#x02013;<lpage>45</lpage><pub-id pub-id-type="pmid">15964736</pub-id></mixed-citation></ref><ref id="R35"><label>35</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enzer</surname><given-names>I</given-names></name><name><surname>Robinson</surname><given-names>J</given-names></name><name><surname>Pearson</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>A reliability study of an instrument for measuring general practitioner consultation skills: the LIV-MAAS scale</article-title>. <source>Int J Qual Health Care</source>
<year>2003</year>;<volume>15</volume>:<fpage>407</fpage>&#x02013;<lpage>12</lpage><pub-id pub-id-type="pmid">14527984</pub-id></mixed-citation></ref><ref id="R36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harasym</surname><given-names>PH</given-names></name><name><surname>Woloschuk</surname><given-names>W</given-names></name><name><surname>Cunning</surname><given-names>L</given-names></name></person-group>
<article-title>Undesired variance due to examiner stringency/leniency effect in communication skill scores assessed in OSCEs</article-title>. <source>Adv Health Sci Educ Theory Pract</source>
<year>2008</year>;<volume>13</volume>:<fpage>617</fpage>&#x02013;<lpage>32</lpage><pub-id pub-id-type="pmid">17610034</pub-id></mixed-citation></ref><ref id="R37"><label>37</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bartman</surname><given-names>I</given-names></name><name><surname>Roy</surname><given-names>M</given-names></name><name><surname>Smee</surname><given-names>S</given-names></name></person-group>
<source>Catching the hawks and doves: a method for identifying extreme examiners on objective structured clinical examinations</source>. <publisher-loc>Ottawa</publisher-loc>: <publisher-name>Medical Council of Canada</publisher-name>, <year>2011</year></mixed-citation></ref></ref-list></back></article>