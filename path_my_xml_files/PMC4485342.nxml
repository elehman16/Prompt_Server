<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Educ</journal-id><journal-id journal-id-type="iso-abbrev">BMC Med Educ</journal-id><journal-title-group><journal-title>BMC Medical Education</journal-title></journal-title-group><issn pub-type="epub">1472-6920</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26100835</article-id><article-id pub-id-type="pmc">4485342</article-id><article-id pub-id-type="publisher-id">390</article-id><article-id pub-id-type="doi">10.1186/s12909-015-0390-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Puzzle-based versus traditional lecture: comparing the effects of pedagogy on academic performance in an undergraduate human anatomy and physiology II lab</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Stetzik</surname><given-names>Lucas</given-names></name><address><email>lstetzik@gmail.com</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Deeter</surname><given-names>Anthony</given-names></name><address><email>aed27@zips.uakron.edu</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Parker</surname><given-names>Jamie</given-names></name><address><email>jtp718@gmail.com</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Yukech</surname><given-names>Christine</given-names></name><address><email>cyukech@gmail.com</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1">University of Akron, Akron, OH USA </aff></contrib-group><pub-date pub-type="epub"><day>23</day><month>6</month><year>2015</year></pub-date><pub-date pub-type="pmc-release"><day>23</day><month>6</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>15</volume><elocation-id>107</elocation-id><history><date date-type="received"><day>3</day><month>3</month><year>2014</year></date><date date-type="accepted"><day>11</day><month>6</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; Stetzik et al. 2015</copyright-statement><license license-type="open-access"><license-p>This article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>A traditional lecture-based pedagogy conveys information and content while lacking sufficient development of critical thinking skills and problem solving. A puzzle-based pedagogy creates a broader contextual framework, and fosters critical thinking as well as logical reasoning skills that can then be used to improve a student&#x02019;s performance on content specific assessments. This paper describes a pedagogical comparison of traditional lecture-based teaching and puzzle-based teaching in a Human Anatomy and Physiology II Lab.</p></sec><sec><title>Methods</title><p>Using a single subject/cross-over design half of the students from seven sections of the course were taught using one type of pedagogy for the first half of the semester, and then taught with a different pedagogy for the second half of the semester. The other half of the students were taught the same material but with the order of the pedagogies reversed. Students&#x02019; performance on quizzes and exams specific to the course, and in-class assignments specific to this study were assessed for: learning outcomes (the ability to form the correct conclusion or recall specific information), and authentic academic performance as described by (Am J Educ 104:280&#x02013;312, 1996).</p></sec><sec><title>Results</title><p>Our findings suggest a significant improvement in students&#x02019; performance on standard course specific assessments using a puzzle-based pedagogy versus a traditional lecture-based teaching style. Quiz and test scores for students improved by 2.1 and 0.4&#x000a0;% respectively in the puzzle-based pedagogy, versus the traditional lecture-based teaching. Additionally, the assessments of authentic academic performance may only effectively measure a broader conceptual understanding in a limited set of contexts, and not in the context of a Human Anatomy and Physiology II Lab.</p></sec><sec><title>Conclusion</title><p>In conclusion, a puzzle-based pedagogy, when compared to traditional lecture-based teaching, can effectively enhance the performance of students on standard course specific assessments, even when the assessments only test a limited conceptual understanding of the material.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Puzzle</kwd><kwd>Lecture</kwd><kwd>Teaching</kwd><kwd>Pedagogy</kwd><kwd>Anatomy</kwd><kwd>Physiology</kwd><kwd>Performance</kwd><kwd>Concept</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Background</title><p>Throughout the past 25&#x000a0;years, studies involving teaching methods that differ from the standard lecture/memorization/testing format have shown promise in increasing the level of authentic intellectual performance demonstrated by students [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR5">5</xref>]. Thus, in more recent studies it has been argued that traditional teaching methods convey information and content while lacking sufficient development of critical thinking skills and problem solving [<xref ref-type="bibr" rid="CR6">6</xref>]. The framework used to score non-traditional teaching methods has focused on learning outcomes, and content-specific conceptual understanding [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. In an effort to assess the broader effects of pedagogy on a student&#x02019;s critical thinking skills, this study has implemented a framework with which to determine the level of students&#x02019; authentic intellectual performance [<xref ref-type="bibr" rid="CR8">8</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>]. The authentic intellectual performance framework used for this study was based on the following standards; higher-order thinking, depth of knowledge, connectedness to the world beyond the classroom, substantive conversation, and social support for student achievement.</p><p>Previous studies have established definitions for project-, problem-, and puzzle-based teaching methods in which each method builds upon those before it [<xref ref-type="bibr" rid="CR6">6</xref>]. The least abstract method, project-based, includes working in teams and dealing with uncertainty and changing conditions. Built upon this method is problem-based learning; this method involves acquiring domain-specific knowledge and reasoning with domain-specific methods. The most abstract method, puzzle-learning, builds upon both of these to develop critical thinking and logical reasoning independent of a specific domain [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR14">14</xref>&#x02013;<xref ref-type="bibr" rid="CR17">17</xref>]. The first two methods have been studied extensively, but little has been done with regards to puzzle-based learning [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>].</p><p>Our research aims to assess the impact of puzzle-based learning on conventionally valued academic knowledge such as: course specific material and course specific conceptual understanding, as well as broadly valued skills, such as conceptual reasoning independent of course material. Non-traditional lecture, memorization, and testing methods enable in-class activities to engage students in a wide range of intellectual skill sets both conventionally academic and broadly applicable [<xref ref-type="bibr" rid="CR20">20</xref>&#x02013;<xref ref-type="bibr" rid="CR22">22</xref>]. In-class activities that use puzzle-based teaching can require students to connect to their prior knowledge, explain, interpret, and apply newly acquired knowledge, as well as develop personal perspective and understanding [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>].</p><p>The objective of this research was to compare the effects of traditional teaching methods and puzzle-based teaching on authentic intellectual performance, and learning outcomes.</p></sec><sec id="Sec2" sec-type="materials|methods"><title>Methods</title><p>The Internal Review Board at the University of Akron deemed acquisition of all data involving human participants exempt from internal review board approval as the proposed methods did not pose a threat of harm to the participants, the methods were in keeping with standard educational practice, and the identities of each participant remained anonymous throughout the study. The participants chosen for this research were students taking the Human Anatomy and Physiology II Lab at the University of Akron. Seven sections of this lab, 185 students in total, were taught using standard teaching practices as well as puzzle-based methods, and their level of authentic intellectual performance was measured in addition to their standard course assessments. Two teaching assistants were utilized among seven sections of the course (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig1"><label>Fig. 1</label><caption><p>Course Structure and Single Subject/Cross-Over Design. A summary of the Human Anatomy and Physiology II Lab course schedule including the implementation of a single subject/cross-over design. I) Course offered at the University of Akron, II) Individual sections or &#x0201c;classes&#x0201d; each approximately 25&#x02013;30 undergraduate students (185 in total). Each section was assigned to meet at the same unique specified time and classroom on campus at the University of Akron. The actual meeting times, and section numbers have been omitted to ensure anonymity of the participants in keeping with the requirements set forth by the Internal Review Board at the University of Akron. III) Weeks 1&#x02013;8 of an academic semester, including indications of how sections were divided among the teaching assistants, and which sections began the study with either a traditional lecture or puzzle-based pedagogy. IV) The mid-term exam and, as indicated by the black five pointed star, the point of pedagogy cross-over. V) Weeks 9&#x02013;16 of an academic semester, including indications of which sections crossed-over to either a traditional lecture or puzzle-based pedagogy</p></caption><graphic xlink:href="12909_2015_390_Fig1_HTML" id="d30e298"/></fig></p><p>Human Anatomy and Physiology II Lab is a prerequisite for all medical related degrees including but not limited to: nursing, pre-med, exercise science, biochemistry, and biology at the University of Akron. The proportion of students representing these specific programs was not controlled, but the intended majors of each student were documented in case there was a strong program related bias observed in any of the six sections. Such a bias was not apparent in the results and so this was not included as a factor in the final analysis.</p><sec id="Sec3"><title>Single subject/cross-over</title><p>As a condition for conducting this study in the Human Anatomy and Physiology II Lab, it was required by the University of Akron that all the course material be presented in a specific order. This order is designed such that the material prior to the mid-term exam is more challenging than the material after the mid-term exam. Consequently, there could be a bias toward improved scores on standard course assessments in the second half of the semester independent of any manipulations to teaching-style (<italic>i.e.</italic> scores on the final exam may be higher than the mid-term exam).</p><p>Knowing that this bias could effect the interpretation of our results by showing improvement in any teaching style used in the second half of the semester, a single subject/cross-over design was implemented (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) to compensate for this bias. Each teaching assistant taught two sections of the course using a puzzle-based pedagogy for the first half of the semester. After the midterm practical exam, these sections then switched to a traditional lecture-based pedagogy for the remainder of the semester. The remaining sections started with a lecture-based pedagogy and then moved to a puzzle-based pedagogy after the midterm practical exam.</p><p>By using the single subject/cross-over design, it can be determined if the order in which the teaching style was used has a significant effect on student performance. Such significance would potentially confirm the suspected bias towards improved scores on standard course assessments in the second half of the semester, and would be the result of a decreased difficulty in the course material. Additionally, by using this design, it can be determined if teaching-style, independent of the order in which the teaching-style was used, had a significant effect on student performance. Taken together, this means that if both order and teaching-style are significant that there is a bias towards improved scores in the second half of the semester, and that teaching-style did have a significant effect on student performance independent of this bias.</p></sec><sec id="Sec4"><title>Traditional/lecture design</title><p>The traditional lecture-based portion of the course used a projector screen and Microsoft Power Point to display images and key information related to the week&#x02019;s lab. The teaching assistant read through a prepared set of notes related to the content of the chapter, as they displayed the slide show. Figure&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> is an example of a Power Point slide and some of the notes that were presented to the class. Once the lecture was over, the students had the remainder of the class period to complete a prelab activity (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>) usually consisting of approximately twelve fill-in-the-blank questions, using their lab manual and the models in the classroom.<fig id="Fig2"><label>Fig. 2</label><caption><p>Presentation Slide For Traditional Lecture-Based Pedagogy with Presenter Notes. An example PowerPoint slide describing course material from chapter 7 of the Human Anatomy and Physiology II Lab complete with presented notes used during the traditional lecture-based pedagogy portion of the study</p></caption><graphic xlink:href="12909_2015_390_Fig2_HTML" id="d30e335"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>In-class Prelab Assignment For Traditional Lecture-Based Pedagogy. The prelab activity for chapter 7 of the Human Anatomy and Physiology II Lab, for use in the traditional teaching portion of the class</p></caption><graphic xlink:href="12909_2015_390_Fig3_HTML" id="d30e344"/></fig></p><p>The students were asked to briefly describe any additional applications of the concepts learned in that week&#x02019;s activity, as a measure of authentic intellectual performance. Every picture in the lab manual had one or more models of the same anatomical structure physically present and available during the class period. At the end of the class period, each student&#x02019;s prelab was graded for correctness and returned to the student so that they could study from it in the following week.</p></sec><sec id="Sec5"><title>Puzzle design</title><sec id="Sec6"><title>Content specificity, and conceptual generality</title><p>As previously stated, a key feature of puzzle-based learning that distinguishes it from problem-based or project-based learning is the emphasis on domain-independent critical thinking and abstract reasoning [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. This is not to say that a puzzle-based learning course is about presenting and discussing a variety of puzzles, but rather that it is about presenting and understanding problem-solving principles through puzzles that serve both as an illustration of broad concepts and of course specific material [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR17">17</xref>].</p><p>This study&#x02019;s puzzle design used the Human Anatomy and Physiology II Lab course content as a vehicle for the development of domain-neutral basic reasoning skills. In general, the participants would have to familiarize themselves with a set of &#x0201c;rules&#x0201d; given in the form of background information regarding a real-world medical application of the course material.</p><p>For example if the chapter material focused on the lymphatic system, a real-world medical application for the lymphatic system was the diagnosis of lymphoma (a cancer specific to the lymphatic system) through histological test results. As previously mentioned, the &#x0201c;rules&#x0201d; for this puzzle were not directly stated; the participant would come to know them by a conceptual understanding of the chapter material in the lab manual, and any supplementary material provided in the form of a photocopied handout on the day of class. In the case of the lymphoma puzzle, such an understanding should have yielded the following rules:<list list-type="order"><list-item><p>The cancer will only affect anatomical structures specific to the lymphatic system.</p></list-item><list-item><p>The lymphatic system has a particular directional flow by which the cancer can spread.</p></list-item><list-item><p>When viewed with basic staining techniques, some types of lymphatic cancer cells have one distinctive morphology, are highly metastatic, and thus have the ability to spread throughout major anatomical features, while other types of cancer cells have a different type of morphology and are only able to spread through minor substructures of the lymphatic system.</p></list-item></list></p><p>While this may appear to be a domain specific problem, the puzzle &#x0201c;rules&#x0201d; directed the participants to develop a set of basic reasoning skills independent of the chapter content. Stated more abstractly, the rules could be simplified to:<list list-type="order"><list-item><p>This is a closed system, the limits of which are defined.</p></list-item><list-item><p>This closed system has sequential order through which it functions on two size dependent scales.</p></list-item><list-item><p>Idea 1 affects the system on one size scale; Idea 2 affects the system on a different size scale. Idea 1 and 2 are mutually exclusive.</p></list-item></list></p><p>In-addition to learning critical thinking and basic reasoning skills, a puzzle-based in-class activity reinforces the specific chapter material by putting it into a contextual framework. Where a traditional lecture would state the directional flow of the lymphatic system on two size scales, its various anatomical structures, and its physiological relevance, a puzzle-based in-class activity reinforces that same information by making it impossible to complete the assignment without a conceptual understanding of the material.</p></sec><sec id="Sec7"><title>Assessments of authentic intellectual performance (AIP)</title><p>At the end of the puzzle activities and the prelab activities, participants were asked to identify any additional applications of the concepts from that activity&#x02019;s chapter material. This provided a means through which to assess the participants&#x02019; broader conceptual understanding of the material. This broader conceptual understanding should, in theory, translate to &#x0201c;real-world&#x0201d; aptitude [<xref ref-type="bibr" rid="CR9">9</xref>&#x02013;<xref ref-type="bibr" rid="CR12">12</xref>]. These assessments were scored using the authentic intellectual performance criteria outlined by Newmann and Wehlage [<xref ref-type="bibr" rid="CR10">10</xref>]. These standards were developed in order to represent the quality of intellectual work without being linked to any one teaching method [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]. Each of the following standards; higher-order thinking, depth of knowledge, connectedness to the world beyond the classroom, substantive conversation, and social support for student achievement; was designed as a continuous, analog representation of quality.</p><p>In general, scores were given on a scale of 0&#x02013;5 in which answers that demonstrated little conceptual understand beyond the domain specific context of the puzzle material were given a 1&#x02013;2, answers that demonstrated conceptual understanding beyond the domain specific content but lacked an application of the concept outside of the domain specific content received a 3, answers that demonstrated a conceptual understanding beyond the domain specific content and an application of the concept that was beyond the domain specific content of the puzzle but were still within the domain specific content of the course received a 4, and answers that demonstrated a conceptual understanding beyond the domain specific content and an application of the concept that was beyond the domain specific content of the puzzle and the course received a 5.</p><p>For example, in the puzzle about the lymphatic system, the participants provided some variation of the following answers and received the following scores:<disp-quote><p><italic>The Lymphatic system has lymph nodes all over the body that move lymphatic fluid and nutrients in the cells.</italic> (Score 1 or 2)</p><p><italic>The lymphatic system is a mechanism for biological cleaning and nutrient transport</italic>. (Score 3)</p><p><italic>The lymphatic system moves waste out of the cell and moves nutrients into the cell, much the way the act of eating and digestion moves nutrients into the body and waste out of the body</italic> (score 4)</p><p><italic>The lymphatic system is like the water treatment center for a city, it moves clean fluid into homes and keeps the residents alive, similar to how the lymphocytes keep cells of the tissue alive, and then the pipes connected to the sewage system remove waste and keep people in their homes clean, the way lymphatic fluid removes wastes from cells.</italic> (Score 5)</p></disp-quote></p><p>If the student failed to answer the question they received no credit.</p><p>One important feature of this assessment is that it demonstrates a broader conceptual understanding independent of the puzzle content [<xref ref-type="bibr" rid="CR10">10</xref>]. We assume that this broader understanding would be difficult to achieve without the use of basic reasoning. This assumption implies that if a puzzle/project/problem requires the participant to use and develop basic reasoning, this basic reasoning will facilitate the connection of domain specific concepts to domain independent concepts [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>].</p></sec><sec id="Sec8"><title>Standard course assessments</title><p>On the days the class had a quiz, the quiz tested a subset of course material defined by the course syllabus, and then the day&#x02019;s activity began once all the quizzes were collected by the teaching assistant. The quiz format was specific to the structure of the Human Anatomy and Physiology II Lab course, prior to the inclusion of this study. Students were presented with a Power Point slideshow in which each slide had one of the figures from the student&#x02019;s lab manual with its structures labeled by an alphabetic letter. The teaching assistant then informed the class which letters needed to be identified as anatomical structures, or asked a question relating to physiological function and included what number-line they should write the anatomy term next to on their quiz sheets. The assessments had a total of 30 questions, and in general 5&#x02013;8 of these questions would be related to a physiological concept while the remainder of the questions were anatomical identification.</p><p>The mid-term and final lab practical exams were also a format specific to the structure of the Human Anatomy and Physiology II Lab course, prior to the inclusion of this study. In these assessments, a total of 20 anatomical models or histological images were assigned individual stations throughout the exam room. Students completed a total of 2, 1-min rotations for each station in sequential order. Each station had 2&#x02013;3 questions that either required the student to identify a particular anatomical structure indicated by a numbered sticker on the model or image, or to answer a question about physiological function related to that station&#x02019;s model or image. The assessments had a total of 50 questions, 30 of which were anatomical identification questions, and 20 of which were physiological function questions.</p><p>All standard course assessments were graded for correctness. To receive full credit, the answers needed to be complete and all vocabulary terms needed to be spelled correctly. Incorrect spellings different by a single vowel received &#x000be; credit; incorrect spellings by a nonessential consonant (C instead of K or S, <italic>etc.</italic>) received &#x000bd; credit. All other misspellings received no credit.</p></sec><sec id="Sec9"><title>Statistical analysis</title><p>Analyses were done with IBM SPSS Statistics version 21. Multivariate analysis of variance (MANOVA) was used to determine if there were between-subjects effects of pedagogical styles on the scores of standard course assessments. MANOVA was used because this method can analyze significant differences in student performance on standard course assessments as single factor, effectively combining the tests and quizzes to look for an overall effect with regards to teaching-style, order, and teaching-style&#x02009;+&#x02009;order (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). A similar MANOVA analysis that separated the standard assessments into quizzes and tests was used because this method can analyze significant differences in student performance on tests and quizzes separately to look for an effect with regards to teaching-style, order, teaching-style&#x02009;+&#x02009;order (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). Additionally, this analysis was split by TA to determine the effect of subtle difference in instruction on teaching-style, order, and teaching-style&#x02009;+&#x02009;order (Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>). For the AIP assessments a univariate analysis of variance was used to determine between-subjects effects with regards to teaching-style, order, and teaching-style&#x02009;+&#x02009;order. For all analyses results were considered statistically significant when <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05.<table-wrap id="Tab1"><label>Table 1</label><caption><p>MANOVA comparing scores on standard assessments between pedagogies</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Effect</th><th>Wilks&#x02019; Lambda</th><th>F</th><th>Hypothesis df</th><th>Error df</th><th><italic>p</italic>-value</th></tr></thead><tbody><tr><td>Teaching Style</td><td>.95</td><td>5.588<sup>a</sup></td><td>3.000</td><td>298.000</td><td>0.001*</td></tr><tr><td>Order</td><td>.88</td><td>13.459<sup>a</sup></td><td>3.000</td><td>298.000</td><td>0.000*</td></tr><tr><td>Teaching Style&#x02009;+&#x02009;Order</td><td>.83</td><td>16.353<sup>a</sup></td><td>3.000</td><td>298.000</td><td>0.000*</td></tr></tbody></table><table-wrap-foot><p>*significant at <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05</p><p><sup>a</sup> exact statistic</p></table-wrap-foot></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>MANOVA comparing scores on standard assessments between pedagogies with tests for between-subjects effects on quizzes and tests</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="5">Multivariate tests</th><th colspan="2">Between subject effects</th></tr><tr><th>Effect</th><th>Wilks&#x02019; Lambda</th><th>F</th><th>Hypothesis df</th><th>Error df</th><th>Dependent variable</th><th><italic>p</italic>-value</th></tr></thead><tbody><tr><td rowspan="2">Teaching style</td><td rowspan="2">.95</td><td rowspan="2">5.588<sup>a</sup></td><td rowspan="2">3.000</td><td rowspan="2">298.000</td><td>Quizzes</td><td>0.876</td></tr><tr><td>Tests</td><td>0.846</td></tr><tr><td rowspan="2">Order</td><td rowspan="2">.88</td><td rowspan="2">13.459<sup>a</sup></td><td rowspan="2">3.000</td><td rowspan="2">298.000</td><td>Quizzes</td><td>0.006*</td></tr><tr><td>Tests</td><td>0.001*</td></tr><tr><td rowspan="2">Teaching Style&#x02009;+&#x02009;Order</td><td rowspan="2">.829</td><td rowspan="2">16.353<sup>a</sup></td><td rowspan="2">3.000</td><td rowspan="2">298.000</td><td>Quizzes</td><td>0.000*</td></tr><tr><td>Tests</td><td>0.186</td></tr></tbody></table><table-wrap-foot><p>*significant at <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05</p><p><sup>a</sup> exact statistic</p></table-wrap-foot></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>MANOVA comparing scores on standard assessments between pedagogies for ta1 and ta2 with tests for between subject effects on quizzes and tests</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="11">Multivariate tests</th><th colspan="3">Between subject effects</th></tr><tr><th>Effect</th><th colspan="2">Wilks&#x02019; Lambda</th><th colspan="2">F</th><th colspan="2">Hypothesis df</th><th colspan="2">Error df</th><th colspan="2">p-value</th><th>Dependent variable</th><th colspan="2"><italic>p</italic>-value</th></tr><tr><th>TA</th><th>TA1</th><th>TA2</th><th>TA1</th><th>TA2</th><th>TA1</th><th>TA2</th><th>TA1</th><th>TA2</th><th>TA1</th><th>TA2</th><th/><th>TA1</th><th>TA2</th></tr></thead><tbody><tr><td rowspan="2">Teaching style</td><td rowspan="2">.98</td><td rowspan="2">.97</td><td rowspan="2">1.421<sup>a</sup></td><td rowspan="2">3.016<sup>a</sup></td><td rowspan="2">2</td><td rowspan="2">2</td><td rowspan="2">167</td><td rowspan="2">183</td><td rowspan="2">.244</td><td rowspan="2">.005*</td><td>Quizzes</td><td>.107</td><td>.758</td></tr><tr><td>Tests</td><td>.702</td><td>.041*</td></tr><tr><td rowspan="2">Order</td><td rowspan="2">.96</td><td rowspan="2">.86</td><td rowspan="2">.959<sup>a</sup></td><td rowspan="2">15.024<sup>a</sup></td><td rowspan="2">2</td><td rowspan="2">2</td><td rowspan="2">167</td><td rowspan="2">183</td><td rowspan="2">.030*</td><td rowspan="2">.000*</td><td>Quizzes</td><td>.205</td><td>.000*</td></tr><tr><td>Tests</td><td>.159</td><td>.000*</td></tr><tr><td rowspan="2">Teaching Style&#x02009;+&#x02009;Order</td><td rowspan="2">.90</td><td rowspan="2">.85</td><td rowspan="2">.902<sup>a</sup></td><td rowspan="2">15.698<sup>a</sup></td><td rowspan="2">2</td><td rowspan="2">2</td><td rowspan="2">167</td><td rowspan="2">183</td><td rowspan="2">.000*</td><td rowspan="2">.000*</td><td>Quizzes</td><td>.000*</td><td>.205</td></tr><tr><td>Tests</td><td>.068</td><td>.000*</td></tr></tbody></table><table-wrap-foot><p>*significant at <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05</p><p><sup>a</sup> exact statistic</p></table-wrap-foot></table-wrap></p><p>It is important to note that the significant effect of order, and teaching-style&#x02009;+&#x02009;order demonstrated a statistically significant improvement in student performance on standard course assessments in the second half of the semester (data not shown). However, the single subject/cross-over design of the study removes this bias when analyzing the effect of teaching style exclusively.</p></sec></sec></sec><sec id="Sec10" sec-type="results"><title>Results</title><p>Overall, our findings indicate a significant improvement in students&#x02019; performance on standard course specific assessments using a puzzle-based pedagogy versus a traditional lecture-based teaching style. Quiz and test scores for students improved by 2.1 and 0.4&#x000a0;% respectively in the puzzle-based pedagogy, versus the traditional lecture-based teaching. Mean quiz and test scores for puzzle-based students were 85.2 and 77.7 respectively, while the mean quiz and test scores for traditional lecture-based teaching were 83.1 and 77.3 respectively (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). The significance of teaching-style independent of order in combination with the cross-over design suggests that the significant bias of order was effectively compensated for (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). If the bias of order were not effectively compensated for there would be no significance in teaching-style independent of order as scores on all standard assessments increased in the second half of the semester independent of teaching-style. Interestingly when analyzing the effect of teaching-style on the specific outcomes of tests and quizzes separately neither is significant (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). However, when these results are further analyzed for the effect of teaching-style on the specific outcomes of test and quizzes with respect to individual TAs the test scores for TA2 remain significantly improved by 3.04&#x000a0;% (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><p>Standard Course Assessments. Mean scores for standard assesments. Both tests and quizzes showing a significant inprovement (<italic>p&#x02009;&#x0003c;&#x02009;0.05</italic>) in the puzzle-based pedagogy (P) versus traditional lecture-based teaching (L). Tests are an average of final and mid-term exams. <italic>N&#x02009;=&#x02009;185</italic></p></caption><graphic xlink:href="12909_2015_390_Fig4_HTML" id="d30e1089"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Standard Course Assessments Separated by Tests, Quizzes, and TA. Mean scores for standard assesments. Tests for TA2 showing a significant inprovement (<italic>p&#x02009;&#x0003c;&#x02009;0.05</italic>) in the puzzle-based pedagogy (P) versus traditional lecture-based teaching (L). Tests are an average of final and mid-term exams. TA1 <italic>N&#x02009;=&#x02009;97,</italic> TA2 <italic>N&#x02009;=&#x02009;88</italic></p></caption><graphic xlink:href="12909_2015_390_Fig5_HTML" id="d30e1106"/></fig></p><p>Additionally, in terms of the assessments for authentic intellectual performance (AIP), our findings indicate a significant difference (<italic>p</italic>&#x02009;=&#x02009;0.001) between puzzle-based and traditional lecture-based pedagogies (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>). However, based on anecdotal accounts of interactions between the teaching assistants and participants, we also report that these assessments contained a number of complicating factors that may have contributed to a fundamental inaccuracy of the significance in this study, and failure to assess the participant&#x02019;s potential for broader reasoning and conceptual understanding independent of domain-specific content.<fig id="Fig6"><label>Fig. 6</label><caption><p>Assessment Authentic Intellectual Performance. Mean scores for AIP assessments showing a significant difference (<italic>p&#x02009;&#x0003c;&#x02009;0.05)</italic> between the puzzle-based pedagogy (P) and traditional lecture-based teaching (L). <italic>N&#x02009;=&#x02009;185</italic></p></caption><graphic xlink:href="12909_2015_390_Fig6_HTML" id="d30e1128"/></fig></p></sec><sec id="Sec11" sec-type="discussion"><title>Discussion</title><p>Taken together, the results of the assessments for learning outcomes and authentic intellectual performance help to inform the relative effectiveness of puzzle-based pedagogies as a tool for &#x0201c;open&#x0201d; or &#x0201c;experiential&#x0201d; learning theories in comparison with more didactic theories, the primary vehicle of which is a traditional lecture based pedagogy [<xref ref-type="bibr" rid="CR8">8</xref>]. Previous studies have demonstrated the effectiveness of implementing &#x0201c;open/experiential&#x0201d; learning through a puzzle-based pedagogy in mathematics and computer science courses [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. This study expands the academic context of &#x0201c;open/experiential&#x0201d; learning theories into a Human Anatomy and Physiology II Lab that is traditionally assumed to be rooted in a didactic theory, through dry anatomical identification and rote memorization. By moving &#x0201c;open/experiential&#x0201d; learning into this new academic territory it could be possible, as previous studies have suggested, that educational techniques such as puzzle-based and problem-based pedagogies are effective in a broad range of academic contexts [<xref ref-type="bibr" rid="CR8">8</xref>]. The findings of this study suggest a significant improvement in performance with puzzle-based versus traditional lecture-based pedagogy, on standard Human Anatomy and Physiology II Lab assessments. Additionally, there is an arguably unreliable significance in assessments of authentic intellectual performance.</p><p>One explanation for the significant improvement in performance on the standard assessments between puzzle-based and traditional lecture-based pedagogies is that the puzzle-based pedagogy creates a contextual framework for the course material that improves students&#x02019; ability to recall specific details. Previous studies have demonstrated the increase in student performance using a puzzle-based pedagogy in advanced mathematics courses and computer science courses [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. The assessments for these courses require students to have a conceptual understanding of the material in order to grasp challenging abstract concepts.</p><p>The standard assessments for a human anatomy and physiology lab, however, are ~80&#x000a0;% anatomical identification and ~20&#x000a0;% physiology. Neither set of questions in the Human Anatomy and Physiology II Lab <italic>requires</italic> a deeper conceptual understanding of the material in order to perform well on the standard assessments. Rather, the assessments are geared toward rote memorization, devoid of conceptual understanding. Despite the vast differences between Human Anatomy and Physiology II Lab and the previous studies that have implemented puzzle-based learning in advanced mathematics and computer science courses [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>] in terms of course design and assessments, the contextual framework established by the puzzle-based pedagogy seems to aid in the recall of specific details improving student performance when compared to traditional lecture-based teaching.</p><sec id="Sec12"><title>Importance of individual characteristics</title><p>The significance of pedagogy in teaching assistant #1&#x02019;s sections presents a very important observation that is intuitively obvious and methodologically difficult to demonstrate. This observation being that the individual characteristics of the teaching assistant significantly impacts the performance of students. In this study the individual characteristics that may have affected students&#x02019; performance are: familiarity with the course material, approachability, and style of fielding questions during class activities.</p><p>While neither teaching assistant had presented an in-class lecture or a puzzle activity for this course, Teaching assistant #2 (TA2) had previously taught this course once prior to this study. Additionally, because TA2 had prior experience with the material, their intellectual input was critical to the design of each in-class activity. Though both TAs met prior to instructing the chapter material for that week to ensure there was a uniformity in instruction, it is possible that TA2&#x02019;s familiarity with that material may have influenced the ability answer activity related questions. Though both TAs did not directly provide any student with answers to any in-class activity, a greater familiarity with the material could possibly have give TA2 the ability to direct students into making conceptual connections more effectively. This is supported by anecdotally reported interactions between numerous participants and the lab coordinator/instructor, in which participants expressed a frustration and dissatisfaction with TA1&#x02019;s level of preparedness and familiarity with in-class activates.</p></sec><sec id="Sec13"><title>Motivational effect of course expectation</title><p>The focus of Human Anatomy and Physiology Labs on anatomical identification and rote memorization is not only something that is commonly accepted and understood, but is expected by students enrolling in the course. Based on anecdotal reports of student-participant teaching assistant interactions, it was clear that the majority of students felt that the puzzle-based in-class activities were excessively difficult, and added little benefit to their understanding of the material. Many participants argued at great length with their teaching assistant about the puzzle activities and consistently expressed the view that Anatomy and Physiology was a memorization course. This predominantly negative attitude towards the puzzles contrasts the claims of many other studies that implement puzzle-based learning, and describe it as being &#x0201c;fun&#x0201d;, and possessing an &#x0201c;entertainment factor&#x0201d; [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR17">17</xref>].</p><p>As previously mentioned, the course this study was conducted in was Human Anatomy and Physiology <italic>II</italic> Lab. Thus, it is important to note that all the participants had completed the Human Anatomy and Physiology <italic>I</italic> lab without any of the in-class puzzle activities used in this study. This generated a workload expectation that was exceeded by the in-class puzzle activities included in this study, and consequently an inherent motivational resistance to any potential benefit that could be gained through the in-class puzzle activities.</p><p>The most striking motivational resistance was apparent in the participants&#x02019; overwhelmingly negative attitude toward and effort applied to the AIP assessments. Specifically, the disproportional relation between the degree of perceived effort required to answer the assessment&#x02019;s question correctly and the credit received for a correct answer. This resulted in many students applying little or no effort to the assessment and in many cases skipping it completely. This was especially true if the participant had applied a self-determined &#x0201c;great deal&#x0201d; of effort on an in-class assignment, and in most instances in which this occurred it was after completing a challenging puzzle activity. This is supported by the percentage of AIP assessments that received a score of &#x0201c;0&#x0201d; (a score of &#x0201c;0&#x0201d; was exclusively used to indicate that the question was left blank). The percentage of AIP assessments with a &#x0201c;0&#x0201d; in the puzzle-based portion of the study was 30.2&#x000a0;%, versus 14.5&#x000a0;% in the traditional lecture-based portion of the study. It is for this reason that we assume there exists a decrease in the students&#x02019; performance on this assessment during the puzzle-based portion of the study. It is possible that this trend in overall decreased performance in AIP scores over time is why other similar studies performed these assessments at only one time point during a semester (<italic>i.e.</italic> once in the spring and once in the fall) [<xref ref-type="bibr" rid="CR10">10</xref>].</p><p>This may suggest that these assessments can only effectively measure a broader conceptual understanding in a limited set of contexts, and not in the context of a Human Anatomy and Physiology II Lab. Alternatively, this may suggest that in order to gain useful information using the AIP assessments that there must be fewer total assessments per individual, and/or that the assessments may need to be conducted such that the&#x000a0;degree of perceived effort needed for this assessment is reduced. Furthermore, had this study been conducted in the Human Anatomy and Physiology&#x000a0;I lab, it possibly would have eliminated the de-motivational effect of course expectation, as the students would have had less prior experience for comparison, and the benefit of the puzzle-based pedagogy may have been even more dramatically demonstrated.</p></sec></sec><sec id="Sec14" sec-type="conclusion"><title>Conclusion</title><p>In keeping with numerous other studies that have highlighted the importance of pedagogical style in various courses, our findings support the critical role of pedagogy in student performance. This study also emphasizes the popular view that a broad contextual framework improves a student&#x02019;s ability to recall specific details and that the individual characteristics of an instructor play a significant role in utilizing pedagogy to influence students&#x02019; performance. Additionally, our findings indicate that there is currently no assessment that can effectively quantify broader conceptual understanding across multiple fields of academia. In conclusion, a puzzle-based pedagogy, when compared to traditional lecture-based teaching, can effectively enhance the performance of students on assessments, even when the assessments only test a limited conceptual understanding of the material.</p></sec></body><back><fn-group><fn><p><bold>Competing interests</bold></p><p>The authors declare that they have no competing interests.</p></fn><fn><p><bold>Authors&#x02019; contributions</bold></p><p>LS proposed project and was critical for every aspect of project, including sole authorship of submitted manuscript. LS also designed puzzle activities, as well as in-class lectures. LS acted as a teaching assistant in 4 of 7 course sections and in doing so administered all assessments to participants, graded assessments, graded both puzzle activities and prelab in-class assignments, answered questions from participants during in-class activities, and gave lectures. AD graded assessments, as well as puzzle activities and prelab in-class assignments, ran all statistical analyses, had critical input regarding experimental design, provided intellectual contributions during the initial planning of project, and approved of the final draft of the manuscript. JP acted as a teaching assistant in 3 of 7 course sections and in doing so administered all assessments to participants, graded assessments, graded both puzzle activities and prelab in-class assignments, answered questions from participants, and gave lectures. JP provided intellectual contributions during the initial planning of project, and approved of the final draft of the manuscript. CY provided some intellectual contributions during the initial planning of project, and approved of the final draft of the manuscript. All authors read and approved the final manuscript.</p></fn></fn-group><ack><title>Acknowledgements</title><p>Funding and Facilitation of Project: The University of Akron, The Integrated Biosciences Program, The Department of Biology.</p><p>Mentors: Dr. Peter Niewiarowski, Pro. Jeffery Spencer, Dr. Bruce Cushing</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>K</given-names></name><name><surname>Allen</surname><given-names>D</given-names></name></person-group><article-title>Approaches to biology teaching and learning: understanding the wrong answers&#x02013;teaching toward conceptual change</article-title><source>Cell Biol Educ</source><year>2005</year><volume>4</volume><fpage>112</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1187/cbe.05-02-0068</pub-id><pub-id pub-id-type="pmid">15917868</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boaler</surname><given-names>J</given-names></name></person-group><article-title>Alternative approaches to teaching, learning and assessing mathematics</article-title><source>Eval Program Plann</source><year>1998</year><volume>21</volume><fpage>129</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/S0149-7189(98)00002-0</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivers</surname><given-names>DB</given-names></name></person-group><article-title>Using a course-long theme for inquiry-based laboratories in a comparative physiology course</article-title><source>Adv Physiol Educ</source><year>2002</year><volume>26</volume><fpage>317</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1152/advan.00001.2002</pub-id><pub-id pub-id-type="pmid">12444004</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>J</given-names></name></person-group><source>A review of research on project-based learning</source><year>2000</year><publisher-loc>San Rafael, CA</publisher-loc><publisher-name>The Autodesk Foundation</publisher-name></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tretten</surname><given-names>R</given-names></name><name><surname>Zachariou</surname><given-names>P</given-names></name></person-group><source>Learning about project-based learning: assessment of project-based learning in Tinkertech schools</source><year>1997</year><publisher-loc>San Rafael, CA</publisher-loc><publisher-name>The Autodesk Foundation</publisher-name></element-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Falkner N, Sooriamurthi R, Michalewicz Z. Puzzle-based learning for engineering and computer science. Computer. 2010;20&#x02013;28.</mixed-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>KM</given-names></name><name><surname>Wandersee</surname><given-names>JH</given-names></name><name><surname>Moody</surname><given-names>D</given-names></name></person-group><source>Mapping biology knowledge</source><year>2001</year><publisher-loc>Dordrecht, Netherlands</publisher-loc><publisher-name>Kluwer</publisher-name></element-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Frey BB, Schmitt VL, Allen JP. Defining Authentic Classroom Assessment. Practical Assessments Research &#x00026; Evaluation. 2012. p.17.</mixed-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Newmann</surname><given-names>FM</given-names></name><name><surname>Archbald</surname><given-names>DA</given-names></name></person-group><article-title>The nature of authentic academic achievement</article-title><source>Toward a new science of educational testing and assessment</source><year>1992</year><publisher-loc>Albany, NY</publisher-loc><publisher-name>State University of New York Press</publisher-name></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newmann</surname><given-names>FM</given-names></name><name><surname>Wehlage</surname><given-names>G</given-names></name></person-group><article-title>Authentic pedagogy and student performance</article-title><source>Am J Educ</source><year>1996</year><volume>104</volume><fpage>280</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1086/444136</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Newmann</surname><given-names>FM</given-names></name></person-group><article-title>Authentic assessment in social studies: standards and examples</article-title><source>Handbook of classroom assessment: learning, adjustment and achievement</source><year>1997</year><publisher-loc>San Diego, CA</publisher-loc><publisher-name>Academic</publisher-name></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newmann</surname><given-names>FM</given-names></name></person-group><article-title>Research news and comment: an exchange of views on &#x0201c;semantics, psychometrics, and assessment reform: a close look at &#x02018;authentic&#x02019; assessments&#x0201c;</article-title><source>Educ Res</source><year>1998</year><volume>27</volume><issue>6</issue><fpage>19</fpage><lpage>20</lpage></element-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Palm T. Performance assessment and authentic assessment. Practical assessments research &#x00026; evaluation. 2008;13.</mixed-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barron</surname><given-names>BJS</given-names></name><name><surname>Schwartz</surname><given-names>DL</given-names></name><name><surname>Vye</surname><given-names>NJ</given-names></name><name><surname>Moore</surname><given-names>A</given-names></name><name><surname>Petrosino</surname><given-names>A</given-names></name><name><surname>Zech</surname><given-names>L</given-names></name><etal/></person-group><article-title>Doing with understanding: lessons from research on problem- and project-based learning</article-title><source>J Learn Sci</source><year>1998</year><volume>7</volume><fpage>271</fpage><lpage>311</lpage></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraemer</surname><given-names>EW</given-names></name><name><surname>Lombardo</surname><given-names>SV</given-names></name><name><surname>Lepkowski</surname><given-names>J</given-names></name></person-group><article-title>The librarian, the machine, or a little of both; a comparative study of three information literacy pedagogies at Oakland University</article-title><source>Coll Res Libr</source><year>2007</year><volume>68</volume><fpage>330</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.5860/crl.68.4.330</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merrick</surname><given-names>KE</given-names></name></person-group><article-title>An empirical evaluation of puzzle-based learning as an interest approach for teaching introductory computer science</article-title><source>IEEE Trans Educ</source><year>2010</year><volume>53</volume><fpage>677</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1109/TE.2009.2039217</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Michalewicz</surname><given-names>M</given-names></name></person-group><source>Puzzle-based learning: an introduction to critical thinking, mathematics, and problem solving</source><year>2008</year><publisher-loc>Melbourne Victoria Australia</publisher-loc><publisher-name>Hybrid Publishers</publisher-name></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Greening</surname><given-names>T</given-names></name><name><surname>Kay</surname><given-names>J</given-names></name><name><surname>Kingston</surname><given-names>JH</given-names></name><name><surname>Crawford</surname><given-names>K</given-names></name></person-group><article-title>Problem-based learning of first year computer science</article-title><source>Proceedings of the 1st Australasian Conference on Computer Science Education. Association for Computing Machinery</source><year>1996</year><fpage>13</fpage><lpage>8</lpage></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>DF</given-names></name></person-group><article-title>Problem based learning</article-title><source>BMJ</source><year>2008</year><volume>336</volume><fpage>971</fpage><pub-id pub-id-type="doi">10.1136/bmj.39546.716053.80</pub-id><pub-id pub-id-type="pmid">18456594</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinstein</surname><given-names>J</given-names></name><name><surname>Dhoble</surname><given-names>A</given-names></name><name><surname>Ferenchick</surname><given-names>G</given-names></name></person-group><article-title>Puzzle based teaching versus traditional instruction in electrocardiogram interpretation for medical students&#x02013;a pilot study</article-title><source>BMC Med Educ</source><year>2009</year><volume>9</volume><fpage>4</fpage><pub-id pub-id-type="doi">10.1186/1472-6920-9-4</pub-id><pub-id pub-id-type="pmid">19144134</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parhami</surname><given-names>B</given-names></name></person-group><article-title>Motivating computer engineering freshmen through mathematical and logical puzzles</article-title><source>IEEE Trans on Educ</source><year>2009</year><volume>52</volume><fpage>360</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1109/TE.2008.930087</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Presthus W, Bygstad B. Business intelligence in college: a teaching case with real life puzzles. J Inform Technol Educ: Innovations In Practice. 2012;11.</mixed-citation></ref></ref-list></back></article>