<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="methods-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29674986</article-id><article-id pub-id-type="pmc">5895927</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2018.00444</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Protocols</subject></subj-group></subj-group></article-categories><title-group><article-title>Comparing Feedback Types in Multimedia Learning of Speech by Young Children With Common Speech Sound Disorders: Research Protocol for a Pretest Posttest Independent Measures Control Trial</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Doub&#x000e9;</surname><given-names>Wendy</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/498080/overview"/></contrib><contrib contrib-type="author"><name><surname>Carding</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Flanagan</surname><given-names>Kieran</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/507150/overview"/></contrib><contrib contrib-type="author"><name><surname>Kaufman</surname><given-names>Jordy</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/15274/overview"/></contrib><contrib contrib-type="author"><name><surname>Armitage</surname><given-names>Hannah</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Film and Animation, Faculty of Health Arts and Design, Swinburne University of Technology</institution>, <addr-line>Melbourne, VIC</addr-line>, <country>Australia</country></aff><aff id="aff2"><sup>2</sup><institution>Speech Pathology, Australian Catholic University</institution>, <addr-line>Brisbane, QLD</addr-line>, <country>Australia</country></aff><aff id="aff3"><sup>3</sup><institution>Department of Psychological Sciences, Faculty of Health Arts and Design, Swinburne University of Technology</institution>, <addr-line>Melbourne, VIC</addr-line>, <country>Australia</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Nicola Pitchford, University of Nottingham, United Kingdom</p></fn><fn fn-type="edited-by"><p>Reviewed by: Jess Price, University of Nottingham Malaysia Campus, Malaysia; Christine, Xiang Ru Leong, University of Nottingham Malaysia Campus, Malaysia</p></fn><corresp id="c001">*Correspondence: Wendy Doub&#x000e9; <email>wdoube@swin.edu.au</email></corresp><fn fn-type="other" id="fn001"><p>This article was submitted to Educational Psychology, a section of the journal Frontiers in Psychology</p></fn></author-notes><pub-date pub-type="epub"><day>05</day><month>4</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>9</volume><elocation-id>444</elocation-id><history><date date-type="received"><day>16</day><month>11</month><year>2017</year></date><date date-type="accepted"><day>16</day><month>3</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Doub&#x000e9;, Carding, Flanagan, Kaufman and Armitage.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Doub&#x000e9;, Carding, Flanagan, Kaufman and Armitage</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Children with speech sound disorders benefit from feedback about the accuracy of sounds they make. Home practice can reinforce feedback received from speech pathologists. Games in mobile device applications could encourage home practice, but those currently available are of limited value because they are unlikely to elaborate &#x0201c;Correct&#x0201d;/&#x0201d;Incorrect&#x0201d; feedback with information that can assist in improving the accuracy of the sound. This protocol proposes a &#x0201c;Wizard of Oz&#x0201d; experiment that aims to provide evidence for the provision of effective multimedia feedback for speech sound development. Children with two common speech sound disorders will play a game on a mobile device and make speech sounds when prompted by the game. A human &#x0201c;Wizard&#x0201d; will provide feedback on the accuracy of the sound but the children will perceive the feedback as coming from the game. Groups of 30 young children will be randomly allocated to one of five conditions: four types of feedback and a control which does not play the game. The results of this experiment will inform not only speech sound therapy, but also other types of language learning, both in general, and in multimedia applications. This experiment is a cost-effective precursor to the development of a mobile application that employs pedagogically and clinically sound processes for speech development in young children.</p></abstract><kwd-group><kwd>feedback</kwd><kwd>speech sound disorder</kwd><kwd>phonological disorder</kwd><kwd>multimedia learning</kwd><kwd>video game</kwd><kwd>mobile application</kwd></kwd-group><counts><fig-count count="4"/><table-count count="4"/><equation-count count="0"/><ref-count count="48"/><page-count count="12"/><word-count count="8916"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>Speech development resources and materials for use on tablet-based and touchscreen devices have become widely available in recent years. However, these resources are severely restricted by the lack of research knowledge about how best to get children to engage, interact and learn from their use. In clinical and classroom settings children with significant speech sound disorders require highly individualized feedback that takes into consideration the child's diagnosis, performance and personal factors (e.g., motivation, attention and self-esteem). Outside the clinic and the classroom, they receive feedback from interaction with the world around them. In particular, speech pathology treatments benefit from home practice. However, applications for mobile devices are unlikely to provide feedback on speech sounds produced by children (see section Preliminary App Search). This project will set up a series of experiments (The Wizard of Oz experiments) to systematically examine which aspects of feedback are most effective in engaging and motivating children with speech sound disorders to use the computer technology that is currently available. This will ultimately result in developed portable technologies which will allow children with speech sound disorders to fully engage and benefit from highly sophisticated speech training &#x0201c;apps&#x0201d; on tablet, web and smart phone devices to assist with homework when engaged in speech pathology interventions with a speech pathologist and consequently develop intelligible and age-appropriate speech. This technology will provide much needed resources for large numbers of children who live in regional, remote and rural settings and who have very limited access to specialist remediation and treatment.</p><p>By far, the two most common speech sound disorders are &#x0201c;phonological delay&#x0201d; and &#x0201c;phonological disorder&#x0201d; with approximately 75% of children with a speech sound disorder meeting the criteria for these diagnoses (Dodd, <xref rid="B12" ref-type="bibr">2005</xref>). Children with phonological delay/disorder are able to produce all sounds expected for their age but make systematic sound substitutions that are either typical of younger children (in the case of phonological delay) or not seen in typical development (in the case of phonological disorder) (Dodd, <xref rid="B13" ref-type="bibr">2014</xref>). For example, a child with a phonological delay may have the error pattern of &#x0201c;stopping&#x0201d; where all fricative sounds (e.g., /s/, /f/, /v/, /z/ etc) are produced as stops (e.g., /t/, /p/, /b/, /d/ etc.) such that &#x0201c;sun&#x0201d; would be produced as &#x0201c;tun&#x0201d; and &#x0201c;fan&#x0201d; as &#x0201c;pan.&#x0201d; Although theories of phonological development vary, it is widely held that minimal pair therapy in the context of speech pathology intervention can be used to resolve phonological delay and disorder (Baker, <xref rid="B2" ref-type="bibr">2010</xref>). In most iterations of the technique, minimal pair therapy involves presenting a child with word pairs that differ by one minimal feature so that the child's error pattern would cause the two words to sound the same (i.e., as homophones). Using the aforementioned example of the child producing fricatives as stops, the child would produce the words &#x0201c;see&#x0201d; and &#x0201c;tea&#x0201d; as &#x0201c;tea&#x0201d; or &#x0201c;four&#x0201d; and &#x0201c;paw&#x0201d; as &#x0201c;paw,&#x0201d; &#x0201c;zoo&#x0201d; and &#x0201c;do&#x0201d; as &#x0201c;do&#x0201d; etc. In the context of therapy, the child's error of producing the minimal pair targets as homophones (e.g., &#x0201c;see&#x0201d; and &#x0201c;tea&#x0201d; as &#x0201c;tea&#x0201d;) creates semantic confusion for the treating clinician and, as a result, the clinician provides feedback to the child that both productions sound the same (e.g., all productions produced as &#x0201c;tea&#x0201d;). This feedback encourages the child to make a phonetic contrast between the minimal pair words (e.g., contrast between the fricative /s/ and stop /t/ sounds in &#x0201c;sea&#x0201d; and &#x0201c;tea&#x0201d;) so that the clinician can distinguish between the child's production of the minimal pair words (Weiner and Ostrowski, <xref rid="B45" ref-type="bibr">1979</xref>). Quite apart from theories of phonological development and representation, the effectiveness of phonological therapy is likely to derive from feedback from the clinician of the child's homophonic productions and the child's motivation to rectify this error.</p><sec><title>Feedback in a multimedia environment</title><p>Feedback can be defined as &#x0201c;any message that is generated in response to a student's action&#x0201d; (Mason and Bruning, <xref rid="B25" ref-type="bibr">2001</xref>). Feedback is a vital component of learning (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>; Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Butler et al., <xref rid="B5" ref-type="bibr">2013</xref>) and the motivational processes that support it (Harks et al., <xref rid="B18" ref-type="bibr">2014</xref>) in both face-to-face and computer-based environments (Mason and Bruning, <xref rid="B25" ref-type="bibr">2001</xref>; Moreno, <xref rid="B32" ref-type="bibr">2004</xref>; Corbalan et al., <xref rid="B9" ref-type="bibr">2009</xref>). The terminology for types of feedback is not consistent. For consistency and for relevance to this investigation of both multimedia learning and speech therapy, this study predominantly adopts terminology and concepts gleaned from &#x0201c;a large body of research&#x0201d; in Narciss et al. (<xref rid="B35" ref-type="bibr">2014</xref>) largely consistent with the comprehensive literature review of factors influencing formative feedback in Shute (<xref rid="B41" ref-type="bibr">2008</xref>) which includes feedback categories specifically for multimedia discussed in Narciss and Huth (<xref rid="B34" ref-type="bibr">2004</xref>). See Table <xref ref-type="table" rid="T1">1</xref> for the sources of each category in the taxonomy we adopted which we will now describe. Systematic reviews of feedback in learning suggest that, notwithstanding instructional, individual, and situational differences, feedback is generally more effective when elaborated with an informational, or <italic>formative</italic>, component (Mason and Bruning, <xref rid="B25" ref-type="bibr">2001</xref>; Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>). In contrast to formative feedback, <italic>summative</italic> feedback of a mark or grade, and <italic>verification</italic> feedback indicating the correctness of a learner response, do not contain information to assist learners in improving their understanding.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Types of feedback commonly used to teach sounds and suitable for multimedia environments, with categories in decreasing order of complexity.</p></caption><table frame="hsides" rules="groups"><thead><tr style="border-bottom: thin solid #000000;"><th valign="top" align="left" rowspan="1" colspan="1"><bold>Feedback category</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Type of formative and verification feedback</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Description</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic occurs directly in response to a learner action but is not a comment on the action.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Extrinsic (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">A comment on a learner response or action. Formative and Verification feedback are Extrinsic.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Formative (Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Contains Information to assist the learner in bridging the gap between their conception and the concepts to be learned. Can be topic contingent or response contingent</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Topic contingent (Mason and Bruning, <xref rid="B25" ref-type="bibr">2001</xref>; Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Elaborative information about the topic being learned. Shute suggests this can reteach the same material whereas Mason and Narciss describe directing learners to search for information themselves.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Response contingent (Shute, <xref rid="B41" ref-type="bibr">2008</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Elaborative information about the learner's response explaining reasons for both incorrect and correct responses.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">KP (Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Knowledge about how to Process the task addresses procedural knowledge. It can be either topic or response contingent.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">KM (Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Knowledge of Mistakes finds errors or provides hints for finding them. Can be either topic or response contingent. Also known as Bugs/Misconceptions when response contingent.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">KC (Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Knowledge of Concepts is topic contingent information about concepts.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Verification (Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Does not contain information other than correct / incorrect.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">KCR(Shute, <xref rid="B41" ref-type="bibr">2008</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Knowledge of Correct Response describes correct answer but no other information.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">RUC(Shute, <xref rid="B41" ref-type="bibr">2008</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Repeat Until Correct indicates incorrect by presenting the task again and proceeds to the next task when a correct response is received. It provides no other information. Also known as Try Again (Shute) or Answer until Correct (Narciss).</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">MT (Shute, <xref rid="B41" ref-type="bibr">2008</xref>; Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Multiple Try proceeds to the next task when a correct response is received or after a predetermined limited number of attempts.</td></tr><tr><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">KR (Shute, <xref rid="B41" ref-type="bibr">2008</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Knowledge of Results indicates correct or incorrect but provides no other information.</td></tr></tbody></table></table-wrap><p>In this paragraph we draw upon examples from speech pathology approaches to illustrate the taxonomy of feedback terminology we adopted, roughly in order of increasing complexity. When working with a child with speech sound disorder (such as a phonological disorder) speech pathologists might highlight errors by claiming to misunderstand the child (Yont et al., <xref rid="B48" ref-type="bibr">2000</xref>; Masso et al., <xref rid="B27" ref-type="bibr">2014</xref>). When the speech pathologist provides no other feedback or cues to assist in correcting the error, this approach could be categorized as <italic>verification</italic> feedback. The verification feedback would be classified as <italic>Knowledge of Response</italic> (KR) when the lesson immediately moves on to a new sound or <italic>Multiple Try</italic> (MT) when the child can make a finite number of attempts or <italic>Repeat Until Correct</italic> (RUC) when the child continues making sounds until an acceptable sound is produced. If the error persists, a speech pathologist might present the sound/word again, providing <italic>Knowledge of Correct Response</italic> (KCR) (e.g., &#x0201c;Try and say &#x0201c;see&#x0201d;). In the absence of speech production literature, Maas et al. (<xref rid="B24" ref-type="bibr">2008</xref>) extrapolated from sensorimotor learning literature to suggest that KR alone may be insufficient for learners, who, in the early stages of speech therapy may require further instruction about the processes in achieving an accurate production or may have difficulty discriminating between a correct or incorrect production. Similarly, Hewlet (<xref rid="B19" ref-type="bibr">1990</xref>) postulated that children need, in addition to awareness of errors in production, knowledge of the ways to articulate a speech target. In other words, <italic>formative</italic> feedback could be more effective than the types of <italic>verification</italic> feedback described above. A demonstration or description of the articulatory processes associated with the sound is a type of formative feedback described as <italic>Knowledge of How to Process the Task</italic> (KP) (Narciss et al., <xref rid="B35" ref-type="bibr">2014</xref>). In this case, the speech pathologist might supplement the KR or KCR with formative feedback providing information about the task to be performed, the underlying concepts or topics in producing the sound (e.g., &#x0201c;Make sure you use your &#x0201c;long sound&#x0201d; when you say &#x0201c;see&#x0201d;), or the processes in producing the sound (e.g., &#x0201c;To make your long sound /s/, make sure that you put your tongue behind your teeth and make long, gentle air&#x0201d;). If the feedback explains the difference between the child's articulatory processes (<italic>Knowledge of Mistake, KM</italic>) and the correct articulation, it would be <italic>response contingent</italic> (e.g., &#x0201c;You said &#x0201c;tea&#x0201d; with a short sound. You need to say &#x0201c;see&#x0201d; with a long sound). If it explains the correct processes without referring to the child's processes, it would be <italic>topic contingent</italic> (e.g., &#x0201c;You need to use your long sound&#x0201d;). Although response contingent feedback is generally considered more effective than topic contingent feedback, procedural skills have been found to benefit from KCR followed by topic contingent feedback, without reference to errors (Shute, <xref rid="B41" ref-type="bibr">2008</xref>). From a narrative review of computer-based instruction, Mason and Bruning (<xref rid="B25" ref-type="bibr">2001</xref>) present a model of feedback variables that suggests that KCR and response contingent feedback is suitable in low level tasks for learners with low levels of prior knowledge whereas KCR followed by topic contingent feedback is more suitable for learners with higher levels of prior knowledge.</p><p>In this paragraph we discuss feedback in multimedia environments. Children initially learn to speak when interacting with their carers and the wider world (Topping et al., <xref rid="B42" ref-type="bibr">2013</xref>). A multimedia environment could simulate natural settings for speech production and language development within mobile device applications thus providing additional opportunities for practice which can build on children's experiences. Cognitive Theory of Multimedia Learning (CTML) provides an evidence-based framework for learning with visual and auditory sensory channels (Mayer, <xref rid="B28" ref-type="bibr">2005</xref>). CTML has been extended to game-play (Mayer, <xref rid="B29" ref-type="bibr">2014a</xref>) and E-learning (Clark and Mayer, <xref rid="B6" ref-type="bibr">2016</xref>) and can consequently guide the development of a virtual speech therapist. Although CTML examines interactivity, it does not focus on feedback. In contrast, the Interactive Tutoring Feedback model views feedback as &#x0201c;one of several basic components of a generic feedback loop, not as an isolated element of instruction&#x0201d; (Narciss, <xref rid="B33" ref-type="bibr">2017</xref>). Similarly, the Conversational Framework for Multimedia Learning (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>) asserts that multimedia learning environments should attempt to replicate learner-teacher dialogue, repeating the feedback loop until the learner's conception matches that of the instructor. Within Laurillard's framework, <italic>intrinsic</italic> feedback received directly in response to learner action on the multimedia environment can assist in relating the learner's concrete experiences of the world to learning goals whereas <italic>extrinsic</italic> feedback is received as a comment on the learner action and would require additional cognitive processing (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>, pp. 58&#x02013;69). In natural settings children would receive intrinsic feedback on the clarity of their speech from responses to their questions or requests, for example, if they ask for more meat but receive a glass of milk instead. Furthermore, &#x0201c;. although not an inevitable response to the action, [correction of] pronunciation is a social norm and feedback of this type is natural and probable in a social situation&#x0201d; (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>, p. 62). An example of intrinsic feedback in a multimedia environment would be an object such as a spaceship moving fast in response to a child saying &#x0201c;fast&#x0201d; or moving slowly when the child says &#x0201c;slow.&#x0201d; Most summative, verification and formative feedback discussed in the paragraph above can be thought of as extrinsic. It could be argued that the speech pathology approach of semantic confusion used as feedback in minimal pair therapy is not merely KR but is instead a type of intrinsic feedback that mirrors a real-world response.</p><p>Table <xref ref-type="table" rid="T1">1</xref> summarizes our discussion of types of feedback commonly used in speech pathology sessions and suitable for multimedia environments. It illustrates the hierarchy from the postulated highest level of complexity (intrinsic) to the lowest level (verification). To assist the reader, Table <xref ref-type="table" rid="T2">2</xref> presents some further examples of multimedia implementations of the individual type of feedback in response to speech sound pronunciation by children.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Examples of implementation in multimedia for common types of feedback.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Type of feedback</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Multimedia example</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Multimedia feedback example</bold></th></tr></thead><tbody><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">KR/RUC</td><td valign="top" align="left" rowspan="1" colspan="1">Memory card game<break/>A grid of cards is presented face down. The card faces consist of pairs of pictures. The child:<break/>&#x02022;Taps on a card to see a picture and hear the word for that picture<break/>&#x02022;Taps on another card to see the matching picture<break/>&#x02022;Says the word for the picture<break/>If the correct picture is chosen and the word is correctly pronounced, the child's score is increased by 1 and the pair is removed from the grid. In multiplayer games, the winner has the greatest number of pairs.</td><td valign="top" align="left" rowspan="1" colspan="1">If the word is not pronounced correctly,<break/>KR&#x02013;The pair of cards returns to face down. In multiplayer games another player takes a turn<break/>RUC&#x02013;If the picture matches, the child can say the word in the picture again until correct, or<break/>MT&#x02013;for a predetermined number of attempts (for example, three).</td></tr><tr style="border-bottom: thin solid #000000;"><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic</td><td valign="top" align="left" rowspan="1" colspan="1">Adventure video game<break/>Objects in a game perform actions in response to accurate pronunciation. For example, a character moves from one scene to another, collecting or using objects along the way to help their journey. A gate object is highlighted in the game, and the child hears the word &#x0201c;gate.&#x0201d; The child then says the word &#x0201c;gate.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">If the word is not pronounced correctly, the gate remains closed. In minimal pairs, if the child makes the predicted error, the image of a gate could be replaced with an image of a date (the predicted error). If it is correctly pronounced, the gate opens and the next scene appears on the screen. If the word is partially correct, the gate opens partly, in response to the degree of correctness, but the next screen does not appear.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">KP</td><td valign="top" align="left" rowspan="1" colspan="1">3D Talking head and/or elaborative feedback comments</td><td valign="top" align="left" rowspan="1" colspan="1">The talking head demonstrates correct movements. Text or spoken comments such as &#x0201c;Move your tongue further back in your mouth&#x0201d; could be presented either alone or accompanying the talking head.</td></tr></tbody></table></table-wrap><p>Limited evidence can be found in literature reviews for the ability of educational computer games to support the acquisition of knowledge and skills (Connolly et al., <xref rid="B8" ref-type="bibr">2012</xref>; Merchant et al., <xref rid="B31" ref-type="bibr">2014</xref>; Boyle et al., <xref rid="B4" ref-type="bibr">2016</xref>; Clark and Mayer, <xref rid="B6" ref-type="bibr">2016</xref>, pp. 368&#x02013;389; Hainey et al., <xref rid="B17" ref-type="bibr">2016</xref>). Importantly, strong evidence can be found of an association between elaborative or formative feedback and positive learning outcomes from computer games, with feedback type depending on a range of variables such as learning content and learner prior knowledge (Moreno, <xref rid="B32" ref-type="bibr">2004</xref>; Merchant et al., <xref rid="B31" ref-type="bibr">2014</xref>). The inclusion of motivational features such as autonomy, appealing colors and face-like images can support learning if they comply with CTML principles, in particular when relevant to the content and not a source of distraction (Ryan et al., <xref rid="B39" ref-type="bibr">2006</xref>; Mayer, <xref rid="B30" ref-type="bibr">2014b</xref>). Strong evidence of positive learning outcomes supports personalization, in particular with avatars which gesture and speak polite conversational language with a human voice (Clark and Mayer, <xref rid="B6" ref-type="bibr">2016</xref>, pp. 169&#x02013;200).</p></sec><sec><title>Wizard of Oz experiments</title><p>Speech pathology applications for independent practice could benefit from speech pathology and multimedia learning expertise during their design and before the expense of development. &#x0201c;Wizard of Oz&#x0201d; experiments provide learners with a computer interface, but supply feedback from a hidden human expert as illustrated in Figures <xref ref-type="fig" rid="F1">1</xref>, <xref ref-type="fig" rid="F2">2</xref>. The approach was used to influence the design of feedback for adult second language learners (Engwall et al., <xref rid="B16" ref-type="bibr">2006</xref>; Engwall and B&#x000e4;lter, <xref rid="B15" ref-type="bibr">2008</xref>) but has not been used to investigate speech sound development to our knowledge. We envisage that a &#x0201c;Wizard of Oz&#x0201d; experiment would provide evidence for the provision of effective multimedia feedback for speech sound development.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>&#x0201c;Wizard of Oz&#x0201d; setup.</p></caption><graphic xlink:href="fpsyg-09-00444-g0001"/></fig><fig id="F2" position="float"><label>Figure 2</label><caption><p>The Main menu screen and the Intrinsic feedback menu screen seen by the &#x0201c;Wizard&#x0201d;.</p></caption><graphic xlink:href="fpsyg-09-00444-g0002"/></fig></sec><sec><title>Aims and objectives</title><p>This study is the first step toward our long-term objective to create a Virtual Speech Therapist that employs pedagogically and clinically sound processes for speech development in young children to assist with home practice as part of therapy with a speech pathologist. Automatic speech recognition (ASR) systems are complex and time-consuming to develop. Sophisticated algorithms are required to cover all possible pronunciations, correct and incorrect, in different voices and background noise conditions (Renals and King, <xref rid="B38" ref-type="bibr">2010</xref>). In speech and language learning, they may identify correct pronunciation as incorrect and vice-versa (Massaro and Light, <xref rid="B26" ref-type="bibr">2004</xref>; van Doremalen et al., <xref rid="B43" ref-type="bibr">2016</xref>). Our study will investigate the effectiveness of different types of feedback for speech sound substitutions occurring in phonological disorders, unhindered by confounding problems in automatic speech recognition (Massaro and Light, <xref rid="B26" ref-type="bibr">2004</xref>) and before committing resources to the development of complicated software.</p><p>This study aims to employ a &#x0201c;Wizard of Oz&#x0201d; design to evaluate the efficacy within a multimedia platform of four types of feedback to assist speech development in young children. In particular, the study aims to compare predominant types of feedback given by speech pathologists during minimal pair therapy, and those recommended in learning literature, with those recommended for multimedia learning.</p></sec><sec><title>Research questions</title><list list-type="order"><list-item><p>How effective are different types of feedback in improving speech sounds in young children while using a multimedia platform?</p></list-item><list-item><p>What variables influence the effectiveness of each type of feedback?</p></list-item></list></sec></sec><sec id="s2"><title>Materials and equipment</title><sec><title>Participants</title><p>Children aged between 4 and 6 with phonological delay or phonological disorder as identified by a qualified speech pathologist using the Developmental Evaluation of Articulation and Phonology (DEAP; Dodd et al., <xref rid="B14" ref-type="bibr">2002</xref>) will be randomly allocated to five groups, each with 30 participants. Phonological delay is defined as the consistent use of phonological processes that are used in typical development that are supressed by 90% of children of the same chronological age (Dodd, <xref rid="B13" ref-type="bibr">2014</xref>). Phonological disorder was defined as the consistent use of phonological processes in which some of the phonological processes used by that child are not used by 90% of children at any stage of their development (Dodd, <xref rid="B13" ref-type="bibr">2014</xref>). The children will all consistently use one or more of the three phonological processes to be targeted by the intervention of this study (stopping, fronting or cluster reduction). The severity of each child's diagnosis will be either mild, moderate or severe with reference to the normative data for percentage consonants correct (PCC) as measured by the DEAP.</p><p>All children will be monolingual English speakers with receptive language within or above the expected range for their age as measured by the Clinical Evaluation of Language Fundamentals &#x02013;Preschool 2nd Edition (Wiig et al., <xref rid="B46" ref-type="bibr">2006</xref>) or Clinical Evaluation of Language Fundamentals &#x02013;Fourth Edition (Semel et al., <xref rid="B40" ref-type="bibr">2006</xref>). Children will have hearing skills within normal limits as measured by their last hearing test within the last 12 months and will not have other symptoms of developmental delay as reported by parents. The children will also have no apparent deficits in structure and function in oromotor structure and function as determined by examination by a speech pathologist.</p></sec><sec><title>Design</title><p>The study will be a pretest posttest independent measures design with a five level experiment consisting of a control group and a 2 &#x000d7; 2 design for type of feedback (intrinsic or KR) and presence of topic contingent KP feedback in the form of articulation guidance. See Figure <xref ref-type="fig" rid="F3">3</xref> for an overview of the aims, variables, outcomes and measures employed in this experiment.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>Study design.</p></caption><graphic xlink:href="fpsyg-09-00444-g0003"/></fig><p>Children will be randomly allocated to one of four experimental groups or to a control group. For type of feedback, verification feedback types KR/MT/RUC are not highly recommended because they do not supply information to guide the learner. However, KR/MT will be included because it is prevalent in multimedia applications, mainly because it is easy to implement. RUC will be excluded because the number of attempts cannot be controlled and because it may inhibit the timely progress of some children. Intrinsic feedback is recommended for multimedia applications because it can assist learning by building upon, and relating to learners' real-world experience (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>, pp. 58&#x02013;69; Ke, <xref rid="B22" ref-type="bibr">2014</xref>). We are interested in comparing these two types of feedback in an attempt to verify the value of the less easily implemented intrinsic feedback. KP will also be included because it is arguably the most effective type of formative feedback (Shute, <xref rid="B41" ref-type="bibr">2008</xref>) and also because it is prevalent in speech pathology practice (e.g., Maas et al., <xref rid="B24" ref-type="bibr">2008</xref>). Whereas, KR/MT and intrinsic feedback can be provided alone or in combination with other types of feedback, KP usually follows and elaborates another type of feedback. Consequently, two types of feedback (KR/MT and Intrinsic) will be provided in isolation to highlight their differences and a further two will combine them with KP. The combined KR and KP condition will allow us to more closely simulate speech pathology sessions whereas the combined intrinsic and KP condition is recommended as best practice for multimedia environments. A fifth condition will act as a control for changes in speech development which could occur over time, either naturally or because of other interventions. KCR will not be provided as feedback because it will appear as a prompt when the sound is presented to the child. Table <xref ref-type="table" rid="T3">3</xref> summarizes the rationale behind the choices of types of feedback to be compared in the study. Table <xref ref-type="table" rid="T4">4</xref> presents examples of feedback provided to each experimental group.</p><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Rationale for feedback type in experimental conditions.</p></caption><table frame="hsides" rules="groups"><thead><tr style="border-bottom: thin solid #000000;"><th valign="top" align="left" rowspan="1" colspan="1"><bold>Group</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Rationale for use of type of feedback in treatment</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Feedback type</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">Prevalent in multimedia applications for speech production because it is easy to implement.</td><td valign="top" align="left" rowspan="1" colspan="1">KR/MT</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">Simulates natural settings. Recommended in evidence-based literature for learning with multimedia. Included to explore if learning benefits outweigh development costs.</td><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">3</td><td valign="top" align="left" rowspan="1" colspan="1">Recommended in learning literature. Prevalent in speech pathology sessions for young children with speech sound disorders.</td><td valign="top" align="left" rowspan="1" colspan="1">KR/MT + topic contingent KP</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">4</td><td valign="top" align="left" rowspan="1" colspan="1">Recommended as best practice in evidence-based literature for learning with multimedia.</td><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic + topic contingent KP</td></tr></tbody></table></table-wrap><table-wrap id="T4" position="float"><label>Table 4</label><caption><p>Context of presentation and feedback delivery for each group.</p></caption><table frame="hsides" rules="groups"><thead><tr style="border-bottom: thin solid #000000;"><th valign="top" align="left" rowspan="1" colspan="1"><bold>Group</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Feedback type</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Context</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Feedback delivery</bold></th><th rowspan="1" colspan="1"/></tr></thead><tbody><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Correct</td><td valign="top" align="left" rowspan="1" colspan="1">Incorrect</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">1&#x02013;4</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">Basic cue&#x02013;the avatar speaks a word and an image of the word is presented.</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">KR/MT</td><td valign="top" align="left" rowspan="1" colspan="1">Basic</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;That's right. Let's move on to the next word.&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0201c;Try again.&#x0201d; After three attempts, &#x0201c;Not quite but let's try another word.&#x0201d;</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic</td><td valign="top" align="left" rowspan="1" colspan="1">Basic +<break/>Image becomes an interactive object in a game.<break/>Avatar says &#x0201c;can you make &#x02026;. happen when you say &#x02026;.?&#x0201d;</td><td valign="top" align="left" rowspan="1" colspan="1">The interaction happens in a way that indicates the child's utterance has been understood and the game proceeds to the next interaction.</td><td valign="top" align="left" rowspan="1" colspan="1">If the child's utterance is:<break/>(a) Not at all accurate, the object is haloed and no action occurs.<break/>(b) Not accurate but partially understandable, the object is haloed, a partial action occurs, but the object returns to its base state.<break/>(c) The predicted minimal pair error, the object is shown as the pair and then returns to its base state.<break/>After three attempts the next object is presented. Possibly comment &#x0201c;I don't understand what you said&#x0201d;</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">3</td><td valign="top" align="left" rowspan="1" colspan="1">KR/MT +KP</td><td valign="top" align="left" rowspan="1" colspan="1">As in 1</td><td valign="top" align="left" rowspan="1" colspan="1">As in 1</td><td valign="top" align="left" rowspan="1" colspan="1">As in 1 plus a spoken comment describing correct articulation</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">4</td><td valign="top" align="left" rowspan="1" colspan="1">Intrinsic +KP</td><td valign="top" align="left" rowspan="1" colspan="1">As in 2</td><td valign="top" align="left" rowspan="1" colspan="1">As in 2</td><td valign="top" align="left" rowspan="1" colspan="1">As in 2 plus a spoken comment describing correct articulation</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">5</td><td valign="top" align="left" rowspan="1" colspan="1">Control group</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td><td valign="top" align="left" rowspan="1" colspan="1">N/A</td></tr></tbody></table></table-wrap></sec><sec><title>Outcome measurement</title><p>The relative benefits of the different experimental conditions will be measured by the primary measure of changes in use of phonological processes and PCC from pre-test to post-test as measured by the DEAP (Dodd et al., <xref rid="B14" ref-type="bibr">2002</xref>). Such assessment will capture suppression of the phonological processes targeted in treatment and generalization effects (if any) to other phonological processes. Phonological process percentage of occurance (Randolph and Wendt, 2014; i.e., the number of times that a child uses a given phonological process) will also be measured and compared pre and posttest. Pre and post-test assessments will be recorded and a sample of the assessments independently analyzed followed by interrater reliability checks. In addition to the pre-test/post-test measures, number of trials and percentage accuracy of trials per session (cumulative accuracy) will be measured for each experimental condition as further indication of the effectiveness of feedback of that condition and determine when goals of intervention have been reached. For example, if a child reaches 90% accuracy of production of target words for one phonological process, another will be targeted. It could be argued that motivation to continue playing will increase practice and consequently improve outcomes (Williams, <xref rid="B47" ref-type="bibr">2012</xref>). A secondary measure of motivation as a variable that could influence the effectiveness of feedback type will be the amount of time participants choose to continue playing the game (Deci et al., <xref rid="B11" ref-type="bibr">1999</xref>) up to a total of 20 min as well as the number of trials they complete.</p></sec><sec><title>Stimuli</title><p>Targets for intervention will be minimal pairs addressing the phonological processes of stopping, velar fronting and cluster reduction as, according to Dodd et al. (<xref rid="B14" ref-type="bibr">2002</xref>) 90% of children over 3;11 (3 years and 11 months of age) will have suppressed these phonological processes and they are therefore considered errors at this stage.</p><p>The target words comprising the minimal pairs will be:
<list list-type="bullet"><list-item><p>High frequency, high imageability words</p></list-item><list-item><p>Exclude the consonants /&#x0222b;/ (&#x0201c;sh&#x0201d;), /&#x003b8;/ (voiceless &#x0201c;th&#x0201d;) and /&#x000f0;/ (voiced &#x0201c;th&#x0201d;) as, according to Dodd et al. (<xref rid="B14" ref-type="bibr">2002</xref>) 90% of children by the age of 4;0 can produce all consonants except these.</p></list-item><list-item><p>Exclude words with triclusters (i.e., words with three sounds in a consonant cluster such as &#x0201c;<underline>spl</underline>ash&#x0201d;)</p></list-item><list-item><p>Initial word position as people tend to identify initial sounds more readily than medial or final sounds (Redford and Diehl, <xref rid="B37" ref-type="bibr">1999</xref>).</p></list-item></list></p><p>For each phonological process addressed, five different examples for each minimal pair will be included as stimuli in the experimental tasks. For example, an experimental task targeting stopping could include the minimal pairs &#x0201c;fin-pin,&#x0201d; &#x0201c;see-tea,&#x0201d; &#x0201c;zoo-do,&#x0201d; &#x0201c;fat-pat,&#x0201d; and &#x0201c;zip-dip.&#x0201d; Hodson (<xref rid="B36" ref-type="bibr">2010</xref>) suggested that at least two exemplars of each phonological process be targeted in therapy. In total, 15 minimal pairs will be addressed across the experimental activities. All minimal pairs will be matched for age of acquisition, imageability and concreteness based on the MRC Psycholinguistic database and frequency using the SUBTLEX-UK database (van Heuven et al., <xref rid="B44" ref-type="bibr">2014</xref>).</p></sec><sec><title>Wizard of Oz setup</title><p>The &#x0201c;Wizard of Oz&#x0201d; application will be designed according to CTML principles (Mayer, <xref rid="B29" ref-type="bibr">2014a</xref>,<xref rid="B30" ref-type="bibr">b</xref>; Clark and Mayer, <xref rid="B6" ref-type="bibr">2016</xref>). The experiment will take place in the Swinburne University of Technology BabyLab which has rooms configured as per Figure <xref ref-type="fig" rid="F1">1</xref> with microphones, speakers, cameras, desktop computers and one way windows. The speech pathologist &#x0201c;Wizard&#x0201d; will be hidden from the child. The child will play the game on a mobile tablet device and produce speech sounds as part of the game. The child's speech sounds will be transmitted to a speaker in the Wizard's room. The Wizard will see a range of feedback options on a mobile device such as a smart phone (Figure <xref ref-type="fig" rid="F2">2</xref>) and select the appropriate option which will immediately take effect on the child's tablet. Information captured by video camera and screen capture will be available for analysis.</p></sec><sec><title>Intervention procedure</title><p>Each child in the four experimental groups will see and hear a word as spoken by an avatar in the application on their tablet device. The avatar will ask the child to repeat the word. As shown in Figure <xref ref-type="fig" rid="F1">1</xref> the &#x0201c;Wizard&#x0201d; will hear the child's response and view a monitor display of the child's screen. The &#x0201c;Wizard&#x0201d; will also see each feedback option on a mobile device and will thus be enabled to immediately assess the utterance and select the appropriate feedback. The child will then see and/or hear the selected feedback as delivered by the avatar in the application.</p><p>Each experimental group will receive the same set of words and the same basic presentation of an animal avatar which speaks polite conversational language in a human voice. The words will be presented in random order, rather than a predetermined sequence, to enable children to keep playing as long as they choose. The experimental activity is anticipated to take approximately 10 min. Based on other similar studies in the same laboratory (e.g., Huber et al., <xref rid="B20" ref-type="bibr">2016</xref>) it is not anticipated that most children will chose to play for longer than 20 min. Each word will be spoken by the avatar, simultaneously as it is presented as an image. The avatar will then prompt the child to say the word. The treatment for each group will differ in the context of the presentation and in the feedback delivery as shown Table <xref ref-type="table" rid="T4">4</xref>.</p></sec><sec><title>Session schedule</title><p>Dosage is a significant variable in intervention for speech sound disorders (Baker, <xref rid="B3" ref-type="bibr">2012</xref>; Kaipa and Peterson, <xref rid="B21" ref-type="bibr">2016</xref>) and relates to the number of treatment sessions, the frequency of treatment sessions, length of treatment sessions and number of trials per treatment session (Baker, <xref rid="B3" ref-type="bibr">2012</xref>). A clear precedent has not been set in the literature as to the most effective or efficacious dosage for phonological therapy, let alone home practice (which the study is aiming to investigate). There is evidence to suggest that treatment should occur three times per week (Allen, <xref rid="B1" ref-type="bibr">2013</xref>) but daily home practice is also used (Crosbie et al., <xref rid="B10" ref-type="bibr">2005</xref>). The number of sessions rarely exceeds 16&#x02013;21 sessions in total in studies of phonological therapy (Crosbie et al., <xref rid="B10" ref-type="bibr">2005</xref>; Williams, <xref rid="B47" ref-type="bibr">2012</xref>). Despite the novelty of the study in exploring practice with an app the above literature will be used as a guide such that each participant will attend the Swinburne Babylab facility for individual sessions 3&#x02013;4 days per week over a 2&#x02013;4 week period for a total of 12 sessions (in addition to testing sessions). As the study seeks to investigate the number of trials (from data on percentage accuracy per trial) and length of session as measures of effectiveness of feedback and motivation, respectively, these parameters of dosage will not be set but we expect that children will engage for up to 20 min completing 80&#x02013;100 trials.</p><p>At the start of the first session children will be evaluated by a qualified speech pathologist with experience in the assessment of children with speech sound disorders to confirm that they fit within the inclusion criteria. This step will be accomplished by collecting a case history and include questions relating to the inclusionary and exclusionary questions as well as previous exposure to speech pathology intervention and speech pathology apps. During this assessment session, the speech pathologist will work through a checklist of instructions which are exemplary of instructions used in the therapy task to ascertain the stimulability of the therapy targets and that the child's comprehension of the instructions to be used in the experimental tasks. Errors in comprehension will be corrected by the speech pathologist within this session. Participants will be randomly assigned to a feedback condition or to the control condition and then take the pre-test. The pre-test and post-test will be offered in a room separate from the Babylab to reduce encoding specificity effects that would provide an advantage to the children in the feedback condition relative to those in the control condition. The control group will attend the first session and then return between 2 and 4 weeks later to take posttest. After completing the pretest, the experimental group will be offered 12 sessions of the experimental activities over a 4-week period. The experimental groups will then be familiarized with the Babylab. Each of sessions two to 12 will consist of approximately 10 min for the experimental task followed by approximately 10 min of an unrelated game or activity for an expected total of 20 min. Children will determine when they want to stop playing the experimental activity. As stated above, the children will complete 80&#x02013;100 trials of the target minimal pairs but the exact number of trials completed by each child for each session will be recorded and checked for equity between participants. On completion of the experimental task in session thirteen, children will move from the Babylab to take the post-test. See Figure <xref ref-type="fig" rid="F4">4</xref> for a diagram of the session schedule.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p>Session schedule.</p></caption><graphic xlink:href="fpsyg-09-00444-g0004"/></fig></sec></sec><sec id="s3"><title>Stepwise procedures</title><sec><title>Preliminary app search</title><p>In August 2016 we conducted a preliminary search of unbundled speech therapy applications currently available on the iTunes store for the learning of English speech sounds by children aged 5 years of age and younger. None of the 44 apps returned by the search supplied feedback for the child's utterance. Nineteen apps relied entirely upon speech pathologists and others to provide feedback. Three apps provided feedback specifically to supplement human feedback. Feedback provided by 25 apps was predominantly verification feedback, which requires less informed judgment of the correctness of the utterance compared with elaborative feedback and consequently requires less complicated software. Fifteen apps provided KR feedback alone, and a further four provided KR in combination with other types of feedback. In summary, from the perspective of the literature discussed in this protocol, the apps returned by the search provide insufficient feedback to be of value during independent practice.</p></sec><sec><title>Ethics</title><p>The protocol was approved by Swinburne University Human Ethics Research Committee: SHR Project 2017/262 on October 20 2017, in accordance with the National Statement on Ethical Conduct in Human Research (2007) and the Australian Code for the Responsible Conduct of Research. The assent of children participating will be sought as well as the consent of a parent or legal guardian as per the NHMRC National Statement Guideline 4.2.7.</p><p>The primary operational concern in conducting research into speech sound disorders is the ethical concern of using a non-standard or tested treatment with children. Speech pathology treatments should be characterized by beneficence and non-maleficence yet a non-standard treatment may be of no benefit and delay a child's access to beneficial treatment. The trial described in this protocol avoids these ethical concerns for several reasons. Firstly, the length of this trial is only 3 weeks which is shorter than average waiting list times for speech pathology services (Community Affairs References Committee, <xref rid="B7" ref-type="bibr">2014</xref>) meaning that participation in the trial is unlikely to delay access to standard speech pathology intervention. Secondly, although the need for feedback in speech pathology intervention is accepted by clinicians and adopted into practice, the efficacy of feedback, let alone form or feedback, has not been established in the literature. Some of the treatment conditions in this protocol may expose children to non-standard feedback conditions but without an evidence base for standard practice, non-standard feedback conditions are no less appropriate to use. Thirdly, the treatment conditions proposed are based on sound principles of learning theory and speech pathology practice such that they may be of benefit and are highly unlikely to be of any harm. A final issue is that the control group could be perceived to be disadvantaged as they will not receive the experimental therapy nor traditional therapy during their participation. This is compensated by the fact that they will receive traditional therapy following their participation in the study.</p></sec><sec><title>Feasibility and pilot study</title><p>We have a working HTML5 / JavaScript prototype which provides a) a practice game with images and sounds for three minimal pairs; and b) a demonstration game with KR feedback for a correct response for one minimal pair (Bee/Pea). The prototype is loaded onto a server from where it enables communication from a mobile device operated by a &#x0201c;Wizard&#x0201d; to a device operated by a child. The &#x0201c;Wizard of Oz&#x0201d; application will build on this prototype.</p><p>Once the application is developed, each option in the game will be tested in the Swinburne University BabyLab &#x0201c;Wizard of Oz&#x0201d; setting by the research team, including at least two speech pathologists. Once any revisions to the application are complete, the testing process will be repeated with four children aged four to six.</p></sec><sec><title>Recruitment of participants</title><p>Potential participants will be identified from the Australian Catholic University Speech Pathology in Schools program in Melbourne. This program operates in several Catholic Education Primary Schools in Melbourne. Parents of clients of this service who are identified as having a phonological delay or disorder will be provided with an information sheet about the study. Parents who wish for their children to participate will be required to contact the staff of the study. Additional participants will be recruited through advertisement in kindergartens, day-care centers and playgroups.</p><p>Stratified random sampling based on severity of speech disorder and will be used to allocate children to experimental conditions. This process will ensure that each condition includes similar proportions of children with either a mild, moderate or severe phonological disorder. Due to the nature of the intervention, participants and therapists cannot be blinded to the experimental condition. However, pre- and post-test assessments of speech production will be carried out by a researcher/therapist blind to the assigned condition.</p></sec></sec><sec id="s4"><title>Proposed analysis</title><p>The assessments of speech production will be transcribed to an Excel spreadsheet. Statistical analysis will be performed using the Statistical Package for the Social Sciences (IBM SPSS Statistics 24).</p><p>The key question to be addressed in this research is: How does feedback type during speech therapy session influence children's production performance. As such, the key dependent variable under analysis will be PCC, phonological process percentage of occurrence and percentage accuracy of trials. Published data of PCC in children's development (e.g., Dodd et al., <xref rid="B14" ref-type="bibr">2002</xref>) suggest that this variable to be normally distributed. As such we intend to perform a full-factorial regression analysis on PCC with feedback condition, number of trials completed, and child age (4, 5, or 6 years) and severity as predictor variables. The full-factorial nature of this analysis will allow us to determine how the effects of condition and trials completed independently predict PCC and the extent to which these factors interact in their effects on PCC between pretest and post-test. For example, we may find that with certain types of feedback, the number of trials completed has a much greater effect than with other types of feedback. Similarly, we may find that some feedback types have a greater effect on performance for younger or older children. These analyses will also be completed with phonological process percentage of occurance at pretest and post-test and percentage accuracy of trials as a dependant variables</p><p>We will also conduct a Generalized Linear Model Analysis assuming a binomial distribution for the number of correct trials post &#x0201c;intervention&#x0201d; within a total of <italic>n</italic> trials where <italic>n</italic> may differ between children. The analysis will control for pre &#x0201c;intervention&#x0201d; language skills, age, and gender. Marginal means will be compared for the five groups using a Bonferroni correction for multiple comparisons. This analysis could assist in distinguishing the effects of real-world simulation vs. verification feedback and the presence of articulation guidance.</p><p>Motivation to persevere could be considered a variable that mediates the impact of type of feedback. Consequently, we will also perform a one-way ANOVA to determine how feedback condition influences motivation as measured by the number of trials and the duration of game play.</p><p>A G-Power power analysis suggested a total sample size of 150 in order to detect a moderate to large effect size (<italic>f</italic> = 0.32) with 5% significance and 80% power. Our recruitment plan of 30 participants in each of our 5 conditions is consistent with the G-Power analysis suggestion to avoid type II error.</p></sec><sec id="s5"><title>Anticipated results</title><p>With respect to research question 1, this study aims to investigate the effectiveness of four different types of feedback in improving speech sounds in young children while using a multimedia platform. Each of the three theoretical frameworks for learning discussed in the Background section predict that KR, the prevalent feedback in speech learning applications, will be the least effective because it does not contain information to assist learners in improving their speech production (Shute, <xref rid="B41" ref-type="bibr">2008</xref>). The conversational framework for multimedia learning predicts that intrinsic feedback will be more effective than KR feedback because it is most likely to resemble real-world speech learning experiences which can be built upon (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>). This framework predicts that the most effective feedback overall will be intrinsic combined with topic contingent KP because children will be able to elaborate and refine knowledge gleaned from real-world experiences with lessons learned during speech pathologist/learner dialogue (Laurillard, <xref rid="B23" ref-type="bibr">2002</xref>). Within the context of novice-expert learning (Mason and Bruning, <xref rid="B25" ref-type="bibr">2001</xref>; Moreno, <xref rid="B32" ref-type="bibr">2004</xref>) children who are more responsive to therapy (influenced by factors such as age and severity of disorder) might benefit from KR combined with topic contingent KP, possibly because they could benefit from smaller amounts of more focused feedback. This combination is also prevalent in speech pathology practice.</p><p>With respect to research question 2, the prediction that the two conditions with intrinsic feedback will be the most effective in improving speech production is accompanied by the prediction that these two conditions will also be the most motivating because they will be situated in natural and social scenarios that could be more visually appealing, possibly more challenging (Mayer, <xref rid="B30" ref-type="bibr">2014b</xref>) while offering greater autonomy and relevance (Ryan et al., <xref rid="B39" ref-type="bibr">2006</xref>) and consequently should encourage more trials and longer gameplay. We also anticipate that other features of the respective feedback types will emerge from the analysis to suggest variables that will improve their effectiveness.</p></sec><sec sec-type="conclusions" id="s6"><title>Conclusion</title><p>It is difficult to find evidence of the efficacy of existing mobile applications to assist young children with developmental speech sound delay. This might be because they generally do not provide informative feedback about the sounds being made by the child. Considerable resources are required to develop mobile multimedia applications. By using a human &#x0201c;Wizard&#x0201d; to provide feedback about the speech sounds that children make while playing a game on a mobile device, evidence for effective feedback will be gathered before substantial development costs are incurred. The results of this experiment will inform the development of a Virtual Speech Therapist that provides pedagogically and clinically sound feedback to assist speech development in young children. The results could also inform other types of language learning.</p></sec><sec id="s7"><title>Author contributions</title><p>All authors contributed to conception and design of the protocol. All authors except HA wrote sections of the manuscript, read and approved the submitted version. WD and KF contributed to the illustrations and manuscript revision; WD commissioned and tested the prototype; HA contributed to the app review.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. The reviewers and handling Editor declared their shared affiliation.</p></sec></sec></body><back><ack><p>We thank Professor Denny Meyer of Swinburne University of Technology, Australia, for her expert assistance with statistical analysis.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>M. M.</given-names></name></person-group> (<year>2013</year>). <article-title>Intervention efficacy and intensity for children with speech sound disorder</article-title>. <source>J. Speech Lang. Hear. Res.</source>
<volume>56</volume>, <fpage>865</fpage>&#x02013;<lpage>877</lpage>. <pub-id pub-id-type="doi">10.1044/1092-4388(2012/11-0076)</pub-id><pub-id pub-id-type="pmid">23275415</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Minimal pair intervention</article-title>, in <source>Interventions for Speech Sound Disorders in Children</source>, eds <person-group person-group-type="editor"><name><surname>Williams</surname><given-names>A. L.</given-names></name><name><surname>McLeod</surname><given-names>S.</given-names></name><name><surname>McCauley</surname><given-names>R. J.</given-names></name></person-group> (<publisher-loc>Baltimore, MD</publisher-loc>: <publisher-name>Paul H. Brookes Publishing Co</publisher-name>), <fpage>41</fpage>&#x02013;<lpage>72</lpage>.</mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>E.</given-names></name></person-group> (<year>2012</year>). <article-title>Optimal intervention intensity</article-title>. <source>Int. J. Speech Lang. Pathol.</source>
<volume>14</volume>, <fpage>401</fpage>&#x02013;<lpage>409</lpage>. <pub-id pub-id-type="doi">10.3109/17549507.2012.700323</pub-id><pub-id pub-id-type="pmid">22916999</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyle</surname><given-names>E. A.</given-names></name><name><surname>Hainey</surname><given-names>T.</given-names></name><name><surname>Connolly</surname><given-names>T. M.</given-names></name><name><surname>Gray</surname><given-names>G.</given-names></name><name><surname>Earp</surname><given-names>J.</given-names></name><name><surname>Ott</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>An update to the systematic literature review of empirical evidence of the impacts and outcomes of computer games and serious games</article-title>. <source>Comput. Educ.</source>
<volume>94</volume>, <fpage>178</fpage>&#x02013;<lpage>192</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2015.11.003</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>A. C.</given-names></name><name><surname>Godbole</surname><given-names>N.</given-names></name><name><surname>Marsh</surname><given-names>E. J.</given-names></name></person-group> (<year>2013</year>). <article-title>Explanation feedback is better than correct answer feedback for promoting transfer of learning</article-title>. <source>J. Educ. Psychol.</source>
<volume>105</volume>, <fpage>290</fpage>&#x02013;<lpage>298</lpage>. <pub-id pub-id-type="doi">10.1037/a0031026</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>R. C.</given-names></name><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2016</year>). <source>E-Learning and the Science of Instruction Proven Guidelines for Consumers and Designers of Multimedia Learning</source>. <edition>4th Edn</edition>
<publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Community Affairs References Committee</collab></person-group> (<year>2014</year>). <source>Prevalence of Different Types of Speech, Language and Communication Disorders and Speech Pathology Services in Australia</source>. <publisher-loc>Canberra, ACT</publisher-loc>: <publisher-name>Senate Community Affairs Committee Secretariat</publisher-name>.</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connolly</surname><given-names>T. M.</given-names></name><name><surname>Boyle</surname><given-names>E. A.</given-names></name><name><surname>MacArthur</surname><given-names>E.</given-names></name><name><surname>Hainey</surname><given-names>T.</given-names></name><name><surname>Boyle</surname><given-names>J. M.</given-names></name></person-group> (<year>2012</year>). <article-title>A systematic literature review of empirical evidence on computer games and serious games</article-title>. <source>Comp. Amp. Educ.</source>
<volume>59</volume>, <fpage>661</fpage>&#x02013;<lpage>686</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2012.03.004</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbalan</surname><given-names>G.</given-names></name><name><surname>Kester</surname><given-names>L.</given-names></name><name><surname>van Merri&#x000eb;nboer</surname><given-names>J. J. G.</given-names></name></person-group> (<year>2009</year>). <article-title>Dynamic task selection: effects of feedback and learner control on efficiency and motivation</article-title>. <source>Learn. Instr.</source>
<volume>19</volume>, <fpage>455</fpage>&#x02013;<lpage>465</lpage>. <pub-id pub-id-type="doi">10.1016/j.learninstruc.2008.07.002</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crosbie</surname><given-names>S.</given-names></name><name><surname>Holm</surname><given-names>A.</given-names></name><name><surname>Dodd</surname><given-names>B.</given-names></name></person-group> (<year>2005</year>). <article-title>Intervention for children with severe speech disorder: a comparison of two approaches</article-title>. <source>Intl. J. Lang. Commun. Disord.</source>
<volume>40</volume>, <fpage>467</fpage>&#x02013;<lpage>491</lpage>. <pub-id pub-id-type="doi">10.1080/13682820500126049</pub-id><pub-id pub-id-type="pmid">16195201</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deci</surname><given-names>E.</given-names></name><name><surname>Koestner</surname><given-names>R.</given-names></name><name><surname>Ryan</surname><given-names>R. M.</given-names></name></person-group> (<year>1999</year>). <article-title>A meta-analytic review of experiments examining the effects of extrinisc rewards on intrinsic motivation</article-title>. <source>Psychol. Bull.</source>
<volume>125</volume>, <fpage>627</fpage>&#x02013;<lpage>668</lpage>. <pub-id pub-id-type="pmid">10589297</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dodd</surname><given-names>B.</given-names></name></person-group> (<year>2005</year>). <article-title>Children with speech disorder: defining the problem</article-title>, in <source>Differential Diagnosis and Treatment of Children With Speech Disorder</source>, ed <person-group person-group-type="editor"><name><surname>Dodd</surname><given-names>B.</given-names></name></person-group> (<publisher-loc>London</publisher-loc>: <publisher-name>Whurr</publisher-name>), <fpage>2</fpage>&#x02013;<lpage>23</lpage>.</mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodd</surname><given-names>B.</given-names></name></person-group> (<year>2014</year>). <article-title>Differential diagnosis of pediatric speech sound disorder</article-title>. <source>Curr. Dev. Disord. Rep.</source>
<volume>1</volume>, <fpage>189</fpage>&#x02013;<lpage>196</lpage>. <pub-id pub-id-type="doi">10.1007/s40474-014-0017-3</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dodd</surname><given-names>B.</given-names></name><name><surname>Hau</surname><given-names>Z.</given-names></name><name><surname>Crosbie</surname><given-names>S.</given-names></name><name><surname>Holm</surname><given-names>A.</given-names></name><name><surname>Ozanne</surname><given-names>A.</given-names></name></person-group> (<year>2002</year>). <source>Diagnostic Evaluation of Articulation and Phonology.</source>
<publisher-loc>London</publisher-loc>: <publisher-name>Pearson</publisher-name>.</mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engwall</surname><given-names>O.</given-names></name><name><surname>B&#x000e4;lter</surname><given-names>O.</given-names></name></person-group> (<year>2008</year>). <article-title>Pronunciation feedback from real and virtual language teachers</article-title>. <source>Comp. Assist. Lang. Learn.</source>
<volume>20</volume>, <fpage>235</fpage>&#x02013;<lpage>262</lpage>. <pub-id pub-id-type="doi">10.1080/09588220701489507</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engwall</surname><given-names>O.</given-names></name><name><surname>Balter</surname><given-names>O.</given-names></name><name><surname>Oster</surname><given-names>A.-M.</given-names></name><name><surname>Kjellstrom</surname><given-names>H.</given-names></name></person-group> (<year>2006</year>). <article-title>Designing the user interface of the computer-based speech training system ARTUR based on early user tests</article-title>. <source>Behav. Inf. Technol.</source>
<volume>25</volume>, <fpage>353</fpage>&#x02013;<lpage>365</lpage>. <pub-id pub-id-type="doi">10.1080/01449290600636702</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hainey</surname><given-names>T.</given-names></name><name><surname>Connolly</surname><given-names>T. M.</given-names></name><name><surname>Boyle</surname><given-names>E. A.</given-names></name><name><surname>Wilson</surname><given-names>A.</given-names></name><name><surname>Razak</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>A systematic literature review of games-based learning empirical evidence in primary education</article-title>. <source>Comput. Educ.</source>
<volume>102</volume>, <fpage>202</fpage>&#x02013;<lpage>223</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2016.09.001</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harks</surname><given-names>B.</given-names></name><name><surname>Rakoczy</surname><given-names>K.</given-names></name><name><surname>Hattie</surname><given-names>J.</given-names></name><name><surname>Besser</surname><given-names>M.</given-names></name><name><surname>Klieme</surname><given-names>E.</given-names></name></person-group> (<year>2014</year>). <article-title>The effects of feedback on achievement, interest and self-evaluation: the role of feedback's perceived usefulness</article-title>. <source>Educ. Psychol.</source>
<volume>34</volume>, <fpage>269</fpage>&#x02013;<lpage>290</lpage>. <pub-id pub-id-type="doi">10.1080/01443410.2013.785384</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hewlet</surname><given-names>N.</given-names></name></person-group> (<year>1990</year>). <article-title>Process of development and production</article-title>, in <source>Developmental Speech Disorders</source>, ed <person-group person-group-type="editor"><name><surname>Grunwell</surname><given-names>P.</given-names></name></person-group> (<publisher-loc>Edinburgh</publisher-loc>: <publisher-name>Churchill Livingstone</publisher-name>), <fpage>15</fpage>&#x02013;<lpage>38</lpage>.</mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>B.</given-names></name><name><surname>Tarasuik</surname><given-names>J.</given-names></name><name><surname>Antoniou</surname><given-names>M. N.</given-names></name><name><surname>Garrett</surname><given-names>C.</given-names></name><name><surname>Bowe</surname><given-names>S. J.</given-names></name><name><surname>Kaufman</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Young children's transfer of learning from a touchscreen device</article-title>. <source>Comput. Human Behav.</source>
<volume>56</volume>, <fpage>56</fpage>&#x02013;<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1016/j.chb.2015.11.010</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaipa</surname><given-names>R.</given-names></name><name><surname>Peterson</surname><given-names>A. M.</given-names></name></person-group> (<year>2016</year>). <article-title>A systematic review of treatment intensity in speech disorders</article-title>. <source>Int. J. Speech Lang. Pathol</source>. <volume>18</volume>, <fpage>507</fpage>&#x02013;<lpage>520</lpage>. <pub-id pub-id-type="doi">10.3109/17549507.2015.1126640</pub-id><pub-id pub-id-type="pmid">27063688</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ke</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>). <article-title>An implementation of design-based learning through creating educational computer games: a case study on mathematics learning during design and computing</article-title>. <source>Comput. Educ.</source>
<volume>73</volume>, <fpage>26</fpage>&#x02013;<lpage>39</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2013.12.010</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Laurillard</surname><given-names>D.</given-names></name></person-group> (<year>2002</year>). <source>Rethinking University Teaching: A Conversational Framework for the Effective Use of Learning Technologies</source>, <edition>2nd Edn</edition>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Routledge</publisher-name>.</mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maas</surname><given-names>E.</given-names></name><name><surname>Robin</surname><given-names>D. A.</given-names></name><name><surname>Hula</surname><given-names>S. N.</given-names></name><name><surname>Freedman</surname><given-names>S. E.</given-names></name><name><surname>Wulf</surname><given-names>G.</given-names></name><name><surname>Ballard</surname><given-names>K. J.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Principles of motor learning in treatment of motor speech disorders</article-title>. <source>Am. J. Speech Lang. Pathol.</source>
<volume>17</volume>, <fpage>277</fpage>&#x02013;<lpage>298</lpage>. <pub-id pub-id-type="doi">10.1044/1058-0360(2008/025)</pub-id><pub-id pub-id-type="pmid">18663111</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mason</surname><given-names>B. J.</given-names></name><name><surname>Bruning</surname><given-names>R. H.</given-names></name></person-group> (<year>2001</year>). <source>Providing Feedback in Computer-based Instruction: What the Research Tells Us.</source> CLASS Research Report No. 9.</mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massaro</surname><given-names>D. W.</given-names></name><name><surname>Light</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>Using visible speech to train perception and production of speech for individuals with hearing loss</article-title>. <source>J. Speech Lang. Hear. Res.</source>
<volume>47</volume>, <fpage>304</fpage>&#x02013;<lpage>320</lpage>. <pub-id pub-id-type="doi">10.1044/1092-4388(2004/025)</pub-id><pub-id pub-id-type="pmid">15157132</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masso</surname><given-names>S.</given-names></name><name><surname>McCabe</surname><given-names>P.</given-names></name><name><surname>Baker</surname><given-names>E.</given-names></name></person-group> (<year>2014</year>). <article-title>How do children with phonological impairment respond to requests for clarification containing polysyllables?</article-title>
<source>Child Lang. Teach. Ther.</source>
<volume>30</volume>, <fpage>367</fpage>&#x02013;<lpage>382</lpage>. <pub-id pub-id-type="doi">10.1177/0265659013516330</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2005</year>). <source>Cognitive Theory of Multimedia Learning</source>. <publisher-loc>Cambridge; NewYork, NY</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref><ref id="B29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2014a</year>). <source>Computer Games for Learning: an Evidence-Based Approach</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>R. E.</given-names></name></person-group> (<year>2014b</year>). <article-title>Incorporating motivation into multimedia learning</article-title>. <source>Learn. Instr.</source>
<volume>29</volume>, <fpage>171</fpage>&#x02013;<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1016/j.learninstruc.2013.04.003</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>Z.</given-names></name><name><surname>Goetz</surname><given-names>E. T.</given-names></name><name><surname>Cifuentes</surname><given-names>L.</given-names></name><name><surname>Keeney-Kennicutt</surname><given-names>W.</given-names></name><name><surname>Davis</surname><given-names>T. J.</given-names></name></person-group> (<year>2014</year>). <article-title>Effectiveness of virtual reality-based instruction on students' learning outcomes in K-12 and higher education: a meta-analysis</article-title>. <source>Comput. Educ.</source>
<volume>70</volume>, <fpage>29</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2013.07.033</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>R.</given-names></name></person-group> (<year>2004</year>). <article-title>Decreasing cognitive load for novice students: effects of explanatory versus corrective feedback in discovery-based multimedia</article-title>. <source>Instr. Sci.</source>
<volume>32</volume>, <fpage>99</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1023/B:TRUC.0000021811.66966.1d</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Narciss</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Conditions and effects of feedback viewed through the lens of the interactive tutoring feedback model</article-title>, in <source>Scaling Up Assessment for Learning in Higher Education</source>, eds <person-group person-group-type="editor"><name><surname>Bridges</surname><given-names>S. M.</given-names></name><name><surname>Carless</surname><given-names>D. C.</given-names></name><name><surname>Yuk</surname><given-names>C. K.</given-names></name><name><surname>Glofcheski</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Singapore</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>173</fpage>&#x02013;<lpage>188</lpage>.</mixed-citation></ref><ref id="B34"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Narciss</surname><given-names>S.</given-names></name><name><surname>Huth</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>How to design informative tutoring feedback for multimedia learning</article-title>, in <source>Instructional Design for Multimedia Learning</source>, eds <person-group person-group-type="editor"><name><surname>Niegemann</surname><given-names>H. M.</given-names></name><name><surname>Leutner</surname><given-names>D.</given-names></name><name><surname>Brunken</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Munster; New York, NY</publisher-loc>: <publisher-name>Waxmann</publisher-name>), <fpage>181</fpage>&#x02013;<lpage>195</lpage>.</mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narciss</surname><given-names>S.</given-names></name><name><surname>Sosnovsky</surname><given-names>S.</given-names></name><name><surname>Schnaubert</surname><given-names>L.</given-names></name><name><surname>Andr&#x000e8;s</surname><given-names>E.</given-names></name><name><surname>Eichelmann</surname><given-names>A.</given-names></name><name><surname>Goguadze</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Exploring feedback and student characteristics relevant for personalizing feedback strategies</article-title>. <source>Comput. Educ.</source>
<volume>71</volume>, <fpage>56</fpage>&#x02013;<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2013.09.011</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hodson</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>) <source>Evaluating and Enhancing Children's Phonological Systems: Research and Theory to Practice</source>. <publisher-loc>Wichita, KS</publisher-loc>: <publisher-name>Phonocomp Publishers</publisher-name>.</mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redford</surname><given-names>M. A.</given-names></name><name><surname>Diehl</surname><given-names>R. L.</given-names></name></person-group> (<year>1999</year>). <article-title>The relative perceptual distinctiveness of initial and final consonants in CVC syllables</article-title>. <source>J. Acoust. Soc. Am.</source>
<volume>106</volume>, <fpage>1555</fpage>&#x02013;<lpage>1565</lpage>. <pub-id pub-id-type="doi">10.1121/1.427152</pub-id><pub-id pub-id-type="pmid">10489711</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Renals</surname><given-names>S.</given-names></name><name><surname>King</surname><given-names>S.</given-names></name></person-group> (<year>2010</year>). <source>Automatic Speech Recognition the Handbook of Phonetic Sciences</source>, <edition>2nd Edn</edition>
<publisher-loc>Oxford</publisher-loc>: <publisher-name>Blackwell Publishing Ltd</publisher-name>
<fpage>804</fpage>&#x02013;<lpage>838</lpage></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname><given-names>R. M.</given-names></name><name><surname>Rigby</surname><given-names>C. S.</given-names></name><name><surname>Przybylski</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>The motivational pull of video games: a self-determination theory approach</article-title>. <source>Motiv. Emot.</source>
<volume>30</volume>, <fpage>347</fpage>&#x02013;<lpage>363</lpage>. <pub-id pub-id-type="doi">10.1007/s11031-006-9051-8</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Semel</surname><given-names>E. M.</given-names></name><name><surname>Wiig</surname><given-names>E. H.</given-names></name><name><surname>Secord</surname><given-names>W. A.</given-names></name><name><surname>Hannan</surname><given-names>T.</given-names></name></person-group> (<year>2006</year>). <article-title>Clinical evaluation of language fundamentals</article-title>, in <source>CELF-4: Australian, 4th Edn., Australian Standardised Edition</source>. ed PsychCorp (<publisher-loc>Sydney, NSW</publisher-loc>: <publisher-name>Pearson Clinical and Talent Assessment</publisher-name>).</mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shute</surname><given-names>V. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Focus on formative feedback</article-title>. <source>Rev. Educ. Res.</source>
<volume>78</volume>, <fpage>153</fpage>&#x02013;<lpage>189</lpage>. <pub-id pub-id-type="doi">10.3102/0034654307313795</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Topping</surname><given-names>K.</given-names></name><name><surname>Dekhinet</surname><given-names>R.</given-names></name><name><surname>Zeedyk</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>Parent&#x02013;infant interaction and children's language development</article-title>. <source>Educ. Psychol.</source>
<volume>33</volume>, <fpage>391</fpage>&#x02013;<lpage>426</lpage>. <pub-id pub-id-type="doi">10.1080/01443410.2012.744159</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Doremalen</surname><given-names>J.</given-names></name><name><surname>Boves</surname><given-names>L.</given-names></name><name><surname>Colpaert</surname><given-names>J.</given-names></name><name><surname>Cucchiarini</surname><given-names>C.</given-names></name><name><surname>Strik</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>). <article-title>Evaluating automatic speech recognition-based language learning systems: a case study</article-title>. <source>Comp. Assisted Lang. Learn.</source>
<volume>29</volume>, <fpage>833</fpage>&#x02013;<lpage>851</lpage>. <pub-id pub-id-type="doi">10.1080/09588221.2016.1167090</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Heuven</surname><given-names>W. J.</given-names></name><name><surname>Mandera</surname><given-names>P.</given-names></name><name><surname>Keuleers</surname><given-names>E.</given-names></name><name><surname>Brysbaert</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>SUBTLEX-UK: a new and improved wordfrequency database for British English</article-title>. <source>Q. J. Exp. Psychol.</source>
<volume>67</volume>. <fpage>1176</fpage>&#x02013;<lpage>1190</lpage>. <pub-id pub-id-type="doi">10.1080/17470218.2013.850521</pub-id><pub-id pub-id-type="pmid">24417251</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiner</surname><given-names>F. F.</given-names></name><name><surname>Ostrowski</surname><given-names>A. A.</given-names></name></person-group> (<year>1979</year>). <article-title>Effects of listener uncertainty on articulatory consistency</article-title>. <source>J. Speech Hear. Disord.</source>
<volume>25</volume>, <fpage>300</fpage>&#x02013;<lpage>309</lpage>.</mixed-citation></ref><ref id="B46"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wiig</surname><given-names>E. H.</given-names></name><name><surname>Semel</surname><given-names>E. M.</given-names></name><name><surname>Secord</surname><given-names>W.</given-names></name><name><surname>Carstairs</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <source>CELF Preschool 2 : Australian and New Zealand Clinical Evaluation of Language Fundamentals, Preschool Clinical Evaluation of Language Fundamentals, Preschool</source>, <edition>2nd Edn</edition>
<publisher-loc>Sydney, NSW</publisher-loc>: <publisher-name>Pearson Clinical and Talent Assessment; PsychCorp</publisher-name>.</mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>A. L.</given-names></name></person-group> (<year>2012</year>). <article-title>Intensity in phonological intervention: is there a prescribed amount?</article-title>
<source>Int. J. Speech Lang. Pathol.</source>
<volume>14</volume>, <fpage>456</fpage>&#x02013;<lpage>461</lpage>. <pub-id pub-id-type="doi">10.3109/17549507.2012.688866</pub-id><pub-id pub-id-type="pmid">22686582</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yont</surname><given-names>K.</given-names></name><name><surname>Hewitt</surname><given-names>L.</given-names></name><name><surname>Miccio</surname><given-names>A.</given-names></name></person-group> (<year>2000</year>). <article-title>A coding system for describing conversational breakdowns in preschool children</article-title>. <source>Am. J. Speech &#x02013; Lang. Pathol.</source>
<volume>9</volume>, <fpage>300</fpage>&#x02013;<lpage>309</lpage>. <pub-id pub-id-type="doi">10.1044/1058-0360.0904.300</pub-id></mixed-citation></ref></ref-list></back></article>